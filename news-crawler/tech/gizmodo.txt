
All things must come to an end, including human civilization. Whether it’s a superbug pandemic tomorrow or a supernova sun in billions of years, one day, somehow, the apocalypse will arrive. You and loved ones plan on being ready for it, and ready for what comes after.
Here are eleven damn useful holiday gifts to ensure that you not only survive the End Times but rebuild and prosper, zombie hordes be damned.
Living in an apocalyptic wasteland, you’re naturally going to be concerned about nuclear radiation. That’s where Quatra-Rad’s RADEX 1503+ high accuracy geiger counter and radiation detector can help. This handheld device can be used to measure beta, gamma, and x-ray radiation, so you’ll never have to wonder if that meal you just scrounged up is going to make your insides explode. It’s got an easy-to-use interface, and an audio and vibration alarm that’ll go off when you venture too close to an area bathing in radioactive waste. It takes a pair of AAA batteries, so you’ll need to stock up on those too before armageddon hits. (RADEX by Quarta-Rad, $158)
Speaking of radiation, you’re also going to want to load up on some high-potency potassium iodine. Known as KI to chemists, this chemical compound prevents radioactive iodine from being absorbed by the thyroid gland, which is a very good thing seeing as your thyroid plays critical role in metabolism, growth, and development.


When a person ingests potassium iodine, the thyroid gland becomes “full,” preventing radioactive iodine from filtering in for 24 hours. Pop one of these suckers if you’re at risk of being zapped by some gamma radiation, and you can rest with ease. Do yourself a favor and grab a bunch, but pay attention to those expiration dates. (Relentless Improvement, $17)
The apocalypse may sound dark, but your survival bunker shouldn’t be. Provided this isn’t a Matrix-esque robots-blacking-out-the-sky situation, MPOWERD’s solar-powered LED lantern will keep your long nights illuminated, lasting up to 12 hours on a single, seven-hour charge. And if you’re planning to go backpacking through civilization’s wreckage, don’t forget to bring it along, too. The lantern is collapsible, waterproof, and weighs just 4.4 pounds. (MPOWERD, $6)
Of all the ways civilization could end, a bio-apocalypse has to be of the scariest. After all, survivors are just one contaminated drink away from agonizing death (followed by re-animation as a zombie, obviously). To survive, you’ll need a water purifier that can remove all sorts of deadly bugs, from anthrax spores and bubonic plague to tiny, genetically modified superviruses. Available in 5 and 12 liter sizes, LifeStraw’s gravity-fed water filter is rated to remove 99.99+ percent of biological contaminants, and has a lifetime capacity of 18,000 liters. (LifeStraw, $130)
You’re going to have a lot of new skills to learn once armageddon hits. With a good fire starter, at least, you can ensure your meat is properly cooked until you master the art of striking flint against knife. This handy survival device ignites in rain or shine, and is good for up to 4,000 strikes—which gives you plenty of time to figure out how to make fires the old fashioned way. (Ultimate Survival Technologies, $13)
Rated to keep astronauts warm during space exploration—provided you also have a decent spacecraft—TITAN’s emergency sleeping bag is a must-have for apocalypse survivors seeking to weather the most extreme environmental changes. (Remember Snowpiercer? A climate apocalypse doesn’t necessarily mean global warming.) Best of all, this extra warm sleeping bag packs into a nylon drawstring bag that’ll fit comfortably in your survival pack. (TITAN Survival, $18)
Described as one tool with “a couple thousand uses,” Leatherman’s Signal multi-tool won’t solve all of your problems in the apocalypse, but it’ll solve a lot of the little ones, from cutting through barbed wire fences to picking locks to opening all of those canned rations you’re going to be eating. The multi-tool features two kinds of pliers, wire cutters and strippers, a combo knife, a saw, a hammer, a box wrench, and more. The only tool I can’t imagine getting much use in the apocalypse is the safety whistle. (Leatherman, $100)
Eventually, you’re going to have to get used to a low-tech lifestyle after civilization collapses. But with a little care and a sun-powered charger, your beloved smartphones, tablets, and laptops might last a long time—definitely long enough to memorize every movie and TV show you downloaded back to front. Anker’s 15 Watt USB charger is compact, lightweight, and rated to convert about 20 percent of the sun’s energy into sweet, sweet electricity, enough to charge two devices simultaneously. Of course, if nuclear winter forces you to migrate underground, get used to reading paper books again. (Anker, $80)
One of my favorite apocalypse writers, Paolo Bacigalupi, thinks a lot about the future of food. In his hit science fiction novel The Windup Girl, aggressive genetic modification of the global food supply renders our staple crops susceptible to horrific diseases. Only after generations of ecological destruction do scientists realize the error of their ways, and begin hunting for lost genetic diversity to fortify the world’s dwindling food supply.


Whether or not we’re in for a GMO-trigged ag-pocalypse, the ability to grow a variety of foods will be critical to our long-term survival after collapse. With 32 varieties of fruits and vegetables from corn to kale to cantaloupe, this 15,000 seed survival garden is going to be your lifeline, so keep it somewhere safe. (Open Seed Vault, $18)
Nothing like an actual armageddon to make violent fantasy realms seem pretty relatable, am I right? Entertainment is a must in the post-apocalyptic future, and if your people can’t get their kicks from stories, they’re going to start torturing animals. With this 5-box set of George R.R. Martin’s Game of Thrones series, you can relive the exhilarating adventures of Starks, Targaryens and Lannisters long after HBO’s dead.


Let’s just hope our buddy George gives this series an ending before the End Times hits. (Amazon, $30)
Surviving the apocalypse isn’t just about fighting off zombies and cannibalistic road warriors, although those bits are important and exciting. Eventually, once you and your fellow survivors establish a secure base, you need to think about rebuilding civilization. Lewis Dartnell’s The Knowledge will help you get started.


We take for granted the centuries of accumulated learning, in everything from mining to medicine, that’s enabled countless technologies and consumer goods to permeate our lives. But after the global supply chain and industrial-scale production collapses, we’re going to have to learn how to do a lot of things from scratch. Want to build a radio? First, you’ll need to extract metals from the ground, produce electricity, and learn to solve problems like an engineer. Dartnell’s apocalypse guide is a brilliant primer on all of this and more. (Amazon, $16)
George Dvorsky contributed to this post.
On December 5th, 1952, a veil of fog rolled over the city of London. It was the start of the deadliest air pollution disaster in British history, and more than sixty years later, an international team of chemists has figured out why.
Locals paid little heed to the fog at first—after all, foggy days have been a hallmark of life in Britain for thousands of years. But by late afternoon, the sky had taken on a yellowish hue and was beginning to smell like rotten eggs.


The next day, the air was the color of pea soup and reeked of foul garbage. As the hours  wore on, visibility got poorer and poorer, and breathing outside became painful. This torture went on for five days. By the time the fog lifted on December 9th, 150,000 people had been hospitalized. Experts now estimate that over 12,000 men, women, and children died from exposure to the befouled air.
London’s Great Smog, as the disaster is now known, was immediately (and correctly) blamed on coal. But the details of what exactly happened remained elusive for decades. Now, through laboratory experiments and atmospheric measurements in two pollution-prone Chinese cities, Xi’an and Beijing, a team lead by Texas A&M’s Renyi Zhang has worked out a likely explanation for the Great Smog and other deadly air pollution events around the world. Their work is published this week in the Proceedings of the National Academies of Sciences.


One of the hallmarks of the Great Smog was sulfate, particles of sulfuric acid that not only contributed to its hue and odor, but its toxic effects on humans. In their study, Zhang and his team demonstrate that under naturally foggy conditions, sulfate will build up inside water droplets due to chemical interactions between sulfur dioxide and nitrogen dioxide. Sulfur dioxide and nitrogen dioxide both come out of coal-fired chimneys, and to a lesser extent, out the tailpipes of automobiles.


“People have known that sulfate was a big contributor to the fog, and sulfuric acid particles were formed from sulfur dioxide released by coal burning,” Zhang said in a statement. “Our results showed that this process was facilitated by nitrogen dioxide, another co-product of coal burning, and occurred initially on natural fog.”
Sulfate, in turn, helps promote the formation of other particles, including nitrate and organic matter, exacerbating the development of severe haze. Eventually, as the water in fog dries up, the acid becomes concentrated, leaving corrosive, gross looking haze particles that coat every surface they come in contact with, from sidewalks to human lungs.
The study found that similar chemistry is responsible for smoggy skies in Beijing and X’ian, although in these cities, agricultural chemicals like ammonia can play a role, too. While it took a certain combination of chemicals and unfavorable weather for  the Great Smog to develop, overall, the study suggests that the conditions behind this deadly event can, in theory, develop all over the world.
If there’s one silver lining to the Great Smog, it’s that it kickstarted an environmental movement that led to the passage of some of the first clean air laws. Now that we’ve worked out more of the finer details, the impetus for ridding the world of coal seems stronger than ever.


[Proceedings of the National Academies of Sciences]
A new machine designed at Stanford University sends digital messages without electronics, using common household chemicals. Eventually, similar systems could allow tiny devices to communicate inside the body, or be adapted to environments in which traditional electronics break down.
This intriguing chemical-based communication system was developed by Nariman Farsad, a post-doctoral fellow at Andrea Goldsmith’s electrical engineering lab. Though unorthodox,  chemical communication opens up many new possibilities in the way we transmit and receive information. In addition to being wireless and cheap, it can work without the benefit of electronics. Consequently, it could be used in environments typically out of reach for electronic systems, such as under water or in places where metal is abundant.


In a nutshell, the system turns pH changes into code, using pulses of an acid (vinegar) and a base (household glass clear) to create zeros and ones. These yin-and-yang chemicals are enough for a small sensor to detect a change in pH, and encode that change as a zero or one. Voila, instant binary code—albeit one driven by liquids instead of electronics.
When using the system, the researchers type a desired message on a small computer. A signal goes out to a machine that pumps out the corresponding “bits” of chemicals, i.e. either a spurt of vinegar or the glass cleaner, which travels through plastic tubes to a small container containing the pH sensor. The changes are then transmitted to a computer that deciphers the encoded message.

Farsad used these particular chemicals because they’re easily obtainable, and because they cancel out at the receiving end of the system.


The potential for this system is limited only by the imagination. Scenarios proposed by the researchers include sending secret messages that others aren’t aware of, having robots message each other with chemical trails, or even substituting for conventional communications in the the event that the electric grid (or an electronic device) is knocked out by an electromagnetic pulse or terrorist attack. Excitingly, the system could even be adapted to work in the human body, in which nanobots could communicate with other tiny machines via liquid text.
This concept is still very much in its early stages, and several limitations still need to be sorted out, including finding ways to transmit the signals over longer distances, figuring out how to separate the signal from the noise at the end of the system (residue is a problem), and ways to power the system.
Here’s to hoping that Farsad and Goldsmith solve these issues—this idea is simply too cool to be allowed to die on the vine.
[Stanford University]
Scientists have learned that upwards of 25 percent of all people who become infected with Ebola show none of the typical symptoms. The finding suggests the recent West African Ebola Epidemic was more widespread than previously thought, and that new methods need to be developed to diagnose and contain the dreaded virus during an outbreak.
Typically, Ebola produces a panoply of symptoms, including fever, unexplained bleeding, headache, muscle pain, rash, vomiting, diarrhea, breathing problems, and difficulty swallowing. As is well documented, this virus is particularly deadly, killing between 10 to 80 percent of people who exhibit these symptoms (the statistical spread reflects the divide between those who have access to intensive care and those who don’t).


But as a new study published in PLOS Neglected Tropical Diseases shows, a significant portion of people who contract Ebola don’t show any of the typical signs, meaning they’re asymptomatic, or their symptoms are relatively mild and not wholly reflective of how the virus affects most people. In other words, they have “minimally symptomatic infections.”
Prior to the new study, scientists suspected that Ebola, like many other viruses, might not always manifest in the same predictable way. The new study, led by Gene Richardson, a PhD candidate in anthropology at Stanford University and a former fellow in the Division of Infectious Diseases and Geographic Medicine, now confirms this suspicion, while providing an actual estimate for the rate of asymptomatic and minimally symptomatic infections in Ebola patients.


Following the recent West African Ebola Epidemic, Richardson and his colleagues went back to the rural village of Sukudu in Sierra Leone, a major hotspot for the outbreak. The village, which is home to 900 residents, recorded 34 cases of Ebola during the epidemic, including 28 deaths. Working with a local physician, Richardson’s team tested 187 men, women, and children from Sukudu who had likely been exposed to Ebola, either because they lived in the same household or shared a public toilet with a person known to have had the disease.


Of these, 14 were found to carry an antibody to Ebola—a sure sign that they were infected at some point. A dozen of these villagers said they had no symptoms of the disease, while two recalled having a fever at the time of the outbreak.
It’s now certainly possible that some of these villagers had full-blown symptoms but were fearful of admitting the truth to doctors. Consequently, more research with a larger sample pool will have to be performed. However, Richardson and his colleagues think they’re onto something, and that the villagers were probably telling the truth.
Importantly, the researchers aren’t sure if an asymptomatic person with Ebola can transmit the virus. “They were not passing it along in the usual way, through vomiting or diarrhea,” noted Richardson in a statement. “It’s unclear if they can pass it along it sexually.”
Much like their human hosts, some deadly pathogens just can’t let go. That’s apparently true of the …
More research is needed to determine if Ebola can be spread by a person who shows no or very few symptoms, but it’s a very distinct possibility. A person with an infection still has Ebola particles in their body, which could find a way to “jump” to another person. But without the typical symptoms, it’s certainly much more difficult. As Richardson noted, the virus might be transmitted sexually, though that still needs to be proven in an asymptomatic individual.


Richardson and his colleagues are now working in other villages in Sierra Leone to get a better handle on the true number of people affected during the crisis. But if the figure of 25 percent is correct—and if Ebola can spread via asymptomatic people (that’s still a big if)—that presents a massive headache for health officials.
Adding insult to injury, the Ebola virus mutated into a deadlier form during the last outbreak, showing an ability to quickly adapt to human biology and become even more virulent. Taken together, these new findings show that Ebola spreads more rapidly and more broadly through a population, highlighting the need for new detection and containment techniques for when the next outbreak hits.
[PLOS Neglected Tropical Diseases]
On Sunday’s episode of Keeping Up with the Kardashians, doctors told Kim that a third pregnancy would be risky and even life-threatening owing to a potential complication known as a “retained placenta.” Here’s what that means, and why Kim is now seriously considering getting a surrogate mother.
During the episode, Kardashian visited two doctors, both of whom advised her to avoid a third pregnancy given the particular complications she experienced during her first two pregnancies.


“You never know if you might have the same type of problem that could be more serious this time,” said Dr. Paul Crane. “You’re always taking a little bit of a chance. There are situations where retained placenta could be life or death.” To which Kris Jenner added, “You could bleed to death.” A fertility specialist echoed these sentiments, advising: “Using a surrogate is not an unreasonable option. If our goal is to grow your family like you want to, then a surrogate makes sense.”
As noted by the doctors, a retained placenta is serious business. It’s when all or some of the placenta stays inside a mother’s womb after birth. The placenta is an organ that provides oxygen and nutrients to the fetus, and it removes waste from the baby’s blood. Normally, the placenta, which is attached to the wall of the mother’s uterus, is expelled during the “third stage” of labor, and that usually happens about a half hour after the baby is born. (The next time a mother is pregnant, a new placenta forms.) But in a small number of cases, the placenta, or parts of it, gets stuck leading to some serious complications.


When the placenta or portions of it remain in the womb, the mother can experience symptoms such as heavy bleeding (post-partum hemorrhage, or PPH), stomach cramps, fever, and an inability to produce breastmilk. In some cases, the bleeding can be severe enough to threaten the life of the mother. If any fragments of the placenta remain, a mother may have to be readmitted to hospital to have them removed. The surgery is serious enough that the mother is put under anesthetic, and it needs to happen a few hours after birth to prevent bleeding. Antibiotics are typically prescribed to avoid infection.


Kardashian had preeclampsia during her first pregnancy, which involves high blood pressure, fluid retention, and placenta accreta, which is a form of retained placenta. In Kardashian’s case, her placenta grew too deeply into the uterine wall, and it failed to detach after birth. (Placenta accreta also happens when the placenta embeds itself over a previous caesarean section scar. A retained placenta can also happen when a womb stops contracting, or doesn’t contract enough, to separate the placenta from the wall of the womb (a condition called uterine atony). And it some cases, the placenta separates from the wall of the uterus, but it becomes trapped behind a semi-closed cervix (trapped placenta).
There’s virtually nothing that can be done to prevent a retained placenta, and the risk increases with each passing pregnancy. The condition happens in about two percent of all deliveries, and has a mortality rate of nearly 10 percent in rural areas; complications tend to happen when active management of the third labor stage is lacking, including home births. A retained placenta, with its associated hemorrhaging, is a leading cause of maternal mortality. In addition to preeclampsia, other risk factors for a retained placenta include having a previous surgery on the uterus, and being over the age of 35. Kim Kardashian, who is now 36, has already given birth to two children, and she had surgery after her first pregnancy, hence the doctor’s warnings.
Placenta accreta can be diagnosed prior to labor through blood and imaging tests, and if detected, can prompt a cesarean section when the time comes. Alternately, and as advised by Kardashian’s doctors, a prospective mother at high risk should avoid pregnancy and consider surrogacy instead. And indeed, Kim seems to be taking this possibility very seriously. “I’ve come to the conclusion in my mind that I can’t carry another one,” Kim told her mother at the end of the episode. “So now I want to explore surrogacy.”
Which sets up some serious drama for the Kardashians, not to mention reality television as well. Who gets to be the surrogate mom of Kim’s third child?


[People, LiveScience, BabyCentre, NCBI]
A team of biologists has just named three new salamanders in  the genus Thorius; the tiniest tailed tetrapods known to science. Smaller than a  matchstick, these creatures are as strange as they are adorable, their miniaturized anatomy pushing the boundaries of what natural selection can produce. Tragically, all three species appear to be edging toward extinction.
Thorius pinicola, Thorius longicaudus, and Thorius tlaxiacus are the subject of a new scientific paper published today in the open-access journal Peer-J. Found high in the montane cloud forests of Oaxaca, Mexico, the three new species join the ranks of twenty six other members of the Thorius genus thanks to a decades-long study that included field surveys, DNA sequencing, digital imaging, and statistical analysis of the wee critters’ anatomy.
Thorius salamanders have exaggerated, almost absurd proportions. Like other New World tropical salamanders, they’ve got enormous projectile tongues, which shoot out to a distance of up to half the length of the body  to catch insects. To make way for the tongue, the rest of the creature’s tiny head is extremely reduced in size, with some skull bones missing entirely.
Thorius salamanders are also well-endowed in the reproductive department. As Harvard University biologist and study co-author James Hanken explained to Gizmodo, adults need to maintain a minimum size of ovaries and testes in order to produce enough eggs and sperm. “As a result, the gonads occupy a relatively large proportion of the total body volume,” he wrote in an email. “In some females, much more than half the volume of the trunk is occupied by yolky eggs inside the oviducts; the rest of the visceral organs are pushed aside.”
Because of their oversized tongues, ovaries and testes, biologists have affectionately nicknamed Thorius the “tongue-flipping gonad” of salamanders.


Unfortunately, even as we continue to discover new species of this remarkable genus, Thorius salamanders are rapidly disappearing, paralleling the global decline in amphibians of all shapes and sizes. “It’s very hard to say definitively what’s causing their decline,” Hanken said, noting that habitat destruction, pesticide poisoning and climate change are all likely factors. We also can’t rule out the possibility that the deadly chytrid fungus which has decimated other amphibian populations in central and south America has infected Thorius, too.
“There is no simple solution, but there are longterm solutions: lessen and hopefully stop global warming and other climate change, preserve large tracts of forest, eliminate dangerous pesticides and herbicides,” Hanken said.
Those are big challenges—but if the plight of these tiny salamanders doesn’t make you want to help the planet, I don’t know what will.
[Peer J]
If you haven’t read up on tardigrades, or “water bears” as they’re more commonly known, take a few minutes and familiarize yourself with the microscopic creatures that are nearly indestructible. Then you’ll understand why you must own this adorable stuffed version.
Tardigrades, also known as “water bears,” are microscopic animals capable of withstanding some of…
Available from the Japanese online store Village/Vanguard, the plush tardigrades are as anatomically correct as a stuffed toy can be, aside from the fact that at around 12-inches long these water bears are about 1,000 times bigger than the real thing.


The toy tardigrades are also available in a couple of different color options, including tan and a darker brown, and even if you find them revolting, there’s almost certainly someone on your Christmas shopping list who loves science enough to appreciate getting one as a gift.
[Village/Vanguard via BoingBoing]
Last night, photographers around the world turned their cameras to the sky to capture the closest full moon—also known as a supermoon—since 1948. We’ve scoured the web to bring you some of our favorite photos of the celestial event that took our minds off the current state of world affairs for a few blissful minutes.
Entire lifetimes have come and gone without the moon looking quite as large as it will this month.…
What makes a good supermoon photo? Critically, there have to be other objects in the shot, so that your brain has some frame of reference for how damn big the Moon looks. NASA has a few more tips for would-be supermoon photographers, so if you didn’t get your money shot already, be sure to read up before trying your luck this evening. (Although the Moon passed its closest point of approach—or perigee—this morning, it will still look pretty darn super tonight.)
Tonight is your chance to see the closest “supermoon” that anyone on Earth has experienced in…
If you took a great photo of the November 14th supermoon, or know of a great photo you’d like to see added to this collection, drop me a line at maddie.stone@gizmodo.com or on Twitter.
Researchers in the Netherlands have successfully tested a brain implant that allows a patient with late-stage Lou Gehrig’s disease to spell messages at the rate of two letters per minute.
The new system was tested on Hanneke De Bruijne, a 58-year-old woman in the late stages of Lou Gehrig’s disease, also known as amyotrophic lateral sclerosis (ALS). Unable to move any part of her body aside from her eyes, De Bruijne used the wireless computer-brain interface to identify letters by imagining that she was using her right hand. She can now use the system at home to communicate with family and caregivers.


Prior to the brain implant, De Bruijne used an eye-tracking system to communicate, but it had to be recalibrated every time light levels in her surroundings changed. The new system is far more reliable and autonomous, and it can be used at home without any extra help. At a rate of two letters per minute, typing is still excruciatingly slow. But it’s an important proof-of-concept showing that patients can use the system on their own and without much technical support. In future, the system could be adapted to stroke patients or quadriplegics.
“This is a major breakthrough in achieving autonomous communication among severely paralyzed patients whose paralysis is caused by either ALS, a cerebral hemorrhage or trauma,” noted Professor Nick Ramsey, professor of cognitive neuroscience at the University Medical Center (UMC) Utrecht, in a statement. “In effect, this patient has had a kind of remote control placed in her head, which enables her to operate a speech computer without the use of her muscles.”


Four sensor strips were implanted on De Bruijne’s motor cortex (the part of the brain that controls voluntary movements). Whenever she thinks about bringing her right thumb and ring finger together, the chip detects a small electrical spike. A computer receives these signals over wireless, and interprets it as a “brain click.”
To type specific letters, De Bruijne uses a tablet display that features four rows of letters. As a red cursor moves from left to right across the alphabet (plus some functions like deleting a letter or word, and selecting words based on the letters she has already spelled), she executes a brain click when the desired letter is highlighted. The process repeats until an entire word is spelled out and spoken by the computer’s speech program.
Using the system, patients like De Bruijne can express their desires or communicate problems, such as an itch, an excessive buildup of saliva, or problems with a ventilator. Looking ahead, the researchers would like to test the system on two more patients before undertaking a large-scale trial.
[New England Journal of Medicine]
Seismologists are warning that the latest earthquake to strike New Zealand could trigger other large earthquakes in the coming days and weeks, but sensationalistic claims of a devastating “mega-quake” are likely overblown.
The 2016 Kaikoura earthquake struck just past midnight on Monday November 14, with the epicenter located about 10 miles (15 km) northeast of Culverden on the South Island of New Zealand. It was the result of two separate, but simultaneous, earthquakes on multiple fault lines. The quakes, with a combined magnitude of 7.5 to 7.8, caused damage to buildings and roads, several landslides, and at least two deaths.
Disturbingly, more quakes could be on the way. In light of Monday’s event, New Zealand’s government earth scientists, GeoNet, have worked out a series of scenarios and probabilities. The scientists say there’s a 12 percent chance of a magnitude 7 or greater earthquake happening within the next 24 hours, and a 32 percent chance of one happening within the next 30 days.


“We have updated our probabilities of larger or similar-sized earthquakes,” noted GeoNet’s Sara McBride in the New Zealand Herald.  “We use probabilities as we cannot predict earthquakes. These probabilities describe the likely progression of the sequence within the next week, month and year.” She acknowledges that these predictions will be distressing for some people, saying “We recognize that while these scenarios may increase anxiety, the best thing is to be prepared.”
With these scenarios in mind, science writer Alice Klein at New Scientist warned that New Zealand’s latest earthquake could trigger a “mega-quake,” particularly along the dreaded Alpine Fault that runs along the South Island. Over the past one thousand years, there have been four mega-quakes exceeding magnitude 8 along the Alpine Fault, including tremors in 1100, 1430, 1620, and most recently in 1717. These quakes seem to be occurring at intervals between 100 and 350 years. The 1717 quake happened 299 years ago, so New Zealand could experience its “big one” at any time. But it’s not immediately clear if Monday’s quake will be the catalyst for this dreaded event.


According to GNS scientist John Ristau, an Alpine Fault earthquake would “produce one of the biggest earthquakes in New Zealand since European settlement.” New Scientist was keen to inject Ristau’s quote into its coverage, but failed to note that the GeoNet scenarios did not include any kind of triggering of the Alpine Fault. As Ristau himself admits, Monday’s earthquake is probably too far away from the Alpine fault to have a direct effect. Geophysicist Jesper Sören Dramsch told Gizmodo, “That does not mean it cannot happen, but other scenarios are much more likely.” Dramsch provided some scientific context.
“A step from a 7.0 earthquake to an 8.0 earthquake releases about 32 times as much energy,” he says. “This is the equivalent of a golf ball (about 46g) tipping over a small kettlebell over (1,450 g or 1.45 kg).”


For the kettlebell to fall in this scenario, it would have to be unstable to begin with. Going back to earthquakes, this would mean that the Alpine fault would have to be similarly unstable. Dramsch says it’s possible that a 7.0 earthquake could act as a trigger, but there would already have to be an enormous amount of stress in the fault. Which leaves open the question of whether the fault wouldn’t have ruptured within a short time anyways.
Dramsch says that measuring the level of stress in a fault is almost impossible, especially at depth, leaving us with probabilities instead of certainties of earthquakes happening.
“I find it questionable that New Scientist publishes a fearmongering article in these times,” Dramsch told Gizmodo. “I am sure the Kiwis have enough to worry about and I feel deep sympathy with them. GNS Science and GeoNet try to educate and spread scientific knowledge among their folks, I don’t think it’s necessary to take these quotes out of context like that.”
[New Scientist]
In a welcome reminder that not everything is terrible always, global carbon emissions barely grew at all in 2016. It marks the third year in a row that humanity’s carbon footprint has been stable. They’re still much higher than they should be, but at least they are stable.
The very good news comes from the Global Carbon Project, an international team of Earth system scientists  tasked with assessing how much CO2 human activity generates, and where it ends up. According to the group’s latest projections, our collective carbon footprint grew by a mere 0.2 percent in 2016. Between 2014 and 2015, the same group measured a net emissions growth of zero; a dramatic departure from the prior decade, in which emissions grew by roughly 2.3 percent per year.
Last week, the Paris climate agreement cleared its final hurdle, when the European Union formally…
Better still, the global GDP continues to grow at more than 3 percent per year. “This third year of almost no growth in emissions is unprecedented at a time of strong economic growth,” lead study author Corinne Le Quéré of the Tyndall Centre for Climate Change Research said in a statement.


The findings, published this week in the open-access journal Earth System Science Data, indicate that the emissions growth pause is driven by a shift away from coal among the world’s two largest carbon emitters, China and the United States.
Emissions in China fell by approximately 0.7 percent in 2015 and are expected to drop another 0.5 percent this year, although there is still a great deal of uncertainty in the recent data. In the United States, emissions dropped 2.6 percent in 2015 and are projected to decline another 1.7 percent this year. By contrast, in rapidly industrializing nations like India, carbon emissions continue to grow fast.
For the last few years, the United States has been a lukewarm leader on global climate action. Now, …
While there’s reason to be cautiously optimistic about a three-year emissions growth stall, especially since the global economy continued to grow, we have to put these numbers in context. Fossil fuels and industrial activity still contributed about 36 billion tons of heat-trapping carbon dioxide to our planet’s atmosphere last year. To halt global warming, we need to bring that number down to zero.


“This is a great help for tackling climate change but it is not enough,” Le Quéré said. “Global emissions now need to decrease rapidly, not just stop growing.”
According to the study’s authors, we now have approximately  800 billion tons of carbon “left in the bank” if we want to preserve a two-thirds chance of staying below 2 degrees Celsius of warming. If we continue our present course, we’re going to blow through that budget in less than 25 years, at which point we may need to invent carbon capture technology to prevent a dangerous climate change.
And now, we’re faced with an incoming administration that denies the reality of climate change; that has promised to “unleash” American coal; that wants to drop Paris climate accord as quickly as possible; and that’ll appoint a Supreme Court justice happy to strike down Obama’s Clean Power Plan. If one thing’s clear, it’s that efforts to curb carbon emissions over the next four years are going to have to move forward in spite of America’s leadership—perhaps, in opposition to it.
[Earth System Science Data via Washington Post]
This is cool. Emanuele Fornasier ran an electric current through various chemical solutions and recorded the reaction to reveal the formation of crystals. It’s like seeing the birth of a snowflake. The process definitely looks fantastic but in reality, it’s really, really slow. It can take hours or even days for the crystals to take shape.

[Emanuele Fornasier via Colossal]
A recent expedition to the explore marine life in the Marianas region of the Pacific has uncovered stunning new video of bubblegum coral, and the strange creatures who make these aquatic structures their home.
Researchers with the NOAA Ocean Explorer team stumbled upon the bubblegum coral, also known as Paragorgia arbore, while exploring the Marianas Region on June 17, 2016 at depths of 1,700 feet.

Stunning video captured by the Okeanos Explorer show the vibrant red coral with a panoply of strange critters slithering around and clinging to the biological structure. The science team is particularly intrigued by the green filaments on the bubblegum coral given the complete lack of light at the seafloor. The researchers figure it’s either some kind of sponge or algae that’s gotten caught on the coral.


The researchers were also intrigued by a worm-like brittle star, or ophiuroids, that’s clinging very tightly to the coral. A crab and several other strange creatures could be seen loitering around. “It’s a little oasis for all kinds of life,” noted one of the marine scientists.
[NOAA Ocean Exploration and Research]
Predicting the future is hard. It’s nearly impossible to know what technological marvels await in the next few years, let alone the next eight decades. Undaunted, we’ve put together a list of 10 super-advanced technologies that should be around by the year 2100.
Some of these technologies are rather “out there,” but I’m reasonably confident in making these predictions. As radical as some of the items described here appear, most—if not all—should be around by the turn of the 22nd century. The reason has to do with an innovation that doesn’t appear on this list: Artificial superintelligence. As computer scientist I. J. Good aptly pointed out in the 1960s, “the first ultraintelligent machine is the last invention that man need ever make.”


Once greater-than-human intelligence emerges in a machine—a development that could happen as early as the 2050s—all bets are off in terms of what’s technically possible. Intelligent machines will replace humans as designers and engineers, constructing the technologies of our dreams, including some we hadn’t even thought of. Here are just 10 of those technologies that could change virtually everything.
Wearable VR-enabling devices like Oculus Rift are all fine and well, but no matter how sophisticated these sorts of gadgets become, a “true” sense of existing in an alternate reality will remain out of reach. What’s required is something a bit more...invasive—and by the time we reach the 2100s we’ll have found a way to create a virtual reality experience that’s indistinguishable from the real thing. Incredibly, these experiences will be fed directly to our brain, bypassing our normal sensory inputs to make it all the more believable.
To get that intangible feeling of what it’s like to exist in our surroundings, we’ll need to go to the source of that experience: the human brain. Indeed, the brain (among other things) is a sensory processing device. All of the things we sense on a regular basis, whether it be the smell of your tacos or the glaring glow of your computer screen, are routed to your brain. As Morpheus put it so eloquently in The Matrix: “What is real?...If you’re talking about what you can feel, what you can smell, what you can taste and see, then ‘real’ is simply electrical signals interpreted by your brain.”


Futurist Ray Kurzweil, author of The Singularity is Near, explained how this could come about in a Q&A about his book.
I see this starting with nanobots in our bodies and brains. The nanobots will keep us healthy, provide full-immersion virtual reality from within the nervous system, provide direct brain-to-brain communication over the Internet, and otherwise greatly expand human intelligence. But keep in mind that nonbiological intelligence is doubling in capability each year, whereas our biological intelligence is essentially fixed in capacity. As we get to the 2030s, the nonbiological portion of our intelligence will predominate.
Kurzweil’s time lines are probably a bit optimistic, but his concepts are sound; we’re finding new ways of breaching the blood-brain-barrier and creating microscopic machines that can travel around the body. And just as importantly, we’re creating a detailed map of the brain, including areas responsible for processing incoming sensory information.
Once implanted in the brain, Kurzweil’s nanobots would locate the brain’s various sensory inputs and shut them down (e.g. disrupting the electrical signals collected by the retina, ear, etc.), making the person completely unaware of their actual surroundings (it would be the perfect sensory deprivation chamber. In place of these signals, the nanobots, fed by wireless transmission, would replace those missing signals, feeding the brain’s cortical regions with artificial senses—and an entirely new subjective experience. To the person, it would feel like they’ve been  transported to another world.
Devised by nanotech pioneer J. Storrs Hall, utility fogs are a swarm of nanobots, or “foglets,” that can take on the shape of virtually any object, and change its shape on the fly. Storrs came up with the idea when trying to imagine a futuristic seat belt. But instead of static straps and inflatable airbags, Hall imagined an intelligent cloud of interconnected snowflake-like foglets capable of morphing along with the movements of anything around it, including the passengers of cars.
Utility fogs defy the imagination in terms of the technological sophistication required. Each foglet would measure just 10 microns across (roughly the same size as a human cell), be equipped with a tiny, rudimentary onboard computer to control its actions (which would be controlled externally by an artificially intelligent system), and a dozen telescopic arms that extrude outwards in the shape of a dodecahedron. When two foglets link up, they would form a circuit, allowing for the distribution of power and communications throughout the network. The foglets wouldn’t be capable of floating, but would instead form a lattice structure, called an octet truss, when holding hands in all 12 directions.


A utility fog would work like programmable matter, capable of moving around, enveloping, and and even transporting an object or person.  More radically, utility fogs could be used to create a virtual world around a person—and even host a person who has uploaded themselves into this nano-infused cloud (similar to the foglet beings in Warren Ellis’ Transmetropolitan).
As our civilization struggles to mitigate the effects of climate change and transition into a more sustainable energy economy, it’s tempting to think we’ll never be able to meet our seemingly insatiable energy needs. Space-based solar power—an idea that’s been around since the 1960s—could solve this problem once and for all.
Nearly 60 years ago, Peter Glaser envisioned solar powered satellites capable of transferring captured solar energy down to receiving dishes on the Earth’s surface via microwaves. A number of different schemes have been proposed since then, with Japan leading the way in terms of having an actual plan to get it done. Called the SBSP System, the Japanese orbital farm would run in a stationary orbit about 22,400 miles above the equator, where it would transmit energy to Earth using laser beams.  Each satellite would target a 1.8-mile wide receiving station that could generate an entire gigawatt of electricity, which is enough to power a half million homes. For safety, the receiving station should be positioned far from human habitation, such as a desert or island.
By the turn of the 22nd century, many humans will have opted for a purely digital existence, one free of all biological constraints. Called mind uploading, or whole brain emulation, this will involve the meticulous copying of an existing biological brain. The scans would capture every cognitive detail down to the molecular level, and include memories, associations, and even a person’s personality quirks.
Futurists aren’t entirely sure how mind uploading will happen, but a critical step will be to make sure the important parts of a brain are copied, particularly those tied to a person’s sense of identity (namely the parahippocampus and retrosplenial cortex). This could involve “destructive” copying, where an existing brain is sliced or otherwise taken apart in order to record a person’s brain state and memories. Alternately, a sufficiently powerful brain scanner could be used to take a snapshot of a person’s brain, and then “pasted” into a computer capable of translating that information into a functioning mind. In order for an uploaded person to function “normally,” they would have to be equipped with a virtual body and environment.
We're still decades — if not centuries — away from being able to transfer a mind to a…
An important scientific and philosophical question to ask is whether or not this represents a true “transfer” of consciousness, and not just the mere copying of a person’s brain. What’s more, it’s not entirely clear if conscious self-awareness can be replicated in digital substrate. Frighteningly, each upload could be a kind of zombie that behaves and functions like the pre-existing person, but would in reality be nothing more than a script-driven bot.
It’s unlikely that our species will be able to completely control the weather by the end of the current century, but we should be able to put a serious dent into it. We’re already seeding clouds with particles to stimulate precipitation, and California has been doing this for nearly 50 years. During the 2008 Summer Olympics in Beijing, Chinese authorities fired 1,100 rockets into the clouds to trigger downpours before the storms reached the capital city. There are even efforts to fire laser pulses into thunderclouds in hopes of drawing out lightning in a controlled manner.
Looking ahead to the future, weather engineers could build massive wall-like structures to prevent devastating tornadoes from forming, or construct massive —and very strong—arrays of offshore turbines to suck the energy out of hurricanes. On that last prospect, a study in 2014 showed that a wind farm consisting of tens of thousands of individual turbines could reduce peak winds by up to 92 mph (148 km/h) and decrease storm surges by up to 79 percent. That would in effect reduce a hurricane’s power by an entire  magnitude.


More radically, we could eventually build a weather machine to create a programmable atmosphere. A particularly intriguing plan calls for a thin global cloud of small transparent balloons lifted up into the stratosphere, where it would shade or reflect the amount of incoming sunlight. A mirror would be placed inside each balloon, along with a GSP to monitor its location, an actuator to control its orientation, and a small computer. Lifted by hydrogen, the “programmable green house gas” would come to a rest about 20 miles above the Earth’s surface. When the millions of mirrors face away from the Earth, they would reflect the sunlight back into space. This system, guided by AI, could influence weather patterns around the world, and turn marginally habitable areas into temperate regions.
Think 3D printers are amazing? Just wait until the arrival of molecular assemblers, a hypothetical fabricator described by nanotechnology pioneer K. Eric Drexler in his seminal book, Engines of Creation. Drexler described a molecular assembler as a device capable of manipulating individual atoms to build a desired product. If you’ve ever seen an episode of Star Trek in which a member of the crew uses a replicator to churn out a steaming hot cup of Earl Grey tea, then you’ve basically seen a molecular assembler, which some futurists refer to as fabricators, or fabs for short.
Drexler basically argued that biological assemblers already exist, producing complex and wonderful structures like bacteria, trees, and even you and me. Using the same logic, he figures we’ll eventually be able to tap into the mechanical properties of the uber-small, and use similar principles to produce objects of any shape, form, or consistency.


Fabs could introduce the world to an era of “radical abundance,” allowing us to produce items and materials that would otherwise be impossible to build, constructing them from the ground up (or more accurately, from the molecules on up). But these devices could even be used to produce items we’re familiar with, like food. To make a steak, for example, the fabricator would take base materials, such as carbon, hydrogen, and nitrogen, and then arrange them into amino acids and proteins, which would then be assembled to form a steak.
Disturbingly, the effects of climate change are likely irreversible. No matter what we do from now until the year 2100, the levels of greenhouse gasses in our atmosphere will continue to warm the planet.
To prevent the many environmental calamities wrought by climate change—from rising sea levels and megadroughts through to superstorms and mass extinctions—we’ll begrudgingly have to start geoengineering the planet.


Some notable geohacking proposals include cirrus cloud seeding to reduce reflectivity, stratospheric particle injection for solar radiation management, sulfur-aerosol injection to induce global dimming, and simple solutions like tropical reforestation to restore the carbon balance. Other ideas include a giant space reflector (though that might be beyond our technological capacities by 2100), ocean fertilization to spawn carbon-sucking algal blooms, and ocean alkalinity enhancement to make the ocean less acidic. Clearly, there are no shortage of ideas, and we won’t be restricted to just one.
The problem with geoengineering, of course, is that we could royally wreck our planet should something go wrong, and we may become dependent upon it. But desperate times will require desperate measures, and we’ll have little choice but to rely on complex climate models and supercomputers to ensure safety and efficacy.
Ongoing advances in communications technologies and neuroscience will transform humanity into a telepathic species.
The advent of direct mind-to-mind communication will bring us even closer together as individuals, and conceivably give rise to a “hive mind”—a vast network of interconnected minds working together over the future instantiation of the internet. In such a future, we may start to see the dissolution of the individual, and the rise of a collective mass consciousness.
Last month, researchers created an electronic link between the brains of two rats separated by…
Remarkably, this future may be closer than we think. Back in 2014, an international team of researchers were the first to demonstrate a direct and completely non-invasive brain-to-brain communication system. During their experiment, two participants were able to exchange mentally-conjured words despite being separated by hundreds of miles. A year later, a separate team of researchers transmitted brain signals over the internet to control the hand motions of another person, allowing them to collaborate on a computer game. These systems, though extremely rudimentary, point to a future in which we can simply use our thoughts to converse with one another, and “telekinetically” control smart devices in our environment.
Earlier this year, physicists in Germany used a 2-megawatt microwave pulse to warm low density hydrogen plasma to 80 million degrees. The experiment didn’t produce any energy, and it only lasted for a quarter of a second, but it was an important step forward in the effort to harness an extremely promising form of energy production known as nuclear fusion.
Unlike nuclear fission, where the nucleus of an atom is divided into smaller parts, nuclear fusion creates a single heavy nucleus from two lighter nuclei. The resulting change in mass generates a tremendous amount of energy that scientists believe can be harnessed into a viable source of clean energy. Eventually, fusion power could replace fossil fuels and conventional nuclear reactors.
The longstanding joke about fusion—that it’s the energy source of the future, and always will…
But to get there, scientists will have to figure out how to reliably and safely manage conditions typically found on the sun. The problem is that fusion plasmas do not like to be contained; these free-flowing streams of protons and electrons are tough to wrangle. Our sun holds on to its plasma with its intense gravity, but here on Earth, we’d have to rely on magnets or lasers to perform the same trick. Should a tiny fraction of the plasma escape, it would scar the wall of the machine, causing the fusion reactor to shut down.
Not content to stop at genetic engineering, scientists of the future will be able to design and create new organisms from scratch—from microscopic synthetic bacteria through to redesigned humans reminiscent of the Replicants in Blade Runner. This burgeoning discipline, known as artificial life (or Alife), is the effort to recreate biological phenomenon with the help of computers and other synthetic media.
The quest to create synthetic forms of life is already underway. Earlier this year, researchers from Synthetic Genomics and the J. Craig Venter Institute successfully created an artificial bacterial genome that, with its scant 473 genes, is smaller than anything found in nature. Further breakthroughs in this domain will help biologists explore the core functions of life, and to categorize essential genes within cells. Researchers could use “building block” cells like these to construct organisms with capacities not found in nature, including bacteria that can consume plastic and toxic waste, and microorganisms that can function like medicines inside the body.


In a related breakthrough, a new initiative co-founded by Harvard Medical School’s George Church is seeking to create a synthetic human genome from scratch. The researchers say they’re content to stop once they figure out how to power cells with synthetic human DNA, but the same technology could conceivably be used to create artificial organisms and even designer humans.
Any one of the technologies listed here has the potential to reshape our civilization. What’s less clear is how these marvels will work in tandem with one another; the convergent effects of technology are often hard to predict. For example, the convergence of brain-linked VR, mind uploading, and AI could result in a hybrid computer-based civilization consisting of real-world humans, emulated brains, and artificial intellects. Future geoengineering schemes could integrate weather control systems and engineered nanoparticles. And so on.
The more predictions we make about our future technologies, the more difficult it becomes to know what the future might actually look like.
It teased us with the possibility of a no-show this summer, but a weak La Niña has officially arrived, according to NOAA. Parts of the northern United States can expect a cooler and wetter-than-average winter, while southern California, unfortunately, can expect more drought.
After pulling us off a La Niña watch in September and then reinstating it last month, NOAA has now confirmed that La Niña conditions are here. In the simplest of terms, this means monthly sea surface temperatures in the Niño 3.4 region of the equatorial Pacific (see below) are more than half a degree cooler than average, and they’re expected to stay that way for several months. It also means we’re seeing indications of a strengthened  Walker circulation pattern, with cool air sinking more vigorously in the central and eastern Pacific as warm air rises more intensively over the western Pacific.


NOAA’s Climate Prediction Center slightly favors (55 percent chance) a weak La Niña persisting through the winter.
Like its recently-departed counterpart El Niño, the La Niña pattern causes changes in global atmospheric circulation that affect weather around the world. While El Niño tends to promote an elongated jet stream that brings extra stormy weather to the southern United States, La Niña favors below-average precipitation and warmer temperatures across the same region. At the same time, La Niña winters often feature cooler weather across parts of the northern United States and Canada, and additional rain and snowfall in the Pacific Northwest and around the Great Lakes.
NOAA’s recent winter weather outlook reflected La Niña’s influence, as you can see in the temperature and precipitation maps below:
Perhaps the biggest takeaway for the United States is that California’s drought woes aren’t going away. While northern California’s reservoirs may experience some much-needed recharge this winter, La Niña is expected to leave the central and southern parts of the state high and dry, in conditions of “extreme or exceptional drought.” It seems extra cruel seeing as last winter’s monster El Niño failed to deliver blockbuster storms.


“The weak La Niña is likely to contribute to persisting or developing drought across much of the southern US this winter,” Mike Halpert of NOAA’s Climate Prediction Center said in a statement.
It’s important to note that NOAA discusses La Niña’s influence in terms of probabilities: the likelihood of warmer, cooler, wetter, or drier-than-average conditions, rather than the absolute the strength of the effect. We should also keep in mind that it isn’t certain La Niña will persist throughout the winter; at this point it’s nearly a toss-up.
But for now, at least, we can welcome the cool embrace of La Niña, and all that she promises to bring (or withhold).
[Climate.gov, NOAA]
A large cylindrical structure thought to be part of a Chinese rocket has fallen down into a mining area in north Myanmar, while another piece of metal tore through the roof of a nearby house.
The metal object, which measures 4 feet (1 meter)  in diameter and 15 feet (4.5 meters) in length, fell on the property of a jade mining company, and then bounced up to 150 feet (46 meters) away. Local residents in a nearby village said they heard a loud noise shortly before the metal object was found. Around the same time, another cylindrical structure measuring about an inch wide and 4.6 inches in length—and bearing Chinese script—tore through the roof of a home nearby. The roof was damaged, but no injuries were reported.

“Every local thought it was the explosion of heavy artillery,” said villager Ko Maung Myo in the Myanmar Times. “I walked over to it and saw it was part of an engine.” Myo said he thought it was an engine because he found “a diode and many copper wires at the tail of the body,” adding that “It also looks like a jet engine block.” Witnesses said the air near the object smelled acrid, as though something was burning.


Initial speculation pointed to satellite debris, a piece of missile, or an aircraft engine, but the incident is likely related to the launch of a Chinese satellite. A Long March 11 rocket blasted off from the Jiuquan Satellite Launch Center on Wednesday night, carrying an experimental satellite. And indeed, the chunk of metal looks like a stage section of a rocket, which falls away before reaching space.
Part of a rocket engine crashes through the roof of a house in northeast China’s Shanxi province…
This sort of thing—sadly—has happened before. Last year, part of a rocket engine crashed through the roof of a house in northeast China’s Shanxi province. Seems China’s space agency—or whoever is responsible for these incidents—needs to do a better job protecting the people down below.


[BBC, Myanmar Times]
Landing on Mars is hard, but the European Space Agency’s first attempt—the Beagle 2 probe—came maddeningly close to being a success. In fact, a new 3D modeling analysis shows that the lander’s failure to communicate with the Earth was likely due to a single jammed solar panel.
A British space probe designed to hunt for signs of life on Mars, Beagle 2 was launched aboard ESA’s Mars Express spacecraft in June 2003. It was released from its mothership on December 19th and scheduled to land on the Red Planet six days later. But Beagle 2's Christmas day phone call home from Mars never came—and subsequent searches by Mars Express and NASA’s Mars Odyssey were unable to locate the lander.


For more than a decade, its fate remained a mystery.
In late 2014, after nearly everyone had given up on the lost lander, Beagle 2 was spotted in a series of eight images taken by the HiRISE camera on NASA’s Mars Reconnaissance Orbiter. The blurry, pixelated photos showed what appeared to be an intact lander, along with its parachute and heat shield nearby. But even after applying advanced image processing techniques, scientists were unable determine the configuration of the lander—the photos were simply too low resolution. The question of what the hell went wrong remained open.


But Mark Sims, a professor of astrobiology at the University of Leicester and former mission manager for Beagle 2, wasn’t about to let the mystery go, not after obtaining photographic evidence of a successful landing. “Call it stubbornness, if you like,” he told Gizmodo. “In the end, all of this is about trying to figure out exactly what happened to Beagle 2.”
An idea came to Sims one evening last fall, toward sunset, after tracing the source of a bright glimmer in his lounge to the reflection of a window down the road. “I looked at that light and thought, there’s information here about what I’m seeing,” he said. Specifically, Sims started thinking about how the appearance of an object can change drastically with the angle of the sun.
The HiRISE images of Beagle 2 were all taken at different sun angles, and in each of them, the lander reflects light in a slightly different way. And so, Sims started to wonder: if the Beagle 2 lander could be simulated under different lighting conditions, could one work out its configuration on the surface?


“It’s an old idea, in a sense,” Sims said. “But I didn’t have the knowledge or technology to do the analysis.”
As luck would have it, a friend of Sims’ introduced him to someone who did: Nick Higgett, a researcher at De Montfort University whose lab uses advanced 3D modeling  techniques to reconstruct historic sites around Leicester.
Taking Sim’s “reflection analysis” concept, Higget and his team constructed a 3D model of the Beagle 2 lander, which is shaped like a clam shell and opens in half before unfurling four solar panels on one side. They modeled the lander in several different configurations, with one, two, three, or all four solar panels deployed. The model was then scaled down to the pixel resolution of the Mars Reconnaissance Orbiter’s images, and bathed in virtual sunlight at different angles. Finally, its reflection patterns were compared with real images of Beagle 2 captured by Hi-RISE.
“We looked at a lot of different configurations in our simulations and saw which was most consistent across a number of [Hi-RISE] images,” Higget told Gizmodo. “There was a lot of trial and error.”


Eventually, the researchers determined that the best match between real and simulated reflection patterns was one in which Beagle 2 had three of its four  solar panels deployed, although a four panel scenario was also possible.
“This confirms that the Beagle 2's entry, descent and landing system worked,” said Sims, who is currently writing up the findings for publication. “It got down to the surface, and it was intact. Furthermore, it was within one solar panel of being fully deployed and fully operational.”


All four of the Beagle 2's solar panels needed to open before an RF communication antenna could pop out and send  signals back to Earth. So, if the the three-panel scenario is correct, that explains why we never heard from the lander. If all four of the panels did deploy, there must have been some other technical problem. It could have been as minor as a bad electrical wire or a loose screw.
“I suspect, given what we’ve seen from prior data analysis back in 2015, it’s the three-panel scenario,” Sims said. “But if all four panels did open, we were excruciatingly close to having a working spacecraft on the surface of Mars.”


We may never find out exactly what went wrong with Beagle 2, although Sims is keen to do more simulations if he receives the funding. Higget notes that his team’s newly devised technique could be applicable to other situations where scientists are trying to understand a highly-reflective object on the surface of a different planet or even in a remote area on Earth.


Unfortunately, reflection analysis won’t be applicable to the European Space Agency’s recently-crashed Schiaparelli lander, which impacted the surface at a very high speed and seemed to explode, leaving nothing but a dark burn mark. “That was a great disaster for the team, and I feel deeply for them,” Sims said. “But it was obviously a crash.”
Beagle 2, meanwhile, obviously wasn’t a crash. And while it may seem a bit arcane to continue puzzling over the pixelated reflections of a machine that died on Mars more than a decade ago, who knows? Maybe in those glimmers, we’ll learn something that’ll keep the next space probe alive.
British red squirrels are being afflicted by a medieval strain of leprosy that was thought to have disappeared from Europe over 700 years ago, according to a new DNA analysis. Researchers say the chances of the dreaded disease spreading to humans is low, but the discovery suggests this strain of leprosy has been lingering for quite some time.
A DNA analysis performed by researchers from the University of Edinburgh and the Swiss Federal Institute of Technology in Lausanne (EPFL) has shown that leprosy in Britain’s red squirrels is being caused by the same species of bacteria responsible for human infections. Human cases of leprosy are practically unheard of in Britain, but scientists say the red squirrels could be a source for the bacteria in the UK, frustrating attempts to eradicate the disease.


Published in the journal Science, results show that samples taken from 25 red squirrels living on Brownsea Island (off of England’s south coast) were infected with Mycobacterium leprae—the variant of leprosy responsible for outbreaks in medieval Europe. The bacteria is very similar to a strain found in the skeletal remains of a leprosy victim buried in Winchester 740 years ago. It’s also quite similar to a strain found in armadillos in the southern United States.
Leprosy is a chronic infectious disease that affects the peripheral nerves, skin, upper respiratory tract, eyes, and the lining of the nose. Once rampant in Europe, the disease declined by the end of the Middle Ages for reasons that still aren’t fully understood. Leprosy in Europe disappeared about a century ago, at least among humans. Today, about 200,000 cases of leprosy are recorded each year around the world, particularly in wet areas in the tropics and subtropics. Countries with the highest prevalence include India, Indonesia, Myanmar, Brazil, and Nigeria. Leprosy can be treated with antibiotics, but the surprising number of new cases each year highlights the need to learn more about this disease and why it’s so tough to stamp out.


Like so many other zoonotic diseases, leprosy can “jump” from animals to humans. With this in mind, the labs of Stewart Cole at EPFL and Anna Meredith at the University of Edinburgh conducted tests on 110 British red squirrels from England, Scotland, and Ireland. Some of these specimens showed signs of leprosy (e.g. hair loss on the ears, muzzle, and feet), while others did not—but most were infected with leprosy bacteria.
“It was completely unexpected to see that centuries after its elimination from humans in the UK, Mycobacterium leprae causes disease in red squirrels,” noted Cole in a statement. “This has never been observed before.”
As noted, the squirrels on Brownsea Island were infected by the medieval form of the disease, but the red squirrels from the other areas were infected with the other known strain of the disease, Mycobacterium lepromatosis. This variant of the disease is known to cause leprosy among humans living in Mexico. Further analysis indicated that the two different two strains diverged from a common ancestor about 27,000 years ago.
This research shows that a pathogen can remain undetected in the environment even hundreds of years after it has disappeared from the human population. Thankfully, residents living in the UK have very little to worry about.


“The risk to people from squirrel leprosy is negligible,” Meredith told Gizmodo. “The bacteria that cause leprosy cannot survive outside the body and evidence shows that 95 percent of all people are naturally unable to get leprosy, even if they are exposed to the bacteria that causes it.” She says it’s sensible to take precautions, like avoiding physical contact with wild animals and washing hands before eating.
“Around a dozen people are treated for leprosy in the UK each year,” said Meredith. “In all cases, the disease was contracted in countries where leprosy is prevalent. The last recorded case of indigenous leprosy [i.e. contracted in the UK] dates from 1798.”
This news comes at a particularly challenging time for the British red squirrel. Their numbers have drastically declined in the UK over the past few years, and only 140,00 remain. These creatures are being threatened from habitat loss and the squirrelpox virus carried by invasive grey squirrels.


“The discovery of leprosy in red squirrels is worrying from a conservation perspective,” said Meredith. “We need to understand how and why the disease is acquired and transmitted among red squirrels so that we can better manage the disease in this iconic species.”
[Science]
Scientists in the UK have developed a USB stick that can quickly and accurately measure the amount of HIV is in a patient’s blood.
The medical device was created by scientists at Imperial College London and tech firm DNA Electronics, and all it needs is a simple drop of blood to measure HIV-1 levels. It then creates an electrical signal that’s fed into a computer, laptop, or handheld device. The disposable test could be used by HIV patients to monitor their own treatment and help patients in remote regions of the world, where more standard HIV tests are inaccessible.
Published in the journal Scientific Reports, results show that the USB stick is highly accurate, and it can produce a result in under 30 minutes. Current tests to detect the amount of HIV in the blood can take as much as three days, requiring patients to send blood samples to a lab. In the latest research, the USB stick tested 991 blood samples with 95 percent accuracy, with an average time to produce a new result just shy of 21 minutes.


When blood is placed onto a spot on the USB stick, it senses the HIV-1 virus through a change in acidity levels. A mobile phone chip in the USB stick converts this information into an electrical signal, and the stick then feeds the result to an app on a handheld device or computer.
The technology is still in its early stages, but it could allow patients to regularly monitor their virus levels similar to the way people with diabetes check their blood sugar levels. The current treatment for HIV reduces virus levels to practically zero, but in some cases, the anti-retroviral medication stops working, typically due to the HIV virus developing a resistance to the drugs. The new USB stick can detect the rise in HIV levels, and flag a potential problem with a patient’s meds or therapy.
“[Monitoring] viral load is crucial to the success of HIV treatment,” noted study lead author Graham Cooke in a statement. “At the moment, testing often requires costly and complex equipment that can take a couple of days to produce a result. We have taken the job done by this equipment, which is the size of a large photocopier, and shrunk it down to a USB chip.”


The team is now investigating the possibility of using the device to test for other viruses, such as hepatitis.
[Scientific Reports]
Behold Tongtianlong, a new species of oviraptor uncovered in China. The fossilized remains of this feathered, bird-like dinosaur were preserved with its limbs outstretched, and its head raised—suggesting it was hopelessly stuck in a patch of mud, where it eventually died.
Before we get into the details of this new study, just take a look at that glorious painting produced by Chinese artist Zhao Chuang. Interpretations like this allow scientists to visualize their findings, while also providing us dino junkies with a glimpse of what these fantastic creatures must have looked like.


This new oviraptor, called Tongtianlong limosus, is described in a new Scientific Reports study led by paleontologist Junchang Lü from Chinese Academy of Geological Sciences. The unique shape of its dome-like skull, and the highly convex cranial bone at the tip of its upper jaw, distinguish it from other oviraptors, signifying the discovery an entirely new species.
A farmer discovered the remains in the Nanxiong Formation of the Ganzhou area of Jiangxi Province in southern China. Unfortunately, he collected the remains and did not map the original location, making it difficult for the researchers to interpret the cause of Tongtianlong’s strange position.


Analysis of the well-preserved fossil show an unusual posture, with the oviraptor’s wing-like limbs splayed to the side, its neck outstretched, and its head raised. The researchers hypothesize that Tongtianlong became hopelessly mired in mud, where it died and was ultimately buried. The researchers describe this as one possible, “but highly speculative,” interpretation of the fossil.
This creature lived in the Ganzhou area during the late Cretaceous period some 72 million years ago, and it’s now the sixth oviraptor species to be discovered in the region. Oviraptors are an unusual group of bird-like theropod dinosaurs, featuring shortened, toothless skulls, and ranging in size from a turkey to nearly the length of an elephant, or 23 feet (7 meters).
Oviraptors are portrayed as stealthy carnivores in films like Jurassic Park, but they probably had varied diets, feasting on eggs, mollusks, plants, shellfish, and nuts. The sheer number of fossils found, along with the apparent diversity of this dinosaur subgroup, suggests they were a very successful adaptation.
[Scientific Reports]
All hail the Brazilian free-tailed bat, which has just claimed a new flight speed record for all mammal-kind.
According to researchers at Max Planck Institute for Ornithology, bats of the species weighing less than half an ounce each were recently recorded flying at speeds exceeding 99 miles per hour, making it the fastest horizontal flyer on Earth.


“Initially, we could hardly believe our data,” said researcher Kamran Safi, “but they were correct.”
In addition to smoking the common swift (the next fastest horizontal flyer at around 68 miles per hour) the insect-loving echolocators shattered the previous highest bat-speed. In the 1950s, researchers estimated the same species to exceed speeds of 59 miles per hour, an observation that hasn’t been replicated until now. From New Atlas:
Scientists from the Max Planck Institute attached radio transmitters to the backs of Brazilian free-tailed bats. Using a mobile receiver aboard a small aircraft to localize the signal, the team tracked the flight paths of the animals and measured their speed through the air.
[...]
After consulting local weather data, the team has ruled out the possibility that tailwinds had a part to play. It says that where birds were assumed to fly more efficiently and faster than bats, its findings suggest a re-think might be in order of how we view the flight ability of the two creatures.
When it comes to vertical flight, however, birds still have the upper hand: In 1999, a peregrine falcon named “Frightful” was recorded dive-bombing at 242 miles per hour.


[New Atlas]
Donald Trump made some pretty scary threats during the election about cracking down on abortion. Here’s a quick refresher on his campaign promises—and why women have every right to be very worried.
Trump has flip-flopped on abortion, and seems to have adopted a rather extreme stance on the issue. Back in 1999 on an episode of “Meet the Press,” Trump said he “hated” abortion, but being from New York, admitted that he is “pro-choice in every respect.” Fast forward to the recently concluded election, and it’s clear that Trump has changed his tune. In a September 2016 letter addressed to “Pro-Life Leader,” Trump made his position on abortion painfully clear, saying he’s committed to:
Earlier this year, Trump said that abortions are “not acceptable,” and that women who try to obtain them should be subject “to some form of punishment.” Following a public outcry, Trump backtracked on his remarks, saying it’s not women who should be punished for having an abortion, but the doctors who perform the procedure.


As noted in his September letter, and as he remarked during the final presidential debate on October 19th, Trump is particularly opposed to so-called “partial-birth” abortions, or what doctors call intact dilation and extraction. According to federal law, this late-term procedure is acceptable if the life of the mother is at stake. But during the last debate, Trump didn’t seem to care, saying “in the ninth month you can take the baby and rip the baby out of the womb of the mother,” adding that it can happen “as late as one or two or three or four days prior to birth.”
But as noted by the Guttmacher Institute, 90 percent of all abortions take place within the first 12 weeks of pregnancy. A mere 1.5 percent of abortions take place beyond the 20 week mark, the vast majority of which happen before the 24 week mark. Thankfully, this issue won’t affect most women, but that’s small consolation for those whose lives might depend on it.
The Trump Administration’s approach to Planned Parenthood in particular is all but certain to be a nightmare. The organization provides services for millions of women (and men), including sexual education and reproductive healthcare. But that hasn’t done much to thwart a largely Republican effort to completely strip it of resources and power. It’s a coordinated campaign that’s been taking place at the Congressional level for some time now; a Trump administration could bring an entirely new dimension of power into the mix.


Mike Pence, in particular, has consistently positioned himself as an opponent to the organization. In October, during a speech at Liberty University, he promised that “a Trump-Pence administration will defund Planned Parenthood and redirect those dollars to women’s health care that doesn’t provide abortion services.” In 2011, the House of Representatives passed a bill co-sponsored by Pence to defund the group.
“He’s been called a one-man crusade against Planned Parenthood, and he got his start going after them earlier than most. I would definitely call him an extremist,” Jan Schakowsky, a Democratic representative for Illinois, told the Guardian in July.


Following Trump’s victory last night, pro-life activists cheered. It’s an ominous sign of what’s to come, though public opposition will be formidable. “Trump would ban abortion, and eliminate women’s ability to have birth control covered by health insurance,” noted Dawn Laguens, the executive vice president of the Planned Parenthood Action Fund, in a CNN article. “A Trump presidency would be a disaster for women.”
Indeed, Trump could threaten women’s procreative liberties is by making it much more difficult to acquire birth control. As it stands, birth-control pills are free under the Affordable Care Act, but Trump says he wants Congress to repeal this act as soon as possible. In the very near future, it could be more difficult for women to avoid getting pregnant and getting an abortion. It suddenly feels like the 19th century.
Unlike most countries in the developed world, the United States is still deeply mired in the…
American pro-choice women are not going to relinquish their right to an abortion without a fight. What’s more, Trump and his Supreme Court justices will have their hands full trying to repeal or find loopholes to Roe V. Wade, the precedent that upholds a woman’s right to an abortion.


Yes, women have a right to be worried, but it may be more difficult—and politically damaging—for Trump to go through with his threats. Sadly, this is a man that doesn’t seem to care about the consequences.


Additional reporting by Sophie Kleeman. 
For the first time ever, a neural device has been used to restore locomotion in paralyzed primates. It may be years before clinical trials can begin for humans, but this latest breakthrough marks an important step in that direction.
A new study published in the science journal Nature describes a new neuroprosthetic interface that acts as a wireless bridge between the brain and the spine, bypassing the injury. Called the “brain-spine interface,” the system restored movement in the paralyzed right legs of two rhesus monkeys. The system was developed by neuroscientist Grégoire Courtine and his colleagues at the Swiss Federal Institute of Technology in Lausanne, along with help from researchers at the University of Bordeaux, Motac Neuroscience, and the Lausanne University Hospital (CHUV).


Back in 2012, Courtine used a chemical cocktail to “re-awaken” the damaged spinal cord of paraplegic rats, allowing them to walk, run, and evade obstacles. For the latest experiment, Courtine’s team chose a different route, one involving implants in the brain and in the area of the spinal injury. It marks the first time that a neuroprosthetic device has been used to restore locomotion in primates, and the scientists are optimistic the system can be adapted to humans.

Paralysis happens when a spinal cord lesion prevents brain signals from the motor cortex (the part of the brain responsible for movement) from reaching neurons that activate muscles. Regrettably, the nerves of the spinal cord do not heal spontaneously after injury, and scientists haven’t had much luck using various pharmacological and regenerative techniques. The World Health Organization estimates that somewhere between 250,000 to 500,000 people suffer a spinal cord injury each year worldwide, highlighting the extent of the problem.


The brain-spine interface overcomes a damaged connection by bridging the spinal cord injury—and it does so in real-time and via wireless technology. The neuroprosthetic device implanted in the monkey’s brain correctly interprets activity generated by the motor cortex, and relays this information to a system of electrodes placed over the surface of the spinal cord, just below the injury. A burst of just a few volts, delivered at the right location, triggers specific muscles in the legs. Monkeys implanted with the device were able to walk within six days of the spinal cord injury.
In experiments, the device allowed monkeys to walk and behave freely, and without having to be hooked up to a tangled web of wires and electronics. The monkeys, who had partial lesions inflicted to their spinal cords, showed immediate progress, and were able to spontaneously regain full mobility after three months.
“The primate was able to walk immediately once the brain-spine interface was activated,” said study co-author Erwan Bezard of Bordeaux in a statement. “No physiotherapy or training was necessary.”
The scientists are hopeful that the device will work for more serious spinal injuries, though according toNewcastle University scientist Andrew Jackson, who wrote a Nature News and Views article on the research, this will likely happen with the help of other interventions, such as chemical and electrical stimulation. Excitingly, the new system might be able to leverage the power of the brain’s plasticity; connections between two neurons are given a boost when both are active at the same time. It’s possible that this device could strengthen surviving motor pathways, further contributing to rehabilitation.
Looking ahead, the researchers say a similar system could be adapted to humans, but more work is need to address locomotion issues such as balance, steering, and obstacle avoidance—motor skills which were not addressed in the current study. On the plus side, many of the components used in the brain-spine interface have already been approved for humans. If all goes well, human trials could start in just a few years.


“For the first time, I can imagine a completely paralyzed patient able to move their legs through this brain-spine interface,” noted Jocelyne Bloch, the lead neurosurgeon on the project.
Nobody likes the idea of experimenting on animals. It seems like the definition of inhumanity,…
It’s important to point out that Courtine and his colleagues deliberately damaged the spinal column of the two rhesus monkeys, causing paralysis in the right leg. Given increasing public pressure to move away from this type of animal testing, particularly in Europe, the scientists were more comfortable doing their research in China. Jackson explains:
[The] use of monkeys for neuroscience experiments continues to be questioned in the media, and animal-rights groups are making concerted efforts to ensure that restrictions on such work are tightened in both the United States and Europe. It is notable that, although [the researchers] are based in Europe and their research conformed to the current regulations of the European Union, the experiments were conducted in China. Grégoire Courtine, the lead researcher on this study, has in the past described the challenges involved in performing such experiments abroad, and other scientists might lack the time, energy or resources to pursue their research so far from home. There is thus a real danger that the development of treatments for debilitating neurological conditions will be delayed if high-quality, well-regulated research in monkeys cannot be performed in Europe and America owing to increasingly tight regulations. Equally, as more primate neuroscience moves to Asia, it will be important for researchers to remain committed to refining techniques and improving welfare standards for experimental animals worldwide.
Jackson is right to point out that more ethical standards need to be implemented in Asia, but the scientific community should most certainly be moving away from primate experimental models. Rather than fleeing to countries with less stringent animals testing protocols, researchers should try and find alternative ways of testing their theories and systems, whether it be through computer models or recruiting human test subjects. Indeed, it’s possible that some paraplegics and quadriplegics would welcome the opportunity to participate in this sort of research, regardless of the risks.


[Nature]
The future of public health in the United States was a hotly contested topic during the 2016 election, with the presidential candidates making bold promises and several important ballot initiatives up for grabs. Here’s how America voted, and what a Trump presidency means to your health.
Donald Trump’s stunning upset victory was clearly the biggest story to come out of the election, but there were other notable developments as well, particularly in the field of healthcare. Last night saw impressive gains for legalized marijuana and doctor assisted death, while a proposal to release genetically modified mosquitoes in Florida is now in doubt.


What a Trump presidency means to other health-related issues, such as the status of medicare and bloated drug prices, remains unclear—though Trump now has the mandate and the power to completely upset various apple carts.
Voters in several states opted to support measures that would permit some use of marijuana. In California and Massachusetts, voters chose to legalize the recreational use of pot. Voters in Florida, North Dakota, and Arkansas approved the use of medical marijuana, while the results in Maine are still too close to call (though it looks good for pot advocates). States that already permit recreational marijuana include Colorado, Washington, Oregon, Alaska, and the District of Columbia. The results from last night means that more than 20 percent of the country’s adult population can now legally spark a doobie.


Voters in Colorado approved a measure allowing terminally ill patients to end their own lives, making it the sixth state in the nation to sanction physician-assisted suicide. Known as the Medical Aid in Dying initiative, it was approved by the vast majority of voters. Similar to a suicide law previously passed in Oregon, the new bill applies to terminally ill patients who have less than six months to live. Patients also need to make three separate requests for life-ending medication, two verbal and one written. In addition to Colorado and Oregon, other states that permit doctor-assisted death include Washington, Vermont, Montana, and California.
In California, voters considered a law, known as the Drug Price Relief Act, that would have placed a cap on prescription drug prices for certain buyers (potentially forcing some pharmaceutical companies to drop their prices). The final vote is not yet official, but it doesn’t look good for this proposal. Had it passed, the bill would have placed a limit on how much California could spend on the prescription drugs it purchases through programs such as Medicaid or insurance plans for state employees. Pharmaceutical companies poured $109 million on ads in an effort to dissuade voters from saying yes.
Voters in Florida expressed uncertainty about a proposed field trial to release bioengineered mosquitoes into the environment. These genetically modified mosquitoes would be able to thwart the spread of diseases like Zika, dengue, and chikungunya, but critics worry about unanticipated negative effects on the environment and public health. Voters in Key Haven rejected the idea, while residents of Monroe County approved it. This result may prevent the project from proceeding in Key Haven, but the results of the referendums are nonbinding. Board members of the Florida Keys Mosquito Control District have a final say on the matter, but given the results of the public vote, it’s not clear how they’ll proceed.
In regards to the future of US healthcare, it’s difficult to know exactly what Trump will do to reshape the system. Trump could try to abolish or roll back Obama’s Affordable Care Act; this is now conceivable given that Republicans have control over both the House and Senate. It’s quite possible that Trump will hand off the responsibility to House Speaker Paul Ryan, who could help craft a new system. That said, there’s considerable disagreement among Republicans over issues such as Medicare restructuring and how to make health insurance more affordable. This is going to be a tricky area for conservatives, who may face a political backlash should 20 million Americans suddenly lose coverage.


Congress has also been working on a bill that would accelerate the approval of drugs and devices by the Food and Drug Administration (a bill that Democrats also supported). This will come as a welcome reform, as the FDA is often accused of taking its sweet time with its approvals.
Another thorny issue is the problem of rapidly rising prescription drug costs (Epipens and price-gouger Martin Shkreli come to mind). Like Hillary Clinton, Trump supports the idea of allowing Medicare to negotiate prices. He also supports price transparency for the entire health care system, and allowing consumers to buy lower-cost drugs from foreign countries. But Republican congressional leaders aren’t on board—and neither are pharmaceutical companies. A potential battle is brewing between Trump and Big Pharma, and it’s not clear who’ll win, or if Trump will even make this a priority.
EpiPen, the life-saving allergy product, is now a $1 billion a year business for Mylan, a drug…
On the issue of the ongoing opioid epidemic and substance abuse, Trump’s campaign promises are unlikely to address the direness of the situation. Trump said he’ll build a wall on the Mexican border “to stop the flow of opioids,” which he says is the “source” of America’s opioid problem. As a solution, this is a non-starter—and that’s bad news for the two million Americans addicted to opioids, such as heroin, morphine, and prescription pain relievers.


[Globe and Mail, UPI, Scientific American, Vox, CNBC, STAT, Chicago Business]
One of the most unsettling moments in Stanley Kubrick’s 2001: A Space Odyssey is when it’s revealed that HAL 9000 can read lips, leaving no secrets between the astronauts and the ship’s computer. That might have been science fiction, but 15 years after the events of that film, researchers in the real world have finally taught computers how to read lips.
LipNet, developed by researchers at the University of Oxford Computer Science Department, isn’t the first software designed to predict what a person is saying by analyzing the movement of their lips. But it’s by far the most accurate, achieving an impressive 93.4 percent accuracy, compared to just 52 percent accuracy achieved by an experienced human lip reader.

So what’s the “secret sauce” that makes LipNet so adept at reading lips? Here’s how the researchers’ abstract that explains what makes their approach different, and better:
Lipreading is the task of decoding text from the movement of a speaker’s mouth. Traditional approaches separated the problem into two stages: designing or learning visual features, and prediction. More recent deep lipreading approaches are end-to-end trainable (Wand et al., 2016; Chung & Zisserman, 2016a). All existing works, however, perform only word classification, not sentence-level sequence prediction. Studies have shown that human lipreading performance increases for longer words (Easton & Basala, 1982), indicating the importance of features capturing temporal context in an ambiguous communication channel. Motivated by this observation, we present LipNet, a model that maps a variable-length sequence of video frames to text, making use of spatiotemporal convolutions, an LSTM recurrent network, and the connectionist temporal classification loss, trained entirely end-to-end.
So what does all that mean in English? Based on previous research, the computer scientists realized that humans are better at reading lips, and deciphering what’s being said, when longer words are spoken. So instead of analyzing footage of someone speaking on a word-by-word basis, LipNet goes one step further by taking entire sentences into consideration, using Deep Learning techniques to then backtrack and decipher each word.


But what does this mean for those of us outside academia? Running on a smartphone, fed a live feed from a body-worn camera, LipNet could serve as an amazing tool for the hearing impaired. Even if they already know how to lip read, it could help boost their understanding while watching someone speak. And those without lip reading skills wouldn’t be frustrated when a person they’re speaking to doesn’t know sign language.
[Cornell University Library via Laughing Squid]
Illegal ivory comes from dead elephants. It comes from elephants that were killed recently, and if you try to argue otherwise, you’re wasting everyone’s time. Hidden ivory stockpiles are not the problem. Freshly slaughtered elephants are, and now, science can prove it.
African elephant populations are in free-fall thanks to humanity’s insatiable demand for ivory. But despite the seemingly obvious connection between fewer live elephants on the African savannah and a surge in the amount of ivory on the black market, there’s a lot of confusion surrounding where illegal ivory comes from from. There’s a persistent idea that corrupt governments are fueling the trade, through vast storehouses of ivory stockpiled long ago.


Now, the issue can finally be laid to rest. In a new study published in the Proceedings of the National Academies of Science, a team led by Thure Cerling at the University of Utah used carbon-14 dating to determine the precise age of 231 tusks confiscated between 2002 and 2014. Their  findings? Only four of the specimens were more than five years old, and most ivory samples were from elephants killed less than three years ago.
A survey published earlier this year found that African elephant populations have declined nearly 30 percent from 2007 to 2014. That amounts to 144,000 magnificent animals killed in the name of household decorating.
“This is another method of seeing what’s happening, independent of the elephant count,” Cerling said in a statement. “It corroborates the count.”


According to the study, most ivory from East Africa hails from animals killed less than a year ago, while ivory from Central Africa tended to be more than two years old. This, the researchers say, suggests East African elephant populations—which live in more exposed savannah environments—may be easier to slaughter en masse, resulting in large shipments of fast-moving product.
That product is making its way all over the world, from jewelry shops in Hong Kong to antique stores in New York. It is even being sold as “legal” ivory. So, next time you’re imagining how attractive that “vintage carved tusk” would look on your living room mantle, just think how much better it would look on the elephant it (perhaps very recently) belonged to.
[Proceedings of the National Academies of Science via Nature News]
Delhi, the capital city of India and home to 25 million residents, is in the midst of an “extreme pollution event.” In other words the city has been overrun with smog—tons of it. Recent photographs show the extent of the problem, which is being blamed on everything from vehicle emissions and crop burning through to smoking and fireworks.
A noxious smog has settled over the city of Delhi, and it’s causing more than just a burning sensation in the eyes and throat. Tempers flared this past Sunday when hundreds of citizens gathered outside the Parliament buildings to protest the deteriorating conditions. It’s the worst pollution to strike the city in nearly two decades.
In response, the government has declared a pollution emergency, temporarily shutting down construction for five days, halting a power plant for 10 days, and closing the city’s 1,800 schools for three days. Should the situation not improve, city officials said they may restrict the number of vehicles allowed on the road.
The level of dangerous particles reached 700 micrograms per cubic meter on Monday. This past weekend, the level surpassed 1,000 in some places, which is 16 times the limit India’s government considers safe—and a whopping 70 times the level the World Health Organization considers safe.

Sustained exposure to these extreme levels of pollution are considered equivalent to smoking more than two packs of cigarettes a day. The fine particles, which measure between 2.5 to 10 micrometers, can enter the lungs, bloodstream, and even heart. The elderly and small children are particularly at risk.

Delhi is a miserable place to be in right now, and it’s easily the most polluted city in the world at the moment. Residents have been told to visit the hospital should they experience breathlessness, giddiness, chest pain, and constriction, and to wash their eyes with running water should they become irritated. Citizens have been clamoring for anti-pollution masks, and vendors are doing brisk business.
The cause of the pollution has been pinned on vehicle emissions, construction, holiday fireworks (Dewali just ended, but it’s a stretch to blame fireworks), and excessive smoking. But it appears that the primary contributor to the smog is the practice of crop burning. Earlier today, a government scientist said that crop fires in Punjab and Haryana contributed as much as 70 percent of the pollution load in Delhi.
Weather has also contributed to the unprecedented pollution levels in Delhi, including a change in wind direction that transported pollutants from the crop fires. Calm surface winds over the capital prevented the pollutants from dispersing, leading to an accumulation of toxic chemicals.
Meteorologists expect the pollution levels to drop today and over the course of the week as surface winds pick up. That said, air quality levels will likely stay within the “severe” to “very poor” levels this week.
Critics say the government is reacting to the pollution emergency by enacting short-term solutions, and that something needs to be done to alleviate the problem in the long-term.


[New York Times, CNN, Times of India]
It isn’t enough to halt global warming, but carbon-hungry plants are helping impede the buildup of CO2 in our atmosphere to a measurable degree, a new study has found. While this is a good thing and you should go thank a tree right now, the effect is probably temporary, speaking to how damn complicated our planet’s response to climate change is going to be.
The amount of carbon in the atmosphere is increasing every year. But while the growth rate of atmospheric CO2 climbed steadily throughout the late 20th century, between 2002 and 2014 it held flat at approximately 1.9 parts per million per year. This observation is difficult to square with the fact that humans are pumping more carbon into the air now than ever before.


When Trevor Keenan, a researcher at Berkeley Lab’s Climate and Ecosystems Division, discovered the growth rate pause while analyzing data from the Global Carbon Project last year, he realized there must be a missing carbon sink. Furthermore, he recognized that the missing sink wasn’t in the ocean, which has been soaking up carbon at a well-measured rate over the last few decades.
But on the land, climate conditions are much more variable from year to year. And changes in temperature and rainfall directly impact the amount of carbon plants draw down from the atmosphere and release back.


“We realized the land sink was increasing,” Keenan told Gizmodo. “We didn’t know where, or why.”
Seeking answers, Keenan and his colleagues combined computer models of Earth’s carbon cycle with thirty years of satellite data on land-based vegetation, in addition to data from research towers that measure the amount of CO2 and water entering and leaving forests at their canopies.
This analysis, which is published today in Nature Communications, zeroed in on two factors responsible for the apparent slowdown in atmospheric CO2 buildup. One, plants drawing down more carbon for photosynthesis. Two, plants burning  less carbon for fuel. (Like humans, plants eat carbon-based sugars, and “respire” some of the energy back to the atmosphere as CO2.)
Greater carbon uptake in a carbon-loaded atmosphere is something ecologists have been discussing for a while. They’ve even given it a fancy name: the “CO2 fertilization effect.” Countering this effect is the respiration of CO2, which tends to increase for plants as temperatures rise.


But between 2002 and 2014, temperatures over the land didn’t rise as fast as they had been rising before. This, Keenan and his co-authors argue, is key.
“A lack of warming meant there wasn’t as much CO2 going into the atmosphere [from plants],” Keenan explained. “Meanwhile, we had CO2 in the atmosphere going up, causing a fertilization effect.”
It’s an elegant solution to what, for Keenan and many others, was a vexing planet-wide mystery. “I think this is an excellent analysis, and will be very thought-provoking,” David Schimel, an Earth scientist at the Jet Propulsion Laboratory who was not involved with the study, told Gizmodo.


But as Keenan and others emphasize, we cannot expect plants to eat enough extra carbon enough to save our collective assess. In fact, given our recent string of record-smashingly hot months, it’s possible Keenan’s newly-identified carbon sink has already started to disappear.
“It’s quite likely this is a temporary pause in the growth rate of CO2,” Keenan said. “As warming kicks back in, we’ll see the growth rate go up again.”


Schimel agrees. “The terrestrial uptake was caused, probably, by increasing CO2, but was aided by the slower growth rate of temperature over ten years or so (the so-called “pause”),” he wrote in an email. “Since the pause had ended, we’d expect to see the more rapid growth of biospheric uptake stop.”


Of course, any research highlighting the voracious CO2 appetite of Earth’s vegetation reminds us that restoring forests is one of the best strategies we have for offsetting carbon emissions. Under the Paris climate agreement, many nations have pledged to reduce their carbon footprints by doing exactly that.
But at the end of the day, there’s only one thing that’s going to protect us from the worst consequences of climate change—and that’s to kick the fossil fuel habit entirely.
[Nature Communications]
Residents of the southern Japanese city of Fukuoka had a rather rude awakening this morning when a gigantic sinkhole formed near the JK Hakata train station. Local officials are now desperately working to prevent the collapse of nearby buildings.
The road outside the train station began to collapse in two sections around 5:15am local time, and they gradually expanded and collapsed into one gigantic hole (check out the dramatic video below). The hole now measures nearly 100 feet across and 50 feet deep.

Flowing water from a drain filled the opening like a bathroom sink, raising concerns that it could expand further and topple buildings nearby. Evacuations were ordered, and electricity was cut off for fear of igniting a gas leak (some 800 households are now without power). No injuries have been reported.

City officials admitted that work to bore a tunnel for a subway extension was the cause of the cave-in. Construction workers were digging about 80 feet below the surface when they noticed groundwater starting to flow into the tunnel. Realizing that something was askew, the workers monitored the tunnel while regulating traffic on the surface. Over the course of the next few hours the hole got increasingly larger. By the early afternoon, the city government decided to fill the hole as a stopgap measure to prevent buildings along the road from collapsing.

A drilling survey found that groundwater flowed into areas deeper than 10 to 16 feet below the surface. Workers tried to discharge the water with pumps, but were unable to prevent the cave-in.


[Asahi Shimbun]
NASA’s Juno mission is not exactly proceeding according to plan. Last month, an engine burn that would have brought the Jupiter-orbiting spacecraft into a low-altitude orbit was delayed following a malfunction with a pair of helium valves. Now, NASA has confirmed that the next opportunity to enter “science orbit” will also be missed—and that may be the case for the foreseeable future.
On October 14th, NASA announced that Juno’s final main engine burn, intended to move the spacecraft from its current 53.5-day elliptical orbit into its 14 day science orbit, was not going to happen as planned on October 19th. Instead, the space agency flagged December 11th, Juno’s next close approach (or perijove), as a possible future opportunity to execute the maneuver.


But a few weeks later, NASA issued another statement indicating that the December 11th perijove would be a “science flyby,” wherein the spacecraft points its scientific instruments at Jupiter to collect data, as it did on August 27th. Jet Propulsion Laboratory spokesperson DC Agle confirmed to Gizmodo that this means no engine burn. “A majority—if not all—instruments would be off during such a maneuver,” he said in an email.
Agle did not speculate as to when Juno might attempt to fire its engine again. The spacecraft’s next perijove falls on February 2nd, and there’s another one after that on March 27th.
But NASA has been dropping hints that Juno may be  stuck in a 53.5 orbit for a long time, possibly for the duration of its mission—and that this might not be the end of the world. “We can do all of our science in a 53-day orbit if needed,” Juno principal investigator Scott Bolton told reporters at recent Division of Planetary sciences press conference in Pasadena.


The Juno spacecraft was originally set to perform 33 two-week science orbits, which would bring it close to Jupiter’s poles and back out again, in order to peer beneath the gas giant’s cloud tops and map its magnetic field in unprecedented detail. In a 53.5 day orbit, it’ll take a longer time for Juno to collect the same amount of data. But since the spacecraft is only exposed to intense radiation during its close polar approaches, the overall radiation dose should not change much. “It’s the number of orbits that drives radiation up,” Botlon explained.
In mid 2019, if Juno is still in a 53.5 day orbit, it starts to run into eclipse issues, passing through Jupiter’s shadow for several hours each orbit. This could cause power deficiencies for the solar-charged spacecraft.
The space agency would have to cross that bridge if and when it arrives. But for now, engineers are still trying to find a solution to the helium valve issue. At a Lunar Exploration Analysis Group meeting last week, SpaceNews reports that James Green of the Planetary Science Division described NASA as taking a “very slow” approach to the problem. Among other things, it’s investigating possible connections to a thruster malfunction with a similar engine in Boeing’s Intelsat 33e satellite, which launched in August.
“We’re going to take another cycle around Jupiter and really study what’s happening before we make a decision on what to do next,” Green said.
Incredible photographs from a beach in Nyda, Siberia, show thousands of naturally formed snowballs spread across an 11 mile stretch of coast. This is now officially the best place in the world to have a snowball fight.
The giant snowballs began to appear on the beach about a week and a half ago. Locals in the village of Nyda, which is situated on the Yamal Peninsula just above the Arctic circle, have never seen anything quite like it. The balls of ice and snow range in size from just a few inches across to almost three feet wide—and they number in the thousands.


The snowballs look as if they were meticulously crafted by hand and then strategically placed across the beach, but they formed through natural processes. As Sergei Lisenkov from Russia’s Arctic and Antarctic Research Institute explained in the Siberian Times, they’re caused by a rare environmental process in which small pieces of ice form and are rolled by the wind and water:
When the water in the gulf rose, it came into contact with the frost. The beach began to be covered with ice. Then the water began to slowly retreat, and the ice remained. Its pieces were rolling over in the wet sand, and turned into these balls.
It is a rare natural phenomenon. As a rule, grease ice forms first, slush. And then a combination of the action of the wind, the outlines of the coastline, and the temperature, may lead to the formation of such balls.
Though exceptionally rare, this sort of this has been seen before, including in 2014 when balls like these appeared on the Lake Michigan shoreline.


[Siberian Times]
We all know how common elements like oxygen and helium are used in every day life. But gallium? Selenium? Rhodium? Keith Enevoldsen has created an interactive periodic table that illustrates exactly where you may encounter even obscure elements on the chart. It’s like taking high school science all over again, except without the tests, and you’re welcome to keep using your phone.
[Elements.wlonk.com via Twitter - Corey S. Powell]
A  magnitude 5.0 earthquake rattled the Oklahoma prairie town of Cushing last night, damaging several buildings and threatening one of the world’s largest oil terminals. Earthquakes are now a disturbingly frequent phenomenon in the region, with all signs pointing to the practice of disposing oil and gas field wastewater deep underground.
The quake—the third 5.0-plus tremor to hit the region this year—struck at 7:44pm local time at a depth of 3 miles (5 km). It was centered about 1.25 miles (2 km) west of Cushing, about 40 km south of where a magnitude 4.3 quake struck last week, forcing a shutdown of several oil wells. Yesterday’s tremor was the 19th to hit the region in the past week. The quake was felt as far away as Iowa, Illinois, and Texas.

“I thought my whole trailer was going to tip over, it was shaking it so bad,” noted a Cushing resident in an Associated Press article. “It was loud and all the lights went out and you could hear things falling on the ground. It was awful and I don’t want to have another one.”

Some minor injuries were reported, and city officials are now eager to inspect the damage, much of it in the town’s century-old downtown area. There’s fear that some of the community’s older buildings may now be unsafe, and that the tremblor might have damaged key infrastructure. Residents have been told to stay away from damaged sites, while schools have been closed for the day.

Pipeline operators haven’t reported any problems, but the community—known as the “Pipeline Crossroads of the World”—hasn’t heard from all companies. The region is home to an oil terminal that’s one of the world’s largest. Tank farms in-and-around Cushing hold about 58 million barrels of crude oil.


It’s the largest quake to hit the region since a 5.8 magnitude quake struck Pawnee on September 3, 2016—a record for Oklahoma. Once rare, earthquakes are now a disturbingly frequent occurrence. The state has experienced 2,200 earthquakes in just the past year.

Quakes above magnitude 5.0 are still quite rare, with yesterday’s being the third felt this year. Human-induced earthquakes are on the rise in both the United States and Canada, likely the result of oil and gas industry practices. The volume of waste water that’s being stored underground has risen more than 80 percent in the past six years, a timeframe that happens to coincide with Oklahoma’s sudden tendency towards earthquakes.


[Associated Press]
Investigating a strange electrical anomaly, geologists have discovered an enormous water reservoir beneath the now-dormant Uturunco volcano in the Bolivian Andes. It’s a remarkable find that speaks to the vast amounts of water stored in Earth’s deep interior, possibly since our planet was formed.
“It’s probably somewhere between Lake Superior and Lake Huron,” Jon Blundy, a geologist at the University of Bristol and co-author on the new discovery published in Earth and Planetary Science Letters, told New Scientist. “It’s a staggeringly large amount.”


As geologists probe Earth’s deep interior using new technologies, it’s becoming clear our classic depiction of volcanoes, as ruptures in the Earth’s crust that sit atop vast reservoirs of gooey rock, is a bit simplistic. In some cases, the magma source is not located beneath the volcano, but many miles away. In other instances, there’s more to the magma itself than meets the eye.
Mikael  Laumonier of the University of Bayreuth and his colleagues discovered Uturuncu’s watery secret while investigating strange properties of the Altiplano-Puna magma body, located nearly 10 miles beneath the volcano. This magma body slows down seismic waves and features a surprisingly high electrical conductivity. According to laboratory experiments that simulated temperatures and pressures inside the volcano, its properties are best explained by a water content of 8 to 10 percent.


Extrapolating this concentration to the entire size of the Altiplano-Puna magma body, the researchers infer the presence of a tremendous subterranean “lake,” of sorts. “It’s dissolved in partially melted rock at 950 to 1000 degrees Celsius, so it’s not accessible,” Blundy told New Scientist.


While we won’t be tapping Uturuncu for irrigation anytime soon, the finding could help explain anomalous electrical readings from other volcanic systems around the world, including the Cascade arc in the Pacific Northwest and the Taupo Volcanic Zone in New Zealand. What’s more, a high water content in active volcanoes may shed light on the composition of Earth’s continental crust, and  on a 4.5 billion year old mystery: how our planet got wet in the first place.
There’s a fierce scientific debate over whether the Earth coalesced from tiny, water-coated grains of dust, or whether our blue marble started its life as a dry rock, with the oceans arriving later via comets and asteroids. The answer may lie in water buried in fiery reservoirs miles beneath our feet.
[Earth and Planetary Science Letters via New Scientist]
Entire lifetimes have come and gone without the moon looking quite as large as it will this month. On November 14th, skygazers will witness the closest full moon, or “supermoon,” of 2016. But more excitingly, it’ll be the closest full moon since 1948—and we won’t get another one like it until 2034.
The reason the moon appears to shrink and grow in the sky is that its orbit is not a perfect circle, but  rather, a modest ellipse. As the moon swings between its closest point (perigee) and its furthest point (apogee), its distance to Earth varies by approximately 30,000 miles. This translates to a size variation comparable to the difference between a nickel and a quarter.


Full moons and new moons occur when the Earth, sun and moon all form a line, something astronomers call “syzygy.” When  the moon is on the opposite side of the Earth as the sun during syzygy, it appears full. And when this particular celestial alignment also happens to coincide with perigee, we get an exceptionally close full moon, also known as a perigee moon or a supermoon.

A full moon at perigee can appear up to 14 percent larger and 30 percent brighter than a full moon at apogee. But even among the elite perigee moons, there’s some variation in size. That’s because the sun and moon—being moving objects in space rather than circles on a diagram—very rarely line up exactly at perigee. And, to a lesser extent, because the Earth’s distance to the sun changes during its orbit, too.


What makes the November 14th moon so special is that it turns full at 1:52pm UTC (9:52am ET), two and a half hours after hitting perigee at 11:23 UTC (7:52am ET).  This is the closest a full moon has to come to hitting perigee on the nose since January 26th, 1948, and the closest it will come for another 18 years, until November 25th, 2034.
All in all, it’ll be the largest moon in an 86 year period, which is pretty damn cool. Although, as NASA Planetary Program Executive Gordon Johnston notes, it’ll be very hard to tell the difference between this super-dupermoon and more ordinary supermoons with the naked eye. “You’d need a ruler,” he said.
According to Johnston, if you’re on the East Coast, the best time to check out this once-in-a-lifetime supermoon is going to be early on the morning of November 14th, before the moon sets and the sky starts to lighten at dawn. Not only is pre-dawn the closest to the full moon perigee us East Coasters are going to get, but—added bonus—as the moon sets, it can appear unnaturally large, owing to the fact that your brain starts measuring it against other objects on the horizon.
So: set an early alarm for the 14th, and get ready to bask in the glory of the most brilliant supermoon the modern world has seen.
[EarthSky, NASA]
The US Centers for Disease Control has released a report in which it identifies over a dozen cases of a deadly, antibiotic-resistant fungus called Candida auris. It’s the first time this super-strain has been found in the US, and disturbingly, four of the first seven patients infected with it have died.
Scientists have known about the fungus since 2009 when it was first identified from the ear canal discharge of a patient in Japan. Since then, infections have been reported in several other countries, including South Africa, the United Kingdom, India, and others. And now, as the CDC reports, the fungus has finally made its way to the United States—and it’s likely been lurking in the country since 2013. This serves as another potent reminder that the antibiotic era is quickly coming to an end.
More and more diseases are becoming resistant to antibiotics. Within a few decades, we’ll enter the …
Candida auris causes a nasty, and often fatal infection that’s typically treated with a class of antifungal drugs called echinocandins. But some isolates of this globally emerging health threat were found to be resistant to all three major classes of antifungal medications. The fungus can trigger infections in the bloodstream, wounds, and inside the ear. Complicating matters, the organism is difficult to identify using standard biochemical methods, and it’s often misidentified as other yeasts (typically Candida haemulonii, Candida famata, Saccharomyces cerevisiae, and Rhodotorula glutinis).


“It appears that C. auris arrived in the United States only in the past few years,” noted Tom Chiller of the CDC’s Mycotic Diseases Branch, in an agency release. “We’re working hard with partners to better understand this fungus and how it spreads so we can improve infection control recommendations and help protect people.”
Seven of the cases described in the new report occurred between May 2013 and August 2016. They were discovered in four states: New York, Illinois, Maryland, and New Jersey. All cases were found in patients, prompting the CDC to say these findings “suggest that C. auris could be spread in healthcare settings.” All of the seven patients had underlying medical conditions, so it’s not clear if the four who died were actually killed by the fungus. Sixty percent of patients who acquired the infection died, but given the small sample size, it’s not clear just how deadly this fungus actually is. The other six cases were discovered after the period covered in the report and are still being investigated.
Lab tests show that the US strains were related to strains from South Asia and South America, but none of the patients travelled or had direct links to those locations. This strongly suggests that the patients acquired their infections locally. Disturbingly, this organism can spread quite easily; a sweep of the Illinois patient’s hospital room revealed traces of C. auris in his mattress, bedside table, bed rail, chair, and windowsill.


The CDC has been warning about C. auris since 2013 when it issued a report describing antibiotic resistant threats that required prompt attention. In light of this finding, the CDC is recommending that healthcare professionals implement strict Standard and Contact Precautions to control and prevent the spread of this vile fungus.
[CDC]
When a droplet of water impacts a larger body of water it has a tendency to bead up and bounce. It happens constantly, but you might not have focused closely enough to consider its strangeness—and it is very strange, especially when viewed on a high-speed camera.
As Destin from Smarter Every Day discovered with some help from astronaut Don Pettit, the answer to why water bounces is air. As the droplet falls, a layer of air gets caught between the two impacting surfaces which keeps them from becoming one singular body of water. Surface tension from the standing water launches the water bead back upward, each time with less energy, until eventually enough air is forced out and the bead coalesces with the larger mass.


On a vibrating surface—a speaker cone, for instance—the droplets survive even longer. And some truly unusual things happen when water, air, and a cello get together in space. But I’ll leave the heavy science lifting to Destin.

Correction: Destin from SED reached out to inform us that Don Pettit is still very much active as an astronaut. Sorry Don!
Say hello to Dave, the largest earthworm ever discovered in Britain.
This ridiculously long specimen of the common earthworm (Lumbricus terrestris) was discovered by Paul Rees of Widness, UK, who spotted the 15 3/4 inch-long (40 cm) behemoth in his veggie garden. His stepson, George, named it Dave. Knowing he had found something rather extraordinary, Rees delivered Dave to Emma Sherlock, a scientist at the Natural Museum of History.
“I was bowled over by the size of this worm when I opened the plastic box they sent it in,” said Sherlock in a museum release. “Not only is it really long, it is almost twice as heavy as any other wild earthworm ever seen, weighing the same as a small chocolate bar.”


How wonderful that she compared it’s weight to a chocolate bar. Anyway, the worm weighed in at 26 grams (0.92 ounces), which absolutely destroys the previous record for the UK—a 15 gram (0.53 ounce) earthworm discovered in Scotland just last year.
Worms the size of Dave are rare because the larger they get, the more likely they are to become some animal’s meal. What’s more, the garden that Dave lived in must have been incredibly fertile and well-drained, with decaying matter quickly recycled back into the soil.
Sadly, Dave is no longer among the living—a victim of his incredible length and girth. Much to the chagrin of some overly sensitive tweeters:


The good news, however, is that Dave will be preserved in a jar at the Natural History Museum for all time. So tweeters calm down.


[Natural History Museum]
Officials in south Florida have been releasing troves of sterile flies in an effort to combat a parasitic maggot that eats the living tissue of warm-blooded animals—including humans.
The New World screwworm outbreak—the first to strike the United States in over 30 years—has already claimed the lives of 120 Key deer in the Florida Keys (out of a herd of 1,000). State officials now fear that the blight could spread to livestock, causing millions of dollars’ worth of damage to agriculture. Residents are being asked to monitor their pets, while park managers have started to erect enclosures in case the deer need to be corralled for preservation purposes.
In response to the infestation—which is currently limited to Big Pine Key and No Name Key—the Florida Commissioner of Agriculture has declared an agricultural state of emergency across the entire Monroe County. Meanwhile, authorities are working to suppress the population of screwworms by releasing sterile males in vast numbers. When these sterile males mate with females, no offspring are produced, resulting in a population crash. With each passing generation, and with increasingly dwindling numbers of fertile males, the fly basically breeds itself out of existence.


The US Department of Agriculture says it has been releasing more than three million sterile files twice a week to prevent the infestation from spreading any further. Since October 11, state officials have carried out 87 releases at 25 sites in the Florida Keys. It’s not clear how long the current effort will take, or how much it’ll cost. Eradication efforts like this typically take about six months.
Much to the chagrin of farmers, the parasitic screwworm fly (Cochliomyia hominivorax) produces larvae maggots that eat the living tissue of warm-blooded animals (a condition called myiasis). When in the larval stage, the worms burrow their way into live flesh in a corkscrew-like fashion (hence its name), effectively eating the animal from the inside. The worms typically enter an animal through an open wound. Frighteningly, it can also infect humans, though cases are rare, and none have been reported during the current outbreak.


To create the sterile males, the flies are bred in vast numbers and then blasted with radiation. No genetic modifications are required. The USDA developed this technique back in the 1950s as a form of biological control. The US government spent $750 million over the course of 45 years to eliminate the troublesome fly in Louisiana, Florida, and Puerto Rico.
The screwworm is a tropical insect, so its re-appearance in the United States may have something to do with rising global temperatures. But as noted, the screwworm has thrived in the US before. More work will be needed to establish a connection, should any exist.


[BBC, USDA]
A new analysis of the Ebola genome shows the dreaded virus acquired several new mutations during the course of the 2013-2016 West African Epidemic, making it even better at infecting human cells.
Two teams of researchers have published papers in the journal Cell (here and here) showing that the Ebola virus emerged from the West African epidemic stronger than before. A series of fortuitous mutations (well, fortuitous for Ebola at least) increased the ability of the virus to infect human cells. The virus, which is already highly communicable, appears to mutate quickly during an epidemic, allowing it to spread quickly. The two independent studies were led by Jeremy Luban from the University of Massachusetts Medical School and Jonathan Ball, a virologist from the University of Nottingham.
The recent Ebola outbreak was unique in that it was the first opportunity for the virus to replicate en masse and infect tens of thousands of humans. Previous to this episode, Ebola outbreaks were short lived, so the virus didn’t have much opportunity to adapt genetically to its human hosts. But during the most recent widespread outbreak, the disease infected an estimated 28,616 people across 10 countries, killing 11,310.


When the virus isn’t circulating through humans, it’s moving around in an unknown animal “reservoir,” likely fruit bats. It’s possible for the virus to acquire human-specific adaptations while circulating through bats, but the chances of this happening are exceedingly slim. The West African Epidemic offered Ebola an unprecedented opportunity to use humans as a testing ground for its genetic experiments, and through the powers of Darwinian natural selection, it was able to exploit our biological defences.
For the two studies, the research teams used publically available Ebola gene sequences to track any potential mutations. Their analysis uncovered mutations in the gene that encodes for Ebola’s glycoprotein—a protein that plays an important role in cell-on-cell interactions. This alteration to its genetic constitution enhanced Ebola’s ability to infect the cells of humans and other primates. Using infection models, the researchers were able to demonstrate the virus’s newfound skills on cultured human cells.


“We believe that the mutant was selected for by the unprecedented human-to-human spread in this epidemic,” Luban told Gizmodo. “It has never been seen before in people or animals.”
The researchers say it’s possible that these mutations increased the spread of Ebola during the outbreak. And indeed, one particular mutation emerged early during the outbreak, and at a time when case numbers spiked. The new strain quickly became the dominant version.


It’s not immediately clear if the mutated form of the virus still exists.
“It might persist in some of the people found to harbor Ebola virus for long periods of time after they recover,” Luban said. “We really don’t know much about this phenomenon yet.”
Another possibility is that the updated virus leaked back into the wild, though that scenario seems unlikely given that the mutated form of the virus is now distinctly disadvantaged in non-primate cells. Luban’s research found that the mutation only increases Ebola’s efficiency in human and other primate cells, which is actually good news—these mutations did not increase Ebola’s ability to infect the cells of fruit bats, the likely source of human outbreaks.
That said, this particular strain of Ebola might arise anew in future outbreaks, or different mutants might emerge. “What our studies show is that viruses better adapted to infecting humans arise quickly, and they can acquire further mutants to improve infectivity further and...play an important role in spread and severity of disease,” Ball told Gizmodo.


Looking ahead, the teams would like to learn more about these mutations, how the virus infiltrates cells, and how diseases evolve over the course of outbreaks. Hopefully, that’ll put us in a better position when the next outbreak hits.


[Cell 1, Cell 2]
To address the burgeoning “loneliness epidemic” and the demands of an aging population, some think that we should deploy robotic caregivers. A new ad titled “B.E.N. (Biologically Engineered Nursing),” however, suggests that this is a dreadful idea.
This five-minute ad was produced by the Society of Saint-Vincent-de-Paul (SSVP), an international Catholic voluntary organization that provides assistance to those in need. When the short story opens, we see a woman, Claudine, dancing with her robotic caregiver, BEN. From there, we travel back to the previous day, and we come to see how the pair came to their gloomy embrace.

As the ad shows, all is not as it appears to be. BEN may be attending to his client’s basic needs—such as preparing food and ensuring she gets up in the morning—but something vital is missing in these encounters. BEN, as an algorithm-driven automaton, is clearly failing to connect with Claudine. After all, robots are still robots at the end of the day.


“Today, companion robots are being introduced to assist lonely people,” proclaims the SSVP at the end of the ad, who are clearly referring to initiatives like Japan’s PARO therapeutic robot, a seal-like robot designed to “simulate interaction between patients and caregivers.” But as this new ad shows, simulation is a poor substitute for the real thing. “We think that only human being[s] can help in fighting loneliness,” says the SSVP. “We recruit volunteers.”
It’s been well established that social isolation is a serious health risk, particularly for…
It’s been well established that social isolation is a serious health risk, particularly for the elderly. Studies have shown that spending too much time alone is just as dangerous as smoking 15 cigarettes a day, and that socially isolated individuals experience a 26 percent increased risk of dying, regardless of the cause of death.


Sending human caregivers into the homes of the lonely is certainly one way to address this problem, but these interactions still need to be sincere in order to be effective. (It’s worth pointing out that some human caregivers can be just as bad—or even worse—than the robot portrayed in this commercial.) At the same time, we cannot discount the potential effectiveness of caregiving robots, whether they be silly robotic seals, or something more futuristic. Psychological projection can be a very powerful thing.
Finally, physicians and healthcare professionals need to do their share by routinely evaluating their patients’ social networks, and make recommendations about reaching out and connecting with more people. You don’t want your loved ones to end up talking to the refrigerator just because that’s their only option.


[AdWeek]
Go get your freak on, because athletes can officially have sex before the big game without feeling guilty. A new study from researchers published in Frontiers in Physiology claims that there “is no robust scientific evidence to indicate that sexual activity has a negative effect upon athletic results.”
This is a huge deal for athletes. As you’ve probably heard before, famous competitors like Muhammed Ali and even entire World Cup teams have implemented no-sex rules before big matches, hoping it would make them more focused and competitive. In recent years, this myth has been called into question, with researchers noting the lack of scientific evidence to support its claims. A new study aims to close the book on this debate and finally declare: athletes can bang before the big game.


“We clearly show that this topic has not been well investigated and only anecdotal stories have been reported,” researcher Laura Stefani said in a news release about the new study. “In fact, unless it takes place less than two hours before, the evidence actually suggests sexual activity may have a beneficial effect on sports performance.”
Researchers reported their findings after sifting through hundreds of studies and whittling down the list to the nine most reliable studies that examined impact of sexual activity on performance. The new study points out that male athletes have been more frequently investigated than females, and there are no comparisons of the effects across genders.


The big takeaway: the findings mean athletes can go back to wearing dirty clothes, talking to inanimate objects, and all of the other weird superstitions they’re already doing anyways—but at least they can have sex before all that.


[Frontiers in Physiology]
If you’re planning to live in the Big Apple for the foreseeable future, it’s time to invest in flood insurance and a gondola. A new study finds that nine-foot floods, like those produced by Hurricane Sandy, will be three to 17 times more frequent by the end of the century, thanks to sea level rise and shifting storm conditions.
Ever since Hurricane Sandy flooded the New York City subway, brought a record 11-foot storm surge to the Battery tide gauge, and caused billions of dollars of property damage,  scientists have been trying to understand just how extreme this disaster was in a historical context. Through detailed sea level reconstructions from 850 to 1850 AD, we’ve learned that Manhattan’s flood risk has indeed been going up steadily over the last millennia. The land is slowly sinking into the ocean, causing relative sea levels to rise at about 1.4 millimeters each year.


But then came the 20th century, and a ramping up of sea level rise to around 3 millimeters per year due to human-caused climate change. “We found that if you factor in this change in sea level that’s happened in New York [since the 19th century] that’s led to about a three fold increase in flood risk,” said Robert Kopp, an Earth scientist at Rutgers University and co-author on the new study.
Overall, Kopp says, a Sandy-like flood jumped from being a 1-in-1,200 year event at the dawn of the Industrial Revolution, to a  1-in-400 year event in the year 2000.


That’s bad news, but it gets much worse when you look at changing flood risks over the 21st century. Our best models estimate that New York City will see 1.6 to 3.2 feet (half a meter to a meter) of sea level rise by the end of the 21st century, thanks to ongoing subsidence of the land, melting ice sheets, and the expansion of seawater as it warms up. Meanwhile, climate change is likely to have complex effects on storm dynamics, with the expectation that a warmer future will promote the growth of more powerful storms that can hold more rain.
Combining models of future sea level rise, shifting storm patterns, and carbon emissions—which are assumed to follow the UN’s middle-of-the-road, RCP 4.5 scenario—Kopp and his colleagues estimated that Sandy-like floods will become about four times as frequent by the late 21st century. In other words, a once every 400 year event will become a one-in-100 year event. But there’s still a lot of uncertainty, particularly depending on which storm model you look at. In a worst-case projection, nine foot floods could make a dramatic, 17-fold jump in frequency, recurring every 23 years on average by the end of the century.
“The grand answer is that things are going to get worse by 2100,” study co-author Ben Horton said in a statement.
For Kopp, the point of studies like this is not to terrify the bejeezus out of people, but to highlight the fact that we live in a rapidly changing world when it comes to flood risk. In New York, the risk is almost certainly going up, and that’s a reality which needs to be factored into all future planning decisions.
The same could be said for Miami, New Orleans, or any other major population center on the front lines of sea level rise. And by the way, the world’s coastal populations are growing fast.


“The punch line is that this basically needs to be a core part of how we make decisions about anything that’ll be around for years to come,” Kopp said.


[Proceedings of the National Academies of Sciences]
At a distance of 4.2 light years, Proxima b is the closest potentially habitable Earth-like planet outside our solar system. New research suggests this distant orb could be completely covered in water. So when do we go?
This past August, scientists with the European Southern Observatory (ESO) confirmed the discovery of a rocky planet in the habitable zone of Proxima Centauri—our nearest neighboring star. Little is known about this distant planet and whether it has what it takes to foster alien life, but a new study accepted for publication in the Astrophysical Journal posits the suggestion that Proxima b is covered with oceans, and possibly even a single massive ocean that envelops the entire planet.
Last week, astronomers announced that our nearest neighboring star hosts an Earth-sized planet in…
Proxima b is a fascinating target for study, and not just because it’s an Earth-like planet in the star system nearest to our sun. The planet has a mass around 1.3 times that of Earth, and it sits in a tight orbit approximately a tenth the distance of Mercury to the sun. That’s not necessarily a problem because Proxima b’s host star, Proxima Centauri, is about 1,000 times weaker than our sun. That places it within the  habitable zone, where liquid water can reside at the surface.


Observations of Proxima b are few and far between, so Bastien Brugger and his colleagues from Marseille University in France ran a series of simulations to get a better sense of the planet’s composition and radius. Their estimates show that Proxima b’s radius ranges somewhere between 0.94 and 1.4 times that of Earth, which is about 3,900 miles (6,300 km) on average.
If the planet’s radius is closer to the lower bound of the estimate, it should be very dense, with a metallic core making up a whopping two-thirds of the planet’s entire mass, and surrounded by a rocky mantle. Any surface water on this planet would contribute to about 0.05 percent of the planet’s total mass, which is comparable to Earth’s 0.02 percent. Vast ocean ranges could very well exist on Proxima b.


But if the planet’s radius is closer to the higher estimate, around 5,540 miles (8,920 km), things get even more interesting. In this scenario, the planet’s mass would be split evenly between a rocky center and surrounding water.
“In this case, Proxima b would be covered by a single, liquid ocean 200 km deep [124 miles],” noted the researchers in an AFP article. “In both cases, a thin, gassy atmosphere could surround the planet, like on Earth, rendering Proxima b potentially habitable.”


It’s easy to get excited about this result, but we need to learn a lot more about this planet before we jump to conclusions. The researchers based their models on the assumption that Proxima b harbors a thin atmosphere—but we actually don’t know what kind of atmosphere this planet has, or if it even has one.
For all we know, it’s a frigid and airless chunk of rock—and not anything that would remotely resemble a habitable planet. But one thing’s for sure, Proxima b is turning out to be the most interesting—and alluring—planet outside of our solar system.
[arXiv]
At the same time that Hurricane Matthew ravages the southeastern US, a new tropical storm has appeared just south of Bermuda. Together, the two have set a new  late-season record for storms in the Atlantic. Welcome to the frightening realities of a warmer world.
This latest storm, called Nicole, achieved hurricane status yesterday afternoon, setting a new record for the Atlantic Ocean. As Hurricane Matthew’s winds approached 120 miles per hour, Nicole’s winds reached 105 miles per hour. As NASA’s Goddard Space Flight Center explained, “it marked the latest in the calendar year that two storms in the North Atlantic Ocean have had winds over 105 mph simultaneously.”
There is no doubt that Hurricane Matthew is a nightmarish storm. Unfortunately, it’s exactly the…
Nicole was downgraded from a Category 1 hurricane to a tropical storm earlier today. It no longer features a tell-tale eye, and satellite images show clouds being pushed away from the center by vertical wind shear. By late morning, the storm was located about 345 miles (555 km) due south of Bermuda.
At the moment, this storm is barely moving, but it’s slowly migrating southwards. Nicole is expected to make an about-face on Sunday and start tracking north towards Bermuda. Another possibility is that the storm will start to drift westwards on Sunday.


Ocean swells produced by Nicole, along with rough surf conditions, will affect Bermuda for at least the next five days. Thankfully, the storm is expected to weaken over the coming days, and it may never re-attain hurricane status.
[NASA’s Goddard Space Flight Center, NOAA]
Unbelievable footage from Australia shows a whale calf as it desperately tries to free its mother from a sandbank.
The humpback whales were spotted near North Stradbroke Island, about an hour’s drive from Brisbane. The mother had swum on top of a sandbank and was unable to get free. Video footage of the scene shows the distressed calf nudging and pushing its mom in an attempt to free her from the bank.


In response, a team from Queensland Parks and Wildlife Services were dispatched to help rescue the pair. Fortunately, owing to incoming tides and the efforts of the youngster, the mother humpback was able to free herself and swim away. Both appeared tired and distressed after the incident, but were otherwise unhurt.
This sort of empathetic or helpful behavior is not uncommon amongst whales. Earlier this summer, a pair of humpback whales came to the rescue of a seal who was being pursued by orca whales. They’ve even saved humans from drowning. And in one fascinating incident from 2013, a group of sperm whales adopted a dolphin with a spine deformity.


[BBC]
Following what was likely the largest evacuation in Florida’s history, winds from Hurricane Matthew reaching 70 miles per hour slammed the state early Friday morning, leaving about 179,980 without electricity. Having claimed over 300 lives in Haiti alone, Matthew is already the deadliest storm system to hit the region in almost a decade.

“This is serious,” warned Florida Governor Rick Scott just hours before the hurricane arrived. “If you need to evacuate and you haven’t, evacuate. This storm will kill you. Time is running out. We don’t have that much time left.”


More than 1.5 million people across the state were ordered to leave their homes due to the hurricane and up to a million more are expected to lose power in its wake. The total human and economic impact of Matthew has been much harder to anticipate, but is feared to be grave.
More than two million people in coastal Florida, Georgia, and South Carolina are being told to flee …
In an advisory to Florida’s eastern counties, the National Weather Service warned of “life-threatening wind” with potentially devastating effects, including “structural damage to sturdy buildings,” “complete roof and wall failures” and “complete destruction of mobile homes.”


“Locations may be uninhabitable for weeks or months,” said the NWS.
UPDATE 3:15 A.M.: According to the NWS, Matthew has slightly weakened while approaching Florida and is now a Category 3 hurricane.

Update 10/7/2016 (9:03am ET): More than 300,000 people in Central Florida have experienced power outages since last night. The area is experiencing flooding, damage from debris, and tree wreckage. The good news is that the violent wind storm has weakened to a Category 3 hurricane overnight and probably won’t make landfall, according to the National Weather Service. At about 7 a.m. ET, Hurricane Matthew sat just outside Florida’s east coast, battering Cape Canaveral with winds as high as 107 mph. Overall, the conditions have been slightly weaker than what forecasters were prepared for.
A popular fertility treatment introduced in the early 1990s has been linked to low sperm counts in men born from the procedure. Scientists aren’t entirely sure why this is happening, but it’s entirely possible that fathers are passing their fertility issues down to the next generation.
A new study published in Human Reproduction has linked intracytoplasmic sperm injection (ICSI) to lower sperm counts and lower sperm quality in men conceived by the popular fertility treatment. This common type of IVF treatment is used to help couples in which the prospective father has some form of infertility, leading the study’s authors to suspect a genetic link—though that has yet to be proven. It’s another case where correlation is not necessarily causation.


“These findings are not unexpected,” said André Van Steirteghem, a consultant at the University Hospital in Brussels and a co-developer of the treatment. “Before ICSI was carried out, prospective parents were informed that it may well be that their sons may have impaired sperm and semen like their fathers.” But as Steirteghem explained in a release, this information was not necessarily a deal breaker because many parents saw ICSI as a solution for their future sons.


The first person to be conceived via ICSI happened in 1992, so it hasn’t been possible to study men born from the procedure until now. During ICSI, doctors take sperm from the father and inject it directly into the mother’s egg. The fertilized egg is then placed in her womb. Many men who opt for ICSI have defective sperm, so doctors have to choose the best candidates from what’s available.
For the new study, 54 men conceived by the procedure between the ages of 18 to 22 had their sperm tested. The results were discouraging, to say the least. These men had nearly half the sperm concentrations found in naturally conceived men of roughly the same age, and a two-fold lower count of motile sperm (i.e. sperm that swim well). The men were also four times more likely to have sperm counts below levels deemed normal by the World Health Organization.


The researchers say that genetic factors may be responsible, but they’re not ruling out other possibilities. They say the results highlight the need to perform more follow-up studies on children conceived by assisted reproduction.
“For instance, paired analysis of samples from fathers and sons should be carried out, and we need to look at larger numbers of offspring,” said Van Steirteghem. “[H]ealth authorities and funding agencies should provide the means to answer questions concerning the effects of genetics, mode of conception, fetal growth patterns and birth weights on the fertility of ICSI men.”
As previously noted, ICSI and other techniques could conceivably be used to help individuals born via this technique to produce their own children. If genetics is eventually implicated, that would be insufficient reason to withhold the practice from men with severe fertility issues. What’s more, telling a man he can’t have children because he’s somehow genetically deficient  is basically eugenics. And with the eventual advent of genetic engineering, we’ll just eliminate heritable male infertility altogether.


[Human Reproduction]
Gallium is one of those rare metals that turns to a liquid somewhere above room temperature, allowing you to do fun experiments—like pouring it onto a vibrating speaker while playing music—without risking severe burns. Point a camera at the results and that fun science experiment suddenly feels like you’ve discovered a distant alien world bubbling to life out of the fabric of the cosmos.

[Let’s Melt This]
Plants employ a wide variety of tactics to lure pollinators, but an ornamental plant popularly known as Giant Ceropegia takes it to another level. Its flower smells like a honeybee under attack—an odor that freeloading, meal-seeking flies find absolutely irresistible.
Around four to six percent of all plants use deception to attract pollinating insects, but researchers have never seen a trick like this before. Writing in the latest edition of Current Biology, researchers from the University of Salzburg in Austria and the University of Bayreuth in Germany describe the unique strategy employed by the Giant Ceropegia, a plant with an umbrella-like flower that it uses to temporarily imprison pollinating insects.
Evolutionary biologist and entomologist Stefan Dötterl and his colleagues show that the trap flower on the Giant Ceropegia smells like a bee under attack. But why, you ask, would a flower want to emit such a distinctive scent? Well, it turns out that this particular aroma attracts parasitic flies—and it tricks them into pollinating the flower. The flies are drawn to the smell because they like to feast on the remains of honeybees who have been killed by a spider or a predatory insect.


The Giant Ceropegia has evolved an ingenious way to attract and temporarily capture a bug that thinks it’s there to steal some food. When an unwary fly ventures inside the flower, the trap closes shut, enclosing the fly inside. The fly struggles for a bit, pollinating the plant in the process. Eventually, the flower opens up and the fly is free to move on.
“Flies are attracted to the flowers, expecting a meal, but instead of finding an attacked honeybee they are temporarily trapped in the non-rewarding flowers [there’s no food inside!] and misused as pollinators,” explains Dötterl in a release. The researchers say it’s the first example of a plant that achieves pollination by pretending to smell like a carnivorous animal’s dinner.
The researchers made the discovery while trying to figure out how the flies, a species known as Desmometopa, were so good at finding honeybees so soon after a spider attack. While observing one such encounter, study co-authors Annemarie Heiduk and Ulrich Meve from the University of Bayreuth noticed that the bees released a shot of venom. This complex compound contains “alarm” pheromones that call and attract nest mates for help. Flies have learned to recognize this smell, and react accordingly.


Studies done in the lab show that the Giant Ceropegia’s flower smells almost exactly like the compounds excreted by bees who are under attack. So this plant, through the extraordinary powers of Darwinian natural selection, has evolved a highly specialized technique for attracting flies and boosting its reproductive potential. Looking ahead, the researchers are hoping to see if other plants employ a similar strategy.
[Current Biology]
Introducing the LudusScope, a 3D-printed, open-sourced system that lets you control and play games with living microbes on your smartphone. Tormenting single-celled organisms has never been so much fun.
LudusScope was developed by Stanford engineer Ingmar Riedel-Kruse, and he envisioned it as a new way of interacting and learning about common microbes. It’s meant for use in educational settings, and teachers can easily 3D print their own LuduScope using plans downloaded from the internet. Students can assemble their own device with very little help required from their teachers.

“Many subject areas like engineering or programming have neat toys that get kids into it, but microbiology does not have that to the same degree,” noted Riedel-Kruse in a release. “The initial idea for this project was to play games with living cells on your phone. And then it developed much beyond that to enable self-driven inquiry, measurement and building your own instrument.”
The system consists of a platform for a microscope slide, and a cell phone holder with a microscope eyepiece that’s positioned up top. Riedel-Kruse’s microbe of choice is Euglena, a tiny single-celled organism that’s attracted to light. Each slide is surrounded by four LEDs, each of which can be controlled by a joystick (instructions on how to assemble the circuit that connects the joystick to the LEDs are also provided).


Once assembled, students can use the LuduScope in any number of ways. Most simply, kids can just watch their Euglena move around as they trigger the different light sources.
But this device can do much more. Riedel-Kruse and his colleagues put together a software program that can run on a mobile phone and overlay on top of the image of the cells. Some of the programs provided are purely educational, allowing students to measure the microbes and record observations of their behavior.

But the games are what make the LudusScope so interesting. Students can target a particular Euglena and try to control its movements using the LEDs. Kids can use the microbes to play soccer (above), or move it around in a Pac-Man-like maze (below). The software includes a number of other activities and games.

For those worried about the welfare of the microbes, there’s probably not a lot to be concerned about. These simple organisms aren’t likely capable of experiencing anything approximating pain or frustration; they’re basically script-driven automatons with photophilic tendencies.


The device has already been tested by some teachers and students, and the researchers are now working to improve and expand the system after receiving feedback. Teachers who are interested  can use the open source information contained within the paper, which can be found at PLOS One.
[PLOS One]
In an open letter to investors on Wednesday, Theranos founder Elizabeth Holmes announced that the company was shuttering all of its labs and wellness centers, “impacting” around 340 employees—presumably by putting them out of work.
“We are profoundly grateful to these team members, many of whom have devoted years to Theranos and our mission, for their commitment to our company and our guests,” wrote the CEO of the beleaguered blood-testing startup.
It’s been almost a month since we last heard from beleaguered blood-testing startup Theranos, which …
Unfortunately for those devoted team members, federal authorities banned Holmes from operating a lab for two years this summer due to allegedly unsafe practices under her leadership. Theranos, given a choice to keep either its laboratories or its founder, evidently picked the latter.


In Wednesday’s letter, Holmes said that the company will now focus on developing its new miniLab device, a move that  allows her to remain at Theranos if the sanctions (which are currently being appealed) are upheld.
That side of the business, however, has its own problems: Last month, Theranos announced it was withdrawing an emergency application for a miniLab Zika test after the FDA discovered evidence of improper patient safeguards.
“After many months spent assessing our strengths and addressing our weaknesses, we have moved to structure our company around the model best aligned with our core values and mission,” wrote Holmes. “I look forward to sharing more with you as we progress along the way.”


[Rebecca Robins]
Using the Chandra X-ray Observatory, astronomers have found evidence of a “wandering” black hole on the outskirts of a distant galaxy. It’s too far away to cause us any trouble, but the discovery of this homeless ball of gravitational despair affirms a long standing theory about the existence of such objects.
A massive black hole that’s more than 100,000 times the mass of our sun has been detected in the outer regions of a galaxy located about 4.5 billion light years from Earth.  Astronomers suspect that this “wandering” black hole was originally located at the core of a smaller galaxy, but it became dislodged during a merger with a larger one. Now homeless, it’s settled into the outer reaches of the usurping galaxy.
If you were going to travel close to a black hole in order to study it, which type should you…
Black holes—objects so heavy that not even light can escape them—come in a range of sizes. Stellar black holes measure about 10 miles across, and are up to 20 times heavier than  our sun. Massive black holes, or so-called intermediate black holes, are 100 to 100,000 times heavier than our sun. At the top of the scale are supermassive black holes, which have upper masses ranging between 100,000 to 10 billion times that of the sun.


Both intermediate black holes and supermassive black holes are parked at the center of their galaxies, but astronomers have theorized about the existence of “rogue” black holes—objects that have been jostled away from their galactic cores following a collision with a galaxy containing its own massive black hole. The stars, dust, and gas from the second galaxy would disperse through the first one—along with its now displaced black hole.
Scientist have spotted a few black holes over the years that could qualify as wanderers, but nothing terribly compelling, and nothing quite on the scale of this latest discovery. Writing in the Astrophysical Journal, astronomer Dacheng Lin and colleagues describe a massive black hole that’s located on the outskirts of a distant galaxy called GJ1417+52.
Black holes themselves may not be visible, but we can detect the damage they do in their immediate neighborhoods. In this case, a star wandered too close to the rogue black hole, ripping it to shreds. The gaseous debris produced by this unfortunate encounter generated a tremendous amount of X-rays, which scientists on Earth were able to pick up using NASA’s Chandra X-ray Observatory and ESA’s XMM-Newton X-ray observatory.


The extreme brightness of this object classifies it as a “hyper-luminous X-ray source,” and it features a mass about 100,000 times that of our sun. That’s 10 times brighter than the brightest X-ray source ever seen for a candidate wandering black hole. Dubbed XJ1417+52, the object measures a whopping 3.13 million light years from tip to tip. The astronomers speculate that the black hole  located within it originally belonged to a small galaxy that rammed into the larger GJ1417+52 galaxy.


At a distance of 4.5 billion years, this wandering black hole is nothing to worry about. But some scientists speculate that our very own Milky Way galaxy is home to hundreds of these massive objects, the remnants of early galaxy formation. None of these objects have ever been detected in our galaxy, but that doesn’t mean they’re not there. And even if they are, they’re probably not as big as the unusually heavy GJ1417+52.
[Astrophysical Journal]
The oldest human to have ever lived died at the age of 122—and that was nearly 20 years ago. A recent analysis of global demographic data suggests this may very well be the maximum age attainable by humans, and that it’s extremely unlikely anyone will ever live much beyond this advanced age. That is, unless we science the shit out of this problem. 
In a new study published in Nature, molecular geneticist Jan Vijg and his team from the Albert Einstein College of Medicine in the Bronx make the case that human lifespan has a natural limit, and that we’ll probably never exceed this maximum bound. It’s a surprising conclusion given the tremendous medical achievements we’ve made in the past 100 years, and the steady rise in life expectancy. But as this study points out, the benefits wrought by these interventions, and all the things we do to stay vibrant and healthy, only go so far. Our bodies, no matter what we do, eventually become worn out and expire.
No one has lived longer than Jeanne Calment, who died in 1997 at the age of 122 years and 164 days. Given the increasing number of people breaching the 100 year barrier, and considering the steady increases in life expectancy, scientists thought that her longevity record would be broken relatively quickly. This simply hasn’t happened. There’s a big difference, it would appear, between life expectancy—the average time a person is expected to live within a certain population—and lifespan, which describes the maximum age reached by a member of a particular species.


Vijg and his colleagues took a look at the Human Mortality Database, a publicly available research tool that provides global mortality and population statistics to researchers, students, and others interested in human longevity. The researchers discovered that jumps in survival rates reached a plateau around 1980. A follow-up analysis of data from the International Database on Longevity, which included demographic statistics from developed nations like the US, UK, France, and Japan, showed that the longest lived people haven’t been getting any older since the time of Calment’s death in 1997. Taken together, the researchers say this reveals a natural limit to longevity.
Models developed by the researchers show that the odds of anyone living much beyond this limit is slim. “Assuming there are 10,000 worlds like ours, then one individual will reach 125 years of age in a given year,” Vijg explained to Gizmodo. “The chance is 1 in 10,000, so it’s extremely remote.”


Sociologist and gerontologist S. Jay Olshansky from the University of Chicago agrees with these findings, saying many people are under the false belief that we can forever manufacture more survival time through medical technology.
“These researchers suggest that we will get diminishing returns from these efforts because we’re butting up against a limit,” Olshansky told Gizmodo. “Having said that, it doesn’t mean that further progress isn’t possible. To the contrary, there is still plenty of low hanging fruit available to extend life—this comes from reducing harmful behavioral risk factors such as smoking and obesity, and reducing disparities.” He cautions, however, that even these interventions won’t yield large gains in life expectancy.


Olshansky isn’t surprised by these findings, saying it’s something he and his colleagues predicted way back in 1990. But he does take issue with the concept of a “natural limit” to human lifespan. Vijg and his colleagues say this apparent limit is a fixed genetic trait that evolved under the direct force of natural selection, and that limited lifespans may be an evolutionary adaptation.
Since the time of Darwin, evolutionary biologists have wondered why the lifespans of different…
This controversial idea, called “programmed aging,” suggests that lifespans are genetically conditioned, and not wholly the result of gradual wear-and-tear. Take birds, for example. Some species live for two or three years, while others, like the albatross, can live for up to 50 years. The difference has to do with the way the lifespans of certain species are genetically controlled.


Writing in a Nature News and Views article, Olshansky says this is simply not possible:
Fixed genetic programs that directly cause ageing and death cannot exist as a direct product of evolution, because the end result would be death at an age beyond which almost every member of a species would ordinarily live. A genetic time bomb designed to kill us at older ages is equivalent to automobile manufacturers building in an explosive device that is set off only when a car reaches one million miles. Because most cars are never driven that far, such a device would be useless.
Olshansky believes that the “natural limit” can be breached, but probably not by any technology we have available today, and probably not even by curing major fatal diseases. “We will need to discover something fundamentally different that allows us to slow the biological process of aging in order to break through this barrier,” he told Gizmodo. “I’m optimistic this will happen in our lifetime.”


Another person who’s optimistic about extending human lifespans is biogerontologist Aubrey de Grey, the Chief Science Officer of the SENS Research Foundation, an organization dedicated to extending healthy human lifespan.
Responding to the question of how life extending interventions might alter this apparent limit, de Grey said, “They will obliterate it,” adding that the “limit exists because of the simple mathematical combination of three things, all related to the fact that aging is the accumulation of self-inflicted damage.”
The three things in question include the degree of damage inflicted onto the body when early life factors such as not smoking and good nutrition are in place, how rapidly the damage increases thereafter, and how much damage the body can withstand without ceasing to function. Modern medicine shows little prospect of being able to change these realities, de Grey says—the more damaged the body, the less it is capable of preventing more damage.


“But new medicine that we will have within the coming decades, and which SENS Research Foundation is racing to develop, will break that feedback loop entirely,” he told Gizmodo. “It will repair the damage, using various types of regenerative medicine, so that the ongoing creation of damage will no longer lead to the accelerated accumulation of that damage and the downstream pathologies that it causes.”
Biologists have successfully extended the life spans of some mice by as much as 70%, leading many…
The damage-repair therapies that de Grey is hoping to develop, plus all the other unknown medical interventions that await in the future, threaten to upset Vijg’s assumption about an upper limit to human lifespan. Future developments could include a dramatic reworking of human genetics using genome editing tools like CRISPR, and the introduction of artificial chromosomes to give us new ways of staving off age related diseases. Advances in molecular nanotechnology, cybernetics, and regenerative medicine could alter human biology even further.


But to be fair, this new Nature study is a normative analysis that assumes a kind of status quo as it pertains to the state of medical technologies. If de Grey and other proponents of radical life extension are correct, however, there’s no limit to how long future humans could live. He predicts that humans will eventually reach a stage of “negligible senescence,” that is, a state in which aging is so slow that it’s imperceptible.
On this point, Olshanksy pumps the brakes.
“Contrary to the futurists claiming that radical life extension or immortality is at hand—a claim that has been made for most of the last two thousand years from alchemists to modern day anti-aging charlatans—it’s not likely we’re going to live much longer than the longest lived among us,” he said.


Olshansky says it’s important to keep our eye on the prize, which is to extend healthy life. Should we succeed, the resulting increases to our longevity will be a bonus, but only if the added survival time is healthy.
“We do need to recognize that there are limits, but this should in no way stop us from developing new ways to manufacture more healthy life,” he says. “Given that healthy life is one of the most precious commodities on earth, it’s hard to imagine that we’ll stop trying—and no one is suggesting that.”


And indeed, the authors of the new study say their research is highlighting the need for scientists to develop “interventions beyond improving health span,” adding that “there is no scientific reason why such efforts could not be successful.”


[Nature]
Ocean-dwelling creatures like whales, seals, and walruses don’t freeze in the icy waters thanks to their thick layers of insulating blubber. But how do scrawny sea otters stay warm? Their furry coats  trap air which also works as an insulator, and researchers at MIT think that approach could help keep humans warmer under water, too.
Wetsuits are certainly an effective way for humans to venture out into the ocean without freezing, but the thick neoprene material they rely on to trap body heat can also be restrictive, making it harder to move. And if you’ve ever watched otters diving in and out of the water at an aquarium, you know maneuverability definitely isn’t a problem for them.
After running countless tests and simulations to determine just how an otter or beaver’s fur coat is able to trap pockets of warm air when they enter the water, the team at MIT came up with a formula to calculate exactly how long and dense a layer of fur needs to be to effectively trap air based on the speed of a diver entering the water.

Using this knowledge, a radically new type of wetsuit could be created. Instead of a thick layer of insulating neoprene foam, a thinner, more flexible material, covered in millions of tiny artificial hairs, could be worn making it easier for divers, or surfers, to move around in the water. Would they look like furry monsters as they dove in and out of the water? Yes, they would. But they’d be warm, without feeling like they’ve been wrapped in a bulky, soaking wet heating blanket.


[MIT News]
The 2016 Nobel Prize for Chemistry has been awarded to a trio of scientists for their pioneering work in developing molecular machines. These gadgets measure just a thousandth of a human hair in width, and they’re poised to revolutionize everything from manufacturing and materials to medicine and the functioning of the human body.
The winners of this year’s prize are Jean-Pierre Sauvage from the University of Strasbourg, France, Sir J. Fraser Stoddart from Northwestern University in Illinois, and Bernard L. Feringa from the University of Groningen in the Netherlands.
As a science, molecular nanotechnology is still in its infancy, but by awarding the Nobel Prize to these three scientists, the Royal Swedish Academy of Sciences is acknowledging the technology’s huge potential.


In his historic 1959 lecture, “There’s Plenty of Room at the Bottom,” physicist Richard Feynman introduced the world to the concept of nanotechnology. He envisioned a world where we could directly manipulate individual atoms, arranging and rearranging them into useful shapes and configurations. The concept was given an added boost in 1986 with the publication of K. Eric Drexler’s seminal book, Engines of Creation: The Coming Era of Nanotechnology. Drexler’s ideas sent shockwaves through the chemistry world, with his super-futuristic ideas of smart materials that change shape, microscopic machines that produce and deliver medicines right inside the body, and rockets built from a single seed.
Researchers from the University of California have developed acid-fueled micro-machines capable of…
But theory is one thing. Actually demonstrating feasibility is entirely another. And it’s at this critical nexus point where the work of Sauvage, Stoddart, and Feringa is being acknowledged. All three are being honored for developing molecules with controllable movements, and for creating tiny devices that can perform a task when energy is added.


Jean-Pierre Sauvage took the first major step in 1983, when he linked two ring-shaped molecules to form a chain, called a “catenane.” Typically, molecules are connected by strong covalent bonds in which atoms share electrons, but Sauvage’s chain was linked by a flexible mechanical bond. This interlocked ring sets the stage for molecular machines that are constructed from freely moving parts that can move relative to one another.
Eight year later, Fraser Stoddart developed the “rotaxane,” which he did by threading a molecular ring onto a thin molecular axle, which was able to move along the axle. His pint-sized contraption inspired further breakthroughs in nanotechnology, including a molecular elevator, a molecular muscle, and a molecule-based computer chip.
In 1999, Bernard Feringa developed a molecular rotor blade that spun continuously in the same direction, making it the world’s first molecular motor. In one experiment, he rotated a glass cylinder that was 10,000 times larger than the motor itself. Feringa is also the inventor of the nanocar—a vehicle made from a single molecule.


These breakthroughs have inspired the development of increasingly sophisticated molecular machines, including “nanofish” that swim through bloodstreams, atom-sized data storage, and cyborg sperm, to name a few. Some experts think that nanotechnology will unleash a second Industrial Revolution, which will run alongside advances in robotics, mass automation, and artificial intelligence.
As we head deeper into the 21st century, we're starting to catch a glimpse of the fantastic…
On the downside, nanotechnology holds tremendous destructive potential, possibly on the same scale as artificial superintelligence. It could be weaponized, or run amok in an accidental grey goo scenario. Regardless, with the 2016 Nobel Awards, it’s clear that nanotechnology has finally arrived.


[RSAS]
To help understand just how destructive earthquakes can be, researchers could spend years examining the aftermath. But displaced residents need to begin cleanup, and return to their homes, as soon as possible. So researchers at Brigham Young University came up with a way to preserve the destruction caused by an earthquake so it can be studied indefinitely.
Immediately after a magnitude 6.2 earthquake hit central Italy earlier this year, a team of civil engineers and professors from Brigham Young University and the Geotechnical Extreme Events Reconnaissance Association—or GEER, for short—visited the sites to document the destruction, including how ancient and modern structures were affected, before cleanup efforts got underway.


But instead of snapping a few photos, the team used a camera-equipped drone to capture over 50-gigabytes of high-res aerial footage. This data was then used to generate 3D interactive models of the affected areas which could be studied, thousands of miles away, while cleanup efforts continued in Italy.

The use of a drone allowed researchers to not only study areas that were far too dangerous and unstable to access on foot, it also allowed the destruction to be captured from multiple angles, facilitating the creation of the 3D models back in the United States. It also meant the researchers weren’t in the way of rescue and cleanup teams trying to assist the local residents as quickly as possible.
The BYU team has already completed a 3D model of one of the areas hardest hit by the earthquake, and posted the results online which can be studied right in a browser. Eventually the team hopes the data and models will give engineers a better idea of how to design structures that can better withstand the forces of an earthquake of this caliber. But to also better predict where landslides, and other devastating side effects of an earthquake, might occur, and maybe even prevent them from happening the next time the ground starts shaking


[Brigham Young University]
We tend to think of coral reefs as luminous, undersea jungles that pepper the shallow, scuba-friendly tropics. But deeper down, in a region about as bright as Pluto on a sunny day, there lie vast reef ecosystems unknown to science.
Richard Pyle, a zoologist at the Bishop Museum, has spent the last twenty years surveying one of these landscapes—the so-called “twilight zone” coral beds that encircle the Hawaiian archipelago at depths of 30 to 150 meters (100 to 500 feet), where light is perpetually dim. His extensive findings are summarized today in the journal Peer J, in the most comprehensive  study of low-light coral reefs ever conducted. And they reveal a world far stranger and more complex than we imagined.
Using a range of high-tech gadgets and vehicles—ROVs and submersibles, drop-down cameras and environmental sensors—Pyle and his colleagues  have documented vast, poorly-lit areas of complete coral cover, spanning tens of square kilometers at depths of 90 meters (300 feet) or more off the islands of Maui and Kaua’i. Interspersed alongside these reefs are thick green “meadows,”  home to dozens of species of never-before-described algae. Both corals and algae require sunlight for photosynthesis, leading Pyle to suspect they can only exist here due to the exceptional clarity of Hawaii’s waters.


One of the most intriguing discoveries to come out of Pyle’s survey is that mesophytic reefs are hotbeds for endemic fish—species found nowhere else on Earth. While only 17 percent of fish species in Hawaii’s shallow reefs are unique to the archipelago, that number jumps to over 50 percent when you plunge below 70 meters.
“The extent of fish endemism on these deep coral reefs, particularly in the Northwestern Hawaiian Islands, is astonishing,” study co-author Randall Kosaki said in a statement. “We were able to document the highest rates of endemism of any marine environment on Earth.”


One theory is that these reefs represent a refuge, where numerous lineages have have survived for millions of years even as ice ages rework Earths’ surface over and over.
Perhaps most importantly, the study highlights highlights just how little we know about life in Earth’s  dark biosphere—which is a problem, because we can’t easily protect what we don’t understand. Then again, a couple of enormous new marine national monuments is a great start.
[Peer J]
By combining archaeology with 3D computer modeling, European researchers have digitally reconstructed a house in Pompeii, showing how lavish and colorful these structures truly were before they were destroyed by a catastrophic volcanic eruption.
When we try to conjure images of the ancient city of Pompeii, we often think about the stark and tortured casts left over from one of Europe’s worst natural disasters. Over 1,000 people were killed when Mount Vesuvius erupted in 79 AD, destroying several Roman settlements. As a new 3D reconstruction from researchers at the University of Lind in Sweden reveals, this ancient civilization had an eye for architecture and interior design.

The reconstruction includes a large house that belonged to a wealthy man named Caecilius Lucundus.(Lund University)


From 2011 to 2012, Italian archaeologists excavated and scanned the remains of a well-preserved city district buried after the disaster. These findings were integrated with 3D modeling technology to show what life was like for the people of Pompeii just before the eruption.

The researchers managed to reveal floor surfaces, perform detailed studies of the building’s development over time, and investigate the remains of a tavern, a laundry, and a bakery. Other architectural discoveries included aqueducts, interior pools, intricately decorated alters, statues, and stunning skylights. Many of the original color schemes could also be inferred.


In one of the many gardens discovered , the researchers uncovered evidence of a lavish water fountain that was running at the time of the eruption—that it was still gushing when the rain of ash and pumice was falling over the city.
The reconstruction also shows the Pompeii Romans’ integration of plants and trees in their dwellings, and their masterful use of color (ancient Greeks had the same proclivity).


While watching this 3D reconstruction, it’s important to remember, however, that these decadent dwellings were the homes of Pompeii’s most affluent residents, and are not indicative of how most of Pompeii’s citizens—and slaves— actually lived. If anything, it’s like an ancient version of Lifestyles of the Rich and Famous.
[Lund University]
During a recent survey of trees in the Queen’s garden at the Palace of Holyroodhouse in Edinburgh, Scotland, botanists were shocked to discover the presence of two elms thought to be extinct for nearly a half century.
The two trees belong to a species known as the Wentworth elm, and scientists thought it had gone extinct last century on account of the Dutch elm disease epidemic.
Turns out they were wrong—but what a strange place for the last two remnants of this majestic breed to be located. It’s not as if these things are tiny saplings, or trees tucked away out of sight. They’re absolutely huge and are among the most photographed trees on the palace grounds.
“Such a discovery when the trees in question are just shy of 100 feet and in plain sight does sound rather odd,” admitted Max Max Coleman of the Royal Botanic Garden Edinburgh (RBGE) in a release. Coleman identified the specimens after they were flagged as being unusual during a recent tree survey. The trees have a weeping-like appearance, and feature large glossy leaves.
Speaking to the BBC, Coleman speculated that the oversight could be blamed on the fact that these trees were never common in the first place. “If you pull your tree book off the shelf to try and look them up, you won’t find Wentworth elm listed in the books,” he said. Coleman also believes that few people these days are able to identify sub-species of elms because of how rare they are. He says that somewhere between 25 to 75 million elms across the UK were lost in the 1970s on account of Dutch Elm Disease.


Coleman attributes the survival of these two trees to a conservation effort invoked nearly 40 years ago.
“It is very likely the only reason these rare elms have survived is because Edinburgh City Council has been surveying and removing diseased elms since the 1980s,” he said. “Without that work many more of the thousands of elms in Edinburgh would have been lost. The success of this program may be partly demonstrated in the way two rare trees have been preserved.”
The queen’s botanists are now trying to figure out where these elms came from, but a preliminary investigation suggests they were introduced by the RBGE during the late 19th century. More importantly, they’re also looking into ways to preserve and propagate these last two remaining specimens.


[RBGE, BBC]
NASA’s Curiosity rover has completed its survey of “Murray Buttes,” and is now set to venture even higher along the slopes of Mount Sharp. The intrepid rover took the opportunity to snap a selfie as it proudly stood in front of some rather dramatic Martian features.
This striking image, taken on September 17, 2016, is actually a composite of 60 individual pictures taken by the rover’s Mars Hand Lens Imager (MAHLI). The camera and the arm are not included in the composite, which is why it looks as though a Martian inhabitant took the time to snap a pic of the four-wheeled exploratory vehicle.


The dark mesa in the background is called “M12,” and upper Mount Sharp can be seen at the top right. M12 stands about 23 feet (7 meters) above the base of the sloping rocks seen just behind the rover. For the past several weeks, Curiosity has been drilling and collecting rock powder samples in the region. Many of the pictures taken during this phase of the mission have been some of the best we’ve ever seen, revealing intricate eroded rock formations.
Click here to download wallpaper versions of the top pic.
NASA’s Curiosity rover is currently exploring the “Murray Buttes” region of lower Mount Sharp,…
With the Murray Buttes region conquered, NASA scientists have set their sights to a destination that’ll require the rover to do some further climbing. Curiosity is scheduled to make a 1.5-mile (2.5-km) uphill trek where it will explore a ridge rich in iron-oxide-rich hematite. Beyond that, the rover will investigate an exposure of clay-rich bedrock.
Both of these areas likely originated from different environmental conditions, but the mission scientists are eager to see if either of them might have once hosted a habitable environment; both hematite and clay typically form in soggy conditions.


“We continue to reach higher and younger layers on Mount Sharp,” noted Curiosity Project Scientist Ashwin Vasavada in an agency release. “Even after four years of exploring near and on the mountain, it still has the potential to completely surprise us.”

In addition to the selfie, NASA has also released a stunning 360-degree interactive panorama. Using your mouse, you can manually steer Curiosity’s camera and investigate the barren Martian landscape.
[NASA Jet Propulsion Laboratory]
The extremely dangerous Hurricane Matthew continues to barrel north, with the center of the storm expected to approach southwestern Haiti by later today. The National Hurricane Center’s latest bulletin calls Matthew “life threatening,” and forecasters are making dire predictions about the how much damage Caribbean nations might suffer.
Hurricane Matthew intensified rapidly on Friday, reaching Category 3, then 4, then 5 status in a matter of hours, and becoming the strongest Atlantic tropical storm since 2007. The hurricane has since cooled back off to a Category 4, which is to say, still a very dangerous cyclone packing 140 mph (220 kph) sustained winds with even stronger gusts. Parts of Jamaica are already being swamped by the storm, which was centered some 205 miles (330 km) south of Kingston as of 11 am ET.


Given Matthew’s current speed and track—moving northward at approximately 6 mph (9 kph)—tropical storm conditions are expected to reach Haiti by the afternoon, with full-on hurricane weather unleashing a torrent over the southwest coast later tonight. The storm is then predicted to gain speed, approaching eastern Cuba late tomorrow and the Bahamas by Tuesday night or Wednesday morning. While some fluctuations in intensity may occur, the NHC advises that Matthew will likely remain a powerful, Category 4 hurricane through mid-week.
Matthew’s impact on the Caribbean is looking more severe by the hour, particularly in Haiti and the southwest Dominican Republic, where as much as 40 inches of rainfall could trigger “life threatening flash floods and mudslides.” Rip-roaring winds and “large and destructive waves” will add to the danger, especially along the southern coasts and Haiti and Cuba, where water levels could swell 11 feet above the high tide line.


“It’s undoubtedly Haiti,” Weather Underground meteorologist Jeff Masters told Gizmodo when asked which nations are going to see the worst impacts. According to Masters, Haiti is particularly vulnerable due to environmental degradation, which has left the land stripped of trees and extremely prone to erosion. “The risk is Haiti is also greater due to poverty—you’ve got 50,000 people who have been living outdoors [since the 2010 earthquake].” he said.
The Bahamas are expected to get hammered hard by mid-week, with storm surges of up to 15 feet predicted in the latest NHC forecast. Impacts on the United States remain highly uncertain, but according to Masters, Florida, North Carolina, and New England could all see heavy rainfall. “Right now, the greatest risk is for North Carolina, but that could change,” he said. “The only thing we’re sure of as far as the US goes is that we’ll see a lot of pounding waves hitting the entire east coast.”
In the Caribbean, governments and international aid organizations are scrambling to make last-minute preparations. USA Today reports that the Haitian Civil Protection agency has opened 576 temporary shelters, while the US Agency for International Development has deployed disaster response teams to both Haiti and Jamaica. But with storm’s outer bands already drenching Jamaica, the south coast of Haiti and the Dominican Republic, time is running out. “Preparations to protect life and property should be rushed to completion,” the NHC said.
[NBC, USA Today, Weather Underground]
Brain-training programs like the ones offered by Luminosity and LearningRx claim to boost intelligence and even offset the effects of aging. A re-evaluation of the existing scientific literature on the matter shows these claims are complete bullshit.
A new study published in Psychological Science in the Public Interest concludes that brain-training games don’t work as advertized, a finding that could make life more difficult for companies that develop such programs. Earlier this year, the Federal Trade Commission fined Luminosity nearly $2 million for making false claims about the effectiveness of its product, and for failing to produce supporting science. This latest study represents another serious setback for the company and others with similar offerings.
Lumosity, which created a brain game powerhouse by telling people it could make them smarter, is…
Back in 2014, a consensus statement published by more than 70 scientists claimed that brain games “ do not provide a scientifically grounded way to improve cognitive functioning or to stave off cognitive decline.” Several months later, a group of 133 scientists put out their own statement, claiming that the scientific literature is filled with examples showing the benefits of brain training for a variety of cognitive tasks and everyday activities.


As University of Illinois at Urbana-Champaign psychology professor Daniel Simons and his fellow researchers rightfully asked in the preface of the new study, “How could two teams of scientists examine the same literature and come to conflicting ‘consensus’ views about the effectiveness of brain training?”
To find out what’s going on, the researchers re-investigated the existing literature, pulling up over 130 published, peer-reviewed, scientific studies that are typically cited by brain-training companies. The researchers went through each paper, scrutinizing the evidence, and evaluating factors such as sample size and the presence of control groups. Very few of them passed these sniff tests.


“Based on our extensive review of the literature cited by brain-training companies in support of their claims, coupled with our review of related brain-training literatures that are not currently associated with a company or product, there does not yet appear to be sufficient evidence to justify the claim that brain training is an effective tool for enhancing real-world cognition,” conclude the authors in the study.
Not surprisingly, brain-training can improve performance on the particular task or puzzle that’s being trained for. But there was very little evidence to show that these brain-games extend beyond that. These programs simply don’t improve everyday cognitive performance.


“It’s disappointing that the evidence isn’t stronger,” noted Simons in an NPR article. “It would be really nice if you could play some games and have it radically change your cognitive abilities. But the studies don’t show that on objectively measured real-world outcomes.”
Keep that in mind the next time you’re tempted to click on one those ubiquitous Luminosity ads.
[Psychological Science in the Public Interest via NPR]
This year’s Nobel Prize in Physiology or Medicine has been awarded to Japan’s Yoshinori Ohsumi for furthering our understanding of autophagy, the biological process wherein the body eats some of itself in order to survive.
Ohsumi won the esteemed prize for his discoveries on how cells break down and recycle biological waste that accumulates in the body. This built-in garbage disposal system keeps the body healthy, but sometimes mutations occur, resulting in diseases such as Parkinson’s and cancer. At a press conference held earlier today, Ohsumi said he was surprised to receive the Nobel Prize, but was “extremely honored.”


Autophagy sounds like something we’d rather avoid, but without it, our bodies wouldn’t be able to degrade and recycle old, worn-out, and diseased cellular components. The term literally translates from the Greek term “self eating,” and it’s a concept that first emerged in cellular biology back in the 1960s. But it wasn’t until the work of Ohsumi in the 1990s and his groundbreaking experiments with yeast cells that scientists truly began to understand the mechanisms that drive the process.
Even though we’re alive, our bodies are constantly undergoing an auto-decomposition process, which can be understood as a kind of self-cannibalism. At the same time, however, our bodies are also going through periods of rejuvenation and growth. Autophagy works as a natural defense that allows the body to survive this decomposition process, clearing away old junk and making room for new, fresh cells. Ohsumi discovered critical genes and fundamental biological processes that drive autophagy.


This remarkable recycling process provides fuel for energy and the building blocks required to create new cellular components. Without autophagy, we’d never be able to respond and survive to starvation and other types of stress. For example, autophagy can destroy invading bacteria and viruses that infiltrate cells. Cells also use autophagy to get rid of damaged proteins and organelles—a kind of quality control mechanism that helps us counteract the effects of aging. Autophagy also plays a critical role during the initial stages of life, contributing to embryonic growth and cell differentiation.


But sometimes the process goes haywire, particularly in the event of a genetic mutation. This can result in Parkinson’s disease, type 2 diabetes, and other age-related diseases. Ohsumi’s discoveries could lead to future treatments for some of these conditions.
Ohsumi was awarded eight million Swedish kronor (~$933,000) by Sweden’s Karolinska Institute for winning the prize. Prizes for physics, chemistry, and peace will be awarded later this week.
[Nobel Prize, BBC]
An ugly, dangerous storm is brewing out there. After a bout of rapid intensification last night, Hurricane Matthew has now achieved Category 3 status, packing 120 mph winds. It’s first major Caribbean hurricane since Sandy, and the strongest to develop in this particular region since 2008.
According to the National Hurricane Center, the storm is expected to maintain its strength and possibly intensify further through the weekend as it rumbles toward Jamaica, reaching Hispaniola and eastern Cuba by early next week. Matthew currently sits a little over 400 miles southeast of Kingston and just 85 miles north of Colombia, where a tropical storm warning is in effect.


A hurricane watch may be issued for Jamaica as early as later today.
Where exactly the storm is headed next, and whether the US will see any impacts, is not yet clear. There’s a decent chance Matthew could pass Florida to the east. Or it hit the peninsula dead on, or track west into the Gulf of Mexico.


Hurricane Matthew has meteorologists all in a tizzy on social media, remarking on its impressive strength and sudden, dramatic intensification. You can be sure they’ll be paying close attention to the storm’s development throughout the weekend, and if you live in a potentially affected area, you should, too.





Update 4:19 PM: Meteorologists are speculating that Matthew might have already intensified into a Category 4 storm, although we’ll have to wait for the next NWS update to be sure.

Update 5:21 PM: Hurricane Matthew has officially been upgraded to a Category 4 storm.


Update 8:25 PM: Matthew is now teetering on Category 5 status, according to the latest NWS advisory, which describes the storm as “extremely dangerous” with 150 mph winds. Tropical storm warnings and watches are in effect for portions of Colombia, Venezuela, and Haiti. A hurricane watch is in effect for Jamaica, with rainfall totals of 10 to 15 inches expected across the nation.

[Associated Press, Capital Weather Gang]
A new microscope developed at the Marine Biological Laboratory in Woods Hole, Massachusetts is allowing scientists track the position and orientation of individual molecules in living cells. It has the potential to reveal unknown aspects of molecular behavior, including those that turn cells into agents of disease.
Dubbed the “instantaneous fluorescence polarization” microscope, this new tool is being used to understand how tiny molecules move and assemble inside live cells, including human skin cells. It reveals how individual molecules—which measure just a billionth of a meter across—wiggle around a live cell, bind together to form larger cellular structures, and drive a cell’s biological functions.

Left: Fluorescent particles move along actin filaments, which allow cells to contract, in a human skin cell. Right: Pink lines show the orientation of the actin filaments. (Credit: Shalin Mehta and Tomomi Tani).


As described in a new paper in Proceedings of the National Academy of Sciences, scientists were able to determine the orientation of single molecules, and watch how an assembly of molecules came together to form a higher-order structure.
“Cells rely on a wide variety of molecular arrangements for their function,” lead author Shalin Mehta of the MBL and the University of Chicago told Gizmodo. “For example, muscles contract along a specific orientation because of the alignment of molecules. This new microscope and algorithms let scientists see how individual molecules align and interact with each other in live cells, even though these assemblies are much finer than the resolution limit of the light microscope.”
Meha and his team were able to catch a glimpse of the microscopic particles by using polarized light, a property of light that’s not visible to the human eye. After labeling DNA and actin molecules with fluorescence, the researchers tracked the movements of these tiny particles in living human skin cells.


This microscope will improve our understanding of cellular function, and potentially explain why cells sometimes go haywire, such as when they turn cancerous.


[Proceedings of the National Academy of Sciences]
Textbook illustrations and museum dioramas could soon be even more accurate in their depiction of the rich colors of long-extinct animals like dinosaurs. An international team of scientists  used advanced X-ray imaging techniques to map out elements related to pigmentation in modern birds of prey, which they will use to reconstruct the likely color patterns of fossil specimens.
Scientists at the Stanford Synchrotron Radiation Lightsource, SLAC National Accelerator Laboratory, and the United Kingdom’s Diamond Light Source teamed up with researchers from the University of Manchester on the experiments, described in a new paper in Scientific Reports.


The critical factor here is melanin, which determines variation in skin tone in humans and plays a big role in the coloring of mammals and birds. But little is known about its exact chemistry, according to lead author Nick Edwards of the University of Manchester, because the stuff is notoriously difficult to characterize via the usual methods.
That’s where the advanced X-ray imaging capabilities come in. “These techniques are non-destructive, so they don’t destroy the samples you are studying,” SLAC scientist and co-author Dimosthenis Sokaras told Gizmodo. “And with the rapid scan imaging we have developed at SLAC, we can analyze objects ranging from a few centimeters to tens of centimeters in size in a few hours.”
This latest work builds on earlier research from 2011, when SLAC scientists used x-ray imaging to examine the fossilized remains of two birds (Confuciusornis sanctus) that lived 120 million years ago. They found traces of the pigment eumelanin, responsible for the brown eyes and dark hair found in many modern species, including humans. It would have been one factor (among many) that determined the patterns of colors for those birds.


But eumelanin isn’t the only pigment of interest to the scientists. Pheomelanin also plays a role, notably in the production of reddish/yellow hues. At the time, the team just didn’t have sufficient data to conduct a similar examination focusing on pheomelanin.
Past studies have shown that pigmented tissues are richer in certain long-lived trace elements like zinc, calcium, and copper. So it made sense to target those elements in the new experiments. It also made sense to test this hypothesis in modern birds rather than ancient fossils, since the colors and pigmentation patterns are already known.
The team collected features from four species of birds of prey, shed naturally in sanctuaries: the Harris hawk, the red-tailed hawk, the kestrel, and the barn owl. Then they used X-ray fluorescent imaging to pinpoint concentrations of those key elements  in the feathers.
This in turn enabled researchers to distinguish between the two types of melanin in samples, because there were subtle differences in he concentrations between the two. For instance, the presence of zinc bonded to sulphur compounds indicates the feather has pheomelanin, so it should have a reddish/yellow hue.
Now the Manchester researchers plan to apply what they’ve learned about those trace metal concentrations to fossilized specimens like those ancient birds, or dinosaurs. Was T. Rex predominantly black or dark brown, or did its coloration fall more in the reddish/yellow range?


“A fundamental rule in geology is that the present is the key to the past,” geochemist and senior author Roy Wogelius said in a statement. “This work on modern animals  provides another chemical ‘key’ for helping us to accurately reconstruct the appearance of long extinct animals.”


[Scientific Reports]
An outbreak of E. coli that caused 10 million pounds of flour to be pulled from shelves is finally over. Yet, cases continue to pop up, and the CDC says it expects to see even more. Here’s why, even when the outbreak is over, the illness still isn’t.
The flour from General Mills was originally recalled back in May, after officials linked a string of E. coli cases dating back to the end of last year to the bags of flour. Even though they knew that the flour was somehow connected, it took almost another two months before the precise spot of contamination--a single factory in Kansas City, during only a week of production--was located. As of today, the CDC has finally declared the outbreak officially over.


However, even with the outbreak over, we’re still counting cases. There were at least 17 new cases after they found the source in the General Mills factory--and the agency says that new “illnesses are expected to continue for some time.”
The problem is really down to flour’s long shelf-life. A bag of flour can easily last in a cabinet for months. Compounding the problem is that people often transfer flour from the bag to a sturdier container and then toss the bag. It’s not uncommon for a canister to hold the remains of a couple different bags of flour or for people to be unsure about the brand of flour they even have.


This means that--even months after the initial outbreak--there are still lots of bags of E. coli-laced flour lurking in cabinets, just waiting to push the final illness tally of the outbreak a little bit higher. Perhaps now is a good time to check your own.
The evidence is mounting that our solar system is rife with oceans. Last week, scientists reported that Pluto could have an insanely deep liquid water swimming pool beneath its surface, and on Monday, NASA revealed new evidence for geyser activity on icy Europa. Now, another frozen moon is poised to join the club of outer space scuba retreats: Dione.
The fourth largest moon of Saturn, Dione was first imaged by the Voyager space probes in the 1980s, and has been viewed more recently by the Cassini spacecraft, during a series of five close flybys. It’s a beautiful, cratered ball of ice and rock, home to deep canyons and towering cliffs. While early flybys offered hints of geologic activity, there’s never been a smoking gun to prove Dione is alive inside—particularly when compared with its next-door neighbor (and orbital resonance partner) Enceladus, which is spewing seawater out of enormous geysers.
But a new study, which has been accepted for publication in Geophysical Research Letters, suggests we may have underestimated Dione. The moon could have a liquid water ocean beneath its surface, just like Enceladus. Using a geophysical model that depicts a crust ‘floating’ atop a mantle, Mikael Beuthe of the Royal Observatory of Belgium shows that gravity data collected by Cassini can be explained by a ~100 kilometer (62 mile)-thick shell of ice enveloping a 65 kilometer (40 mile)-deep ocean. Dione’s ocean, in turn, would smother a rocky core.


The first evidence for a subsurface ocean on Enceladus also came from gravity anomalies detected by Cassini, in a series of flybys between 2010 and 2012. As the spacecraft zipped past the moon, its velocity was slightly altered due to variations in Enceladus’ gravitational field. That change in velocity was measured from Earth via the Doppler effect—a shift in the radio frequency of Cassini’s transmissions.
In 2014, researchers at the Jet Propulsion Laboratory concluded that Cassini’s radio transmissions were hinting at a south polar sea beneath Enceladus’ icy shell. But a year later, independent measurements of Enceladus’ “libration”—a slight wobble as it orbits Saturn—revealed that the ocean is probably global.
“For Dione, we did a similar gravity-topography analysis as was done for Enceladus in 2014, but with improved techniques,” Beuthe told Gizmodo. “Thus that’s the best evidence we have now for a present-day ocean on Dione.”
According to Beuthe, we won’t be able to confirm Dione’s ocean with libration measurements the way we did for Enceladus, both because Dione is more spherical and because its crust is thicker. But there are other reasons to suspect this moon’s ocean is the real deal.


For one, gravity data also tells us Dione has a rocky core, spanning approximately 70 percent of its total radius. As radioactive elements decay within the core, they produce heat, melting the overlying ice. This almost certainly caused a subsurface ocean to form in Dione’s early history—which, by the way, might not have been too long ago.
“We don’t yet know whether the ocean froze or not afterwards,” Beuthe said. “But freezing would cause global expansion which should be seen in a certain type of cracks [which have] not been observed on the surface.”
Icy cliffs and smooth terrains also hint at recent geologic activity, which again, is difficult to explain if Dione is simply a ball of ice frozen to rock. Detection of geysers, similar to those seen on Enceladus and Europa, would really seal the deal for an ocean on Dione. But we haven’t seen geysers yet, and given the estimated thickness of Dione’s crust, Beuthe isn’t so sure we will.
To confirm the ocean, he says, “we need a new mission, which won’t happen for a long time.”
If Beuthe’s hunch about Dione is correct, the astrobiology implications are thrilling. It’s likely the ocean would have been around for the moon’s entire existence, long enough for microbial life to emerge under the right conditions. Another mind boggling thought: perhaps Dione and Enceladus have been exchanging alien microbes for hundreds of millions of years.


If one thing is becoming clear, it’s that oceans are not so unusual or special in our cosmic backyard. Does that mean life isn’t, either? We’ll need to keep exploring to find out.
Have you heard? The Black Moon rises tonight! But if you’re worried about catching this “rare” phenomenon don’t be—it’s actually not that special.
A Black Moon is not an actual astronomy term and there’s a couple different definitions floating around out there. The Black Moon that people are talking about now is defined as when two new moons—the phase of the moon where it appears invisible in Earth’s sky—happen in a single calendar month. This is the first time in over two years that’s happened.


While it’s technically true that it’s rare, it isn’t all that meaningful. The new moon pops up approximately every 29.5 days and September’s cluster of two is no exception. The two new moons in September aren’t really any closer together than any other new moons this year—it’s simply that the first one happened to fall on the very first day of September and the last one on the last day of September. The gap between the two is still practically identical to the gap between the July 4th and August 2nd new moons, or the coming November 29 and December 29 new moons, or any of the other 13 new moons this year.
Getting excited about two new moons popping up together in the month of September is a little like telling everyone to celebrate your birthday extra hard this year because it won’t fall on a Tuesday again for another two years. It’s not factually wrong that it’s rare, exactly, it’s just a very weird and not very meaningful coincidence of the calendar to get excited about.


Does that mean you shouldn’t bother to look up tonight? Not quite, a new moon is always a good opportunity to see the sky at its darkest without moonlight drowning out any constellations or planets you may want to catch a glimpse of. But, if you do happen to miss it or the sky is covered in clouds, don’t fret. The exact same opportunity will pop-up again literally about every 30 days, over and over and over again.
A stunning photograph taken from the ALMA observatory in Chile shows a young star surrounded by a large disk of gas and dust. Like our very own Milky Way, this protoplanetary disk exhibits a spiral structure—a feature that could solve a lingering mystery about how planets start to form.
This baby star is called Elias 2-27, and it’s located about 450 light-years from Earth. Those spiral arms that you see in the photo extend more than 6 billion miles (10 billion kilometers) away from the center of the system, which is further away than our sun is to the Kuiper Belt. Scientists have seen this galaxy-like feature before, but never at the circumstellar disk midplane—the region where planet formation takes place. The details of this unprecedented observation now appear in Science AAAS.
The presence of these spiral arms comes as a relief to astronomers. Planets form in the disks of gas and dust around newborn stars, but it’s not clear how these tiny particles grow into objects as large as Saturn and Jupiter. When the protoplanetary disk is smooth and even, objects can only grow in a cumulative fashion as particles continually collide and clump together. Trouble is, when these bodies get a couple of feet across in width, the drag created by the surrounding gas makes them migrate towards the star. This process only takes about 1,000 years, but larger timescales are required to build considerably bigger objects, and eventually planets.


Spiral arms could actually solve this conundrum. Their presence in the circumstellar disk—and the gravitational influence they exert—could disrupt the otherwise uniform composition of the disk. In regions with increased particle density, planet formation can move at a faster pace. The regions of uneven gravitational pull creates more confined space, making collisions of grains or rocks more likely. Writing in a press release, lead author Laura M. Pérez from the Max Planck Institute for Radio Astronomy described it this way:
The observed spirals in Elias 2-27 are the first direct evidence for the shocks of spiral density waves in a protoplanetary disk. They show that density instabilities are possible within the disk, which can eventually lead to strong disk inhomogeneities and further planet formation.
These sorts of instabilities aren’t specific to planet formation. Indeed, the best examples are the density waves in disk galaxies, which produces the spectacular arms of spiral galaxies.


The presence of these arms in a circumstellar disk may help explain the formation of planets, but the next mystery to solve is the presence of the spirals themselves, and how they come to exist. A possible explanation is that a planet had already formed, but that presents a chicken-and-egg scenario. As the authors of the study themselves admit, more observations are needed.
[Science AAAS]
After two years of science, the European Space Agency’s Rosetta mission ended today in a gentle crash-landing. But if you haven’t been tracking this spacecraft’s movements as obsessively as we have, you might be wracking your brain this morning trying to remember what the Rosetta mission was.
It’s okay—we’re here to help. To start, you should watch this adorable new send-off movie just released by the ESA, which gives you a sense of tone the mission team has tried to cultivate throughout Rosetta’s journey. (Cutesy and anthropomorphizing? Unabashedly so. Space is still innocent.)

You can follow it up with some of our extensive coverage—links below.


[ESA]
The historic Rosetta mission has finally come to an end. Over the past two years, the probe’s many instruments have scanned virtually every nook and cranny of this weirdly shaped rock, unleashing a treasure trove of new information about comets in general, and 67P/Churyumov–Gerasimenko in particular.
When Halley’s Comet paid us a visit back in 1986, the European Space Agency’s Giotto spacecraft was sent to explore the incoming ball of ice and dirt. By the time the mission was over, it became glaringly obvious that if we were ever going to learn anything about comets, we’re going to have to get a bit closer. Like, a lot closer.
So the ESA began to brainstorm a number of concepts, but the one that eventually came to fruition was the Rosetta Mission. Among the project’s many lofty goals, the mission planners sought to put a space probe in orbit around Comet 67P/Churyumov–Gerasimenko, or simply 67P, and then to have it fly alongside the celestial object as it made its way around the sun.


In addition to being equipped with a diverse set of measuring instruments and cameras, Rosetta was also supplied with the Philae Lander—a probe within a probe that was to land on the comet itself.
Launched on March 2, 2004, the Rosetta probe began to make its way towards the comet, passing by Mars and several large asteroids along the way. Several weeks after its launch, Rosetta used its dual imaging camera to take its first picture of the comet.


As the probe got closer, mission scientists were shocked to discover that the comet was...well...really weird. Known as a two-fold comet, it bore a startling resemblance to a rubber ducky. Follow-up studies showed that the comet merged from two separate objects.
Rosetta arrived at Comet 67P on August 6, 2014, and a flood of amazing pics soon followed. Taken from a distance of just 80 miles (130 kilometers), the first close-up images ever taken of a comet revealed boulders, craters, and steep cliffs—including an epic 3,280-foot cliff that would rival anything found on Earth.


On November 12, 2014, the Philae Lander began its slow descent towards the comet, but things didn’t go exactly as planned. Instead of securing itself to the surface with its harpoon-fired grappling hooks, Philae bounced several times, and eventually settled within a shadowed crevice.
Unable to draw solar energy from the sun, Philae went into hibernation mode. It awoke briefly a few months later, but was eventually declared dead. The lander was finally discovered on September 5, 2016.


It wasn’t exactly what the mission planners had hoped for, but the experience still managed to produce some meaningful data.
As Philae made its harrowing journey across the surface of the comet, its onboard sensors were busy collecting important data. Based on the lander’s initial contact with the comet, the researchers learned that the surface, at least at the landing site, was comprised of a soft, mushy layer about a foot thick.
Below this granular layer of regolith was a surprisingly solid layer of rock. The hardness of this layer may explain why only one of Philae’s legs was able to anchor itself to this lower surface level. Data from Philae suggests that the upper layers of the comet’s surface consist of dust that’s about 4-8 inches (10 to 20 cm) thick.


And Rosetta isn’t solid all the way through. It is filled with a surprising amount of dust. Studies of the comet’s gravitational pull suggests that its interior is not filled with caverns and tunnels, but is relatively consistent throughout.
As the data streamed in from Rosetta and Philae, scientists sought to make sense of it all. In late January 2015, a batch of preliminary findings were published in the journal Science. Among the many surprising discoveries, scientists observed ripples and dunes on the comet’s surface, which was completely unexpected given that the comet lacks an atmosphere (and therefore wind) and experiences very little gravity.
To explain the phenomenon, scientists speculated that jets of gas and dust were substituting for wind, and the particles were bound together by the van der Waals force (weak, short-ranged electrostatic forces between uncharged molecules) instead of gravity.


Mission scientists also began to paint a picture of the comet’s chemical composition. Using the Rosetta Orbiter Sensor for Ion and Neutral Analysis (ROSINA), the scientists detected water, carbon monoxide, carbon dioxide, ammonia, methane, and methanol. But the chemical cocktail didn’t stop there; ROSINA also sniffed out formaldehyde, hydrogen sulfide, hydrogen cyanide, sulfur dioxide, and carbon disulfide.


Taken together, it became clear that this comet really stinks. Here’s how a mission scientist described its foul stench:
The perfume of 67P/C-G is quite strong, with the odour of rotten eggs (hydrogen sulphide), horse stable (ammonia), and the pungent, suffocating odour of formaldehyde. This is mixed with the faint, bitter, almond-like aroma of hydrogen cyanide. Add some whiff of alcohol (methanol) to this mixture, paired with the vinegar-like aroma of sulphur dioxide and a hint of the sweet aromatic scent of carbon disulphide, and you arrive at the ‘perfume’ of our comet.
Not only does the comet have a smell, it apparently also has a characteristic noise. Here’s what the “singing” comet sounds like.


And then there were the mysterious balancing boulders.
Using the OSIRIS camera aboard Rosetta, scientists caught a glimpse of a strange formation of what appeared to be three boulders balanced in an extremely precarious position on the comet surface. Similar objects appear on Earth, the result of erosion or glacial measures, but how “this apparent balancing rock on Comet 67P/C-G was formed is not clear at this point,” noted OSIRIS Principal Investigator Holger Sierks soon after the discovery.


One theory is that cometary activity caused the boulders to move from one location to another, a process that would indicate evolving exo-geological processes on the comet. Another possibility is that the rocks weren’t actually balancing, and that the shadows were playing tricks with the researchers.
Thanks to Philae, we also learned that organic molecules exist on the comet—though not necessarily the kind that can deliver the chemical prerequisites for life. Organic molecules, i.e. molecules with one or more carbon atoms within it, are abundant in the cosmos, so this discovery wasn’t all that revealing. That said, a study put out earlier this month shows that complex organic molecules—the kind that form the basis of our biology—exists in the dust around the comet. This bolsters the argument that the basic building blocks of ice may have been delivered to Earth via icy space rocks.
Comets like 67P may have peppered Earth with the building blocks of life, but they likely didn’t bring water to our planet, according to scientists who analyzed the quantity and quality of water vapor streaming from the comet. Simply put, the kind of water found on the comet doesn’t match the kind of water found on Earth. The water on the comet features a different chemical composition. This suggests that asteroids, and not comets, were the primary delivery mechanism of water to our planet.
In the months that followed Rosetta’s arrival, the surface largely remained static, but things had changed by the midpoint of 2015. A number of land features disappeared, while others suddenly popped up from nowhere. The scientists weren’t sure about the cause, but they said it might have been the result of weak surface materials, which allowed for rapid erosion.


As the comet approached its perihelion (its closest approach to the sun before heading back towards the outer solar system), it started to come alive.
Images taken in August 2015 showed jets sprouting from the comet’s surface, spewing 60 to 260 tons of cometary dust with a single shot. For the first time ever, scientists had an opportunity to witness ice as it sublimated and exploded in the form of these dramatic dust-loaded jets. Meanwhile, chunks of ice ranging from a few feet to 130 feet (1-40 meters) in diameter were thrown into space. As the intense radiation from the sun bombarded the comet, fractures splintered across its tortured surface.
Follow up studies showed that these weird eruptions happened on the edge between one geographic feature and another, and at dawn when the sun re-appeared (the comet is clearly not a morning person).


Another surprising discovery was the presence of actual weather on the comet—an unexpected phenomenon given that this rock has no atmosphere to speak of. It’s driven by the comet’s intense day-night cycle. Ice patches on the surface transform into a cloud of water vapor when the sun rises, growing again when its “neck” (the thin mid-section of the comet connecting the two lobes) rotates into darkness. This vapor is lost to space, but the discovery suggests that the comet’s surface ice, some of which is just beneath the surface, is replenished from below, probably through fissures that expand during the day.
Another shock came in October 2015, when scientists detected traces of molecular oxygen, something that had never been seen before in a comet’s coma (the cloud of dust and gas surrounding a comet). This free-floating oxygen shouldn’t have been there, prompting the scientist to speculate that the comet has an interior source of molecular oxygen to replenish the diminishing molecules on the outside. In fact, the comet may be bleeding oxygen that’s older than the sun.


Even as Rosetta made its final death plunge onto the surface of the comet, mission scientists were busy collecting data. Its final resting place—named Ma’at after the ancient Egyptian goddess of harmony, balance, and order—is a region strewn with boulders and treacherous sinkholes. By exploring this area in detail, scientists hope to gain a better understanding of how comets form.
Rosetta may be dead, and the exploratory part of the mission may be over, but there’s still plenty of work to be done, and many mysteries yet to be solved.
At 6:39 am EDT today, a spacecraft weighing over 2,000 kilograms (4,400 pounds) with a wingspan half that of a Boeing 747 crashed gently into a comet’s surface, following 13 hours of free-fall. These, my friends, are the last, fleeting glimpses of Comet 67P that Rosetta managed to capture before its instruments went dead.
They’re also some of the best photos humans have ever taken of the surface of a comet, period. So enjoy them—because we won’t get another mission like this for a long time.
On Rosetta’s blog this morning, the ESA also posted a series of screenshots showing the signal from the spacecraft fading into white noise at around 7:19 am EDT (it takes 40 minutes for communications to travel from Comet 67P to the Earth). No doubt, these images will come in handy when Rosetta truthers start insisting the comet landing was faked.
Fare thee well, Rosetta. Your watch is over.


Did Donald Trump happen to lose one of his signature hairpieces in the Amazonian wilds of Peru? Wildlife photographer Jeff Cremer snapped this image of a caterpillar sporting the Republican candidate’s signature bright orange-yellow tufts of hair while on a scouting expedition in Peru.
“I was putting on my boots and someone said, ‘Hey, check out this caterpillar hanging out,’” Cremer recalled. “Sure enough, it was Donald Trump’s hair hanging on a branch.” He’s dubbed it the “Trumpapillar.”


The locals in the Peruvian Amazon call the critter ovejillo (“little sheep” in Spanish), but its full name is Megalopyge opercularis, or colloquially, the flannel moth caterpillar. It’s tiny, just 2.5 inches long, and its fluffy tufts can be red, white, or pink, as well as that Trump-tastic Day-Glo yellow.

But don’t let that adorable fluffy exterior fool you into thinking it’s harmless. The flannel moth caterpillar is actually venomous, and the hairs have very sharp, hollow spines, akin to a hypodermic needle, the better to puncture your skin and deliver a powerful dose of poisonous toxin. Yep, just like tarantulas, which at least have the decency to look scary. They can break off and lodge in your skin, too. The result, according to Cremer, is bright red welts and rather excruciating pain.


There’s some kind of metaphor in there, maybe.
[Live Science]
After a twelve year journey in space, the Rosetta spacecraft has less than 24 hours of life left before it crashes straight into the comet it has been orbiting. Today at 3 p.m., Rosetta team scientist Paul Weissman will be here taking your questions live.
Rosetta was originally launched by the ESA back in 2004. It was only after a journey of ten years that it finally arrived at Comet Churyumov–Gerasimenko and attempted a daring touchdown by the spacecraft’s accompanying lander, Philae. Some unexpected bounces meant that Philae was almost lost in space—but it managed to hang on and send back data before powering down. Now, as Rosetta prepares to join it on the surface of Comet 67P—this time, though, with a crash—ESA scientists are looking at the end of a more than decades-long mission that has revealed more about comets than perhaps any other mission.


In addition to his work as an interdisciplinary scientist for ESA’s Rosetta team, Weissman is also a senior scientist at the Planetary Science Institute in Pasadena, California, where he focuses on the evolution of comets. He’ll be joining us here live at 3 p.m. EDT to answer your questions. So start dropping your questions—about comets, the final images we’ll see as Rosetta prepares to die, the bouncing Philae lander and anything else you want to know—right now.
Update 3:20 p.m.: We’re having a little technical difficulty, but Paul is standing by and will be answering your questions shortly.


Update 5:10 p.m.: And the Q&A has now wrapped up. Thanks again to Paul for joining us and to everyone who asked a question.
The US Food and Drug Administration has approved Medtronic’s MiniMed 670G, a medical device that monitors a diabetic’s sugar levels, and then automatically injects the required dose of insulin.
This first-of-its kind automated insulin delivery system was approved for people over the age of 14 who have type 1 diabetes, and it’s poised to make life considerably easier for the millions of Americans who suffer from this condition.
People with type 1 diabetes can’t produce enough insulin, a hormone that regulates the amount of glucose, or sugar, in our blood. So they must replenish their insulin stock either with multiple daily injections, or by pumping insulin through a tiny catheter. Unlike these manual techniques, Medtronic’s MiniMed 670G is a “hybrid closed system,” meaning it autonomously tracks glucose levels about every five minutes or so, and then adjusts insulin levels with little or no input from the user.


“[MiniMed 670G] can provide people with type 1 diabetes greater freedom to live their lives without having to consistently and manually monitor baseline glucose levels and administer insulin,” the FDA’s Jeffrey Shuren said in a release.
MiniMed 670G includes a sensor that attaches to the body to measure glucose levels under the skin, an insulin pump that’s strapped to the body, and a catheter that delivers the insulin. The insulin delivery site needs to be changed about twice a week.
The device has been referred to as an “artificial pancreas,” but that’s probably not the best description. The device is not an internal organ, and it’s not completely autonomous. People with type 1 diabetes still need to track their carbohydrate intake, and then enter that information into the system.


The FDA approved Medtronic’s MiniMed 670G following a successful clinical trial that included 123 participants with type 1 diabetes. During the course of the three-month trial, no serious or adverse effects—such as diabetic ketoacidosis (DKA) or severe hypoglycemia (low glucose levels—were reported.
Medtronic, a medical tech firm based in Dublin, Ireland, says the device will be made available to the public in the spring of 2017. Looking ahead, the company plans to refine and further test the device in the hope that children under of the age of 14 can also use it.


[FDA, Medtronic]
File this under bad news for humanity’s climate ambitions: The dams and reservoirs we use to harness ‘clean’ hydroelectric power and irrigate our crops apparently emit carbon. A lot of it. All told, man-made reservoirs release roughly a gigaton of heat-trapping greenhouse gases each year. That’s more than the entire nation of Canada.
Scientists interested in quantifying humanity’s carbon footprint have been on the trail of man-made reservoirs since the early 2000s. Most studies to date have focused on a single type of reservoir—those used for electricity production, for instance—and just one or two greenhouse gases. Now, researchers at Washington State University have synthesized prior research to examine a wide variety of reservoirs and heat-trapping molecules. Their analysis, which appears next week in Bioscience, comes to a disturbing conclusion.


All told, reservoirs used for everything from power to flood control to irrigation account for roughly 1.3 percent of our global carbon footprint, much higher than previous estimates. The main culprit, according to the study, is methane.
“We had a sense that methane might be pretty important but we were surprised that it was as important as it was,” lead study author Bridget Deemer said in a statement. “It’s contributing right around 80 percent of the total global warming impact of all those gases from reservoirs.”


Methane is a potent greenhouse gas, with 84 times the global warming potential of CO2. The reason reservoirs are such hotbeds for the stuff has to do with how they are made. When carbon-rich soils are inundated, they quickly run out of oxygen, promoting the growth of microorganisms that respire CO2 and produce methane as a byproduct. This is the same reason swamps often smell like a giant fart: they are literally filled with billions of tiny methane factories.


“We found that the estimates of methane emissions per area of reservoir are about 25 percent higher than previously thought, which we think is significant given the global boom in dam construction, which is currently underway,” Deemer told the Washington Post.
In a sense, the timing of the discovery is fortuitous, given that world leaders are on the verge of ratifying a treaty that would begin the process of decarbonizing the global economy. With one more piece of the carbon budget accounted for, we can make better decisions about how to reduce our greenhouse footprint.
The solution, of course, will not be to abolish reservoirs, but to take their carbon emissions into consideration and make more aggressive cuts where we can. Clearly, the task ahead is going to be even more challenging than we thought.
[WSU News, Washington Post]
Regulators in the state of Illinois have suspended a Chicago doctor who allegedly gave patients vaccinations containing cat saliva and vodka.
The Chicago Tribune reports that the Illinois Department of Financial and Professional Regulation took the action against Dr. Ming Te Lin after hearing complaints from healthcare providers that children were being administered unapproved oral versions of childhood shots developed by the doctor.


Investigators who visited Lin’s office discovered a cluttered, unsterile office, and a “box filled with vials and tubes that [Lin] was using to make his own vaccinations.” Lin admitted to the investigators that he’s been making his own “alternative” vaccinations for over a decade—a revelation that must come as a shock to some parents. Children as young as a seven-day-old infant received the unapproved oral vaccines.
To create his custom brew, Lin added alcohol in the form of vodka. And for children with allergies, he would add cat saliva gathered by a cotton swab. Lin administered the modified vaccinations orally or in nasal form.


He also used a device called the Wavefront 2000 to detoxify vaccinations from mercury. The contraption is based entirely on pseudoscientific principles. It’s described by the manufacturer as, “an electronic device that detects the unique, subtle electro-magnetic frequency information of any substance placed in its input well and imprints the signal into a carrier fluid placed in the output well. The signal can be inverted to form an anti-allergen remedy.”


State officials are accusing Lin of signing state forms certifying that he had given children conventional, state-approved immunizations, and of failing to inform his patients of the risks associated with not following vaccine guidelines. Needless to say, none of the methods adopted by Lin are approved by the US Food and Drug Administration. Line will attend a hearing before the Medical Disciplinary Board on October 11 in Chicago.
It’s not immediately clear if Lin was a traditional Chinese medicine practitioner or a homeopath (Lin is not returning anyone’s calls at the moment). As noted at Doubtful News, he graduated from the Medical College of Taiwan, and was certified by the American Board of Pediatrics and the American Board of Allergy and Immunology. What’s more, he’s got some glowing reviews at Vitals.com, but clearly from patients who subscribe to the doctor’s homeopathic “natural” remedies.
For some of Lins’ patients, these recent allegations may come as a shock—but not necessarily because they felt he was doing anything wrong.
[Chicago Tribune]
This week Elon Musk announced plans to plans to build a “self-sustaining city” on Mars. It’s a thrilling notion, although folks were quick to point out not just the technical challenges of accomplishing such a feat, but also the tremendous cost. Even living on the Moon for a year would be pretty pricey, as a new video makes clear.
Produced by Wendover Productions, the narrator runs through an itemized list of everything you’d need to send just four astronauts to the Moon for the year: notably, transportation there and back, lunar landers, housing, greenhouses to grow food (let’s hope those astronauts love sweet potatoes), water, and power. The grand total: $36 billion, or $98 million per day.

Granted, that’s assuming old Saturn V rockets. If Space X and other commercial rocket companies keep making progress in developing reusable rockets (rather than blowing them up), that could bring the cost down substantially some day.


[Laughing Squid]
Dr. John Zhang of Manhattan’s New Hope Fertility Center has long performed miracles for fertility-challenged couples. In a typical year, his futuristic-looking clinic (its sleek all white-interior looks like something out of a 2001: A Space Odyssey-themed spa) oversees hundreds of births.
Zhang is responsible for creating the world’s first three-parent infant—a baby produced by combining a father’s sperm, a mother’s egg, and a donor egg.


The birth of the baby, formally announced this week in New Scientist, is a big deal in fertility circles. The technology Zhang employed to produce the three-parent baby not only provides a source of hope for couples looking to avoid passing deadly genetic disorders on to their offspring, but also, Zhang says, potentially ushers in an era in which more and more women in their 40s and 50s will be able to have their own biological children. Researchers additionally speculate the technology lays the groundwork for the possibility that same-sex male partners may one day be able to have biological children of their own.
The three-parent baby—a boy—was born at a Manhattan hospital in April to a couple who had worked for 20 years to start a family. The mother, from Jordan, is a carrier of Leigh Syndrome, which is likely to affect a baby’s developing nervous system. She and her husband lost two infants to the disorder, and miscarried four more, which is why she sought Zhang’s help.


New Scientist reports that a method of three-parent reproduction called “pronuclear transfer” is already approved in the UK:
[It] involves fertilising both the mother’s egg and a donor egg with the father’s sperm. Before the fertilised eggs start dividing into early-stage embryos, each nucleus is removed. The nucleus from the donor’s fertilised egg is discarded and replaced by that from the mother’s fertilised egg.
Because the couple is Muslim and didn’t want to destroy two embryos, Zhang and his team used a different method—they removed the cellular nucleus of the mother’s egg and inserted it into a disease-free donor egg which had already had its nucleus removed. Working in Mexico, the team then fertilized the new combination egg with the father’s sperm.


The procedure, Zhang said in an interview with Jezebel, essentially replaced the corrupted “egg white” of the birth mother with the healthy “egg white,” or mitochondria, of the egg donor, without altering the nucleus, or the “egg yolk” of the biological mother, which contains most of the genetic information responsible for determining a baby’s traits. According to New Scientist, five eggs were prepared using the new technology but only one was deemed suitable to fertilize.
“This is considered one of the latest and biggest breakthroughs in the IVF [in vitro fertilization] world,” Zhang told Jezebel. “The first breakthrough in the world of IVF was the development of IVF itself, the second was the development of embryo freezing, the third is PGD, or genetic testing of embryos (where embryos are biopsied prior to transfer to determine whether they are healthy). And number four is ICSI, which enhances the ability of sperm (particularly in older fathers) to fertilize an egg.”


“This is number five,” Zhang said of the three-parent baby. “The principle we are applying is very different.”
Zhang chose to perform the controversial procedure in Mexico because the U.S. doesn’t currently authorize such reproductive methods, having deemed them potentially unsafe. After a successful embryo transfer, the couple later returned to New York, where a beaming Zhang was on hand in the delivery room, when the baby was delivered by Caesarean section this spring. The baby is being monitored closely.
“We still have a long way to go to follow up with the patient closely to ensure the safety of the procedure,” he said. But so far there are no signs of illness.
The parents, Zhang says, are overwhelmed by the media attention that the birth of their son has created and Zhang says it is now his mission to protect the privacy of the family as best he can.


“This is a very neat technique and it’s amazing and we still can’t believe we made it,” he said.


Zhang says he shies away from using the term “three parent baby” to describe the newborn, arguing that the term, while he says is “sexy” to the media, perhaps places too much emphasis on the role of the egg donor.
“A parent is someone who educates and molds a child,” he continued. “It’s a matter of opinion, but I think it’s the two parents who are raising the child who should be called parents.”


Zhang had intended to wait until late October to announce news of the three-parent baby’s arrival at a meeting of the American Society for Reproductive Medicine in Salt Lake City, but on Tuesday, New Scientist broke news of Zhang’s paper which documented the birth.
Within hours, Zhang was inundated with media requests from around the world, ranging from Nature to the New York Post. Long after his office had closed Tuesday evening, Zhang—who went to medical school in China and has been pioneering IVF techniques for more than two decades—was fielding calls from the BBC as he struggled to go over patient charts.
Zhang says he is cautiously optimistic about this first “miracle” baby and what he says it could mean for infertile couples. He says it’s not inconceivable to think that three-parent babies could eventually become an offering at the nation’s leading IVF clinics.


But he says there is much more research and testing to do. The procedure won’t be regularly available to most families in the U.S. until it has undergone clinical trials to make sure it does not harm a pregnant woman and that a baby can be born safely.
Unsurprisingly, the procedure is attracting its fair share of controversy. Critics worry it continues the ongoing trend towards ‘designer’ babies, and pro-life advocates fear the procedure will result in the disposal of a growing number of fertilized embryos.
Zhang’s success is, of course, not without precedent: A U.S. based doctor, Jacques Cohen, developed a previous three-parent fertility method in the 1990s, according to the BBC, creating 17 babies using the technique. But some of the fetuses resulting from the technique were missing X chromosomes and at least one child showed signs of a development disorder, prompting the FDA to ask clinics to stop using the technique.


Still, Zhang’s development of the new three-parent-baby technology is exciting for fertility-challenged women, particularly those ages 35 and over. The leading cause of miscarriage among women of advanced maternal age is ‘aging’ eggs, in which the mitochondria is corrupted. But Zhang’s method—replacing a woman’s mitochondria with donor mitochondria—solves that problem, meaning more and more women in their 40s and 50s will potentially be able to have biological children of their own.
The new technology, as also previously mentioned, could also hold potential for same-sex couples hoping to reproduce. Using donor egg mitochondria, scientists have been able to produce offspring in mice, parented by two males, although it remains to be seen whether that can be replicated in humans.


How soon could we see the first three-parent baby produced by two male humans, with the help of a donor egg’s mitochondria?


Zhang won’t put a timeline on it. What he will say is this: “Whether it can happen with humans, you have to leave it to your imagination.”
Mary Pflum Peterson is a multi-Emmy-Award-winning producer who has spent years covering parenting and fertility stories. She is additionally the author of the New York Times bestselling memoir, White Dresses: A Memoir of Love and Secrets, Mothers and Daughter.
The United Nations just announced a date for its first ever mission to space—and it’s pretty soon.
The U.N. intends to send Sierra Nevada’s Dream Chaser spacecraft, which is currently still in its testing-phase, into a 2-week, low-Earth orbit flight in 2021. Sierra Nevada signed on to partner with the UN in June, but the target date for launch was announced yesterday during a session of the International Astronautical Congress—where Elon Musk also detailed his long-game for sending a whole bunch of humans to Mars.


Exactly what the mission will accomplish remains vague. The United Nations Office for Outer Space Affairs says that any member nation can submit a proposal for a possible payload for the flight, although it’s primarily geared towards countries with no space program of their own.
Before we get too excited about another spacecraft heading up, however, there’s still the big question of where the money to launch would come from. The countries whose payloads were selected would pay something for the flight. But UNOOSA also says it’s still looking for “major sponsors” who would be responsible for much of the overall mission cost, with no assurance that it will find them. If that money does come through, though, the first UN space mission will launch just five years from now.


[Motherboard, United Nations Office for Outer Space Affairs]
Typhoons are generally associated with mass destruction, but a Japanese engineer has developed a wind turbine that can harness the tremendous power of these storms and turn it into useful energy. If he’s right, a single typhoon could power Japan for 50 years.
Atsushi Shimizu is the inventor of the world’s first typhoon turbine—an extremely durable, eggbeater-shaped device that can not only withstand the awesome forces generated by a typhoon, it can convert all that power into useable energy. Shimizu’s calculations show that a sufficiently large array of his turbines could capture enough energy from a single typhoon to power Japan for 50 years.


Given that Japan is currently dealing with an energy shortage—a problem incited by the 2011 Fukushima disaster—this comes as a very welcome solution. As Shimizu told CNN, “Japan actually has a lot more wind power than it does solar power, it’s just not utilized.”
Shimizu is not wrong. Japan has already seen six typhoons this year. Shimizu, the founder of green tech firm Challenergy, believes that Japan has the potential to become “a superpower of wind.”
The typhoon turbine differs from conventional turbines in two important ways. It works on an omnidirectional axis that allows the machine to survive unpredictable wind patterns, and the speed of the blades can be adjusted to ensure they don’t spin out of control during a storm.


Tests of a prototype yielded 30 percent efficiency, which is 10 percent lower than propeller-based turbines. The difference, of course, is that Shimizu’s turbines can actually survive a storm. Back in 2013, Typhoon Usagi destroyed eight conventional turbines, while damaging eight.
A functional prototype was installed near Okinawa earlier this summer, and the next big step is to test the device under high-wind conditions. All that’s needed now is a typhoon.
It’s not immediately clear where all the incoming energy will be channeled, whether it be sent straight to the grid or stored in large batteries (Tesla’s large battery backup comes to mind). We’ve contacted the company to learn more.
[CNN]
Scientists have been working on materials that change shape for a while now. But as New Scientist points out, these metamorphoses usually require external stimuli to get going—until now. New research published in Nature Communications shows that some non-living substances can be made to transform all on their own.
The secret to these remarkably lifelike polymers is that they employ two different kinds of bonds—some don’t move at all while others break and rearrange themselves. This allows for variability in the shape, as well as the speed at which it morphs. And the transformations can either be one-way or fully reversible!


This flower is the most complex of the polymer creations the team of researchers made, and they had to employ a few tricks to make it look so lifelike. Rather than create a single convoluted structure, each petal was programmed individually to maintain the illusion of legitimate plant growth. The whole thing was also given a coating that dissolved in water, which acted as a sort of time release.
Who cares about a self-blooming plastic flower? The applications for this technology go well beyond fancy tricks. Mainly the shape-changing polymers are being considered for biomedical applications, like implants that would start off small when inserted and expand to their true size once inside a patient. Scientists working on the project are even finding workarounds to allow the polymer transformation to pause, accelerate, or decelerate.


[New Scientist]
Do you think you know what “healthy” food means? Then the FDA would like to hear from you.
The FDA just requested public input on the meaning of the word “healthy,” the first step towards a new definition. The agency first announced it would be revamping the term’s definition this summer.


The decision came after a scuffle with KIND granola bars where—after being told to remove the tag “healthy and tasty” from its bars—the food manufacturer asked to keep it, arguing it wasn’t nutritional information but a “corporate philosophy.” The FDA eventually agreed to let the company keep the tag but also said it had decided to update the definition of the term.
At the time, they told Gizmodo there was no real timeline for when the new definition would be issued. But, as of today, the move towards a new definition appears to be moving forward.


The current FDA definition describes “healthy” as “an implied nutrient content claim” that suggests the food is consistent with current dietary recommendations, particularly for fat and cholesterol. The problem is that still leaves the term pretty wide open for interpretation—and, as we’ve seen with the case of “natural” that can cause big problems.


After the FDA refused to define natural—under the premise that everything we eat has been at least a little processed—people went wild with the term, in both directions. A plain bucket of oats, with nothing added, was sued for being “unnatural,” while 7-Up, fruit snacks, and Cheetos all happily touted their own “natural” benefits to customers.
Last year, the FDA started collecting definitions of what “natural” means to the public—although no actual definition has yet come out from the agency nor has it actually said it plans to write one. The case of “healthy” is a little different, because it started out with a definition, and the FDA has promised from the beginning that the process is going to result in another one. The sooner we see clear definitions of both terms out, the less room there will be for food advertisers to try and create new definitions for themselves.
Endemic measles has officially been wiped out in the Americas. That means the only outbreaks that happen are those imported from abroad. It’s the first region in the world to achieve this certification, but the battle against measles is far from over. We’re looking at you, anti-vaxxers.
The historic announcement was made yesterday at a meeting held by the Pan American Health Organization (PAHO), a division of the World Health Organization (WHO). The Western Hemisphere’s last case of endemic measles happened back in 2002, but it took the PAHO 14 years to declare the Region of the Americas completely free of the disease. That‘s mostly due to poor communication between departments, the large number of unvaccinated migrants, and civil strife.


“This is a historic day for our region and indeed the world,” PAHO/WHO Director Carissa Etienne said in a statement. “It is proof of the remarkable success that can be achieved when countries work together in solidarity towards a common goal. It is the result of a commitment made more than two decades ago, in 1994, when the countries of the Americas pledged to end measles circulation by the turn of the 21st century.”
This historic milestone took a lot of work and coordination, including strong political commitments from member states and mass vaccination campaigns against measles, mumps, and rubella throughout the Americas. Measles is now the fifth vaccine-preventable disease to be wiped out from the Americas, joining smallpox, polio, rubella, and congenital rubella syndrome.


Prior to the introduction of mass vaccinations in 1980, measles caused nearly 2.6 million annual deaths worldwide. These days, about 96,000 people die each year from the highly contagious disease. Measles is transmitted by airborne droplets or by direct contact with bodily secretions, and symptoms include high fever, a body rash, stuffy nose, and reddened eyes. Children are particularly vulnerable.
"The Happiest Place On Earth" is ground zero for a recent measles outbreak centered in…
However, imported outbreaks still occur. Infected travelers bring the disease along with them on an all-too frequent basis, highlighting the need for constant vigilance. In recent years, the United States has experienced a batch of these highly localized outbreaks, including one in 2015 involving 189 people from 24 states. In the majority of these cases, the people who became infected were unvaccinated.


Measles can quickly spread when it reaches a community where significant numbers of people aren’t vaccinated. All of the cases in the United States were quickly contained, preventing the disease from becoming endemic in the country once more. Prior to the introduction of the measles vaccination in 1963, around three to four million cases of the disease were recorded in the United States each year.
But anti-vaxxers could destroy all of this work. A disease can only become endemic—that is, spread through a population without the need for an external source (like an infected traveler)—if most of the people in the population are vaccinated. It’s called herd immunity. According to the Oxford Vaccination Group, 19 out of 20 people, or 95 percent of the population, need to be vaccinated against measles to protect people who are not vaccinated.
The latest figures: Between January 1 and August 29 of this year, nearly 600 confirmed measles…
Unlike anti-vaxxers who voluntarily and irrationally choose to not get themselves or their children vaccinated, there are some people who can’t get vaccinated for health reasons and depend on herd immunity. That include those without fully functional immune systems, people undergoing chemotherapy, newborn babies, and the elderly, to name a few. Anti-vaxxers—and the growing number of unvaccinated children—pose a direct threat to these vulnerable groups.


As for the global battle to combat measles, that work is ongoing.
“We can not become complacent with this achievement but must rather protect it carefully,” said Etienne. “Measles still circulates widely in other parts of the world, and so we must be prepared to respond to imported cases. It is critical that we continue to maintain high vaccination coverage rates, and it is crucial that any suspected measles cases be immediately reported to the authorities for rapid follow-up.”
[PAHO WHO, CDC, NYT]
Just days before it was scheduled to open, a park in Rizhao, China, was severely damaged when the north slope of the mountain right next to it suddenly collapsed.
There were no casualties in the landslide which occurred earlier this month, but the facility’s new rock climbing facility was completely wiped out. Images taken after the rockslide show gigantic boulders strewn across a large section of Shandong Park, which is located in southeastern China.
After inspecting the site, local officials said the landslide was a natural phenomenon, and not the result of human activity. As Charles Liu reports in The Nanfang, local officials “did not answer questions as to why the park facilities are located so close to the mountain, or if any studies or investigations were conducted prior to the construction of the rock climbing facility.”
Geologist Dave Petley of the American Geophysical Union isn’t entirely convinced that the collapse was natural, pointing to extensive engineering work done around the area, and on the slope in particular. “The failure itself appears to have been structurally controlled,” writes Petley. “Note the very large boulder sizes.”
At a cost of 70 million yuan (~$10 million), and after two years of construction, the park was scheduled to open “later this month.” Thank goodness it happened prior to its opening, otherwise this story could have been far more catastrophic.


[The Nanfang via The Landslide Blog]
A team of European researchers put six highly-trained sniffer dogs to the test to see if they were any good at detecting lung cancer. The results were surprisingly bad, but the scientists say factors other than the canine sense of smell were responsible for the poor performance.
The new study, published in Journal of Breath Research, shows that dogs fare poorly when asked to sniff out lung cancer in actual screening situations—despite their uncanny ability to sniff out certain cancers. It’s not their sniffing skills that’s the problem, but canine tendencies—like distraction and boredom—that cause them to lose focus and make mistakes. Simply put, they’re not great at being clinicians.


There’s still good reason to believe that assistance dogs can be tremendously helpful in medical contexts. They’ve been used to detect low blood sugar levels in their diabetic owners, and warn of an impending hypoglycemia attack. Dogs have also displayed an uncanny ability to sniff out certain cancers, such as urological cancers and breast cancer, leading to early detection. But little research has been done to determine if they’re any good at detecting lung cancer, particularly in a real screening situation.
Hence the new study.


Researchers from Krems University Hospital and several other institutions recruited 122 volunteer patients. Twenty-nine had already been diagnosed with lung cancer (but hadn’t yet received any treatments) and 93 subjects showed no signs or symptoms of the disease. The six dogs were trained for six months beforehand, with a total of 150 training samples.


When it came time for the real test, the dogs were exposed to breath samples provided by the participants. This was done in a double-blind manner to eliminate any subjective bias. The dogs correctly detected 79 percent of the patients who actually had lung cancer, but when it came to those without lung cancer, the dogs correctly identified just 34 percent. That’s just not a good return rate, given the seriousness of the diagnosis.
“Our dogs made mistakes with both positive and negative samples, and I think that one important reason for the inferior results might be that a true double blind situation puts a lot of stress on the animals and their handlers,” said Klaus Hackner, a co-author of the study. “Success and regular rewards are important for every kind of sniffer detection work.”
Hackner believes this was a learning experience, and he hasn’t given up hope that dogs can someday be used to sniff out lung cancer. It’s just a matter of setting up effective protocols.
“This disparity is not likely to be a detection issue; dogs have been shown to have extremely sensitive noses as proven by their use in tracking, bomb detection, and search and rescue,” he said. “However, in contrast to analytical instruments, dogs are subject to boredom, limited attention span, fatigue, hunger, and external distraction.”


Still, this study points to the limitations of using dogs for such complex and psychologically-demanding tasks. It would probably be more practical to develop the much heralded “e-nose”—a sensor just as powerful as a dog’s extremely sensitive nose.
[Journal of Breath Research]
Elon Musk finally revealed his plans for a mission to Mars today. But a new set of images from SpaceX show the Interplanetary Transport System going even further in the solar system than the Red Planet.
As we speculated yesterday, the plans for the ITS do, indeed, go well beyond Mars. Musk confirmed an interest in traveling elsewhere in the solar system, especially to Europa, during his speech today—and SpaceX confirmed in a tweet and with this new artwork, as well.


In the latest renderings from SpaceX, you can see the ITS heading past Jupiter’s Great Red Spot, and also Saturn’s rings. Other destinations appear to include Titan, Enceladus, Europa, or others. But before the ITS can make it way out there, the spacecraft has to show that it can get to Mars first.
SpaceX plans to build a “self-sustaining city” on Mars, according to its founder Elon Musk. But, while we now know a lot more about how SpaceX plans to get to Mars, details about how people will actually survive up there remain sketchy.
Musk dropped the news on Tuesday during an address at the International Astronautical Congress meeting in Guadalajara, Mexico, where he had promised to reveal how the company planned to send people to live on Mars.


“I don’t have an immediate doomsday prophecy,” said Musk, but he noted that he saw only two possible paths forward. “One path is to stay on Earth forever, and there will be some extinction event. The alternative is to become a multi-planetary species, which I hope you will agree is the right way to go.”
The plan comes less than a month after the company’s rockets were grounded following a mysterious explosion that caused a Falcon 9 to burst into flames on the launchpad. Since then, the company has released the results of an initial investigation, tracing the fire back to a breach in the rocket’s helium supply, and announced that it plans to take to the skies again by November.


Right before the presentation, SpaceX released a mini-preview of what we could expect from its new Interplanetary Transport System. The system was previously called the Mars Colonial Transporter, until just a few weeks ago, when Musk changed the name after suggesting that it could take us to other destinations in the solar system.
As noted earlier, the video gives us a pretty good idea of the sequence of events for how the system would work:
In the video, first, we see the rocket lift-off from Cape Canaveral’s Launchpad 39a with 28,730,000 pounds of thrust behind it. After stage separation, the spaceships parks in orbit while the booster returns to Earth—where it lands. A propellant tanker is loaded onto the booster to refuel the spaceship in orbit for its trip to Mars. The tanker returns to Earth and the spaceship heads for Mars. The solar arrays deploy and the ships coasts until it finally enter Mars’ orbit. The ship lands on the Martian surface and then we get a glimpse of the astronauts looking out onto the Martian plains.

What we didn’t see in the video, however, is any kind of infrastructure that would support those astronauts to keep them alive after landing. Based on Musk’s comments, it sounds like SpaceX intends to send colonizers to a permanent city on the Red Planet. With 1,000 ships and 200 people per ship, Musk estimated that it would take 40 to 100 years to achieve a fully self-sustaining civilization on Mars.


One of the big barriers to doing that is the cost, which Musk estimated at about $10 billion. The SpaceX founder detailed four ways that he believed a ticket to Mars would become a possible purchase for many people—similar to buying a house. These methods include using reusable rockets, refuelling the spaceship in space, and using a methane fuel instead of traditional rocket fuels. Finally, that methane fuel could be harvested on Mars itself.
We also learned quite a bit about the rocket and what it would be like to travel to Mars. Just like the Falcon 9, the rocket booster on the Interplanetary Transport System will land and be re-used. (SpaceX has landed a number of its Falcon 9 rockets after flight, but hasn’t yet flown one of the used rockets back into space.) A key feature of the rocket re-usage plan is to send their Mars rockets back into space, so seeing a Falcon 9 rocket successfully make a second trip will be critical to convincing people that the plan is plausible.


The new SpaceX rocket will be incredibly large, dwarfing even the company’s Falcon Heavy and the world’s last tallest rocket, the now-defunct Saturn V.
If being locked into a spaceship for months at a time with a bunch of your fellow humans sounds a little grim, though, Musk says not to worry. “It’ll be, like, really fun to go—you’ll have a great time,” he says. Key to doing that will be making the inside of the rocket comfortable for the long ride, which for initial trips will last 80 days. Musk says that he eventually believes a trip could be brought down to a single month.


But whether this is really doable depends a lot on whether SpaceX can actually get the money together. “I would say it’s going to be a challenge to fund this whole project,” Musk noted. He spent a lot of time today talking about the economics of an individual ticket, which he said could drop as low as $100,000.
Musk hinted that he would personally be devoting assets to the project. “I really don’t have any other motivation for personally accumulating assets, except to make the biggest contribution I can to making life multi-planetary,” he said. But even then, there would still need to be significant outside investment.


“I know there’s a lot of people in the private sector interested in funding a trip to Mars, hopefully there will be interest in the government side as well,” Musk said. “Ultimately this will be a huge private-public partnership.”
How quickly all this could happen would, in large degree, depend on whether that funding comes through at all. But if the money is there and all goes as planned on the technical side, Musk said we could see Mars flights begin as soon as 2023—although he cautioned that the timeline was still in-flux. He also kept to SpaceX’s original date for when we would see Red Dragon missions head to Mars in 2018 with payloads between 2 or 3 tons.
But while he described the project as a “self-sustaining city,” Musk did not go into detail about the kind of long-term infrastructure that would keep people alive once they got there.


“The goal of SpaceX is really to build the transport system,” said Musk, before suggesting that the Martian colonists themselves would do much of the building. “Who wants to be among the first to build everything, from refineries to the first pizza joint?” Musk asked.
But before we can build a pizza joint on Mars, people will need a whole lot of other things, including but not limited to clean and usable water, a space habitat capable of withstanding Martian environments, some kind of transport, and presumably some more people who would eat there. Musk also failed to explain who—if anyone—is actually going to build and maintain that basic infrastructure. Without it, the plan is unlikely to succeed.
For what it’s worth, Musk says that he’d like to make the trip to Mars himself—but only after putting together a Plan B for his company, in case of disaster. “I would definitely like to go to orbit and visit the space station and then ultimately go to Mars,” he said. “I have to make sure if something goes wrong on the flight and I die there’s a good succession plan and the mission of the company continues.”


If SpaceX’s plans to get to Mars do succeed, though, we could be looking at trips even further out. As I noted yesterday, Musk has hinted at the possibility of using this transport system to go beyond Mars—and it appears that future plans could be heading that way.
“If we have a propellent depot, you can go from Mars to Jupiter, no problem,” Musk said. “It means full access to the entire greater solar system.” He noted a particular interest in traveling to Europa.


The first step, though, would be establishing regular travel—or even a first trip—to Mars. And to see if that’s really possible, we’ll have to wait.
A new reproductive technique in which a baby is produced with the genetic material from three distinct parents has yielded its first human.
As reported in New Scientist, the baby was born five months ago in Mexico with the help of US researchers. The three-parent reproductive technique, known as mitochondrial donation or pronuclear transfer, is not yet legal in the United States, but it is under serious discussion. The method was approved two years ago in the UK, but that country has yet to produce its first “three-parent” child.

This therapy stops serious conditions from being passed down from mother to child. In this case, the five-month old boy was born to a Jordanian mother who was at risk of passing down a fatal and debilitating genetic disorder called Leigh Syndrome, which affects the developing nervous system. The mother had previously lost two children to the disorder, so she sought the help of John Zhang, a researcher at the New Hope Fertility Center in New York City. As noted in New Scientist, Zhang performed the procedure in Mexico, where “there are no rules,” adding that “[saving] lives is the ethical thing to do.”


Mitochondria are the powerpacks that fuel every human cell, and just like the nucleus, they contain DNA. Unfortunately, inherited defects in mitochondrial DNA can cause severe or even fatal results. To overcome this problem, scientists extract two eggs—one from the mother and one from a donor. The nucleus of the donor egg is removed, leaving the mitochondria intact, and replaced by the mother’s nucleus. The resulting embryo is free from the inherited defect, resulting in a potentially healthy baby—albeit it with three parents.
Zhang and his colleagues tested the baby’s mitochondria, and found that less than one percent contains the harmful mutation. It usually takes about 18 percent of mitochondria to be affected before problems set in.
The technique is considered controversial by some because of the unorthodox number of parents. But bear in mind that a scant 0.1 percent of genetic information is being transferred by the donor. This concern is basically a non-issue, and people need to get over it. Also, this is not the first time that a baby has been born with three parents; it simply marks the first time it’s been done using this new technique.


More important are the questions of safety and efficacy. Running off to Mexico to perform a procedure because it’s still illegal in the United States may push the science forward, but it’s clearly sending the wrong message.
[New Scientist]
New research shows that as many as 700,000 microscopic fibers are released into the environment each time we do the laundry. It’s a problem with no easy solution in sight.
For years, scientists and environmentalists have wondered—and worried—if the simple act of washing our clothes might be triggering the release of microscopic plastic particles. A new Plymouth University study, now published in Marine Pollution Bulletin, shows this is very much the case.


The new research shows that over 700,000 microscopic fibers are flushed down the washing machine’s drain each time we run a load in a conventional washer. These particles are tiny enough to pass through sewage treatment plants and leech their way into the environment, where they pose a threat to fragile ecosystems.
This week, Illinois became the first state in the country to ban exfoliating plastic beads. Good…
Microplastics are bad news once they enter into the environment. Measuring as small as 0.355 millimeters in size, these tiny bits of plastic cause all sorts of problems for marine organisms. Plastics absorb toxins—like PCBs, pesticides, and motor oil—like a sponge, poisoning the food chain. Easily ingested, they start to build up in an animal’s digestive tract, hindering its ability to absorb energy from foods. Earlier this year, European researchers discovered that young fish get hooked on plastic microbeads (the kind you find in exfoliants), stunting their growth and making them more vulnerable to predators.


Researchers have suspected that synthetic textiles release microscopic fibers during the wash, but no definitive proof has existed. To see if this is in fact the case, PhD student Imogen Napper, with the help of Plymouth University professor Richard Thompson, looked at the mass, quantity, and size of fibers that leech into the wastewater after synthetic fabrics are washed at standard temperatures.
For the study, the researchers washed various fabrics at 86 and 104 degrees Fahrenheit (30 and 40 degrees Celsius) using various combinations of detergent and fabric softeners. The researchers sent the different batches of wastewater to the lab for analysis where a scanning electron microscope was used to determine the size, mass, and quantity of the plastic particles.
The researchers found that washing 13 pounds (6 kg) of polyester-cotton blend fabrics released (on average) nearly 138,000 individual strands of microscopic fibers. A similarly sized load of polyester produced 496,000 fibers. But it was acrylic that yielded the greatest number of fibers, spewing out a whopping 729,000 individual particles. The polyester-cotton blend shed the least amount of fibers on average, but the addition of bio-detergents or conditioners caused more plastic particles to be released.
Given that virtually all of us do the laundry on a consistent basis, that adds up to an astronomically high number of microplastic particles. It’s not immediately clear how much of these fibers eventually make their way into our aquatic environments, so more research is clearly needed to find out. Some jurisdictions have already banned the use of microbeads from personal care products, but banning the use of synthetic textiles is an entirely different—and wholly unrealistic—proposition. It’s a problem in need of a different solution.
“The societal benefits of textiles are without question and so any voluntary or policy intervention should be directed toward reducing emissions either via changes in textile design or filtration of [wastewater], or both,” suggested Thompson in a statement.


Moving forward, the researchers are hoping to understand why certain types of fabrics are releasing substantially more fibers than others—a finding that could have an impact on how our clothes are designed and manufactured. It could also influence the choices we make as consumers. More work is also needed to understand some of the other factors that are affecting the leakage of microplastics from our clothing, such as wash duration, washing machine filter designs, and spin speeds.


[Marine Pollution Bulletin]
Our solar system is rife with geologic activity, from eruptive ice moons to mountainous dwarf planets. Still, Earth always held a special place in the hall of geologic fame. It was the only bonafide planet to exhibit tectonic and seismic activity—until now.
Mercury, a world just a little larger than our Moon that’s spent the last four billion years in a broiler, is also geologically active. That’s according to a new analysis of high-resolution images taken near the planet’s north pole in the final months of the MESSENGER mission. These images reveal numerous tiny fault scarps; offsets in the surface that form as Mercury’s interior cools and the planet’s crust shrinks.


While Mercury’s has no plate tectonics in the terrestrial sense, crustal shrinking still qualifies as tectonic activity. It could even trigger Mercury-quakes.
Since the Mariner 10 probe zipped past Mercury in the 1970s, scientists have been aware that the solar system’s innermost planet is scarred by enormous rifts and canyons. These features tell a story of of a planet whose crust has contracted over geologic time, like a raisin shriveling up in the sun.


“The biggest of these features is comparable to the San Andreas [fault],” Thomas Watters of the Smithsonian Institute, who led the new study, told Gizmodo. “They’re huge. So we know Mercury had contracted, but we didn’t know if that contraction had happened millions or billions of years ago, because large features with kilometers of relief will not disappear.”
Smaller fault scarps, however, won’t survive more than a few million years on Mercury, an airless world whose surface is bombarded by a constant onslaught of meteorites. Watters also happens to be a mission scientist for the Lunar Reconnaissance Orbiter, which has spent the last few years snapping incredibly high-res images of the Moon’s surface, through which we’ve identified numerous tiny fault scarps. This tells us that the Moon’s crust is shrinking and quaking to this day.
“It was a surprise to discover that the Moon had these very young faults,” Watters said. “It made me wonder if Mercury had similar features.”
Several years back, Watters and his colleagues had an opportunity to find out. During the last 18 months of the MESSENGER mission in 2014 and 2015, the spacecraft entered a low-altitude orbit over Mercury’s north pole, and began snapping photographs at a resolution of less than 20 meters per pixel. Sure enough, a slew of kilometer-sized scarp features were quickly revealed. It also became clear that older, larger fault scarps remain active today.
Based on Mercury’s size, conventional scientific wisdom holds that its core should have cooled and solidified billions of years ago. But recently, MESSENGER’s magnetometer produced evidence of ongoing magnetic field activity. If Mercury still has a magnetic field, it implies that part of the core is still be molten and convecting. The new high-resolution imaging seems to confirm this.


One of the most intriguing implications of Watters’ discovery is that Mercury might be quite seismically active. Small fault scarps on the Moon are believed to be connected with moonquakes, which we’ve been picking up ever since Apollo astronauts installed a seismometer on the lunar surface.
“If we ever get to the point where we could put a seismometer on Mercury, there’s a very good chance it could detect Mercury quakes associated with continued contraction,” Watters said, adding that ongoing seismic activity may help tiny scarps evolve into larger features.
Until that future, Mercury quake-hunting mission arrives, Watters remains preoccupied with another mystery: how in the heck this tiny world has managed to hold enough core heat to stay geologically active for 4.5 billion years.


“MESSENGER has opened up a new door into this question of how Mercury has evolved,” Watters said. “We’re starting to see this picture that, in my mind, is going to change the way we think about terrestrial planets. We are going to have to think a little differently about how [they] are losing their interior heat.”
[Nature Geoscience]
We’re finally going to hear Elon Musk’s plans for a mission to Mars. You can watch along to find out what it is at 2:30pm EDT. In the meantime, here’s some of what we expect to hear—and what it means to finally put a person on Mars. [Update: And here’s some video concept art of the system at work.]
Musk will deliver an address this afternoon explaining the plan to the International Astronautical Congress titled “Making Humans a Multiplanetary Species.” SpaceX describes the speech as a “technical presentation [which] will focus on potential architectures for sustaining humans on the Red Planet.” Beyond that, details are sketchy, although there are some things we expect to hear today.


Yesterday, Musk finally revealed the Raptor engine that will power his Martian flights in action. He also shared some specs for the engine. Today, we’ll almost definitely hear follow-up details and specs for the spaceship and rocket Musk intends to ferry people to the Red Planet. When we can expect to see them in the skies is also likely to be revealed.
Musk had previously sketched out a loose timeline for SpaceX’s trip to Mars. The private space company has said it wants to send a Red Dragon space capsule to Mars in 2018 aboard one of its Falcon Heavy rockets, which hasn’t actually yet had a test flight. That’s all a prelude, though, to Musk’s stated plan to send a person (or people?) there in 2025—at least five years sooner than NASA plans to even reach Mars.
After SpaceX’s big rocket explosion (complete with its satellite payload) just this month, however, the company is currently grounded, pending the full investigation of what caused the flame-up. SpaceX intends to be back in the air by this November, but the delay is going to push back some of the milestones—particularly the debut of its Falcon Heavy rocket, which we were originally probably going to see make its first test flight this year. That flight will be pushed back until next year.


Besides the hardware of how to get there, we can also expect Musk to tell us his plans for how SpaceX intends to keep a Martian crew alive once they hit the surface of the planet. Right now, that’s the part of the plan we know the least about. What kind of structure will the colonists live in? How will they be protected from the Martian elements? What will they eat up there? Before anyone steps foot into a capsule, we need to answer all these questions—and more.
Much of what we’ll see and hear today remains a mystery. Will Musk rip through his skin suit to reveal the alien lizard-person inside? (No.) Will he show off the scale model he’s been building in his basement of Martian city, New Elonsberg? (Perhaps.) Will he finally reveal SpaceX’s plan to colonize Mars—and, maybe, even beyond? (Probably!)
But, we’ll have to wait till 2:30pm EDT to see for sure. You can watch along with us right here.

Update 1:55 p.m. SpaceX has released a teaser video featuring concept art of the Interplanetary Transport System in action.


In the video, first, we see the rocket lift-off from Cape Canaveral’s Launchpad 39a with 28,730,000 pounds of thrust behind it. After stage separation, the spaceships parks in orbit while the booster returns to Earth—where it lands. A propellant tanker is loaded onto the booster to refuel the spaceship in orbit for its trip to Mars. The tanker returns to Earth and the spaceships heads for Mars. The solar arrays deploy and the ships coasts until it finally enter Mars’ orbit.
The ship lands on the Martian surface and then we get a glimpse of the astronauts looking out onto the Martian plains. Crucially, there’s no extra infrastructure in view. We’ll have to wait a little longer to learn how the astronauts can expect to live once they reach the Red Planet.

Update 2:11 p.m: And Musk has also added a few more details about the size of the Interplanetary Transport System. (Hint: Big.)

Researchers working in Africa have uncovered 3.8 million-year-old protein fragments encased in an ostrich eggshell. These biological building blocks are millions of years older than the oldest DNA ever found, highlighting the possibility of recovering ancient proteins from extinct animals—and even the remains of early humans.
The new study, published in eLife, represents an important breakthrough in paleontology and ancient proteomics. Proteins are expressed by our DNA, and they represent the basic building blocks of life, forming everything from our teeth and toenails to our skin and vital organs. The researchers, led by Matthew Collins from York University, recovered the protein fragments in a 3.8 million-year-old ostrich eggshell that was found in Laetoli, Tanzania.


These protein sequences are significantly older than the oldest DNA ever extracted from fossils, which only go far back in time to about 700,000 years ago. This opens up the tantalizing possibility of recovering similar proteins from the earliest human fossils; traces of human habitation in the Laetoli region date back to 3.75 million years ago. Proteins may not yield the same information as DNA, but they can still reveal much about an organism.
“Ancient proteins derived from the enamel of fossil teeth have the potential to yield important clues to the evolutionary relationships, species identity, sex, and migration patterns of early human ancestors,” said Terry Harrison, an anthropologist at New York University and a co-author of the study.


Recovery of the “entrapped” proteins in the eggshell was possible due to the way they were protected by surface minerals. The researchers were actually testing a theory to see if it’s possible to extract full sequences of proteins from hard surfaces, such as egg shells, bones and enamel—and it turns out their suspicions were right. Using a computer model, the researchers demonstrated that protein sequences do in fact survive longer when they’re stabilized by strong binding to the surface of minerals found on a hard shell or bone.
We can all blame Jurassic Park for getting our hopes up that we could bring the dinosaurs using…
Excitingly, the researchers say their findings could translate to older fossils. “Even dinosaur eggshells will now be of interest [for chemical analysis],” noted study co-author Kirsty Penkman in the BBC.


Proteins have the potential to reveal genetic information up to 50 times older than DNA, which tends to degrade relatively quickly. By finding and isolating entire protein sequences, rather than a single instance, the researchers stand a better chance of determining biological function. Moreover, by studying these coherent sequences, the researchers can make educated inferences about the DNA that encoded for those functions. It’s basically virtual DNA .
[eLife]
Fire up the grill and invite me over, friend. Today, we feast in celebration.
The latest USDA meat production projections are out, and they predict that, after years of domination by chicken, beef will become the fastest growing meat category over the course of the next decade. Beef isn’t just going to be more available, though. It’s also going to be cheaper than it’s been in years.


Beef and pork consumption have been on a steady decline in the United States for the last decade, while the amount of chicken America eats has been steadily rising over the same period. This isn’t due to people losing—and then finding—their taste for steak, however. It’s because beef has been getting progressively more expensive.
You may have noticed something a little odd happening at your meat counter. Most meat prices,…
In 2015, with ranchers hit hard by both high feed prices and drought, America’s beef production hit an all-time low, right as global demand was spiking. This pushed beef prices to skyrocket by over 50 percent in the course of a decade, while chicken (which was already considerably cheaper than beef) held mostly steady. The end result was that, Americans ate considerably less beef over the last decade and quite a bit more chicken. Now, the USDA is not only forecasting that the decline will end but that beef will become the fastest growing meat category for the next ten years.
The USDA anticipates a price decline thanks to changing conditions on the ranch. High feed prices are dropping, and the drought, although it’s still ongoing, has eased up slightly. This means that ranchers’ cost of raising cows is falling. With cheaper herds, ranchers can raise more cows and send more beef out to the market. This will increase the amount of beef we eat, and it should lower the cost of beef by about 10 percent, the USDA predicts.


Chicken and pork fans shouldn’t be too worried, though. While beef had the sharpest projected gain, every single category of meat saw a predicted rise in supply throughout the next decade. By 2025, the average American will be eating 219 pounds of meat a year, compared with this decade’s 211 pounds—with no end to the upward trend in sight.
For years, scientists have speculated that morning sickness is connected to a lower risk of miscarriage, but the evidence was lacking. A new analysis involving nearly 800 pregnant women shows there may be some truth to this claim.
As many expectant women know all too well, the first half of a pregnancy is often mired by bouts of nausea and vomiting. Morning sickness tends to go away after about four months, but some women are stuck with these symptoms for the entire duration of the pregnancy. Scientists aren’t entirely sure what causes it, but it may have something to do with the way the body protects the fetus against toxins and dangerous microorganisms in foods and beverages.


Many expectant women also know that friends and family are apt to point out that morning sickness—which happens in about 80 percent of all pregnancies—is a good sign that the pregnancy is going well. Trouble is, much of this is anecdotal, and there hasn’t been a lot of high-quality evidence to support the claim. A new study published in JAMA Internal Medicine by researchers from the NIH’s National Institute of Child Health and Human Development have finally addressed this shortcoming, but more research will be needed to make a definitive confirmation.
“Our study evaluates symptoms from the earliest weeks of pregnancy, immediately after conception, and confirms that there is a protective association between nausea and vomiting and a lower risk of pregnancy loss,” noted Stefanie N. Hinkle, a researcher at NICHD and a co-author of the study, in a statement.


For the study, Hinkle and her team pulled data from previous research—a 2014 study that looked into the effects of aspirin on pregnancies (known as the EAGeR trial). The 797 women enrolled in this study kept daily diaries of whether they experienced nausea and vomiting from weeks two to eight of their pregnancies, while also answering a monthly questionnaire about their symptoms up to week 36 of their pregnancies. Prior studies failed to acquire such detailed reports in the early stages, and they typically asked women about their symptoms after they experienced a pregnancy loss.


Of these 797 women, a total of 188 experienced a pregnancy loss (23.6 percent). By the two-month mark, around 57 percent of women experienced regular bouts of nausea, while another 27 percent reported both nausea and vomiting. This latter group of women was 50 to 75 percent less likely to have a miscarriage compared to those women who didn’t deal with any sickness. The same results also applied to women who had a prior history of miscarriage.
This study is an important step forward, but it doesn’t mean that pregnant women who don’t have these symptoms should be worried. No two pregnancies are the same, and no two women are completely alike. Looking ahead to future research, it would be good to see scientists draw data from elsewhere, and not just a study that focused on the effects of aspirin on a pregnancy. Finally, this study was purely correlative—and we all know that correlation does not imply causation. With this in mind, the researchers are already planning to do more research to find out if they can figure out the connection.
[JAMA Internal Medicine]
Jupiter’s moon Europa is on the shortlist of places we might discover alien life in our solar system. And today, the prospects for finding extraterrestrial microbes on this little ice moon got a lot better, when NASA unveiled new evidence for water geysers near Europa’s south pole. The discovery strengthens the case for a geothermally-heated, subsurface ocean.
“Today, we are presenting new Hubble evidence for water vapor plumes being expelled from the ice surface of Europa,” William Sparks, an astronomer with the Space Telescope Science Institute in Baltimore said in a NASA press briefing this afternoon. “Observations indicate a global, saline liquid water ocean engulfs the moon at the present time. If there are plumes emerging, it is significant because it means we may be able to explore that ocean... without having to drill through miles of ice.”
The discovery, which will be published this week in the Astrophysical Journal, came about after a 15 month-long Hubble Space Telescope observational campaign, which saw Europa transit in front of Jupiter in the far ultraviolet on ten separate occasions. During three of those transit events, Hubble observed spectral features that could be plumes, mostly emanating from Europa’s south polar terrain.
Today’s announcement marks the second time that astronomers have discovered signs of geyser activity on Europa. The first evidence came in late 2012, when a separate UV imaging analysis by Hubble revealed elevated levels of hydrogen and oxygen near the moon’s south pole. That data was taken to indicate two enormous plumes of water, jettisoning skyward to a height of 125 miles (200 km).


But the finding was never replicated—not by Hubble, nor in data captured by several Jupiter-bound spacecrafts—until now. This prompted speculation that Europa’s geologic activity is quite intermittent, perhaps only occurring during specific parts of its orbit around Jupiter, when the gas giant exerts a powerful tidal strain on the moon.

Hubble’s latest exciting clues—UV absorption features that could indicate water—seem to support this picture. “If the features are real, they have to be intermittent, because we did not see anything on seven occasions,” Sparks said.


Europa isn’t only the eruptive moon that might be sheltering warm, life-friendly waters beneath its frozen exterior. A little further down the cosmic street lies Enceladus, whose south pole plumes spew seawater full throttle all the time, offering free samples to any spacecraft that happen to be in the neighborhood. Cassini’s discovery of activity on Enceladus has prompted some astronomers to propose a dedicated astrobiology mission to the moon, which could sample that seawater for signs of life.
An Enceladus life finder mission has not yet been greenlit by NASA—but a mission to Europa is already in the works for the 2020s. Not only are the latest signs of activity sure to generate excitement for that mission, they could help us design it for the best possible results.


“I think one of the biggest unknowns we have [regarding the plumes] is understanding their timing,” a spokesperson for the Europa mission said during the press briefing. “The more observations we can get with Hubble and James Webb Space Telescope, the better we can develop a schedule to search for these plumes [when we’re] close.”
“We know that Europa is a special place,” Amanda Hendrix, an expert in icy moons and satellites with the Planetary Science Institute told Gizmodo. “The upcoming Europa mission will be awesome in how much it reveals about Europa as a world and its potential for habitability.”
A team of researchers rode a roller coaster more times than they probably care to remember, just to figure out why roller coasters trigger the passage of small kidney stones. With the further help of a 3D-printed model of a kidney filled with urine, they think they’ve solved the puzzle.
In the new study, published in the Journal of the American Osteopathic Association, urologist David D. Wartinger and his colleagues at Michigan State University College present evidence to support widespread claims that riding a moderate-intensity roller coaster can help people pass small kidney stones. The results, though still preliminary, could assist in the development of a rather unconventional therapy for patients.
Kidney stones are a mass of chemicals and salts found in urine. Passing kidney stones can be an excruciating experience, particularly when the stones are large. Getting them out early before they get too large is key to reducing much of the discomfort and risk.


Prior to the new study, virtually no one took the time to figure out what prompts a kidney stone to pass through the urinary canal, though urologists are familiar with some common triggers.
Pregnant women often pass kidney stones, the result of increased vitamin intake. Physical labor will sometimes loosen it, as will bungee jumping, bouncing on a trampoline, dirt bike riding, and even a violent sneeze. The fact is, scientists haven’t been able to isolate a single trigger—but roller coasters seem to play an important, and even reproducible, role.
“When a series of patients returned from spring break with stories of passing a kidney stone after riding the Big Thunder Mountain Railroad at Disney World in Orlando, I started to wonder if we had a unique opportunity to help patients,” Wartinger told Gizmodo. “The moment one of my students and I realized we had to move forward was hearing from a patient who rode the ride three times and after each consecutive ride he passed a stone.”
Wartinger and study co-author Marc Mitchell used 3D printing to create a clear silicone anatomical model of this particular male patient’s kidney. They filled the model with the patient’s urine, and placed three kidney stones of various sizes in the upper, middle, and lower passageways of the simulated kidney. After sealing the model, the researchers set off for Disney World.


With the permission of park officials,the researchers placed the model of the kidney in a backpack. Then they hopped on the Big Thunder Mountain Railroad ride, holding the kidney model between themselves at approximately the position of a real kidney to stimulate the forces that would be felt by a real person. They repeated this 20 times, collecting important data with each run. Then they repeated the experiment on Space Mountain and the Walt Disney World railroad, for a total of 60 rides.
“As far as having to ride the coaster repeatedly, honestly, the first five to six times were great,” said Wartinger.”By the end we were just gritting our teeth and wishing to be done.”
At least for this patient’s simulated kidney, the data showed that sitting in the back of Big Thunder Mountain Railroad resulted in a stone passage rate of nearly 64 percent. Front seat rides produced a passage rate of nearly 17 percent. The researchers say that powerful and random forces jarred the stone lose, guiding it through the passageway.
“A kidney looks like a tree with branches,” said Wartinger. “The forces move the stone from being positioned where a leaf is located, down through the branches and out through the trunk—and onward to the bladder. It’s not surprising that the model we used passed kidney stones on this coaster because it’s based on a gentleman that passed three stones on this exact roller coaster.”
Wartinger believes this can be replicated, but not everyone will respond to the same ride. Like a fingerprint, each person has a unique kidney passage pattern, so everyone is going to have their own “ideal” kidney stone-jostling roller coaster ride. And for some, other activities may prove to be more effective.


The researchers believe that these findings can translate to preventive care, and be of help to three distinct groups.
“If you have a stone smaller than four millimeters it can help you pass it before it becomes obstructive or large enough to become stuck in the tube,” said Wartinger. “When stuck it may require emergency surgery and will cause extreme pain.”
Indeed, many have compared the pain of passing a large stone to natural childbirth. He says it could also help people who have a procedure that smashes a big stone into smaller stones, who can then pass the smaller fragments with the help of a thrill ride. Finally, it can help young women clear small stones before they become pregnant (it’s not advised that pregnant women ride roller coasters).


Looking ahead, the researchers would like to test more models on a range of other coasters, assuming they can get access to additional theme parks. And to make these findings truly helpful for patients, the researchers would need to conduct ultrasounds of individuals before and after each ride.
The study is also pertinent to space exploration. The effect of gravity normally helps with the passage of kidney stones, which is why so many astronauts suffer on the International Space Station. “Kidney stones will truly be a challenge for people on Mars 1,” said Wartinger.


[Journal of the American Osteopathic Association]
SpaceX has been talking up its Martian travel plans for a while now, but we still don’t know how it intends to get (or survive) there. As of today, however, it’s cleared a major hurdle: the rocket engine it will use to get to the Red Planet just fired-up for the first time.
Company founder Elon Musk announced that his company’s Raptor engine had its first successful firing test and included a few pictures of the mysterious engine in action:


Musk also revealed a few specs for the rocket engine, including its thrust capabilities of over 300 metric tons, a specific impulse of 382 seconds, and chamber pressure of almost three times greater than that of the Merlin engine in SpaceX’s Falcon 9 rocket. In other words, the Raptor engine is really big and really powerful. These details may also hint at some of the private spaceflight company’s upcoming plans.


The Raptor engine’s firing test is a good sign, but a successfully-firing rocket engine is still a long ways away from a fully operational spacecraft and launch system. Tomorrow afternoon, Musk is due to give a speech at the International Astronautical Congress. There, he’s expected to reveal details about his plan to get people to Mars and the spaceship—part of his Interplanetary Transport System—he wants to use to get them (and the supplies to keep them alive) to the Red Planet.
Two weeks ago, the Interplanetary Transport System had a different name, though: the Mars Colonial Transporter. Then—after tweeting “Turns out MCT can go well beyond Mars, so will need a new name…” and bandying a few name suggestions—Musk switched up the name to the Interplanetary Transport System. The key word in the new name, of course, is “interplanetary.” Musk might just be hinting that we could soon hear about travel plans that go not only to Mars but also even further in our solar system.
Cone snails employ a fast-acting venom to paralyze their prey. But what is bad news for fish is good news for diabetics. New research suggests the “weaponized insulin” produced by these sea critters is far more efficient than conventional medicines used to treat high blood sugar.
While hunting, some cone snails secrete insulin, along with other toxic compounds, into the water. When an unsuspecting fish swims by, this poisonous brew causes its blood sugar to plummet, sending the fish into a hypoglycemic trance. Stunned, the fish is easy prey for the cone snail, who engulfs and consumes it. That’s why marine biologists refer to this as weaponized insulin.


In a new study published in Nature Structural & Molecular Biology, a research team from the United States and Australia show that this undersea weapon could inspire the development of fast-acting medicines to treat diabetes in humans. A molecular analysis of the cone snail venom revealed its potency; it’s much faster than the best rapid-acting therapeutic insulin, and it can begin working in the body in just five minutes. Compare that to the 15 minutes it takes the fastest-acting insulin to kick in.
“You look at what venoms animals make to affect the physiology of their prey, and you use that as a starting point,” noted University of Utah biologist Helena Safavi, a co-author of the paper, in a press statement. “You can get new ideas from venoms. To have something that has already been evolved—that’s a huge advantage.”


Like cone snails, humans also produce insulin. But instead of using it as a venom, our bodies use it to regulate the amount of glucose in our blood. When the body can’t produce enough insulin—a condition known as diabetes—it can result in high blood sugar, or hyperglycemia. To prevent this from happening, diabetics receive synthetic insulin injections. (Natural insulin is produced in the pancreas.)


Safavi and her colleagues discovered that cone snail insulin is different than human insulin and synthetic insulin in one very important way: it lacks a molecular segment that causes it to stick to other insulin molecules. This allows it to act fast in the body. Tests on insulin receptors show that snail insulin isn’t quite as good as human insulin, but its ability to quickly get to work makes it an attractive candidate for future therapies. More experiments are needed to measure how snail insulin works in the human body, and whether it’ll function the way the researchers hope it will.
“People think it’s easy to make drugs,” said Safavi. “But where do you start? You have to have some kind of idea of what a drug should look like, what kind of properties the drug should have, so it’s very difficult to design novel drugs.” And as her colleague and study co-author Danny Chou aptly put it, “It’s really about learning from nature.”
[Nature Structural & Molecular Biology via Popular Science]
As Arctic sea ice flirts with its lowest levels in recorded history, polar scientists are taking the opportunity to remind us that it isn’t just humans who are screwed because of melting ice caps. Remember polar bears, global warming’s first darling poster child? They’re still around, and they’re not happy with what we’ve done to the planet.
Across the Arctic, nineteen separate polar bear subpopulations head out onto the ice in the winter and spring to hunt seals, their main source of calories. All nineteen groups have seen hunting season dramatically shortened because of climate change. That’s according to a new analysis published today in The Cryosphere, which drew on 35 years of satellite data to show that dwindling sea ice is bringing an earlier spring thaw and later fall freeze-up to all regions of the Arctic inhabited by polar bears.
On average, the researchers found that in polar bear-populated regions, spring ice melt has been starting three to nine days earlier per decade since 1979, while fall freeze up has been arriving three to nine days later. Over 35 years, this amounts to a reduction in hunting season of up to seven weeks, which is a lot of time that mamma bears could be packing on the seal blubber and feeding it to their young.


“These spring and fall transitions bound the period when there is good ice habitat available for bears to feed,” study co-author Kristin Laidre, a researcher at the University of Washington’s Polar Science Center said in a statement. “Those periods are also tied to the breeding season when bears find mates, and when females come out of their maternity dens with very small cubs and haven’t eaten for months.”
At the rate sea ice is dwindling, the researchers say that polar bears can expect to see their hunting season reduced by another six to seven weeks by mid-century. This, of course, will leave the enormous Arctic predators with one option: terrorizing the very scientists who want to save them. So unless we’re willing to let human-polar bear relations descend into chaos, we might want to do something about all that carbon being added to the atmosphere.
[The Cryosphere via NASA]
An arctic research mission claims that it’s discovered the HMS Terror, one of two Franklin Expedition ships that sunk during a doomed attempt to traverse the Northwest Passage. Incredibly, the 168-year-old wreck would probably not have been found if it weren’t for information provided by an indigenous crew member.
As reported in the The Guardian, the Arctic Research Foundation discovered the HMS Terror in Nunavut Bay. “Resting proud on 24 metres [78 feet] of water, we found HMS Terror—203 years old, it is perfectly preserved in the frigid waters of the Northwest Passage,” noted Arctic Research Foundation spokesperson Adrian Schimnowski.
Canadian prime minister Stephen Harper was absolutely gushing yesterday when he announced the…
Underwater footage shows the ship in excellent condition, with all three masts still standing and nearly all hatches closed. A pair of wine bottles, tables, a desk (with its drawers open), and empty shelving were seen inside the wreck.


The ship was abandoned in sea ice in 1848 during a failed attempt to find the Northwest Passage from the Atlantic Ocean to Asia. All 129 crew members were lost, nearly three years after the Franklin Expedition set out from England. Two years ago, it’s companion ship, the HMS Erebus, was discovered by underwater archaeologists from Parks Canada. Inuit oral history helped researchers narrow its location.
The HMS Terror was finally located 60 miles (96 kilometers) south of where archaeologists thought it had been lost. Finding nothing, the Martin Bergmann-led crew decided to take a detour to Terror Bay after hearing a story from an indigenous crew member named Sammy Kogvik. He told the crew that he noticed a large piece of wood sticking out of the Terror Bay’s sea ice while on a fishing trip several years ago, and that it resembled a ship’s mast. It turned out to be one hell of a tip.
The archaeologists had assumed that the HMS Terror was trapped in ice somewhere between King William Island and Victoria Island, but its location much further to the south is altering our understanding of what happened during the doomed mission.


Now that both Franklin Expedition ships have been found, there’s still one lingering mystery: the final resting place of Sir John Franklin himself. And once again, it’s here where oral tradition can help; legend has it that Franklin was buried in a vault somewhere on northern King William Island. Probably a good place to start.
[Guardian, CBC]
After demonstrating the miraculous protective capabilities of Line-X spray on a watermelon, YouTube’s How Ridiculous wanted to what else the wonder material could protect from a 150-foot drop. Surprisingly, eggs, one of Mother Nature’s most fragile creations, simply bounced off the pavement after the plunge.
The amateur scientists also tried the same experiment with a lightbulb, which ended up completely shattering inside its protective coating as it happened to land right on the screw cap. They also covered a bowling ball in the Line-X spray, but it was promptly destroyed when it made contact with a vertically-mounted axe instead of just flat pavement. Why couldn’t high school science have been this fun?


[YouTube]

While working at a remote weather station in the Russian Arctic might sound like a lot of fun, the reality is apparently far grimmer. In addition to the cold, the isolation and the possibility of literally falling off a cliff thanks to climate change, researchers have to deal with unruly locals, like the dozen or so polar bears currently “besieging” scientists on Troynoy Island in Russia’s Great Arctic State Nature Reserve.
On a tiny island at the end of the world, a lonely weather station is slowly tumbling off a…
According to Russian news agency TASS, the weather station’s five workers have been stuck inside since running out of flares to frighten the bears that arrived late last month, including one that has begun sleeping under their windows.


“We have issued a recommendation for the station’s personnel to use extreme caution, not to leave the station without a serious need and continue only with possible meteorological observations,” Vassiliy Shevchenko, head of the agency that runs the station, told TASS.


To address the crisis, Shevchenko says a research vessel has been instructed to bring the scientists additional flares and some dogs “as one of the station’s canines was killed by a bear.” Fortunately, the ship is only a month away. Shevchenko, however, remains optimistic about the situation.
“At the end of October, or in the beginning of November the near-shore waters will freeze and the bears will leave the island in search for food,” said Shevchenko. “Things like this have happened before.”
In two weeks, the European Space Agency will crash-land its prized Rosetta spacecraft, marking a dramatic end to the whirlwind two-year science mission that saw humanity’s first-ever comet landing. It’ll be 48 action-packed hours as Rosetta descends to its ultimate resting place on Comet 67P—and to get you properly excited for that event, we wanted to share the fascinating reason this site was chosen.
Recently, the European Space Agency released images of the Rosetta spacecraft’s planned impact site, located near the top of Comet 67P’s smaller lobe. The site has been named Ma’at after the ancient Egyptian goddess of harmony, balance, and order—perhaps in the hope that Rosetta’s slow-mo crash landing will channel some of these qualities. A more accurate name for this region might have been Mordor.


Littered with goosebump-like boulders and deep, treacherous sinkholes, Ma’at is a rugged and inhospitable place, prone to violent outbursts of gas and dust.


But the very same features that give Rosetta’s landing pad a frightening appearance also make it a scientific gold mine. In fact, it’s possible this spot could hold the key to understanding how comets form.
“The pits on Ma’at have unusual structures inside their walls—it’s like the edge of the walls are made of three meter balls clumped together,” Rosetta mission scientist Laurence O’Rourke told Gizmodo. “We believe these are remnants from the formation of the comet itself.”


“An important question for Rosetta is, how does a comet become a comet?” Rosetta project scientist Matt Taylor added. “How do small particles of ice get stuck together, coagulate, and aggregate? Getting better resolution of imagery these features—we call them goosebumps, but I think they look a bit like lizard skin—will help answer that question.”
As Rosetta descends on the evening of the 29th, it’ll be angling its OSIRIS camera to get a good look at several pits, capturing some insanely detailed glamor shots before it loses communication with the Earth.


“We’re trying to cram as much [data] collection as possible into this final section, and we hope to get the highest resolution images of the entire mission,” Taylor said.
Ultimately, the lander will be targeting the side of a 130 meter-wide pit known as Deir el-Medina, an appellation that once again pays homage to ancient Egyptian culture. (Deir el-Medina was home to artisans who worked on tombs in the Valley of the Kings.) Rosetta isn’t going to be entering the pit—at least not on purpose. Rather, it’ll be side-eyeing Deir el-Medina from an angle that offers good illumination as it aims for the pit’s rim. “Everything looks better by doing it this way,” Taylor said.
Of course, Rosetta’s other scientific instruments aren’t just going to sit tight while OSIRIS has all the fun. As the spacecraft dives through Comet 67P’s hazy coma, it’ll use its mass spectrometer to sniff out a variety of molecules within the gas, which early scientific reports have likened to cat piss. Rosetta will also be tasting Comet 67P’s airborne dust, and using plasma measurements to study how the solar wind interacts with the surface. “Really, this is a massive bonus for us in terms of science,” Taylor said.


There’s one other thing to know about the Rosetta spacecraft’s final resting place. Ma’at is located on the same chunk of Comet 67P—the head—as the recently rediscovered Philae lander. The two spacecraft will be just a few kilometers apart. So, even as humanity’s favorite icy rock plunges into the frigid void of the outer solar system and our communications go dead forever, sentimental space nerds can console themselves with the knowledge that neither Rosetta nor Philae will ever truly be alone.
This is probably going to terrify you, but you’ve got a ticking time bomb in your lap, or your purse, or nestled into your back pocket. If you have a consumer electronic device powered by a rechargeable battery there is a very good chance it is a lithium-based battery. Which means when you toss your kid your phone, you’re tossing them a firebomb too.
Of course the likelihood of that device actually exploding is pretty small. “Something like 1 in 10 million,” Ken Boyce, a battery expert and principal engineer director at UL, told Gizmodo. And as Boyce notes, there are currently billions of lithium batteries out there. Two decades of improvements by engineers and material scientists, assisted by safety science gurus like those at UL, have made the nearly ubiquitous lithium battery safer. Yet the fundamental nature of lithium batteries means the potential for a weenie roaster is always there.


That was a rude awakening for consumers back in 1995. Apple launched its Powerbook 5300 that year, and was one of the earliest adopters of lithium batteries. But when the Powerbook 5300 started catching on fire and a recall was launched, it cost the company millions and tech pundits started ringing the apocalypse bell. Fortunately the tech has now improved to the point that, when Apple batteries started swelling (and sometimes catching fire) in 2007, it was merely a cause for a quiet recall.
That’s why the current Samsung Note 7 fiasco is so fascinating. Following many, many explosions, the Note 7 is the subject of a giant global recall. It’s been banned by multiple airlines, and US officials have told people to  turn of the phone and stop using it forever. It certainly isn’t the first phone to go boom, but a confluence of new tech, and the inherent failings central to battery technology, improved the odds of Samsung’s current firestorm.


Indeed, the central cause of the explosions isn’t new. Heat is the enemy of the lithium battery. Heat degrades the battery’s potential to hold a charge, which is why your phone runs down faster in the heat of the summer or when you use it for an extended period of time. And on rare occasions there can be too much heat. That’s when you get thermal runaway.


“Thermal runaway is the technical term for the popular term of explosion,” Professor Yang Shao-Horn, the W.M. Keck professor of energy at MIT, told Gizmodo with a chuckle. Then she clarified. “It’s not actually an explosion, just a fire.” Thermal runaway is a chemical reaction where heat grows exponentially—which isn’t good when the chemicals getting heated rapidly, like those in a lithium battery, are also highly flammable.
Lithium batteries are nothing more than a mess of very flammable chemicals smooshed together and exposed to an electrical charge via electrodes. There are two primary electrodes in a lithium battery, the anode and the cathode (think the plus and minus sign on your AA battery). Energy goes in through the anode and out through the cathode and the two components are separated by an organic material that holds lithium salts—which is a fantastic element for efficient energy containment and transfer.
If the anode and the cathode experience contact with one another, then a thermal runaway can occur. Early lithium batteries were contained in flimsy looking bags which led to them easily being punctured, the anode and cathode touching each other, and the whole thing going poof. But later batteries aren’t immune either.

In the video above, you see a standard lithium ion battery (18650) like those found in a vape or bundled together in the battery pack of a Tesla Model S. As soon as the nail punctures the battery, the anode and cathode touch and thermal runaway occurs.


The potential for explosion due to a puncture can be mitigated with better battery construction—which is why you generally don’t have to worry about your Tesla Model S turning into charcoal after a car crash.
From what Samsung is currently reporting, the Note 7's flaming failure was something akin to the above nail example. A failure in the production of a number of Note 7 batteries meant undue pressure was being exerted on some of the battery packs, and in turn, increasing the likelihood that the anode and cathodes would come into contact.
It’s a plausible conclusion, according to Shao-Horn. But she doesn’t rule out another potential thermal runaway cause: overcharging. That’s when the positive electrode on the battery becomes so juiced up it begins to create oxygen inside, which wrecks the delicately balanced chemical composition of the hermetically sealed battery and leads to thermal runaway.


“These processes can happen even in a perfect battery,” Shao-Horn said, referring to overcharging and anode on cathode contact. Manufacturing defects like the ones reported in the Note 7 failures and those linked to the explosions of cheap vapes, “only make these two processes much worse.”
And they’re not the only processes. Even a bad USB cable can harm your device! The charging process in a phone or laptop or vape is delicate, and the batteries we use, are potentially dangerous—a ticking timebomb if managed incorrectly. That’s why the FAA always tells you to carry all your lithium batteries in the cabin. That way if they catch fire the crew can respond quickly. It’s why Apple quietly replaced swollen laptop batteries nearly ten years ago, and why Samsung, despite the massive loss to its bottom line, is currently replacing defective Note 7s.


It’s also why the UL exists. People like Ken Boyce work very hard to build out the safety science they then disseminate to vendors. If you follow UL’s guidelines to a T you’re less likely to see your hoverboard destroyed or your vape setting a pocket aflame. Because there exists, within every lithium battery, the potential for thermal runaway. So protect your batteries, keep them out of the heat, and make sure you don’t overcharge them or use the wrong cable or powerbrick.


And if the company starts a recall on your product return it ASAP. Otherwise it could be your hotel room going up in flames.

The US Air Force has declassified a harrowing video showing the heads-up display of student pilot who passed out during a tight maneuver. Mercifully, his F-16 was equipped with a ground collision avoidance system, saving him from certain death.
It’s called the Automatic Ground Collision Avoidance System, or Auto-GCAS for short. It took nearly 30 years for the USAF to develop this system, requiring the help of NASA, Lockheed Martin, and its own Air Force Research Laboratory. The USAF introduced Auto-GCAS into its F-16 fleet in late 2014, and it’s already saved at least four pilots, including the one in this video.


Auto-GCAS works by continuously comparing a prediction of the plane’s trajectory against a pre-existing terrain profile. If the system predicts an imminent collision with the terrain profile—as it does at the 26-second mark of this video (you can see the two chevrons come together)—the autopilot kicks in. Writing in Aviation Week, Guy Norris explains what happened:
In this instance, an international F-16 student pilot was undergoing basic fighter maneuver training with his USAF instructor pilot in two separate F-16s over the U.S. southwest. The student rolled and started to pull the aircraft but experienced G-induced loss of consciousness (G-LOC) as the F-16 hit around 8.3g. With the pilot now unconscious, the aircraft’s nose dropped and, from an altitude of just over 17,000 ft., entered a steepening dive in full afterburner.
After only 22 sec., the F-16 was nose-down almost 50 deg. below the horizon and going supersonic. The shocked instructor called “2 recover!” as the student passed 12,320 ft. at 587 kt [675 mph, 1,086 kph]. Two seconds later, with the nose down in a 55-deg. dive, altitude at 10,800 ft. and speed passing 613 kt [705 mph, 1,134 kph]., the worried instructor again calls “2 recover!” In a little less than another 2 sec., as the now frantic instructor makes a third call for the student pilot to pull up, the Auto-GCAS executes a recovery maneuver at 8,760 ft. and 652 kt [750 mph, 1,207 kph].
And that’s when the student pilot finally woke up, pulling back on the stick. The radar altimeter suggests a minimum altitude of about 2,940 feet which, at that speed, isn’t a whole lot of breathing room.


A close call indeed—and kudos to the USAF for developing such an amazing system. It probably won’t be much longer before these high-speed fighter jets become fully autonomous, replacing us feeble humans.
[Aviation Week via Popular Science]
Using a brain implant, Stanford researchers have developed a mind-machine interface that allows monkeys to text at the very reasonable rate of 12 words per minute. Eventually, the system could be used to help people with movement disorders to communicate more efficiently.
The new technology, developed by Stanford researchers Krishna Shenoy and Paul Nuyujukian, allowed monkeys to move a cursor across a keyboard and select letters without having to lift a finger. The animals transcribed passages from the New York Times and Hamlet at a rate of 12 words per minute.


This isn’t the first time that scientists have used a brain-computer interface (BCI) to enable thought-controlled typing, but the new technique, described in the latest edition of the Proceedings of the IEEE, improves upon earlier techniques more than three fold.

Other techniques, which rely on eye tracking or facial movements, tend to be tedious (just ask Stephen Hawking), while previous versions of BCIs have resulted in slow and imprecise typing among paralyzed human test subjects. The new system improves upon these earlier efforts, enabling “a typing rate sufficient for a meaningful conversation,” in the words of the researchers.


For the experiment, the researchers implanted a multi-electrode array into the brains of two rhesus macaques. The device reads signals from a brain region that normally controls hand and arm movements. “The interface we tested is exactly what a human would use,” noted Nuyujukian in a statement. “What we had never quantified before was the typing rate that could be achieved.”
Importantly, the monkeys were tested in ideal conditions—and with “cheat sheets” (the monkeys were simply copying the text being shown to them—there’s no actual comprehension). The researchers expect that human subjects will likely text a bit slower than the monkeys, but not by much. That said, this system doesn’t have auto-complete functionality which would most assuredly be used in a human version.
Encouragingly, multi-electrode arrays, though invasive (they have to be surgically implanted), are proving safe and durable in both non-human and human test subjects. It won’t be long before this technology enters into the real world. And who knows, it may eventually be used by anyone who wants to text with their brains instead of their thumbs.
[Proceedings of the IEEE]
For the first time ever, scientists have produced live mice without a fertilized egg cell. The potentially revolutionary technique could one day allow gay men to produce biological offspring, or—even more radically—allow both men and women to self-fertilize.
Researchers from the University of Bath injected sperm directly into a modified, inactive mouse embryo. The resulting mice appeared to be normal, and were even able to reproduce. The new study, published in Nature Communications, challenges nearly two centuries of conventional wisdom, showing that it’s possible to produce healthy mammalian offspring without first having to fertilize an egg.


In 1827, biologist Karl Ernst Ritter von Baer became the first scientist to knowingly observe mammalian eggs (in dogs), concluding that all animals develop from eggs. This has largely informed our understanding of reproduction ever since, and until now, no one has been able to show that any cell other than an egg cell can combine with sperm to produce offspring.
It’s not as if scientists haven’t tried. Previously, researchers have “tricked” eggs into developing into an embryo without fertilization, but the resulting embryos (known as parthenogenetic embryos) died after just a few days.


“In some vertebrate species, like geckos for example, parthenogenetic embryos can develop fully to produce healthy live young, but there are no examples of parthenogenetic mammals known to science,” lead author Tony Perry told Gizmodo. “Instead, development peters out after a few days.”


Perry says this has a lot to do with the need for two distinct sets of genomes—one from the mother and one from the father—which, for mammals, is essential to get the right balance of gene expression.
Basically, mammalian sperm can only transform into a mature sperm cell capable of dividing and producing to form a complex organism within an egg—or so we thought. That’s why this new study is so significant. The Bath researchers have shown that a non-egg cell can kickstart this process and completely “reprogram” a sperm cell, resulting in live birth.
Perry and his colleagues exposed mouse eggs to a chemical bath containing a salt called strontium chloride (SrCl2). As previous research has shown, this compound prevents the parthenogenetic embryos from going into a state of arrest. “Essentially, for the egg to be ‘tricked’ into initiating parthenogenetic development, one has to remove the activity that keeps it arrested in the meiotic cell cycle, and that, in effect, is what the SrCl2 does,” explained Perry. (By meiotic cell cycle, Perry is referring to the stage in reproduction when a “mother” cell starts to divide into “daughter” cells, resulting in reproductive cells, namely sperm and eggs.)


Next, the researchers injected sperm nuclei into these chemically modified mouse embryos, kickstarting the reprogramming process. The resulting embryos were then implanted into surrogate mothers.
“As far as we can tell, the [resulting] baby mice were normal and healthy,” said Perry. “We checked how long they lived, and their life expectancies were similar—in some cases longer—to those of controls. We found that the mice reproduced efficiently...and had similarly healthy offspring.”


The researchers aren’t entirely sure how the sperm genome was reprogrammed, but preliminary results suggest a different route than what occurs during conventional fertilization. Future research will be needed to fill in these gaps.
There’s no evidence to suggest the same thing applies to human embryos, but it’s very likely. “Yes, the cells are special—a parthenogenote and a sperm—but imagine if any mitotic cell could reprogram a sperm in the same way,” Perry said. “Then there would be no need for eggs.”


Clearly, many technical and ethical hurdles will have to be sorted out if this is to ever to be used to enable gay men to reproduce (with the help of surrogate mothers), or men and women to self-fertilize. Until then, it could be used to treat infertility and other reproductive issues. This process could even apply to conservation efforts and the assisted reproduction of endangered species.


More philosophically, this research further teases our notions as to when life begins, and how it’s defined. Some individuals believe that life begins at the union of sperm and egg, but this newly developed process would seem to violate that sensibility.
Moving forward, the University of Bath researchers are hoping to learn if their modified embryos can reprogram other cell types and not just sperm, and conversely, whether other cell types can reprogram sperm.
[Nature Communications]
Quadrotors need outside help to navigate and perform their remarkable stunts, whether it be a human behind the controls or an array of complex sensors placed around a room. But not this one. Developed by researchers from the University of Pennsylvania, this drone is practically autonomous—which means it’s an actual drone. The future is finally here.
As tech writer Evan Ackerman writes at IEEE Spectrum, Vijay Kumar’s lab at the University of Pennsylvania has succeeded in getting quadrotors to make aggressive maneuvers using only onboard sensing and computing, “meaning that no window is safe from a quadrotor incursion. None. Anywhere. You’ve been warned.” Indeed, it’s an achievement that takes quadrotor flight to the next level.

Normally, external motion-capture systems are what allow quadrotors to zip and flit through the air, guiding them as they dodge obstacles and navigate through hoops. These systems, like the Vicon motion-capture system, records boatloads of information about a given room, and then transmits that critical information to the drone. In essence, the drone is “dumb,” and it’s the external system that’s actually guiding it.


That’s all fine and well for a university lab, but the inability of a drone to fly on its own is clearly a huge limiter. Without their fancy navigation systems, quadrotors are unable to do many of the things we actually expect autonomous drone to do in the real world, like fly through a window.
Now, after six years of tedious work, the Vijay Kumar Lab researchers have developed a small quadrotor that’s equipped with a single camera, a computer, and an IMU (intertial measurement unit) which allows it to know where it is in space, and then perform trajectory calculations as its executes a planned path. Essentially, the researchers took a room’s worth of external technology and packed it all onto a 250-gram quadrotor. That’s amazing.
“This is the first time that aggressive maneuvers are solved with such a small footprint vehicle using only onboard sensors and without relying on external motion-capture systems,” note the researchers.


But as Ackerman explains, there is a caveat: “the location of the obstacles relative to the starting position of the quadrotor are provided to the robot in advance.” This is because its front-facing stereo camera can’t perform the dense mapping required for such a feat, but the researchers say they’re going to resolve this limitation fairly shortly.
Still, what this machine is doing is extraordinary. While in flight, the quadrotor is estimating its location and orientation in space 500 times a second. It can reach speeds of 4.5 meters per second, accelerate at 1.5 g, and roll and pitch at angles of up to 90 degrees.


A few more tweaks by these developers and we could finally start to see these tiny drones in the real world. You may want to keep your windows shut.
[IEEE Spectrum]
Instead of just working on improving what 3D printers are capable of, researchers at the Hasso-Plattner-Institut are also finding ways to make everyday objects more 3D printer-friendly, including those that rely on moving parts that can’t be reproduced during the printing process.
So how do you replicate an object that moves when you’ve eliminated all of its moving parts? By using something called metamaterials which rely on an internal grid of cells, aligned in specific patterns, to give them mechanical properties. The Hasso-Plattner-Institut researchers took things one step further by developing metamaterials that allowed for repetitive and pre-defined directional movement, in order to replicate specific motions or movement.

For example, 3D-printing a door handle and latch isn’t impossible, but it would require you to replicate every last moving part and then assemble them all when complete—a time consuming process. But by using metamaterials, where turning the handle causes the inner cell structure to collapse in a domino effect which then causes the latch to retract, the mechanical object can be 3D-printed in one pass saving time, money, and materials.
The door handle example is a little impractical, since you probably don’t want to use a frail plastic mechanism to secure your home, but the researchers have also designed more useful tools that can be 3D-printed on demand. You might one day have the need for a pair of needle-nosed pliers of a very specific length, and with a 3D-printer you could churn out the exact tool you need, ready to use, without requiring a run to the hardware store.


[Hasso-Plattner-Institut via Creative Applications]
The moon is our almost constant frenemy in space, lighting our nights and spoiling our star-views in equal turns. But now, new measurements from Apollo-era moon rocks suggest that the moon and Earth had a much more savage past than we knew.
A new paper out today in Nature says that the moon formed as a result of a more violent space collision than previously believed. Since the 1970s, many researchers have championed a theory in which the moon was created from thrown-off debris when a Mars-sized body grazed Earth in a relatively low-contact collision. Instead, the researchers say new evidence shows that the impact was more “like a sledgehammer hitting a watermelon.”


The old theory of the moon’s origin—in which it formed from debris from a grazing collision—neatly explains both the moon’s size and orbital position. But a test on some lunar rocks from the Apollo mission revealed something odd which that theory couldn’t explain.
“We’re still remeasuring the old Apollo samples from the the ‘70s, because the tech has been developing in recent years. We can measure much smaller differences between Earth and the moon, so we found a lot of things we didn’t find in the 1970s,” Kun Wang, an assistant professor at Washington University who is the lead author of the paper told Gizmodo. “The old models just could not explain the new observations.”


If the four-decade old theory were correct, then researchers would expect to find that well over half of the moon’s material had come from that Mars-sized body that scraped Earth to form the moon. But the researchers weren’t finding signs of that in the samples; instead, chemical analyses on the samples were returning isotopic compound readings that were nearly identical.


They started to do more and more advanced tests to try and pinpoint any differences in the signatures. They finally found one—but one that suggested that the samples’ origins were even more tightly connected than previously expected.
The isotope signatures were the same, except for more of a heavy-potassium isotope in the lunar samples which would have required incredibly hot temperatures to separate out. A violent collision between the Earth and the Mars-sized impactor could have caused those incredibly high temperatures. In this model, the temperatures were so high and the force so powerful that the impactor and even much of Earth vaporized on contact. That vapor then expanded out over an area 500 times the size of the Earth before finally cooling and condensing into the moon.
“We need a much, much bigger impact to form a moon according to our study,” explained Wang. “The giant impact itself should be called extremely giant impact. The amount of energy required isn’t even close.”
This new data doesn’t just change our conception of how the moon was formed, though. It also suggests an early solar system that was much more volatile than we knew—and it could be just the beginning of what new analyses on old lunar samples could teach us.


“Everything we know about the early solar system is from our study of meteorites and lunar samples, all those really really old rocks,” said Wang. “It has changed our understanding of the early solar system, it’s much more violent than we thought.”
The researchers will continue to study the Apollo lunar samples to try and pull yet more clues from them. Even now, they suspect that these samples that we’ve been holding on to for decades could have more secrets to reveal.
Attention, moon-fearing humans: your long-held suspicion that the full moon can interfere with life on Earth seems to have a scientific basis after all. No, the moon still doesn’t make you crazy, horny, or murderous. But it seems it can help trigger large earthquakes.
Since the 19th century, scientists have debated whether the gravitational tug of the Moon and the Sun influence seismic activity here on Earth. In recent years, evidence has been mounting that the ocean’s twice-daily high tides can result in small, slow-moving tremors. But to date, this relationship has been restricted to specific environments and parts of the world, such as the the San Andreas fault in California.


Now, we have the first strong evidence for a global relationship between the larger, monthly lunar cycle and powerful rumbles within the Earth. Examining three separate seismic databases, a team of geologists at the University of Tokyo has found an overlap between some of the largest quakes in recent memory (magnitude 5.5 or above), and periods of high tidal stress, when the Sun and Moon are aligned to yield the strongest gravitational tug on the Earth. Those events include the 2004 Sumatra quake (magnitude 9.3), the 2010 Maule quake in Chile (magnitude 8.8) and the 2011 Fukushima quake in Japan (magnitude 9.0).
While the details of how large earthquakes form and evolve haven’t been fully worked out, the process is thought to involve a number of small ruptures cascading to form a really big one. Based on the new analysis, it would seem that such a cascade is more likely at the full or new moon, when the Sun and Moon are exerting the maximum amount of strain on the Earth. The authors also found that the fraction of large earthquakes compared with small earthquakes increased as tidal stress increased.


“[The study] suggests that the small additional encouragement from the tides can actually make an earthquake grow a bit larger than it would have otherwise,” Nicholas van der Elst of the U.S. Geological Survey told Gizmodo. “This is surprising, considering how small the tidal stress is, compared to thestresses generated by the ongoing earthquake.”
Don’t expect this to be the final word on the matter—many factors are involved in triggering earthquakes, and within the geologic community, there’s a wide spectrum of viewpoints on the importance of the Moon’s role. Still, the new results could be valuable to those in the earthquake prediction business, because, as the authors note, they “suggest that the final earthquake size can be estimated probabilistically.”
More generally, the discovery could lead to new paradigms for understanding Earth’s most epic shakeups.
“If the observation can be confirmed,” van der Elst said, “this sort of tidal triggering could teach us something pretty fundamental about how earthquakes start, grow, and ultimately run their course.”
[Nature Geoscience]
Hillary Clinton has been diagnosed with pneumonia, fueling ongoing concerns about the Democratic presidential nominee’s health. Here’s what you need to know about this common illness, and why Clinton will quickly bounce back.
Video taken yesterday during the 9/11 ceremony in New York showed Mrs. Clinton being taken to her car by security aids. She approached the car with wobbly legs, finally collapsing just as she was about to enter the vehicle.


Clinton, as we now know, has pneumonia, and she’s currently on antibiotics. Her diagnosis may sound bad, but this illness is quite common and very treatable. The next few days and weeks might be rough as she battles a nasty cough and some fatigue, but she’ll likely bounce back fast.

Clinton was apparently dehydrated and “overheated” at the 9/11 event, which in conjunction with the pneumonia caused her to fall ill. Soon afterwards, her physician, Lisa R. Bardack, said Clinton was re-hydrated and “recovering nicely.” That said, the presidential nominee has canceled a trip to California.


The timing is bad. Not only is Clinton in the midst of a heated presidential campaign against Republican nominee Donald Trump, there’s been rampant speculation about the 68-year-old nominee’s health. Clinton has been uncharacteristically tight-lipped about her health, fueling speculation that she’s not as fit as she claims to be.
But Clinton’s pneumonia diagnosis is hardly Earth-shattering. The National Heart, Lung, and Blood Institute estimates that four million Americans contract the illness each year, the vast majority of whom make a full recovery. Clinton will likely be no exception.
Simply put, pneumonia is an infection in one or both of the lungs. It’s caused by many different germs, including bacteria, viruses, and even fungi. When microbes reach the lungs, the body’s immune system reacts by dispatching cells to attack them. But sometimes, these immune cells cause air sacs to form in the lungs, known as alveoli, to become inflamed or fill with fluids and pus, causing the symptoms of pneumonia.
Clinton’s doctors didn’t specify the exact type of pneumonia that she’s dealing with, but she likely has bacterial community-acquired pneumonia. Clinton’s doctors prescribed antibiotics, which suggests she doesn’t have viral pneumonia—otherwise she would have been put on antiviral medicines.
Symptoms can vary from mild to severe, and depend on a number of factors, such as the type of germ causing the infection, and the age and overall health of the individual. They include high fever, shaking, chills, a persistent cough with phlegm, shortness of breath, chest pain while breathing or coughing, and suddenly feeling worse after a cold or flu.


Older people sometimes experience sudden changes in mental awareness, such as temporary confusion. Around one in five people with pneumonia will require hospitalization. Most can be treated at home.
The key to getting over pneumonia is treatment and rest. Adults typically start to feel the effects of the medicine within about three days, and it usually takes about three weeks for a person starts to feel like themselves again, although sometimes it can take about a month to get over feeling fatigued.
This bout of pneumonia isn’t likely to pose a long-term problem for Clinton, given that the vast majority of cases can be treated. There’s little reason to expect complications, as well, since Clinton doesn’t have a serious pre-existing health condition that we know of. The illness may slow Clinton down for the next several weeks while she recovers, and some rest might do her some good.


As for concerns that this illness will somehow affect her ability to campaign and govern as president, that’s completely unfounded. But this episode should send a clear message about the need to communicate clearly. If Clinton is truly healthy, then people should know about it. Otherwise, the conspiracy nutters will fill in the information gaps with all sorts of nonsense.
[NIH, BBC, NYT,]
After promising biblical rains and instead giving California crabs, El Niño passed away quietly last spring. But while early data suggested La Niña would rise to fill the chasm El Niño’s departure had left in our meteorological newsfeeds, NOAA is now starting to think La Niña might not happen at all.
As early as last winter, climate forecasters told us they were “reasonably confident” La Niña conditions would emerge by late 2016. As the spring wore on, our confidence in the anti-El Niño climate pattern grew stronger, bolstered by the expansion of a telltale, cold water undercurrent in the equatorial Pacific. When that cold water mass started to breach the surface last May, ending the reign of El Niño’s hot blob once and for all, climatologists forecasted a 75 percent chance La Niña would be here by the end of the year.
But late last week, NOAA’s Climate Prediction Center poured some cold water on our hope that lots and lots of cold water would spread across the Pacific’s midsection, perhaps even making a temporary dent in our global, carbon emissions-fueled heat wave. Last week, the La Niña watch was officially taken down. Forecasters are now placing their bets on ENSO-neutral conditions (aka, neither El Niño nor La Niña) persisting through the winter.


What changed? As a blog post by NOAA explains, we’re still measuring cooler-than-average temperatures across the so-called Niño 3.4 region of the tropical Pacific, which are considered typical for La Niña. But that temperature dip hasn’t been accompanied by the La Niña atmospheric response. By this point, we should be seeing an amping up of the Walker circulation pattern, meaning cool air should be sinking more vigorously in the central and eastern Pacific as warm air rises more vigorously over the western Pacific.
An intensification of Walker circulation would strengthen westerly winds across the tropical Pacific, leading to more rainfall over places like Indonesia. “So far, there have only been some very weak indications of this intensification,” NOAA writes. And without these atmospheric acrobatics, the cool subsurface waters in the Niño 3.4 region are likely to fizzle out.


La Niña could still happen—it might just be a late bloomer. But the probability that we’ll be welcoming a La Niña into the world this winter has been downgraded significantly to about 40 percent.
As disappointing as this is, it’s worth remembering that El Niño, too, was a bit of a let-down. Despite having virtually tied the 1997-98 El Niño in terms of strength, our planetary party guest didn’t end California’s drought, although that may have been an unreasonable expectation. It sorta figures that El Niño’s alter ego would be a no-show.


[NOAA]
In a breakthrough that will appeal to both spies and those who work with priceless but frail historical documents, researchers at MIT have developed a camera that uses terahertz radiation to peer at the text on pages of a book, without it having to be open.
Terahertz radiation falls somewhere between the microwave and infrared spectrums, and the research team, including Barmak Heshmat, Ramesh Raskar, and Albert Redo Sanchez from MIT, and Justin Romberg and Alireza Aghasi from Georgia Tech, chose that particular flavor of radiation because of how it reacts with different chemicals. Different chemicals produce a distinct frequency as they react with different terahertz frequencies, which can be measured and distinguished. In this instance, it allows the researchers to tell the different between ink and blank paper.
Complex algorithms and software is required to translate the frequencies being bounced back to the camera, allowing it to distinguish letters on a page. But it also relies on how far the short bursts of terahertz radiation are traveling, by precisely timing how long it takes to reach the 20-micrometer-thick air gaps between pages of a book, it’s able to calculate when it moves from page to page.

In its current form the terahertz camera can accurately calculate distance to a depth of about 20 pages, but it can only distinguish characters on a page to a depth of about nine pages. The device also requires the paper used to have some degree of transparency. However, as the detectors and emitters used are further refined, the researchers feel their system could be a fantastic tool for museums or other facilities who want to explore and catalog historical documents, without actually having to touch or open them, and risk damage.


[MIT via Gizmag]
It’s been called “the worst infectious disease ever recorded among vertebrates.” The devastating effect of the chytrid fungus on frog populations around the world has contributed to the extinction of at least 200 species and no one knows where it came from. But now scientists are hoping to tweak the amphibian’s evolutionary development by bulking up their bods with small doses of the very thing that’s killing them.
Batrachochytrium dendrobatidis has been wreaking havoc on frogs for 20 years now. The amphibian skin fungus causes the disease chytridiomycosis. When a frog is infected, its skin ceases to function properly. Because frogs breathe underwater and absorb key nutrients through their skin, a chytridiomycosis diagnosis is most certainly terminal.


Jessie Bushell, director of conservation at the San Francisco Zoo, is part of a search-and-rescue mission that is focused on saving the mountain yellow-legged frog by immunizing it against the chytrid fungus. This particular species has seen more that 90 percent of its population disappear as the fungus spreads across the Sierra Nevada. She explained to NPR just how quick and vicious this problem is, “when it hits, it’s within weeks that they’re just gone, just literally gone.”
For twenty years, the deadly fungal disease Bd has been wiping out amphibians across the world. But …
Last Summer, Federal biologists found dozens of the mountain yellow-legged frog dying and decided to attempt to save the species by collecting their young. The biologists then handed over the hundreds of tadpoles to Bushell’s team to start experimenting.


Using a treatment that originated at UC Santa Barbara, the conservationists at the San Francisco Zoo began immunizing the young frogs with small amounts of the chytrid fungus in an attempt build up their immunity. “Their bodies identify it and can already be primed to fight off that infection, at least to keep it under control because they’ve seen it before,” she says. After infecting her test subjects, Bushell gives them an anti-fungal treatment that pulls them back from the brink of death. Once healthy, the frogs are released into the wild.
This is the third year that Bushell’s team has conducted the experiment. Roland Knapp, a biologist with UC Santa Barbara says, “they seem to be surviving pretty well.”
Evolution takes its time and it will be a while before we know if this approach can build a generational resistance. Knapp says that we are facing “what could be the extinction of a significant fraction of the world’s amphibians,” and “if we can do something to reverse that, even for a few species here and there, we should try to do that.”
Scientists have been arguing over the authenticity of an ancient document called the Grolier Codex for 50 years. A new analysis published in a special section of the journal Maya Archaeology has concluded that the codex is indeed genuine, making it the oldest surviving manuscript from the pre-Colombian era.
Perhaps you’re not familiar with the Grolier Codex. It’s the surviving pages of a 20-page book, made of stucco-coated bark paper folded into an accordion shape. The pages are painted with typical Maya iconography—gods, warriors, slaves, and hieroglyphs, for instance—and include a calendar charting the movement of the planet Venus.


Legend has it that looters ransacking a cave in Mexico came across the badly damaged pages in the 1960s, along with a turquoise mask, a sacrificial knife, and some blank pieces of fig-bark paper. That’s according to a Mexican collector named Josue Saenz, who claimed he was contacted by the looters and taken by plane to a remote airstrip to collect the items—although at least one archaeologist, Donna Yates, has called this account “fantastical.”
Saenz’s questionable account and subsequent actions cast doubt on the authenticity of the fragments from the start, even though the other artifacts have since been shown to be genuine. Scientists tested the codex in 2007, but couldn’t decisively settle the matter of its authenticity, partly because while many of the materials used were pre-Colombian, some of the wear and tear in the pages seemed artificial. It was possible a gifted forger may have used materials from the right period to throw off archaeologists. And radiocarbon dating revealed the blank pages of bark paper found with the codex pegged them to around 1230 AD.
“It became a kind of dogma that this was a fake,” co-author Stephen Houston of Brown University said in a statement. “We decided to return and look at it very carefully, to check criticisms one at a time. Now we are issuing a definitive facsimile of the book. There can’t be the slightest doubt that the Grolier is genuine.”


Along with Harvard University’s Michael Coe, and Mary Miller and Karl Taube of the University of California, Riverside, Houston reviewed all the known research on the codex.
That included assessing the manuscript’s origins, the carbon dating results, the various deities depicted, how the bark paper was made, the Maya blue pigments, and thin red sketch lines underneath the paintings, among other aspects. The team concluded that a forger in the 1960s simply could not have known all the details required to create such a forgery. Many of the deities shown in the codex hadn’t even been discovered then, for example, and scientists didn’t successfully make Maya blue in the lab until the 1980s.
There are three other known (authenticated) ancient Maya manuscripts, known as the Dresden, Madrid, and Paris Codices, in addition to the Grolier Codex. There are variations among them, but all include astronomical calendars tracking the movements of heavenly heavenly bodies. And radiocarbon dating shows the Grolier predates the other three.
“A reasoned weighing of evidence leaves only one possible conclusion,” the authors wrote. “Four intact Mayan codices survive from the Precolumbian period, and one of them is the Grolier.”
[Maya Archaeology]
New research from the University of Nebraska-Lincoln shows that a widely-used class of nicotine-based insecticides is causing queen bees to lay substantially fewer eggs than normal. This particular class of insecticides—the most popular in the world—has also been linked to colony collapse disorder, a mysterious phenomenon in which the majority of worker bees suddenly abandon the hive, leaving immature bees and the queen behind.
Previous research has shown that neonicotinoid insecticides have a detrimental effect on bees, resulting in impairments to foraging, learning, and memory in worker bees. But few studies have looked at the effects of neonicotinoids on the queen bees in particular, who are the mothers of most—if not all—bees in a beehive.


In the latest study published in Scientific Reports, lead author Judy Wu-Smart and colleagues found that queen bees in colonies who were fed a sweet syrup laced in Imidacloprid, a neonicotinoid insecticide, laid substantially fewer eggs than normal. Depending on the dose, the queens laid anywhere from one-third to two-thirds fewer eggs compared to queens in unexposed colonies.
“The queens are of particular importance because they’re the only reproductive individual laying eggs in the colony,” Wu-Smart said in a statement. “One queen can lay up to 1,000 eggs a day. If her ability to lay eggs is reduced, that is a subtle effect that isn’t (immediately) noticeable but translates to really dramatic consequences for the colony.”


With the help of Marla Spivak from the University of Minnesota, Wu-Smart evaluated colonies populated by 1,500, 3,000, and 7,000 honey bees. The control colonies received untainted syrup, while the test hives received samples with insecticide doses of 10, 20, 50, and 100 parts per billion. This was done over a three-week period, resulting in a number of adverse effects to the queens and their broods.


In addition to an impaired ability to lay eggs, the queens also exhibited poor locomotor activity. Workers experienced impairments to foraging and hygienic activities, and the colony as a whole experienced poor development overall (e.g. poor brood production and reduced pollen stores). The larger the colony, however, the lesser the effect, suggesting that larger populations act as a buffer to offset pesticide exposure.
These results are a strong indication that neonicotinoid insecticides are contributing to the global decline in bee populations. Growers typically apply insecticides or sow insecticide-treated seeds during early spring, when bees are at their most vulnerable. But Wu-Smart says that banning neonicotinoids is not the solution. Rather, she advocates for regulating insecticide-treated seeds the same way that sprays and other application techniques are regulated, and recommends that farmers be smart about when they conduct their aerial sprays (i.e. not on windy days).
“In many of these cases, we want to figure out why these colonies are dwindling when they should be at their peak production,” said We-Smart. “[Our study] is providing some of that insight. It’s not answering all the questions, but it’s definitely something to consider.”
[Scientific Reports]
Secretly gloating over the misfortunes of others (a.k.a. schadenfreude) might not be the most noble of human traits, but it’s certainly universal—so much so, that it was memorably immortalized in the hit musical Avenue Q. Neuroscientists may have just identified the brain cells associated with that feeling.
Discovering these so-called “schadenfreude neurons” was serendipitous—a side benefit of the main study, whose key findings were focused on neurons associated with observational learning. The gory details of both conclusions are outlined in a new paper in Nature Communications.


Human beings often learn by watching how other people succeed or fail at specific tasks. That’s the essence of observational learning. “Observational learning is the cornerstone for our ability to change behavior,” senior author Itzhak Fried of the University of California, Los Angeles, said in a statement. “It’s human nature to want to learn from other people’s mistakes rather than commit your own.”
For the study, ten epileptic patients who had electrodes implanted deep in their brains—standard procedure for epileptic studies—were asked to play a card game in which they would draw a card from one of two decks. The odds were stacked against them in one deck, so that they only had a 30 percent chance of winning. The other deck was rigged in their favor, giving players a 70 percent chance of winning. By comparing their own results with those of two other players, each participant was able to figure out which deck gave them the best chance of winning.


The researchers noticed a change in the firing of brain cells deep in the frontal lobe—specifically in a brain area associated with decision-making, emotion, and social interactions—that corresponded to whether the players thought their opponents would win or lose. Furthermore, the cells responded differently after players learned whether their prediction was correct or not. They concluded that those brain cells were learning from those cues and using that information to calculate which of the two decks to draw from next.
This may sound similar to mirror neurons—special brain cells that fire not only we perform a particular action, but also when we watch someone else do the same. But there is a key difference. Granted, both types of neuronal response relate to social interactions and learning. According to lead author Michael Hill (now based at the Swiss National Science Foundation), however, the specific activity of these neurons (encoding errors of observational prediction) is quite different from mirror neurons.
The most surprising observation was that those cells also showed increased firing activity whenever a player won, or his or her opponents lost, and decreased activity when a player lost and the opponents won. That’s the basic definition of schadenfreude: we experience pleasure when we win, but also when others lose.

But how can we know for sure that the increased activity observed in these neurons is truly an indication of the emotion we call shadenfreude? Hill is quick to clarify the oft-repeated adage that correlation doesn’t necessarily imply direct causation.


“What we are actually seeing is that the activity correlates with schadenfreude; within the limits of this study, we cannot know what the causal relationship is,” he told Gizmodo. “It might be that these neurons simply differentiate between winning and losing, and between self and other, even if we personally are not actually feeling any schadenfreude at all.”
That’s a much more difficult question to answer. “Making the jump from neuronal activity to a feeling that we experience is one of the hardest problems we face in science today,” said Hill. “It boils down to the question of how does the matter of the brain lead to the experience of the mind, and is actually referred to as ‘the hard problem’ in neuroscience.”
[Nature Communications]
Actual lab tests have revealed that the commonly-cited five-second rule doesn’t hold up. And yet, they still can’t stop me from eating this piece of floor candy! Who’s in charge now, Science?
The five-second rule—which says that you can still happily snack on fallen food as long as you scoop it back up within five seconds—has been the subject of some disagreement among scientists. Previous lab tests have suggested that there might actually have some backing behind it, but although the tests took place in a lab, they didn’t come with an accompanying published study. The only published study on the subject had found that bacteria transfer did indeed start happening from the first moment your food hits the floor.


Now, a new study published in Applied and Environmental Microbiology by researchers at the University of Rutgers confirms there is no grace period of five seconds for your food to spend on the floor. More bacteria can get on your food the longer it’s on the floor, but, just like in the previously published study, they found that contamination had already started at initial food-to-floor contact.
Researches also found that the type of food that’s fallen down and the type of surface it fell onto matters. Falling on stainless steel may sound like the cleanest option, but carpet was actually the best floor surface to eat off of—beating steel, ceramic, and wood—probably because its rough texture minimizes contact with the floor. Additionally, the higher the moisture content of the food, the more quickly it picked up bacteria. Of the foods tested, a watermelon sample picked up the most bacteria, while a gummy candy picked up the least. So, perhaps that floor candy is, if not good-to-eat, better than the other options.


[Applied and Environmental Microbiology]
Many DUI offenders revert back to drunk driving once their car breathalyzers have been removed, making these gadgets useless from a rehabilitative perspective. But a new pilot project shows that these devices, when used in conjunction with rehab, are effective in preventing future DUIs.
A car breathalyzer, more formally known as an alcohol ignition interlock device, measures a person’s blood alcohol content and prevents them from starting the vehicle if they’re impaired. Depending on the nature of the offense, drivers must use these devices for a mandated period of time, typically a few months through to an entire year.


While installed, car breathalyzers reduce re-arrests for DUIs by nearly 70 percent. But once these devices are removed, drivers typically revert back to their old ways. Re-arrests for DUIs are similar to those offenders who never had interlocks installed. Car breathalyzers, therefore, are good at reducing DUIs while they’re installed, but they don’t really serve a rehabilitative purpose.
At least not on their own. In a new study published in Alcoholism: Clinical & Experimental Research, researchers showed that car breathalyzers, when used in conjunction with a rehabilitation program, resulted in a dramatic decrease in DUIs even after these devices were removed.


The study, led by quantitative sociologist Robert Voas from the UCL Institute of Education, followed the results of a 2008 Florida policy mandating alcohol abuse treatment classes for DUI offenders with car breathalyzers. Drivers who committed three or more interlock violations—that is, two failed attempts to start a car with a blood content level greater than 0.5 percent within a four-hour period—were mandated to attend rehab for eight to 12 weeks.


To gauge the effects of this policy, Voas, with the help from the US Centers for Disease Control, the Pacific Institute for Research and Evaluation, and the Florida Department of Highway Safety and Motor Vehicles, compared two groups: drivers who received treatment while their interlocks were installed and those who just had the interlocks installed. Results showed that the 640 individuals who went to rehab experienced a 32 percent decrease in re-arrests during the 12 to 48 months afterward compared to the non-treatment group.
The researchers say that the resulting decline in impaired driving probably prevented 41 re-arrests, 13 crashes, and nearly 9 injuries in crashes following the interlock removal.
This study shows that alcohol ignition interlock programs should include alcohol abuse treatments to prevent future DUIs. More obviously, it suggests that all multiple DUI offenders should be sent to rehab anyway, and that these interlock gadgets are basically useless at preventing future indiscretions behind the wheel.
[Alcoholism: Clinical & Experimental Research]
A disturbing new report shows that 1.3 million square miles of the Earth’s wilderness has been lost since the 1990s—an area half the size of Australia. The researchers say this “catastrophic loss” highlights the need for an international agreement to protect our planet’s invaluable forests.
Our planet has lost a tenth of its global wilderness in just two decades, according to a new Current Biology study authored by researchers from the Wildlife Conservation Society and the University of Queensland. In a statement, lead researcher James Watson described his team’s findings as “staggering and very saddening,” adding that the findings “underscore an immediate need for international policies to recognize the value of wilderness and to address the unprecedented threats it faces.” Watson says we have about 20 years to “turn this around.”


No doubt, further losses to the Earth’s forests could prove disastrous. Wilderness areas perform a number of important functions, such as providing fresh water, food, and medicine. Forests are gigantic carbon sinks, sucking up greenhouse gasses and expelling precious oxygen. They also stave off the effects of erosion, reduce extreme weather, and even work to support many of the planet’s most politically and economically marginalized communities. But as Watson points out, our forests are “completely ignored in environmental policy.”
For the new study, the researchers mapped wilderness areas around the globe, with “wilderness” being defined as an area with biologically and ecologically intact landscapes free from significant human disturbance. The updated map shows that 11.62 million square miles (30.1 million square kilometers) still remain as wilderness, which is approximately 20 percent of the world’s land area. The majority of these areas are in North America, North Asia, North Africa, and Australia.


But then the researchers compared their new map to one produced by a similar method back in 1993. The researchers saw that about 1.3 million square miles (3.3 million square kilometers) of wilderness has been lost since the early 1990s, with a 30 percent loss of wilderness in South America, and a 14 percent loss in Africa.


“You cannot restore wilderness. Once it is gone, the ecological process that underpins these ecosystems are gone, and it never comes back to the state it was,” said Watson. “If we don’t act soon, it will be all gone, and this is a disaster for conservation, for climate change, and for some of the most vulnerable human communities on the planet.”
Leading drivers of deforestation include the conversion of wooded areas to farms, ranches, and urban use, but forest management policies and environmental laws are failing to prevent developers from taking these efforts too far. Tropical forests are currently experiencing the worst levels of deforestation, yet they’re home to more than half of the planet’s land and plant species.
Deforestation is clearly a serious problem, but it’s not immediately obvious how or if a global consensus can be reached on the matter. Just look at how difficult it’s proving to get an international agreement on climate change—a crisis that’s staring us right in the face.
[Current Biology]
NASA’s asteroid-skimming spacecraft just blasted off into space without a hitch, completing the first step in a seven-year journey that will eventually bring us back several spoonfuls worth of dirt from an asteroid.
With lift-off taking place in Cape Canaveral, not too far from the site of SpaceX’s exploded rocket, there was some concern that residual damage from the destroyed rocket could delay OSIRIS-REx’s trip up today. But after a review, NASA pronounced the capsule ready and capable of launching on schedule.


The Atlas V rocket carrying the craft blasted off seamlessly at the very start of its two-hour launch window, which you can watch right here.

With a successful lift-off behind it, the journey is still far from over. The spacecraft is scheduled to separate itself just after 8 p.m. Then we’ve got seven more years to wait before the return capsule brings back a few scoops of asteroid dirt—and, perhaps, some answers to our questions about how life started here on Earth.
Until then, there will be quite a bit to tide us over, including the results of a 2-year long mapping mission, which NASA scientists say will give us such a high-resolution map that we would be able to spot a penny on the asteroid. We’ll update you on its progress as the craft continues outward on its journey.


Update 8:04 p.m. And at just after 8:04 p.m. as scheduled, OSIRIS-REx successfully separated from its configuration to continue on its journey. NASA still has a confirmation check coming up later tonight to ensure that the spacecraft is healthy, but all indications are that everything is looking great for the trip to Bennu.
Update 9:30 p.m. NASA reports that the OSIRIS-REx spacecraft is communicating with ground control as expected and everything went according to plan for the launch, which principle investigator Dante Lauretta described as “just exactly perfect.”
Now, the wait begins—first for the spacecraft to make its way out to the asteroid and then for the data (and dirt) to come back here.
By building a gigantic petri dish, researchers from Harvard Medical School and Technion-Israel Institute of Technology have produced a jaw-dropping visualization showing bacteria as it mutates to become resistant to drugs.
The new study, published today in Science, is the first large-scale demonstration showing how bacteria react to ever-increasing doses of antibiotics, and how these relentless microbes exploit Darwinian selection to adapt to—and even thrive within—the very medicines meant to kill them.


“What surprised me most about it was that we could actually see evolution happening in front of us,” co-author Michael Baym, a postdoc at the Kishony lab at Harvard Medical School, told Gizmodo. “Here were the abstract diagrams we’d been drawing for years, come to life.”
An 18-month review into antimicrobial resistance warns that superbugs will kill upwards of 10…
Each year, around 700,000 people die around the world from untreatable bacterial infections, and antibiotic-resistant superbugs could kill upwards of 10 million people each year by the mid-21st century. Just today, the UN announced a high-level meeting to discuss possible strategies and countermeasures.


Baym worked with Roy Kishony of Technion-Israel Institute of Technology and Harvard Medical School on the experiment. They call their giant petri dish the Microbial Evolution and Growth Arena, or MEGA for short. It’s a rectangular platform, two feet wide and four feet long, filled with a gelatinous substance known as agar, a seaweed-derived substance that’s commonly used to facilitate microbial growth. Using the MEGA-plate, the researchers were able to watch antibiotic resistance develop in Escherichia coli.
They divided the MEGA-plate into several sections, each of which was saturated with varying doses of antibiotics. The ends of the platform contained no antibiotics, allowing the bacteria to thrive; these areas represented the starting line. But the adjacent inner sections contained a small amount of antibiotic—just enough to kill the E. coli. Moving inward, each subsequent section of the MEGA plate was treated with a ten-fold increase in the dose of antibiotics. At the very core of the dish, there was 1,000 times as much antibiotic compared to the areas with the lowest dose.

For the next two weeks, the researchers watched—and filmed—as the bacteria died, survived, and adapted to the increasingly poisonous conditions located at the borders of their immediate perimeters. The resulting timelapse video literally shows Darwinian processes at work—a process that would normally remain invisible to the human eye.


As the two-week experiment progressed, the bacteria spread until they reached a potent concentration of antibiotics beyond which they could not grow. That is, until mutants—armed with the specific set of traits required to fight off the poison—finally emerged. This often didn’t take long. At each concentration level, a small segment of bacteria adapted to the hostile conditions, the result of successive accumulated genetic changes.
Once settled in the new section of the MEGA-plate, these tiny populations of antibacterial-resistant mutants were able to grow. When they reached the next section of the platform, the pattern repeated itself. The descendents of this initial group of mutants were able to move to areas filled with higher concentrations of antibiotics. Eventually, multiple lineages of mutants competed for the same space, with winning strains moving on to areas with higher drug doses.
By the eleventh day, the bacteria had migrated all the way to the highest drug concentration in the center. These hardy mutants were capable of surviving an antibiotic known as trimethoprim at a dose 1,000 times greater than the one that killed their ancestors. And some bacteria acquired a 100,000-fold ability to fend off ciprofloxacin, another common antibiotic.


“We were able to evolve over a thousand-fold wild-type resistance to trimethoprim in 11 days— that’s very nearly the saturation limit of the drug,” said Baym. “Put simply, there was no way to dissolve enough drug to kill these bacteria.” Importantly, all bacterial mutants were contained and all materials decontaminated after use.


Observations showed that initial mutations led to slower growth. That suggests bacteria aren’t capable of growing at optimal speeds while in the midst of developing adaptations. But once they stumble upon a fortuitous immunity, it’s all systems go, with growth proceeding at normal rates.
Also, the fittest mutants weren’t always the fastest growers. The most successful bacteria remained behind while the weaker strains were forced to deal with the intense drug doses at the front lines.


“Thanks to the the bacteria needing to migrate to survive, we saw a surprising dynamic by which the strongest weren’t necessarily winning, rather those that were good enough and close enough to the new area would beat out nominally superior mutants just by being faster,” Baym said. “Nevertheless, in every case we saw that this successive accumulation of mutations was able to evolve extremely high levels of antibiotic resistance in a relatively short time.”
Looking ahead, the researchers would like to use the the MEGA-plate to predict the future evolutionary potential of specific pathogens. Armed with this knowledge, future clinicians will be able to tell which antibiotic a pathogen is resistant to, and how it might evolve resistance if certain antibiotics are used.
[Science]
Throw some dye into milk, add a drop of soap and suddenly the whole thing turns into a psychedelic mess of shapes and colors. Sound familiar? You probably did this science experiment in the 5th grade and felt astounded by it.
Now you’re an adult, and the only way to recapture that magic is to film the same messy process with a gorgeous macro lens. Up close a plate of gross colored milk looks more like a new universe being born. Hell yeah.

Astronomers have discovered a new asteroid—just in time to catch it as it hurtled past us at less than a tenth of the distance between us and the moon. It’s the second time that’s happened in two weeks. What have we done to anger you, space gods?
This most recent asteroid, 2016 RB1, was both slightly smaller and slightly closer than 2016 QA2, the other undiscovered asteroid that brushed by us at the end of August. Still, their specs are pretty similar. 2016 RB1 measured in at somewhere between 25-50 feet and came by us at a distance of 25,000 miles yesterday. 2016 QA2 was around 50,000 miles away and measured over 50 feet.
Despite their close approaches, neither asteroid was actually on-course to hit Earth at all. Still, the fact that they are so close—and we had no idea until they were practically on our doorstep—is a little surprising.


Part of it is due to the classic space problem: Space is very big and it’s easy to miss things even when they are about to fly right through our orbit. The other problem is that it gets much harder to predict what asteroids are going to do once they get closer to us, because of a curious effect of nearing the sun on the paths of asteroids.
Asteroids rotate and, as they come closer to the sun, the side closest starts to heat up. This built up heat can then push the asteroid miles into a different and sometimes hard-to-predict path.
Tonight, NASA is going to be launching their first mission to capture some dirt from yet another near Earth asteroid, Bennu. But they also hope the trip will give them a chance to get a better idea of how these sun-powered pushes, called the Yarkovsky effect, work. If they’re successful, we could get a whole lot better at predicting where nearby asteroids are going to go, before they’re right next to us.
Doctors have this nasty habit of asking a lot of questions, many of which make us uncomfortable or self-conscious. So we bluff. A lot. Here are 10 typical lies we tell our doctors, and why these seemingly innocuous fibs are hazardous to our health.
No, you’re not. Sure, it’s difficult to take medications routinely. It’s awkward to fess up to your GP that you don’t. But now, you’re not just skipping out on prescribed treatment, you’ve given your doctor a dose of misinformation which could result in further adverse effects.


“I need to know whether the patient is taking the meds. If they aren’t, and I assume the drug isn’t working, it may cause me to switch to a different second choice med,” Dr. David B. Agus, the Director of the Lawrence J. Ellison Institute for Transformative Medicine, told Gizmodo. A doctor might also unnecessarily adjust your dosage, since your current one (the one you’re not actually taking) isn’t apparently having its intended effect.
Dosage boosts come with their own set of consequences, such as increased heart rate, dizziness, and fatigue. So now you’re actually undermining your health, which is the opposite outcome of why you went to the doctor in the first place.


Often, the doctor can tell if you’re not taking specific medications—if you show up with elevated blood pressure, or your blood tests indicate high cholesterol. Ultimately, however, it’s really on you. “Be honest about the meds you are taking or not taking,” Agus says, “and then together we can make the right decisions.”
Oh, really? This seemingly minor omission could seriously derail your health. As Agus explains, when his patients don’t tell him about all of the medications they’re taking, he may miss an important interaction or potential side effect. This includes prescription drugs like blood-thinners, antibiotics, antidepressants, and heart medications, as well as supplements and over-the-counter drugs, such as aspirin, minerals, amino acids, botanicals, and vitamins.
“Supplements are drugs and need to be treated as such,” he told Gizmodo. “They should be listed on a patient’s record of their medications.” The nature of drug-on-drug reactions depend on the particular mixture and the unique physiology of the patient, but some drugs pack a bigger punch than others.
Car accidents are no longer the leading cause of accidental deaths in the United States. According…
“These may be painkillers, benzodiazepines, and so on,” Dr. Gail Saltz, an associate professor of psychiatry at The New York Presbyterian Hospital Weill-Cornel School of Medicine, told Gizmodo. She says it’s unfortunate when people lie to their doctor about addictive medications they’re taking, or have been prescribed by another doctor. “These medications interact with others and can have an additive effect, which can be dangerous.”


Problematic drug-on-drug interactions can include a dangerous drop in blood pressure, a fast-paced irregular heart beat, a build-up of toxins that damage the liver, and less serious symptoms such as nausea, upset stomach, and headache.
Patients may lie, says Saltz, because they want more of these medications, or because they feel embarrassed. They may also fail to tell their doctor that they are on antidepressants because they feel uncomfortable sharing that psychiatric treatment information with another doctor, or feel that it’s not important.
“Drug interactions make it important for your doctor to know.” says Saltz, “A diagnosis of depression or anxiety is also important to know because some medications can, as a side effect, cause depression or anxiety—and particularly in someone who has already been experiencing that.”
A patient comes in for surgery and the anesthesiologists asks, “When was the last time you had anything to eat or drink?” The patient responds, “Oh doc, I haven’t had anything all day.” It may sound like a harmless fib, but according to M. Fahad Khan, assistant professor of anesthesiology at NYU Langone Medical Center, it could result in disaster.


“It is very important for patients to be honest about that last oral intake of food or drink as it can have significant consequences with regards to their anesthetic plan,” he told Gizmodo. “Patients presenting for elective surgery are assumed to have an empty stomach, because they are prepped to do so.”
Trouble is, when a patient is put to sleep via anesthesia, their lower esophageal sphincter (the valve that connects the esophagus to the stomach) relaxes. During this period of relaxation, says Khan, food contents from the stomach can dangerously regurgitate up into the patient’s mouth and snake their way into the patient’s trachea (windpipe) on their way to the lungs. Once in the lungs, this regurgitated acidic food material can start to cause inflammation and may even lead to the development of a pneumonia.
“Lying to your anesthesiologist about the last time you had anything to eat prior to surgery can have devastating consequences and in a worst case scenario can land you in the ICU,” he says.
Many of us are guilty of this one. Dr. Harriet Hall, editor of Science Based Medicine, says our failure to tell the truth about alcohol consumption is counterproductive. “Underreporting the amount of alcohol you drink will only delay diagnosis and treatment,” she told Gizmodo.


Health experts say that you shouldn’t have more than two-three drinks a day (10-15 per week), adding that’s okay to indulge on special occasions. Health problems can arise when we exceed these limits, including raised blood pressure, abnormal blood-test results, and digestive issues. So if you lie to your doctor about your alcohol intake, and you exhibit these symptoms, you’re potentially leading your doctor down the garden path. What’s more, alcohol—like any other drug—may be influencing the effectiveness of medications you’re taking, and your doctor needs to know.
For those with a more serious alcohol issue, this is a kind of lie that could actually kill them, according Dr. David Juurlink from Sunnybrook Health Sciences Centre in Toronto. “I’m referring specifically to patients who are admitted to hospital, and who subsequently develop alcohol withdrawal,” he told Gizmodo. “It’s a potentially lethal—and sometimes hard to diagnose—disorder.”


In a hospital, if doctors have been truthfully told about a patient’s alcohol history, they know to watch for withdrawal and treat it accordingly. But if they’re not told or misled about a patient’s alcohol consumption, and the patient goes into withdrawal, health practitioners often look for other disorders that can cause similar findings (e.g. fever, agitation, confusion, etc.), and may forgo what can be lifesaving treatment for alcohol withdrawal.
“Seriously, people shouldn’t worry about being judged by their doctors,” says Juurlink. “Plenty of doctors drink more alcohol than they should.”
Around 13 percent of smokers keep their habit a secret from their doctors. Taken as a whole, that means about six million smokers in the United States are withholding this very important information.


“When I ask them if they’re a smoker they often say they’re an ex-smoker,” says Dave Hepburn, a general practitioner in Victoria, British Columbia. “When I ask how long, some will admit five days or similar.” Needless to say, that does not make one an ex-smoker, particularly if that person has been smoking regularly for years.
People are afraid to tell their doctors the truth because of the social stigma surrounding cigarette use, and because they’re afraid to admit to themselves that they’re engaging in an extremely risky health habit. What’s more, patients may be hiding their habit from their families (who often share a GP) or their employers.
A new British report concludes that e-cigarettes are a blessing rather than a curse, arguing that…
Nonetheless, it’s important to tell the truth. If your doctor knows you smoke, they can recommend further screenings and evaluations, and assign a more stringent schedule of check-ups to catch smoking-related diseases, such as cancer, COPD (chronic obstructive pulmonary disease), and heart disease. It’s also important to remember that your doctor can help you kick the habit before it’s too late.


“Smoking is one of the most important lifestyle changes that can be made that affects health dramatically in many areas ranging from stroke and heart attack to cancers of all types,” Hepburn told Gizmodo.
Given that most recreational drugs are illegal, we’re obviously uncomfortable about sharing these habits with our doctors. Dr. Ramin Manshadi, an Associate Clinical Professor at UC Davis, feels that the vast majority of people who take recreational drugs lie to their doctors about it, yet the truth often shows up in their urine.


Failure to disclose the drugs we’re taking, especially hard drugs, can seriously impede a doctor’s ability to diagnosis a health condition. Marijuana, an increasingly socially and legally acceptable recreational drug, can interfere with other drugs, such as antidepressants, aspirin, blood thinners (e.g. warfarin and heparin), antiplatlet drugs, and nonsteroidal anti-inflammatory drugs (e.g. ibuprofen). It can also affect blood sugar levels and cause low blood pressure.
Importantly, if you’re being taken to the hospital for a drug-related reason, or if you’re on some kind of drug when a health emergency happens, you should tell your doctor or the ER so they know exactly how to treat you and save you from something potentially much worse than a bad trip.
“It’s very important to disclose your drug use to your doctors specially if you are having a heart attack,” says Manshadi. “If a patient is having a heart attack and they have used cocaine for example, then we cannot give them some beneficial meds that we normally give heart attack patients,” adding that the combination “can cause worsening of heart attack and possibly death.”
“If your cholesterol is up, blood glucose is high, as is your blood pressure, don’t just say you’ve been going through a bad period when your life has been bad for as long as you can remember,” says David Jenkins, professor of Nutritional Sciences and Medicine at the University of Toronto. “You need help. You need a change in lifestyle. And if that’s not sufficient then you need a change in meds.”


Dr. G. John Mullen says that too many patients try to sound perfect for their doctors, but lying about exercise in particular only hurts the patients. “We all know diabetes and heart disease are major problems in developed countries,” he told Gizmodo. “Exercise and diet are the best methods for beating these diseases, so don’t lie about it! Overlooking the daily necessity of nutrition and exercise is a big problem. Be honest and get some helpful tips from your doctor.”
A patient may tell their doctor that they’re only taking about 1 to 2 tablets of Tylenol once in a while, but in reality they’re taking about two tablets every four hours around the clock, seven days a week. As Dr. Khan explains, acetaminophen toxicity is real and can be deadly.


“Doctors need to know an accurate record of how much over-the-counter acetaminophen a patient is actually taking in order to prescribe them a safe pain management plan,” he says. “Several pain medications (i.e. Percocet, Vicodin, Norco, Ultracet) are combination pills that include a strong acting opioid medication in addition to acetaminophen.”
Khan says a patient’s liver doesn’t know where all the acetaminophen is coming from, nor does it really care. It’s just trying to figure out a way to metabolize the copious amount of medicine safely and effectively.


“The most recent guidelines for the use of acetaminophen have suggested that no more than 4,000 mg (some even cite 3,000 mg) as the upper daily limit of allowable intake,” says Khan. “So now if a doctor is under the assumption that a patient is only taking a small amount of over-the-counter acetaminophen on their own, he/she may unknowingly prescribe a combination pain medication—one that that also contains acetaminophen—that will put the patient at risk for potentially developing liver failure.”
Some of us go to the doctor and under-exaggerate our symptoms in hopes that the doctor won’t find anything wrong with us, or to feed our inflated egos in regards to how much discomfort we can handle. This is obviously a huge no-no.


As an example, Dr. Mashadi points to patients who have had stents implanted to treat blockages in their arteries. “They downplay their symptoms because they do not want to end up getting another stent,” he explains. “This is dangerous since the sooner we find out there are issues, the better the outcome.”
On the other hand, Manshadi says there are patients who have financial hardships and downplay their symptoms so they don’t have to pay their deductibles and/or co-pay. “This is also dangerous,” he says. “The advice is to always the truth to your doctors. As much as legally possible, I would discount patients that can not afford to pay or refer them to free clinics. Health comes first.”


Similarly, Dr. Mullen says he has patients who come in and downplay the amount of aches and pains they’re feeling, saying they keep quiet about neck, shoulder, or low back pain. “Unfortunately, these painful areas may be more problematic than they think,” he says. “Many systemic diseases refer pain to other areas (i.e. referral pain). If it isn’t a referral pain, it doesn’t mean it isn’t serious. Regular joint pain should be addressed early and referred to a physical therapist, as pain can increase risk for joint degeneration and replacement later in life.”
As Dr. Hall pointed out to Gizmodo, about 40 to 80 percent of medical information provided by doctors is forgotten immediately, and much of what is remembered is remembered wrong. “Get the doctor to provide written information, read it carefully at home, and prepare questions for the next visit,” she recommends.


Clearly, our ability to understand and remember our doctor’s instructions and admonitions is critical to getting better and staying healthy. When we don’t comprehend something our doctor says, we might not take our medications correctly, or we might engage in risky habits if we don’t truly understand the implications of a concussion or an x-ray.
We need to stop pretending and nodding our heads in agreement when our doctors start talking gobbledygook. As patients, we’re the non-experts, so we need to check our egos at the door. It’s okay to ask your doctor for clarification. Remember—that’s their job, and just like you, they want to see your health improve.
With only a few days left before it’s scheduled to crash-land on the surface of Comet 67P, the Rosetta spacecraft is still yielding amazing discoveries. And I’m not just talking about lost comet landers.
Scientists now report that Rosetta detected complex organic molecules in the dust surrounding its comet. This strengthens the argument that the building blocks of life itself may have come from icy space rocks.


Complex organic molecules—mixtures of mostly carbon, hydrogen, and oxygen that form the basis of our biology—have been hinted at on comets before, most notably during fast flybys of Halley’s comet. But Rosetta is the first mission to actually catch dusty organic particles escaping the surface of such a body, affording scientists a detailed look at their composition.
Two of those dust grains, curiously nicknamed Kenneth and Juliette, are the subject of a scientific paper published this week in Nature. Captured in May and October of 2015 and analyzed with Rosetta’s on-board mass spectrometer, each of these wee grains contains carbon-based molecules bound together in very large structures, similar to the organic matter found in carbonaceous chondrite meteorites here on Earth.


“Our analysis reveals carbon in a far more complex form than expected,” Hervé Cottin, a co-author on the new study, said in a statement. “It is so complex, we can’t give it a proper formula or a name!”
The finding is significant for a few reasons. For one, it builds off early discoveries made by the Philae lander in the hours before its batteries went dead on Comet 67P’s surface. While Philae only sniffed very light, gaseous organic compounds known as volatiles, the new analysis focused on large, solid particles, which indicate more complex organic chemistry.


Second, scientists have long debated whether the organics found in meteorite samples come from space, or whether these rocks were contaminated after crash-landing on a biological planet. The discovery of similar molecules in space itself strengthens the argument that the carbon-based stuff we see in meteorites came from beyond Earth.
Finally, Rosetta’s discovery offers a tantalizing glimpse of what’s to come from NASA’s OSIRIS-REx asteroid sample return mission. A first-of-its kind attempt to grab a scoop of dirt from a space rock and bring it back to Earth for analysis, OSIRIS-REx is expected to give us a detailed look at the makeup of the rogue bodies buzzing our planet’s backyard. That mission launches today, by the way—so even as we say goodbye to Rosetta, expect plenty more on whether all of the Kenneths and Juliettes out there are your distant ancestors in the years ahead.


[Rosetta Blogs]
Extreme, catastrophic flood events like the one that swamped Louisiana last month are becoming more likely because of climate change, according to a hot-off-the-press analysis by the National Oceanic and Atmospheric Administration (NOAA).
The study found that the record rainfall responsible for last month’s epic floods—the worst natural disaster to hit the United States since superstorm Sandy—was made at least 40 percent more likely by global warming. The researchers arrived at that conclusion by applying a new but increasingly popular statistical approach called “weather attribution.” Details of the analysis, which is currently under peer review, can be found in the open-access journal Hydrology and Earth System Sciences.
“We found human-caused, heat-trapping greenhouse gases can play a measurable role in events such as the August rains that resulted in such devastating floods, affecting so many people,” NOAA geophysicist Karin van der Wiel said in a statement. “While we concluded that 40 percent is the minimum increase in the chances of such rains, we found that the most likely impact of climate change is a near doubling of the odds of such a storm.”


The no-name storm began around August 11th when a low-pressure air mass rumbled up the Gulf of Mexico, stalling out over the Louisiana coast for several days. As I explained at the time, a combination of high air and sea surface temperatures fed an incredible amount of moisture into this system—moisture that was then hauled inland and unleashed over neighborhoods from Baton Rouge to Livingston. Over several days, the storm dumped three times as much rainfall as Hurricane Katrina, with some locations receiving 20 inches of precipitation in just 48 hours. Rivers overflowed and flooding ensued.
By August 17th, flood waters had claimed 13 lives, more than 30,000 people had been rescued, and over 60,000 homes suffered damage.


For some, it’s easy to look at an event like this and pinpoint the fingerprints of climate change. After all, records show that the frequency of heavy downpours has increased along the Gulf Coast since the mid-20th century, which makes sense because a warmer atmosphere can hold and dump more water. And yet, the majority of meteorologists are still reticent to discuss climate change in their reporting, due to a combination of cultural and political factors, and the relative novelty of scientific research tying planet-wide changes to weather.
That’s why the attribution studies now being done by NOAA and others are so critical. They are building a foundation that legitimizes the connection between extreme weather and climate change through statistics.
In the new study, scientists at NOAA’s Geophysical Fluid Dynamics Laboratory and elsewhere examined the risk of devastating, three-day flood events along the central Gulf Coast from the early 20th century to the present. Observational data told the researchers that the frequency of extreme flooding had indeed increased in this part of the country. Using climate models, they were able to reproduce a similar uptick in flood frequency by increasing the concentration of greenhouse gases in the atmosphere. That’s the attribution part.
According to NOAA’s models, the odds of a Louisiana-like downpour drenching the central Gulf Coast have increased by at least 40 percent since 1900. It’s worth noting that changes in the frequency of heavy downpours are unlikely to be limited to the Gulf Coast. Climate models show that while some areas, notably the southwestern United States, are expected to become drier this century, others, including the midwest and Pacific Northwest, will likely see an uptick in the number of extreme rainfall days.


The point of doing all this is not to arrive at some arcane statistical conclusion. It’s to help emergency responders, planners, and the public understand how weather risks are changing so that we, as a society, can be better prepared. The planet is changing whether we like it or not, and it’s time to adapt.
[NOAA]
A blue-ribbon panel commissioned by the Obama administration has released a report describing 10 transformative research strategies designed to increase the speed at which cancer research is conducted—but it’s not clear if US Congress will commit the necessary funds.
The 28-member Blue Ribbon panel presented its report to the National Cancer Advisory Board earlier today. To come up with its recommendations, the committee organized several working groups involving some 150 experts, who focused on such topics as pediatric cancer, improved data sharing, and clinical trials.

In total, the panel made 10 recommendations which it believes represents the “most compelling” opportunities available to speed progress against the disease; the ultimate goal of the Cancer Moonshot initiative is to make “a decade’s worth of research progress in cancer prevention, diagnosis, and treatment in just five years,” and to “bring the most promising science and clinical developments to cancer patients in the near term.”


The 10 recommendations are as follows (a full description of each item can be found here, along with accompanying summary videos):
It’s a diversified strategy, one that recognizes the need to merge science, technology, advocacy, social science, and big data.


Vice President Joseph Biden, who lost a son to brain cancer more than a year ago, is leading this campaign, pledging, “I plan to do two things: increase resources—both private and public—to fight cancer, and break down silos and bring all the cancer fighters together—to work together, share information, and end cancer as we know it.”
A groundbreaking new therapy in which white blood cells were reprogrammed to attack cancer cells is …
Importantly, the recommendations stress the need to create a clinical trial network dedicated to immunotherapy—a revolutionary new line of research that leverages the body’s own immune system to to fight cancer. The proposal to increase testing for hereditary cancer syndromes is likewise prudent, as these conditions are known to increase risk for breast, colon, and other cancers.
The proposals are appropriately ambitious given that cancer claims 600,000 American lives each year, but as the Washington Post makes clear, the recommendations come at an uncertain time:
Many of the ideas would require millions—if not hundreds of millions — of dollars in additional funding, but Congress has not yet approved any extra spending for the moonshot effort. And within the cancer community itself, federal officials are still struggling to overcome skepticism that the moonshot will result in breakthroughs against [the disease]....
And with the election just a few months away, time is ticking on the Obama administration to put these recommendations in action, lest it drop the ball on its promise to make a meaningful and lasting impact on the war against cancer.


[National Cancer Institute via Washington Post]
Researchers from the UK and Spain have shown that spiders are capable of tuning their webs, allowing these eight-legged critters to receive specific information about their environment, including the presence of prey, potential mates, and the structural condition of the web.
Similar to the strings of a finely tuned instrument, each strand of spider silk transmits vibrations across a wide range of frequencies, which propagates throughout the web. This allows spiders, who don’t see very well, to sense the integrity of their webs, and to detect the presence of prey and mates.


Scientist have known about this for years, but they weren’t entirely sure about the precise characteristics of these vibrations, or if spiders had any control over this cool architectural feature. To learn more, researchers from Oxford University and Universidad Carlos III de Madrid explored the links between the material properties of spider webs and how vibrations propagate through the silken strands. Their study, which now appears in the Journal of the Royal Society Interface, demonstrates that spiders can in fact tune their webs to transmit specific messages.

Above video: The web, in addition to catching prey, signals vibrations to the spider—who reacts almost instantly upon impact.


Using high-powered lasers to measure the ultra-small vibrations, the researchers isolated three particular web features that allow spiders to turn their traps into data transmitters: web tension, silk stiffness, and overall web architecture. Importantly, spiders are able to manipulate all three of these characteristics.
For example, both transverse waves, i.e. waves that vibrate at right angles to the direction of its spread, and longitudinal waves, i.e. waves that vibrate in the direction of propagation, can be adjusted, or tuned, by the spider when it adjusts the web’s tension and the stiffness of the web’s outer rim and spokes, known as the dragline. In fact, spider webs are so customizable, the researchers hypothesize that specific features of silk evolved for this very purpose.
“[We] propose that dragline silk [features] may have evolved as a control mechanism for these multifunctional fibres,” write the authors in their study. “The various degrees of active influence on web engineering reveals the extraordinary ability of spiders to shape the physical properties of their self-made materials and architectures to affect biological [i.e. data transmission] functionality.”
So when a spider builds its web, it’s not just constructing a trap and blindly hoping its design will lend itself well to the propagation of specific vibrations. Rather, the spider is working like a diligent engineer, building a stable web that performs its primary trapping function, while also optimizing the web’s ability to relay critical information. It’s essentially constructing—and then fine-tuning—its web to be a multi-function device.
At the same time, the spider has to constantly balance trade-offs between the structural integrity of the web and the web’s ability to transmit signals at specific frequencies.


Wow. Spiders are truly amazing.


[Journal of the Royal Society Interface]
We already know that spider silk is something of a wonder material, but scientists are still…
Tomorrow night, an asteroid-bound mission will launch towards a shadowy space rock, Bennu. There, it will scoop up a bit of dirt and deliver it back to us, all without ever attempting a landing. It’s not just any dirt, though. Bound up in these grains could be the answer to how life first emerged here on Earth.
Researchers have long theorized that comets or asteroids could have been responsible for delivering the first specks of organic materials or perhaps water that got things brewing on our planet. We have even found organic materials and chemically-bound water in meteorites that may have come from carbonaceous asteroids like Bennu.


The problem is that these meteorites have spent so long on Earth that there’s no way of knowing whether organic compounds inside them came from asteroids, Earth itself, or somewhere else along their journey. This will be the first time that we ever have the opportunity to check that profile directly from the asteroid.
“The reason we go to an asteroid like Bennu is we believe it’s a pristine remnant of the very early solar system,” Ed Beshore, the project’s deputy principal investigator, told Gizmodo. “It’s important because we want to answer questions about the rise of life on Earth.”


It will take two years until OSIRIS-REx even arrives at Bennu, and another two years before the sample is taken. The samples will get back to Earth in 2023.
Still, there are several things that the mission can teach us even before we bring a little piece of the asteroid back. For one, it could help us better predict which asteroids are going to come close to us, and how close they’ll get.


Bennu belongs to a category of close-by asteroids called Near Earth Asteroids (NEAs). In fact, this proximity was one of the reasons it was chosen for the mission. But, as we’ve seen lately, the orbit of those NEAs—even when they buzz right next to us—can be hard to predict. This is due primarily to something called the Yarkovsky effect, which happens when asteroids are heated by the sun.
“Asteroids get hot,” explained Beshore, “like how asphalt streets get hot on the Earth. They rotate like the Earth does and that re-radiated heat acts like a tiny rocket thruster which can actually move the asteroid around.”


Since 1999, NASA has seen Bennu shift its trajectory over 99 miles from this effect. By studying Bennu’s movements up-close, researchers hope to get a better idea of just how—and how much—the Yarkovsky effect is moving asteroids around.
The real prize from Bennu, though, are the four tablespoons of asteroid dirt that will be scooped up by the spacecraft at the mission’s conclusion and packed into its return capsule. How it will accomplish this collection is one of the trickiest aspects of the mission.
Before any sample-taking is even attempted, scientists will first make a painstakingly complete map of the entire asteroid, a process that could take up to two years. From that first map, they’ll identify a dozen or so potential sampling sites, then create even more refined maps to choose the spot most likely for success.
“By the end, we’ll be able to see an object the size of a penny on Bennu,” said Daniella DellaGiustina, the mission’s lead image processing scientist. Once they’ve selected a spot, though, things get even more harrowing.


While the craft buzzes the asteroid, a 10-foot-long “pogo arm” comes forth—like a boxing glove on a spring—to grab the sample. It’s not just a simple scoop, though. The arm uses puffs of nitrogen gas to swirl some dirt from the asteroid up into a storage compartment in a matter of seconds. If the sample collection isn’t successful the first time, engineers have made plans to do a couple loop-backs, but as soon as the compartment has a full sample, the craft will immediately depart back to Earth.
“It’s a safe, slow, smooth high-five to collect that sample and bring it back to Earth” explained Christina Richey, the mission’s deputy program scientist. The entire collection will take just five seconds, she noted, but in those few seconds and approximately 60 grams of dirt, scientists are hoping to find answers to some of their oldest questions about life on Earth.


“We’re fairly confident that there’s going to be some of these organic compounds but until we get it back down to earth we won’t know for sure,” Richey said.
Getting the samples back to Earth also presents a significant challenge. The spacecraft will take the dirt most of the way back, but it’s not equipped for a landing. Instead, it will eject the capsule four hours above Earth at a speed of 27,000 mph. A parachute will help it descend safely in Utah and, after seven years, researchers will finally be able to get their hands on those bits of dirt from an asteroid.


“This is really an opportunity to bring back a piece of the very early solar system,” Beshore said. “These samples can be analyzed for decades, just like the moon samples returned over 40 years ago are still being analyzed using tools we didn’t even know would exist, and of course the same will happen on the samples from Bennu.”
The launch takes place Thursday night from Florida’s Cape Canaveral station, aboard one of the United Launch Alliance’s Atlas V rockets. It’s the 13th major NASA mission to use that rocket.
There was some concern that last week’s fire from a SpaceX rocket—which also took place at the Cape Canaveral station, but from a different launch pad—might delay the launch. But after a full assessment, NASA said there was no damage to facilities for this launch or any elevated risk from the blazing Falcon 9 rocket.


OSIRIS-REx is expected to leave on-schedule in a 2-hour launch window starting at 7:05 p.m. EDT. From then, it will be a wait of seven years before we start to get answers about what’s really up on Bennu—and, perhaps, even how life on our planet really got started.
On April 10, 1940, British submarine HMS Tarpon and its crew of 50 were sent to Norway to intercept Nazi merchant vessels. They were was never heard from again. Now, after 76 years, the sub has finally been found. An investigation of the remarkably well preserved vessel shows it didn’t go down without a fight.
The wreck was discovered earlier this year by Gert Normann Andersen, who runs a Danish war museum, and Innes McCartney, a British marine archaeologist. The shattered remains of the vessel, a 275-foot (84 meter) T-class submarine of the Royal Navy, was found in the Danish section of the North Sea, about 50 miles (80 km) from the harbor town of Thyborøn.


The discovery solves a longstanding mystery as to the exact location of the wreck, but historians know exactly what happened to the HMS Tarpon.
The submarine was dispatched from Rosyth, Fife, in order to attack German merchant ships that were supplying arms to Nazi-occupied Norway. German war records show that the British sub attacked the Q-ship Schiff 40/Schürbek, but its torpedoes missed their mark. The German ship then managed to pick up the Tarpon on its sonar, and its periscope was spotted. The Schürbek dropped batches of depth charges in a sustained attack that lasted the duration of the morning. Finally, a calculated series of depth charges struck the ill-fated submarine, causing debris to float to the surface. 50 British crewmen were killed in the attack.


Remarkably, the wreck of the Tarpon still bears witness to this account. Danish divers who recently visited the site observed open hatches, shattered glass in the periscope, and severe destruction below the tower where the depth charge struck. McCartney said the damage was so severe behind the conning tower that “it would have flooded in seconds.” Also, two of the sub’s torpedo tubes were empty, showing that the Tarpon did in fact engage the Schürbek in battle. And incredibly, the divers observed a crater on the seabed, which was formed by one of the powerful depth charges.

Today, the Tarpon sits almost upright under 130 feet (40 meters) of water. The challenge now, say its discoverers, is to protect the historic site from threats, such as fishing trawlers and illegal metal reclaimers. In respect for the dead, no further diving missions are planned.
[Guardian]
An incredible 19,000 light years away, in the Sagittarius constellation, lies a brilliant star cluster unlike any other. A new analysis indicates that Terzan 5 is a “fossil relic” from the formation of the Milky Way—and it could help us piece together our cosmic origin story.
For 40 years, Terzan 5 was taken for a globular cluster, a brilliant region of gravitationally-bound space that packs thousands of stars into the distance between our Sun and Alpha Centauri. But after scouring data on this patch of sky collected with the European Southern Observatory’s Very Large Telescope and space-based companions, an Italian-led team of astronomers has learned it’s like no globular cluster ever studied before.
Globular clusters are ancient—nearly as old as the galaxy itself—and their stars tend to form in a single, brief burst of cosmic time. Terzan 5, however, contains two distinct populations of stars. The dominant population formed some 12 billion years ago, consistent with the age of most known globular clusters. But a second population didn’t form until seven billion years later, around the same time as our Sun.


The higher metal content of the younger generation indicates these stars were polluted with heavy elements generated during supernovae explosions from the older generation. “No genuine globular cluster was able to retain the gas ejected by supernovae,” lead study author Francesco Ferraro told Gizmodo in an email.
As Ferraro and his colleagues write in a new scientific paper, this unusual situation makes Terzan 5 an ideal representative of a key stage in the formation of our galaxy and many others—the assembly of a densely packed, central core known as the “galactic bulge.”


Theory indicates that the formation of the Milky Way’s bulge, some 12 billion years ago, relied on the interaction between enormous clumps of gas and stars, which merged and dissolved in the process. Astronomers have observed this interaction taking place in faraway galaxies at high redshifts.
The size of Terzan 5's second population of stars tells us that a tremendous amount of gas was present in this patch of space during bulge assembly. What’s more, the supernovae explosions required to infuse the younger stars with heavy metals would have ejected a large amount of material out of the system entirely. Taken together, the evidence indicates that when the Milky Way’s bulge was forming, Terzan 5 would have been 500 to 1,000 times heavier than it is today. It was a monster in the sky, laden with primordial gas.


“[Terzan 5] is the relic of a structure that was much more massive in the past: a fossil of the epoch of the galaxy formation,” Ferraro said. “Such galactic fossils allow us to reconstruct an important piece of history of our Milky Way.”
Ferrano and his co-authors are now conducting an extensive search for other stellar systems similar to Terzan 5, which could help us learn more about how our galaxy, and others like it, assembled. Like archaeologists sifting through dust to unearth clues about past civilizations, astronomers are now sifting through layers of information encoded in starlight. The history books are going get a lot longer as a result.
Despite the name “canned air,” computer duster isn’t oxygen at all. It’s actually 1,1-Difluoroethane kept under pressure in its liquid form and released as a freezing cold gas. It can cause moderate frostbite. It can get you high if you huff it (but don’t do that—it’s a truly awful idea.) And it makes boiling water explode. Wait, what?
The easy hypothesis is that the temperature difference between boiling water and liquid 1,1-Difluoroethane causes the duster to rapidly and violently covert into its gaseous state. But TheBackyardScientist gave the same experiment a shot with liquid nitrogen and liquid butane. No dice. To make matters stranger, butane has an even lower boiling point than duster.


So what gives? The Backyard Scientist speculates it has something to do with duster and water both being polar molecules, while nitrogen and butane are not. I’m no scientist, backyard or otherwise. All I know is that if I were planning on making boiling water explode, shorts wouldn’t be my first choice of clothing.
Feel free to speculate on matter scientific and otherwise in the comments.

After 172 days in space, three astronauts are heading back to Earth tonight. For NASA astronaut Jeff Williams, this brings his total days in space to 534 days across his four missions, the most an American astronaut has ever spent in space.
The previous record holder, NASA’s Scott Kelly had spent 522 days in space when he returned to Earth last year. In addition to Williams, Roscomos Alexey Ovchinin and Oleg Skripochka are also on their way back from the ISS tonight.


The return-bound Soyuz spacecraft will land at 9:14 p.m. EDT tonight in Kazakhstan. But if you turn in early at 8:21 pm, you can also watch the de-orbiting burn of the craft right here.

Hurricane Newton is currently making landfall near Baja California in Mexico. The Category 1 tropical storm—the fifteenth of the season—is churning winds up to 115 mph (185 km/hr), and has already resulted in flooding along the Pacific west coast.
Earlier today, a Hurricane Warning was issued along a swath from Cabo San Lazaro to Mulege, including Cabo San Lucas, and from Guaymas to Bahia Kino, Mexico. At 11:00 am EDT/8:00 am PDT, the hurricane was located about 110 miles (180 km) northwest of Caba San Lucas and 50 miles (80 km) west of La Paz, Mexico.

Newton is expected to produce heavy rainfall over a long distance—from Baja California, Mexico all the way to the US southwest. The National Hurricane Center is predicting total rain accumulations of eight to 12 inches over the Mexican state of Baja California Sur, and five to 10 inches over Sinaloa, Sonora, western Nayarit, and Jalisco.
The outer rainband of the hurricane has already wreaked havoc in Mexico. In Guerrero, nearly 700 homes were flooded and 12 communities isolated, resulting in the mobilization of 817 troops to help with the clean-up. At least three deaths are being blamed on the storm system.
Newton is expected to weaken once it makes landfall later today, but officials warn of life-threatening flash floods and mud slides, particularly in mountainous areas. Americans living in Arizona and New Mexico could also feel the effects of Newton, and are being advised to stay tuned to local weather conditions.


[NASA]
Add this to the growing list of reasons to never go outside again: the human brain is apparently a sponge for toxic magnetic waste found in smog.
That’s according to research published this week in the Proceedings of the National Academies of Sciences, which examined the brain tissue of 37 individuals age three to 92 living in the UK and Mexico City. The study found that extraordinarily high levels of magnetite, an iron nanoparticle that has been indirectly linked to neurodegenerative diseases including Alzheimer’s. While biologically-produced magnetite crystals were also found in the patients’ brains, small, perfectly spherical iron particles outnumbered natural magnetite roughly 100 to one.
By carefully examining the particles using electron microscopy, atmospheric scientist Barbara Maher and her colleagues discovered they are precisely the same form of magnetite found in air pollution. It’s the first time this common air-borne pollutant has been directly associated with the human brain.


“These are tiny, tiny little particles—they’re only about the size of a virus,” study co-author David Allsop, a biologist at Lancaster University told Gizmodo. “If you breathe them up through your nose, they’re going to bypass the blood brain barrier and enter the brain quite readily.”
Magnetite nanoparticles are emitted to the air via car exhaust, power plant smokestacks, and pretty much any other industrial, fossil fuel-burning process. “Most fuels will have a bit of iron as an impurity,” Maher explained. “When you have enough heat and a source of iron, you get these very distinctive molten droplets. If they cool quickly enough, they keep that shape.”
According to Maher, the particles are found everywhere: “I haven’t made any measurements of a roadside where they haven’t shown up,” she put it. And at less than 200 nanometers in diameter, they’re far too small to be filtered by a breathing mask, making it nigh impossible for urban residents to avoid some level of exposure.


How much of a danger magnetite nanoparticles pose has yet to be determined, but there is reason to be concerned. They are part of a family of metals that produces reactive oxygen species on contact with organic tissues. “Reactive oxygen species damage the brain,” Allsop said. “There’s already evidence for this specific type of damage in Alzheimer’s, possibly very early in the course of the disease.”
Allsop added that some of the young brains examined in the study showed changes that look like the early stages of Alzheimer’s, supporting the notion that magnetic nanoparticles can cause cellular damage consistent with what we see in dementia. “This is not the last word at all, but it does mean we have to progress the research now,” Maher said.


Of course, we already knew that air pollution is terrible—it accounts for some 5.5 million premature deaths each year by contributing to asthma, heart and lung diseases. Whether or not magnetic waste on the brain should be our top concern as far as dirty air goes, the discovery offers a timely reminder that cleaning up our atmosphere won’t just help the planet, it will save lives.
[PNAS]
Researchers at the University of California San Diego have taken a significant step forward in the effort to develop a vaccine against the bacteria responsible for strep throat, toxic shock syndrome, and flesh-eating disease.
Group A Streptococcus, or group A strep, are nasty breed of bacteria that can cause an assortment of infections. Most group A strep infections are relatively mild, such as strep throat and the impetigo skin infection, but occasionally these bacteria go on to cause more serious and even life threatening conditions, such as toxic shock syndrome and necrotizing fasciitis, or “flesh-eating disease.” According to the CDC, around 500,000 people die each year from this bacteria, prompting researchers to find novel ways of staving off these dreaded germs.
You first notice a bump — a tender, cherry red bruise. Over the next 12 hours, the center of this…
In a new study published in Nature Microbiology, a group of researchers from the University of California San Diego have detected previously unseen patterns in the outer protein coat of group A strep. These hidden sequence patterns, called the M protein, limit the body’s immune response against these bacteria. It’s an important piece of insight that shows why the human body is so vulnerable to this bacteria—and how we might be able to develop a vaccine to compensate.


“When we become infected with a particular strain of group A Strep, we generally mount an immune response against the particular M protein displayed by that strain,” explained lead researcher Partho Ghosh in a statement. “But this immunity works only against the infecting strain.”
Ghosh says the bacteria mounts a disguise, leaving us vulnerable to infection by other group A strep strains with other types of M proteins. “This is because the antibody response against the M protein is almost always specific to the sequence of that M protein, and M proteins of different types appear to be unrelated in sequence to one another,” Gosh said.
Insidiously, strep A bacteria uses our own body against us, recruiting a human protein called C4BP which tricks the body into calling off an immune response. But practically all M proteins can bind to C4BP, so if the researchers can develop an antibody that does the same thing, they will have found a way to destroy the otherwise invisible bacteria.


To see if this is indeed possible, the researchers conducted an experimental computational study. The biochemists recreated four crystal structures of four different M proteins—and like lego blocks, each of these structures attached themselves to human C4BP.
“The idea now is to have antibodies do the same thing as C4BP—that is, recognize many different M protein types,” said Ghosh. Assuming this can be done, the researchers will engineer an antibody response that’s not limited to one M protein and one strain of group A strep. And in fact, it could extend to practically all M protein types and strains of group A strep.


It may be years, if ever, before we see this vaccine reach the market. Until then, we can do some practical things to help prevent group A infections. The CDC recommends hand washing, especially after coughing and sneezing, and before preparing foods or eating. People with sore throats should visit their doctor, and if the tests reveal strep, they should stay home from school or work at least 24 hours after starting antibiotics. As for wounds, they should be kept immaculately clean and observed for signs of infection, such as redness, swelling, drainage, and pain. Should any of these signs appear, it’s advised that you see a doctor immediately.
[Nature Microbiology]
Isabelle Dinoire, the woman who received the world’s first partial face transplant with a new nose, chin and mouth, has passed away.
Dinoire suffered catastrophic injuries to her face in May 2005 after her Labrador attacked her while she was sleeping. Less than a year later, she received a partial face transplant—the world’s first and a procedure that drew international attention and acclaim. The surgeons declared it a success but Dinoire struggled over the years as her body never fully accepted the new nose, chin, and mouth, which came from a donor.


Dinoire had been taking powerful immunosuppressant drugs for years, but she became ill last winter after her body rejected a new skin graft, causing her to lose some function in her lips. What’s more, the anti-rejection treatments appeared to have triggered two different cancers. She died on April 22, 2016 at the age of 49, but her death was only announced by the hospital in Amiens, France, earlier today. It’s not entirely clear why it took hospital officials so long to make the news public.
Dinoire’s death is a significant setback in the effort to help people who have lost portions of their face to disease or injury. Some critics contend that such “non-elective” surgeries are wasteful and dangerous.


“From the day of the operation I have a face like everyone else,” said Dinoire after her operation. “I can open my mouth and eat. Recently, I feel my lips, my nose and my mouth.”
A firefighter from Mississippi whose face became disfigured during a rescue attempt is the…
Undoubtedly, Dinoire’s death won’t come in vain. It’s through pioneering work like this—and those who are brave enough to be on the receiving end—that progress is made in the medical sciences.


[The Local, Mirror]
We eat fish and throw away the scales. But now researchers have figured out a reason those fish scales might be worth saving.
A new paper out in Applied Physics Letters today details a method for transforming fish scales into an energy harvester. Researchers processed the raw scales to make them flexible and then attached two electrodes to each scale before laminating it. The resulting cell could then harvest energy from movement around it, including motion as simple as just vibrations or even a heartbeat. This has researchers suggesting that they could one day use it to power things like pacemakers.


“In the future, our goal is to implant a bio-piezoelectric nanogenerator into a heart for pacemaker devices, where it will continuously generate power from heartbeats for the device’s operation,” co-author of the paper Dipankar Mandal of Jadavpur University explained in a statement. “Then it will degrade when no longer needed.”
That particular application is fairly far off, but the research is an important reminder that there may be a better use for the incredible amount of food waste we’re generating—140 trillion calories  every year in the US alone. A lot of that wasted food is readily-edible stuff that just gets tossed. But there are also inedible byproducts like fish scales and orange peels that could be put to productive use with a little creativity.


“The fish scale is available in large quantity in our society because it is basically bio-waste component and thrown away in food processing,” co-author Sujoy Kumar Ghosh told Gizmodo. To get the scales they used, the researchers simply collected them from a local fish market. Not only is figuring out how to use non-edible food waste for other purposes cost-effective, it gives us a way to use even the parts of food we don’t eat.


[Applied Physics Letters]
Researchers from Rice University say that around 4.4 billion years ago, a Mercury-like planet smashed into Earth, seeding our primordial planet with life-giving carbon. Had this never occurred, it’s an open question as to whether or not life could have ever emerged.
Geoscientists have struggled to explain how life was able to arise on Earth given that most of the planet’s carbon—an important prerequisite for life—should have either boiled away during the planet’s earliest stages or become trapped within the Earth’s core. By conducting high-pressure and high-temperature experiments in the lab, researchers from Rice University have concluded that virtually all of our planet’s carbon likely arrived when a Mercury-like planet smashed into the young Earth some 4.4 billion years ago.


Scientists aren’t entirely sure how Earth’s volatile elements, such as carbon, hydrogen, nitrogen, and sulfur, were able to remain outside the Earth’s core and stay locked within the mantle. Models show that most of our planet’s carbon should have vaporized into space, or ended up in the metallic core of our planet, sucked up by its iron-rich alloys.
Prior to the new study, many scientists speculated that these volatile elements came to Earth after our planet’s core finished forming. As Rice University geoscientist and study co-author Yuan Li pointed out in a statement, “Any of those elements that fell to Earth in meteorites and comets more than about 100 million years after the solar system formed could have avoided the intense heat of the magma ocean that covered Earth up to that point.” Trouble is, there are no known meteorites capable of producing the required ratio of volatile elements.Three years ago, Li and his colleagues began to take a different approach to the problem. They conducted a series of experiments to assess how carbon’s affinity for iron may have been altered by other compounds present in the Earth’s early environment. Importantly, they considered the potential role of other celestial bodies with characteristically different chemical compositions.


“We thought we definitely needed to break away from the conventional core composition of just iron and nickel and carbon,” noted study co-author Rajdeep Dasgupta. “So we began exploring very sulfur-rich and silicon-rich alloys, in part because the core of Mars is thought to be sulfur-rich and the core of Mercury is thought to be relatively silicon-rich.”
Their experiments recreated the high-pressure and high-temperature conditions found deep inside the Earth and other rocky planets. Results showed that carbon could be excluded from the core and relegated to the Earth’s mantle, provided that the iron alloys in the core were rich in either silicon or sulfur. One scenario that explains this particular ratio is that an embryonic planet—one that already formed a silicon-rich core—slammed into Earth, and was absorbed by Earth.


“Because it’s a massive body, the dynamics could work in a way that the core of that planet would go directly to the core of our planet, and the carbon-rich mantle would mix with Earth’s mantle,” said Gupta.
The researchers say this collision likely happened about 4.4 billion years ago, which is only about 150 to 200 million years after the Earth formed. With carbon locked within the crust, and with the planet settling down to produce habitable conditions, life soon emerged. Indeed, the most recent estimates suggest that microbial life formed approximately 4.1 billion years ago.
Researchers working in Greenland have found traces of microbial life in our planet’s most ancient…
It’s important to point out that evidence for this primordial collision is circumstantial as best. The researchers agree that more work is needed to support this theory, including analyses of abundant elements other than carbon. If true, however, it could mean that Earth only became a habitable oasis only after this tremendous cosmic smashup. Carbon forms a key component of all known life on Earth; complex molecules are comprised of carbon bonded with other elements, such as oxygen, hydrogen, and nitrogen.


Regardless, the theory makes you wonder about life on other planets, and how specific the conditions need to be for life to finally emerge on dead, rocky worlds.
[Nature Geoscience]
Hordes of lionfish have been roaming the Atlantic for several decades now, and their voracious appetite—and lack of natural predators—has seriously upset the ecological balance of those waters. Now there’s a new foundation devoted to building robots to hunt them down—a Terminator for lionfish.
The prototypes under development are technically cousins to robotic vacuum cleaners, because iRobot CEO Colin Angle is one of the founders of Robots in the Service of the Environment (RISE). He and his wife, biochemist Erika Ebbel, were visiting friends in Bermuda, and the group went diving one day, along with a marine specimen collector named Chris Flook. It was Flook who regaled the group with stories of the invasive lionfish, and RISE was born.


Lionfish have been dubbed “Darwin’s nightmare” because of their tremendous adaptability. They are flexible in what they eat, they can thrive in many different environments (salt water or fresh, cold water or warm), and they reproduce like crazy, all year round, rather than having a particular breeding season. Plus they have venomous spikes, discouraging potential predators from eating them in turn.
That makes lionfish a particularly problematic invasive species. Originally from the Indo-Pacific region, the bright stripes and frilly fins of the lionfish made it a popular choice for exotic pet owners. Those same owners likely dumped adult lionfish into public waters in the mid-1980s, and the species reproduced like gangbusters, with devastating ecological results.
In the Bahamas, for instance, lionfish devoured parrotfish and other smaller species that consume plants, the better to keep algae growth in check. Without them, algae bloomed freely and choked the coral reef ecosystems.


“The only thing that we can do is try to eat them,” marine biologist Christie Wilcox—author of a new book called Venomous: How Earth’s Deadliest Creatures Mastered Biochemistry—told Gizmodo. Because they are venomous—as opposed to poisonous—they are perfectly edible. “Lionfish venom is largely proteins, which are easily denatured [when cooked],” said Wilcox, and you can even eat them uncooked, as in a ceviche. “As long as you don’t stab yourself along the way, you can theoretically swallow a spine freshly cut from a lionfish and be fine.” She’s sampled lionfish herself, in various preparations. “It’s a flaky, white, sort of sweet fish,” she said.
There’s definitely a growing market for lionfish: Whole Foods sells fillets in certain geographical areas, as do several sea-to-table restaurants in Florida and North Carolina, in particular. But lionfish have to be speared by hand; they lurk in coral reefs, avoiding dragging nets, and they don’t fall for the old bait-on-a-hook trick of pole fishing, either. Spearing them one by one is the only option-and that’s a tedious and time-consuming process.
That’s where RISE’s prototype robotic harvesters can help. The first model uses a pressure-powered spear gun to humanely hunt lionfish, which should start field tests this month. A second prototype is designed to zap the lionfish with electricity, thanks to a robotic arm rigged out with two metal electrodes. “When the probes get to either side of the fish, you basically zap it,” RISE executive director Joe Rizzo told PBS Newshour.
The two prototypes include video cameras, so that pilots can guide the robots through the water, but the ultimate goal is to build autonomous underwater robots to hunt lionfish.

[Nanowerk News]
The European Space Agency lost contact with its Rosetta mission’s plucky little lander, Philae, in May 2015. Now the orbiter’s high-resolution camera has found Philae wedged into a dark crack on the surface of Comet 67P/Churyumov-Gerasimenko.
Landing a small craft on a moving comet was always an incredibly ambitious mission, but the Rosetta team pulled it off in November 2014, with a few hiccups that ultimately resulted in losing contact with Philae. As Gizmodo’s Maddie Stone reported in January:
When the lander touched down in November of 2014, it bounced twice, and wound up in the dark shadow of a cliff. Without enough sunlight to charge its solar panels, Philae quickly exhausted its power supply. Within 57 hours, it had fallen silent.
Six months later, as Comet 67P approached the sun, Philae briefly woke from its slumber and phoned home. Then, it went quiet again. The DLR’s Philae team hasn’t heard a peep since.
Rosetta’s scientists could only narrow the range of Philae’s final resting place based on radio ranging data from its final transmissions. But while they found a few possible locations, the images were not of sufficiently high resolution to confirm with confidence that the lander had been found.


On September 2, Rosetta’s orbit passed sufficiently closet the comet’s surface for its Osiris narrow-angle camera to capture a high-resolution image of the lander’s body and two of its three legs:
As Comet 67P/C-G heads away from the sun and towards the orbit of Jupiter, there will be less and less solar energy available to power Rosetta and its instruments. So mission planners will crash the probe into the comet in a slow, controlled descent on September 30th. All the while, Rosetta’s instruments will be feverishly collecting and transmitting data, hopefully giving up some spectacular close-up shots of this extraordinary comet.

Lasers are behind so much of our cutting-edge technology. Now scientists at the University of Michigan have successfully shown that is possible to build a working laser with blood, the better to spot tumors in the human body.
A laser is technically defined as any device that creates and amplifies a narrow, focused beam of light whose photos are all traveling in the same direction, rather than in every direction at once, like the light emitted by, say, a flashlight. There are many different types of lasers, from the semiconductor lasers found in laser pointers and DVD players, to CO2 lasers capable of melting through objects. (These were no doubt the type coveted by Dr. Evil when he demanded “sharks with frickin’ laser beams” on their heads in the first Austin Powers movie.)
All you need to build a laser is an empty cavity holding two mirrors on either end—one of which should be half-silvered, so that it reflects some light but lets other light through—and a lasing medium. The latter medium can be a crystal, like ruby or garnet, or some kind of gas or liquid. Really, almost anything that can be made to emit light will do. Pioneering laser scientists Theodor Hänsch and Arthur Schawlow even created the first edible laser out of Jell-O around 1970, trying out 12 different flavors before finding just the right one.


Zap the medium with light or electricity boosts the atoms to higher energy levels—an “excited” state. Then photons are pumped into the cavity. If one strikes an excited atom, that atom will drop back down to its ground state, releasing a second photon of the same frequency and direction. These in turn strike other energized atoms, releasing even more photons. The end result is a sudden burst of coherent light—the laser beam—as all the atoms discharge in a rapid chain reaction. It’s called stimulated emission, and yes, we’ve heard all the dirty jokes before.
In recent years, scientists have figured out how to turn individual cells into functioning lasers, injecting fatty cells in pig skin with fluorescent dye and zapping them with lasers to get them to emit light. In 2011, Harvard scientists built a laser out of a human kidney cell injected with DNA coding for a green fluorescent protein typically found in jellyfish. And the same team of Michigan scientists figured out how to turn the light-sensitive chlorophyll in plants into laser beams earlier this year.
Now Xudong Fan and his Ann Arbor colleagues are back with a new study using a fluorescent dye commonly injected into the bloodstream for medical imaging: indocyanine green (ICG). It’s the combination of the dye binding with proteins in blood plasma that results in the blood emitting light—essentially amplifying the emission and turning your blood into a lasing medium.


Because the dye accumulates in blood vessels, and tumors usually have lots of them, the technique should make it easier to spot tumors in the body. Just inject a bit of ICG and shine a laser onto the skin, using an infrared camera to capture any resulting glow. Fan and his colleagues still need to test the concept in animal tissue. But so far, the blood laser seems promising.
[New Scientist]
Until Hermine blew through the Florida Panhandle and up into Georgia, Florida had experienced a pleasant, hurricane-free few years. In fact, as The Weather Channel noted, Florida went nearly eleven years without a single hurricane making landfall.
The last hurricane to set foot in Florida was Hurricane Wilma, a Category 3 storm that made landfall in south Florida back on October 24, 2005. Since then 68 Atlantic-based hurricanes have skipped the Sunshine State—more than twice the previous record of hurricanes.

That’s alarming as, according to the National Hurricane Center, 40-percent of Atlantic and Gulf-based hurricanes from 1851-2010 affected Florida. The state has more coastline than any other state touching the Gulf of Mexico or the Atlantic, so the odds were never in Florida’s favor.


Yet there’s no precise reason why Florida’s hurricane drought lasted so long. Each case of a hurricane skipping the state was entirely unique.
While the hurricane drought lasted a record shattering 11 years, Florida was not without its storms. Nine different tropical storms have touched down in Florida sense Hurricane Wilma.
[The Weather Channel]
If you’re taking advantage of the long holiday weekend to visit your favorite theme park, take a moment to learn a little about the underlying physics of roller coasters, via the latest video from the folks at SciShow.
All roller coasters basically involve Newtonian physics 101: inertia, gravity, acceleration, and friction. The higher the train rises, the greater the distance gravity must pull it back down, and the greater the resulting speeds. A roller coaster is constantly shifting between potential and kinetic energy, and the constant variation in forces is part of what makes riding a roller coaster so exhilarating.


This is pretty familiar ground. But SciShow host Michael Aranda also goes into some cool details about the hydraulic launch systems used in today’s coasters, as well as the permanent magnets used in cutting-edge braking systems (as opposed to the standard friction braking).
Just something to ponder when you’re momentarily hanging in free fall at the top of your favorite coaster.

[Laughing Squid]
Oklahoma was hit with an earthquake yesterday, its second 5.0+ quake this year. The increased number of earthquakes have been linked to the use of hydraulic fracturing, or fracking—specifically the underground disposal wells where the run off from fracking is stored. The Oklahoma Corporation Commission has taken note of the relationship between the quakes and the wells and has ordered the shutdown of 35 disposal wells.
“This is a mandatory directive,” Oklahoma governor Mary Fallin told CNN.


In February, after a large earthquake shook the state in January, the Oklahoma Corporation Commission cut back on the planned number of wells produced via fracking. Clearly that did not seem to do the trick, which is why Fallin and company are instituting this new shut down.
Fracking is inextricably linked to Oklahoma, which was the site of the first test of fracking back in 1968. But in the last twenty years fracking has become increasingly common. In 1998 a new fracking technique was developed in North Texas that allowed companies to extract natural gas from shale very cheaply.


Since then use of the technique, which shoots water and chemicals into the shale to forcibly move natural gas up and out into containers above ground, has exploded. From Canada to Texas it is the preferred method of natural gas extraction.


But shooting all that water into the shale makes normally very stable rocks very slippery. And slippery rocks means a lot of movement. That’s where Oklahoma’s recent rash of earthquakes are coming from.
[CNN]
Yeah, we know, your CrossFit gym has completely changed your life, you’ve never looked/felt better, and all other exercise programs pale in comparison. But you may want to ease off the intensive workouts now and then. All that over-exertion can actually impair your immune system, according to a new study just published in Frontiers in Physiology.
CrossFit, for the uninitiated, is a grueling exercise program combining high-intensity cardio workouts with strength training, organized into circuits. The idea is to complete as many reps as possible in the allotted time, with little to no recovery time, and to vary the workouts constantly so your muscles don’t become too accustomed to any particular exercise.
It’s attracted a reasonably sized, extremely vocal and enthusiastic—and sometimes annoying—fan base since its introduction in 2000. Even Game of Thrones’ Jon Snow (and world’s worst dinner guest) is a confessed fan: “The high intensity interval training keeps me in shape for fighting wildlings, while the increased muscle mass helps me defend the seven kingdoms against 55-foot giants.”


But there’s a dark side to CrossFit. Too much exercise can be just as harmful to your health as too little. That hardcore culture of “deplete-endure-repeat” can lead to a rare condition known as Rhabdomyolsis (“rhabdo” for short). Basically, extreme exertion can cause muscle cells to explode, leaching proteins into the bloodstream—a place they really shouldn’t be. The kidneys have to work overtime to remove those proteins, and can become badly damaged.
Even if your kidneys recover, your muscles might not ever be the same, because the damaged muscle tissue has been replaced by fatty scar tissue. Do all the military pushups you want, your triceps will still be flabby.
The good news is that relatively few CrossFit enthusiasts train hard enough to develop rhabdo. But a team of Brazilian researchers has identified another health risk of over-training: a weakened immune system.


The scientists recruited a group of experienced CrossFit enthusiasts to perform two consecutive days of intense workouts, finishing in the fastest time possible. Afterward, they assessed the participants’ muscle power, and levels of metabolic markers and anti-inflammatory proteins produced by white blood cells.


They found that too many consecutive CrossFit workouts, with no rest periods, can significantly reduce the number of anti-inflammatory proteins, resulting in a suppressed immune system. On the plus side, the workouts didn’t appear to have much of an adverse effect on overall muscle power.
What do these findings mean for your CrossFit habit?
“For non-athlete subjects who want to improve their health and quality of life through CrossFit training, we recommend that they decrease their training volume after two consecutive days of high-intensity training to prevent possible immunosuppression,” lead author Ramires Tibana of the Catholic University of Brasilia said in a statement. “A rest day is important for recovery for subsequent training sessions.”
So put down that kettle bell and give yourself a break from your Crossfit regime this weekend. Your body will thank you. And you can hit the gym with renewed gusto the day after.
[Frontiers in Physiology]
Eat them while you can, people. Pistachios are about to become a whole lot less available.
The USDA recently released a report showing that the United States, one of the world’s two main pistachio producers, would cut the number of pistachios it harvested by nearly half this year, due mainly to California’s punishing drought. This means a loss of over 100,000 tons of pistachios in the U.S. alone—an amount equal to nearly a fifth of the world’s entire 520,000 ton pistachio crop for this year.


Now, a worsening drought in Iran, the other top producer of pistachios in the world, has farmers there predicting that their pistachio harvest is also going to continue to fall dramatically—perhaps even further than the 20,000-ton drop that was already predicted for this year.
USDA says worldwide we’re going to lose 86,000 tons of pistachios this year. That figure sounds unsettlingly big, but the losses would look heavier yet if Turkey hadn’t had a surprise bumper crop which nearly tripled its expected harvest. Even that anomaly, though, still wasn’t enough to offset the loses.


Pistachios join chocolate, red wine, IPAs, salmon, coffee, almonds, and so much more on the list of foods that are going to get harder to come by in our hotter and drier world. On the plus side, however, the world market for edible insects continues to grow.
Sometimes in life, you get lucky and end up living in a normal ant colony. But sometimes, you find yourself shit out of luck, living out your days in a cold, dark abandoned Soviet bunker.
Such is the case for a “colony” of wood-ants in Western Poland. According to research recently published in the Journal of Hymenoptera Research, using the term “colony” is even a bit of a stretch, because the demonstrated characteristics of the gathering—a lack of offspring, no queens, barely any food—“is a far cry from a fully functional colony.”


The ants were accidentally discovered in 2013 while researchers were busy looking for bats. The colony, the intrepid explorers realized, was actually a kind of ant underworld—it was populated by ants who had fallen through a hole in the middle of another, more normally-functioning colony above. While the ants were able to crawl around the bunker, they weren’t able to escape back up into the hole from which they came.
Down below, in an abandoned chamber of the bunker—originally built to house nuclear weapons—the bizarro ants had constructed an “irregularly shaped” earthen mound. All around the mound, the researchers reported, was a “carpet” of an estimated two million dead ants.


Given the brutal conditions of the bunker—pitch black, freezing cold, isolated from the natural world—it’s not surprising that a bunch of these poor suckers didn’t make it. The researchers haven’t yet managed to pinpoint a definite food source for the ants, though they hypothesized that bat poop and small mites might help. Either way, it’s not nearly enough to sustain an entire colony—but that’s where the lucky ants above come in.
“The continued survival of the ‘colony’ through the years is dependent on new workers falling in through the ventilation pipe,” researchers wrote. “The supplement of workers more than compensates for the mortality rate of workers such that through the years the bunker workforce has grown to the level of big, mature natural colonies.”
“The wood-ant ‘colony’ described here ... is an example of survival of a large amount of workers trapped within a hostile environment,” the researchers conclude.
The whole thing sounds like the skin-crawling plot to a horror movie, but if and when the apocalypse ever comes, you can bet they’ll manage to survive for a little while.


[Popular Mechanics]
We’ve all been frustrated by city traffic, waiting in a long line of cars for the light to change at an intersection. And then the stupid light turns red again before we can make it through because the cars ahead of us took so long to get going.
A new video by CPG Grey deftly explains what’s going on. Basically, intersections are bad for traffic because they inevitably lead to so-called phantom traffic jams

The problem: densely packed cars become “highly correlated,” meaning that they move in unison. This creates a feedback mechanism in which a tiny perturbation—a single driver braking unexpectedly—will send little ripples of corresponding slowdowns through the entire chain of cars behind him/her. CPG Grey colorfully likens it to a “traffic snake slithering down the road eating incoming cars at one end and pooping them out the other.”


There’s a simple solution: if every driver makes sure he or she maintains the exact same distance between the cars in front and back—no tailgating like a big old jerk!—those tiny fluctuations smooth out and that phantom jam is less likely to develop.
Alas, human beings are basically “monkey drivers with slow reaction times and short attention spans,” not to mention stubborn creatures of habit Getting everyone to change their behavior and coordinate with each other so precisely is pretty much impossible.


A better solution, per the video, is self-driving cars, programmed to maintain those ideal distances between other vehicles at all times. They could even communicate with others wirelessly, removing the need for traffic lights altogether.
That’s right: ban humans, not cars. In Grey’s words, “No more monkeys driving cars.”


[Twisted Sifter]
The star system Eta Carinae has puzzled astronomers for centuries because of its oddly variable brightness—as bright as a supernova explosion at one point in the 19th century. Now astronomers from the University of Arizona have determined that there were at least two earlier explosions in the star’s long history, making this a very strange star system indeed.
A star can go supernova in a couple of ways. If it’s massive enough, when its fuel runs out—i.e., the nuclear reactions at its core stop—there is no longer sufficient internal pressure to keep the star from collapsing in on itself. When the outer layers hit the core, they explode outward, spewing debris into the surrounding space. Alternatively, matter can pile up onto a white dwarf star, until it gets so dense it triggers an explosion.


Eta Carinae doesn’t fit either scenario. In the mid-1800s, Eta Carinae got so bright it outshone most of the other stars in the night sky, before fading away. That’s the hallmark of a supernova, and the gas and debris produced in that so-called Great Eruption formed the Homonculus nebula. Except Eta Carinae didn’t stay “dead.” It got brighter around 1890, and again in 1953, and abruptly doubled in brightness in 1998-1999.
What the hell is going on?


“Eta Carinae is what we call a supernova impostor,” Megan Kiminki, a graduate student at the University of Arizona, said in a statement. “The star became very bright as it blew off a lot of material [in the 1800s], but it was still there.” She is a co-author of a new paper in the Monthly Notices of the Royal Astronomical Society detailing these new findings.
Along with her professor, Nathan Smith, and Megan Reiter, a postdoct at the University of Michigan, Kiminki pored over images of the star system taken by the Hubble Space Telescope over the last two decades.
At first they were just measuring the motions of streams of matter being ejected from new stars forming in the Carina nebula. Then they realized the same approach could be used to measure how fast the debris ejected by the star system itself was moving. All those glowing gases of the surrounding nebula make it tough to really see what’s going on. By measuring how fast those gassy clouds are expanding, the team could ferret out valuable clues about the star system’s history.
Specifically, they tracked the movement of around 800 blobs of gas by aligning various images taken at different time periods, and calculating a likely date for the eruption that produced each one. “This is a bit like reconstructing the eruption history of a volcano by discovering ancient lava flows,” said Smith.


It turns out to be quite a violent history. The Arizona team found evidence of two earlier eruptions: namely, the gas that was further away from the Homonculus nebula was moving more slowly than the debris closer in. That means it must have been produced by earlier eruptions, in the 13th and 16th centuries, respectively.
They also determined that Eta Carinae seems to be a binary system, with two massive stars orbiting each other every five-and-a-half years or so—and the larger of the two seems to be in the last throes of life. “We found one of the prior eruptions was... at a totally different angle from the axis of the Great Eruption,” said Kiminki. “The oldest eruption was very one-sided, suggesting two stars were involved, because it would be very unlikely for one star to blow material out onward just one side.”


Exactly what caused the Great Eruption in the 1800s remains a mystery, but the fact that it wasn’t an isolated event adds an important piece to the puzzle. And this discovery is consistent with a subclass of supernova explosions, whereby massive dying stars experience a series of violent eruptions before finally going supernova. In fact, Eta Carinae may have done so already—it takes 7000 years for light to reach us from that region of space.
[Monthly Notices of the Royal Astronomical Society via arXiv]
Scientists working in British Columbia have uncovered the fossils of a small Cretaceous-era pterosaur, showing this extinct flying reptile came in travel size.
Pterosaurs are an extinct group of flying reptiles that were extremely well adapted to flight. Most featured impressive wingspans, extending to between 13 to 36 feet (4 to 11 meters). Incredibly, the largest pterosaur was the size of a giraffe, boasting a wingspan of a small plane.
But the recent discovery of a tiny, cat-sized pterosaur in British Columbia shows that these flying reptiles also came in a pint-sized version. A new study published in Royal Society Open Science describes a rare, small-bodied pterosaur that had a wingspan measuring just 5 feet (1.5 meters). That’s smaller than some condors and pelicans.
Paleontologists don't always speculate about the existence of gigantic, winged reptiles living …
The newly described pterosaur was pieced together from just a few fragments, including a humerus and several fused vertebrae. The researchers, led by Elizabeth Martin-Silverstone from the University of Southampton, categorize it as an “azhdarchoid” pterosaur—a group of short-winged and toothless flying reptiles that represented the final phase of pterosaur evolution.
“The specimen is far from the prettiest or most complete pterosaur fossil you’ll ever see, but it’s still an exciting and significant find.” noted study co-author Mark Witton in a statement. “It’s rare to find pterosaur fossils at all because their skeletons were lightweight and easily damaged once they died, and the small ones are the rarest of all. But luck was on our side and several bones of this animal survived the preservation process.”


The new study shows that flying reptiles were more diverse than previously thought, and that small pterosaurs hadn’t yet been outcompeted by birds during the late Cretaceous some 100 to 66 million years ago. It adds to a growing body of evidence showing that this era wasn’t dominated by large or giant species, and that smaller pterosaurs were well represented during this epoch.
[Royal Society Open Science]
A Hungarian-born man is found ranting in the street that he is “king of the Puerto Ricans.” A perfectly healthy woman feels compelled to undergo over a dozen operations. A man in a straightjacket somehow manages to commit suicide while inside a locked psychiatric ward.
These are just a few of the compelling stories in Mark Rubinstein’s new book, Bedlam’s Door: True Tales of Madness and Hope. (You can read an exclusive excerpt here.) Rubinstein is a former practicing psychiatrist turned novelist who has drawn on his years of clinical experience to follow in the nonfiction footsteps of Oliver Sacks, shedding light on the complexities of the human mind with real stories about real people. Gizmodo sat down with him to learn more.


Gizmodo: What drove you to write this nonfiction book, after years of clinical practice and novel-writing?
Mark Rubinstein: It all came down to my wanting to tell the general public a little bit more about mental illness. When someone has a physical illness, people feel some kind of empathy, but they still respond to an obviously disturbed person with fear. It’s not just your heart, lung, or liver that’s sick—it is you. That is very threatening to people. And people don’t really understand the mental health dilemma, and the issues that mental health practitioners face.
Q: You brought a novelist’s sensibility to these stories, with composite characters and reconstructed dialogue. How much is fiction and how much is nonfiction?


Rubinstein: It is kind of a combination of fiction superimposed on a nonfictional layer of things that really happened. These were all real people and real cases—sometimes a composite of more than one person to protect their privacy. Oliver Sacks was accused of unwittingly giving away the identities of some of the people he wrote about in The Man Who Mistook His Wife for a Hat.
I never wanted to be accused of anything like that, so I changed everything: times, places, people, venues, even races. I didn’t even use a real hospital. Of course, I couldn’t remember all the dialogue from 30 years ago, but I created dialogue consistent with the story line. But these were all real stories and real people from people I had treated. There isn’t a story in there that isn’t true.
But the overarching theme running through most of the stories is that even with the most bizarre cases, if time is taken to listen to these people and understand their stories and background, perhaps we can offer them help. It’s all about storytelling. That’s what novelists do, and in a sense that’s what patients do when they come to see a psychiatrist: they tell a story.
Q: I was struck by your statement that even people who suffer from the same diagnosed condition can have very different stories.
Rubinstein: [Mental illness] can affect almost anybody, given certain circumstances. Some of the most successful people on the planet have a touch of hypomania. I know physicians and attorneys who don’t have full-blown manic episodes but they are filled with boundless energy. They are restless. They feel bored and unhappy unless they are facing a challenge. And they are highly successful. Take that to a more severe degree, however, and it can be completely disabling. And 100 different people can have 100 different pathways to the same diagnosable psychiatric disorder.
You contrast two very different examples of PTSD in the book, for instance.


Rubinstein: In one case, a police officer was shot while sitting in his patrol car outside a store near Tompkins Square Park in New York City. A bullet smashed through the windshield and hit him in the armpit, ruining his brachial plexus—a complicated series of nerves that serves the entire arm. He almost bled to death in the ride to the hospital, and he was crippled for the rest of his life. The depression, the PTSD, the pain he felt in his right arm—the pins and needles and tingling—was directly related to the psychic impact of that half-second of impact.
Then there is the man I call Nathan, found ranting on Delancy Street that he was the king of the Puerto Ricans. He was a carpenter, born in Hungary, and that skill saved his life at Auschwitz. He watched people disappear into the gas chambers—his family, his entire village. He was the sole survivor. But his PTSD didn’t develop until 40 years later, when he was in America and fell off the ladder while working on a roof, breaking some vertebrae in his back. He could no longer work and began having horrifying nightmares. It’s called delayed onset PTSD. So these two men came by totally different pathways to the same condition.
Q: In both your preface and conclusion, you talk about how mental illness has always been stigmatized throughout history. Is it really any different today?


Rubinstein: Well, today we don’t torture people. As recently as the 1950s, they were lobotomizing psychotic patients. They removed a good portion of the white matter of the frontal lobes of the cortex, and turned those people into—for lack of a better term—the walking dead. They became blunted and unresponsive to most emotional stimuli. It was done to try to improve their lot in life, but it shows how primitive things used to be.


When I was in resident psychiatry, the cops would drag a guy in and tell me, “This guy belongs in the loony bin, doc.” Even if the person was just drunk, they wanted to dump these people off in the psychiatric emergency room rather than take them to the precinct. They didn’t want to be bothered with an agitated, fulminating individual who was obviously disturbed.
What’s really changed is there is a much more scientific and compassionate approach. The popular conception of electroconvulsive therapy (ECT) still exists from a famous scene in the 1974 movie One Flew Over the Cuckoo’s Nest—Jack Nicholson with the bulging eyes and convulsions and coming out of it like a vegetable.


But they now use unipolar leads, and very low, slow pulse electricity. They administer muscle relaxants, so there is no convulsion. There is hardly any retrograde amnesia and what little there is resolves with a matter of days. It doesn’t take 12 to 18 sessions anymore, it only takes between four and six.
Q: You end on a somewhat surprising note of optimism, given that these are such very sad stories. I am curious about why you see hope for the future.


Rubinstein: No matter what kind of progress we make, there will always be people slipping through the cracks. There will always be people who either don’t want to be helped, or can’t be helped for some reason. But transcranial magnetic stimulation is a noninvasive new treatment that, so far at least, according to preliminary findings, has tremendously good effects—with no side effects or ingestion of chemicals.
Then there is the promise of gene therapy. At some point in the not too distant future, neuroscience will advance to the point where blood can be taken from a newborn child, and based on that baby’s genome, scientists will be able to predict what mental dysfunctions or illnesses that individual will have a predisposition for. Imagine if you could do that for people with a high risk of schizophrenia or severe bipolar disorder, based on the genome analysis of a two-day-old baby? It would put every psychiatrist out of business.
So in the long run, if the human race survives as a species, I think the prognosis medically [for mental illness] is very good. I am not sure that I am optimistic about the survivability of the human species, but I am optimistic in that limited way.
“How dare you treat me this way!” boomed a husky voice with a thick Eastern European accent. “I’m king of the Puerto Ricans,” came the roar from the packed waiting room.
It was a warm, humid June evening, about eight p.m. Although I’d been a resident for only a few months, my instincts told me this would be one of those nights when the emergency room would earn its moniker as Bedlam’s Door, a revolving carousel of psychosis, with one disturbed person after another being steered to the facility by the police, family members, or friends. “King of the Puerto Ricans,” bellowed the man, his voice reverberating through the corridor. The claim was utterly absurd—from his self-proclaimed royalty to his non-Hispanic accent. It was bizarre, even for the environs of Manhattan Hospital’s emergency room. Another leonine roar of Slavic-sounding speech brought me to my feet. Peering into the reception area, I saw a burly man bound securely to the confines of a high-backed wooden wheelchair. Despite his raging, the man—appearing to be in his sixties—had a cherubic-looking face, with round, rosy cheeks and bushy, dark eyebrows. A huge mane of white hair crowned his head. Highly agitated, he struggled against the canvas straps binding him to the wheelchair. Though his ankles were secured to the contraption’s front rigging, he managed to kick and stomp his feet on the footrest. “Let me go. I have work to do,” he roared. His words were barely comprehensible, partly due to his agitation, but also because he lapsed into a foreign language—perhaps Polish, or some other Slavic-sounding tongue. He shook the wheelchair violently, attempting to break free. A woman wearing a drab housedress tried to quiet him, but he kept shouting. A police officer I knew saw me and approached. “What’s up, Officer Romano?” I asked. “He was running down Delancey Street, tossing trash baskets and shouting. We couldn’t control him. He’s as strong as an ox. You hear what he’s yelling?” Romano shook his head. Over the years, he’d brought his share of patients to our doors, but this one clearly perplexed him. That week I’d already encountered the putative son of God, an enraged Moses, and Satan himself. But I never imagined meeting the king of the Puerto Ricans. “Who’s the woman?” I asked. “His wife. She said his name’s Nathan . . . Nathan B.” “Any previous history you know of?” I asked. “Nope. The neighbors say he’s always been a quiet guy and a hard worker. A carpenter.” A carpenter? Why doesn’t he think he’s Jesus? Romano looked at me with raised eyebrows. “You’re not gonna give us trouble with this one, are you, Doc?” He knew I’d sent the police packing scores of times with drunken and disorderly miscreants they dragged to the emergency room, trying to avoid tossing them into the precinct’s drying-out tank. The cops hated babysitting drunks almost as much as they loathed the paperwork involved. But Nathan B. was a man lost in the throes of madness. “Looks like you’re safe on this one, but let me talk to his wife.” Mark RubinsteinSarah B.’s pale face sagged. Her gray hair was tied back in a bun. She dabbed at her reddened eyes with a handkerchief. In the housedress, she looked like a Russian or Polish peasant woman from a bygone era. “Mrs. B., how did this start?” “It was maybe two weeks ago, Doctor,” she said with a thick accent. “After Nathan hurt his back.” “What happened?” “He’s a carpenter and was working on the roof of a house. He fell down onto a pile of wood. He’s lucky to be alive,” she said, again dabbing at her eyes. “He broke a bone in his back, and now he can’t work. Maybe never . . . Only if it heals, the doctors said. And they don’t know—a man his age. He’s sixty-four. And, all he knows is work.” “What happened after the accident?” “After he got out of the hospital, he was very quiet. He talked to no one—not even me. He just looked out the window. He wasn’t my Nathan anymore.” “What do you mean?” “He seemed so sad, so depressed,” she said, brushing away a tear. “Did he ever have an episode like this before?” I asked, wondering if Nathan B. might be suffering from bipolar disorder. “No. Never. But after he got hurt, he began talking to himself—strange words. And then came dreams, terrible dreams. He would cry out in his sleep. And when he woke up, he would shake and be covered in sweat. He was so wet, I had to change the sheets. He would pace all night, like a wild beast. And talking to himself—under his breath, in Hungarian. I tell you, Doctor, we never talk in that language . . . only English. “I asked him, ‘Nathan, what’s wrong?’ and he said, ‘I have nightmares.’ But he would tell me nothing more. He said, ‘Sarah, you would not want to know.’ “It got worse. He would never leave the house.” Her lips trembled. “When he heard sirens, he shook. He thought they were coming for him.” “The police?” “Yes. He said, ‘They’re coming for me.’” “Did he tell you why?” “He wouldn’t say. He never did a thing wrong in his life.” Tears spilled from her eyes. “I know it’s from his life in Europe.” “What happened?” I asked, fairly certain of the events to which she was referring. “The Nazis,” she murmured, as her hands went to her face and she sobbed. “Mrs. B., where are you from originally?” “We’re from Hungary.” “When did you come to the United States?” “We came in 1947, after the war.” “Where were you during the war?” “Nathan lived through Auschwitz. But he never talks about it.” “And what about you? Were you in the camps?” “No. I lived with a family on a farm. And I met Nathan after liberation.” “In a displaced persons camp?” She nodded. “And we came here. We made a good life together.” When Nathan was wheeled into the office, his eyes bulged and his face shone with sweat. His shirt was soaked with perspiration. He was restless and his eyes darted from the walls to the ceiling. I introduced myself, saying, “I’d like to talk with you.” No response. He seemed lost in some inner world. He wore work pants, heavy boots, and a short-sleeved work shirt. His chest was broad and powerful-looking. His hands, large and roughly calloused, were those of a man who’d done carpentry all his life. His forearms, strapped to the wheelchair’s armrests, looked as though cables were bundled within them. A series of blue-black numbers was tattooed on his left forearm—a remnant of Auschwitz. “Mr. B.?” “How can you do this?” he growled. Suddenly, his eyes crawled over me. Spittle formed at the corners of his mouth. “Do what?” “How dare you tie up a king!” he shouted hoarsely. “How did you become king?” “God made me king. Do you question his word?” His chin quivered. I said nothing. “Answer me,” he demanded. “Do you question God’s word?” He trembled so intensely, the wheelchair shook. “No. I don’t question God or his word,” I said. “But why king of the Puerto Ricans?” “Such a poor people . . . and persecuted. They must go to their own land.” His eyes roamed about the office once again. “What is this place?” he demanded. “You’re at Manhattan Hospital.” “What am I doing here? I’m not crazy.” “You were running down the street, throwing trash cans . . .” “I was calling my people . . . my subjects.” “What did you have in mind?” “We must leave before the SS gets here.” “What makes you think they’re coming?” His face tightened, and sweat dribbled from his hairline. “Can’t you see? There’s no time left.” “Before what happens?” “We’ll be taken away . . . to the camps. They want to kill all of us.” “Kill who?” “My people. All the Puerto Rican people. It will be a holocaust.” “Why now?” “The time has come.” His eyeballs rolled upward and he fixed his stare at the ceiling. He began muttering a goulash of English, German, and Hungarian. Nathan B.’s mane of white hair, coupled with his upward gaze, reminded me of Renaissance paintings depicting ancient prophets—maybe something by Caravaggio—painted in dusky colors with ethereal light radiating from some godly presence. “Mr. B., I understand you began feeling bad a few weeks ago . . .” His garbled muttering continued. He was lost in a world of messianic revelation. The extent to which deluded thinking could seize a person never failed to amaze me. I tried again to get him to talk. “I’m king of the Puerto Ricans” was all he would say in English. “Mr. B., I’m going to admit you to the hospital,” I finally said. His incantations stopped. He turned to me, his eyes burning with pious fury. “You want to make me a slave, so I will work for you.” “You won’t be a slave,” I said. “You’ll be here until you calm down.” “You Nazi. God will make you pay for this.” I’d tapped into his past—and the source of his madness.


“King of the Puerto Ricans,” excerpted from Bedlam’s Door: True Tales of Madness and Hope by Mark Rubinstein, MD (Thunder Lake Press). © Mark Rubinstein. You can read an interview with the author here.
A 5.6 magnitude earthquake shook parts of the US Midwest earlier this morning, rattling homes from Nebraska to North Texas. The unusually strong quake will likely draw further scrutiny to the practice of disposing oil and gas field wastewater deep underground.
The US Geological Survey recorded a 5.6 magnitude earthquake at 7:02 am this morning in north-central Oklahoma. It was centered about nine miles (14 km) from Pawnee, Oklahoma. A second quake was recorded less than an hour later, measuring 3.6.

Initial reports indicate that the earthquake was felt as far north as Nebraska, and in large metropolitan areas such as Dallas and St. Louis. No major damage or injuries have been reported, but officials in the city are meeting to form a plan to assess damage and determine potential next steps.


This earthquake is similar to one that struck the region five years ago, but quakes of this magnitude are exceptionally rare. Oklahoma has experienced many quakes in recent years, but the vast majority have been under 4.0. This is already the second 5.0+ quake to hit the region this year. Back in January, a swarm of 32 quakes struck northwest Oklahoma in a 24-hour period.


Experts say the quakes are related to an increase in the disposal of waste water from oil and natural gas drilling. A Tulsa World analysis has shown that the volume of waste water that’s being stored underground has jumped more than 80 percent over the past six years, which also happens to coincide with the state’s sudden proclivity to earthquakes. The Oklahoma Corporation Commission has already imposed restrictions on the amount of water that can be injected in certain areas, but this latest quake could prompt revisions.
[Associated Press, Tulsa World]
In what’s being seen as a huge step forward in the effort to curb climate-warming emissions, the United States and China have ratified the Paris global climate agreement. Other countries are now expected to follow suit.
Earlier today, US President Barack Obama and Chinese President Xi Jinping submitted their written commitments to join the Paris agreement at a meeting in Hangzhou, China, that included UN Secretary-General Ban Ki-moon. The joint ratification, which involved the world’s largest two economies, could inspire other countries, such as Canada, India, the UK, and Brazil, to do the same.
After two weeks of marathon negotiations, 195 countries approved an accord that would wean the…
“The signal of the two large emitters taking this step together and taking it early, far earlier than people had anticipated a year ago, should give confidence to the global communities and to other countries that are working on their climate change plans, that they too can move quickly and will be part of a global effort,” said senior Obama adviser Brian Deese in a meeting with reporters. Both the US and China hope to see the pact put into force by the end of the year.


The Paris agreement is a global pact to slash greenhouse gases and limit the rise in temperatures to well “below two” degrees Celsius. It was forged by nearly 200 countries last December, but has yet to go into effect. In order for it to become legally binding, 55 nations representing at least 55 percent of global emissions need to formally ratify the treaty.
Prior to today’s announcement, only 23 nations had ratified the agreement, collectively representing a meager 1.08 percent of all global emissions. With the US and China now officially joining in, this figure jumps up quite substantially; China represents about 20 percent of global emissions, while the US accounts for about 18 percent.
The joint pact is considered a big victory for President Obama who hopes to see the pact put into place before the US election in November. US Democratic presidential candidate Hillary Clinton is a supporter of the accord, but her rival, Republican nominee Donald Trump has said he’d dump the Paris agreement if elected, saying climate change is an elaborate hoax.


[Reuters]
Hope you’re ready to face the day with nothing but your own unsharpened wits about you. Soon, they will be all you have left.
A new report from Australia’s Climate Institute predicts that by 2050, global warming will make at least half of the land currently used for coffee production unable to produce quality beans. By 2080, it cautions, hot temperatures could make wild coffee plants completely extinct. Although this report is projecting what will happen to supplies in decades to come, the coffee shortage isn’t really off in the distant future. It’s already started to fall.


Brazil—the source for over a third of the world’s coffee—has seen its coffee stores dip dramatically in the last two years as the result of a long drought. So far, unusually large harvests in other world coffee markets helped to make up most of the difference. But we can hardly expect these big harvests to continue. In fact, their trend may actually reverse. Much of Brazil’s latest shortfall was made up for by a record-breaking coffee harvest in Honduras—which is a coffee-growing area that this new report will probably be hit particularly hard in the coming decades.
Even the relatively smaller shift from Brazil’s shortage in the last couple years resulted in a price surge and a jump in counterfeit coffee beans (which pretend to be fancier coffee varieties than they are). With the spread of the shortage, we can only expect to see rising coffee prices and counterfeiting show up as even more of a problem in our daily cups.
Astronomers using the RATAN-600 radio telescope in the Russian Republic of Karachay-Cherkessia have detected an unusual signal emanating from a star located about 94 light-years from Earth. It’s not clear if the signal is being transmitted by aliens, but the researchers say we should keep a close watch on this intriguing new extraterrestrial candidate.
As reported by Paul Gilster at Centauri Dreams, the anomalous signal was detected by an international team of astronomers back on May 15, 2015. The researchers, led by N. N. Brusilov, describe a “strong signal in the direction of HD164595,” a planetary system located in the constellation Hercules. The finding is set to be discussed at a meeting of the IAA SETI Permanent Committee on September 27, 2016.
It’s still too early to tell if the signal is coming from an extraterrestrial civilization, but the researchers say it’s serious enough that scientists should now permanently monitor this new target. HD164595 is practically the same size and age as our own sun, it shares a similar chemistry, and it’s less than 100 light-years away. What’s more, it hosts at least one known planet, a warm Neptune in a circular orbit. It’s very possible that other planets reside within this system.


Looking at the signal, the researchers say that if it came from a multi-directional, isotropic radio beacon, it would have to be produced by a Kardashev Type II civilization, i.e. an alien civilization that has tapped into nearly 100 percent of its host star’s energy potential. If the signal was targeted directly at our solar system, then it would be of a power available to a Kardashev Type I civilization, i.e. an alien civilization capable of exploiting nearly all of its home planet’s energy potential.
We have yet to make contact with an extraterrestrial civilization. If they're out there — and…
Another possibility, of course, is that the signal is a natural anomaly, such as background noise. French astronomer Jean Schneider is considering the possibility that HD164595 is amplifying a background radio source through a process known as gravitational microlensing.


To move forward, scientists will need to confirm the quality and integrity of this signal and rule out other possibilities. And by focusing their radio dishes onto this planetary system, scientists may detect new signals, and possibly even patterns. Like the intriguing Tabby’s Star, and the rampant speculation that it’s home to an alien megastructure, more data is needed before we jump to conclusions.
Update: Turns out not everyone is impressed with this anomalous signal. Here’s what Daren Lynch from SETI@home has to say about it:
I was one of the many people who received the the email with the subject “Candidate SETI SIGNAL DETECTED by Russians from star HD 164595 by virtue of RATAN-600 radio telescope.” Since the email did come from known SETI researchers, I looked over the presentation. I was unimpressed. In one out of 39 scans that passed over star showed a signal at about 4.5 times the mean noise power with a profile somewhat like the beam profile. Of course SETI@home has seen millions of potential signals with similar characteristics, but it takes more than that to make a good candidate. Multiple detections are a minimum criterion.
Because the receivers used were making broad band measurements, there’s really nothing about this “signal” that would distinguish it from a natural radio transient (stellar flare, active galactic nucleus, microlensing of a background source, etc.) There’s also nothing that could distinguish it from a satellite passing through the telescope field of view. All in all, it’s relatively uninteresting from a SETI standpoint.
[Centauri Dreams]
Pharmaceutical company Mylan has announced plans to launch its first generic EpiPen. But at a cost of $300—which is half of the branded product’s list price—it’s still a heap of money for this critically important medicine.
Mylan is taking a lot of heat these days for boosting the price of its EpiPen by more than 400 percent. Just eight years ago the auto-injection epinephrine pens, which are used to stave off the effects of potentially life-threatening allergic reactions, were priced at just $100 per pack. Today the branded product costs about $600. The company has subsequently been accused of price gouging, attracting the ire of consumers, lawmakers, doctors, and at least one disgruntled celebrity endorser.
Sarah Jessica Parker has cut ties with Mylan, the company that makes EpiPen, after it was…
In response to this growing wave of criticism, Mylan will launch a generic version of its EpiPen. The product should be available “in several weeks” and will retail for about $300 per shot. At the same time, the company said it still intends to market and distribute its exorbitantly priced branded EpiPen.


The announcement comes just four days after Mylan said it would offer patients a coupon and expanded financial assistance—a move referred to by some politicians and insurers as a superficial “PR fix.” Mylan is clearly benefiting from its virtual monopoly position and the inability of competitors to produce a rival product. Mylan is also the beneficiary of patent protections and laws requiring allergy medications in schools.
Mylan’s decision to produce a generic product at half the cost is a smooth move, but it likely won’t stave off the mounting criticism. At $300, and for something so important to those who suffer from severe allergies, it’s still stupidly overpriced.
[Reuters]
One year ago, six volunteers—an astrobiologist, a physicist, a pilot, an architect, a journalist, and a soil scientist — entered a 36-by-20 foot dome, located near a barren volcano in Hawaii, to simulate what living conditions would be like on Mars. Today they re-emerged from their year-long isolation.
The NASA-funded project is called HI-SEAS (Hawaii Space Exploration Analog and Simulation), designed to test the effects of isolation in confined conditions of a human mission to Mars. This is the third such simulation, and the longest; the two prior missions lasted for four and eight months, respectively. The Mauna Loa volcano in Hawaii was chosen as a location because it’s most similar to the red, barren Martian terrain.
The six participants could only communicate with the outside world via email, and those transmissions were delayed by 20 minutes to mimic how long it would take for such a signal to travel between Earth and Mars. Resources were limited: anything they needed, they had to bring into the dome with them at the outset, right down to duct tape. Food was replenished every four months, and water every two months.


The crew were allowed to leave the dome, but only if they donned heavy space suits. And there were simulated emergencies: everything from power outages and broken tools, to a forced evacuation to avoid a harsh radiation wave.
When the HI-SEAS crew finally emerged today, a documentary film crew was on hand to capture the moment for posterity. The film-in-progress is called Red Heaven, and it’s the passion project of indie filmmakers Lauren DeFilippo and Katherine Gorringe. Their goal: to provide a “raw and intimate look into what life on Mars might really be like.”
The two women were there when the crew entered the dome last year, snagging exclusive interviews and a peek inside the dome itself before the members went into isolation. And they left the crew with their own cameras so they could film themselves going about their daily life. “We would give them a shot list [via email] and they uploaded the footage throughout the year,” DeFilippo told Gizmodo.

DeFilippo and Gorringe met as graduate film students at Stanford University, and something about Silicon Valley’s fascination with futurism and technology rubbed off. “We realized the stuff sci-fi dreams are made of was becoming reality, and we kept wondering, what would be actually be like to live on Mars?” said DeFilippo. When they heard about the HI-SEAS program, they immediately wanted to be part of it. And the Red Heaven documentary project was born.


Now the filmmakers will be doing follow-up interviews and hopefully following each member as they re-acclimate to life in their hometowns. Then they’ll head into post-production on Red Heaven, processing the hundreds of hours of footage they’ve collected, with a projected release date of 2018.
All of that will cost money, of course. So DeFilippo and Gorringe have launched a Kickstarter campaign to raise funds for the final phase of their documentary project. So far they’ve racked up over $23,000 of their $40,000 goal, with 23 days left to go in the campaign.
As for NASA, its researchers will now begin the laborious process of analyzing and comparing data from the three HI-SEAS simulation missions, focusing on the psychological effects of isolation on the crew members. There will two more HI-SEAS missions under the dome, starting in January 2017. NASA’s goal is to send humans to Mars by 2030.
An earlier version of this post included a photo of crew members from a prior HI-SEAS simulation. It has been updated with a new photograph of the current crew.
In May 2013, a bridge spanning the Skagit River along Interstate 5 in Washington state catastrophically collapsed, after an oversized trailer clipped one of the bridge’s cross beams. A new analysis by engineers at the University of Illinois at Urbana Champaign confirms the many factors that contributed to the collapse, and offers recommendations for how to prevent similar failures in the future.
They published their analysis in the Journal of Performance of Constructed Facilities. “The bridge repair costs exceeded $15 million, and that doesn’t account for the economic losses that the area felt because they and visitors no longer had access to the interstate,” co-author Tim Stark said in a statement. “Even though this accident occurred three years ago, it’s still very important because many bridges have this same design, not only in Washington but in other states.”


An entire section of the bridge fell into the water, taking two other cars with it. Fortunately there were no fatalities, although three people suffered minor injuries. Built in 1955, the bridge was a crucial link between Vancouver, British Columbia, and Seattle, with more than 71,000 vehicles crossing every day. After the collapse, people naturally scrambled to explain how it could have happened, including Mike Lindblom, a reporter from the Seattle Times:

A preliminary report by the National Transportation Safety Board attributed the failure to the bridge’s so-called “fracture-critical” design, whereby a small crack in just one essential part can trigger a chain reaction of even more failures. That’s what happened in 2007, with the collapse of the similarly designed I-35W Mississippi River bridge in Minneapolis. There are more than 10,000 aging through-truss bridges in the U.S.


The Illinois team suggested ways to reinforce such bridges to reduce the risk of catastrophic failure in the future. “[T]he initial damage of where the truck hit was not a primary support, it was a cross beam, and the damage cascaded, causing the entire collapse,” co-author Jim LaFave said. “We can selectively add supports so there are ways to redistribute the impact load, so the structure can remain stable and stay standing even if there’s damage to a particular area.”
And then there was human error. The truck with the oversized load was erroneously driving in the outside lane, where the clearance was lower, in part to give space to another passing truck.. The state’s Department of Transportation rubber-stamped an oversize-load permit to the trucking company without verifying clearance limitations along the proposed route. And the driver underestimated the height of his load by a critical two inches.
Stark and his colleagues attribute much of this to poor record-keeping. “The key issue in this case is the variable vertical bridge clearance,” he said. “Many bridges have a square opening, so the clearance is the same across all lanes. The problem with this bridge was that it curved down over the edge lanes. The oversized trailer was 15 feet 9 inches tall. The database said the bridge was 17 feet 3 inches, which was in the center – almost two feet higher than the edges, which is where the oversized trailer was traveling.”
The authors recommend changing policy to report the lowest vertical clearance for bridges, rather than the highest—and periodically verifying that data with LIDAR measurements.


There was a pilot car traveling ahead of the truck, outfitted with an antenna to detect any possibility of too-low clearance. But the driver of the pilot car admitted to using a cell phone (albeit with a hands-free device) while crossing the bridge. Even if the pilot car had alerted the truck driver, there would not have been time to avoid a collision. The driver was following the pilot car too closely: more than half the recommended distance for adequate response (400 feet, or a five-second response time, instead of the recommended 865 feet, allowing for a 10-second response time).
“In this case, the pilot car either did not impact the bridge or the driver didn’t hear the impact. They never called the truck, so that part of the safety mechanism failed,” Stark said. “One solution we suggest is a sensor at the top of the pole that automatically contacts the oversized vehicle if it hits an object. This eliminates the drivers having to communicate quickly so the oversized vehicle can change course. Also, the pilot car antenna was not straight, so it was not accurately measuring the full height.”


It will never be possible to eliminate human error entirely. We are fallible creatures, and sometimes all those tiny lapses in judgement—typically harmless on their own—combine in disastrous ways. But the lessons learned from the 2013 Skagit River bridge collapse could make catastrophic failures just a bit less likely in the future.
[Journal of Performance of Constructed Facilities]
You forgot to buy milk. Naturally, it’s all the big bang’s fault.
Cheeky video essayist exurb1a uses human forgetfulness to explain the concept of determinism. Essentially, it’s the idea that because the universe and everything in it follows rules, we all exist in a highly complicated chain reaction that governs everything from the movement of planets to the release of specific chemicals in our brains.


Free will? “Bah!” says determinism.
Did you read this post because you wanted to, or because you were always going to? Don’t all frantically check the fridge at once.

It’s been an exciting week for planet hunters with the discovery of the nearest exoplanet yet found, orbiting a star called Proxima Centauri. Now you can get a closer look at that star system via a live broadcast tonight, courtesy of the robotic telescope service Slooh. The fun starts at 8 PM ET/5 PM PT.
Proxima Centauri is a small red dwarf star located just 4.25 light years away, slightly closer to Earth than the famous binary pair of Alpha Centauri A and B. The newly discovered exoplanet has been dubbed Proxima b, and the ESO team pegs its mass as being roughly 1.3 times that of Earth.


According to Slooh team member Paul Cox, when collaboration launched its new telescopes in Chile back in 2007, Proxima Centauri was one of their first observational targets of its global network. Since getting a heads-up on the new exoplanet, the telescopes have been imaging the star every night.
“It’s amazing to watch that small red dot live in the online telescopes every night, and imagine the earth-like world that we now know orbits the star,” Cox said in a statement. “With the possibility that liquid water exists on Proxima b, who knows, there may be some Centaurian amateur astronomers gazing back at us every night.”


You can share the wonder and watch the Live stream embedded below, or watch on the Slooh website. Broadcast host Eric Edelman will be joined by the University of Texas, Austin’s Michael Endl—part of the ESO team that discovered Proxima b—and Lisa Kaltnegger, director of Cornell University’s Carl Sagan Institute, who will address the implications of this discovery for extraterrestrial life.

Astronaut Scott Kelly returned from a year-long sojourn in space in June. His slightly older astronaut twin, Mark Kelly, stayed home as a control—part of NASA’s twin study to monitor the effects of space on the human body. But there’s a physical change that NASA might not be able to measure that easily. Mark is now even older (by about 5 milliseconds) than his space-faring twin, thanks to special relativity.
It’s due to a quirky little thing called time dilation: time can slow down for one person, but not for another, because there is no such thing as a fixed frame of reference against which all motion can be measured. Two people who are moving relative to each other, wearing identical watches, will measure time differently, depending on how fast each is moving.


This isn’t just a mathematical oddity. It’s been experimentally verified over and over again with pairs of atomic clocks, although on human scales it’s a pretty tiny effect. It’s only when you reach speeds close to the speed of light that time dilates significantly. This new video from Minute Physics will give you a visual sense of how time dilation works:

Why does this happen? Well, the three dimensions of space and one dimension of time are merged in Einstein’s theory to become a single four-dimensional spacetime. That means motion through time and motion through space are connected, and light is the link between them.


Since the speed of light in a vacuum is always constant (670 million MPH), time and space must adjust with motion to ensure that two people moving relative to each other will always measure the same speed for light. So as an object speeds up as it moves through space, time must pass more slowly. (Also, lengths contract.) But from your perspective, nothing would seem amiss.
And that brings us to the Twin Paradox, or why Mark Kelly is now technically even older than his twin, Scott Kelly. Here’s Minute Physics again with the solution to this famous paradox:

To put it another way, time passes differently for the hypothetical twins in the video because they haven’t had equivalent experiences. One stayed home in an inertial frame of reference. The other accelerated out to space, then decelerated, turned around, and accelerated home of the return trip. So the symmetry between them is broken.
And as you may recall from Interstellar, time also passes more slowly in proximity to a black hole because of the strong gravitational effects. It’s just one more challenge to be overcome if humans are ever going to travel deep into space.
A group of scientists at Lancaster University in England are constantly monitoring geomagnetic activity, to get a heads-up for the spectacular night sky display known as the Northern Lights. So a couple of days ago, they were thrilled to get a strong reading that an aurora was likely imminent.
Alas, it turned out to be a false alarm. The culprit? A ridable lawn mower.


Auroras happen when solar winds disturb the Earth’s magnetosphere. When that happens, charged particles—mainly electrons and protons—pour into the upper atmosphere, colliding with oxygen and nitrogen atoms. As the atoms get excited or return to their normal state, they emit visible energy. When it is an oxygen atom, the light emitted is either green or brownish-red, depending on the energy level absorbed by the molecule. Blue happens when nitrogen gets ionized, and red when it returns to ground state.
The Lancaster scientists with Aurora Watch have magnetometers in place to monitor geomagnetic activity around the UK, including Lancaster, Aberdeen, and the Faroe Islands. The group sent out a red alert to members on its email list on Tuesday afternoon, after readings of magnetic field data from their Lancaster magnetometer showed a sharp spike.


Usually this is a sign of a burst of geomagnetic activity, heralding the onset of the aurora phenomenon. The spike was strong enough that it probably would have been visible through the United Kingdom, had it been real. Instead, the group retracted the red alert four hours later, after noticing no similar spikes from their other sensors.


“It appears that some local interference set off a massive spike in the data,” the group’s cancellation notice read, adding, “No, it wasn’t the intern.” Rather, it was university staff, namely a groundskeeper who got a bit too close to the magnetometer while cutting the lawn. The folks at Aurora Watch said they’ll be coordinating with the maintenance staff to avoid this kind of mix-up in the future.
This is why it’s important to get readings from multiple sensors. Maybe next time, the signal will be real. Because the Northern Lights really are an impressive display.
[via Boing Boing and BBC]
This is a barren time in the sports calendar. We are in a desolate trough between the international intrigue of the Olympics and the drama and nonsense of football season. I’m goddamn bored. Coincidentally, the National Parks Service turns 100 years old today. Unlike late August, the National Parks are good, and as the only member of the Deadspin staff with a geology degree, I am slightly more qualified to write about the natural wonders of our nation than anyone else.
The summer is drawing to a close, and maybe you want to visit a National Park. Which one should you go to? Do you wanna see cool rocks? What about bears? Please consult these airtight rankings. (I’m not going to rank American Samoa National Park or Virgin Islands National Park for various reasons we don’t need to get into.)
Yellowstone National Park’s geothermal features are the products of a caldera, which is a recharging supervolcano with over 6,000 times the eruptive potential of Mt. St. Helens. Basically, magma from the Earth’s lower mantle travelled up through the upper mantle and the crust, and it feeds the Yellowstone caldera. It’s like Hawaii, but on land. As the Earth’s crust shifts over the hotspot, the location of the Yellowstone magma has changed. It erupted 2.1 million years ago, 1.2 million years ago, and 630,000 years ago. Astute readers will note that that recurrence interval indicates that another explosion could be approaching in the immediate future. When it explodes again, it will cover the Western United States in ash.


Anyway, Yellowstone is also very large, stocked with buffalo, and features a series of naturally heated rivers you can swim in.
By the time the last glaciers carved their way through the Yosemite Valley 12,000 years ago, they’d managed to smooth over almost every peak in the region. Unlike the Lake Tahoe area, the Eastern Sierras are full of granite, and other felsic rocks. Harder mineral compositions means that famous hanging walls like Half Dome and El Capitan are able to stand up more or less perfectly straight.


All that said, the cooler part of the actual park is the less-visited eastern half. If you hike Cloud’s Rest, you can stare down at the little line of ant people scurrying up Half Dome, 2,000 feet below you. You are their queen. Look at those doofuses.

Look at this shit.
As established in the Yosemite segment, glacial geomorphology is the shit. Glacier has the actual benefit of actual, uh, glaciers. Near-dead as they are, alpine glaciers are much weirder than glaciers that calve into the ocean. Experts estimate that the remaining glaciers in the park will all be gone by 2030, so go see them before these last remnants of the Ice Age die forever. Glacier NP has the additional benefit of a big grizzly bear population as well as mountain goats.
Bryce Canyon looks like an alien civilization tried to carve a long, complicated message to humanity via orange spires of rock. In fact, these hoodoos only exist because of a very specific confluence of circumstances. Most of the body of each column consists of soft layers of limestone and siltstone, capped off by a thinner, harder layer. The Bryce Canyon area was a paleo-lake, but it’s a very arid and cold climate now. Because there’s precious little rainfall in the area, conventional erosion is not the dominant regime. Instead, frost wedging contributed to much of the separation within rock columns that leads to hoodoos. Higher layers are more chemically resistant to weathering, allowing them to resist.
I usually think of rainforests as a rather equatorial biome, but there are several temperate rainforests on Washington’s Olympic peninsula. This is where people think Bigfoot lives. If I was him, I would hang here too.
The only problem with the Grand Canyon is that there’s too much of it to comprehend at once. When you look down into it, there are simply too many incredibly detailed ridges and sub-valleys to take in to truly grasp its size in one go.
Here’s a fact: This National Park is named after boobs.
Because Hawaii is so volcanically active, many words for lava come from the native Hawaiian, like A’a and Pāhoehoe. If you look at the islands on a map, you can chart the course of the hotspot that created them over time. The islands furthest to the northwest are older and more degraded, while the big island is still actively growing on its southern margin. There is a chain of fallen, crumbled Hawaiis to the north of the existing island chain. Twenty two miles off the coast of the big island, the Lōʻihi Seamount has been slowly forming, and it will become the newest Hawaiian island. Sadly, it won’t breach the surface for at least 10,000 years, so we’re stuck the islands we’ve got.
I respect and fear the power of mighty Denali.
More fun than it sounds! Every 10 or so years, Death Valley experiences a “super bloom” as long-dormant seeds sprout en masse, covering the once-desolate landscape in a carpet of life. It’s weird as hell.

Nobody goes here, because it’s off in a strange pocket of northeastern California, but nowhere else has so many different types of magmatic systems packed into one area. The Gorda Plate, a fucked up old tectonic plate, has been subducting into the west coast for a long long time, and has produced some strange inland volcanism. Lassen Peak is the southernmost of the active volcanos in the Cascade Range, but the park also has a perfect cinder cone and some sulfuric hot spring action.
Sequoias are redwoods, but with modesty.
Nice glacier.
West Texas has a National Park and somehow it’s pretty good.
The Channel Islands were inhabited by a species of pygmy mammoth until about 10,000 years ago, when the ice age ended. A group of mammoths must have swam over to the islands and set up shop, gradually evolving into smaller and smaller animals to adapt to their island biome.
Mammoth Cave is easily the longest cave in the world, about 405 miles of tubes and such under Kentucky. It’s so big they keep finding stuff in it, and it’s probably not fully explored.
Pretty canyon.
They gave poor Teddy, who set the National Park system up, a very pretty but unspectacular park in North Dakota. Also, it’s split up into two unconnected segments, which, really, makes it two parks.
Using a super-absorbing chemical compound called sodium polyacrylate, you can turn boring old H2O into a magical blob-like substance. There’s a lot of fun you can have with these water beads, including deep frying them, but watching them turn invisible when submerged is easily the best trick.
Self-billed chemist and science enthusiast Andres Tretiakov posted a brief demonstration to Twitter showing how water beads seem to turn invisible when submerged, because they have the same refractive index as the water that surrounds them. When held in hand, light is able to reflect and create visible distortions while passing through the water beads, but in a bowl filled with H2O they blend in and appear to completely disappear. Science!


[Twitter - Andres Tretiakov]

For decades, tin foil fashionistas have attributed a number of sinister happenings to the atmospheric research program known as HAARP, including hurricanes, earthquakes and even the destruction of the Space Shuttle Columbia. After this week, however, it will be a lot harder to entertain those claims: On Saturday, the supposed weather-altering secret weapon is holding an open house.
Can a facility that has inspired global conspiracy theories be designated a World Heritage Site? If …
“We hope that people will be able to see the actual science of it,” a spokesperson from the University of Alaska, which now operates the facility, told Alaska Dispatch News. “We hope to show people that it is not capable of mind control and not capable of weather control and all the other things it’s been accused of.”


According to KTVF, the university expects both scientists and conspiracy theorists to show up at the event. With any luck, that will include former Minnesota governor and professional wrestler Jesse Ventura, who questioned whether HAARP was being used for mind control in 2009 after being turned away at the facility’s gates.


“This thing can knock planes out of the air,” said Ventura at the time. “It can control the weather. And it’s a very dangerous, dangerous weapon.”
Ventura and his ilk should find themselves more than welcome: According to the university, children of all ages are invited and refreshments will be provided.


[h/t Metafilter]
By now you’ve heard the exciting news that astronomers have discovered an Earth-like exoplanet a mere four light years away. It’s a promising candidate for harboring life, and it’s close enough to Earth to make a robotic exploratory mission feasible within a generation.
We’re sure you have questions—lots and lots of questions—about this potentially momentous discovery, the hunt for exoplanets more generally, the prospects for future exploration (or even colonization), and the tantalizing possibility of extraterrestrial life. Harvard University astronomer Dr. Abraham (Avi) Loeb, who chairs the advisory committee for billionaire Yuri Milner’s Breakthrough Starshot Initiative, is with us today to answer them.


UPDATE 2:43 PM: And we’re done! Thanks to Dr. Avi Loeb for joining us today, and to our readers for asking such great questions.

In what’s being hailed as one of the biggest astronomical discoveries of the century, scientists with the European Southern Observatory (ESO) today confirmed the discovery of an Earth-like exoplanet in the habitable zone of Proxima Centauri—our nearest neighboring star. Details of the team’s discovery were just published in Nature.
Rumors of a possible Earth-like exoplanet first surfaced on August 12 in the German weekly Der Spiegel. Citing an anonymous source with the La Silla Observatory research team, the magazine claimed the rumored planet “is believed to be Earth-like and orbits at a distance to Proxima Centauri that could allow it to have liquid water on its surface—an important requirement for the emergence of life.”


Now we know those rumors were true: There is clear evidence for a planet orbiting Proxima Centauri, a small red dwarf star located just 4.25 light years away, slightly closer to Earth than the famous binary pair of Alpha Centauri A and B. It’s been dubbed Proxima b, and the ESO team pegs its mass as being roughly 1.3 times that of Earth.
Its orbit is 4.3 million miles from Proxima Centauri, just 5 percent of the distance between Earth and our own Sun. But the star is also much cooler than our Sun, so Proxima b still lies within the so-called “habitable zone” for exoplanets, with temperatures sufficient for water to be in a liquid state on the surface.


Since the first exoplanet was discovered in 1995, astronomers have identified more than 3000 such bodies orbiting distant stars. “We live in a universe that is teeming with terrestrial planets,” Pedro Amado of the Instituto de Astrofisica de Andalalucia said during a press conference this morning. Red dwarf stars like Proxima Centauri in particular are believed to be rife with small, rocky Earth-sized planets.
According to lead author and project coordinator Guillem Anglada-Escude of Queen Mary University of London, the first hints of this new planet appeared in 2013, but there was insufficient evidence to claim discovery. The latest observation campaign is called Pale Red Dot (because Proxima Centauri is a red dwarf), inspired by Carl Sagan’s famous description of Earth as a pale blue dot.
The team of 31 scientists from eight countries relied on the Doppler effect to detect a faint wobble in Proxima Centauri’s spectrum of light, which approaches and recedes from Earth every 11.2 days at around 3 MPH. Such a wobble could be caused by the gravitational pull of an orbiting planet. By combining data from the Pale Red Dot campaign with earlier data collected between 2000 and 2014, the astronomers confirmed a sharp peak—well above the threshold for discovery—in the Doppler shift data indicative of an Earth-sized exoplanet.
The technology to detect Proxima b has been around for at least ten years, so why has it taken so long for astronomers to make the discovery? It’s because Proxima Centauri is pretty active as stars go, and its natural brightness can mimic the signal of a possible planet. The team relied on observations with two other telescopes to chart how the star’s brightness changed over time, enabling them to exclude the possibility of a false positive. There is just a 1 in 10 million chance that this signal is a false positive, according to Anglada-Escude.
It’s not yet clear whether this new exoplanet has an atmosphere. Because Proxima Centauri is a fairly active star, Proxima b suffers x-ray fluxes approximately 400 times greater than what we experience here on Earth, and this could cause any atmosphere to blow away.


But Ansgar Reiners of the University of Gottingen in Germany said that it really depends on how and when the exoplanet formed. Did it form further out, with water present, and then migrate closer to its star, or did it form very close to Proxima Centauri? The former scenario would make an atmosphere more likely.
“There are many models and simulations that produce very different outcomes, including possible atmosphere and water,” said Reiners. “We have no clue, but the existence of [an atmosphere] is certainly possible.” That would bode very well for the possibility of the planet harboring life. And the relative closeness to our solar system makes robotic exploration feasible within a generation.
“The lifetime of Proxima is several trillion years, almost a thousand times longer than the remaining lifetime of the Sun,” Harvard University’s Abraham (Avi) Loeb, who chairs the advisory committee for billionaire Yuri Milner’s Breakthrough Starshot Initiative, told Gizmodo. “A habitable rocky planet around Proxima would be the most natural location to where our civilization could aspire to move after the Sun will die, five billion years from now.”
Announced to great fanfare in April, the Starshot Initiative is a $100 million research and engineering program seeking to lay the foundations for an eventual interstellar voyage. The first step involves building light-propelled “nanocrafts” that can travel up to 20 percent the speed of light. Such a spacecraft would reach the Alpha Centauri star system just over 20 years after launch. Currently, the project’s scientists are trying to demonstrate the feasibility of using powerful laser beams to propel a lightweight sail.


According to Loeb, the discovery of a potentially habitable planet around Proxima Centauri provides an excellent target for a flyby mission. “A spacecraft equipped with a camera and various filters could take color images of the planet and infer whether it is green (harboring life as we know it), blue (with water oceans on its surface), or just brown (dry rock),” he told Gizmodo. “The curiosity to know more about the planet—most importantly whether it hosts life—will give the Starshot Initiative a sense of urgency in finding out more facts about the planet, especially those that cannot be inferred with existing telescopes from our current vantage point on Earth.”
“We certainly hope that within a generation, we can launch these nano probes,” Peter Worden of the Breakthrough Prize Foundation said during this morning’s press conference—perhaps by 2060. “We now know there’s at least one very interesting target that’s within range of our proposed system. We can get the images to see if there is life there, possibly advanced life. Those are the great questions, and I think they’re going to be answered this century.”
Note: Avi Loeb will be joining Gizmodo today from 2:00 -2:30 PM ET. He’ll answer all your questions about this exciting new discovery, the hunt for exoplanets in general, and the Breakthrough Starshot initiative.

[Nature]


Maddie Stone contributed to the reporting for this story.
It’s one of those numbers that I’ve got in the back of my head for no reason: 2.75 seconds. That’s how long it takes a car dropped out of a plane to accelerate to 60 miles per hour. When I saw the hilarious new Tesla Model S P100D did 0-60 mph in 2.5 seconds it was a reminder that Elon’s electric sedan was now faster than gravity.
I tweeted about this and it led to a bunch of fun questions and retweets, so I thought I’d expand a little on what it actually means to be “faster than gravity.”

There are a lot of caveats but let’s get into the simple math. Everyone knows that an object in a vacuum accelerates at 32 feet per second squared (ft/s2). What many people may not know is that 60 mph = 88 ft/s. Thus, an object gets to about 47 mph in two seconds and by the time it gets to 60 mph it’s been approximately 2.75 seconds (88/32 = 2.75).
Of course, 60 mph is a somewhat arbitrary measure created to test cars and it comes from a time when 60 mph was much harder for a car to achieve. Now these numbers are suspect because that’s what automakers are aiming at with their launch modes. We should really be talking about 0-to-100 mph times, but I’ll never get my way with that.


Where it gets more complicated is when you add in wind resistance and other factors. As we learned in the Mythbusters episode below (where they sped the car up to its top speed), a car will tend to stay nose down so wind resistance on an aerodynamic car means that it probably has a pretty high terminal velocity.

We’d have to figure out the terminal velocity of a Tesla Model S falling from the sky, which, despite being very slippery in the air, will still contend with atmosphere at some point (as does the car driving on the ground, but that’s already factored into its acceleration time.)


Again, in a vacuum, this paper from amateur physicist Mark Virag has a helpful chart:

Because the Model S P100D is electronically limited at 155 mph that means that you could drop one from about 3400 feet and it would hit the ground roughly at the same time as an identical car on the ground would travel the same distance. So a Tesla Model S P100D is faster than a car dropped from more than half a mile in the air. But what’s the fun in that?


Using this calculator you can try and figure out what the terminal velocity of a Tesla Model S really is. We know cars tend to point down when they’re dropped (although those are usually front-engined cars and the Tesla has a good weight balance) so we’re using this work from Car And Driver to determine the slipperiness of a Tesla and hoping it will apply even though the new Tesla seems a little sleeker.
Assuming the typical density of air at ground level, a coefficient of drag of 0.24, a mass of around 5100 pounds (it has more batteries), and a frontal surface area of 25.2 square feet you get a terminal velocity of 520 mph, which seems high to me, but there’s the math. If you assume that the car, which has a nice weight balance and a low center of gravity, would fall with its wheels pointing down towards the earth, it reaches a much lower terminal velocity closer to 110 mph.


There’s no way that a Model S even totally uncorked is going to get anywhere near its terminal velocity so at some point gravity will win, but it’s fun to think that a vehicle is capable of hitting this faster-than-gravity measure, which I shall call the “Hardigree Line” because I’m vain.
According to manufacturer times here are other regular production cars below the Hardigree Line:
Notable here is that the Tesla Model S is a sedan and the other cars are high performance exotics or near-exotics. Also worth noting is that a Model S is going to run out of juice pretty quickly if you keep testing this.


I do think we should test this, though, and I call on Elon Musk to offer us two Tesla Model S P100Ds, a helicopter, and a wide open space in order to do so. With the autopilot system in a Tesla we don’t have to worry about anyone getting harmed.
Special thanks to mathematician Galen McQuillen for his assistance.
Rubber bands can become colder than room temperature through sheer mechanical force. Stretching one heats it up (duh) but letting it contract cools it below its starting temperature. Let that weirdness sink in for a moment.
Most people would leave that odd bit of science at “Woah...” and that would be that. But the folks at Applied Science thought, “Hey, someone could scale this up and build a tiny fridge—and that someone is me!”


Of course the thermodynamic gains of such a simple system are minimal. Wood is far from the best insulator, and rubber bands are a less than ideal coolant. What’s neat is that this actually works at all, and we might see a more efficient version of this prototype down the line. Stay weird, science.

His blue face and blank stare suggest a look of despair or simply disbelief. Yet, the snub-nosed monkey above and 37 other similar species just got their genomes sequenced. This one monkey, though. He seems sad as hell about it.
His family seems chill, though.
[Nature]
Is it possible to find trace evidence of supernovae from millions of years ago in the sediment lining the ocean floor? One astrophysicist has spent the better part of a decade trying to find the proverbial smoking gun to prove that it is. And now, it seems, he has succeeded.
Shawn Bishop, an astrophysicist at the Technical University in Munich, Germany, has been investigating the fossils of ancient bacteria on the ocean floor for several years now, in hopes of finding traces of an iron isotope produced in a supernova explosion some 2.2 million years ago. He presented promising preliminary findings at a physics conference in 2013. He has now confirmed those early findings, according to a new paper in the Proceedings of the National Academy of Sciences (PNAS). “The signal is definitely there,” he told Gizmodo.


The isotope in question is iron-60 (60Fe), just one of the heavy elements produced by supernovae when they explode, scattering those elements into space. Because of 60Fe’s short half life, there shouldn’t be any of it on Earth, but traces have nonetheless been detected in the ferromanganese crust on the ocean floor. And that means there could be traces of the isotope elsewhere as well.
Bishop thought the best candidates were tiny microfossils of ancient bacteria that scientists have found in ocean floor core sediment samples. Back in 1963, Italian microbiologist Salvatore Bellini noticed these types of bacteria could orient themselves towards the North Pole—that is, they could sense magnetic fields to help them navigate their way to favorable low-oxygen environments.


In technical terminology, they are “magneto tactic,” thanks to the presence of chains of magnetite crystals inside the critters. The bacteria likely picked up the crystals from sediments along the sea bed. As I wrote at Scientific American in 2013:
Bishop thinks it’s possible that fine-grained debris from a supernova explosion could pass through Earth’s atmosphere, rapidly oxidizing in the process so that they are broken down into tiny nano-oxides.
These would rapidly dissolve in oxygen, form rust, and eventually settle in the sediment along the ocean floor, where the bacteria would suck them up for their crystal chains. When the bacteria eventually die, those chains remain behind in the sediment, and 60Fe would be locked inside. So any traces of 60Fe found in that sediment would constitute a kind of biogenic signature of a supernova event, preserved in the fossil record.
Detecting those traces is, needless to say, very tricky, but Bishop figured out a way to do so using accelerator mass spectrometry (AMS) to analyze the grains of bacteria contained inside core samples from the floor of the Pacific Ocean. And then he counted, one by one, each individual atom of 60Fe. In his preliminary results, he found strong peaks in the concentrations of 60Fe in one of the cores that could be linked to a supernova explosion some 2.2 million years ago. He even identified a couple of candidate stars in the Scorpio Centauri cluster.
It was pretty exciting stuff, inspiring Anton Wallner of The Australian National University to assemble an international team to conduct its own research, in hopes of finding even more traces of 60Fe. As described in a pair of papers published in Nature in April, they did indeed find evidence for a series of nearby supernovae explosions that lit up the sky several million years ago, raining radioactive particles down onto Earth. The nearest of the explosions probably occurred in an aging star cluster some 326 light years away.


Between that result and Bishop’s new confirmation of his preliminary 2013 findings, this constitutes some pretty strong evidence. And at least one of the events coincides with the onset of the Pleistocene, ushering in a period of major global cooling. Astronomers have long suspected that nearby supernovae can affect Earth’s climate, most notably by burning up the ozone layer. Maybe one such explosion triggered the Pleistocene.
“We don’t have any concrete evidence that any one event is tied to a supernovae,” astronomer Adrian Mellott of the University of Kansas told Gizmodo’s Maddie Stone back in April. “But the odds are, one or more are.”


[Proceedings of the National Academy of Sciences]
It’s a scorching midsummer day, and the sawgrass is still under a pale blue sky. Waist-deep in water and sinking slowly into the muck, I fend off mosquitos as a man from South Florida’s Water Management District mixes a bag of salt into a hot tub-sized bucket on the side of the road. Thirty feet away in the marsh, another city official wearing waders and a bug hat stands on a narrow steel walkway, dangling the end of a long hose over a plexiglass chamber.
The experiment seems innocuous enough. Seawater is being added to a freshwater wetland, and scientists are observing what happens. The grim subtext is that this same experiment is about to play out in real life and on an enormous scale, from here in the southern Everglades, to Miami forty miles east, to the Florida Keys due south. If scientists are correct, much of South Florida will be underwater by the end of the century.
Standing next to me, pulling strands of what looks like a moss-covered scarf out of the water, is Viviana Mazzei, an ecology PhD student at Florida International University. It’s a periphyton mat, she explains, a unique symbiosis of algae, bacteria, and other microorganisms that forms the base of the Everglades’ food chain. When the saltwater comes, it’s expected to die, with profound ecological consequences.


“The urgency for doing this work has never been greater,” Tiffany Troxler, the FIU ecologist leading the experiment, told me later that week over the phone. “The Everglades is a world treasure, and we’d like for people to continue coming here to enjoy it for a long time.”
Today, the Everglades is fighting a war. Its adversary—rising sea levels brought on by man-made climate change—is relentless and merciless. It’s coming faster than we think. And unlike an earlier war between man and the so-called river of grass, this fight will have no winners.
The first war on the Everglades began over a century ago, when European colonists arrived in South Florida intending to grow crops and build cities, and instead found themselves wading through a mosquito-infested swamp. It was a dreary, dismal, abominable place, “suitable only for the haunt of noxious vermin, or the resort of pestilential reptiles” according to an early government report.


In other words, it was America’s last frontier, and man’s God-given right to conquer it. And so, men conquered, or at least they tried. For decades, efforts to tame the wetlands proved futile. The tides turned in 1928, when a devastating hurricane flooded Lake Okeechobee—the enormous freshwater reservoir that fed wetlands to south—sending nearly three thousand Everglades pioneers to a watery grave. That disaster prompted the US Army Corps of Engineers to erect an enormous dike around the lake, cutting off the Everglades’ lifeblood and draining hundreds of thousands of acres for agriculture. East, west, and south of Lake Okeechobee, the Army Corps dug thousands of miles of levees and canals to move water around in a more orderly fashion.
Fast forward to 2016. The Miami metropolitan area is home to nearly six million people and hundreds of billions of dollars’ worth of real estate. It’s a popular travel destination, a gateway to Latin America, and headquarters to major multinational corporations including Burger King and Office Depot. The gentle creep of freshwater down a hundred-mile-long, sixty-mile-wide river of grass is no more—it’s been replaced by the largest flood control structure in America.


A quick drive inland reveals what subjugation of the Everglades has wrought: an ecosystem in shambles. Reduced to less than half of their former extent and receiving only a third of the freshwater that they used to, most of the remaining wetlands are far too dry. Populations of native birds, fish, and reptiles have declined precipitously; invasive species are rampant. Toxic algae blooms are now a summertime tradition. So-called “white zones”—vast expanses of dead vegetation—speckle America’s largest wetland like canker sores.
Still, all of the ecological problems triggered by development and artifical drainage pale in comparison to the existential threat now posed by too much carbon in the atmosphere: sea level rise.
Since 1930, sea levels in South Florida have risen nearly a foot. The Intergovernmental Panel on Climate Change conservatively predicts another three feet of global sea level rise this century, as polar ice caps melt and warming seawater expands. The National Oceanic and Atmospheric Administration, meanwhile, projects up to six and a half feet of rise.
Hal Wanless, a geologist at the University of Miami who’s spent 50 years documenting the past 18,000 years of sea level changes in South Florida, thinks the highest government projections are too low. “The important thing we have learned from studying the past is that sea level rises in pulses,” he told me when I met him in his office on campus. These pulses, which have caused as much as thirty feet of sea level rise per century in the recent geologic past, are tied to periods of “rapid ice sheet disintegration” on Greenland and Antarctica.


Wanless believes we’re entering another such period now. And the evidence is certainly mounting. In the late 1980s, scientists were talking about how Greenland might start to melt due to global warming; by the mid 1990s it was already happening. Now, that melt is accelerating. A recent study in Geophysical Research Letters estimates that Greenland lost a trillion tons of ice between 2011 and 2014, contributing twice as much to global sea level rise as it did during the prior two decades.
All of this is just the beginning. A recent study in Nature Climate Change concludes that if every nation aggressively reduced its carbon emissions now, we’d still be locked into nearly 100 feet of sea level rise over the long term.
And when it comes to vulnerable coastlines, South Florida is at the top of the list. Not only is the region very flat and very low, it sits on a porous limestone bedrock built of ancient reef structures. “The analogy most commonly used is Swiss cheese,” Doug Yoder, deputy director of Miami Dade’s Water and Sewer Department, told me. Over thousands of years, acidic rainwater has eaten holes through the limestone, allowing the ocean to bubble up from below.


“You can’t build dikes or sandbars to keep it out,” Coral Gables’ mayor Jim Cason said. As mayor of a city that would have been underwater just a few million years ago, Cason is acutely aware of his community’s tenuous relationship with the sea. He has a saying about South Florida: “Our future is what happens to ice.”


“Many people still don’t get it,” Wanless said, describing an instance when he was called out to Miami Beach’s Public Works Department in 2009. At the time, the city’s now-infamous tidal flooding was just starting to garner attention. Wanless recalled a group of men in suits and ties saying, “Dr. Wanless, we’re having a problem. We need to know where to put the water.”
“I said, you can put it anywhere you want,” he told me. “It’s the ocean. It’s arrived.”
The battle against rising sea levels is conspicuous at Miami Beach, which is already spending hundreds of millions of dollars raising its roads and building pumps to divert the invading saltwater into Biscayne Bay. But along South Florida’s wilder coastlines, a more dramatic siege has garnered comparably little attention.


Take Cape Sable, a lonely expanse of marsh, mangrove swamp, and white sand beach at the southwest toe of Everglades National Park. Wanless has been trekking out here for decades, and he’s watched the shoreline fall back hundreds of feet. “This is a very dynamic area, and it gives us an inkling of the kinds of changes we’re going to see,” he said.
Cape Sable’s troubles began in the early 20th century, when settlers cut canals to the ocean to drain the inland swamp and gain access for cattle pasture. The land was eventually abandoned, but the canals remained and broadened over time, channeling saltwater into the sawgrass marsh, a freshwater ecosystem. Today, this is causing the marshes’ thick peat soils to collapse.


“You have to understand that these highly organic peat soils we have in the Everglades are a balance between the production of plant matter and the forces breaking that plant matter down,” Steve Davis, an ecologist at the Everglades Foundation, told me. “As these soils become exposed to salt, you strongly tip the balance toward a more rapid breakdown.”
Peat collapse is now being observed at freshwater-starved inland marshes, too, and as seawater continues to invade, the problem will get worse. “The more we look, the more evidence we see,” Davis said. “The rate of elevation loss we could be looking at is potentially dramatic.”
According to Erik Stabenau, an oceanographer with the National Park Service, the issue of whether or not to restore Cape Sable’s collapsed marshes—now open lakes of seawater—is complicated by sea level rise. “We can shut down the flow through the canals so you don’t get saltwater in there,” he said. “And we might be able to manage it for a generation or two. But we’re in the forever business.”


Further east, the ecosystems of Florida Bay are also suffering, thanks to historic drainage problems and modern climate change. Covering 800 square miles between the southern coastline and the Florida Keys, the bay is home to a stunning variety of plants, fish, and birds, endangered manatees, bottlenose dolphins, loggerhead sea turtles, and American crocodiles. Like a thirstier version of parklands to the north, it receives far less freshwater than it used to.
If there are too many hot days and not enough rain, salinity levels in Florida Bay skyrocket—which is exactly what happened last fall following a severe drought. The consequence? Tens of thousands of acres of seagrass wilted and died, blanketing the estuary in a plume of yellow sulfide.


For now, the die-off appears to have ended. But as miles upon miles of dead seagrass stews in the summer heat, it’s being gobbled up by jellyfish, which excrete nitrogen and phosphorus-rich waste. This, ecologists fear, could trigger an enormous algae bloom, choking out sunlight and sucking the remaining oxygen out of the bay. “It’s sort of a chain reaction that causes the die-off to persist over a long time,” Davis said.
One way or another, it’ll take the seagrass years to recover. In the meantime, Florida Bay will continue to fight storm surges and rising sea levels at half-health. Whether this means the ocean will plow further inland faster is unclear.
Eventually, the seawater will push inland, and if Wanless is right, eventually is coming soon. This adds urgency to the research of Troxler and her students. After watching a freshwater wetland get hosed down with brine, Mazzei and I drive south to a brackish site, where the same treatment is being applied. Here, the dearth of freshwater caused by recent drought and so many dikes up north has taken a toll. In some places, tufts of sawgrass stand nearly a foot above the peat; their long white roots exposed like teeth with receding gum lines.
Ben Wilson, an ecology PhD student from Alabama, is out in the muck taking measurements of carbon dioxide, methane, and other invisible gases from the saltwater addition plots. These chemical fingerprints, he explains, will help scientists understand how important ecological processes like carbon sequestration will be impacted by rising sea levels.


I ask Wilson if studying a doomed ecosystem gets him down at all. Not really, he says. “If we can learn anything that helps us preserve these ecosystems a little longer, to me that’s worth it.”
One could dismiss the plight of the swamp as trivial compared with the annihilation of entire cities along South Florida’s coastline, but the two are inextricably linked. The millions of people living in the Miami metro area drink from the Biscayne aquifer, a vast freshwater lens underlying much of South Florida. If the Everglades becomes too salty, so will Miami’s water supply. “The extent that these wetlands can hold together is the extent that we get water quality protection,” Troxler said.
Freshwater flows through the Biscayne aquifer in a southeasterly direction, mixing with seawater when it arrives at the coast. But as sea levels rise, the saltwater front is advancing. Already, this has caused a handful of drinking wells at Hallandale Beach to become contaminated. With another eight inches of rise, more than half of the flood control structures built to keep the seawater at bay could become useless. “Gravity is just not going to work as well as it used to,” Yoder said.


There is, however, a way to buy the communities of South Florida time: by restoring the flow of freshwater from the north to push back against the rising seas. And that’s exactly what Everglades conservationists have been fighting to do for decades.
A dozen miles west of Miami, the strip malls peter out and give way to expansive meadows of sawgrass, marking the edge of Everglades National Park. If you want to cross the park to catch a boat tour out of Everglades City, there’s only one direct route—the Tamiami trail.


Cutting straight across the park like a pencil line etched into a pastel landscape of muted greens and browns, the Tamiami trail was considered a feat of engineering when it was laid down in the 1920s. Now, as with many other legacies of South Florida’s development boom, it’s clear the highway has inflicted untold harm on the Everglades.
A canal roughly the width of the highway itself rims the Tamiami’s north-facing side, catching freshwater and diverting it east, to aquifers along the coast. “The Tamiami trail has become an obstruction to north-south water flow—it basically acts as a dam,” Julie Hill Gabriel, director of Everglades policy for Audubon Florida, told me. “One of our big challenges is, how do you get that obstruction out of the way?”


For now, the solution lies in raising parts of the road so that water can flow underneath. A one-mile section of the so-called Tamiami bridge was completed in 2013, and construction of another 2.6 mile segment could begin this fall. Eventually, federal government plans to extend the bridge up to 6.5 miles.
It’s a major symbolic victory for conservationists, but in reality the Tamiami bridge is a small piece of what’s needed to solve the Everglades’ water problems. The fundamental issue is that not enough fresh water comes south from Lake Okeechobee anymore—and that problem calls for more complex and costly engineering solutions.
That’s where the Comprehensive Everglades Restoration Plan (CERP) comes in. Formally launched in 2000, this multi-decade, Army Corps-led effort to restore the Everglades by putting the water back where it needs to be was initially pegged as a $10.5 billion project. Nearly twenty years in, it’s been plagued by delays and budget cuts, fought by agricultural lobbies, and remains nowhere near completion. Meanwhile, the estimated cost of CERP has soared.


One of the biggest challenges facing Everglades restoration is simply acquiring land south of Lake Okeechobee, in what’s known as the Everglades Agricultural Area (EAA). “We need big, engineered wetlands,” Zack Jud of the Florida Oceanographic Society told me. “Instead of flowing billions of gallons of water [from Lake Okeechobee] to the coast, we need to send it through filtration marshes, so that by the time it gets to the south, it’s clean enough to give to the Everglades.”
But most of the land that could store water to send into these wetlands is owned by several politically powerful sugar companies, who like South Florida’s plumbing the way it is.


In 2014, after a large parcel of land south of the lake went on the market, Floridians voted overwhelmingly in support of Amendment 1, which earmarked hundreds of millions of taxpayer dollars for its purchase. Instead, the state took that money and used it to purchase anything and everything else in the name of conservation. They even gave some of it directly to farmers. Environmentalists place the blame squarely on the sugar lobby.
“Amendment 1 was misappropriated, and we did not get the opportunity to buy land south of the lake,” Jud said. “The governor sided with the sugar industry.”


Despite recent setbacks, proponents of Everglades restoration are encouraged by the public support their cause has garnered. It’s now widely agreed that moving more freshwater south is our best (and perhaps only) shot at revitalizing the Everglades—stopping peat collapse, preventing seagrass die-offs, and allowing more natural ecological transitions to occur as climate change progresses.


What’s more, with rising sea levels threatening to wipe South Florida off the map, a healthy Everglades could be the last line of defense. “You could say Everglades restoration is a waste of money because it’s all going to be drowned anyhow,” Wanless said. “But if you can have a more reliable, higher level of freshwater running through the Everglades, and the wetlands can build up peat again, you can keep the saltwater encroachment at bay better. And that’s worth it’s weight in gold.”
“Putting that water back certainly buys us time,” Stabenau said. “It certainly buys us environmental resilience. Does it solve the problem forever? I don’t think sea level is going to come up just a few inches and stop. But if it turns out down the road that we have engineering solutions to climate issues and water problems, we’re buying ourselves time to figure that out.”
On my last day in the Everglades, I took a tour of Ten Thousand Islands, a swampy archipelago rimming Florida’s southwest coast. For thousands of years, Native Americans lived here like kings, feasting off oysters, crabs, lobsters, and fish. Peregrine falcons soared overhead as our airboat navigated tufts of land held together by twisted mangrove roots. The silhouettes of sausage-shaped manatees appeared and faded again. A bottlenose dolphin caught our boat’s wake and followed it, leaping in and out of the water as my tour guide made sharp turns to kick up surf.
In this tattered mosaic of water and land, the Everglades is still wild. The existential threats I’d spent the last week learning about seemed to fade into irrelevance. It was difficult to imagine how humans could destroy something so vast.


My guide seemed to share this view. The rise and fall of the sea, he said, was something that city folk in Miami worried about. Out here, the will of the ocean was inevitable, as much a part of the fabric of life as the rise and fall of the sun.
Florida will be underwater again someday, probably no matter what we do. But right now, on timescales that matter to people, it is people who will decide its fate.
As black-bottomed storm clouds rolled in, we hurried back to the shore.
Obviously, in order to answer this super-silly thought exercise, you’d have to make it a little bit more manageable to calculate. That means in this scenario, the Earth is perfectly round, has the same density all throughout, and won’t, like, scorch your bum when you fall through the core. Life Noggin explains the math behind how long it would take, giving consideration to all that gravity nonsense, and comes up with a shockingly small number.
It’s 42 minutes. Let’s start digging a hole.

Bagpipes and other wind instruments produce beautiful music, but they can also be prime breeding grounds for molds and fungi. Players then regularly breathe in those creatures, and can develop inflamed lungs as a result—or even a fatal lung disease.
That’s the conclusion of an unusual case study just published in the journal Thorax by researchers at the University Hospital South Manchester in England. They’ve dubbed it “bagpipe lung,” because that was this particular patient’s instrument of choice, but the same risk applies to any wind instrument, the authors caution.


We’ve all experienced that annoying nagging cough that lingers on after we catch a cold or the flu. Now imagine coughing for seven years. That’s what happened to the 61-year-old man in the case study. He was diagnosed with hypersensitivity pneumonitis (HP)—essentially chronic inflammation of the lungs usually brought on by inhaling dust, fungus, mold, or chemicals—which can lead to severe lung disease.
It can be difficult to pinpoint whatever triggered the onset of HP. This particular patient had none of the usual risk factors: there was no mold in his home, he hadn’t been exposed to pigeons or other birds, he didn’t smoke, and he didn’t work with chemicals.
But he did play his beloved bagpipes every day, despite having trouble breathing because of his inflamed lungs. Coincidentally, the only time his symptoms improved during those seven years was when he spent three months in Australia and left his bagpipes behind.


When samples were taken from the bag, neck, and reed protector of the instrument and placed in a petri dish, several different varieties of fungi bloomed.
It seems that yeast, mold, and other microbes really flourish in the moist environment provided by the bagpipes. The man had been breathing in these fungi every day when he played, triggering his HP.
Alas, the man did not respond to treatment and died from all the damage to his lungs. Granted, it’s a single isolated case, but there have also been reported (non-fatal) cases of HP in people who played the saxophone and the trumpet. There are no established guidelines on the best way to clean wind instruments, but lead author Jenny King and her colleagues advise regularly swabbing them with disinfectant after use, the better to keep the growth of microbes in check.
The case also illustrates just how vital it is to take a detailed, thorough case history, including patient hobbies. If doctors and musicians become more aware of this particular health risk, maybe the next bagpipe player with a chronic cough won’t have to wait seven years to pinpoint the trigger.
UPDATE: 8/23/16 12:45 PM: The fine folks at the Piping Live! Glasgow International Piping Festival have recorded a helpful video at the National Piping Centre to show musicians how to properly clean their bagpipes.

[Thorax]
Generally, if scientists want to see how a living thing functions in high resolution, they need to slice it into tiny pieces first. Now, there’s scientists a powerful and bizarre new tool in researchers’ arsenal.
According to research published in Nature, a new technique called ultimate 3D imaging of solvent-cleared organs (uDISCO for short) makes mice look like glow-in-the-dark gummy bears.
uDISCO isn’t completely new, but it was recently perfected by Ali Ertürk of the Ludwig Maximilian University of Munich. It uses genetic modification to make a specimen’s proteins glow green, making them easy to identify by laser scanning. As for the “solvent-cleared organs” portion of the name, therein lies the gruesome bit: water and fat are chemically stripped and dehydrated out of the specimen over the course of several days, shrinking it by as much as 65 percent. The process even turns bones transparent.


The result, in this case anyway, is a small, nearly transparent mouse whose nerves and organs can be viewed with terrific detail. The essential parts of the mouse are exactly where they normally are, with the extraneous stuff is removed or made see-through.
Chief among uDISCO’s potential applications is the possibility for mapping the human brain, as well as learning about diseases that affect it like Alzheimers and Parkinson’s. The level of detail achievable through the technique is best illustrated by the video below, which includes a fly-through of a mouse’s nervous system. (Which let’s not even pretend that isn’t the coolest shit you’ve seen today.)


[Nature, New Scientist, Motherboard]

The “coffee ring effect” is that pattern you get when a single liquid evaporates and leaves behind a ring of previously dissolved solids. In the case of coffee, that would be the coffee grounds. A new paper in Physical Review E. demonstrates that we still have a lot to learn about this seemingly simple everyday occurrence.
Physicists know that the ring occurs because the liquid evaporates more quickly at the edges of the drop than at the center. So the remaining liquid at the center will flow outward to the edges to fill in the gaps, dragging particles like coffee grounds with it. Those particles stick to the surface at the edges of the ring—hence the dark outline around the stain.


The more you know about the various forces at play during this process, the better you can predict where those grounds will end up. So physicists engaged n fluid dynamics research are naturally keen to lean more about the coffee ring effect. It doesn’t just appear in coffee. Whiskey will also leave telltale rings, as will any other liquid with tiny particles suspended in it: blood, paint, and ink, for instance.
Lehigh University graduate student Baiou Shi accidentally spilled her coffee one morning in the lab, and just as she was about to clean it up, her advisor, Edmund Webb, stopped her: “Don’t do it!” That inspired them to run their own computer simulation of how a drop spreads out on a flat surface.


They didn’t simulate coffee, however, but a drop of lead filled with tiny copper particles on a copper surface, which simplifies the physics just a bit—the better to calculate all the forces involved. And they used surfaces with different crystal structures to get a better idea of how the spreading of the drops can vary, and what impact this has on if and how the particles eventually stick to the surface at the outer edges of the resulting ring.
Shi and Webb’s simulation showed that a very thin film will form on the surface, just ahead of the spreading droplet, and unlike the drop, it doesn’t stop spreading once the dark outer ring has formed. They’re not sure why; more experiments and simulations will no doubt be in order. But if physicists can crack the mystery, they’ll be able to manipulate these kinds of liquids at the nanoscale, opening up a host of potential applications in medicine and high-tech manufacturing.
[Physical Review E via Physics Buzz]
Remember that time Stephen Colbert brought physicist Brian Greene on The Late Show to demonstrate the concept of gravitational waves with green lasers? Yeah, that was pretty awesome. Now there’s a handy DIY demonstration for those of us without access to that kind of technology, courtesy of science presenter Steve Mould.
For those who haven’t been following the biggest science story of the year, gravitational waves are light-speed ripples in the fabric of spacetime caused by such epically violent events as exploding stars and black hole mergers. They’re incredibly tiny and difficult to detect, but the Laser Interferometer Gravitational Wave Observatory (LIGO) did just that, announcing the first direct detection in February. They announced a second detection in June.


But Mould felt something was missing in the deluge of explainers, graphics, and animations spawned by the discovery. “In all the graphics that I’ve seen, there’s a kind of disconnect between the objects and the waves that they produce,” he explains in the video. “There’s no way to see how one causes the other, and I think we can fix that with an actual physical demonstration of gravitational waves.”
First, build your own spacetime warping demo with stretched spandex lycra, marbles, and weights. Then mount a couple of little wheels onto a wooden plank to simulate a pair of binary black holes, and use a drill to set them rotating at the requisite 18 times per second. Voila! Ripples in the fabric of your two-dimensional spacetime.

[The Kids Should See This]
We already know that spider silk is something of a wonder material, but scientists are still discovering more awesome things that it can do. An international team of researchers has found that spider silk shares a useful property with semiconductors—except rather than exploiting this to manipulate electrons, it can be used to manipulate sound and heat.
As described in a new paper in Nature Materials, spider silk can block certain quasiparticles of sound (called “phonons”), depending on their frequency, the same way semiconductors can block certain electrons. “There’s a range of frequencies that are not allowed to propagate,” co-author Edwin Thomas of Rice University said in a statement. “If you broadcast sound at a particular frequency, it won’t go into the material.”


It’s known as a band gap, and it’s what lets scientists effectively “tune” materials with this property for specific applications. Photonic crystals—opals are a naturally occurring example—do this for light waves. Phononic crystals do the same for sound, but this is the first time anyone has found such a band gap in this kind of material.
Spider silk is as strong as steel and as stretchy as rubber, on a weight-to-weight basis. That’s why it’s inspired lots of synthetic materials mimicking those properties, such as Kevlar and nylon. Plus, spider silk is sticky (the better to catch unsuspecting prey), has natural antimicrobial properties, and is both hypoallergenic and biodegradable.


Those nifty properties all arise from spider silk’s intricate crystalline structure. There are rigid layers to hold the silk together, soft areas to keep it flexible, and within those soft areas, places that enable the silk to stretch. Two proteins rich in the amino acid alanine are embedded in a jelly-like polymer make up the fiber, although another amino acid, glycine, makes up 70 percent of the material. One of those two proteins has a highly ordered structure, while the other has a less ordered structure. That tension between order and disorder gives the silk its strength and stretch.
Spiders can also sense when a web is damaged, or when prey becomes trapped, via vibrations that travel through the web, just like sound waves move through the air. Apparently they can distinguish between different frequencies because of spider silk’s unusual dampening ability.
When Thomas et al. examined the microstructure of spider silk, they found that stretching or relaxing the softer chains that connect the harder protein crystals also changes the material’s acoustic properties. They could also control the position of the band gap, simply by changing the strain in the silk fiber. Spider silk can even be tweaked to have unusual thermal properties.
“Phononic crystals give you the ability to manipulate sound waves, and if you get sound small enough and at high enough frequencies, you’re talking about heat,” Thomas explained. “Being able to make heat flow this way and not that way, or make it so it can’t flow at all, means you’re turning a material into a thermal insulator that wasn’t one before.”


If scientists can replicate that crystalline microstructure that makes spider silk so special, it could translate into all kinds of interesting applications for new synthetic materials—waveguides, for instance, or materials that can dampen sound or provide insulation.


[Nature Materials]
It’s been 20 years since the birth of Dolly the Sheep, the first mammal to be cloned from an adult. Because Dolly died prematurely, scientists have worried that cloning accelerates the aging process. But a new analysis of 13 cloned sheep—including a batch of Dolly’s genetic duplicates—shows this isn’t the case.
In a study published in Nature Communications, researchers from the University of Nottingham have shown that 13 cloned sheep, four of which were genetic duplicates of Dolly, have reached an advanced age in good health. It’s the strongest evidence yet that large cloned animals age normally. This is an important result given that many animals are now being cloned on a regular basis—and that humans may eventually be produced with the technique.
Human cloning is currently illegal in virtually all parts of the world, but that doesn't mean…
Dolly, born on July 5, 1996, was produced by a cloning technique known as somatic-cell nuclear transfer. She lived her entire life at the Roslin Institute in Edinburgh, UK, but had to be euthanized after developing a progressive lung disease and severe arthritis. Most sheep live to be about 11 or 12, but Dolly lived just 6.5 years. Dolly’s death prompted concern that cloned animals age more rapidly, or less healthily, than sheep born naturally.


To see if this is in fact the case, Nottingham researcher Kevin Sinclair and colleagues studied 13 cloned sheep between the ages of seven and nine (the equivalent of 60 to 70 human years). All 13 sheep were assessed for muscular and skeletal health, glucose tolerance, insulin sensitivity, and blood pressure, and were administered metabolic and x-ray exams. Results showed that all the clones are healthy, except one sheep with mild osteoarthritis. Their health was compared to a group of naturally bred six-year-old sheep living in similar conditions.
Results of the tests showed that none of the cloned sheep exhibited signs of diabetes, hypertension, serious arthritis, or abnormal blood pressure. Importantly, all of the sheep survived their first 6.5 years, surpassing Dolly’s lifespan. It’s worth pointing out that the researchers did not test for telomere length, a molecular marker linked to age-related diseases.
These results suggest that Dolly was a bit of an anomaly. And in fact, other sheep in Dolly’s flock died of the same rare lung disease, a condition which may have been a consequence of being raised indoors. So it seems that environment, rather than genetics, may have ultimately been responsible for Dolly’s premature demise. SCNT as a reproductive technique is still far from perfect, but this research strongly suggests that clones can live long and healthy lives.


[Nature Communications]

Meet the Eye of Horus. It’s a newly discovered galaxy system that’s hiding something incredible in those fuzzy swirls of light circling it: a way of looking back into even further and older galaxies.
The new galaxy system was discovered by the National Astronomical Observatory of Japan using the Subaru Telescope over the course of a massive survey that it’s been conducting of deep space. During a session for student astronomers, the galaxy was flagged for its unusual appearance. In addition to the galaxy you can see right in the center of the above image, there are actually multiple galaxies behind that appear as swirling lights you see around the main galaxy’s center.


That we can see the more distant galaxies at all is due to gravitational lensing. It’s the same phenomenon responsible for letting us see those images of galaxy clusters in deep space through the Hubble telescope. The strong gravity of multiple galaxy clusters makes the space around them bend, which means the light around them also bends. This creates a “zoom lens” into space which we can combine with the power of telescopes like the Hubble to see incredibly deep and far into space.
Stare deep into this abyss. What you are seeing right now is one of the deepest views into space…
The phenomenon occurs with single galaxies, too. When a galaxy has a strong enough gravity to bend the space around it into a lens, it can sometimes reflect a galaxy behind it, so that it initially appears to be part of the galaxy itself. That’s what’s happening in the Eye of Horus—except there are two separate galaxies, creating two separate reflections. You can see them in this diagram:
The end result of this effect is that both galaxies—one 10.5 billion light years away and the other 9 billion light years away—are reflected in different rings. Although many galaxies can reflect a single galaxy behind it, the Eye of Horus’ ability to reflect multiple galaxies is rare. Researchers at NAOJ hope to find even more examples of this phenomenon as they continue the survey.
Our current solution to apples that start to soften (just bake them into a pie) has been working darn well. But a new method could give us apples that stay crisp for several weeks.
A team of researchers used a specially designed plasma tool, based on one that had been used in hospitals to disinfect wounds, to wipe out the bacteria on the surface of the apple. They found that, when given a blast with this tool, the apples stayed fresh for considerably longer. Their results are published today in a paper in Physics of Plasmas.


“Fruits or vegetables turn bad mainly due to the bacteria,” co-author Xinpei Lu of China’s Huazhong University of Science and Technology told Gizmodo. “That’s the reason why we keep fruits [at] either a low temperature, or in nitrogen gas, or vacuum packed to avoid the growing of bacteria, and thus to extend the shelf-life.”
Using the plasma tool eliminates bacteria that forms a biofilm covering the apple. “If biofilm is formed, the fruits will turn bad in few days,” Lu noted. With this new technique, however, he said that time was stretched into weeks. “I would say that extended shelf-life up to several weeks should be fine.”


Of course, it’s already been possible to give apples a pretty long shelf-life. Apple-growers use everything from just plain cold storage to chemical treatments designed to slow ripening, which can give apples shelf lives of several months not weeks.


Still, this new tool could have applications beyond apples. This research team is currently looking into how they could use the tool over a much bigger selection of fruits and vegetables to keep them fresh as well.
The ability to control fire brought our ancestors countless benefits, but as a new study by Australian researchers suggests, it may have also triggered the spread of one of the worst blights to afflict our species: tuberculosis.
Mathematical biologist Mark Tanaka from the University of New South Wales hypothesizes that controlled fire use in early humans created the perfect conditions for tuberculosis to mutate from a harmless soil bacterium into our top microbial killer. In a paper published in Proceedings of the National Academy of Sciences, Tanaka suggests that campfires brought more people together and contributed to smoke-damaged lungs— factors that increased the likelihood of tuberculosis making the leap to ancient humans and then spreading within the population.


Tuberculosis emerged as an ancient human disease thousands of years ago, but scientists aren’t entirely sure when or how it happened. It’s generally agreed that TB emerged in Africa thousands of years ago, first establishing itself in human populations, and then spreading from humans to animals (oops, our bad). TB, which is spread through the air, is caused by the Mycobacterium tuberculosis complex (MTBC) and most commonly affects the lungs. Today, it’s responsible for nearly 1.5 million deaths each year, making it the top bacterial killer of humans. And if Tanaka’s new theory is correct, we have campfires to blame.
“When fire was controlled around 400,000 years ago in human populations, probably cultural practices changed, so there would have been increases in social interactions, increases in population density and increased time for interaction into the night,” Tanaka told Australia’s ABC News.


Normally, bacteria found in the soil can’t make the leap from ground-dwelling organism to one that can thrive in the human body. To do so, it has to undergo a mutation that allows it to work within the biological system of another species. This happens exceptionally rarely, but it does happen. In addition to this fortuitous mutation, it also has to spread to a host and then propagate from there.


The only reasonable way for this to happen—outside of freakish luck—is for humans to develop an increased susceptibility to the microbe, contract the mutated microbe, and then spread the disease within the population. Campfires, argues Tanaka, provided these opportunities.
“You get multiple sporadic cases, and most of them fail in the sense that they fail to evolve and so there are multiple failed chains of transmission, but eventually the right mutations come along and the whole thing is triggered,” he told ABC News. Tanaka’s mathematical model shows how an otherwise harmless bacterium like M. tuberculosis is capable of developing into a transmissible pathogen. It’s not definitive proof, but it’s an intriguing possibility.
An interesting ramification of this study is the association of new technologies with the emergence of pathogens. As Tanaka and his colleagues aptly conclude in their study, “Our results have serious and cautionary implications for the emergence of new infectious diseases—feedback between cultural innovation and alteration of living conditions can catalyze unexpected changes with potentially devastating consequences lasting thousands of years.”
[PNAS via ABC News]
Take a good hard look at the weather we’ve been having lately: the Earth doesn’t want us here anymore. It’s been politely hinting we’ve overstayed our welcome for some time, and now it’s resorted to throwing plates. We did this to ourselves. It’s time to bow out gracefully.

This most recent spate of terrifying phenomena arguably began weeks ago in West Virginia, where storm and hail (in the summer...in the South...) left thousands without power.

California’s “sand fire” continues to engulf more than 35,000 acres of the Santa Clarita Valley. Five years of drought and 14 consecutive months of record breaking temperatures combined with a heat dome will do that. Fire crews are struggling to contain it by land and by air. Normally sand + fire = glass, but not in these trying times. We just get more fire.

Meanwhile, tornados have been cropping up with starting regularity throughout the Midwest, with severe storms on the way. It seems Iowans are equally culpable in whatever we did to make our planet so unhappy.

Heavy storms and flooding wrecked havoc on Chicago’s public transit, with one driver capturing dramatic video of a metal canopy collapsing onto the Blue Line tracks in a hail of sparks. Lightning in the area also gave a hearty “fuck you” to one pole in particular. Is it obvious we’re really screwed yet?

And then there was last night in New York, where severe storms turned the subways into waterfalls, the Long Island Rail Road got a much-needed bath, and lightning stuck the Empire State Building. If that’s not a metaphor I don’t know what is.


And don’t worry, there’s plenty more bullshit on the way.
Ceres, the tiny asteroid belt world we’ve come to know and love through NASA’s Dawn mission, seems to delight in mysteries, from flickering bright spots to unexpected ocean minerals. Now, astronomers have discovered yet another puzzle while examining images of Ceres’ surface. Something has been erasing its craters.
Craters offer a window into a planet’s history, which is why they’re one of the first things astronomers examine when trying to understand a new object. For instance, one of immediate shocks from the New Horizons Pluto flyby last summer was that Pluto’s surface is mostly crater-free, indicating a geologically active interior.


Based on the heavily battered appearance of other asteroid belt objects, astronomers expected that our first close-up glimpse of Ceres would yield numerous large craters. Instead, we didn’t find any.
When Simone Marchi of the Southwest Research Institute and his colleagues analyzed global image and topography datasets collected by the Dawn spacecraft over the past year, they discovered that most of Ceres’ craters are less than 60 miles (100 kilometers) wide. That’s in spite of the fact that neighboring minor planet Vesta, which Dawn visited first, has craters of up to 300 miles (500 kilometers) across.
“This was a total surprise,” Marchi, who led a crater analysis published today in Nature Communications, told Gizmodo. Considering Ceres’ size and its 4.5 billion year history, “it is extremely unlikely that Ceres was not hit by large objects,” Marchi said.


That means something has been eating away at Ceres’ big craters over time. Space Cthulhu aside, astronomers have a few hypotheses as to what it could be.
The first is that Ceres’ internal structure is responsible. Other recent work, including several detailed analyses of the dwarf planet’s bright spots, points to a layer of ice and salt just beneath the surface. Over geologic time, the flow of this briny mantle could have flattened out the overlying topography, a process known as “viscous relaxation.” As study co-author Michael Bland of the US Geological Survey pointed out, viscous relaxation flattens out big craters faster than small craters.
An even more intriguing hypothesis is that large craters have been erased by ice volcanoes. “We have these bright spots all over the surface—clearly, that’s stuff that came out of the interior,” Marchi said. It’s possible that Ceres was much wetter in the distant past, and that an early period of intense cryovolcanism dramatically altered the surface we see today.
Dawn’s most recent datasets could offer answers. The spacecraft is currently in a low-altitude orbit, snapping high resolution surface photos and taking detailed gravity measurements as it rotates Ceres every 5.4 hours. “With this high-resolution data, we can look more specifically at sites on the surface that may have evidence of large-scale cryolavas,” Marchi said. And with the gravity field data, we’ll get a clearer picture of Ceres’ interior, including its layering structure and any subsurface anomalies.
To Bland, the mystery of Ceres’ missing craters underscores the importance of designing missions to visit multiple targets. “Because of Dawn’s exploration of Vesta, we have a really good idea how many craters we should see on Ceres,” he told Gizmodo. “That is, Vesta provides a critical data set to calibrate our models of crater production on Ceres.”


“Ceres is unlike any other [asteroid belt] objects we’ve been able to sample through meteorites,” Marchi said. “I have no doubt there is a big story here.”
Most American adults are nervous about the prospect of enhancing humans beyond normal capacities, a new Pew Research Center poll reveals. But while many of those surveyed expressed concerns about brain-boosting chips and designer babies, a significant number had a positive view of technology’s ability to transform humans and society.
What makes this new poll particularly interesting is that the Pew Research Center sought to assess the public’s reaction to, and perceptions about, technologies that don’t even exist yet. What’s more, these pending technologies—unlike flying cars and space elevators—promise to alter and augment human capacities in some rather profound ways, such as boosts to intelligence, strength and stamina, and resistance to diseases. But as the results of the poll show, most Americans aren’t ready to buy into this biologically enhanced future.


More than 4,700 American adults were asked to consider the ramifications of three different, but still hypothetical, biomedical interventions. These included gene-editing to prevent babies from developing serious diseases, implantable brain chips to give people improved ability to concentrate and process information, and the prospect of synthetic blood transfusions to endow people with greater speed, stamina, and strength. The Pew researchers carefully chose these three enhancements following focus group sessions and advice from experts. The idea was to pick interventions that touched upon an important aspect of human enhancement, while still remaining relatively straightforward and constrained.
According to the results, 68 percent of Americans are either “very” or “somewhat” worried about gene-editing, while 69 percent and 63 percent had the same opinion of brain chips and synthetic blood (respectively).


Consistent with these results, 66 percent said they would not want brain enhancements, and 63 percent would not want synthetic blood transfusions. Interestingly, respondents were split on the question of wanting gene-editing to help prevent diseases for their babies: 48 percent said they would, while 50 percent said they would not. This is a particularly interesting result given the potential for CRISPR—a powerful new genetic cut-and-paste tool—to actually make this happen. Last year, scientists in China became the first in the world to use the system to genetically modify human embryos, which were destroyed soon after.
After weeks of speculation, it can finally be confirmed that geneticists in China have modified the …
The majority of those polled worried that such enhancements will exacerbate the divide between the haves and have-nots. Specifically, around 73 percent believe social inequality would result if brain chips are initially available to only the wealthy. More than two-thirds believe that these technologies will become available before they’re fully tested or fully understood. At the same time, many Americans believe that these technologies are going to happen, regardless of their own opinions; close to half think these changes to human capacities, or changes like them, will become common in the next 50 years.
A majority of those polled believe such enhancements are morally unacceptable, while only 36 percent believe that gene-editing will have more benefits than downsides. Opinion is roughly split on the question of whether or not these interventions qualify as “meddling with nature.”
Results of the survey were sorted according to age, gender, socioeconomic status, education, and so on, but the true delineator of opinions was the strength of religious convictions. “Religiosity definitely stands out as a key divide in how people are thinking about these issues,” said Cary Funk, Associate Director of Research at the Pew Research Center. The more religious the respondents, the less likely they were to accept these prospective enhancements. Around six in 10 people rated high in religious commitment agreed it was meddling with nature and that it was a “line that should not be crossed.” Conversely, a majority of people assessed as being non-religious believe each of these enhancements would be no different from other ways humans are trying to better themselves.


Men and women also shared differing opinions. Around 43 percent of women were in favor of gene-editing for their offspring, compared to 54 percent of men. The same went for brain chips (26 percent vs 39 percent) and synthetic blood transfusions (28 percent vs 43 percent).
The more extreme the enhancement, the less likely people were to support it. Same for the degree of permanence. For example, nearly half of respondents were willing to accept blood transfusions if the resulting impacts on strength, stamina, and speed matched a person’s own peak ability. But if the intervention resulted in physical abilities “far above that of any human known to date,” only 28 percent believed it was an appropriate use of the technology. Similar results were recorded for use of brain chips.


An interesting take-away of the survey is the consistency with which Americans view enhancement technologies. “Because the three [technological] scenarios were so different it was striking to see how similar these patterns were in terms of their thinking about what would be more acceptable,” Funk told Gizmodo. Accordingly, the survey also showed similarities between opinions on these speculative enhancement technologies and those already in existence, including elective cosmetic surgery, laser eye surgery, skin or lip injections, hair replacement surgery, and contraceptive surgery.
To supplement the survey, Pew organized a series of focus groups. Most who participated felt that no effort should be spared to help the sick, but that society should proceed cautiously to avoid the creation of “superhumans” or human “robots.” Interestingly, some people ranked high in religious commitment had no problem with “playing God,” arguing that God wants humans to make the most of their abilities and improve humanity. Other themes discussed included the need for oversight and regulation, and the suggestion that no enhancement should ever be imposed on anyone against their will.


James Hughes, the director of the Institute for Ethics and Emerging Technologies (IEET), has mixed feelings about the poll results. A technoprogressive bioethicist, Hughes is largely in favor of human enhancement, though under strict conditions.


“Respondents had a mostly positive view of the effects of science and technology on society, and their concerns about enhancement were focused on safety and inequality,” Hughes told Gizmodo. “Safety and equity are things that can be addressed by public policy, so even if they were more worried than enthusiastic about brain chips or gene editing, those concerns can be alleviated.” He believes that concerns about brain chips being “the mark of the beast,” as some in the focus groups expressed it, are less tractable, but nothing that bothers atheists and agnostics.
Brave New World used to be one of the most terrifying stories about a false utopia. It gave us the…
Hughes says that these technologies result in a kind of “future shock,” and that acceptance takes time. “It is a process, and the evolution of public opinion towards acceptance is fairly predictable,” he said. “The danger is that new technologies can get linked to irrational anxieties—about terrorism, for instance, or crime or immigrants—before they become normalized.” Hughes believes the same thing is likely going to happen with robotic driving, where the public will be much more freaked out by infrequent robo-accidents then by the thousands of daily deaths from human driving.


Eventually, the area of overlap between technologies that simply remedy our health problems and those that enhance our capabilities will widen, further complicating the issue (this is what’s referred to as the “therapy versus enhancement” debate). Hughes questions the wisdom of banning a therapy, for example, that would in effect work to fight off multiple diseases. “When people and politicians finally confront these questions they will come around to supporting the benefits of enhancement,” he said.


“These are public issues—science issues are civic issues, and clearly technologies like CRISPR and others are raising broader social and ethical debates, and the public is part of that,” Funk said. “This is an early look to find out where the public stands on these issues, and I think that has an importance for our broader debate.”
[Pew Research Center: Survey Findings, Focus Group Findings]

By studying the genomes of more than 5,000 Samoans, researchers have uncovered a single gene that boosts a person’s obesity risk by upwards of 40 percent. Remarkably, this gene—which appears in a quarter of all Samoans—may have arisen in the population as they colonized the South Pacific.
As described in the latest edition of Nature Genetics, this “thrifty” genetic variant, called CREBRF, is associated with a 1.5 percent increase in Body Mass Index (BMI). So, for a person of average height weighing around 180 pounds, this gene corresponds to an extra 10 pounds. As noted by the researchers in their study, CREBRF promotes more efficient storage of fat and features “an effect size much larger than that of any other known common BMI risk variant.”


Working with colleagues from several universities, Stephen McGarvey from Brown University made the discovery while scanning the genomes of thousands of Samoans. This populations has some of the highest obesity rates in the world, a fact that prompted the scientists to conduct a genetic investigation. Around a quarter of all Samoans involved in the study had the genetic variant, which was associated with 30 to 40 percent increased odds of being obese compared to those who don’t have the gene. At the same time, this gene is virtually non-existent in European and African populations and occurs at very low frequencies among East Asians.
“Although we have found a genetic variant with a reasonable biological mechanism, this genetic variant is just one part of the many reasons for the high levels of BMI and obesity among Samoans,” noted McGarvey in a press statement.


Other factors include diet and physical activity. Indeed, the globe’s shift to calorie-rich processed foods and more sedentary lifestyles has contributed significantly to the elevated rates of obesity among Samoans. But as this new study points out, their genetics are also working against them.


This gene appears to work by causing cells to store more fat and release less energy. As Alice Klein pointed out in New Scientist, it’s as “if [cells] are trying to conserve as much fuel as possible.” And indeed, there may be a very good reason why this gene appears at elevated levels among Samoans. It has to do with their history of colonizing the South Pacific Islands.
The 24 major island groups of the Pacific Ocean were settled by early Austronesians between 3,500…
Starting around 3,500 years ago, ancestors of Samoans began the arduous task of settling the 24 major island groups of Polynesia. This colonization process—one of the most extreme examples in all of human history—took possibly thousands of years to complete. “They had to endure voyages between islands and subsequently survive on those islands,” study co-author Ryan Minster told New Scientist.
As Darwin pointed out many years ago, evolution requires long timescales. But in some instances, when environmental conditions are particularly severe and attritional, selectional processes accelerate the process—an evolutionary phenomenon dubbed “punctuated equilibrium” by the late evolutionary biologist Stephen Jay Gould.


The problem, however, is that Samoans no longer require this gene. This would explain why upwards of 80 percent of men and women in Samoa are now overweight. “Samoans weren’t obese 200 years ago,” noted McGarvey. “The gene hasn’t changed that rapidly—it’s the nutritional environment that changed that rapidly.”
[Nature Genetics via New Scientist]
Keeping a tomato flavorful and firm past a few days is no easy task, as anyone who has made the catastrophic mistake of sticking a tomato in the fridge can attest. Now, new research could finally give us a much longer span of time to eat that tomato.
The short shelf-life of a tomato is due to the texture more than the taste. Eat a tomato too soon and the tomato will be flavorless and hard. Wait even a little too long and the tomato turns to mush. A new paper out today in Nature Biotechnology from researchers at Britain’s University of Nottingham finally reveals the enzyme responsible for making tomatoes soften so fast.


The enzyme is pectate lyase. Even more intriguingly, the researchers say that silencing the gene for that enzyme doesn’t appear to have an impact on other signs of tomato ripeness, like color or taste.
“The potential for extended shelf life is apparent,” lead author of the paper, the University of Nottingham’s Graham Seymour, told Gizmodo. “The data we have indicates that the modifying softening in this way has no effect on taste metabolites, including sugars, acids or volatiles.”


But before we can really know just how long the tomato will last—and how it will taste both at the beginning and end of a longer shelf-life—we’ll need to wait for the researchers to do extended tastes into both flavor and lifespan. Until then, the best plan is simply to eat your tomatoes quickly, while the season lasts.
Diehard fans of space exploration, rejoice! That pseudonymous foul-mouthed mastermind, exurb1a, who gave us the universe in just four minutes, is back with an irreverent video tackling the colorful history of rocket science.
It’s set to the tune of “I Am the Very Model of a Modern Major General” from Gilbert and Sullivan’s The Pirates of Penzance—although calling it a “tune” might be pushing that definition a bit. It’s more of a rapid-fire recitation with piano accompaniment.


The lyrics touch on the Chinese discovery of gunpowder, Isaac Newton, the invention of liquid-fuel rockets, the Sputnik era, the first manned moon landing, the International Space Station, and the emergence of private rocket companies. Plus the odd cutting remark about the JFK assassination, NASA funding cuts, Total Recall, and Pokemon Go. (“Team Mystic represent by the way. We’ll bathe in the blood of our enemies.”)

If you’re keen for more, exurb1a also has a Patreon page, where you can donate to support future videos. Personally, I’d love to see his cover version of “Total Eclipse of the Heart,” played entirely on the Belgian nose flute.


Little is known about the mysterious exurb1, but he claims to live in Eastern Europe with a trusty pencil named Tim. Per the Patreon page:
“I currently make Youtube videos with snatches of my time in between working and my other hobbies which include: working, managing a Mexican drug empire, and working.... When I was young I wanted to be a musician. But I’m terrible at piano. So I decided to be a writer. I was atrocious at writing. I got a little older. Youtubing seems to be going all right. And by all right I mean mediocre content and angst.”
[Laughing Squid]
In need of a quick refresher course on, well, the science of pretty much everything? Here’s a…
Buried inside ancient grains of rock salt, a team of geologists has discovered traces of a breathable, animal-friendly atmosphere. If confirmed, the finding will push back the rise of oxygen on Earth hundreds of millions of years, raising new questions about the evolution of complex life both here and beyond our solar system.
Earth may be our cozy blue marble today, but hop in a time machine and travel back two billion years, and you’d soon asphyxiate from a lack of oxygen. While scientists have found traces of oxygen on Earth dating back more than three billion years, it took eons of microbial activity before the air became anything close to what we’d consider breathable.


According to models and indirect geochemical evidence, atmospheric oxygen levels rose sharply toward the end of the Neoproterozoic era some 600 million years ago, closely coinciding with the appearance of marine animals in the fossil record. But a new study published in the journal Geology calls that date—and its tight link to the emergence of multicellular life—into question.
“Scientists have long debated which came first: higher life or O2,” Uwe Brand, a geologist at Brock University and co-author on the study told Gizmodo. “With our finding, we can put that debate to rest.”


By analyzing air bubbles trapped inside 815-million-year-old grains of halite, or rock salt, Brand and his co-authors have now produced the oldest direct measurements of an oxygen-rich atmosphere. The ancient air samples have oxygen contents ranging from 10.3 to 13.1 percent, more than five times higher than what scientists had previously estimated for the mid Neoproterozoic. (Our modern atmosphere is approximately 21 percent oxygen.)


“I think our results will take people by surprise,” study co-author Nigel Blamey told Science News. “We came out of left field, and I think some people are going to embrace it, and other people are going to be very skeptical. But the data is what the data is.”
The scientists are continuing to study additional halite grains from earlier and later chapters of Earth’s history, and they hope to have a more detailed chronology of the rise of oxygen soon. If their initial discovery holds up, it’d imply a substantial gap between the emergence of oxygen and the rise of animals during the Cambrian explosion, suggesting that some other preconditions had to be met before multicellular life took over.
And that would have profound implications for the discovery of complex life beyond our solar system. With Earth as our only example to go on, one might assume that complex life always follows an oxygen-rich atmosphere. If it turns out that’s not the case, then biospheres like our own and beings like ourselves may be less cosmically common than we hope.
[University of Aberdeen News via Science News]


This article has been updated to reflect additional comments from the researchers.
Look closely at this photograph of Saturn. There, in the planet’s two outermost rings, is something very strange. Right where they pass behind the planet, those rings are bending.
This photograph of Saturn’s bent A and F rings was snagged by Cassini’s Saturn-monitoring cameras from over 1 million miles away last month and just released by NASA today. What’s going on isn’t a real bend, though, it’s an optical illusion caused by the incredible brightness of the rings.


Saturn’s rings throw off a considerable amount of light, more even than any of the stars around the planet. A lot of that light is absorbed by the planet’s atmosphere, but some of it also simply passes through the atmosphere. When the light passes through, the atmosphere acts like a lens, bending it as it moves into space.
The end result is that rings appear to bend around the planet, even though Saturn’s rings remain as straight as ever. You can see the full photograph below:
Environmentalists in Siberia are expressing concern over an ongoing fire at the world’s largest sawdust dump—a fire that’s been burning since 2013 and will continue to do so for years to come.
As The Siberian Times reports, the monumental mountain of sawdust—which caught fire three years ago—is located in the Ust-Kutsky district of Irkutsk, and measures more than 10.4 hectares (25.7 acres) in size. That’s roughly the size of 800 Olympic swimming pools.


According to a council spokesperson, “It is now impossible to extinguish [the] dump with such an amount of sawdust,” adding, “Obviously, it will keep burning for a few more years.”

Adding insult to injury, 15 trucks arrive each day from the Trans-Siberian Forest company carrying 70 cubic meters (2,500 cubic feet) of sawdust waste. They’re literally adding fuel to this fire. Estimates place the total amount of sawdust at the site at about two million cubic meters (70 million cubic feet). To prevent the spread of smoldering flames, the company has constructed a “mineral border line” around the dump (guessing that means a bunch of rocks), and a fire crew is on permanent standby.


“Over the past three years this fire has caused dangerous smoke to Ust-Kut and nearby settlements multiple times, with overall population of about 50,000 people,” noted Alexander Yaroshenko, head of the Forestry Programme of Greenpeace Russia, in The Siberian Times. “That is an emergency situation of at least regional scale.”
[Siberian Times]

Shifting winds and blazingly hot temperatures are fueling a wildfire in southern California that has now spread to 51 square miles and is now threatening several neighborhoods.
The Sand Fire—named for the area’s Sand Canyon—started on July 22 and has now grown to 33,000 acres. This troublesome blaze is currently burning near Big Sur and the Angeles National Forest east of the Santa Clarita Valley, about 30 miles from downtown Los Angeles.
More than 1,600 firefighters with help from water-dropping helicopters are currently working on several fronts to contain the flames. As of 11:00 pm local time Sunday, the fire was 10 percent contained, but spreading in several different directions owing to variable winds.
If you were in the Los Angeles area on Saturday and looked up into the sky, you might have thought…
Five years of drought and a lack of winter rain due to El Niño conditions has set the stage for what could be one of the worst wildfire seasons in California history. “These are not normal times,” noted Los Angeles County Fire Chief Daryl Osby in NBC News. “When we say evacuate, that means evacuate.”
At least 18 homes have been destroyed so far, including Sable Ranch—a popular movie set used in such shows as The A-Team, 24, and Maverick. A man was found dead in his burnt-out vehicle, while hundreds of animals, including a mountain lion and bengal tigers, had to be evacuated from the Wildlife Waystation sanctuary. On Sunday, helicopters were grounded for about a half-hour when an unauthorized aerial drone was spotted in the skies above the wildfire.
In just three days, the Sand Fire has spread to 51 square miles, doubling in size since Saturday night. The fire is being fueled by heavy chaparral and brush, and is spreading rapidly owing to strong, shifting winds and high temperatures. Forecasters are once again projecting 100 degree-plus temperatures for Monday.
“Things got in alignment yesterday and that fire came through like a freight train,” said Deputy Fire Chief John Tripp, of the Los Angeles County Fire Department.
Mandatory evacuations have been ordered for parts of Acton on Agua Dulce Canyon road north to the 14 Freeway, Crown Valley Road to the 14 Freeway and all of Soledad Canyon. An area downwind from the fire is considered to be in danger. The fires have also generated poor air quality, so people with respiratory problems are being asked to stay indoors.


[NBC, CBS]
Seeking to safeguard the future of its kiwis, parrots, and hobbits, New Zealand has just made the “world first” decision to eradicate all wild predators by 2050.
That means rats, possums, stoats, ferrets, and feral cats, all introduced from foreign countries and responsible for the deaths of millions of native birds each year, will have to go, Radio New Zealand reports. The government is shelling out $28 million to jumpstart a new joint venture company, Predator Free New Zealand Ltd, that will identify and sponsor “high value predator control projects” that can be applied across tens of thousands of acres, with the ultimate goal of making the entire nation predator-free by 2050.


It’s an enormously ambitious conservation project, and as New Zealand freely acknowledges, the effort will require the development of new pest control technologies. Although traditional methods like predator-proof fences and pesticides will play a role, a stated goal of Predator Free New Zealand is a “scientific breakthrough capable of removing at least one small mammalian predator from New Zealand entirely” by 2025.
While a ban on predators may sound cruel, unusual, and ripped straight out of popular kid’s movie Zootopia, it’s important to keep in mind that before the arrival of humans, New Zealand’s terrestrial ecosystems had no significant predation. The introduction of Polynesian rats and dogs by the Māori, followed by the arrival of Europeans with countless non-native mammals in tow, wrought untold havoc on the island’s native wildlife.


“New Zealand’s unique native creatures and plants are central to our national identity,” Conservation Minister Maggie Barry said in a statement. They evolved for millions of years in a world without mammals and as a result are extremely vulnerable to introduced predators.”
While there’s no going back to a pre-settlement ecological state, for New Zealand or anywhere else, removing all predators would be a major step in that direction.
There are, however, two exceptions to the predator ban: family pets and humans. Arguably the two most successful groups of predators on planet Earth, the decision to exclusive two-legged mammals and their collared companions can best be described as an act of blatant favoritism.
Gizmodo has also been unable to determine whether orcs are explicitly included in the predator ban, but we will update if and when that information becomes available.
[Radio New Zealand, The Guardian]
Controversy has long surrounded the presumed accidental death of Belgium’s King Albert I in 1934, with conspiracy theorists crying murder. Now, 80 years later, forensic geneticists have successfully matched DNA from blood found at the scene of his death with that of two of the late king’s distant relatives, hopefully resolving the mystery once and for all.
King Albert I was arguably one of the most popular monarchs to rule the small kingdom of Belgium. He presided over a hugely tumultuous period in history, steering the country through the German occupation during World War I, the post-war reconstruction, and the Great Depression, to name a few key events. And he died young, at age 58, in an Alpine climbing accident—or did he?


See, the king was an avid and highly skilled mountain climber, leading some to question whether his “accident” was actually murder or suicide. It’s not like there were any eyewitnesses on hand. The pro-conspiracy crowd speculated that Albert was killed somewhere else and his body planted at the Marche-les-Dames site after the fact.
Historians have largely dismissed such theories. The official investigations concluded that the king either fell after leaning on a boulder that suddenly dislodged, or he fell 60 feet after the rocky pinnacle to which his climbing rope was attached broke away.


According to a new paper in Forensic Science International: Genetics, historians have reason to be confident in that consensus. Flemish journalist Reinout Goddyn had purchased one of the many relics collected from the site where the king’s body was found—in this case, tree leaves stained with blood. An earlier analysis in 2014 confirmed the blood was human.
Now two forensic geneticists have conclusively shown that the blood is indeed that of the late beloved king. They compared DNA from the blood on the leaves with that of two of Albert I’s living distant relatives: the last tsar and former prime minister of Bulgaria, Simeon II of Saxe-Coburg and Gotha, and a German baroness, Anna Maria Freifrau von Haxthausen.
Will this be enough to convince the most diehard conspiracy theorists? Probably not. “Eighty years after the fact, everyone involved has passed away, and most material is gone; we will probably never be able to dismiss all speculations concerning this ‘cold case,’” co-author Maarten Larmuseau of University of Leuven in Belgium said in a statement.
However, “The authenticity of the trails of blood confirms the official account of the death of Albert I,” he added. “The story that the dead body of the king has never been in Marche-les-Dames or was only placed there at night has now become very improbable. Furthermore, the results show that conducting a perfect legal investigation at the time was impossible right from the start, because souvenir hunters had disturbed the scene.”


[Forensic Science International: Genetics]
Sound is something of an ephemeral phenomenon, existing in the moment that vibrations travel through the air. Those vibrations also exhibit distinct patterns, depending on frequency, which can be visualized by scattering a fine dust over a vibrating plate. This was the inspiration for Resonantia, an album whose catalog features photographs that capture those distinctive patterns for all 12 musical notes.
The technical term is cymatics (from the Greek word for “wave”), and it’s been an active field of study—particularly in acoustics—since at least the time of Galileo. In 1680, Robert Hooke first saw these so-called “nodal patterns” when he ran a bow along glass plates to induce vibrations. But it was Ernst Chladni who perfected the technique in 1787, which is why the patterns are known as “Chladni figures.”


There’s a certain amount of pseudo-scientific nonsense associated with Chladni figures thanks to the work of Hans Jenny in the 1960s, who believed they were manifestations of an otherwise invisible “vibrational energy.” But there’s no denying the beauty of such figures, and their connection to music, makes perfect sense. Perhaps that’s why the figures have inspired quite a few artists in recent years—like Jack White, whose music video for “High Ball Stepper” features Chladni patterns created by the music:

Add Jeff Louviere and Vanessa Brown, the masterminds behind Resonantia, to that list. Struck by the fact that each note produced a distinct shape in a liquid medium, they decided to use photography as a form of sonic sculpture to capture those patterns. “We are translating a time-based medium of sound and contrasting it with the space-based form of photography,” they write on their website. “Everything you see is a sound. Everything you hear is a photography.”


Louviere used a frequency generator on his laptop, a guitar tuner, and an old amplifier, placed directly beneath a plastic plate. Then, as Heather Sparks writes at Nautilus:
Louviere vibrated the water with the amp by adjusting the generator’s frequency. As he did so, he used his tuner to seek out the frequency of each of the 12 notes—A, B, C through G, plus the five halftones. While Louviere dialed the knobs, Brown stood on a ladder above the contraption illuminating the water with a ring light, her camera in hand. When the tuner registered a note—reading 220 hertz, the frequency that produces an A, for instance—Louviere stopped adjusting. As each note’s unique vibration induced its characteristic pattern into the water, Brown captured it with her camera. The pair worked together to obtain a “portrait” of each of the 12 notes.
In each, Louviere and Brown saw a distinct image: G looks like a devil, C# is the tree in the Garden of Eden, and F is something like the underbelly of a frog. If you were to repeat this experiment, you would get the same designs.
But Louviere didn’t stop there. He also used a program called Photo Sounder to scan the 12 resulting images and turn them back into sounds. He mixed the 12 sound files back into the final “soundscape.” As for the images themselves, they make for a dazzling artistic display.
[Facts So Romantic]
Anyone who’s imbibed a glass of ouzo—the licorice-flavored spirit that is practically the national drink of Greece—may be familiar with how it turns cloudy when the liquor is mixed with water. But there are still some mysteries about how such mixed liquids behave.
Now physicists at the University of Twente in the Netherlands have captured the various life phases of an evaporating drop of ouzo on camera. They describe their work in a new paper in the Proceedings of the National Academy of Sciences.


The so-called “ouzo effect” is a well-known phenomenon, among mixologists as well as physicists. It’s what happens when you add water to ouzo (a mix of water, alcohol, and anise oil) or other liquors that contain anise—notably pastis, raki, arak, sambuca, and absinthe. The spirit takes on a milky appearance.
This happens because adding water alters the alcohol-to-water ratio, a key factor in in determining the beverage’s oil solubility. Remember the adage about how oil and water don’t mix? Oil is hydrophobic, so water repels the anise oil. So if you decrease the solubility, instead of dissolving into the ouzo, tiny anise oil droplets start to form, desperate to avoid contact with all that icky water. These in turn form larger micro-dropets. The milky appearance is due to how light scatters off those microdroplets.


The Dutch scientists were keen to study this mechanism more closely, by examining how the liquid evaporates. They placed a drop of ouzo on a water-repellent surface and set up several cameras to capture the process on film over the course of 15 minutes. Check it out:

The effect is actually kind of pretty, although lead author Detlef Lohse told Discover, “What perhaps surprised me is the violence [of the flow].”


Lohse and his colleagues identified four distinct stages to the evaporation process. At first the drop of ouzo is clear; the ethanol has just begun to evaporate, and it starts at the droplet’s edges. As the concentration of alcohol decreases in proportion to the water and oil, the mechanism behind the ouzo effect kicks in: micro droplets start to form in the second phase. Then a ring of oil starts to form around the droplet, and the latter starts to shrink. Eventually it gets so tiny that it evaporates completely.
Why should you care? Well, it’s wicked cool, for starters. How many of us ever stop to think about the amazing processes that happen on the micro scale when we spill drops of ouzo on the table? Also, understanding how these kinds of liquid mixtures behave—especially how they evaporate—is of great interest to folks in industry, medicine, or technology, not to mention anyone keen on the chemistry of cocktails. And that’s always cause for a celebratory toast.
[Proceedings of the National Academy of Sciences via Inkfish/Discover]
A tiny Colorado town made national headlines this week after authorities told residents not to use the water, citing concerns that it had been contaminated with THC, the main psychoactive ingredient in marijuana.
On Wednesday, the 700-strong town of Hugo, located roughly 100 miles from Denver in eastern Colorado, advised residents not to drink, bathe, or cook with the tap water, after multiple field tests came back positive for THC. The results are fishy, to say the least, and more detailed laboratory analyses are underway to verify the nature of the contaminant.


According to the Denver Post, it was a Hugo-based company that first raised the alarm. After getting “inconsistent” results when using a THC field test (not unlike a pregnancy test) on its employees, the company decided to test the water and was surprised to see it come back positive. This prompted an investigation by the county, which performed ten field tests with two different kits, yielding six positive results.
Eventually, the presumptively contaminated samples were isolated to a single well, which “showed signs of forced entry.” It was at this point that the city issued a public warning about the water.


The story raises a few red flags. For one, it isn’t clear why anybody would try to contaminate a small town’s water supply with THC. As the Denver Post points out, this isn’t a place that’s seen a fierce debate over marijuana use, although commercial growing is banned in the surrounding Lincoln county. Moreover, it’s extremely unlikely that the town’s water supply could have been contaminated with THC—at least, in concentrations high enough to produce even the slightest buzz.


That’s because, as any college survivor will know, THC is extremely insoluble in water. There’s a reason pot is baked into cookies and brownies, but nobody’s tapping the THC-infused energy drink market: you need a lot of butter or oil to get this stuff into solution.
“It would take more product than any of us could afford to contaminate a city water supply to the extent that people would suffer any effects,” Lincoln county’s health officer John Fox said in a statement.
More likely than some highly motivated stoner dropping an enormous chunk of change to get a town blazed is that the readings are false positives caused by some other contaminant, or that the field test kits themselves are unreliable.
Deeper laboratory tests could be completed by later today.


Update, July 23, 2:27 pm EDT: According to the Associated Press, tests concluded that there wasn’t any evidence of the marijuana chemical in the water, and the warning has been canceled.
The sheriff’s office will conduct a criminal investigation into the suspected tampering in the community—since there was still evidence of forced entry—but the matter has been turned over to the Colorado Bureau of Investigation.


“There never was THC in our water supply. We did get multiple tests showing the possibility of THC, but independent tests taken by different people at different times and places showed no evidence of THC,” said sheriff’s Capt. Michael Yowell.
No illnesses have been reported.
[NPR, Denver Post]
A crew of NASA and ESA astronauts and researchers has arrived to underwater laboratory, Aquarius. They’ll be using the underwater conditions to simulate a crewed trip to Mars.
This is the 21st mission of the NASA Extreme Environment Mission Operations (or NEEMO) in the underwater lab. At 16 days, it’s the longest one for the project yet. The aquanauts will spend over two weeks testing equipment and protocols that they someday hope to carry-over to a future trip to Mars.


Especially key will be a series of “waterwalks”, in which the aquanauts walk out along the sea floor having adjusted their diving suits to mimic the gravity of Mars. Just like in a real spacewalk, the aquanauts are given outside missions to accomplish, which they use to test performance of both procedures and even equipment that could be someday be used in similar situations in space. Among the equipment being tested is a prototype wearable from the ESA called the mobiPV. The wearable can be used to stream a series of personalized instructions, including visuals, to an astronaut headset while they are completing a mission.
The first of the mission’s simulated Martian-gravity expedition will take place today, when the aquanauts construct a coral nursery near the underwater lab.
Think it’s hot in North America right now? Well, you need to shut-up and stop complaining, because parts of the Middle East are getting absolutely scorched right now. Yesterday, the temperature in Mitribah, Kuwait soared to a blistering 129.2 degrees Fahrenheit (54 degrees Celsius). That’s a record for our planet’s Eastern hemisphere.
As Weather Underground meteorologists Jeff Masters and Christopher C. Burt noted, if confirmed, that would be Earth’s hottest temperature ever recorded outside of Death Valley, California. This record will likely be verified given that this temperature was recorded not once but twice. Earlier today, Basra, Iraq recorded the exact same temperature, 129.2 degrees F (54 degrees C).

The official world record high temperature is 134.1 degrees F (56.7 degrees C ), which occurred on July 10, 1913, in Furnace Creek Ranch, California, in Death Valley. This is a hotly contested measurement, and it’s probably not a valid reading. According to Burt, a more plausible record for Death Valley is a June 30, 2013 reading of 129.2 degrees F (54 degrees C), which interestingly enough is the same temperature recorded just yesterday. Masters provides some more comparisons:
...Thursday’s Basrah reading ranks as the fourth highest temperature ever reliably measured outside of Death Valley; the only higher non-Death Valley temperatures were today’s 54°C (129.2°F) at Mitribah, Kuwait, a 53.6°C reading at Sulaibya, Kuwait in 2011, and a 53.5°C reading at Mohenjodaro, Pakistan on May 26, 2010. Note that there is one other competitor for hottest non-Death Valley temperature ever measured: the official all-time high temperature in Israel is a 54°C (129.2°F) reading from Tirat Tsvi, Israel on June 22, 1942...[but the] Israeli Met Office...refused to make public the details leading to their conclusions. Until they do so, the record remains suspect.
In response to the heat wave, the Iraqi government declared a two-day public holiday.

But some have found ways to beat the heat.

Personally, I recommend this.
The Middle East’s record-setting heat wave is expected to last for yet another brutal day, where temperatures could reach 128 degrees F or higher. Crazily enough, when the final maximum is recorded for the day, it could even be higher. We’ll keep you posted should the record get smashed once again.


[Weather Underground]
Earlier this year a video appeared online purportedly showing how you could turn a lemon into a simple battery, and then use it to start a fire by igniting a piece of steel wool. It was similar to a simple science experiment we all tried in grade school, but going one step further to make fire? That’s where the science falls apart.
You can now add lemons to the long list of random objects that can be used to start a fire. But…
Wilson and Adam, two amateur Mythbusters hoping to carry on Adam and Jamie’s important work, decided to try and recreate the experiment as demonstrated in that video. They were met with zero success—but not because they were doing it wrong. The problem is that a lemon stuffed with copper and zinc electrodes simply doesn’t generate enough power to ignite steel wool.

The two even substituted a giant pineapple for the lemon and were still unable to generate enough power to start their fire. You need about two AA batteries worth of electricity to ignite steel wool. That would end up requiring an entire bag of lemons to be wired up in series.


So don’t bother packing a lemon as part of your emergency supplies for the next time the power goes out. Just toss a box of matches in there and save yourself a lot of trouble.
[YouTube]
Refrigerated pasteurized milk typically lasts about two to three weeks before turning into a wretched hive of scum and villainy. A new process developed by researchers at Purdue University extends the shelf life of milk up to 63 days—and without the benefit of added chemicals.
Purdue University researcher Bruce Applegate, along with pals from the University of Tennessee, accomplished the feat by increasing the temperature of milk by 10 degrees for less than a second. The process, described in the latest issue of SpringerPlus, eliminated more than 99 percent of the bacteria left behind after initial pasteurization.


“It’s an add-on to pasteurization, but it can add shelf life of up to five, six or seven weeks to cold milk,” noted Applegate in a press release.
Milk that comes from cows is normally packed with microorganisms. To make it safe for human consumption, milk is pasteurized to remove significant amounts of harmful pathogens that can make us sick and eventually turn our favorite dairy beverage into a sour glop of uselessness. Developed by Louis Pasteur in the 19th century, the technique kills most of the bacteria, so commercially processed milk contains basically no microorganisms. The new process destroys most of the trace amounts of bacteria left over by this tried-and-true treatment, dramatically extending milk’s expiration date.
Here’s how the low-temperature, short-time (LTST) method works: Tiny droplets of already-pasteurized milk are placed into a heated, pressurized chamber that rapidly raises and lowers the temperature of the milk about 10 degrees Celsius, but still below the 70-degree Celsius threshold required for pasteurization. After treatment, milk that was pre-loaded with Lactobacillus and Pseudomonas showed bacterial levels below detection limits.


“With the treatment, you’re taking out almost everything,” noted Applegate. “Whatever does survive is at such a low level that it takes much longer for it to multiply to a point at which it damages the quality of the milk.”
Follow-up tests found no discernible differences between regular pasteurized milk and milk treated with LTST. Importantly, panelists weren’t able to detect any differences in color, aroma, taste, or aftertaste between the two versions. The researchers admit that the technique isn’t perfect—they’re still dealing with some minor contamination issues—but they say their initial experiments show promise as something that can be ramped up to an industrial scale.
A neat part about this method is that it already uses the heat required to pasteurize milk, so extra energy isn’t required to run the system. The LTST chamber was developed by Millisecond Technologies from New York, and a US patent has already been awarded. This company and the researchers who developed the method stand to profit from this breakthrough, but it could also go a long way in reducing food waste. This is brilliant, but there’s still no word on when super milk might find its way to your grocery store.
[SpringerPlus]

Never assume that Leonardo Da Vinci’s doodles are meaningless. That, at least, is the takeaway of a new study out of the University of Cambridge, which shows that a page of Leonardo’s scribbled notes from 1493—previously dismissed as “irrelevant” by art historians—is actually the first written demonstration of the laws of friction.
It is widely recognized that Leonardo had an exceptional grasp of friction centuries before the modern science of “tribology” was codified. In his mock-ups of complex machines, the Renaissance inventor incorporated friction into the behavior of wheels, axels, and pulleys, recognizing its role in limiting operation and efficiency. But exactly when and how Leonardo first developed his ideas on friction has been a mystery.


Now, a detailed chronology put together by Cambridge manufacturing engineering professor Ian Hutchings pegs Leonardo’s eureka moment to a tiny, yellowing scrap of paper inked in 1493. Held in the Victoria and Albert Museum of London, this notebook page was actually a subject of academic debate years ago, because of the faint sketch of an old woman near the top, followed by the statement “cosa bella mortal passa e non dura,” which translates to “mortal beauty passes and does not last.” But the sketches beneath these ominous words were dismissed by the 1920s museum director as “irrelevant notes and diagrams in red chalk.”
As Hutchings explains in his paper, those red scribblings are actually a pivotal moment in the history of tribology. They show blocks being pulled by a weight hanging over a pulley—the very same sort of experiment used in introductory physics today to demonstrate how friction works. The paper goes on to trace Leonardo’s 20-year study of friction from this initial incarnation to more complex demonstrations and ideas.


“The sketches and text show Leonardo understood the fundamentals of friction in 1493,” Hutchings said in a statement. “He knew that the force of friction acting between two sliding surfaces is proportional to the load pressing the surfaces together and that friction is independent of the apparent area of contact between the two surfaces. These are the ‘laws of friction’ that we nowadays usually credit to a French scientist, Guillaume Amontons, working two hundred years later.”
I think the real takeaway here is that we should encourage scientists and engineers to pore over all of Leonardo’s old notes. Who knows what other incredible insights were just… overlooked?
[University of Cambridge News]

These soft patches of grass in Siberia look like a cool trampoline, but are actually concealing dangerous bubbles of methane. It’s probably a good thing the guy didn’t shoot the bubble at the end.
The hunt for the elusive dark matter received yet another blow earlier today at an international conference in Sheffield, England. Scientists with the Large Underground Xenon (LUX) dark matter experiment announced that they found no hints of dark matter particles in their latest analysis, despite increasing the sensitivity of the experiment fourfold for its final run.
“We built an experiment that has delivered world-leading sensitivity in multiple new results over the last three years,” Brown University’s Rick Gaitskell, co-spokesperson for the LUX collaboration, told Symmetry. “We gave dark matter every opportunity to show up in our experiment, but it chose not to.”


Stupid dark matter. At least these results have resolved most of the troubling discrepancies between various dark matter experiments over the last several years.
The planets, stars, galaxies, and everything else that we see makes up just 4.9 percent of the stuff in the universe. Roughly 26.8 percent is dark matter. (The rest — 68.3 percent — is made up of dark energy.) We’re not exactly sure what it is, but physicists can tell it’s there because of its indirect effects, like the famous “bullet cluster” composite image that made headlines several years ago. Physicists have been searching for years to directly detect dark matter particles, using instruments in the sky and deep underground.
The leading contender for a dark matter particle is a class of weakly interacting massive particle (WIMP), which is similar to another subatomic particle called a neutrino in that it rarely interacts with other matter. There are lots of different experiments around the world, with a dizzying array of acronyms, all looking to be the first to directly detect WIMPs. How difficult that is likely to be depends on whether the WIMPs are heavy or light. As I wrote at Quanta in 2013:
These kinds of experiments are usually housed deep underground — the better to block out cosmic rays, which can easily be confused with a dark matter signal — and feature a detector housing a carefully chosen target material, such as germanium or silicon crystals, or liquid xenon. [LUX uses xenon.] Then physicists wait for a rare collision between an incoming dark matter particle and the nucleus of an atom in the target material. This should give rise to a tiny flash of light, and if that flash is strong enough, it will be recorded by the detector. [I]n order to be detected, the dark matter particle must transfer enough energy when it knocks the nucleus for the resulting signal to go above the detector’s energy threshold.
A lighter WIMP would be much more difficult to detect, which is why physicists originally favored models that predicted a heavier WIMP. “Kinematically, it’s much easier for a heavier particle to transmit that energy than a lighter particle,” New York University physicist Neal Weiner told me at the time, comparing the two scenarios to bowling balls and ping-pong balls. As experiment after experiment has failed to detect a dark matter particle, the light WIMP scenario has started looking more likely—assuming it’s even a WIMP at all and not some other more exotic possibility.


There have been tantalizing hints now and then, but none met the threshold required to claim a bona fide discovery. Most controversial is the DAMA/LIBRA experiment (Dark Matter/Large Sodium Iodide Bulk for Rare Processes), located deep underground in the Gran Sasso mountain in central Italy. Over a decade ago, that collaboration claimed to detect tiny fluctuations in the rate of collision events over the course of a year. But others doubted it was a dark matter signal, especially since the similar XENON10 Cryogenic Dark Matter Search II (CDMSII) experiments failed to detect any signal in that energy range.
The LUX collaboration didn’t have much earlier success either, but physicists were hoping their luck would change during this final run, especially given the huge upgrades in the experiment’s sensitivity. In particular, they hoped to confirm recent hints of a dark matter signal in data collected by the Fermi space telescope.
Alas, LUX physicists saw nothing when they analyzed the data from that final run. “It would have been marvelous if the improved sensitivity had also delivered a clear dark matter signal,” Gaitskell admitted in a statement.
On the plus side, these latest results from LUX definitively showed that prior hints of possible WIMPs were false. “Those experiments with possible positive signals have also now clarified their position,” Gaitskell told Gizmodo. “They no longer assert they have evidence for WIMP events.” The notable exception is the stubborn folks at the DAMA/LIBRA collaboration, who still insist their signal is real. The rest of the community remains unconvinced. “It would have to be a very exotic dark matter particle to avoid detection in our experiment and yet appear in theirs,” said Gaitskell.
The successor to LUX, known as LUX-ZEPLIN (or LZ), will have a bigger target made of much purer xenon, increasing the chances of a direct collision with a dark matter particle.


Will there ever come a day when dark matter hunters throw up their hands and declare defeat on the WIMPs scenario? It’s a possibility constantly under consideration, according to Gaitskell, although WIMPs are still the favored candidate. The University of Chicago’s Juan Collar is more pessimistic, particularly if the upgraded XENON-1T experiment also finds nothing. If that happens, “I personally believe there will be a mass migration to look for other dark matter candidates beyond the WIMP,” he told Gizmodo.
Gaitskell emphasizes that the hunt for dark matter is a long game. Even though he’s been hunting for WIMPs for nearly three decades now, physicists have explored just a fraction of the possible ranges when it comes to interaction rates. “This is the kind of science that takes a lifetime,” he said, adding “Ask me in 15 years where we stand.”
[Lawrence Berkeley Laboratory, University College London]
Seventy-one days from now, the Rosetta spacecraft will end its historic mission by crashing onto the surface of its target, Comet 67P/Churyumov-Gerasimenko. Mission planners have now selected the spacecraft’s final, mission-ending destination—and it’s a good one.
As announced by the ESA earlier today, Rosetta will make its controlled impact on an area known as Ma’at, a dusty and pitted region located on the comet’s small lobe.
This region was chosen for its scientific value, and, in the words of the ESA, was a spot that took “into account key operational constraints involved in executing the descent.” In other words, it was one of only a few locations where the spacecraft could actually be maneuvered. The descent will be extremely complicated, requiring several precise navigational adjustments.


Ma’at features active pits, which hint at the comet’s ever-changing and dynamic surface. Scientists theorize that the pits are formed when the ceiling of a subsurface cavity can’t support its own weight, resulting in cometary version of a sinkhole. The resulting pits are exposed to the elements, causing continual erosion over time.
ESA scientists also want to take a look at Ma’at’s dust-covered surface. Coated on the comet like icing sugar, it exhibits sharp outcrops of materials that appear to be emerging from the ash-like surface. This matches several other regions of the comet, and scientists would like to take a closer look.


As Rosetta makes its descent, it will take hi-resolution images of the region, allowing scientists to peer closer view at the pits and the dusty surface. Unfortunately, the spacecraft will likely be damaged once it hits the comet, effectively ending the mission.
Rosetta is scheduled to crash on the comet in a controlled descent on September 30, 2016.


[ESA]
The United States wastes over 140 trillion calories of perfectly good food every year. A national survey just provided a comprehensive overview of the reasons we waste so much—and one of the most common ones is based on a total misconception.
Researchers at Ohio State University wrapped up a survey about why Americans are wasting so much food and published it today in PLOS One. Some of the reasons were no surprise. Most people ran out of time, bought a little too much in bulk, or simply thought that those apples that had been sitting out a couple days no longer looked quite so crisp.


But there was also one pretty alarming reason: the majority of people—over 68 percent—were throwing away food under the mistaken assumption that, once the expiration date had passed, eating those foods was likely to cause food poisoning.
Food borne illnesses aren’t spread by old food, they’re spread by contaminated food, and food can be contaminated no matter how fresh it is. But underlying that misconception is an even more insidious one: expiration dates don’t actually tell you whether your food has spoiled or not.


Expiration dates are not scientific calculations, they’re estimates designed more for the use of grocery store stocking decisions than determining whether your food is still good or not. The only food actually required by federal law to have a real expiration date, when it shouldn’t be consumed after, is baby formula. For all other foods, government regulators are perfectly chill with selling and eating food past its expiration date.


In fact, the FDA tacitly acknowledges that expiration dates have little to do with whether they will or won’t consider a food safe. “A principle of US food law is that foods in US commerce must be wholesome and fit for consumption,” notes the agency. “A ‘best by, ‘use by’ or expiration date does not relieve a firm from this obligation.”
So how can you really tell if your food is spoiled? It’s pretty simple, and it has almost nothing to do with the date on the package. Instead, you can go simply by the food’s look, smell, feel, and, if it comes to it, taste. Believe me, the signs of spoiled food are not easy to miss, even if you weren’t looking for them.
Hundreds of millions of years ago, a tiny green microbe joined forces with a fungus, and together they conquered the world. It’s a tale of two cross-kingdom organisms, one providing food and the one other shelter, and it’s been our touchstone example of symbiosis for 150 years. Trouble is, that story is nowhere near complete.
A sweeping genetic analysis of lichen has revealed a third symbiotic organism, hiding in plain sight alongside the familiar two, that has eluded scientists for decades. The stowaway is another fungus, a basidiomycete yeast. It’s been found in 52 genera of lichen across six continents, indicating that it is an extremely widespread, if not ubiquitous, part of the symbiosis. And according to molecular dating, it’s probably been along for the ride since the beginning.


“I think this will require some rewriting of the textbooks,” said Catharine Aime, a mycologist at Purdue University and co-author on the study published today in Science.
Toby Spribille, who led the new analysis, has been studying lichens in one way or another for most of his life. He grew up in northwest Montana, where the shrubby, rubbery organisms are a ubiquitous part of the natural landscape. But when Spribille started to get serious about lichen research in grad school, he hit a roadblock.


“Lichens are nearly impossible to re-synthesize in the lab,” he told Gizmodo, explaining how the colonies take a long time to grow and the conditions needed to induce symbiosis are not well known. Unable to rear their test subjects in controlled environments, lichen researchers have struggled to perform basic experiments that could shed light the roles of the different symbionts.
But recent advances in metagenomics—tools for extracting and sequencing DNA from environmental samples, no culturing required—offer a new way in. This approach caught Spribille’s attention when he learned something very strange about Bryoria, a lichen found throughout conifer forests of the western United States and Canada.
“Bryoria have a long and storied cultural significance,” Spribille said, explaining how certain Native American tribes relied on the lichen as winter survival food. “There’s also evidence that first peoples would remove the more light colored ones and wash them, so that certain substances wouldn’t make them sick.”
Those substances include a toxin called vulpinic acid. The lichen that produces it, Bryoria tortuosa, can be distinguished from its non-toxic cousin, Bryoria fremontii, on the basis of its yellowish hue. But a few years back, when a group of biologists at the University of Helsinki tried uncover the genetic basis for this difference using a targeted approach called barcoding, they were stumped.


“They found that the toxic and non-toxic forms [of the two species] were identical—at least, in the known parts of the lichen,” Spribille said. “And they didn’t really study it further. We looked at that and said, this is a classic question you could go at with genomics.”
When Spribille and his colleagues analyzed Bryoria’s RNA—the messenger form of DNA—they discovered something amazing. “We found there was this third thing, riding along in every single sample,” he said, referring to the previously unknown basidiomycete.


At first, the researchers worried that the extra RNA sequences could be contamination, a common pitfall of genomic research. And so, they decided to see if they could find the basidiomycete in other lichens, too. “We found it in everything,” Spribille said. “From Alaska to Ethiopia to Antarctica, it always was there.”

The final proof that this was not an elaborate hoax came when the researchers developed green fluorescent markers that attach to specific RNA sequences in the basidiomycete, and blue markers that attach to complementary RNA sequences in the other fungus, an ascomycete. Sure enough, when they added these markers to samples of lichen tissue, the cells of a hidden fungal partner glowed under the microscope.


“This is an exciting discovery that forces us to reconsider what we thought we knew about lichens,” said Kathleen Treseder, a fungal ecologist at the University of California Irvine who was not involved with the study. “It would not have been possible without recent technological advances in how we study fungi.”
We can’t be certain the second fungus is present in all lichens. Spribille’s study only looked at lichens in the Parmeliaceae family, the most widespread and successful group on Earth today. But the entire lineage is vast and ancient, and it’s possible some groups split off on the evolutionary tree before the basidiomycete arrived on the scene.


We also can’t be sure when that third partner joined up. Using an age-estimation method called molecular clock dating, the researchers showed that the basidiomycete lineage is as old as the ascomycete lineage. “By inference, these two lineages arose at the same point in time,” Aime said. But we’d need well-preserved fossils to build a case that all three lichen partners have been together since the very beginning.
Aime and her collaborators are now studying the new fungus more closely. The classic view of lichen is that the photosynthetic organism (an algae or a cyanobacteria, occasionally both) provides food, while the ascomycete fungus offers shelter and structure.


The recent studies on Bryoria and vulpinic acid hint at a likely role for the newcomer: defense. “We can’t prove the connection of the yeast to the toxin, but the evidence points overwhelmingly to it being involved in some way,” Spribille said.
“Basidiomycetes have really cool metabolisms,” Aime said, describing how these fungi produce all sorts of toxic defense compounds, called secondary metabolites. “It’s likely they’re producing a lot of the metabolites we’ve used to diagnose lichens in the past.”


Spribille noted that the location of the new fungus, inside a layer of starch that gives lichen its rubbery toughness, suggests it may also play a structural role. Clearly, more research is needed to sort out all the ways this newcomer fits into our picture of lichen—but serendipitously, its discovery could make future studies easier. “One reason we think it may have been so hard to culture lichen is that we were missing a key ingredient,” Spribille said.
The nuances of lichen ecology aside, Spribille’s research underscores the incredible complexity of the microbial world which is now being revealed through genomics. “One thing that sets lichen apart from all other symbioses is that all the components are microbes,” Spribille said. “But when they come together, they form something self-replicating and beautiful that you can hold in your hand. For me, that’s something to draw inspiration from.”
A little brown bird in sub-Saharan Africa known as the greater honeyguide is known to cooperate with humans to locate honey-rich bees’ nests. The bird calls out to honey hunters and then leads them to the nests. Now there is evidence that the communication goes both ways. In a new paper published today in Science, South African researchers report that the birds seem to recognize and respond to human calls in turn.
We’ve known about this unique partnership for hundred of years, according to lead author Claire Spottiswoode of the University of Cambridge and the University of Cape Town. In 1588, a Portuguese missionary in what is now Mozambique named João dos Santos wrote about spotting a small brown bird nibbling on on the beeswax candles in his church. He also noted how the bird called to men and led them to bees’ nests by flying from tree to tree. Then the men would harvest the honey, and the bird would feast on the wax left behind.
Spottiswoode recalls being “electrified” as an 11-year-old girl in Cape Town when she heard Kenyan naturalist and ethnobiologist Hussein Isack speak about this unusual behavior of honeyguide birds. He found that humans could significantly increase their chances of finding bees’ nest if they followed the little brown birds.


For the honeyguides, it’s a win-win partnership: the birds help the humans find the nests, while humans do the work of subduing the bees and cracking open the hive, so the birds can avoid being stung. The humans get to collect all that sweet, sweet honey, while the honeyguide birds gorge themselves on the tasty beeswax left behind.
Spottiswoode cites this as a rare example of mutualism between species. “Mutualisms are crucial everywhere in nature, but to our knowledge the only comparable foraging partnership between wild animals and our own species involves free-living dolphins who chase schools of mullet into fishermen’s nets,” she said in a statement. “In so doing, [they] manage to catch more themselves.”
It’s not that the honeyguide is altruistic. Mostly, it’s just lazy—and occasionally brutal. Honeyguides are known to lay their eggs in the nests of other bird species. The chicks hatch with sharp hooks at the tips of their beaks, the better to kill their foster-siblings as soon as they hatch. Spottiswoode calls them “a proper Jekyll and Hyde of the bird world.”


As an adult, and a scientist in her own right, Spottiswoode learned that the Yao people of Mozambique actively recruited honeyguide birds with a distinctive call— a kind of trill followed by a grunt (brrr-hm):

She wanted to find out if this really was an example of two-way interspecies communication. She and her coauthors—conservationists Keith and Colleen Begg of the Niassa Carnivore Project—interviewed 20 Yao men, all of whom learned the bird calls from their fathers. All insisted it was the best way to attract the birds. They also followed the honey hunters on their searches, and found that 75 percent of the time, the birds led the men to bees’ nests.


Spottiswoode made recordings of the hunters’ calls, along with two control sounds: hunters calling out arbitrary words, and the bird calls of other species. Then she walked with two honey hunters, playing one of three types of acoustic cues every 7 seconds over 15 minute intervals.
The results: using the specific honeyguide call increased the probability of attracting the aid of a honeyguide from 33 percent to 66 percent, compared to the control sounds. And using the “brrr-hm” call more than tripled the likelihood of finding a bees’ nest, from 16 percent to 54 percent.


Spottiswoode points out that Hazda honey-hunters in Tanzania use a different sound—a melodious whistle—to attract the honeyguide birds. “We’d love to know whether honeyguides have learnt this language-like variation in human signals across Africa, allowing them to recognize good collaborators among the local people living alongside them,” she said.
[Science]
Pharmaceutical giant GlaxoSmithKline (GSK) has partnered with Apple on a new clinical study on rheumatoid arthritis. The study relies on an iPhone app to collect data about arthritic symptoms from users as they go about their daily lives. That sounds great at first glance, but how well will it protect your privacy?
The app was built by the London-based GSK using Apple’s ResearchKit, an open source software framework to transform your iPhone into a handy diagnostic tool for clinical studies. Launched last year, ResearchKit is designed to make it easier for medical researchers to access data about millions of potential subjects. As Lifehacker’s Alan Henry wrote at the time, “The platform aims to give anyone with an iOS device the opportunity to participate in medical research, join programs that can help them track their symptoms, or share information with their doctors.”


So far there are just a handful of ResearchKit apps tied to clinical studies, but the GSK partnership is the first time Apple has joined forces with a major drug company. The Patient Rheumatoid Arthritis Data from the Real World (PARADE) study will use its app to track the mobility of over 300 participants suffering from rheumatoid arthritis, including information on their level of joint pain, fatigue, and changing moods. No drugs are being tested. Rather, the app guides users through a simple wrist exercise, with the iPhone’s built-in sensors recording data from that motion. That data may help Glaxo design better clinical trials in the future.
There are plenty of potential benefits to using the ResearchKit platform. It’s a huge boon to recruiting viable participants for medical studies—which can take months or years, depending on the study—and it’s cost effective, potentially saving millions of dollars. “Certainly you’ve also taken out the site costs, and the costs of having nurses and physicians explaining the studies to them and recording information,” Rob DiCicco, head of Glaxo’s clinical innovation and digital platforms group, told Bloomberg News.
But from the start, ResearchKit raised a host of ethical questions, particularly about protecting consumer privacy, and getting informed consent from all study participants.


Apple insists it never sees the data you provide through ResearchKit. But who the research institutions, hospitals, and doctors share that data with is up to them (within the constraints of laws like HIPAA.) And collected data is typically “anonymized” by companies like Sage Bionetwork, removing any possible identifiable information before sending the data to the institution conducting the study.
That may not be sufficient to protect users’ privacy in this age of powerful big data informatics. There’s something called the “mosaic effect,” whereby it is possible to reconstruct someone’s identity from a relatively small amount of data, even after that data has technically been made anonymous. “We can’t promise perfect anonymity,” John Wilbanks, chief commons officer for Sage Bionetwork, told The Verge last year. “We’re going to de-identify it, but because we’re going to make it available for lots of research, there exists the chance that someone could re-identify you.”
The first few ResearchKit apps seemed to improve on the usual one-on-one process for informed consent. With an asthma app designed by Mount Sinai Hospital, for instance, users must flick through 12 separate pages, each with big graphics, large 18-point font print, and simple words describing every possible risk and benefit of the study. Then users take a quiz to demonstrate they at least have a rudimentary understanding of just what they’re agreeing to.
So how does the GSK PARADE app-based study address those concerns? We asked bioethicist Nicholas Evans of the University of Massachusetts Lowell to weigh in, based on his own cursory exploration of the app.
The biggest issue, according to Evans, is the app’s approach to informed consent. Tapping the button to launch the consent process takes the user to a nine-page PDF document in 12-point font—the kind of thing that’s really difficult to read on your iPhone. Then the user taps the “Agree” button in the bottom right hand corner. Voila! Instant informed consent. It’s similar to those End User License Agreements that everybody agrees to without even reading them, because come on, we just want to use the damn app already.


UPDATE 7/21 6:45 PM: According to Mary Ann Rhyme, director of external communications for GSK in the U.S., the PARADE app does walk the user through several explanatory screens before prompting them with the PDF consent document. Users also have the option of emailing that document to themselves if they’re having trouble reading it on the iPhone screen, and of contacting an independent support center if they have questions. Whether this is sufficient to overcome the cultural conditioning of users to just click “agree” will likely remain a point of contention for bioethicists.
“A nine-page letter in PDF format is not a great way to structure informed consent on an iPhone,” Evans said. “I don’t see that there’s any incentive for someone to read this.”


In response to concerns about informed consent, the folks at Apple ResearchKit changed its terms of use to require an ethics review when creating an app—that is, the app must pass muster with what’s known as an Institutional Review Board (IRB). GSK did so before launching their app-based study.
According to Evans, the app didn’t work with the usual university-based IRBs, but with a Seattle-based, private, for-profit IRB called Quorum Review.


UPDATE: Rhyme confirmed to Gizmodo via email that GSK used Quorum Review for its IRB review. “The study design and informed consent documents all underwent two comprehensive reviews (one and three weeks, respectively), as well as through multiple internal legal and compliance reviews,” she wrote. On the issue of privacy, Rhyme said GSK is taking great care to protect the personal information of PARADE app users: “We take the obligation to protect participants’ data as seriously with this app as we do with data from studies performed in the traditional clinic setting.”


It’s great that Apple put an IRB requirement in place, but according to Evans, that has led to an increased market for private IRBs, and a greater potential risk of “rubber stamping” proposed studies. “It’s going to become an increasing problem as more tech companies get into the biomedical space to do research that have really promising results,” Evans said, “but don’t go about crossing all their T’s and dotting all their I’s when it comes to their human subject research ethics.”
Part of that is linked to the “fail early, fail often” mantra associated with the Silicon Valley start-up culture, which is at odds with the slow and incremental steps required for biomedical research. “It’s great to fail early and often when the worst that can happen is someone losing their Instagram account,” Evans said. “It’s a lot more serious when failing early involves giving someone an incorrect diagnosis for a congenital condition for which there isn’t a cure. So validation has to be done.”
[Bloomberg News]


Correction, 7/26/16, 5:00 PM ET: Corrects earlier version of this article to state that the GSK app, and not the Apple ResearchKit platform, worked with a private IRB.


Update, 7/26/16, 5:00 PM ET: This article has been updated to clarify the role of a private IRB in the development of the GSK app.
Volcanic super-eruptions are bad. Like really bad. Scientists warn of such a potentially civilization-ending catastrophe in our future, but as a new study shows, we’ll only have a year to prepare once the signs of an impending eruption become visible.
A new microscopic analysis of quartz crystals taken from the site of a massive volcanic eruption that occurred 760,000 years ago in eastern California suggests we’ll only have about a year’s worth of advance warning before a devastating super-eruption. In a paper published in PLOS ONE, Guilherme Gualda from Vanderbilt University and Stephen Sutton from the University of Chicago show that super-eruptions don’t require much time to blow their tops, even though they’re tens of thousands of years in the making.
Unlike “conventional” eruptions, these explosions are among the most devastating on the planet, unleashing destruction that can flatten continents, trigger new ice ages, and potentially put an end to human civilization as we know it. They happen when the magma in the mantle rises into the crust, but is unable to breach the surface. The ensuing pressure builds and builds in an ever-growing magma pool until the crust can no longer contain the pressure. The results of the ensuing explosion are nothing short of catastrophic. In the most severe cases, a supervolcano can eject upwards of 1,000 cubic kilometers of ash into the sky.


Our planet has experienced several super-eruptions in the recent geological past. The Taupo Volcanic Zone in New Zealand erupted 26,500 years ago, and Campi Flegrei in Italy erupted 40,000 years ago. Other noteable super-eruptions include Indonesia’s Toba super-eruption in Sumatra 75,000 years ago and the Tambora eruption in 1815. Wyoming’s Yellowstone has super-erupted three times in the past million years, and there’s fear it could happen again. As these episodes show, super-eruptions are still a part of Earth’s geological fabric. It’s not a matter of if they’ll happen again, but when.
As these timelines suggest, super-eruptions evolve over relatively long timescales. But as the new study by Gualda and Sutton shows, the final stage doesn’t take very long at all.
“The evolution of a giant, super-eruption-feeding magma body is characterized by events taking place at a variety of time scales,” noted Gualda in a release. It typically takes tens of thousands of years to “prime” the crust with the requisite amounts of magma. Once these pools are established, the giant magma bodies swell and fester for a few millennia or even just a few centuries. “Now we have shown that the onset of the process of decompression, which releases the gas bubbles that power the eruption, starts less than a year before eruption,” said Gualda.
Gualda and Sutton reached this conclusion by analyzing small quartz crystals in pumice taken from the site of the Long Valley Caldera that formed nearly a million years ago. This allowed the researchers to measure the distinctive surface rims found at the sites of super-eruptions. By measuring the size and growth rates of these rims, the researchers were able to determine the length of time it took for an explosion to happen once the collapse phase begins. Analysis showed that more than 70 percent of rim growth times were less than a year, indicating that quartz rims mostly grow in the days and months prior to an eruption.


According to the researchers, we’ll likely be able to detect the signs of a pending super-eruption by noticing the bloating effects of the expanding magma body on the surface. More work is needed to know more about these warning signs, but this new study suggests that these signals will start to appear within a year of an eruption. And they’ll intensify as the explosion gets closer.
[PLOS ONE]

Despite their diminutive size, raptors were among the most terrifying dinosaurs to menace the Cretaceous Period. But as the discovery of a new dinosaur called Murusraptor shows, their plus-sized versions, aptly known as “megaraptors,” were considerably worse.
The fossilized remains of this dinosaur, now known as Murusraptor barrosaensis, was discovered back in 2000 at the Sierra Barrosa site in Argentina, but it has taken University of Alberta paleontologist Philip Currie and his team over a decade to perform their analysis. In a paper published in PLOS ONE, the researchers describe the skeleton as one of the most complete megaraptors ever found, and it’s offering fresh clues to the origin of this mysterious new family of dinosaurs.


“This is a super-cool specimen from a very enigmatic family of big dinosaurs,” noted Currie in a statement. “Because we have most of the skeleton in a single entity, it really helps consolidate their relationships to other animals.” By other animals, Currie is referring to Murusraptor’s fellow megaraptor cousins, megaraptor namunhaiquii, orkoraptor, and aerosteon.


Precious little evidence of this dinosaur family exists in the fossil record, but scientists have managed to find traces of their existence in Japan, Brazil, Patagonia, and Australia. These fearsome, mid-sized theropods featured large claws and air-filled bird-like bones. They lived during the Cretaceous Period some 84 million years ago, but their evolutionary origins aren’t entirely clear. Some scientists think they’re derived from coelurosaurs, a subgroup of dinosaurs that include Tyrannosaurs, while others believe they’re derived from neovenatorids, a family of dinosaurs in the Allosaurus family.
Though technically a “medium-sized” dinosaur, Murusraptor was not a creature to be trifled with. The specimen analyzed by Currie was a juvenile that measured over 26 feet long (8 meters) when it was alive—and it was still growing. It featured an enormous set of claws that it likely used to seize and shred apart its prey. Like other megaraptors, its hips were pneumatic, meaning they were filled with air. This meant that—like modern birds—Murusraptor’s bones were light, allowing for exceptional speed and agility, even for a creature of that size. With its low center of gravity, this carnivore was clearly designed to hunt.


Importantly, the fossilized remains of Murusraptor contained an unusually intact braincase and distinctive features not previously seen in other megaraptors. “It’s the only known braincase material we have of any megaraptor,” said Currie. He believes that the discovery of this skeleton will help paleontologists finally discern the true evolutionary origins the megaraptor family.
[PLOS ONE]
Stare deep into this abyss. What you are seeing right now is one of the deepest views into space possible.
Hubble just snagged these shots of galaxy cluster Abell S1063 as the latest addition to its Frontier Fields collection, which shows us the very furthest views into space ever taken. Hubble’s deep images owe a lot to the power of the telescope, but they owe just as much to a weird naturally-occurring phenomenon called gravitational lensing.
Gravitational lensing occurs when the combined gravities of galaxies in a cluster are pulling with so much combined force that they warp and ripple the space around them. The bent space also bends light, and this creates a natural “zoom lens” into space that lets us see much, much deeper than we ever could otherwise.


The distortion doesn’t just let us see deep into space, though, it also adds a few other odd features into this particular view. For example, researchers have already identified at least sixteen galaxies in the back of the photo that are reflected multiple times by the lens, making it falsely look like they have a twin (or even triplet). These reflections, however, only make it possible for astronomers to calculate even more precisely just how space has bent to form this naturally-occurring lens.

A spacecraft parked in orbit at a distance of one million miles has captured the mother of all timelapse videos—an entire year on Earth. Enjoy.
The EPIC camera aboard NOAA’s DSCOVR satellite has now recorded a full year of life on Earth from its position at Lagrange point 1, a sweet orbital spot a million miles from Earth where the spacecraft is perfectly balanced between the gravity of the Earth and the sun. It’s the perfect vantage point to see our beautiful blue marble as it makes its yearly journey around the sun.

The camera, which belongs to NASA, snaps a picture once every two hours. A team led by EPIC lead scientist Jay Herman took the 3,000+ images captured by the satellite to create the unprecedented video. The video runs from August 2015 to July 2016, capturing the ever-changing perturbations of the Earth’s weather systems. Prominent features seen in the video include the continents, deserts, forests, and various bodies of water.


Of particular note, the shadow cast by the moon on the Earth during the total solar eclipse on March 8 2016, can also be seen (at the 1:50 mark).
This video is super cool, but DSCOVR and EPIC are being used to do some serious science, including monitoring the ozone and aerosol levels in Earth’s atmosphere, and measuring cloud height, vegetation patterns, and ultraviolet reflectivity.
[NASA]

There’s a whole new way to build custom scientific instruments affordably in bioengineering: a system of 3D-printed building blocks that can link together in various combinations. The system combines design elements of both biological cells and electronic components, and it can evolve over time to adapt to the changing needs of the research community.
As outlined in a new paper in PLOS One, the blocks are known as “Multifluidic Evolutionary Components” (MECs) because they’re just so darned flexible and adaptable to so many different uses. Each block corresponds to a specific common task that bioengineers need to perform in the lab, and they can be combined in many different ways to tailor the final apparatus to the needs of the researcher.


It’s the brainchild of Douglas Hill, a graduate student at University of California, Riverside, who spent 20 years designing electronics before coming to UCR. According to his advisor, William Grover, Hill was surprised to find that bioengineers usually have to build their instruments from scratch, combining fluidic, mechanical, electronic, and optical elements.
“He’s used to putting together a few resistors and capacitors and making a new circuit in just a few minutes,” Grover said in a statement. “But building new tools for live science research can take months or even years.” The various components are cobbled together and often don’t interface well as a result. And that can seriously hamper progress in chemical, biological, and medical research.
So Hill decided to exploit the explosion in 3D printing technology to find a solution. There are two basic types of MECs: macro scale off-the-shelf components that snap together easily to make instruments that operate on the millimeter scale; and microMECs, which are tailored to applications at the nanoscale and are made via conventional techniques like etching, embossing, or soft lithography. The entire system is designed to be easily adapted for new applications, accommodating new components as needed.


As proof of concept, Hill’s team first built a fluidic router out of MECs: a component for pumping and mixing various fluids, which is a critical task for diagnostic arrays, among other tools. (It’s pictured above.) That worked so well, the team went on to built a bioreactor for making alternative fuels and an acid-based titration tool that is common in high school chemistry classrooms for figuring out the acid concentrations in chemical solutions.
The authors believe the MEC system would be invaluable to hospitals and laboratories in the developing world, which have far more limited resources. “Having a library of MECs would give these individuals access to a virtually limitless variety of custom instruments,” they write, although first the existing MEC library must be expanded significantly. And then, of course, they’ll need to scale up the production of the components, possibly by incorporating techniques like injection molding.
Even undergraduate students from multiple disciplines and with little to no research experience have been using the MEC system with ease.
“We’ve had computer science students write the code that runs the blocks, bioengineering students culture cells using instruments built from the blocks, and even art students design the graphical interface for the software that controls the blocks,” said Grover. “Once the students have created these instruments, they also understand how they work, they can ‘hack’ them to make them better, and they can take them apart to create something else.”

[PLOS One]
Neuroscientists working on the Human Connectome Project have compiled the most accurate map yet of the human cerebral cortex. The researchers identified 180 distinct areas of the brain’s outer layer—effectively doubling the previous number of known regions.
The new map, compiled by David Van Essen and Matthew Glasser of Washington University in St. Louis—with the help of colleagues from several other institutions—confirmed the existence of 83 previously known regions. The team also identified 97 new areas of the human cerebral cortex—the outer part of the brain responsible for sensory and motor processing, language, and logical reasoning. Published in Nature, the updated map will serve as a new reference atlas to assist in the ongoing study of brain structure, function, and connectivity.
Geographers and neuroscientists share something in common: they both need maps to do their work and improve their understanding of what they’re looking at. When it comes to brain science, researchers need a map that shows the brain’s major subdivisions, known as cortical areas. Each of these areas is responsible for a particular cognitive function, such as touch, personality, and planning, and many of them work in conjunction with other areas.


Trouble is, creating these maps is easier said than done. Every location of the brain contains an enormous set of features, from cellular structure and the density of proteins, to various neurotransmitter molecules and long-range connections. Scientists have struggled to define many of these features, resulting in a fairly hazy and often ambiguous map of the cerebral cortex.
Previous studies lacked the tools, and hence the proper resolution, required to create a map with the required level of detail. But according to study lead author Matthew Glasser, a fortunate set of circumstances came together to make it possible.


“[The Human Connectome Project] started back in 2010 and the National Institutes of Health gave us two years to work on improving the MRI acquisition methods and the data analysis methods,” he told Gizmodo. “That allowed us to get much higher quality data than was typically available.” The project also brought together neuroimaging experts from around the world to work on these issues.
The tools, methods, and software used by the researchers were also unique, including the use of multiple measures, rather than a single measure, of architecture, function, connectivity, and topographic maps. Finally, the team trained a learning algorithm to recognize the “fingerprints” of the various areas across all measures. That algorithm was able to process the trove of incoming data and identify regions that would normally be invisible to the researchers.
The end result was a highly accurate, high-resolution map of the cerebral cortex’s microstructural architecture, connectivity, and function. The researchers gave the map a name worthy of its stature, the Human Connectome Project Multi-Modal Parcellation version 1.0, or HCP-MMP1.0 for short.


Of the 180 regions mapped, some performed an obvious function, while others evaded explanation. For example, area 55b is involved in language tasks, according to Glasser. In about 90 percent of healthy young adults, this region has a typical pattern of relationships with its neighbors. But in some small fraction of the 210 study participants, it displayed different patterns, including a surprising association with areas involved in eye movements.
“Another interesting area is POS2. This is an area that had not previously been mapped before neuroanatomically,” said Glasser. “We don’t yet know what it is doing, but given its unique pattern, it will likely be something very specialized.”
In terms of actual applications, the updated map will be used by neuroimaging experts to help them understand where they are in the brain. It’ll also improve our understanding of how the brain works. And as Glasser pointed out, it could also be used by surgeons during the planning stage, where brain areas could be mapped ahead of an operation.


Looking ahead, Glasser and his team are focusing on helping the community use the new map and some of the improved brain imaging methods developed as part of the project. They’re also hoping to look at the human connectome, i.e. the many pathways that underlie brain function and behavior, to study the effects of aging.
[Nature]

Two months ago, researchers discovered that a nearby star system held at least three potentially habitable planets. Now, it turns out that at least two of those planets have even more potential for habitability than we initially thought.
All three of the planets appeared to be good candidates when they were first discovered back in May. They all orbit the same small cool dwarf star, TRAPPIST-1, just 40 light years away from us. All were approximately Earth-sized, and all fell within the coveted not-too hot/not-too-cold habitable zone capable of supporting life.


In a paper published in Nature today, the same researchers have determined that at least two of those planets are, like Earth, terrestrial planets—with rocky surfaces and small, compact atmospheres—instead of gas giants like Jupiter or Saturn. “These planets are not mini-gas giants, which is a good thing because they wouldn’t be habitable,” lead author Julien de Wit of MIT told Gizmodo. “We ruled out that scenario.”
Of course, just because we now know that the planets are rocky doesn’t necessarily mean the planets are also more Earth-like. “They could be like Earth,” said de Wit, “or they could be like Venus, with an atmosphere dominated by carbon dioxide and high-altitude clouds, or maybe like Mars.”


To study the planets’ atmospheres, the researchers observed them with the Hubble telescope as they passed in front of the star they orbit. While the planets were in this so-called double transit across their sun, the researchers measured changes in the wavelength of the starlight.
Gas giants, like Jupiter, have lighter and more diffuse atmospheres that aren’t conducive to habitability. By using slight changes in wavelength, the researchers were able to visualize the planets’ atmospheres and found that the atmospheres were wound fairly tightly around the planet—just like they’d expect from a rocky planet. Now, they want to observe even more transits of the TRAPPIST-1 planets to narrow down more precisely what their atmospheres are like.
The TRAPPIST-1 system was originally found using a prototype robotic telescope placed in Chile. The researchers are curious about whether other relatively small cool dwarf stars could also host similar types of habitable systems. To figure it out, they’re building six additional telescopes—four already in construction and two more that they plan to erect in Morocco and Chile—based on that prototype. Once all six are scanning the skies, we could discover that these potentially habitable planetary systems are much more common than we imagined.
Four billion years ago, an endless barrage of space rock pummeled the surface of the Earth and the Moon, in a period known as the Late Heavy Bombardment. Now, astronomers have performed a detailed analysis of one of the most famous craters from that time, and what they’ve learned could rewrite the most violent chapter in Earth’s history.
Imbrium basin, better known as the man in the moon’s right eye, was punched out by an enormous object—a protoplanet roughly the size of New Jersey. According to research published in today’s Nature, that impactor was so big that as it broke up, it sent chunks of debris spewing in all directions, helping fuel the 200-million year-long hard rain. And there could have been many other protoplanetary impacts like it.


“Previous models estimated that this asteroid was maybe eighty kilometers across,” lead study author Peter Schultz of Brown University told Gizmodo. “We’re talking something at least 250 kilometers across. And that is a conservative estimate.”
A dark depression some 750 miles (1200 kilometers) wide, Imbrium basin is one of the most striking impact craters in our solar system. Clearly visible with the aid of a backyard telescope, it’s been the subject of intense scrutiny by professional and amateur astronomers alike.


Among the basin’s more prominent features are a series of gashes that emanate radially outward, like spokes on a wheel. These were created by rocks blasted from the crater when it was formed, and they are concentrated on the basin’s southeastern side, suggesting the impact came from the northwest.
But those who’ve stared deep into the moon man’s eye have noticed something else: another set of landscape scars that do not converge on the crater’s center. “Way back in the 50s and 60s, astronomers couldn’t figure out why these features were there,” Schultz said. “It’s been a curiosity for a long, long time.”
Now, Schultz appears to have solved the mystery and shed new light on the nature of the Late Heavy Bombardment. He did so in a manner keeping with the spirit of ancient geologic times: by shooting projectiles at hypersonic speeds out of a giant cannon.
“It’s a three story tall gun at NASA Ames that was created during the Apollo program to understand the nature of the lunar surface,” Schultz explained, referring to the Vertical Gun Range he used to simulate collisions. “It fires small projectiles at six to seven kilometers per second. What this does is reveal [dynamics] you can’t recreate with a slingshot, because the objects are going so fast that they let off strong shockwaves.”


Using a high speed camera to record the simulated impacts, Schultz discovered that chunks of material break off up-range of the main crater. These rocks will continue to travel at high speeds, scouring the impact crater’s surface in a non-radial fashion. Pairing this observations with computer models, Schultz and his colleagues were able to show that the same physics works out on the much larger scale of a lunar impact.
Having solved the mystery of Imbrium basin’s non-radial scars, Schultz realized something else: that these features could be used to estimate the assaulting space rock’s girth. According to his calculations, it was about ten times more massive than astronomers previously thought.
In fact, the impactor was large enough to be considered a protoplanet—an object rounded by its own gravity and featuring signs of differentiation. A similar analysis of the Moon’s Moscoviense and Orientale basins revealed that these craters, too, were probably caused by protoplanet-sized collisions.


The discovery adds a new twist to the Late Heavy Bombardment, which astronomers have long theorized to be the result of numerous small objects swept into our cosmic backyard from the asteroid and Kuiper belts. The cratering record on Mercury suggests that a vast swath of the inner solar system was impacted during this time.
“We’re not claiming the entire Late Heavy Bombardment was from protoplanets—other asteroids were going bump in the night as well,” Schultz said. “But this paper does suggest there were a lot of large protoplanets roaming the inner solar system.”


By modeling what happened after Imbrium basin formed, Schultz and his co-authors showed that protoplanetary impacts could have been responsible for many small craters, as well. The initial impact sent thousands of chunks of debris flying in all directions, and some of these would have eventually rained back down.“It’s like shrapnel ripping off and coming back to hit us again and again,” Schultz said.


Schultz is now applying his methods to other cratered worlds, including Mercury and Mars. If his hunch about the Late Heavy Bombardment is correct, there should plenty more signs of an ancient planetary turf war waiting to be discovered.
Statistician Nathan Yau of Flowing Data has compiled a beautiful and revealing infographic showing the 50 most common family structures in the United States. As this clever visualization shows, the nuclear family—though the most common—is far from the only one.
To create this infographic, Yau took data from the five-year American Community Survey (2009-2014), and manually tallied-up 10,276 different types of households. The chart below shows the top 50, which represents 94 percent of all household types in the United States.
Yau divided the results into three broad categories: nuclear, composite, and extended. Relationships are shown relative to the surveyed head of the household. Larger circles represent older adults, while smaller circles represent children and grandchildren. Dark green shows direct family members, light green shows extended family, and grey shows non-related, non-married individuals.


Of the total, 54 percent represent so-called nuclear families. As Yau aptly observes, “that leaves 46 percent of households that are not nuclear, and that seems worth looking into more deeply.” Also, 10,226 household types were not represented in the chart, and they’re also deserving of a deeper dive.
An interesting aspect of this chart is that some members of the households surveyed would not identify themselves as being part of a “family.” Take the composite household, “Unrelated group of three.” That just sounds like three room mates. Or, it could be a polyamorous trio. Hard to know.
Family is a moving target. Our ideas about what constitutes a “normal” family have changed a lot…
Regardless, it’s clear that households and families—however you define them—are more complicated than we typically think, and they’re rapidly changing.


[Flowing Data]
A flown spacesuit from an ISS mission, a navigational globe from an Soyuz mission in the 1970s, lunar navigation charts from Apollo 11, and a 1963 training module used by astronauts in the Gemini program are just a few of the space history items going up for auction today.
Bonhams is putting up a nearly 300 space history items for sale at 1pm EST. A lot of the collection is made up of models, signed photos, artwork, and documents—most of which look pretty fascinating. But there’s also some genuine treasures in there that, frankly, would be a shame to see completely disappear into a private collection.


My favorite item is a collection of plaster casts used to make the astronaut gloves of NASA’s early spacesuits, including those of Neil Armstrong and Buzz Aldrin. But there’s also the Gemini training module which was used by astronauts in 1963 to learn how to maneuver spacecraft, a lunar navigation chart that once belonged to Buzz Aldrin, a spacesuit worn by astronaut Don Pettit during his return flight from the ISS in 2003, as well as a navigational globe used by Soviet cosmonauts in 1975.
What’s especially exciting is that these things don’t cost millions of dollars. While extremely awesome ones, like the spacesuit, are expected to fetch upwards of $25,000, price estimates on some of the smaller items are as low as $150. Regardless of the price, whomever buys these items will hopefully put them on display for all to see.
Following Melania’s now-infamous speech from the Republican Convention, a Canadian physicist has calculated the odds of those words and phrases appearing in the same order as Michelle Obama’s speech eight years ago. Looking at his answer, let’s just say it would be a coincidence of cosmic proportions.
According to Canadian physicist and McGill University professor Robert Rutledge, the odds are 1 in 87 billion. To put that into perspective, that’s about 7,000 times less likely than winning the lottery (the 6/49 to be exact), and about 9,000 times less likely than being struck by lightning—twice, in a lifetime.

Rutledge decided to do the calculation after listening to several Republicans defend Melania, the wife of Republican nominee Donald Trump, arguing there are only so many words in the English language, and that she was bound to use some of the words and phrases used by Michelle Obama. Paul Manafort of the Trump campaign rushed to Melania’s defense, saying it wasn’t a big deal, and that there are only so many words in the English language. It was even argued that Twilight Sparkle said it first, and that only a small fraction of the speech was plagiarized, which apparently makes it okay.

As Rutledge told Global News, “I thought, ‘that’s sort of silly.’ I’m a physicist, so when things come up that you can mathematically model, that’s sort of the thing we do.” The physicist then asked a basic, calculable question, “What is the probability that, giving Melania Trump the same distinct phrases as used by Michelle Obama, they are used in exactly the same order?” He came up with 14 “distinct” phases in both speeches, i.e. phrases replaceable with synonyms, and came up with this N factorial formula:
14*13*12*11*10*9*8*7*6*5*4*3*2*1
“According to this calculation, there are a grand total of about 87 billion different permutations for those 14 distinct phrases,” noted Rutledge at his Facebook page. “That’s 87,000,000,000—or about the number of stars in the Milky Way Galaxy.”


Hmmm, wondering the odds that Melania and her defenders will actually understand this calculation...
Correction: An earlier version stated the odds were 1 in 87 million. It’s actually one in 87 billion.


Update: it’s all but been confirmed that the speech was plagiarized.
Meredith McIver, a former ballerina and in-house staff writer for the Trump Organization, has…
[Global News]

Humans may be more closely related to great apes, but according to science, our true spirit animals are aye-ayes. These Gollum-eyed lemurs like to skulk about in the forest getting liquored until the sun comes up. Wow, same!
Alcohol is found naturally in fermented nectars, honeys, and fruits, but the enjoyment of this liver-destroying toxin is seen as a uniquely human trait. This view, however, has recently come under fire—not only have field biologists observed chimps swilling naturally fermented palm wine, genetic studies suggest that the basis for alcohol tolerance (an enzyme called alcohol dehydrogenase) may be widespread among primates.


Which begs an important question: do our arboreal ancestors also imbibe crunk juice for kicks?
In the first controlled study to test that hypothesis, Dartmouth scientists turned to two likely alcoholics, ayes-ayes and the slow loris. Over the course of fifteen days in the case of aye-ayes and five days in the case of the slow loris, the animals were offered sugary solutions with alcohol concentrations varying from zero to five percent. They found that aye-ayes could not only discriminate between the different concentrations of alcohol, they preferred their soda with as much booze as possible. While the slow loris had similar feeding patterns, the trials were too few to yield statistically significant results.


Another trait aye-ayes share with humans: when their bottle runs dry, they continue to poke at it sadly, suggesting they want more. The researchers suspect that a preference for alcohol offers an evolutionary advantage, given that it’s a source of calories otherwise avoided. A likely excuse.
Correction 6/20/16: A previous version of this article incorrectly referred to aye-ayes as monkeys, they are in fact prosimians. We apologize for the error.
[Royal Society Open Science]
SpaceX’s Dragon spacecraft arrived at the International Space Station this morning, where it was neatly snagged by the station’s 57-foot robotic arm.
Here’s a clip of the capsule right after it was captured at the ISS by NASA astronauts Jeff Williams and Kate Rubins:

Now that Dragon has arrived, the next step will be to dock it to the ISS so that the crew can get to the more than 5,000 pounds of gear stashed in the capsule’s cargo hold. Highlights of that gear include the space station’s first DNA sequencer, which Rubins will use to attempt to sequence DNA in space for the first time—and also hopefully figure out what the weird, unidentified mold growing on the ISS walls could be.
The ISS is getting an incredible new tool: a handheld DNA sequencer. The questions scientists hope…
Dragon also has something else unusual onboard: a new standardized docking adapter to fit future commercial spacecraft from SpaceX, Boeing, and perhaps additional companies shuttling astronauts to the station. The new adapter is the first of two that will fitted to the ISS.
Rembrandt was renowned for his masterful use of light and dark contrasts, and the precise proportions in his paintings and etchings. Now a British artist claims the 17th century painter likely used combinations of mirrors and lenses to project images onto a drawing surface to create them—especially his famous self-portraits. It’s the latest volley in a longstanding debate about the possible use of optical aids by Renaissance artists.
“The evidence suggests [Rembrandt] used lenses,” said Francis O’Neill, lead author of a new paper in the Journal of Optical Physics. “The similarity of his images to projections, in their lighting and soft focus, along with the use of lens technology by his peers and fellow artists, and the contemporary literature on the subject, all support this.”


O’Neill had just completed his foundational art courses several years ago when he decided to spend a month in Europe, visiting all the big galleries. He was particularly impressed with the works of Rembrandt, especially the small, jewel-like self portraits. They were so detailed, with such rich textures and well-controlled proportions, that O’Neill couldn’t help wondering how Rembrandt had managed the feat.
Back in England, he happened upon a BBC program about David Hockney’s book, Secret Knowledge. Hockney had broached a controversial theory that some early Renaissance painters, including the 15th century Dutch Master Jan van Eyck, used optical devices to achieve certain ultra-realistic effects in their paintings, particularly when it came to perspective.


Hockney partnered with University of Arizona optics professor Charles Falco to analyze key measurable distortions in early paintings he saw as providing strong evidence for his theory.
For instance, in Lorenzo Lotto’s late Italian Renaissance painting Husband and Wife (circa 1543), the geometric keyhole pattern of the carpet loses focus as it recedes into the painting, and there are two vanishing points in the detail of the fabric’s border. Had linear perspective been used, the pattern would have receded in a straight line. Instead, there is a kink in the pattern, which then continues in a slightly different direction.
Hockney and Falco see this as evidence that Lotto used a lens to project and trace the pattern of the cloth, but then found he could not keep it all in focus at the same time. So he refocused the lens to complete the back portion of the cloth, changing the vanishing point.
It proved to be a controversial thesis, and the debate is ongoing. But Hockney didn’t think such methods would work in the case of self-portraits. The artists of the Baroque era who used optical aids would have relied on a camera obscura effect, requiring the subject of a painting to be in a brightly lit room, with the artist sitting in a dark room. This would be impossible for a self portrait—how could the artist be in both light and dark rooms at the same time? O’Neill eventually realized it was possible to see projections on metallic surfaces, and that Rembrandt had done some of his earlier etchings  on copper plates.
So O’Neill bought a cheap ladies’ compact mirror—the kind with both a curved and flat mirror—and found he could, indeed, project an image of his face onto a crinkly sheet of aluminum while hovering in a doorway to partially shade himself from sunlight. “As I started to understand how it worked, it was easy to do the etching type of projections on copper, because copper is very reflective,” he told Gizmodo.


Like Hockney, he enlisted the aid of an optics expert to further test his hypothesis: physicist Sofia Palazza Corner, who co-authored the paper. They figured out five possible setups by which Renaissance artists might have made projections for tracing, using different combinations of mirrors and lenses.
A thorough review of 17th century literary sources revealed that Rembrandt likely would have known about such lenses and experimented with them. Small pocket mirrors and spectacles first appeared towards the end of the 13th century. Hockney reasoned Van Eyck and his contemporaries most likely owned such “mirror lenses” and might have used them in their work.
The use of such a setup would also explain the unusual off-center focus of the eyes in Rembrandt’s self portraits. “It’s impossible to make a self portrait [in that pre-photography age] if you’re not looking at a flat mirror,” said O’Neill. “Whereas this system always requires you to look just slightly to the side, because that’s where the [projected] image is.”


One of the fiercest critics of Hockney’s and Falco’s thesis has been David Stork, who somewhat predictably pops up in the New York Times article about O’Neill’s paper citing brush strokes as counter evidence.


“If the artist is painting over it with downward strokes, then when you take the paintings and turn it right side up, all those brushstrokes would go upward,” he told the New York Times. “But in every Rembrandt, not a single brushstroke goes in that direction.”
Not surprisingly, both O’Neill and Falco dismiss Stork’s critiques. O’Neill, as an artist himself, scoffs at the notion that brush strokes should all go in one direction. Furthermore, he and Falco both point out that is highly unlikely that Renaissance artists would have created full paintings by tracing the projections with a paintbrush.


Rather, for portraits, an artist would probably have used the projection to capture just the critical details—the corners of the eyes and mouth, points of perspective, blocks of color—then turned the painting right side up to complete it without projection. “Even if an artist did a good amount of painting directly from the projections, when he turned it over to finish it a lot of work still remains to be done at that point,” Falco told Gizmodo. “So early brush strokes almost certainly would end up being covered by later ones.”
O’Neill’s work has certainly gained gained Falco’s approval. “The optical setups the authors propose are reasonable ones and could certainly work in the way described,” he said. “It’s not surprising that the lead author of the paper is an artist, not an art historian, since artists are immersed in matters of technique, and so are particularly open to making findings like this.”
As for O’Neill, he said, “I think we’ve got proof beyond reasonable doubt.”


[Journal of Optical Physics]
Notice something strange about the wall mural in the above photograph? It’s upside down! That’s…
Futurama may not make me laugh as hard as other comedies, but its vision of the future and all the shenanigans that come with it have always been enjoyable to watch (throughout all its various cancellations and comebacks). Kaptain Kristian makes the case that Futurama is special because it was the “master of hiding brilliance in plain sight. Bridging the gap between comedy and arithmetic while bringing humanity to the science.”
Plus, the writing staff had three PhDs and seven masters degrees, so of course they were stupid smart.

Drought is spreading across farmland worldwide—and it’s only going to get more intense. New research offers a clue on how we might be able to continue to grow the staples we’re used to but with much less water.
A lot of staple crops, like rice and wheat, actually have a defense mechanism to protect against drought. But by the time it kicks in, it’s often too late. Researchers at the Australian National University have just identified the enzyme—phosphatase SAL1—responsible in a new paper in Proceedings of the National Academy of Sciences. Now, they want to use it to push plants into drought-mode early.


The researchers say the enzyme acts like a “fire alarm” in the plant. The problem is that its like a fire alarm that doesn’t start to blare until at least a few rooms of your house are already ash. The defense mechanism cuts down on water loss and usage in the plant, but it will only kick-in when the plant has been in steady drought-like conditions for a long period of time.
By the time a plant goes into water-preservation mode, it’s often already fairly mature. Unfortunately, plants are especially vulnerable to damage in their early seedling stages. So starting drought-countermeasures early could mean that plants are more likely to not only survive but to produce a larger edible product in the end.


Now that researchers have figured out what and where the enzyme trigger is, their next step is to figure out how to use it. So far, it’s only a first step, but in a rapidly drying world, it could end up being a pivotal one.
If your life has felt like a hot mess this year, you’re not alone. Same goes for the Arctic, which month after month has seen its ice cover contract to new lows. By late September, Arctic sea ice may reach its lowest extent since satellite record-keeping began.
And that’s got scientists in a tizzy, because if there’s one thing geologic history has taught us, it’s that sudden drops in Arctic ice cover are often the tip of the proverbial iceberg for a whole slew of planetary feedbacks.


It’s difficult to keep up with all the climate-related records our world has been smashing, so here’s a quick recap of what’s been happening up north. At the close of 2015 (currently the hottest year in recorded history, but not for long), the Arctic was already sweating iceberg-shaped bullets, thanks to freakishly warm weather brought on by a combination of a monster El Niño and the underlying global warming trend. Then 2016 burst on the scene, with temperatures at the North Pole rising some fifty degrees Fahrenheit above normal. The Arctic stayed exceptionally hot through January and February.
By the time March rolled around, the atmosphere was loaded with heat, and Arctic sea ice was already starting to look thin. NASA confirmed that it was indeed the smallest wintertime Arctic sea ice extent on the record books, peaking at some 5.6 million square miles (14.5 million square km).


Then, the Arctic started to melt. And it kept going, and going, and going, smashing record after record, month after month.
As of this writing, we’ve just come off the fifth record-low sea ice month this year. Every month except March has marked an all-time monthly low, with June sea ice maxing out a full 100,000 square miles (260,000 square kilometers) below the previous record low, set in 2010. June sea ice was also 525,000 square miles (1.36 million square km) below the 1981-2010 average. Put another way, a Texas-sized chunk of sea ice has disappeared from our planet’s north pole between the early 1980s and today.
“The first six months [of 2016] have certainly primed this year to be a record,” NASA sea ice scientist Walt Myer told Gizmodo in a press call, adding that we’ll need to see the data from July and August before we can give this summer the gold. (While a period of sustained high pressure over the Arctic helped fan the flames early, recent weeks have brought a cooler, low pressure system to the region.)
“Regardless, it’s going to be a very low ice year,” Myer continued. “Which is fitting with what we’ve seen over the last fifteen years and beyond.” If recent trends are any indicator, we’re speeding toward a future free of summertime sea ice by mid-century, and all of the complex feedbacks that go along with it.


The first of those is albedo, or the reflectivity of the planet’s surface. As shiny, ice-covered surface gives way to darker ocean water, the Arctic absorbs additional heat. “That’s changing the Arctic climate,” Myer said. “You have a lot more heat going into the system [in the summer], meaning more warm temperatures in the fall.”
Indeed, NASA researchers are finding that the frequency of aquamarine ponds called “melt pools” on the surface of sea ice sheets are a very good predictor of the summertime sea ice minimum, for exactly this reason. “Melt ponds are a major contributor to radiation and heat in the Arctic,” said Nathan Kurtz, a sea ice researcher at NASA’s Goddard Spaceflight Center. “The more of them there are, the more energy is being absorbed from the sun, and transferring into the ice and the ocean.”


This melt-driven feedback loop is likely contributing to the rapid warming we’re seeing in the Arctic—approximately three times the globally-averaged rate.
Rapid warming up north, in turn, is contributing to profound shifts on land, including a greening of the Arctic tundra, the collapse of permafrost banks along Alaska’s northern shores and elsewhere, and an intensification of fire season. “Both fire [increases] and greening are happening on a continental scale,” said Charles Miller, an Arctic ecologist at the Jet Propulsion Laboratory.
There could also be more global effects. Some evidence indicates that Arctic warming—which is causing a change in the temperature gradient between the equator and the poles—could be shifting the polar jet stream, causing it to meander more north and south rather than traveling a straight line. A recent study from Rutgers University linked a wavier jet stream to an uptick in extreme weather events, noting that “these are the types of phenomena that are expected to occur more often as the world continues to warm and the Arctic continues to lose its ice.”


However, as the National Snow and Ice Data Center’s Julienne Stroeve told Gizmodo, these links are still controversial. “Everybody agrees that we should see an effect, but whether or not the signal has emerged above the chaotic climate system is not clear,” she told Gizmodo.
Climate feedbacks aside, the rapid disintegration of Arctic sea ice will have a dramatic impact on the ecology of this unique part of our planet. The ice shelf is home to numerous charismatic megafauna, including Pacific walruses and polar bears, which are having to swim further and expend more energy to find a meal. Meanwhile, at the other end of the food chain, biologists are starting to worry about subtle changes in ice algae blooms affecting the reproduction of tiny, algae-eating crustaceans called copepods. This in turn could reduce the food supply for everything from seabirds to whales.
It’s a domino effect for the plants, animals, and ecosystems of the Arctic, and for the planet at large. And let’s not forget who else that planet supports: all of us.
Venus’s unusually thick atmosphere is typically regarded as a barrier that prevents us from gazing upon its tortured surface. By studying subtle shifts in weather patterns, however, scientists have learned that these clouds also offer important clues as to what lies beneath.
New research published in the Journal of Geophysical Research shows there’s another way to study the topography of this mysterious planet, and that’s by looking at the very thing that’s obscuring its surface: clouds. Using radar and infrared light, the researchers managed to pierce our nearest planetary neighbor’s oppressive atmosphere and peer below.


Like Earth, Venus features mountain ranges, canyons, rift valleys, and vast plains. And like our planet, these surface features influence weather. Weather is markedly different on Venus than it is on Earth, and scientists are now starting to get a handle on just how weird it is.
Add this to the list of reasons Venus is a blistering hellscape: not only is the surface hot enough …
Owing to a greenhouse effect, the surface of Venus is a scorching 450 degrees Celsius. Ground-level winds are achingly slow, moving at just three feet a second. But things are different higher up, where winds reach upwards of 30 to 45 miles per hour, and where temperatures reach a more manageable and Earth-like -70 degrees Celsius (-94 degrees Fahrenheit). Even higher up, near the top of the 12-mile-thick atmospheric layer, the winds blow hundreds of times faster than they do on the surface.


Using the Venus Express Satellite, an international team of astronomers, including a team from the Max Planck Institute in Germany, studied three different aspects of the planet’s cloudy weather, namely the speeds at which these clouds circulate, the amount of water locked up in these clouds, and the brightness of these clouds across the visual spectrum (particularly in ultraviolet light). Together, these three aspects could be connected to surface features below.
For example, the researchers discovered one particular area of cloud near the equator that contained more water vapor than usual. It just so happens that this “damp” region is located directly above a 15,000-foot-high mountain range called Aphrodite Terra. Water-rich air from the lower atmosphere is being forced upwards above the mountains, causing the unusually wet clouds. The researchers dubbed this meteorological feature, the “Fountain of Aphrodite.”
To explain this effect, the researchers point to a phenomenon known as gravity waves, which shouldn’t be confused with gravitational waves. (Those are very different).
“Gravity waves are an atmospheric phenomenon we often see in mountainous parts of Earth’s surface,” explained Jean-Loup Bertaux of LATMOS (Laboratoire Atmosphères, Milieux, Observations Spatiales), and lead author of the new study, in a statement. “Crudely speaking, they form when air ripples over bumpy surfaces. The waves then propagate vertically upwards, growing larger and larger in amplitude until they break just below the cloud-top, like sea waves on a shoreline.”


As the waves break, they push back against the fast-moving high-altitude winds which slow them down. This results in a wind circulation system that functions like an air pump; water-rich air is thrown up into the atmosphere, creating the “fountain” and a resulting downwind plume of vapor. Similar effects were observed along other mountainous regions along Venus’s equator, where the warmer temperatures fuel this particular weather feature.


This research is important—and not just because it improves our understanding of Venus. The new details also enhance our understanding of climate as well. Our planet is steadily warming due to the steady release of greenhouse gasses, so it would behoove us to learn as much about this stifling hot planet as possible.
[Journal of Geophysical Research]

Having successfully launched and landed a few single rockets, SpaceX is now planning a simultaneous triple rocket landing. This is going to look cool.
SpaceX told The Orlando Sentinel that it’s seeking government permission for two extra landing pads in preparation for the launch of the new Falcon Heavy rocket. The private spaceflight company says that it might attempt to land its Falcon Heavy rockets on one of its drone barges—a protocol that the SpaceX has nearly perfected in the past year. Eventually, however, SpaceX wants to land three rockets on solid ground. The extra two ports SpaceX hopes to build at Cape Canaveral’s Air Force Base, where the company already has one port, would give it the real estate to do that.


When the Falcon Heavy launches, it will be the world’s most powerful rocket, beating the current title-holder, the Delta IV, with more than twice the power. The Falcon Heavy will be capable of lifting up to 54 tons of weight into space. To get that much thrust, it actually has three separate rocket cores, and that means that the company will need multiple landing pads to successfully save all three rockets.
Musk went on Twitter to further explain that two of those rockets would land practically simultaneously, while the third would arrive after a slight delay. You can see how the process would unfold in this animation the company put together:

Three rocket landings at once certainly sounds like something to see, but Musk also went on to hint at one more landing down the road. While the rocket cores in the Falcon Heavy are designed to return, the upper stage of the rocket is not—not yet anyways. Musk tweeted:

Prob best to stay focused on the Mars rocket, indeed.
Between 2011 and 2014, while humans were discovering dubstep and the wonder of selfies, Greenland was melting fast. It lost a trillion tons of ice in just three years, and the world neither noticed nor gave a damn.
That’s according to a new, open-access study published in Geophysical Research Letters, which used the European Space Agency’s CryoSat satellite, along with regional ice models, to show that recent melting of the Greenland ice sheet contributed twice as much to sea level rise (roughly 2.5 millimeters over the study period) as the prior two decades. In other words, Greenland—which has been visibly losing ice since the ‘90s—is melting at an accelerating rate.


This falls right in line with the picture Earth scientists have built by studying past ice sheet contractions. Namely, when ice starts melting, it doesn’t go in a plodding, linear fashion. It disintegrates quickly, resulting in large pulses of sea level rise over short periods of time. One such pulse 12,500 years ago wound up adding approximately 50 feet to global mean sea level within three to four centuries.
The Intergovernmental Panel on Climate Change predicts roughly three feet of sea level rise this century, while NOAA predicts somewhere between four and six and a half feet. But these estimates don’t fully account for the feedbacks that cause ice sheet melt to accelerate, leading some scientists to suspect they are very low.

We’ll just have to wait and see how the planetary experiment plays out this time around. As geologist Hal Wanless of the University of Miami pointed out to me in a recent conversation, sea level was roughly 420 feet lower 18,000 years ago than it is today. At that time, atmospheric carbon concentrations were only 180 parts per million—100 ppm lower than they were at the start of the Industrial Revolution. Now, over less than two centuries, we’ve pushed the atmosphere permanently north of 400 ppm.


“That should be a huge red flag to people,” Wanless said. “That should tell people, hey look, we’ve really done it. We’re really going to initiate some serious ice sheet melt.”
Zika is scary, but as long as we don’t travel to certain countries and don’t have sex with people who are infected, all is well, right? Nope, maybe not. Scientist are trying to figure out how a man in Utah got Zika when the state has no infected mosquitoes and he didn’t have sex with the infected person he was helping.
There are currently about 1,300 Zika cases in the U.S., all of which were acquired by traveling abroad. Until the Utah case, traveling abroad and sex were thought to be the only ways to transmit the disease. Though the virus can live in urine, blood, and saliva—in addition to semen and vaginal fluid—there were previously no cases of it being spread in those ways.


The Utah man has now fully recovered. He had been taking care of an older man who had contacted Zika after traveling, and who died in June. A team from the Centers for Disease Control and Prevention is investigating the case and testing people who came in contact with the recovered Utah man. Results are not yet available.
“We don’t have any evidence that suggests Zika can be passed from one person to another by sneezing or coughing or kissing or sharing utensils,” CDC director Dr. Thomas R. Frieden said. Good, because if there’s one thing we don’t need, it’s another scare like the SARS one that had everyone wearing face masks and quarantined.


[New York Times]
If you’ve ever enjoyed those horror movies that involve organ harvesting, you may be pleased to know that scientists are one step closer to using organic matter to power robots. Sea slugs are getting first honors though.
Scientists from Case Western Reserve University took a sea slug’s mouth muscle and attached it to two-inch 3-D printed parts to make a “biohybrid robot.” When shocked using electricity, the muscle helps the hybrid crawl forward—though at the not-very-quick speed of 0.4 centimeters a minute.


“We’re creating a robot that can manage different tasks than an animal or a purely manmade robot could,” said doctoral candidate Victoria Quinn, who is leading the research. Sea slugs are adaptable to different temperatures and the soft muscle cells are safer to operate than hard parts.
In the future, these biohybrid robots could be used for search missions in the ocean. Between this 3-D printed sea slug and the stingray robot fueled from light-activated cells from rat hearts one day we could have an entire fleet of cyborg animals doing our bidding.


[Phys.org]
If you can’t stand the heat, it’s not the week to be in America, my friends. All signs are pointing toward a miserable, record-smashing heat dome engulfing most of the continental US over the next few days. For a scientific illustration of what our impending heat death will look like, meteorologists over at NOAA have just released an exceptionally visceral map.
The visualization above shows us predicted high air temperatures today, reflecting the onset of the heat wave expected to grip the nation from the Rockies to the eastern seaboard by later in the week. In other words, this is America going into the worst hot spell of the summer, one which could bring heat index values of up to 110 degrees Fahrenheit (43 degrees Celsius) or higher.
Do you like sweating profusely and racking up enormous AC bills? Then you should head anywhere east …
I can’t wait for the visualization of what we’re going to look like coming out the other side.


[NOAA]
Since the time of Isaac Newton, scientists have wondered if the gravitational pull of the sun and moon might be strong enough to trigger earthquakes and tremors on Earth. An analysis of 81,000 low-frequency earthquakes along the San Andreas Fault now confirms these suspicions.
The new paper, published in Proceedings of the National Academy of Sciences, shows that small, deep earthquakes within California’s San Andreas Fault—the primary plate boundary fault in southern California that extends for 800 miles—are more likely to occur when the tide is waxing. A team led by Nicholas J. van der Elst from the U.S. Geological Survey chronicled tens of thousands of quakes along the fault during a repeating two-week tidal cycle, known as “fortnightly tides.”


Given the complex dance of the sun and moon relative to the Earth’s surface, different parts of the Earth are subject to different tidal cycles. The classic 12-hour and 24-hour tides are well observed along the coast lines, but other long period tides exist as well, including the fortnightly tide—a recurring tidal phase that varies in magnitude over the course of its 14-day cycle. A fortnightly tide happens when the Earth-moon “bulges” are combined with the Earth-sun “bulges,” resulting in a twice monthly change in the range of the tides.
The idea that the sun and moon might be pulling and pushing the Earth’s crust like an accordion, has captivated scientists for hundreds of years. Alexis Perrey, a 19th century French seismologist, suspected a correlation between the moon and seismic activity on Earth, and devoted much of his life’s work to the subject.


Perrey struggled to find empirical evidence to support his assertion, but his followers would have better luck. Today, it’s well established that “solid Earth tides,” as they’re called, can trigger tremors (very slight earthquakes that cause little to no damage) virtually anywhere that tectonic tremors are found. Scientists have also found evidence (though that evidence is scant) that solid-Earth tides can trigger more substantial earthquakes. But these gravitationally triggered events are only observed in very select environments, such as mid-oceanic ridges and shallow thrust faults.
For the new study, van der Elst and his team considered the potential for tidal cycles to trigger slow, deep, and relatively weak tremblors known as low-frequency earthquakes (LFEs). They compared the phase of the solid-earth tide with the timing of 81,000 cataloged LFEs that occurred along the fault from 2008 to 2015.
And they discovered that the fortnightly tide cycle triggers earthquakes along the San Andreas fault, but only under certain conditions. The number of LFEs spiked as the two-week cycle was still waxing—not at its maximum peak when the gravitational pull from the sun and the moon is at its strongest.
The researchers theorize that the LFEs are triggered when the stress imposed by the solid-earth tide exceeds the strength of the fault at a given point, resulting in a fault slip. The gravitational pull of sun and moon slightly lifts and lowers the earth’s crust, stretching and compressing crustal rocks. Sometimes this is enough to cause a quake.
This research strengthens the suspected links between tidal forces and earthquakes, while providing a new way of studying plate tectonics. It could even help seismologists predict when earthquakes and tremors might happen.


[Proceedings of the National Academy of Science]

The rings are the star of almost every picture of Saturn. But take a closer look and there’s something mysterious about those pictures. Where are all the actual stars around the planet?
The stars are there, you just can’t see them, and the reason why is the rings themselves. The rings of Saturn are incredibly bright—in fact, they’re brighter than most known stars. And that brightness comes at a cost.


When astronomers take photos of the planet with Cassini’s Saturn-orbiting camera, including both the rings and stars in the same frame saturates the camera with too much light. To get just the rings, photographers can use a shorter exposure time, but that also means that the less-bright stars don’t show up in the frame at all. Even pictures of Saturn’s surrounding moons often end up with no stars in the frame because the moons also add to the overall brightness.
Cassini did manage to snag a picture of Saturn’s moon Enceladus in 2008, with stars in the background, but only because the moon was in eclipse at the time.
Wonder Bread is already semi-miraculous: It’s impossibly soft, sweet, and shelf-stable. But unlocking the true potential inside this fluffy stuff results in a substance nearly impervious to heat and electricity, not dissimilar from what used to cover the exterior of spacecraft.
The process for turning Wonder Bread into carbon foam is essentially the same as making charcoal. As extremely Canadian tinkerer AvE shows, you just stick the material into a very hot oxygen-free container until it’s blackened. Just as charcoal retains the shape of the wood, carbonized Wonder Bread is full of the same tiny holes that make the unburnt version so fluffy. Holes mean foam, foam means incredible insulating properties.


AvE’s creation can, by his estimation, withstand temperature of up to 6,600 degrees Celsius (about 11,900 degrees Fahrenheit) and has an exceptionally high electric resistance. Arguably the coolest thing about this baking incident gone wrong is that astonishing levels of heat don’t really melt or burn it in the traditional sense—it sublimates, instantly turning into gas.
All of this is backed up by a recent study in ACS Applied Materials and Interfaces. The researchers found that carbon foam made from bread “is mechanically stiff, can shield against electromagnetic interference and is much less flammable than current carbon foams.” Scientists sat in a lab, made bread, and torched it because this method is cheaper—and in some cases better—than existing options to manufacture carbon foam.


Do you like sweating profusely and racking up enormous AC bills? Then you should head anywhere east of the Rockies stat, because this week, a high pressure dome is coming to town, and it may bring some of the hottest summertime highs the US has ever seen.
Since last week, weather forecast models have been in agreement that a high pressure ridge of air will march across most of the contiguous US this week. It’s expected to spawn in the Plains tomorrow, strengthen on Wednesday, reach the Northeast by Friday, and persist through the weekend.


The heat wave is predicted to bring temperatures of above 90 degrees Fahrenheit (32 degrees Celsius) to many locations and highs above 100 (38 degrees Celsius) to especially lucky states, including Iowa, Wisconsin, and Minnesota. By the latter part of the week, parts of Minnesota and the Great Lakes places may experience highs close to thirty degrees Fahrenheit above normal. Potentially hard-hit cities include Minneapolis, Des Moines, Chicago, and Milwaukee.
It’s already been a sizzling summer—we recently learned that June was the hottest on record for the lower 48, and the mercury is showing no signs of mercy this month. Globally, we’re well on our way to another hottest year in recorded history. While specific meteorological events are not caused by climate trends, extreme heat waves are predicted to become more common in a warming world.


With any heat wave, there’s always the concern of heat exhaustion, and this week will be no exception. As meteorologist Dan Satterfield points out over at AGU, the dew point, or temperature below which water vapor can condense, has been extremely high along the east coast recently, owing to the enormous amount of heat being stored in the ocean (for which our dearly departed record-breaking El Niño is partially to thank). Since the human body’s natural cooling mechanism relies on the evaporation of sweat, a high dew point combined with high temperatures can increase the risk of heat stroke.
In other words: if you’ve got to catch them Pokémon this weekend, do so early or late in the day, and don’t forget to drink a ton of water.
Trompe l’oeil (literally “to deceive the eye”) is an ancient technique whereby a painter creates a visual illusion via a trick of perspective. French street artist Patrick Commecy is a modern master of this art form, working with his team of artists at A-Fresco to create huge, hyper-realistic murals on otherwise drab building facades.
Per S.A. Rogers of Web Urbanist:
“The most dramatic example is a Montpelier building, the back of which is within view of a nearby park. Worn and neglected, the structure was a bit of an eyesore as-is. Commecy’s team A-Fresco transformed it with a full faux facade including a tiled roof, windows with balconies and a small tower. The figures seen in the outdoor spaces are famous and influential Montpelier residents throughout history.”
Those figures include Antoine Jérôme Balard, a 19th century chemist who discovered bromine. Check it out:
For even more amazing trompe l’oeil murals, check out the A-Fresco website (in French).


[Design You Trust]
Knuckleballs are mostly associated with baseball in the United States, but this devilishly unpredictable ball motion also shows up in soccer, cricket, and volleyball. Yet it’s never seen in other sports like squash, basketball, and table tennis. A team of French scientists think they’ve finally figured out why and describe their conclusions in the New Journal of Physics.
What makes the knuckleball so damned difficult to hit or catch is its unusually erratic trajectory. It starts out flying straight through the air, but can break quite suddenly in any direction, zigzagging wildly late in its flight. So naturally players and coaches around the world are quite keen for any new insights science has to offer that might give them an edge against the knuckleball.


Part of the secret is the spin, or lack thereof. In baseball (and cricket), knuckleballs are the result of pitchers (or bowlers) holding the ball between the knuckles and using just the fingertips to avoid putting a spin on it. New York Mets pitcher R.A. Dickey is famous for his knuckleballs, winning the 2012 National League Cy Young Award for his skill. A spiked volleyball can also exhibit that telltale zigzag motion.
In soccer, when a player strikes the ball in such a way as to give it very little spin, the ball will flutter unpredictably from side to side—a specialty of Real Madrid star player Christiano Ronaldo. In Brazil it’s known as pombo sem asa (“dove without wings”).
In 2012, scientists at the Ecole Polytechnique in France managed to devise a set of laws predicting how much different ball sizes, moving through a fluid (notably air and water), would “knuckle.” They conducted a series of experiments that included dropping steel, glass, and plastic beads into a tank of water spiked with fluorescent dye, the better to study their trajectories with ultrafast cameras. All the beads zigzagged in the water, regardless of density, and the less dense the beads, the more they knuckled.


But their initial findings predicted that we shouldn’t see the knuckeball effect in soccer. So what might be Ronaldo’s secret? The key is something physicists call the drag crisis. “When a sphere is in a flow, there is a critical velocity at which the wake behind the sphere and the drag force acting on the ball sharply decreases,” co-author Caroline Cohen told Inside Science News at the time. That asymmetry in the wake creates a sideways force resulting in the zigzagging motion.
So generally speaking, the surrounding air flow is different on opposite sides of the ball, and since the distribution of air pressure is constantly changing, the ball will flutter. That means Ronaldo must kick the soccer ball at just the right velocity (close to the drag crisis threshold) with no spin to produce a knuckleball. And the smoother the sphere—i.e., the fewer seams in the ball—the more you see the knuckle effect.
Now Cohen and her Ecole Polytechnique colleagues are back with a new analysis of the knuckleball effect. This time around, the team built their own custom kicking machine to launch balls through the air in a wind tunnel at different speeds, with very little spin.
And they found a more universal culprit for the knuckling effect: unsteady lift forces. However, “Unsteady lift forces are inherent to balls traveling through the air in every sport, so to complete our work we needed to find out why zigzag shots are associated with just a few games, such as soccer or baseball,” co-author Baptise Darbois Texier said in a statement.


Once again, the drag crisis proved critical: there is a sweet spot in terms of velocity that produces larger lift forces and more side-to-side movement. The typical shooting distance for any given sport also matters. “In bocce, for example, a zigzag path should occur over a length of 27 meters, but this distance is much longer than the typical shooting length and so the knuckleball effect will be incomplete,” said Darbois Texier.
And that’s why we typically don’t see the knuckling effect in bocce, handball, table tennis, or basketball.


[New Journal of Physics]
The Pokémon Go craze is still going strong, as players scamper about the great outdoors trying desperately to catch ‘em all. And amid all the accompanying media frenzy, there’s one burning question on everyone’s mind: where’s the science?
Yes, there is a science of Pokémon—specifically, a 2012 satirical study that appeared in the humorous journal, Annals of Improbable Research entitled, “A Phylogeny and Evolutionary History of the Pokémon.” The authors—then a group of budding young entomologists at the University of Caifornia Davis—traced the evolutionary history of the 646 fictional species of “pocket monsters,” even creating an impressive 16-generation phylogenetic or evolutionary tree.


Why do this at all? Well, the paper itself cites the need to document all the species because they are “threatened by the Pokémon fighting rings that are growing rapidly in popularity, particularly among urban youth.” But really, it was just a fun side project.
“I had a lull in my dissertation research and decided to spend the weekends and downtime making this phylogeny,” lead author Matan Shelomi said at the time. “It took at least a month to actually collect all the data, which I did manually by scrolling through Pokémon websites.”


Considering the creatures are entirely made up, the tree turned out surprisingly well, although a fierce debate over possible errors raged on Reddit when the tree was first published. It was also a fitting tribute to Pokémon’s creator: Japanese video game developer Satoshi Tajiri, who collected insects in his childhood and once considered becoming an entomologist.


You can see the full-scale, high resolution image of the evolutionary tree here.
[Annals of Improbable Research]
Rock and mountain climbers rely on strong, yet elastic ropes to keep them safe should they happen to fall. Now mathematicians at the University of Utah have come up with an equation to design an ideal climbing rope—one that would be safer and more durable. They described this perfect rope, and a promising class of materials that might be used to make it, in a recent paper in the Journal of Sports Engineering and Technology.
Climbing ropes are designed with a bit of stretch in them—the better to absorb some of the impact during a fall—although the ropes will gradually lose their elasticity over time. They’re usually made of nylon fiber, twisted at the core to give the ropes their strength. But “with a normal rope, you’re going to experience increasing force the longer you fall,” co-author Graeme Milton said in a statement. That means a harder jerk when a falling climber hits the end of the rope, depending on how far he or she has fallen.


An ideal rope, like the one envisioned by Milton and his co-authors, would slow down climbers as they fall by applying a constant deceleration force, thereby bringing the climber to a gradual stop rather than hitting the end of the rope with sudden jerk. It’s the same concept as applying the brakes evenly when decelerating in a car over a short fixed distance to avoid giving yourself whiplash. As Milton explained, “The ideal climbing rope would decelerate a falling climber in the same way that on an aircraft carrier, the braking cable and its hydraulics slow down and stop a jet within a short distance.”
Right now this ideal rope is purely theoretical, but Milton et al’s paper demonstrates that it’s at least mathematically possible to design something like this. They even proposed a promising class of materials: so-called shape-memory materials, which “remember” their original shape and return to it even after they’re deformed.


One example is the nitinol wire found in everything from helicopter blades, stents, and heart valves, to golf clubs, underwire bras, and flexible eyeglass frames. These materials can absorb a lot of energy, so a rope made out of the stuff would stretch out and then retract slowly, instead of snapping back suddenly.
Unfortunately, nitinol (an alloy of nickel and titanium) is too heavy and expensive to make such an ideal rope, plus it’s ultra-sensitive to changes in temperature, and difficult to knot or coil. And the other known shape memory materials don’t stretch quite enough for climbing purposes: a rope made of them might stretch 108 percent of its usual length, compared to 125 to 135 percent for the top climbing ropes now being used. Combining a shape memory material with nylon fiber or other conventional materials might be one way to address that shortcoming.
It’s really just a first step. As the authors write in their paper, “We do not expect...to have an immediate effect on the climbing community, but by providing a prescription for a mathematically ideal rope,the work may help guide the development of new ropes.” Perhaps rock and mountain climbers will one day have cause to thank them.
[Journal of Sports Engineering and Technology]
The smell hit me as soon as I opened my car door—like rancid milk mixed with dog shit. I gasped for breath as humid air descended, filling my pores with the putrid odor.
“It’s been like this for three weeks,” Mary, the unhappy attendant at the deserted Central Marine boat dealer told me. “Last week it smelled like a dead animal. Today—I don’t even know.”


“Be careful out there,” she added as I headed off to the docks.
The reason for her warning was soon clear: at the water’s edge, the stench of fly-covered slime was almost impossible to bear. Eyes and lungs searing, I walked up and down the harbor snapping photos. The taste of the air was as bad as the smell.


This was my warm welcome to Stuart, Florida, whose St. Lucie estuary is currently suffocating under a vast, nutrient-fueled algae bloom. The St. Lucie is no stranger to algae, but this summer’s slime is fouler and more widespread than anything locals have ever seen.


Not only does the water look and smell like a sewer, it’s potentially a serious health hazard. The Department of Environmental Protection has begun detecting microcystins, cyanobacteria toxins which if ingested can cause nausea, vomiting, and liver failure. Locals exposed to the rank odor of “guacamole thick” algae mats have complained of rashes, eye and skin irritation. Tourism is taking a nosedive.
It could get worse before it gets better.
And this is no accident. What’s happened to the St. Lucie is the latest symptom of a problem that can be traced 35 miles west to Lake Okeechobee, where years of mismanagement and entrenched agricultural interests have precipitated one ecological crisis after another.


“This is absolutely, positively a Lake Okeechobee issue,” oceanographer Zack Jud told me when I arrived at Florida’s Oceanographic Society a few miles away to learn what the hell was going on. “That’s where the whole crux of this problem lies.”
The second largest freshwater lake located entirely within the continental US, Okeechobee used to be the beating heart of the Everglades, connecting freshwater from the Kissimmee river in the north to the sawgrass prairies stretching more than 100 miles south. That all changed in the 1930s, when the US Army Corps of Engineers erected the a vast dike system around the lake in order to drain lands for settlement and cultivation. It was the first of many decisions that would forever alter the hydrology and ecology of the Everglades.
But water was still entering the lake from the north, and it had to go somewhere. So the Army Corps dredged two canals—one west, to the Caloosahatchee river, another east to the St. Lucie. Today, these man-made flow paths are Lake Okeechobee’s overflow valves.


“Initially, this wasn’t a problem,” Jud said. “It becomes a problem when you look at how the lake is managed.”
When the Army Corps first girdled the lake, flood prevention was the key motivating factor. (In 1928, thousands of people drowned after a major hurricane caused Lake Okeechobee to overflow.) Flooding remains a major concern today, but for a slightly different reason: large, politically powerful sugar companies, which own most of the land due south of the lake.
Sugar farms depend on Lake Okeechobee’s dike system to keep their fields from becoming swamps. But they also rely on the lake as an irrigation reservoir. “These are two completely conflicting uses, and they helped set up this year’s catastrophic algae bloom,” Jud said.


The trouble started last fall, with the onset of strong El Niño conditions that brought boatloads of rain to central Florida. Instead of keeping Lake Okeechobee low, the state allowed the lake to fill up to ensure there was ample water to irrigate farms throughout what is normally a dry winter. Only this year—thanks once again to El Niño—it turned out to be a very wet winter.
The result is that by early spring, Lake Okeechobee was becoming dangerously full. Fearing a catastrophic dike breach, the Army Corps began discharging billions of gallons of water a day through its canals, turning the St. Lucie estuary into a freshwater ecosystem overnight.


This alone would have harmed the oysters, seagrass, and other saltwater-adapted organisms living there. But it wasn’t exactly spring water entering the ecosystem. The discharges were filled with nitrogen and phosphorus-laden fertilizer, which seeps into Lake Okeechobee from farms to the north. This stuff was algae fuel.
And sure enough, as summer heated up, the slime came. First, algae blooms appeared on Lake Okeechobee itself, but neon green filaments were soon spotted flowing down canals and into the St. Lucie estuary. The algae bloom started making national headlines several weeks back, after Governor Rick Scott declared states of emergency in four afflicted Florida counties, and shortly before NASA released stunning satellite images depicting the scale of the problem. As of last week, the bloom encompassed over 200 square miles on Lake Okeechobee itself.
Coastal residents are fed up, and they have a right to be. Summer algae blooms like this have been a regular sight on the St. Lucie since 2011, and many feel that the state is ignoring a common-sense solution: restoring the natural flow of fresh water from Lake Okeechobee into the Everglades.


“We have too much freshwater flowing to the east and west, and not enough to the south,” Julie Hill-Gabriel, director of Everglades policy for Audubon Florida, told me over breakfast in Coral Gables. “This year was the ultimate depiction of Lake Okeechobee’s problems.”
For years, environmentalists like Hill-Gabriel have been calling for the state to purchase large parcels of land south of Lake Okeechobee that can be converted into “remediation wetlands,” which would clean fertilizer-fouled water before sending it into Everglades National Park. Not only would this take some pressure off the nutrient-loaded St. Lucie and Caloosahatchee, it’d bring additional freshwater to Florida Bay, where hypersaline conditions have resulted in an enormous seagrass die-off.


Two years back, Floridians voted overwhelmingly in support of a constitutional amendment which earmarked hundreds of millions of taxpayer dollars to purchase land for exactly this purpose. Instead, the state used the money to buy anything and everything else in the name of conservation. Environmentalists blame the sugar lobby, which opposed the land purchase and has helped bankroll the careers of prominent Florida politicians, including Governor Scott and Senator Marco Rubio.
Now, the state has an environmental and PR crisis on its hands. Governor Scott, who recently gutted the state’s water policy of pollution regulation, is trying to blame the Obama administration for failing to repair Okeechobee’s aging dike system, and to paint septic tanks, not agriculture, as the cause of the bloom.


Meanwhile, in response to public backlash the Army Corps says it’ll begin restricting the flow of polluted water out of Lake Okeechobee July 15. But as Army Corps spokesperson Jenn Miller told Gizmodo, the situation is week-by-week. “It’s all conditions-dependent,” she said, noting that the lake is currently 14.73 feet high. If heavy rains hit and the water level rises above 16 feet, the channels will have to be reopened to prevent an even bigger disaster.
Miller said that sending more water south is “absolutely” part of the long-term solution.
“My fear is that we have not seen the worst,” Jud said. “With 200 square miles of algae blooming on the lake, and conditions getting more and more favorable for algae growth, and the potential for rainfall to require additional discharges, I think we have the potential for things to get much worse before they get better.”
No, the space-based Solar Dynamics Observatory isn’t on the fritz—it was actually instructed to make this flip while snapping pics of the Sun. It might sound like NASA took this thing out for a joy ride, but there’s a very good reason for the evasive maneuver.
Since 2010, the SDO has been dutifully studying the sun, sending back some of the most stunning pictures we’ve ever seen of this flaming orb. Twice each year, NASA has the SDO perform a complete 360, and it does this to the help the probe’s Helioseismic and Magnetic Imager (HMI) instrument take precise measurements of the outer edge of the sun, known as the “solar limb,” as seen by the SDO.
Taking measurements with the HMI instrument is not without its challenges. The sun, with all its flares and stellar perturbations, is not a totally spherical object. This makes it tough for HMI to detect the sun’s outer perimeter when it’s perfectly still. The probe’s biannual spin allows each part of the camera to peer at the entire outer rim, allowing it to map the sun’s shape with greater accuracy.


The video shown above was taken in extreme ultraviolet wavelengths, a spectrum of light our eyes cannot detect. NASA colorized these wavelengths in gold, allowing us puny humans to view it. As the SDO performed its seven-hour maneuver, it took a photo once every 12 seconds. The resulting video makes it look the sun suddenly decided to perform a rather dramatic summersault.
[NASA]

A conservation biologist has come up with a novel method for protecting cattle from being hunted by African lions: paint eyes on their butts. The lions will think their intended prey has seen them and will move on, since they’ve lost the element of surprise.
This bit of psychological trickery has been dubbed “iCow” by the man who came up with the idea—Neil Jordan of the University of New South Wales in Australia. It’s actually not as nutty as it sounds. The eye-like patterns on butterfly wings are known to ward off preying birds and, according to Jordan, woodcutters in Indian forests actually wear masks on the backs of their heads when working to discourage hungry tigers.


The inspiration for the iCow strategy came while Jordan was based in a village in Botswana, when two lionesses were killed by local farmers in retaliation for preying on their cattle herds. The African lion is a vulnerable species, with numbers dropping from over 100,000 in the 1990s to between 23,000 and 39,000 today, according to the Botswana Predator Conservation Trust (BPCT). Much of that decline is due to these kinds of retaliation killings because farmers have no non-lethal strategies for protecting their herds.
“Lions are ambush hunters, so they creep up on their prey, get close, and jump on them unseen,” he said in a statement. When Jordan was watching a lion stalk an impala one day, he noticed the lion gave up the hunt once the impala spotted it.


So he joined forces with the BPCT and one of the local farmers on a 10-week trial study, stamping eyes on one-third of a herd of 62 cattle. When the cattle returned each night, they took a head count to see how many had survived. Only three cows were killed by lions during this period—all without the painted eyes on their rumps. And all the painted cows survived.
It was such a promising early result that Jordan is now back in Botswana for a more ambitious study, augmented with GPS devices to better monitor the movement of predators and prey. “This will give us information about the exposure of painted and unpainted cows to predation risks, and where the conflict hot spots are,” he said.

[Oddity Central]
NASA is racing to finish a new Mars rover, and the mission just got a launch and land date. The new rover will leave Earth by August 2020, and in February of 2021, it will hit the surface of the Red Planet to search for signs of life.
If the unnamed rover—which NASA is temporarily calling Mars 2020—looks familiar, there’s a good reason. It’s modeled on the very successful Curiosity rover, which landed in 2012 and, despite some glitches, has remained in good working order for years longer than expected. Although Mars 2020 looks a lot like Curiosity, there’s plenty under the hood that distinguishes it.


Mars 2020 will have better cameras and microphones as well as thicker wheels to keep it from breaking down like Curiosity’s did. There’s also a new coring drill and a ground-penetrating radar to look below the surface of Mars. Since Mars 2020's primary objective is to look for signs of life, it will also have features to analyze organic chemicals, including a device that will test the ability to form oxygen on the planet for future colonization efforts. Some rumored features that the researchers considered, however, were ultimately rejected.
“We had been asked to study the possibility of bringing a helicopter with us,” Kenneth Farley, the project scientist for Mars 2020, said. “But Mars 2020 is certainly not going to be flying a drone.”
Although the design for the 1,050 kilogram rover is finalized, there’s still plenty to do before its ready for launch in four years. Not only do they have to finish construction, NASA also has to select a landing site that will put the rover within range of the most likely hotbeds of previous Martian life.


“There’s a very short [launch] window in 2020,” Farley noted. “If we don’t hit it, we have to wait two years. So we’re working very hard to hit it.”
When the rover finally does hit Mars, the landing is going to be a nail-biter. The rover will enter the planet’s atmosphere at 11,000 mph and will use a combination of a supersonic parachute and above-ground rocket thrusters to brake during its descent. If all goes well, one of the first things the rover will beam back to us is footage of its (hopefully very soft) crash. And then Mars 2020's real work can begin.
I’ll take an unagi roll, some tuna nigiri, and a side of lies, please.
The dab of spicy green paste that accompanies your sushi may go by the name wasabi, but it’s actually something else entirely. What we call wasabi is almost always just a mix of horseradish, mustard, and a bit of green dye.


Because of similarities in their chemical compounds, which you can see detailed below in a new video from the American Chemical Society’s Reactions series, horseradish makes a less-spicy (but passable) substitute for wasabi. Why aren’t sushi restaurants just serving the real thing?
Wasabi has a reputation as one of the hardest crops to successfully farm. It doesn’t like direct sunlight, but doesn’t want complete shade either. It does well only in mild climates that aren’t ever very hot or cold. And, even when you do manage to get wasabi to grow, it tends to do best in small plots, not large farms.


Given how hard it is to grow, and how often it fails, it’s no big surprise that real wasabi is extremely expensive, costing about $160 per kilogram. Restaurant guests aren’t used to paying for the condiment at all, much less paying more for it than for the sushi itself. So instead of real wasabi, a much cheaper substitute is served—one that people won’t be able to distinguish from the real thing because they’ve never had the real thing.


But how can you tell if your wasabi is real? If you’re eating real wasabi, you almost certainly grated it yourself or had it grated in front of you. If it came out in a paste on the plate, then you probably had some lightly-dyed (but still tasty) horseradish.

Models produced by researchers at Imperial College London indicate that the ongoing Zika epidemic in parts of Latin American will likely burn itself out within three years. Finally, we have some good news to share about this dreadful disease.
A new report published in Science concludes that the Zika epidemic will largely come to an end in about two to three years, and that the next large-scale epidemic is unlikely to emerge for at least another ten years. Unfortunately, the Zika virus is not going to disappear completely, so we still face the distinct possibility that smaller outbreaks may emerge over the course of this time. The study also concludes that the epidemic cannot be contained with existing control measures.
For the study, a team led by epidemiologist Neil Ferguson collated all existing data pertaining to Zika transmission across Latin America, along with data about the spread of similar viruses, such as dengue. The researchers used this information to build a mathematical model representing the current epidemic, and to predict future waves of transmission.


“The current explosive epidemic will burn itself out due to a phenomenon called herd immunity,” explained Ferguson in a release. “Because the virus is unable to infect the same person twice—thanks to the immune system generating antibodies to kill it—the epidemic reaches a stage where there are too few people left to infect for transmission to be sustained.”
According to the models, another large-scale epidemic won’t start for at least another ten years—a time when a new generation who hasn’t been exposed to the virus will emerge in the population. This is similar to the way other epidemics work, such as chikungunya (another mosquito-borne disease that’s similar to Zika and dengue), in which explosive epidemics are followed by long periods with few new cases.
Ferguson’s team also cautioned against any large-scale government programs to target mosquitoes, saying the effort will have very little impact at this point.


“[Previous] experience with dengue has shown controlling spread to be incredibly difficult,” said Ferguson. “Also, efforts to contain the epidemic would have needed to have been implemented much earlier in the current Zika epidemic to have a major effect—but by the time we realised the scale of the problem it was too late.”
The latest figures: Between January 1 and August 29 of this year, nearly 600 confirmed measles…
As this research shows, herd immunity is a very powerful natural process that enables a population to hold back and prevent the ongoing spread of dangerous viruses. Herd immunity can also be commuted to the population through vaccinations which is why it’s so important to get immunized. Sadly, the grossly irresponsible and irrational anti-vaxxer movement is weakening herd immunity, making young children and those who cannot get vaccinated for valid health reasons more susceptible to diseases such as measles and whooping cough.


[Science]
Hordes of gypsy moth caterpillars are currently ravaging parts of the Northeastern United States. Newly released images from space show the alarming damage being done to New England forests by these leaf-munching insects.
Incredible as it may seem, insects and disease damage 45 times more forest area annually than wildfires. A single caterpillar or bug can’t do much damage, but it’s a different story when they number in the millions. Collectively, they’re a true force of nature.
Parts of New England and the mid-Atlantic states are witnessing a population explosion in European gypsy moth caterpillars, an insect that was introduced to the region in the 1860s. Soon after hatching in early summer, these bugs start feasting on the leaves of deciduous trees. Newly released satellite images show the extent of this defoliation in parts of Rhode Island. In the image below, healthy forests appear green, while the leaf-stripped areas feature a gray-brown tint.
The image below shows a closer view of forests near Barden and Scituate Reservoirs in western Rhode Island on June 30, 2016. The remaining green patches belong to coniferous trees trees, which the caterpillars avoid.
Ecologists partly attribute the infestation to a decline in population of white-footed mice (a key predator of gypsy moths), which has shrunk in recent years owing to poor acorn production by oak trees. But the true culprit driving the caterpillar boom are the drought conditions currently ravaging the region. Dry weather tends to holds back pathogens that normally keep the caterpillars in check.


It looks awful, but the effects of this infestation aren’t terrible—at least not yet. Trees can survive one or two years of defoliation by caterpillars. But should this continue for the next three or more years, that would be a different story.
[NASA Earth Observatory]
The astronomical map you see here doesn’t depict stars, it shows galaxies—1.2 million of them, to be exact, a new record for astronomers. This extraordinary new 3D scan of the universe provides yet more evidence that a mysterious substance known as dark energy is likely causing the universe to expand at an accelerating rate.
The map encompasses 650 cubic billion light-years of space—about a quarter of the sky—and required the work of hundreds of scientists from the Baryon Oscillation Spectroscopic Survey (BOSS). BOSS is a program within the Sloan Digital Sky Survey III (SDSS-III) that measures the sound waves of the early universe, which left faint imprints on the cosmic background radiation—the “afterglow,” as it were, of the Big Bang. They also left their imprints on the distribution of galaxies, which is what BOSS is using to map the positions and distances of galaxies back through time.


And the new map is not just a pretty cosmic picture. It provides one of the most precise measurements of the expansion of the universe to date, and confirms a leading explanation for the dark energy physicists believe is driving that expansion.
When Albert Einstein first proposed his general theory of relativity in 1916, he didn’t know the universe was expanding. Like everyone else at the time, he thought the size of the cosmos was fixed, and the only way he could get the equations to work for a static universe was by introducing a mathematical fudge factor he dubbed the “cosmological constant,” symbolized by the Greek letter lambda. Without it, the universe would have either contracted or expanded.


Einstein had to revise this idea when American astronomer Edwin Hubble discovered in 1929 that the universe really was expanding. Einstein called it the biggest blunder of his career. Then, in 1998, two teams of physicists studying supernovae found that not only are distant galaxies receding from us, they are doing so at a faster and faster rate.


To account for this, physicists proposed that the cosmos is filled with dark energy, although they aren’t sure precisely what this is. One of the most promising explanations is that Einstein was on the right track when he proposed a cosmological constant—except now, instead of keeping the universe static, it serves as a kind of counter force against gravity, driving the universe to expand at an ever-accelerating rate.
The data collected in the BOSS survey—which had to factor in the rates at which galaxies are moving—strongly affirms this model.
In the image above, each dot represents the position of a galaxy as much as six billion years into the past, within just a twentieth of the sky we see above us, encompassing a segment of the universe six billion light years wide, 4.5 billion light years high, and 500 million light years thick. The map contains 48,741 galaxies, which is about three percent of the total BOSS survey set. (There are an estimated 100 billion galaxies in the entire universe.)


The colors indicate relative distance from Earth, where yellow objects are the closest, and purple objects the furthest. Grey patches are small regions where no data exists. Galaxies appear to be highly clustered, revealing superclusters and voids.
Let’s put this image into perspective. For the sake of argument, let’s say that each galaxy contains an average of 100 billion stars. At about 48,741 galaxies, that represents approximately 4,874,100,000,000,000 (4.8741 × 1015) stars, or 4.8 quadrillion stars. And that’s just this portion of the map, which represents 1/20th of the total survey. Taking the entire map into account, that’s nearly 100 quadrillion stars— a one followed by 18 zeros.
The image above shows a segment of the universe in three dimensions. The rectangle on the left shows a cut-out of 1,000 square degrees in the sky containing nearly 120,000 galaxies, or roughly 10 percent of the total survey. Brighter regions correspond to more galaxies. “We see a dramatic connection between the sound wave imprints seen in the cosmic microwave background 400,000 years after the Big Bang to the clustering of galaxies 7 to 12 billion years later,” BOSS co-leader Rita Tojeiro, of the University of St. Andrews, said in a statement.


The BOSS data shows that dark energy—which drives cosmological expansion—is consistent with the cosmological constant with an error of only five percent. This map is also fully consistent with the standard cosmological model (in which the universe contains a cosmological constant), adding further weight to this prevailing scientific theory. Moving forward, cosmologists can use this information to better understand the precise mechanics behind dark energy.


[arXiv]

The ISS is getting an incredible new tool: a handheld DNA sequencer. The questions scientists hope it will answer include whether life exists beyond our planet and just what is that weird fungus growing on the wall of the space station?
The biomolecule sequencer, called a minION, will be part of the cargo that SpaceX will launch to the ISS on Monday. Once it arrives, the newly arrived ISS astronaut Kate Rubins will use it to attempt the first in-space DNA sequencing. We talked with the NASA scientists—Camille Alleyne, Aaron Burton, and Sarah Wallace—behind the project to find out what else it could do, both right away and in the future.
As a self-contained unit with a rotating crew of astronauts, a constantly changing cargo hold, and all the microbes that have ever accompanied them, the ISS is a microbial stew. One task the researchers hope he sequencer can accomplish is investigating exactly what’s floating around the station. Right now, if there are questions, the only way to answer them is with an old-fashioned culture test in a petri dish. But the sequencer could answer questions, especially about the air and water, almost immediately.


“All the [ISS’s] water is recycled and that’s from urine, condensate, sweat, everything,” Sarah Wallace, a microbiologist and the manager of the sequencing project told Gizmodo. “Is it being processed to where it’s microbially clean? We want to know in a more real-time way is that water processor working.”
Simply being able to monitor the air and water quality in the moment would be a big step. But there are also some unexpected questions that arise on the ISS that the sequencer can answer. For instance, the matter of a weird fungus that astronauts keep scrubbing off the wall—but no one has quite identified yet.
“In the past, we’ve had visible fungi growing on the ISS, and we want to know what that fungi is,” said Wallace. “Is it benign or something to be concerned about? Knowing what it is, the microbiologists can recommend what to do to deal with the issue.”
The sequencer could also answer questions about the long-term impact of living in space on the human body, or even someday be used to diagnose astronaut illnesses, as they move towards longer stays.


But the real applications of the sequencer might only be seen once its off the ISS and going out further into space. The researchers hope to someday use it to identify life—in practically real-time—on other planets, including Mars.
“For all the reasons the sequencer is good for microbiology applications—it’s small, it’s lightweight, pretty robust—it’s a good piece of equipment to send to other locations in the solar system,” Aaron Burton astrobiologist and the lead of the sequencing project, told Gizmodo. “So if you wanted to go to Mars and see if there was life, if you had a small sequencer device, you could take it with you, and you could actually start looking for life.”
Of course, that life could take multiple forms. It would be very useful to see what kind of life we’re dragging along with us when we visit, whether ourselves or via our robot rovers. But another extremely exciting possibility would be finding life that’s native to other planets. The researchers are already looking at how the sequencer could be modified to deal with truly alien life—for instance, life that didn’t even have DNA.
“It doesn’t have to be DNA that you’re sequencing, it could be closely related molecules,” Burton noted. “RNA is one we have on earth, but you could also envision having different sugars with different nucleobases. You could look for a whole range of information from molecules and people are starting to look at protein sequencing with it, too.”
While some of these applications are in the distant future and far from our home planet, the basic research the astronauts hope to do could also easily come closer to home. The ISS (a remote, minimalist environment, by necessity) also functions as a good template for how to conduct operations on remote areas of Earth. But having a working sequencer in space also opens up new laboratory possibilities that could fundamentally add to the way that we understand genes and their workings—and that’s knowledge we can apply here at home.


“There’s also an Earth benefit,” Camille Alleyne, associate program scientist for the ISS said. “Understanding, for instance, how gene expression happens in salmonella bacteria could lead to vaccine development. So there’s the space application, but there’s also the benefit to our lives here, too.”
For now, though, the sequencer’s first project is simply to see if it can perform as well up in space as it does here on earth. Once they’ve got a benchmark, then the real work can begin.

Two years ago, Iceland’s Bardarbunga volcano erupted—and it kept erupting for the next 181 days, forming the largest volcanic depression ever seen. New research reveals the extraordinary processes that transpired beneath the surface, including the formation of a magma-filled canal that measured a whopping 28 miles long.
The Bardarbunga volcano began to erupt on August 29, 2014, ending finally on February 27, 2015. It was the strongest in Europe in more than 240 years, emitting large volumes of sulphur dioxide into the atmosphere and causing poor air quality in Iceland.
It also produced the largest caldera ever observed—a rare and mysterious cauldron-like depression that forms atop volcanoes. Calderas are relatively rare geologic phenomena, occurring only a handful of times each century. Observations are thus exceptionally rare, and scientists are still trying to figure out what causes them and how they work. For example, geologists aren’t entirely sure if calderas are triggered by volcanic eruptions, or vice versa.
The Bardarbunga eruption provided a once-in-a-lifetime opportunity for scientists to observe the formation of a caldera while it was happening. In a new study published in Science, lead researcher Magnus T. Gudmundsson from the University of Iceland, with the help of geologists from the GFZ German Research Centre for Geosciences, describe the Bardarbunga eruption in unprecedented detail.


Their analysis revealed surprising insights into calderas and how they emerge. The caldera and subsequent caving-in of the land—a process known as subsidence—began when magma seeped up from a depth of 7 miles (12 km) below the surface. This magma didn’t just shoot straight up—it flowed perpendicular to the surface along an underground canal for a distance of 28 miles (45 km), before erupting as a major lava flow northeast of the actual volcano at a site called Holuhraun.
During the course of the eruption, the region experienced no less than 77 earthquakes. Data shows that this flow of magma along the subterranean dike preceded the formation of the caldera, which means it drove the formation of the caldera.


Over the course of six months, the ice-filled land mass above it sunk down even further, creating a massive bowl-like depression that is characteristic of calderas. During the initial stage, the ground decreased in elevation at a rate of about 3 feet (1 meter) a day. By the end, the caldera measured 5 by 4 miles wide (8 by 7 kilometers), and up to 210 feet (65 meters) deep.
“With an area of 110 square kilometers, this is the largest caldera collapse ever monitored,” said geologist Eoghan Holohan, who works at the GFZ. “The results provide the clearest picture yet of the onset and evolution of this enigmatic geological process.” His team’s work showed that steeply-dipping ring faults controlled the collapse of the surface from intense depths.


Tremors and seismic shocks at the eruption site sent the magma rushing back and forth along the dike, which functioned much like a two-way water hose.
The chamber is located beneath Europe’s largest glacier, Vatnajokull, which was (and still is) filled with ice. But the eruption didn’t happen directly beneath the ice. “In that case, we’d have had a water vapour explosion with a volcanic ash cloud even bigger and longer lasting than the one that followed the eruption of Eyjafjallajokull in 2010,” said Thomas Walter from the GFZ.
For comparison, the Bardarbunga eruption spewed out two cubic kilometers of volcanic material over the course of several months, nearly ten times more than the Eyjafjallajokull.
Lurking beneath Yellowstone National Park is a massive underground reservoir of magma, capped by…
Insights gleaned over the course of this research project will undoubtedly help scientists understand other calderas, including the ominous kettle located at Yellowstone in the United States, or those in the Andes region. Back in 1815, the Eruption of the Tambora volcano in Indonesia led to a caldera and a devastating tsunami. Volcanic aerosols and ash in the stratosphere brought on the infamous “year without summer” in 1816.


[Science]

An underwater survey off the coast of Greece has uncovered a massive cache of wrecked ships, sunk over a span of more than 2,000 years. And researchers just keep finding more and more to add to that tally.
In the nine months they’ve been swimming around Greece’s Fourni archipelago, the research team from The Fourni Underwater Survey has already found 45 individual shipwrecks in the 17-mile stretch. A whopping 23 of those shipwrecks were detailed in a new announcement from the team issued today. Strangest of all, there doesn’t seem to be any pattern to the age of the shipwrecks. The oldest dates back to around 500 BC, while the youngest is from around 1800.


To put the scale of the find in perspective, Peter Campbell of the University of Southampton and lead archaeologist on the project, points out that similar coastlines in the area only have a couple shipwrecks—and other similarly-sized finds have been spread across areas about 20 times as big.
“For comparison, many larger islands around the Mediterranean have only three or four known shipwrecks. The United States recently created a national marine sanctuary in Lake Michigan to protect 39 known shipwrecks located in 875 square miles,” Campbell noted in a statement. “Fourni has 45 known shipwrecks around its 17 square mile territory.”


And the team isn’t done adding to the total yet. There are two more years left in the investigation—and still several areas that divers haven’t even begun to explore. So researchers expect to find even more shipwrecks, from across different eras, as they investigate through 2018.


The message is clear: Stay away from the Fourni islands, sailor. Here be monsters.
All images by Vasilis Mentogianis / Fourni Underwater Survey
The Centers for Disease Control and Prevention is collecting semen from hundreds of Zika-infected men to figure out how long the sexually transmitted virus lingers in the body.
Zika is primarily transmitted by infected mosquitoes, but it can also spread through sexual contact. Virus particles remain in the body even after symptoms have disappeared, but scientists aren’t entirely sure how long it takes the body to completely flush out this disease, which is known to cause serious birth defects.


For the past two months, the CDC has been asking men who have been infected with Zika to provide semen samples. In return for their contribution, the CDC is awarding them a $50 multi-use gift card. To date, some 40 men have volunteered their precious bodily fluids, but the CDC would like to collect about 210 more.
To make it convenient, a courier will pick up the donations and deliver them directly to the CDC’s lab in Fort Collins, Colorado. “I’m happy to say patients really have been quite receptive about volunteering their specimens,” noted Dr. Paul Mead, an epidemiologist in charge of the study, in a CNN post. “They seem to understand the importance of the study.”


Collecting semen samples from men in the United States shouldn’t be too difficult. The number of Zika cases has nearly quadrupled in New York City alone since May. In all, there have been more than a thousand cases of Zika in the US, and that number is expected to grow. The CDC reports that the disease has been sexually transmitted at least 14 times in the United States.

Until more is learned, sexually active people who have visited areas in which Zika is active, or who have good reason to believe they’ve been exposed to the virus, are being told to adopt safe sex practices, like wearing a condom. Men who are seeking to get their partners pregnant should wait at least six months after their symptoms first appeared, and women who have been infected should hold off for two months.


[CNN]
The endangered black-footed ferret is dying out due to a plague, and the government has a solution: Call in a “glorified gumball machine” attached to a drone to dispense M&Ms smeared in vaccine-covered peanut butter.
U.S. Fish and Wildlife Service will release vaccine-laced M&Ms in northeastern Montana out of drones that can shoot simultaneously in three directions and hopefully cover enough land to make a difference. The drone will use GPS to drone vaccines are 30-feet intervals. Considering that drones are now being used to attempt hacking Pokemon Go, why not use them to help real animals?


“It is the fastest, cheapest way to distribute the vaccine,” FWS biologist Randy Machett said. “We are hopeful this oral vaccine will be used to mitigate plague sites and treat tens of thousands of acres each year.”
The M&Ms are not for the ferrets themselves, but for the prairie dogs in the area, which are a main source of food for the ferrets. The spread of sylvatic plague means the prairie dog population has been low, which has affected other species including North America’s only native ferret, which only recovered from near-extinction with the help of artificial insemination. Even now, only about 300 are left.


Lab tests have shown that prairie dogs like the M&Ms, and the dye shows up on their whiskers, which makes the vaccinated animals easier to track.


The plan should be in place by September following final FWS approval. Maybe this idea could have application for human children too?
[The Guardian]
Paleontologists working in Argentina uncovered the remains of a Cretaceous-era dinosaur that featured the same kind of miniaturized arms found on the T. rex. These ancient creatures weren’t closely related, so scientists now suspect that tiny arms evolved independently.
Introducing Gualicho shinyae, a 1,000-pound, bipedal theropod that featured a pair of short arms with two fingered claws on each. This fearsome, polar bear-sized creature is similar to the T. rex in this regard, but it sits on a separate branch of the family tree, which means this creature’s unusual limbs evolved independently (i.e. parallel evolution), and was not a trait that was handed down from a common ancestor. Small arms, it appears, was a thing among certain bipedal carnivores during the Late Cretaceous, and for reasons that aren’t entirely clear.
Gualicho is classified as an allosauridae, which describes medium-to-large carnivorous theropods, and it was distinct from other dinosaurs that lived near it.


“Gualicho is kind of a mosaic dinosaur, it has features that you normally see in different kinds of theropods,” noted study co-author Peter Makovicky, who works out of the Field Museum in Chicago. “It’s really unusual—it’s different from the other carnivorous dinosaurs found in the same rock formation, and it doesn’t fit neatly into any category.”
Like the T. rex, this dino featured forelimbs the size of a human child’s. The discovery of Gualicho doesn’t explain why certain carnivores featured such tiny arms, but it does strengthen the hypothesis that the trait evolved independently numerous times.
As for this newfound dinosaur’s distinctive name, shinyae comes from its discoverer, Akiko Shinya, while Gualicho is derived from “Gualichu,” a spirit revered by Patagonia’s Tehuelche people.


[PLOS ONE]
Some combinations of notes inherently sound better than others, right? It’s why the bread and butter of pop music, which is engineered to be upbeat and danceable, is highly consonant major chords. It’s why unpredictable 12-tone compositions create unease in the listener, and why Stravinsky’s dissonant Rite of Spring sparked a riot when it debuted.
A new study from MIT and Brandeis University shows that’s not at all true. Our preference towards—or distaste for, as the case may be—certain musical intervals stems from being steeped from an early age in the rules of Western music.


To get to the bottom of the issue, the only option was to go to one of the few places in the world where humans have almost no exposure to Western compositions: the Amazon Rainforest. MIT assistant professor Josh McDermott and Brandies professor Ricardo Godoy performed a variety of experiments on members of the Tsimane tribe to see if they had any sort of preference for consonant chords over dissonant ones. They performed the same tests on people nearby who were not part of the Tsimane, residents in La Paz, and American musicians and non-musicians.
Preference towards more consonant intervals varied widely between the five groups. “In the Tsimane it’s undetectable, and in the two groups in Bolivia, there’s a statistically significant but small preference,” McDermott told MIT News. “In the American groups it’s quite a bit larger, and it’s bigger in the musicians than in the nonmusicians.” It’s not as though the Tsimane are unfamiliar with musical concepts: they were able to distinguish between consonant and dissonant chords. Tut the music they make generally involves only one instrument or voice playing at a time, and presumably had no preconceptions as to which type of interval sounded “better.”


So there you go: everything you think and feel about the construction of music is cultural dogma. And not surprisingly you’ll find yourself more attuned to it if you’re a working musician or had music lessons at some point in your life. So far there haven’t been any studies I could find about unlearning Western musical bias.


[Nature via MIT News]
A telescope just snagged the very first image of a water snow line drifting around a young star in space—and it could transform what we know about how planets form.
The extreme conditions around young stars sometimes means that water goes directly from gas into snow and ice, skipping the liquid phase entirely. The region right where that transition happens is called the water snow line. This water snow line was only visible because the star in question, V883 Orionis, had a massive flare that pushed the water snow line around its protoplanetary disk, where planets are formed, outwards. This made it visible to Atacama Large Millimeter/submillimeter Array (ALMA) which took this view:

It’s not just a cool thing to see, though. It also has some implications for how planets form. Researchers at ESO say they suspect that the location of a forming-planet within the water snow line shows up in the planet’s eventual form. If a forming planet is on the inside of the water snow line, where water shows up as gas, the resulting planet is rocky like Earth. Planets forming on the outside of the water snow line, where the water shows up as ice, eventually form into gas giants like Jupiter.


Now that they’ve gotten a good look at a water snow line in action, they hope to be able to explain even more about the role it plays in planetary evolution.
Just days after shutting down tests of a groundbreaking new cancer therapy in the wake of three patient deaths, the US Food and Drug Administration has said the trials can resume. So what changed?
Late last week, it was reported that three leukemia patients had died in a Juno Therapeutics Phase II clinical trial that’s assessing a revolutionary new therapy, called JCAR015, that uses genetically engineered immune cells to treat cancer. In response, the US Food and Drug Administration ordered a temporary halt to the trial—temporary being the key word. Just days later, it’s letting the cancer trial resume.
Clinical trials of a promising new therapy, in which white blood cells are reprogrammed to attack…
Juno Therapeutics attributed the deaths to an unexpected interaction between the engineered blood cells, known as CAR-Ts, and a chemotherapy drug known as fludarabine. The combination of the two caused excessive fluids to accumulate in the patients’ brains, resulting in death. Last week, executives with Juno said they wanted to resume the trials without the benefit of this particular chemotherapy drug, and it appears the FDA agrees.


That’s a surprise given that the FDA is particularly risk-averse when it comes to these things. There’s also no conclusive evidence that the chemotherapy caused the bad reaction. The regulatory agency—for whatever reason—must be satisfied with what Juno is telling them. The FDA is also probably looking at similar oncological treatments, none of which have reported any fatal brain swelling.
News of the FDA’s decision to remove the clinical hold resulted in an investment surge, sending Juno’s shares up about 28 percent in extended trading. The company’s shares dropped 31 percent last week, so that’s a nice recovery. Hopefully some more optimistic and less reactive folks will now make a bit of money in the long term, snatching the stocks while the prices were down. This experimental therapy, which has shown incredible promise, could revolutionize the way certain cancers are treated. It’s a shame that progress often has to come to the whim of nervous investors.
[Reuters, STAT]
The future looks bright, except when it doesn’t. Here are 10 exceptionally regrettable developments we can expect in the coming decades.
Listed in no particular order.
Earlier this year, Oxford’s Global Priorities Project compiled a list of catastrophes that could kill off 10 percent or more of the human population. High on the list was a deliberately engineered pandemic, and the authors warned that it could happen in as few as five years.
Many of the technologies for this prospect are starting to appear, including the CRISPR/cas9 gene-editing system and 3D-bioprinters. What’s more, the blueprints for this kind of destruction are being made available. A decade ago, futurist Ray Kurzweil and technologist Bill Joy scolded the US Department of Health for publishing the full genome of the 1918 influenza virus, calling it “extremely foolish.” More recently, a number of scientists spoke out when Nature decided to publish a so-called “gain of function” study explaining how the bird flu could be mutated into something even deadlier.


The fear is that a rogue state, terrorist group, or a malign individual might create their own virus and unleash it. Natural selection is good at creating nasty and highly prolific viruses, but imagine what intentional design could concoct.
One of the more radical visions of the future is a world in which biological humans have traded-in their corporeal bodies in favor of a purely digital existence. This would require a person to literally upload their mind to a supercomputer, but this hypothetical process might actually result in the permanent destruction of the original person. It would be a form of unintentional suicide.
This is what’s known as the “continuity of consciousness” problem. Sure, we may eventually be able to cut, copy, and paste the essence of a person’s personality and memories to a digital substrate, but transferring the seat of consciousness itself may be an untenable proposition. Neuroscientists know that memories are parked in the brain as physical constructs; there’s something physically there to copy. But consciousness still eludes our understanding, and we’re not certain how it arises in the brain, let alone how we can transfer it from point A to point B. It’s also quite possible that subjective awareness cannot be replicated in the digital realm, and that it’s dependent on the presence and orientation of specific physical structures.
Many futurists predict that one day we'll upload our minds into computers, where we'll…
Mind uploading will likely require destructive atomic-scale scanning of the brain. It would be similar to the way teleportation is done in Star Trek. Indeed, one of the dirty little secrets of this sci-fi show is that the person being teleported is actually killed each time it happens, replaced by an exact duplicate who’s none the wiser. Mind transfers could be similar, where the original brain is destroyed, replaced by a digital being who’s convinced they’re still the original—but it would be a delusion.
As threats to national security increase, and as these threats expand in severity, governments will find it necessary to enact draconian measures. Over time, many of the freedoms and civil liberties we currently take for granted, such as the freedom of assembly, the right to privacy (more on this next—it’s worse than you think), or the right to travel both within and beyond the borders of our home country, could be drastically diminished.
At the same time, a fearful population will be more tempted and willing to elect a hardline government that promises to throw the hammer down on perceived threats—even overtly undemocratic regimes.


The threats to national security will have to be severe to instigate these changes, but history has precedents. Following the September 11 attacks and the subsequent mailings of anthrax spores, the US government enacted the Homeland Security Act. This legislation was criticized for being too severe and reactionary, but it’s a perfect example of what happens when a nation feels under threat. Now imagine what would happen if another 9/11-type event happened, but one involving hundreds of thousands of deaths, or even millions.
Such an act of terrorism could be unleashed through miniaturized nuclear weapons, or the deliberate release of bioweapons. And the fact that small groups, and even single individuals, will have the power to attain and use these weapons will only make governments and citizens more willing to accept the loss of freedoms.
We are rapidly approaching the era of ubiquitous surveillance, a time when virtually every aspect of our lives will be monitored. Privacy as we know it will cease to exist, supplanted by Big Brother’s eyes and ears.
Governments, ever fearful of internal and external threats, will increasingly turn to low-cost, high-tech surveillance technologies. Corporations, eager to track the tendencies and behaviors of its users, will find it impossible to resist. Citizens of the surveillance society will have no choice but to accept that every last detail of their lives will be recorded.


Already today, surveillance cameras litter our environment, while our computers, smartphones, and tablet devices follow our daily affairs, whether it be our purchasing proclivities or the types of porn we watch.
Looking ahead, government agencies and police could deploy more sophisticated tracking devices, including the much-anticipated smart dust—tiny sensors that would monitor practically anything, from light and temperature to chemicals and vibrations. These particles could be sprinkled around Earth, functioning as the eyes and ears of the planet. In conjunction with powerful data mining algorithms, virtually everything we do would be monitored. To ensure accountability, we could watch the watchers—but will they allow it?
Long before artificial intelligences become truly conscious or self-aware, they’ll be programmed by humans and corporations to seem that way. We’ll be tricked into thinking they have minds of their own, leaving us vulnerable to all manner of manipulation and persuasion. Such is the near future envisaged by futurist and sci-fi novelist David Brin. He refers to these insidious machine minds as HIERS, or Human-Interaction Empathetic Robots.
“Human empathy is both one of our paramount gifts and among our biggest weaknesses,” Brin told Gizmodo. “For at least a million years, we’ve developed skills at lie-detection...[but] no liars ever had the training that these new HIERS will get, learning via feedback from hundreds, then thousands, then millions of human exchanges around the world, adjusting their simulated voices and facial expressions and specific wordings, till the only folks able to resist will be sociopaths—and they have plenty of chinks in their armor, as well.”
We puny humans can be depressingly fragile and flawed, a realization that's all the more…
Brin figures that some experts will be able to tell when they’re being manipulated by one of these bots, but “that will matter about as much as it does today, as millions of voters cast their ballots based on emotional cues, defying their own clear self-interest or reason.” Eventually, robots may guide and protect their gullible human partners, advising them when “to ignore the guilt-tripping scowl, the pitiable smile, the endearingly winsome gaze, the sob story or eager sales pitch—and, inevitably, the claims of sapient pain at being persecuted or oppressed for being a robot.”
Late last year, world leaders forged an agreement to limit human-caused global warming to two degrees Celsius. It’s a laudable goal, but we may have already passed a critical tipping point. The effects of climate change are going to be felt for hundreds, and possibly thousands, of years to come. And as we enter into the planet’s Sixth Mass Extinction, we run the risk of damaging critical ecosystems and radically diminishing the diversity of life on Earth.
Climate models show that even if carbon dioxide levels came to a sudden halt, the levels of this greenhouse gas in Earth’s atmosphere will continue to warm our planet for hundreds of years. Our oceans will slowly release the CO2 it has been steadily absorbing, and our atmosphere may not return to pre-industrial levels for many centuries. As a recent assessment from the Intergovernmental Panel on Climate Change stated, “A large fraction of climate change is largely irreversible on human time scales.”


In The Bulletin, science writer Dawn Stover lists the ramifications:
The melting of snow and ice will expose darker patches of water and land that absorb more of the sun’s radiation, accelerating global warming and the retreat of ice sheets and glaciers. Scientists agree that the Western Antarctic Ice Sheet has already gone into an unstoppable decline. Currents that transport heat within the oceans will be disrupted. Ocean acidification will continue to rise, with unknown effects on marine life. Thawing permafrost and sea beds will release methane, a greenhouse gas. Droughts predicted to be the worst in 1,000 years will trigger vegetation changes and wildfires, releasing carbon. Species unable to adapt quickly to a changing climate will go extinct. Coastal communities will be submerged, creating a humanitarian crisis.
Our only recourse, it would seem, is to start geoengineering the planet, but that will also introduce complications.
An increasing number of diseases are becoming resistant to antibiotics. Eventually, we could make the unhappy transition to a “post-antibiotic era,” a time when even the most routine infections could threaten our lives.
The era of antimicrobial resistant bacteria will change medicine as we know it. Transplant surgery will become difficult, if not impossible. Simple operations, such as a burst appendix, will be perilous once again. Pneumonia would ravage the elderly, as would many other diseases of old age, including cancer.


How bad could it get? A recent report by the Institute and Faculty of Actuaries in Britain predicted that the new era of antimicrobial resistance will kill upwards of 10 million people each year by 2050. No wonder they’re calling it the “antibiotic apocalypse.”
A team of scientists has discovered a gene that renders bacteria resistant to colistin, a so-called …
Thankfully, we’re not completely out of options. Scientists are currently on the hunt for undiscovered antibacterial compounds. They’re also working to develop bacteria-fighting viruses and vaccines. Failing that, we could alway design artificial microorganisms that can hunt down and destroy problematic bacteria.
It’s The Terminator scenario come to life—the unleashing of fully automated weapons systems that dispassionately hunt down and kill human combatants.
These systems, known as LAWS (Lethal Autonomous Weapons), are under development, and it’ll only be a matter of time before they’re tacked onto pre-existing weapons, including powerful munitions and nuclear warheads. These robotic weapons are supposed to reduce human casualties and make war more humane, but experts fear these futuristic killing machines could be prone to accidents and even escape human control.
Devices like laser-guided bombs and nonlethal weapons have the potential to reduce civilian…
LAWS will be imbued with safety mechanisms and “moral” programming, but as Wendell Wallach from Yale University’s Interdisciplinary Center for Bioethics told to Gizmodo, they’ll be difficult to test, will still have software bugs, and will act unpredictably at times, even displaying unanticipated behavior.


“The speed-up of warfare and cost factors will make LAWS essential for advanced nations and attractive to non-state actors,” Wallach said. “While countries like the US promise that there will be meaningful human control and strong communication links to LAWS, they are particularly interested in LAWS for undersea weapons because they are difficult to communicate with.” As an example, Wallach worries about an unmanned submarine that mistakenly launches powerful munitions or even a nuclear warhead.
“We could have a nuclear conflagration before anyone even recognized what happened,” he said. “This is only one of hundreds of scenarios where semi-intelligent weaponry poses existential risks for humanity, long before the better recognized superintelligence might ever be realized. The long-term consequences of failing to ban LAWS far-outweigh any short-term benefits.”
Few people today are aware of the risks posed by the partial or total loss of our satellite fleet, a catastrophe that could be instigated by a Kessler Syndrome (as portrayed in the film Gravity), a massive geomagnetic solar storm, or through a space war.
Without satellites, our ability to communicate would diminish dramatically. GPS would be completely wiped out, along with those systems dependent upon it. Space-based synchronization would grind to a halt, affecting everything from the financial sector to the electrical grid.
Since their inception 60 years ago, satellites have gone on to become an indispensable component of …
We need to take this risk more seriously and act accordingly. For starters, we should improve the robustness and resilience of our infrastructure; our dependence on satellites has put us in a precarious position. We also need to develop an appreciation of the orbital ecology. As time passes, both Low Earth Orbit (LEO) and Geosynchronous Orbit (GEO) are getting increasingly cluttered with satellites and space junk. Unless we start to clean it up, we could lose these precious areas of space for decades, if not longer.
We take it for granted that eventually—whether it be next week or sometime during the next millennia—we’ll make contact with an extraterrestrial intelligence. Trouble is, it’ll likely never happen. That’s because there’s no one out there transmitting signals for us to intercept, and no one’s travelling between stars in search of new places to conquer.
The ongoing Great Silence isn’t just a trivial observation. Our galaxy is ancient, so we should have made contact with aliens by now. Signs of ET, from radio signal leakage through to megascale engineering projects, should be virtually everywhere. Yet we see nothing.
One of the greatest conundrums to face humanity is the question of extraterrestrial life. Many…
The fact that we haven’t had an alien meet-and-greet could be read as a dire warning for our future. Perhaps there’s a technological barrier that can’t be surmounted, such as artificial superintelligence or weaponized nanotechnology. Alternately, aliens might be paranoid and xenophobic, playing it safe in case the neighbors are hostile. Alternately, intelligent life may choose to explore the infinite realms of cyberspace instead of the cold, dead cosmos. Either way, zipping around the galaxy in spaceships doesn’t appear to be an option.
Jet lag is objectively terrible. It grants no immunity and bends to no form of treatment, unless “consuming an entire bottle of liquor and popping a few Ambien” is considered treatment. (It’s not.) But according to conventional wisdom, some kinds of jet lag are worse than others—traveling east, for example, is harder on the sleep cycle than traveling west. As it turns out, conventional wisdom is largely correct.
According to a new study published in the journal Chaos from researchers at the University of Maryland, our natural circadian rhythm actually clocks in around 24.5 hours—a little more than a day. This extra slice of time makes it easier to travel in a direction that lengthens the day—west—than to travel in a direction that shortens the day—east.


Our circadian rhythm is regulated by brain cells located in the suprachiasmatic nucleus, which is found in the hypothalamus. In normal conditions, these cells move in a synchronized pattern controlled by regular exposure to light. During travel, however, this exposure is thrown off—which results in jet lag.
To test the conditions associated with jet lag, researchers used a mathematical model to simulate what happens to these brain cells during travel. The model produced results that matched up with the conventionally held east-west dichotomy: It would take a person a little less than four days to recover from a trip in which they passed westward through three time zones; six time zones takes about six days; and nine time zones takes roughly eight days.


For those traveling east, however, the recovery periods were longer: three time zones takes a bit more than four days; six time zones takes about eight days; and nine time zones eats up 12 days. (Don’t go to Australia, probably!)


“Our model explores what would happen to an individual it he/she were suddenly taken from one time zone and dropped in another,” Michelle Girvan, an associate professor of physics at the University of Maryland, told Gizmodo in an email. “The important 30 minute difference that comes into play is that the natural frequency of [the brain cells] is about 30 minutes longer than 24 hours.”
But given that everyone has a different internal clock—some of us run on fewer than 24 hours, some of us run on more—each person recovers from jet lag differently. “Our model suggests that the difference between a person’s natural period and 24 hours controls how they experience jet lag,” Girvan explained in a statement.
Still, understanding why it happens doesn’t change the fact that jet lag sucks, time is a flat circle, and even Ambien can’t save us.
[Chaos via CNN]
This image taken by NASA’s Juno spacecraft is one of the first to be taken by the probe since it entered Jupiter’s orbit last week.
It’s not the most spectacular image we’ve seen of Jupiter and its moons, but it’s a positive sign that the spacecraft’s visible light camera, the JunoCam, is operational and capable of transmitting data. The instrument was switched on six days after Juno fired its main engine and slipped into orbit around the gas giant.


“This scene from JunoCam indicates it survived its first pass through Jupiter’s extreme radiation environment without any degradation and is ready to take on Jupiter,” noted Scott Bolton, principal investigator from the Southwest Research Institute in San Antonio, in a statement. “We can’t wait to see the first view of Jupiter’s poles.”
Earlier this month, Juno sent back a grainy image of Jupiter and its largest moons, but this is the first in-orbit image taken by the probe.
NASA’s Juno spacecraft made all the headlines this past Fourth of July as it successfully went into …
This new photo was captured on July 10 when Juno was 2.7 million miles (4.3 million km) from Jupiter on the outbound leg of its initial 53-day capture orbit. The image may be low definition, but you can still make out atmospheric features—including the famous Great Red Spot—and three of Jupiter’s largest moons: Io, Europa, Ganymede (from left to right).


NASA says the first high-resolution images will be taken on August 27 when Juno makes its next close pass to Jupiter. Indeed, it’s only going to get better from here. Eventually, the JunoCam will be used to take unprecedented pictures of Jupiter’s poles and cloud tops. Over the course of its mission, Juno will circle the gas giant 37 times, flying as close as 2,600 miles (4,100 km).
[NASA]

Last week, after raging for two months over an area the size of Delaware, the Fort McMurray fire was finally declared “under control.” This was the costliest fire in Canadian history, forcing the relocation of 90,000 people—the largest evacuation in Alberta’s history—and over $2.9 billion in losses. Although the fire is finally manageable, parts of the forest will likely burn for another year. Think about that: an entire year.
Scientists agree that large, destructive wildfires, of which the Fort McMurray fire is a prime example, are  becoming more frequent because of climate change. But when it comes to those who warn people about the extreme weather that caused the fires—blistering temperatures, nonexistent snowpack—climate change has largely been scrubbed from the script. Why aren’t meteorologists, the people who tell the public about severe weather, also telling us what’s contributing to it? After all, any respectable climate scientist would tell you that this type of extreme weather is consistent with what you’d expect from climate change.


The role of the meteorologist in contemporary society is important but often invisible. They’re the people who remind us to grab a sweater or take an umbrella—sometimes on TV or the radio, more likely through a weather app on our phones. But they are also the only individuals that Americans receive advice from during potentially life-threatening weather. If a meteorologist is warning about an impending storm surge, wouldn’t it be helpful to know that those surges are likely to be worse due to rising sea levels—particularly if you live near the coast? “As a weather junkie as well as a climate scientist, I see it as our responsibility to include context,” Jason Samenow of the Capital Weather Gang told Gizmodo.

But meteorologists like Samenow seem to be in the minority. Although 96 percent of American Meteorological Society members say they believe climate change is real and human-caused, climate doesn’t make its way into their reports. On MSNBC, Bill Nye called out the network’s own meteorologists on live TV for failing to make the connection to climate change.


Granted, weather is not the same thing as climate. But for the past year, meteorological data has confirmed each month that it is once again the warmest month in the planet’s history, like a broken record of broken records. And after the harrowing weather stories of the last few months—not just the catastrophic fires in Alberta, but also the end-of-days rain in Houston and the most bizarre temperature data ever coming out of Alaska—it’s clear that extreme weather is becoming the norm.
Scientists are only now starting to understand how changes in climate affect extreme weather, in a field of study that’s called “attribution.” This has become such an important area that Climate Central has launched an entire initiative around it called World Weather Attribution. By adding historical data and other types of context to extreme weather events, climate scientists look for “fingerprints” of human behavior. Heavy rainfall, like what caused historic flooding in France and Germany last month, has been directly attributed to climate change. But these kinds of weather stories are nuanced and complicated, so it’s not easy to quickly communicate them during the weekend outlook forecast.
As a broadcast meteorologist, Bernadette Woods Placky saw firsthand how difficult it was to get climate stories on air. First, there’s the issue of time—most weather reports are only a few minutes long and don’t offer much space for commentary. Then there’s the fact that climate change has become so politicized that a conservative audience, or a fear of losing the brands that advertise to them, could scare stations out of reporting on it. “The focus wasn’t on science as much as I wanted to to be,” she told Gizmodo. “But at the same time, the public was asking questions, and there was a lot of misinformation.”
Woods Placky now heads up Climate Central’s Climate Matters, where she creates tools for meteorologists ranging from talking points to on-air graphics, that help them communicate climate change messages with their audiences. This also includes extensive social media assets which allow meteorologists to report beyond the handful of on-air minutes they’re allotted. In her mind, weather forecasts are the perfect place to talk about climate, because weather is accessible and relatable. “It is one of the things in life that affects absolutely everyone—weather is all-encompassing.”


There are about 2,200 broadcast meteorologists in the US and Climate Central is working with 300 of them, including John Morales, chief meteorologist at NBC 6 in Miami. One might say there is no meteorologist who is more on the front lines of climate change; reporting from a place where “nuisance floods” are now affecting residents more often than not. Morales’ extensive reporting on the link between a warming climate and the city’s intensifying “king tides” earned him a cameo in the famous New Yorker story on Miami’s vanishing coastlines.

“I don’t do it every day,” he said, when asked about how often he works climate messaging into his reports. “My job is to give viewers the weather forecast that they need short-term, including warnings for extreme weather that can affect their lives. But if an opportunity arises, like nuisance floods are being linked to sea level rise, I will get on air and do more of a presentation aligned with informing the public while it’s happening.”


But if my neighborhood is flooding, does it really matter whether extreme flooding is related to climate change or not? Is believing in the science going to make me pay attention, or prepare, or, as a last resort, evacuate?
Social scientists are engaging with that issue through a program called the Communication of Contentious Science, a two-year initiative of the National Academies of Sciences, Engineering, and Medicine that specifically studies skepticism—not just in the field of climate change but other culturally contentious areas like vaccinations.


“It’s not just about information—you have to link it to actions and very concrete steps that people can take,” said Irina Feygina, director of behavioral science at Climate Central, and one of the study partners. “One thing that research has shown is that balancing information about the problem with solutions can help this. So if people want to talk about protecting their homes, talk about protecting their homes—don’t start by talking about climate change.”
So, say meteorologists start making attribution part of their forecasts. Do we get daily reminders for how not to screw up the planet? This approach is very tricky. If you use a severe weather hook to talk about climate change, especially when lives or property have been lost, climate deniers will brand your message insensitive or opportunistic. But without meteorologists connecting the dots, how else will people start to see the those human “fingerprints” on their weather, and potentially make changes?


I asked Eric Holthaus, a meteorologist for Slate and host of the new podcast Warm Regards, who has encouraged meteorologists to talk about climate change, if he thought having climate information inserted into our daily forecasts might help people to take action. He was not optimistic. “I think that really, what you’re describing is the main challenge of climate change communication for the last 35 years or more,” he said. “We’ve known the science of climate change for a long time, but just knowing what’s going to happen hasn’t been enough to reduce emissions yet.”
In a place like Alberta, which will be recovering from the Ft. McMurray wildfire for a very long time, it may not be popular to make a connection to climate change, but I’d argue it’s critical. This is a region where the economy is almost entirely supported by the extraction of fossil fuels. These fossil fuels are in turn directly contributing to the warming that has extended the region’s fire season by 20 percent in just 35 years. In this case, suppressing that connection is not just destroying the livelihoods of those residents, it’s criminal. Giving weather attribution data to residents who have lost everything in severe weather events might empower them to demand serious reform.
A brand new underwater microscope just took an unprecedentedly-close look at the deep seafloor. You can see the footage it took, including a microscopic coral cage-match, right here.
The footage was taken with the Benthic Underwater Microscope, which was developed specially to look at coral reefs and other life on the seafloor by the University of California San Diego’s Scripps Institution of Oceanography.


This is not the first underwater microscope, but it is the first ever to be capable of viewing live coral interacting with each other on the seafloor. Among the scenes it saw was the coral having a snack, coral bleaching, and even a staged-fight between two neighboring coral that ended, rather alarmingly, with one coral essentially eating the other.
Nature is grim, folks—but it’s also pretty stunning.


Observe:

All images and footage of microscopic coral via the Scripps Institution of Oceanography
That little bead right there? That’s all the gold in four and a half pounds of electronics waste. And it took so very much work to get there.
Here’s what YouTuber is no stranger to the refinement of precious metals. Previously he’s gotten silver from shit-tier fireworks and found platinum dust on the side of the road. But striking gold in junk electronics is just so much more involved than expected. Here’s what he had to do to get that tiny pellet:
And at the end of all that work, Cody was left with... four milligrams of gold, from a two-kilogram bag of busted circuitboards. As he mentions early on, the margins on this type of work are very tight, but for the purposes of the video, it’s worth it to watch the bright flash of that gold bead solidifying.


Curiosity is finally back in action, after it threw itself into a mysterious partial shutdown last week, briefly falling out of communication with Earth. Now, NASA has figured out the cause—and the culprit is also one of Curiosity’s best features.
The problem stemmed from Curiosity’s cameras and how they stored their image data. A software mismatch occurred when Curiosity attempted to save images to its main computer, throwing the rover into safe mode. In safe mode, the rover shuts down everything but its most essential functions. Curiosity fell into safe mode on July 2, and while it quickly got back in touch with Earth, it wasn’t until last night that the rover finally regained its full functionality.


Just because Curiosity had a problem with its cameras doesn’t mean that we’re going to miss out on its dope photographs. NASA’s Jet Propulsion Laboratory has already figured out a way to route image-saving around the faulty software.
Earlier this month, NASA approved a 2-year extension on the rover’s original mission that would have the rover operating straight through 2018 at least. Curiosity has been a remarkably tough little robot—especially considering that it’s already gone a full five years without a tune-up, all while rolling over some harsh terrain.


In that span, it’s undergone a broken arm, got stuck on a hill, punched a hole almost straight through its wheels, and lost the ability to focus in one of its cameras. Each time, NASA has managed to get around the problem without being able to actually physically fix the problem. Hopefully, they can keep patching Curiosity up from afar through its new, longer mission.

Astronomers working with the Very Large Telescope in Chile have captured the deepest view yet of the heart of the Orion Nebula. Wow.
Located 1,350 light-years from the sun, the Orion Nebula star-formation measures about 24 light-years across. It’s visible to the naked eye, appearing as a fuzzy patch in Orion’s sword. Like other nebulae, Orion is illuminated by the many hot stars that are spawned within it, along with the glowing plasma clouds that have been stripped of their electrons from the ensuing ultraviolet radiation.
Scientists used the HAWK-I infrared instrument mounted to the VLT to capture this image, but it produced more than just a pretty picture. The new survey has revealed a treasure trove of low-mass objects, suggesting this stellar expanse is probably forming more low-mass objects than star formation regions.
Observations show that there are more planet-sized objects within this region than previously thought. The researchers also found about ten times as many brown dwarfs (objects that blur the line between gas giants and stars) compared to previous surveys.


Click here for a full resolution image.
[Royal Astronomical Society]
We’ve always wanted body armor to look less like a chunky Kevlar vest and more like a sleek superhero suit. The Army wants that too, enough so that it just awarded a $100,000 contract to a company to see if its genetically engineered spider silk can be used for body armor.
Kraig Biocraft, the winner of the contract, will test its futuristic spider silk to see how well it stands up to wear and tear. The company’s chief operating officer Jon Rice explained, “We are going to provide them a series of different thread counts, thicknesses, construction techniques that they will test against standard material performance specifications.”


If all goes well and the material looks promising, the contract could be extended up to $1 million, and the rest of us can prepare for the coolest body armor known to man. It’s important to note, however, that these spider silk—or, as Kraig calls them, “dragon silk”—suits might not be the strongest suits known to man. Existing body armor is usually made of Kevlar and dragon silk is only two-thirds as strong, though pure dragon silk would be stronger than Kevlar. But Kevlar is also super bulky and limited to protecting only the torso, while dragon silk retains strength while being far more flexible. This leads not only to wider range of motion but also opens up the possibility of a full-body suit and more protection.
Scientists have long known that spider silk is basically a miracle material. It’s five times stronger than steel of the same diameter, waterproof, and thanks to protein threads that serve as stretchy “superstrings,” it can be stretched up to 40 percent without breaking. It’s even inspired the creation of a liquid wire and could be used to grow replacement hearts.


Problem is, it’s hard to produce. We have millennia of experience raising silkworms on farms, but nobody really wants to have a spider farm. That’s not only because spiders are creepy. Arachnids are also cannibalistic and hard to work with, making spider silk incredibly rare. Some scientists are tackling the problem by spinning limited amounts of artificial silk in a lab, but the folks at Kraig inserted spider DNA into silkworms to make them spin a spider silk-like material.


But don’t you wonder what would happen if one of those silkworms bit someone? Do mutant silkworms have the same effect on humans as radioactive spiders? We might soon find out.
[Defense One]
Millions of years ago, a pair of exploding stars showered our planet with radioactive fallout. Had those supernovae popped off a bit closer to home, Earth’s biosphere would have been toast. But even at a distance of 300 light years, the stellar events might have had an impact on the evolution of life here.
The idea that astrophysical phenomena, including black hole x-ray flares and supernovae, can shake up life on Earth enough to direct evolution has been around for a while. And when a crop of scientific studies published in Nature and Science this past April presented evidence for two nearby back-to-back supernovae toward the end of the Pliocene, scientists immediately began discussing potential impacts on Earth’s climate and biology.


Now, the hypothesis that there were impacts has gotten a boost from a computer modeling study, which estimates how much additional radiation life on Earth was dosed with following the cosmic fireworks. To cut to the chase, the radiation load for terrestrial and shallow marine life would have roughly tripled for thousands of years after each event, thanks to a 20-fold increase in the number of high-energy muon particles striking the ground.
This was a bit of a surprise.“I was expecting there to be very little effect at all,” said University of Kansas physicist Adrian Melott, who co-authored the study appearing this week in The Astrophysical Journal Letters.


Melott is not a biologist, but he doesn’t seem to mind a bit of wild speculation where supernovae are concerned. Regarding the new finding, he says the extra radiation at ground level might have been enough to increase the rate of DNA mutation, which in turn could have briefly sped-up evolution. (Evolution can’t occur unless DNA is mutating, a process that typically happens very, very slowly.)


The study further suggests that high-energy cosmic radiation could have increased the ionization, or electric charge, of the troposphere, resulting in more cloud-to-ground lightning strikes. Whether tropospheric ionization had an additional climatic or ecological impact remains an open question.
It’s by no means a silver bullet for the argument that supernovae have impacted evolution—just another shred of evidence that the history of life on Earth was a rocky roller coaster. Really, it’s a goddamned miracle we’re here at all.

Among a baseball pitcher’s arsenal of tricks is the infamous curveball, whereby the baseball takes a sudden dive downward just before it reaches the plate, faking out the batter. A new “History Minute” video from the National Institute of Standards and Technology takes a look at the physics behind this longstanding bane of batters.
The video is a tribute to Lyman Briggs, a physicist who served as director of the National Bureau of Standards (now called NIST) from 1933 to 1945. He was also a lifelong baseball fan, having played outfield on his college baseball team during the 1890s, and conducted several experiments in the 1950s to determine the precise physics at work in a curve ball.

At the time, there was much heated debate about whether a curve ball actually curves, or if it was just a perceptual illusion. Dizzy Dean, a pitcher with the St. Louis Cardinals, believed the former and once boasted, “Ball can’t curve? Shucks, get behind a tree and I’ll hit you with an optical illusion.” But Briggs was a scientist. He wasn’t going to just take Dizzy Dean’s word for it. He was going to do a bunch of experiments.


His hypothesis was that it had something to do with the Magnus effect: when a pitcher throws a curveball with good topspin, this creates a high-pressure zone at the top, and the ball gets deflected downward in an exaggerated drop. That seemed straightforward enough. But Briggs also wanted to know how much that telltale curve depends on spin, versus speed.
First he tried photographing the balls in mid-flight, but they just moved too fast to capture any definitive information about their trajectories. So he mounted a ball on a rubber tree and then shot at it with wooden bullets from an air gun to measure the curve and the speed. Measuring the spin, however, proved to be a bit trickier. For that, Briggs turned to the NSB’s old wind tunnel used to study aerodynamics. As I wrote in 2011:
This allowed him to precisely control most of the variables. He tossed baseballs into the wind tunnel, and let them freefall against the horizontal wind streams, which naturally caused the ball to curve. When a baseball finally hit the ground after the requisite 0.6 seconds, it bounced off a sheet of cardboard treated with lampblack, which left a smear on the ball, indicating point of impact. His conclusion: “An increase in the speed of the pitch beyond 100 feet per second reduced the curve only slightly and the important thing was the spin.”
So how much a ball curves depending more on spin than speed. And it really does curve—a lot. In fact, it can curve as much as 17-1/2 inches between the pitcher’s mound and home plate.
Do you hear that sound? It’s 65 million years ago and there’s a dinosaur calling out through the wilds. But it’s not a roar. Instead new research says that sound would probably be better described as a “coo” or a “mumble.”
Researchers from the University of Texas did a comprehensive review of the vocal organs of birds and the kinds of sounds they made. Then they matched those up with the vocal organs found in fossilized dinosaurs for a paper coming out next month in Evolution. The results, they say, suggest that many dinosaurs were far more likely to vocalize with a closed-mouth—perhaps, a disapproving “hmm” or a more pensive “umm”—than with a full-throated roar.


This is far from the only finding paleontologists have borrowed from the birds. Feathers are replacing scales more and more often in our dinosaur drawings. A group of scientists recently stuck a prosthetic tail on a chicken to make it mimic the gait of a bipedal dinosaur.
You already know about the evolutionary areas of overlap between dinosaurs and modern-day birds.…
Some may say that this comparison diminishes the awesome power of the dinosaur, but the truth is that it only makes them all the more terrifying.


Still don’t think a coo sounds so intimidating? Well, listen to this:

Now imagine that ostrich suddenly 60 feet taller and stepping right through that fence like it wasn’t even there.
“What is it doing?” asks the unnamed videographer in the clip—moments before it becomes unsettlingly clear exactly what the ostrich is doing. It’s teaching you the true meaning of fear.
Say hello to 2015 RR245, a 440-mile-wide dwarf planet located approximately 7.5 billion miles from the sun. It takes 700 years to make a complete orbit, making it one of the most remote known objects in the entire solar system of significant size.
The newly discovered dwarf planet was discovered by an international team of astronomers using the Canada-France-Hawaii Telescope on Maunakea, Hawaii, as part of the ongoing Outer Solar System Origins Survey (OSSOS). Astronomer J.J. Kavelaars from Canada’s National Research Council was the first to spot the minor planet in February 2016 while pouring through OSSOS images taken back in September 2015.


“There it was on the screen—this dot of light moving so slowly that it had to be at least twice as far as Neptune from the Sun,” Michelle Bannister, an astronomer at the University of Victoria in British Columbia, and a postdoctoral fellow with the survey, said in a statement.
Our solar system is home to a bunch of trans-Neptunian dwarf planets (such as Pluto, Makemake, Sedna, and Eris), but RR245 is exceptional because its aphelion (i.e, the point that is the furthest distance from the sun) has been estimated at a whopping 10 billion miles (17 billion kilometers) from the sun. It’s so far that light from the sun requires 16.63 hours to get there. By comparison, it takes nearly seven hours for the sun’s light to reach Pluto. RR245 is currently approaching its perihelion, which should happen around 2096.


Astronomers say it’s the 18th largest object in the Kuiper Belt, and that it likely formed some 100 million years ago. Like other minor planets that formed within the protoplanetary disc, it slowly drifted outward. Many minor planets were destroyed or thrown out from the solar system during this process, but RR245 managed to hang in there.
In a universe full of planets, 2007 OR10 is something special. It’s big, just slightly smaller than …
Earlier this year, researchers from Konkoly Observatory detected 2007 OR10, a minor planet nearly the size of Pluto. The Kuiper Belt is home to thousands of much smaller trans-Neptunian worlds, the vast majority of which are still yet to discovered. Previous surveys have detected a small handful of these objects, but RR245 may be one the last large worlds beyond Neptune to be detected until larger telescopes come online in the coming decades.
The International Astronomical Union has officially recognized RR245 as a dwarf planet. Its precise orbit will be refined in the coming years, after which time it’ll be given a proper name. As its discoverers, OSSOS team members can submit their preferred name to the IAU for consideration. Let’s hope they come up with something cool.
[CFHT]

Parents, you can stop fretting about your child’s disgusting habits. An analysis of more than 1,000 kids between the ages of 5 and 11 reveals that nail-biters and thumb-suckers are less likely to develop allergic sensitivities later on in life.
New research published in the journal Pediatrics shows that children with these habits are less likely to develop allergies to house dust mites, grass, cats, dogs, or airborne fungi. It’s further evidence in support of the so-called “hygiene hypothesis,” which suggests that childhood exposure to microbial organisms and other nasties alters immune function, resulting in a decreased risk of developing allergies.


“While we don’t recommend that these habits should be encouraged, there does appear to be a positive side to these habits,” study co-author Malcolm Sears of McMaster University said in a statement.
For the study, the researchers took data from the ongoing Dunedin Multidisciplinary Study, which is following the progress of 1,037 participants born in Dunedin, New Zealand from 1972 to 1973. Back when this study got started, parents reported their children’s thumb-sucking and nail-biting habits when they were 5, 7, 9, and 11 years old. When these children turned 13, and again at 32, they were checked for atopic sensitization—a skin prick test that detects a sensitivity to at least one common allergen.


Slightly less than a third of all children enrolled in the study were frequent nail biters or thumb suckers. By the time these kids reached their teenage years, nearly half showed an atopic sensitization of some sort—so oral habit or not, half of these kids still developed an allergy. But for those with one oral habit, their chance of developing an allergy dropped to 40 percent. And for those with both habits, this figure plummeted to 31 percent. That’s significant.


This trend held true into adulthood, and was not altered by factors such as smoking in the household, owning cats or dogs, exposure to house dust mites, or breastfeeding. And this study did not find associations between nail-biting and thumb-sucking with the onset of asthma or hay fever.
Oral habits such as thumb-sucking and nail-biting are likely providing a channel through which microbial organisms can enter the body, particularly at a young age. But it would be a mistake to deliberately expose our children to these pathogens, which could lead to sickness. Moreover, the authors of the new study aren’t suggesting that children be encouraged to take up these habits, saying there’s no clear-cut evidence of a true health benefit.
For years, parents have been told to withhold peanuts from their  children until the age of three,…
Relatedly, previous studies have shown that most peanut allergies can be staved off by not withholding peanuts from children before the age of three. This makes sense when you think about it. An allergic reaction is basically the body’s immune system freaking out when it detects a potentially dangerous foreign agent. By “training” the immune system at a young age to recognize certain substances as being harmless—whether they be benign microbes or peanut particles—we may be able to reduce our chances of developing an allergy in the future.


[Pediatrics]
A fairly ordinary-looking galaxy has been hiding a strange secret in plain sight. It is ten times larger than anyone thought (a whopping 718,000 light-years in diameter), plus it’s younger on the inside than it is on the out. Scientists think that it’s been stitched together from the pieces of several other galaxies—hence its nickname, the “Frankenstein galaxy.”
Under ordinary, optical light, Galaxy UGC 1382 looks smaller and fairly ordinary. In fact, the galaxy had been included in over 40 different papers before this discovery, and none of them had catalogued it as unusual. Then astronomers decided to take a closer look in the ultraviolet regime as part of a different survey, and the strange features of the galaxy began to shine through.
“We pulled up one of these galaxies and, lo and behold, there’s this amazing set of spiral arms extending out,” co-author Mark Seibert of the Observatories of the Carnegie Institution for Science told Gizmodo. “You simply don’t expect to see spiral arms in an elliptical galaxy.”


Furthermore, for almost all known galaxies, the outside edges are younger than the inside. That’s because galaxies form from the center, and expand outwards with newer, younger stars. But for UGC 1382, the galaxy’s center was younger than its outside.
“We call it the Frankenstein galaxy because it formed out of a couple different galaxies,” said Lea Hagen, a graduate student at Pennsylvania State University who led the study. “The idea of galactic cannibalism, of galaxies eating their friends, is well-established. We think what happened is you had some tiny dwarf galaxies and then a few billion years later another galaxy formed nearby. At some point, those all came together.”
For Galaxy UGC 1382 to form as it did—to essentially merge, leaving whole parts of the galaxies relatively intact—everything had to occur exactly as it did. Even slight changes would have been enough to dramatically change the course. “If they were galaxies of equivalent size, that would be a crash and that would have been disastrous,” Seibert said. “Large galaxies don’t come together like this, it’s a medium sized galaxy and some little ones.”


Also key was Galaxy UGC 1382's location, 250 million light years away from us. Its position in a relatively quite patch of universe let it form undisturbed by other nearby galaxies, until it reached an incredible size. “As large as it is, it’s still very thin and diffuse,” Seibert said. “It requires very specific conditions to make these kinds of monsters. They have to be in very specific environments.”


The unexpected size of the galaxy raises questions over just what else we’re missing out there. Although the researchers believe the strange features of Galaxy UGC 1382 are very rare, there are other faint objects that could have their own secrets hidden.
Vincent van Gogh’s “Starry Night” seems to have a special appeal for scientists, who have recreated it using bacteria, among other media, in the past. Now scientists at Caltech have made their own tiny version of the painting—a dime’s width across—out of folded DNA molecules. Some day the same technique could be used to build teensy biosensors, or for targeted drug delivery.
It’s called “DNA origami,” and while many different kinds of shapes have been created using it, this is the first proof of concept that it’s possible to scale up and build large numbers of DNA based devices on computer chips. The Caltech team described their work in a new paper in Nature.


“Everybody thinks molecules are eventually going to be the devices of the future,” Caltech’s Paul Rothemund, DNA origami pioneer and co-author, told Gizmodo. “But how do you connect them? How do you wire them up into larger circuits? How do you do anything with them? You need an interface between the molecular and the macroscopic world, and that’s what this is.”
It’s been ten years since Rothemund made the first amusing shapes by folding strands of DNA. His nanoscale smiley faces, stars, snowflakes, and a miniature map of the Western hemisphere were even displayed at the Museum of Modern Art in New York City in 2008—a true marriage of science and art.


DNA takes the form of a double helix, and encodes all the genetic instructions for manufacturing proteins. It has four repeating chemical bases—known as A, T, G, and C—that are complementary, so A always pairs with T, and G always pairs with C.
To create his special shapes, Rothemund folded a single long strand of DNA back and forth into whatever shape or pattern he desired (determined beforehand with computer modeling), then stuck it all together at strategic points with “staples” comprised of shorter DNA strands. Each V-shaped staple had two “arms” with a base sequence that would bind to its complementary sequence on the longer DNA strand. Then he heated the long DNA strand in a saline solution, and let the whole thing self-assemble into the desired pattern.
It only takes about one week to design the pattern on the computer, and another week to synthesize the DNA, and the actual self-assembly only takes a few hours. “But then you’re stuck with a device that’s floating around in a solution,” said Rothemund. “You can’t combine it with anything else, you can’t wire it into a circuit, it’s even hard to measure its performance.”
If this were ever to find any practical application, Rothemund knew he needed to figure out how to integrate his DNA origami with silicon microfabrication, and he collaborated with IBM scientists to do just that. By 2009, they had discovered that you could make sticky patches on a chip that were the same size and shape as the DNA origami. Simply pour the solution containing the DNA over the surface of the chip and the DNA molecules will stick to those matching patches.
That DNA shape now acts as scaffolding, making it possible to attach other tiny components—like fluorescent molecules. Rothemund likens it to the pegboards typically found in garages to hold various tools, except this is a self-assembled pegboard where the tools find their own positions and stick there, held in place by DNA functioning like Velcro.


Rothemund and his colleagues have been refining this technique ever since. Over the last six years, he and a Caltech postdoc, Ashwin Gopinath, have shown that they can position their DNA origami on pretty much any surface used to make computer chips.
And their latest paper offers the first application: using the method to stick fluorescent molecules into tiny light sources, much like light bulbs screw into lamps. The “lamps” in these experiments are photonic crystal cavities tuned to a specific wavelength of light—in this case, a deep shade of red. (Manmade photonic crystals are engineered with a highly precise honeycomb structure that causes light to reflect off the surface in such a way as to block certain frequencies of light and let others through.)
The injected fluorescent molecules will glow at the tuned wavelength, thereby “lighting” the lamps. But location is key: the molecules will glow more brightly at some locations within the cavity than at other locations. By fiddling with positioning, Rothemund and Gopinath found they could create checkerboard patterns of “hot” and “cold” spots.


That gave them the capability to reproduce other, more elaborate patterns. Gopinath chose to recreate “Starry Night” to demonstrate the technique’s power, because he’d always liked van Gogh’s work. Besides, he had just seen that Doctor Who episode (“Vincent and the Doctor”) in which everyone’s favorite Time Lord goes back to 1890 to help a fictional van Gogh battle an alien monster. Whereas prior work in this area used just a handful of these kinds of devices, Gopinath scaled everything up and stitched together 65,536 of them to recreate van Gogh’s masterpiece.
The next step is to refine this technique even further, perhaps by using different fluorescent molecules or another type of light emitter, like quantum dots, since the ones they used for these experiments tend to burn out quickly. Plus, the colors aren’t as pure as one would like for certain applications, like optical or quantum computing at the nanoscale.


Physicists are likely to be more interested in the potential for doing more fundamental experiments. For instance, an upcoming set of experiments will involve placing multiple emitters inside resonators and trying to get them to sync with each other—a phenomenon called “superadiance” that was first predicted by Robert Dicke back in 1952.


Gopinath likens the effect to how a bunch of metronomes on a table may start ticking out of sync, but will gradually start ticking in unison over time if the conditions are just right. In much the same way, multiple light emitters should sync up as well. “Nobody has yet done a clean experiment, because you have to position emitters at specific distances with respect to each other,” said Gopinath. This new paper provides a possible way to do that.
[Nature]
Van Gogh’s The Starry Night can be recreated in real life in two ways: one of them is to be on…
As Portugal and France snoozed their way through the final match yesterday at Euro 2016, thousands of Silver Y moths crashed the party—including one that fluttered onto Ronaldo’s anguished face as he sat injured on the pitch. They’re calling it the moth ball final. So what brought all these moths to the Stade de France?


A fan from Iceland suggested the moths were retribution against Ronaldo for insulting their upstart team, but there’s a more plausible explanation. Silver Y moths are a migratory species that move north through Europe each summer, eventually returning back south in the autumn. The Euro 2016 final was held at just the right place and time for the moths to make their unwelcome appearance.
It also didn’t help that the stadium’s flood lights were left on from the previous night. A post from The Guardian explains more:
“It’s an obligate migrant species – a proper migratory species,” says Richard Fox of Butterfly Conservation. “Individuals must migrate and choose the right winds to fly at different altitudes to maximise the efficiency of their migration. There’s very clever stuff going on.”
On a warm summer’s evening, the lights of the stadium act like an enormous moth trap, drawing down a migrating front of thousands of these moths.
Pictures show the moths rising from the turf in clouds when the referee, Mark Clattenberg, and officials first stepped on to the pitch. The moths had arrived in the stadium before the footballers – almost certainly drawn down on the previous night when the floodlights were reportedly left on.
“When you’ve got all these big mammals tramping around on the grass, the moths quite sensibly flew up and away,” said Fox.
We may not have seen the last of these moths. Winds are currently blowing from the south and south-west, so the Silver Ys might actually end up at a future Premier League football match in Britain later this summer.


[Guardian]
Consider the water flea. They don’t seem like the flashiest animals, but it turns out they can grow helmets and spines to beat their enemies, and can even customize the defenses based on which predator they’re fighting.
Linda Weiss, a professor at Ruhr-University Bochum in Germany, is leading research on how water fleas, or Daphnia lumholtzi, developed this ability, and presented it at the most recent meeting of the Society for Experimental Biology. Apparently, the fleas have the ability to detect the unique chemical traces left in their environment by predators such as phantom midge larvae and fish. Depending on which chemical traces the water flea detects, they will develop different types of armor.


“These defences are speculated to act like an anti-lock key system, which means that they somehow interfere with the predator’s feeding apparatus,” says Dr. Weiss.
For example, many freshwater fish can only eat small prey so the water fleas who detect freshwater fish will grow head and tail spines to make themselves larger and harder to eat. Her team has detected the specific neurotransmitters that detect the chemical traces and then activate the process that causes the spines or helmets to grow.


Future research will look at how the water flea’s “arming” abilities affect the local ecosystem, but for now we’re just wishing there were a way that we could do the same thing.


[EurekAlert]
For over a century, paleoanthropologists have been fascinated by a gory question: were Neanderthals cannibals? In recent years, we’ve found remains that suggest cannibalism did exist in various parts of southern Europe but new remains found in northern Europe add further evidence to the “yes” answer and tell us more about why cannibalism was practiced.
Cannibalized remains have been found in Spain, France, and other parts of southern Europe but, according to a recent study published in Scientific Reports, these new remains are from the Goyet region of Belgium and are the first in northern Europe.


All the remains found at the site—human, horse, reindeer—show cut marks where muscle and bone were separated and “percussion” marks that show that bones were crushed to extract the marrow. Because the Neanderthals ate horse and reindeer, and because no modern humans were in the area, the researchers believe that these similar cut marks on human bones confirm cannibalism.
Neanderthals didn’t just eat each other either. They also used bones as tools to sharpen stones, and may “have been aware that they were using human remains.”


That being said, lest the reader think that cannibalism are just par for the course, remains found at other sites have contained uneaten, buried remains, showing that it was not a universal practice. At the Goyet site, the researchers claim that cannibalism was probably not part of a funerary rite.


So why cannibalism here? Desperation.
According to radiocarbon dating, the bones are about 40,500 to 45,500 years old, around the time the Neanderthals died in Europe. DNA testing shows that the Neanderthals in northern Europe are genetically similar to those in southern regions, which means that there weren’t a lot of them left.
Many remains show evidence of malnutrition and so, given these factors, it’s likely that Neanderthal cannibalism was—as with famous cases like the Donner party myth—a result of food shortages and the “you gotta go what you gotta do” mindset. (However, given that cannibalism isn’t simply morally distasteful but is also unhealthy, it’s unclear how much the last-ditch attempt helped.)
Even after the cannibalism, the Neanderthals obviously died out. However, they live on in one important way: Some of their DNA lives on in us and continues to affect humanity.


[Atlas Obscura]
The stereotype concerning someone with anger issues is that they just have bad impulse control. You joke that they haven’t slept in a week, they start screaming. But it may be that people blow up not because they can’t hold in their feelings, but because of poor social processing that makes them think your sleep comment was actually you telling them they’re completely incompetent.
In a new study published in the journal Neuropsychopharmacology, University of Chicago neuroscientists used fMRI to to measure the white matter in the brains of people with intermittent explosive disorder. They found that, for people with the anger disorder, white matter in an area called the superior longitudinal fasciculus was less dense than in people that had other psychiatric disorders or were otherwise healthy.


The SLF area is the “information superhighway” that connects the frontal lobe with the parietal lobe. The frontal lobe is responsible for processing emotion and for decision-making, while the parietal lobe processes sensory output, as well as language.
“It’s not so much how the brain is structured, but the way these regions are connected to each other,” said Royce Lee, lead author of the study. “That might be where we’re going to see a lot of the problems in psychiatric disorders, so white matter is a natural place to start since that’s the brain’s natural wiring from one region to another.”


The findings suggest that one reason people have anger issues is that they misinterpret social behavior and think that other people’s behavior is negative when it isn’t. They don’t fully understand the situation and misread cues like body language, which leads them to become more angry and more likely to explode. This is bad news for people with the disorder because experiments have shown that venting anger—even more justified anger—makes you feel worse.


Looking at brain connectivity is key in understanding psychiatric disorders because people with psychiatric disorders otherwise show few physical differences from those who are healthy. The research could have important implications both for those with anger disorders and with borderline personality disorder.
In the meantime, those of us without an anger disorder could learn how to prevent our anger from spiraling out of control. Justified or no, life is usually better when we minimize the amount of ragestrokes we have to experience, and apologize for.
[Neuropsychopharmacology via University of Chicago]
Baby sea turtles don’t really need our help being adorable, but remarkably, scientists have figured out a way to make the tiny shelled reptiles even more mind-numbingly cute: by hypnotizing them.
Mohd Uzair Rusli, a biologist at the University of Malaysia Terengganu, ran into some trouble recently when he was trying to weigh baby green sea turtles for a physiological study. The little scamps just wouldn’t stay still! But Rusli stumbled upon a simple solution when he noticed that his hatchlings did stop wriggling if placed in a dark container or stacked atop one another. He suspects that darkness and the pressure of stacking trigger the sensation of being packed in a nest with hundreds of other baby sea turtles.

Using these observations, Rusli developed a simple hypnosis technique. By flipping the hatchlings on their backs, shutting their eyes and applying gentle pressure to their chests, he can immobilize his subjects long enough to take an accurate weight measurement. Between this new development and poop-catching swimsuits, we’re well on our way to learning everything there is to know about baby sea turtles, or dying of cute in the process.


[New Scientist]

For two years, researchers have been farming a series of crops in Martian and lunar soils. Now, a vegetable from the garden is finally about to get its first taste test. It will be a radish.
The radish wasn’t actually grown on Mars or the moon. Researchers in the Netherlands Wageningen University have grown a series of 10 crops in lunar and Martian simulated soils, including peas, tomatoes, radishes, potatoes, green beans and carrots. The results have been surprisingly delicious-looking, like so:
That’s a pretty good-looking tomato. But as good as it looks, a bigger question still remained: How does it taste?


When I first reported on the successful harvest of these crops back in March, lead researcher Wieger Wamelink told us he was waiting to taste them until the heavy metals test results came in.
“We had crops and harvested them, tomatoes, rye grains, radish, rocket, cress, but did not taste them yet,” Wamelink told Gizmodo. “First we have to make sure that it is safe to eat them because of the heavy metals that are present in the soils and may end up in the plants.”
Now, the first heavy metal tests of those crops are in. Of the four crops sampled—peas, tomatoes, rye, and radishes—all of them had heavy metal concentrations within normal levels, the researchers reported.


In fact, both peas and tomatoes in some cases had lower levels than the earth crops:
The researchers still have six additional crops to send through heavy metals testing—including potatoes, green beans, and carrots. But, with these preliminary results from the first crops, it looks as though the crops are finally ready to be eaten.


We talked to Wamelink again to find out if these latest results were enough to clear the plants to become part of a Martian salad. Yes, he said, with one caveat.
“In principle, there could be another problem, but the chances of that are very low and we would taste it immediately,” he told us. “Plants may form alkaloids when they are under pressure, in high quantities they could be poisonous to us. We will check on them later, to see if any of them are in the crops, together with vitamins and flavonoids.”
The taste test, which will start with a radish, hasn’t been conducted quite yet, but it’s scheduled for Wednesday 29th.

A remarkable new image captured by a satellite in orbit around Mars shows the Curiosity rover as it explores the barren landscape.
Curiosity is currently investigating the Naukluft Plateau, which is just north of the Bagnold Dune field. A newly released photo taken by the HiRISE instrument on board the Mars Reconnaissance Orbiter shows the rover as it’s trundling across the Martian surface.
Located within the the Naukluft Plateau are sandstone outcrops known as the Stimson Foundation. Looking at the image, it doesn’t appear that the four-wheeled probe is leaving any tracks behind. But that’s because this expanse of bedrock doesn’t contain much sand or dust that could be displaced by its wheels. Below is a zoomed in view.
The image below was taken by Curiosity and it shows what the area looks like from the surface.
Man, that’s a barren place. Here’s to hoping that human explorers will be able to pay Curiosity a much needed visit in the not-too-distant future.


[HiRISE]
Around 40 people attending a seminar with motivational speaker Tony Robbins in downtown Dallas yesterday were injured when a group exercise involving walking across hot coals went wrong. And it’s not the first time this has happened: back in 2012, for instance, 21 people in San Jose were burned after attempting the stunt at another Robbins seminar.
People got burned walking across hot coals, you say? There’s a shocker. But the Dallas seminar had over 7000 participants, most of whom completed the fire walking ceremony without injury. Why did most of those people walk across the coals safely while a (relative) handful got burned?


The Robbins camp might say they just didn’t believe in themselves enough to fully unleash the power within, but it actually has everything to do with physics. As I wrote back in 2012, it is quite possible to firewalk safely. A physics professor at the University of Pittsburgh named David Willey does it all the time, thanks to his grasp of the underlying physics.
This is well-established science. The key factors at play are the low thermal conductivity of the burning wood-turned-to-coal, an insulating layer of ash, and the short time of contact between the hot coals and the soles of the feet.


In particular, the coals must burn down to around 1000 degrees Fahrenheit, preferably with a thin layer of ash providing extra insulation. This also burns off excess water, which increases the heat capacity and thermal conductivity of the coals.
And while it’s tempting to want to run across hot coals, this actually pushes your feet deeper into the embers, increasing the burn risk. A nice steady walking pace is best. (Some say wetting your feet beforehand can add protection via the Leidenfrost effect, but Willey has found the effects of this to be negligible and prefers to firewalk dry-footed.)
Back in 1998, Willey and Kjetil Kjernsmo of University of Oslo developed a computer model of a fire walker’s foot, and then compared it to infrared imagery of people fire walking in Seattle. Those images showed that the foot really does remain cool when the stunt is done correctly.
So what went wrong in Dallas? Probably the same thing that happened at the 2012 San Jose seminar. You have to set up a scientific experiment correctly to get the best results, and for something like fire walking there’s not much margin for error. Those who got burned probably lingered just a bit too long on the hot coals, the better to, say, snap a selfie of their moment of enlightenment.


That seems to be borne out by witness statements. “From my observation, there was someone in front of us and someone behind us on their cell phone, taking selfies and taking pictures,” Jacqueline Luxemberg, a participant who did the firewalk and emerged unscathed, told WFAA. “[She asked others] to video record for her, so I think that that has a lot to do with it.”
So should you ever decide to attempt a fire walking stunt yourself, remember: walk (don’t run), make sure the coals have burned down sufficiently, don’t wet your feet beforehand, and try not to strike too long a pose for that selfie. Oh, and have some ice and Vicodin handy, just in case.
[WFAA]
Britain is saying goodbye to the European Union, a monumental decision that’s triggering some serious alarm bells among the country’s researchers. Here’s why they have a right to be worried.
For months, scientists and environmentalists in the UK have been warning about the consequences of a Brexit. And now it’s actually happened. It’ll likely take a couple of years for Britain to negotiate its way out of the EU, but researchers around the country are already worried about what this divorce means to them, their jobs, and the state of the British union.
No doubt, Britain’s historic decision to extricate itself from the European Union is poised to have a pronounced effect on science funding, research, regulation, and the environment.


“This is a poor outcome for British science and so is bad for Britain,” declared Paul Nurse, a Nobel-prize winning geneticist, to a group of journalists. He said that British scientists will now have to figure out a way to “counter the isolationism of Brexit if our science is to continue to thrive,” adding that science “thrives on the permeability of ideas and people, and flourishes in environments that pool intelligence, minimize barriers and are open to free exchange and collaboration.”
Nurse is one of hundreds of scientists who nervously awaited the outcome of Thursday’s referendum. In the months preceding the vote, droves of British scientists voiced their opinions on the matter, arguing that a Brexit vote would be potentially disastrous to science in the UK and the EU at large. Back in March, the Times published a passionate pro-Remain letter that contained the signatures of more than 150 researchers from the University of Cambridge. Polls showed that nine out of 10 university staff backed the Remain camp, and that 40 percent might leave the UK should the Brexiters win. Stephen Hawking also chimed in, saying that staying in the EU is vital for Britain’s economy and security, and that Britain risks being isolated.
Academic institutions in the UK are now in serious limbo. Around 18 percent of the UK’s funding from the EU goes to scientific research and development. If the British government can’t find a way to make up for this shortfall, that could lead to some serious job losses and the outright termination of certain research programs. Prior to the vote, the Digital Science group estimated that the UK could lose £1 billion ($1.4 billion) in science funding annually.


The UK is also in danger of losing access to some major EU research programs, including the Horizon 2020 program of research grants. That’s not to say that Britain can’t find ways to stay within these programs and others. Assuming that Britain still has the will and financial means to stay within these programs, it could still continue to work alongside its former EU partners.


Jonathan Butterworth, a British physicist who works on the ATLAS experiment at the Large Hadron Collider near Geneva, Switzerland, says the Brexit is “going to be very damaging,” and demands that the British government come up with real solutions to ensure that “the level of research and education funding that was coming through the EU will be guaranteed.”
In defense of the Brexit, Conservative justice minister Michael Gove noted that the money normally given to the EU by the UK could now be channeled into science. It’s an encouraging thought, but one that will have to be translated into action. Others are hopeful that the Brexit could free Britain to do more exploratory forms of scientific research. An advisor to Gove, Angus Dalgleish, believes the Brexit is good for the UK in this regard in that it’ll remove some restrictive EU regulations on scientific research.
Another perk of EU membership is the freedom of citizens of member states to work and go to school in each other’s country without restrictions. There’s a fear that many of these individuals will either be forced out of the UK, or simply choose to leave. That could lead to a serious “brain drain” given that 15 percent of all university staff in the UK come from the EU, and that around 5 percent of all students are from other European countries. The University of Cambridge in particular could be hard hit as 23 percent of its research scientists are from other EU countries. It’s also not clear how the Brexit will affect British scientists working abroad.
“I hope that ways will be found to reassure all those non-UK EU citizens who work in science or the NHS that their futures are secure here, and that we will make sure that whatever happens the UK remains an attractive place for others to come and help take medical science and the NHS forward,” noted Simon Wessely, president of the Royal College of Psychiatrists, in The Independent.
The Royal Astronomical Society is particularly concerned about pending travel restrictions:
UK and European science benefit from the free movement of people between countries, something that has allowed UK research to become world leading. Although for example membership of the European Space Agency and European Southern Observatory is not contingent on EU membership, these organisations depend on international recruitment made easier by straightforward migration between countries. We therefore urge the Government to ensure it remains straightforward for UK scientists to travel and work in EU countries, and for EU scientists to come to the UK.
Dame Julia Goodfellow, the president of Universities UK, said that her group’s first priority will be to convince the UK government “to take steps to ensure that staff and students from EU countries can continue to work and study at British universities in the long term, and to promote the UK as a welcoming destination for the brightest and best minds.” She reminded Britons that “leaving the EU will not happen overnight—there will be a gradual exit process with significant opportunities to seek assurances and influence future policy.”


And then there’s the environment to consider.
“The short answer to what happens next with pollution, wildlife, farming, green energy, climate change and more is we don’t know—we are in uncharted territory,” Damian Carrington wrote in The Guardian. “But all the indications—from the “red-tape” slashing desires of the Brexiters to the judgment of environmental professionals—are that the protections for our environment will get weaker.” Carrington worries that the plunging stock markets will “damage the huge investments needed to create a cleaner and safer environment.”
As it stands, many UK laws and regulations are determined by EU legislation. It’s not immediately clear which environmental protections will remain and which will be abandoned. Some environmentalists worry that Britain’s departure from the EU will result in the watering down of environmental and climate policy.


“It is therefore essential that the government gives a commitment that, in negotiating the terms of the UK’s exit from the EU, an equivalent or enhanced level of environmental protection and climate policy will be implemented here in the UK,” noted the the Institute of Environmental Management and Assessment (IEMA) in a statement.
The EU has a history of getting Britain’s environmental act together, including an injunction to clean-up its sewage-strewn beaches. The same can be said for many protections currently in place in the UK for nature and wildlife, along with an EU-driven mandate to improve recycling and waste. There’s now fear, for example, that Britain will scrap a ban on pesticides that harm bees and other important pollinators.


It’s only been a few hours since the referendum, so reactions are understandably intense and distressed. As noted, there’s still a long road ahead, and many of the concerns expressed by the scientific community are likely to be addressed in the coming negotiations. Panic is obviously not the way to go, but as many of these scientists have made painfully clear, the UK government would be making a huge mistake should they choose to ignore the needs of this crucially valuable sector of British society.


[Nature 1, 2, Wired, The Independent, The Guardian]
Attention, New Yorkers: If climate change continues unabated, over 3,000 people in the city will die every year from heat by 2080. Do something, and maybe only about 1,500 will die.
This fun news is according to a paper published online this week in Environmental Health Perspectives that analyzes the effect of future climate change on New York City. We’ve long known that climate change equals higher temperatures equals more heat death, but the new paper is notable in focusing so specifically on one area and taking into account the projected demographic shifts of New York.


The authors used data from 33 global climate change models to create their projections. These models also included factors like migration and future population size—with a focus on the elderly population, which is most vulnerable to heat—as well as the availability of air conditioning and public cooling centers, and greenhouse gas emission trajectories.
Ultimately, they came up with two scenarios. In the optimistic one, steps like reducing fossil fuels and building more public cooling centers are taken, and about 1,552 people die each year from heat death by the 2080s. In the status-quo scenario, the number of deaths more than doubles to 3,331. In contrast, there were about 600 heat-related deaths in New York City from 2000 to 2006, according to the National Center for Health Statistics.


This is already the hottest the Earth has ever been and even the South Pole is warming up. The paper is about New York City specifically, but probably has similar implications for other large metropolitan areas. However, there does seem to be one remaining place that is hopeful for climate change: the wonderful forests of Eastern Canada. If things get too bad and nobody builds those cooling centers, maybe we’ll all move there?


[Environmental Health Perspectives, via Scientific American]
Rumors are swirling again among physicists, but this time they’re not about gravitational waves. Instead, hopes are fading that two separate, but complementary, experiments at the Large Hadron Collider may have discovered a possible new particle.
Last December, LHC physicists announced that they’d found tantalizing traces of an exotic particle not predicted by the Standard Model of particle physics— perhaps a heavier cousin of the Higgs boson, or the elusive graviton, a quantum carrier of the force of gravity. Neither reported finding was solid enough to claim discovery, but both experiments reported hints of a signal in exactly the same spot in the data, which was promising.


At the time, I (and others) cautioned that it was likely that those hints of a signal would disappear as more data was added to the analytical mix:
Physicists know precisely how many of each type of particle they should expect to see in the data; any excess above a certain threshold is a promising hint of possible new physics (like a new particle).
When all’s said and done, those signals show up as unexpected “bumps” in the data — that’s why experimental particle physicists often call themselves “bump hunters.” The thing is, it’s easy to see small “bumps” that aren’t really there; statistical artifacts crop up all the time, particularly during early data runs. The more data you have, the better the statistical analysis. If a small “bump” persists and gets bigger — the signal gets stronger — it’s much more likely that it’s the signature of a bona fide new particle.
The LHC began analyzing tons of new data in May. Unfortunately, Science News is reporting that it’s looking like the former case—a statistical artifact—is the more likely scenario. That’s according to rumors on Twitter and on two physics blogs. Noting that the field is fast approaching a crucial crossroads, physicist Peter Woit wrote, “If the bump is there, the field will be revolutionized and dominated by this for years, if it’s not, we’re back to the usual frustrating grind.”

The official stance is that we can’t be sure until all the data is in later this summer. “Currently the data are still being recorded and analyzed and it is too early to conclude,” Beate Heinemann of the University of California, Berkeley, and deputy spokesperson for the ATLAS experiment at the LHC, told Science News. “We hope to be able to present the new data in early August,” during a high energy physics conference (ICHEP 2016) in Chicago.


[Science News]
Earlier this week, physicists at the Large Hadron Collider announced they’d found tantalizing…
Salt preserves food, and we’ve using it in that capacity for thousands of years. But here’s a neat tip: meat and fish aren’t the only things you can keep from going rancid with salt curing. It also works with egg yolks.
Your friends (the ones with reservations at Stone Barns anyway) are going to think you’re a goddamn food wizard for turning eggs into crumbly pucks of umami, and hell yes they taste delicious. The principle is the same as any other type of curing: salt wicks away moisture and starts killing off the bacteria that makes food go bad. Sugar is also included because it feeds bacteria in the lactobacillus genus—which seems counterintuitive at first, but lactobacillus are friendly bugs. They show up in cider, kimchi, and yogurt and make whatever they’re in more acidic, thereby killing even more of that harmful bacteria. Enemy of my enemy, etc. etc.


Chef Elise Kornack decided to jazz things up for this recipe by burying her yolks in a shit-ton of salt and sugar seasoned with bonito flake and bay leaves. Additional flavors or not, you just stick the buried yolks in the fridge for two days so the cure has time to work its magic. Once they’re cleaned off, toss them in an oven, a dehydrator, or just hang them in cheesecloth if you’re very patient. They should come out solid, bright orange, and delicious.
Grated over carbonara is one of the best and most obvious uses, but Kornack also suggests using the yolks in salads or on vegetables. Either way, you’re going to blow some minds when your dinner guests realize they’re eating eggs instead of grated cheese.


An ambitious but controversial plan to clean up the Great Pacific Garbage Patch moves closer to reality this week, with the deployment of an ocean plastic cleanup boom off the coast of the Netherlands in the North Sea.
The 100-meter floating boom is a scaled-down version of a 100-kilometer long system that Dutch nonprofit The Ocean Cleanup eventually hopes to deploy in the Pacific Ocean between California and Hawaii. The boom is meant to slurp up the millions of tons of unsightly plastic comprising the Great Pacific Garbage Patch. The prototype, aptly named “Boomy McBoomface,” will sit roughly 20 kilometers off the Dutch coast for a year in a critical field test of the system’s survivability.


The Ocean Cleanup’s mission has garnered international media attention, thanks in no small part to the nonprofit’s charismatic founder, 21-year-old Boyan Slat, who was just 18 when he started working on the idea. The basic concept is to use currents, wind, and waves—the natural motion of the ocean—to push plastic garbage into screens that extend outward from floating booms. The booms, which are anchored to the sea floor through a system of cables, form a V-shaped structure that concentrates plastic at the center, where it can be easily harvested by collection vessels.
To bring that concept to life, the nonprofit has assembled a team of engineers, who’ve spent the last year testing a small-scale model at a maritime research institute in the Netherlands. That the team is already moving to field trials speaks to the strong public support for the project, which raised over $2 million in a crowdfunding campaign in 2014, and secured an additional million dollars for its prototype test from the Dutch government and private supporters. The full-scale structure is expected to cost roughly $350 million.


But the plan is not without its critics—namely, members of oceanography and marine biology community, many of whom feel the design hasn’t been properly vetted and are worried about the potential ecological impacts of what would become the largest offshore structure ever assembled.
After The Ocean Cleanup published a lengthy feasibility study in 2014, oceanographers Kim Martini and Miriam Goldstein responded with their own technical review, which found “major issues” with the plan. These included the use of average rather than extreme current speeds, which could cause engineers to significantly underestimate the loads and tensions the structure will be subjected to in the field. The feasibility study also failed to address biofouling—the accumulation of life forms that’ll add weight to the booms over time. What’s more, it’s unclear how the company will fix the system should a catastrophic failure occur in the middle of the ocean.
Others have raised concerns about the effects of the boom structure on marine life, either through direct by-catch or by impacting the behavior of migratory species. As deep sea biologist and Southern Fried Science blogger Andrew Thaler pointed out in a blog post last year, The Ocean Cleanup boom system is, by definition, a Fish Aggregating Device, or FAD:
In it’s crudest form, an FAD is any floating, semi-stationary structure in the open ocean. Prey species tend to aggregate under floating structures, and predators naturally follow. The Ocean Cleanup won’t simply act as a barrier to migration, but will also attract pelagic species. Long term, this could create permanent or semi-permanent communities, resulting in changes to migratory patterns.
“Our engineers take all criticisms and concerns very seriously,” said Ocean Cleanup spokesperson Jan van Ewijk, adding that the organization was aware of the scientific community’s response to its feasibility study. (Gizmodo was referred to the group’s engineering team for response to technical questions about environmental impacts, and we will update when we hear back.)


Goldstein and Martini, meanwhile, received no feedback to their analysis outside of a video response from Slat, which downplayed their qualifications for commenting on engineering issues but acknowledged that they made many “valid points.” How many of those valid points are being acted on is unclear.
“There are some changes to the version 2.0 of the feasibility study, but none that allows us to easily see what is different, as would be the case in normal peer review,” Martini told Gizmodo in an email, adding that the limited response to her review and an earlier offer for review by the Scripps Institute of Oceanography “has discouraged engagement from other scientists.”
It’s possible that The Ocean Cleanup will address many of the concerns its critics have raised before deploying the full-scale array in 2020. The nonprofit is reportedly conducting an environmental impact analysis with Royal Haskoning DHV. And with its newly deployed prototype, the group stands to learn a lot more about how the system will fare and how it may fail under stormy conditions.


Update 6/23/16 4:15 pm: Kim Martini has just posted some additional thoughts (and great questions, including why the heck is The Ocean Cleanup using RO-BOOMS, which have been around since the ‘90s?) on the blog Deep Sea News. Check out her post here.
Update 6/24/16: A spokesperson for The Ocean Cleanup responded to Gizmodo’s request for comment on concerns raised by certain members of the scientific community. He emphasized that the tests being run in the North Sea are intended to determine what could be wrong with the boom design and to identify possible modes of failure. The Ocean Cleanup is also aware of concerns that their boom system could act as a Fish Aggregating Device. This is something it plans to monitor and continue studying with the engagement of the marine biology community, the spokesperson said.
No need to worry, everything is fine! It’s just that a mysterious dark vortex has opened up in the skies over Neptune.
Hubble just snagged a picture of a dark vortex looming over Neptune during a May 16th view of the planet. This is actually the third documented sighting of a dark vortex in Neptune’s atmosphere. It was seen in 1989, during a Voyager fly-by. Then, in 1994, Hubble spotted the strange feature again.


Dark vortices form when clouds of gas and air in Neptune’s atmosphere begin swirling and eventually freeze up in the icy temperatures, to move as a single strange mass. “Dark vortices coast through the atmosphere like huge, lens-shaped gaseous mountains,” leader of the study, Mike Wong of the University of California-Berkeley said to NASA. Along with the dark vortices, comes an accompanying stream of bright clouds—which Wong notes are similar to the “clouds that appear as pancake-shaped features lingering over mountains on Earth.”
All the dark vortices have a cloud of frozen gas, topped with bright clouds, but all the other features appear to be completely changeable. Differences in size, shape, and the duration they last has been noted among all the observed dark vortices.


Although this is the first time the strange feature has been spotted in 22 years, researchers suspect that other dark vortices have passed through Neptune’s atmosphere unnoticed in the meantime. In particular, an incident in 2015 raised suspicions, when astronomers worldwide reported seeing bright clouds in Neptune’s skies. Ultimately, though, they couldn’t confirm a sighting of a dark vortex beneath them.
Now that they have a better look at Hubble’s view of one of Neptune’s dark vortices, researchers hope to get a better understanding of just why they form and why they eventually disappear.
A recent survey shows that people want self-driving cars to be programmed to minimize casualties during a crash, even if it causes the death of the rider. Trouble is, the same survey shows that people don’t actually want to ride in cars that are programmed this way. That’s obviously a problem—and we’re going to have to get over it.
These are the kinds of thought experiments that are taught to Ethics 101 students during the first weeks of class—but now they’re actually being applied to real life. Similar to the vexing trolley problem, manufacturers are struggling to come up with new rules for autonomous vehicles to guide them when a crash is inevitable, and the lives of people, both inside and outside of the car, are at stake.
A new study published in Science shows there’s a big disconnect between the kinds of ethical programming we want these vehicles to have, and the kinds of cars we actually want to ride in. Surveys done last year demonstrate that people tend to take a utilitarian approach to safety ethics. That is, they generally agree that a car with one rider should swerve off the road and crash to avoid a crowd of 10 pedestrians. But when the survey’s respondents were asked if they’d actually ride in a vehicle programmed in this way, they said no thanks.
“Most people want to live in in a world where cars will minimize casualties,” said Iyad Rahwan, a professor at MIT who co-authored the study. “But everybody wants their own car to protect them at all costs.”


The researchers call this a “social dilemma” whereby consumer choice—and the urge to act in one’s own self-interest—could make road conditions less safe for everyone. Frustratingly, there’s no known way to design a cake-and-eat-it-too algorithm that reconciles our moral values and the understandable human desire to not die.
Results of the survey showed that people are on board with utilitarian-minded robotic vehicles, and would be content to see others buy them. This is an easy sell; the needs of one or two individuals, we tend to agree, is greatly outweighed by the needs of the many. The more lives saved, the more inclined people are towards this utilitarian attitude. As shown in the survey, as many as 76 percent of respondents were cool with a vehicle being programmed to sacrifice one passenger if it meant saving the lives of 10 pedestrians.


But these same people showed considerably less enthusiasm when it came to their desire to purchase or ride in one of these autonomous vehicles. When asked to rate the morality of a car programmed to crash and kill its own passenger to save 10 pedestrians, the favorable rating dropped by an entire third when respondents had to consider the possibility that they’d be the ones riding in that car.
The study also revealed that people don’t like the idea of having the government regulate the auto industry to enforce utilitarian principles. Respondents were only a third as likely to purchase a vehicle regulated in this way, as opposed to an unregulated vehicle, which could conceivably be programmed in any number of ways.


Rahwan and his colleagues warned that the concerns over regulations could “paradoxically increase casualties by postponing the adoption of a safer technology.”
Patrick Lin, the director of the Ethics + Emerging Sciences Group at California Polytechnic State University, says we humans are a fickle lot, and that we don’t always know what we want or what we can live with.
“What we intellectually believe is true and what we in fact do may be two very different things,” he told Gizmodo. “Humans are often selfish even as they profess altruism. Car manufacturers, then, might not fully appreciate this human paradox as they offer up AI and robots to replace us behind the wheel.”
What’s particularly bizarre about this latest research is that many of these survey respondents, should they find themselves in a situation where they’re driving a car and are suddenly confronted with a similar situation, would probably go out of their way and make a suicidally evasive maneuver to avoid a crowd. There appears to be a bit of a disconnect between the morality of human decision-making in these matters, and having robots make these decisions on our behalf. We’re clearly uncomfortable with it, but we’re going to have to get over it if we ever want to see safe and responsible self-driving vehicles on the road.


“It shouldn’t be surprising that ordinary people haven’t thought deeply enough about ethics to be consistent,” said Lin, who wasn’t involved in the study. “Most people think that ethics is just about your ‘gut instinct’, but there’s so much more to that. It’s practically a science, complete with guiding principles or laws.”


Lin also noted that we trade safety for other priorities and conveniences all the time. “Humans are notoriously bad at risk assessments: we drink and drive, we text and drive, we go way over the speed limit, and so on,” he said. “If we really didn’t care about being killed, we wouldn’t be in a car in the first place or allow guns in society.” To which he added: “So, by asking for opinions from ordinary people, the study is collecting uninformed answers, and that’s not very helpful in resolving dilemmas, which may be useful in advertising and marketing, but not so much for law and ethics.”
At the same time, Lin acknowledges that public opinion can be a powerful thing. All it would take is for a Hollywood movie to embed a self-driving car in the story and show how wonderful and safe things will be when autonomous cars hit the road. At the same time, a high-profile crash caused by a self-driving vehicle could turn opinions away from the technology, “so manufacturers really need to be careful.”
Rahwan says these opinions “are not guaranteed to persist.” Indeed, as people learn more about autonomous vehicles and how they work, it’s likely that public opinion will come around. And if not, that’s when auto manufacturers, the government, the law, and the insurance industry will all step in.


[Science]

We assume that all biological processes come to an end when we die, but new research shows that many genes remain active for up to four days following clinical death. These zombie genes can’t bring a person back to life, but this discovery has serious implications for forensics and organ donor recipients.
A pair of new studies, both of which are still undergoing peer review, are teasing our conceptions of death and what goes on in our bodies after we die. University of Washington biologist Peter Noble and his pals have shown that certain parts of the body remain active even after the rest of it has come to a grinding halt. In future, these insights could be used by scientists who are seeking to improve the way that donated organs are preserved, and by forensic investigators seeking to determine when a person was killed.


As Mitch Leslie points out in Science Magazine, previous work on human cadavers demonstrated that some genes remain active after death, but we had no idea as to the extent of this strange phenomenon. By analyzing the tissue of recently deceased animals, Noble and his colleagues managed to pinpoint hundreds of genes that were still functioning in the days—yes days—following death. If the same thing applies to us—and there’s no reason to believe it doesn’t—it could change the way we perceive the recently deceased and how we define death.
At what point does a person actually die? That depends on who you ask. To one person, it's the …
In the first of the two studies, the researchers sought to determine which genes out of about a thousand might still be functioning in zebrafish and mice in the immediate days following death. To their surprise, the researchers found that hundreds of genes sprung back to life. Not only that, the activity of some of these genes actually increased. Most of these genes eventually gave up after about 24 hours, but some remained active for as much as four days after death. That’s surprising, to say the least.


The majority of these zombie genes were not random in terms of function. Each of them play an important role when an animal experiences some kind of trauma or illness. For example, some genes that were ramped up are responsible for stimulating inflammation and the immune system as well as for countering stress. Some genetic activity, like a gene that’s responsible for embryonic development, baffled the scientists. Noble suspects that this gene becomes active because the cellular environment in dead bodies must somehow resemble those found in embryos.
Importantly, several genes that promote cancer also became active. This may explain why many organ donor recipients develop cancer. This tidbit of information could help scientists develop better methods of organ preservation prior to transplantation.
The second study, also co-authored by Nobel, shows that similar assessments of postmortem genetic activity could be used in criminal and civil investigations. Forensic teams could take genetic samples at murder scene, for example, to get a better estimate of time of death.
As noted, these two papers have yet to appear in a peer-reviewed journal, and the genetic evaluations were not performed on human cadavers. Further research will be required before we draw too many conclusions about these fascinating studies.
[bioRxiv here and here via Science Magazine]
India just sent twenty satellites into space at once, the most the country has ever launched in a single go. The record is certainly impressive. The photo documentation of the satellites blasting off to the skies is simply incredible.
The satellites launched successfully this morning aboard India’s Polar Satellite Launch Vehicle. In addition to the photos below, ISRO also provided a full list of every satellite on board. The rundown seems pretty unremarkable, at first. Almost every satellite is either destined for earth-imaging or earth-monitoring. Things get a little more interesting, though, when you look at where those satellites are coming from.


Fifteen of the twenty satellite spaces were sold to American or Canadian companies. Indonesian and German space organizations also each booked single tickets for their satellites. In fact, since India first began accepting satellites from abroad in 1999, 74 of the 113 launched came from other countries.
India has been building up its space presence aggressively over the last few years. Recently it successfully launched both a Mars orbiter and a mini space shuttle.
Early this morning, India launched its very first reusable space shuttle. These remarkable photos…
So far, India has been able to operate its spacecrafts on relatively tiny budgets, but as it sends up more and more vessels costs are rising too. A thriving global satellite-launching business, which competes for business with SpaceX and other rising private space companies, would be a way to fund not just its own rocket launches, but perhaps more new spacecraft as well.


Here’s the full gallery of today’s record-breaking satellite launch:
Described as “energetic, lively, and ready to work,” the Hungarian Pumi has just become the 190th breed recognized by the American Kennel Club. It’s been a long road for the Pumi to get to this point—a showcase for how hard it is for dogs to enter into this exclusive club.
Pumis may be headed to the Westminster Kennel Club, but this furry quadruped has been around for over 1,200 years. These medium-sized dogs were originally bred in Hungary around 800 AD to herd sheep. Pumis are often referred to as “herding terriers,” but they’re actually descended from traditional sheep dogs. The terrier label is on account of their very terrier-like attributes, such as their face, quickness, alertness, and their lean, muscular body. As of July 1, the breed becomes eligible to compete in the Herding group of US dog show competitions.
So why did it take so long for the American Kennel Club to recognize the breed? Much of it has to do with the AFK’s painfully convoluted and at times completely arbitrary admission criteria.


A breed is considered “rare,” for example, if its population is small in the United States. In order for the AFK to even consider a breed as being legit, a breeding club must prove that there’s a “sufficient” US population with a minimum of 300 to 400 dogs with three-generation pedigrees and at least 100 households forming a national club devoted solely to the breed. What’s more, the club must prove that the dog is “truly national,” with a geographic distribution of “dogs and fanciers” in at least 20 states.
In addition, clubs must provide accurate pedigrees and ownership records, while also showing that the breed has been “breeding true” for several generations, that is, having two dogs of the same breed consistently producing offspring that are recognizable as that breed.
That’s just for the privilege of becoming eligible for the Miscellaneous class. From there, it’s still a long road to official status. As noted at the AKC website:
There is no official quota or timetable for adding new breeds, but dogs typically reside in the Miscellaneous class for one to three years. At the end of the first year, AKC contacts the national breed club for updates on the number of dogs and litters recorded, and the number of dogs who have entered events since being eligible to compete in the Miscellaneous Class. Finally, the club must have held match shows, local and national breed specialty shows, judges’ workshops, and breed seminars.
Once all this criteria is met, the AKC board of directors then vote on the breed’s full recognition. Whew. No wonder the announcement of the Pumi as an official breed is considered such a big deal.


Of course, there’s also the ethics of dog breeding to consider. Many purebred dogs suffer from hip dysplasia and other symptoms of inbreeding. And as noted in an AP article, “Some animal-rights advocates say dog breeding is too appearance-focused and irresponsible when many mixed-breed animals need adoption.” Fair point.

[AKC, AP]
Your first thought on seeing this weird pink snow might be an industrial accident or a nearby Big Foot massacre. Rest assured, it’s neither—just a perfectly natural, snow-dwelling algae. So, why are scientists all in a tizzy about it? Because it’s causing glaciers to melt faster.
That’s the startling conclusion of a study just published in Nature Communications that which suggests we may have seriously underestimated the ability of tiny red algae to screw with Earth’s ice caps. And their so-called “bio-albedo” feedback is only expected to grow as the planet warms up.


Red snow algae have been described all over the world in polar and alpine settings from Greenland and Antarctica to Iceland and the European Alps. In the winter, they lie dormant in the snow as spores. But in the late spring and summer, when their icy habitat begins to melt, they blossom to produce striking pink landscapes.
Now, a sweeping analysis of red snow algae across 21 glaciers in the pan-European Arctic shows that these tiny critters are actually helping the snow melt faster.
The reason has to do with a simple climate-altering process known as the albedo effect. You’ve probably heard about how glaciers keep our planet cool by reflecting sunlight. As glaciers melt, they give way to darker land or ocean surfaces—surfaces with a lower albedo. This causes the Earth to absorb more sunlight and heat up even more.


Turns out, red snow algae have a non-trivial effect on the albedo of the snowy surfaces they colonize, reducing it by as much as 13 percent, according to the new study. And while it’s still unclear just how large these blooms can get, lead study author Steffi Lutz of the University of Leeds says they can be quite widespread in the Arctic by summertime.
“Based on personal observations, a conservative estimate would be 50 percent of the snow surface on a glacier at the end of a melt season,” she told Gizmodo in an email. “But this can potentially be even higher.”
This makes red snow algae an unaccounted mechanism in the long list of reasons the Arctic is melting like a popsicle in a microwave. Lutz and her colleagues are now working to estimate how much glacial melt red snow algae are actually responsible for. They’re also hoping to incorporate the colorful critters into future global climate models.
It’s been a hot year in the Arctic, with sea ice melting earlier and faster than ever before. New…
What’s worrisome is that even if red snow algae have a small influence on Arctic ice cover today, their role is likely to grow as human carbon emissions warm the planet.


“The algae need liquid water in order to bloom,” Lutz said. “Therefore the melting of snow and ice surfaces controls the abundance of the algae. The more melting, the more algae. With temperatures rising globally, the snow algae phenomenon will likely also increase leading to an even higher bio-albedo effect.”
It’s yet another reminder that microbes are pulling the strings around here much more than we humans tend to appreciate. And that even as Miami drowns, some creatures will thrive in the hotter future.
[Nature Communications]
A team of pilots and a medical worker are in the midst of evacuating a sick staff member from a science base near the South Pole. The rescue attempt is considered treacherous given the extreme midwinter temperatures and distances involved.
An unnamed staff worker at the National Science Foundation’s Amundsen-Scott South Pole Station has become seriously ill. The medical situation is serious enough to facilitate a perilous midwinter rescue—a time of year when dark and cold conditions make routine flights treacherous. This is apparently just the third time this has ever happened.


For privacy reasons, the nature of the medical emergency has not been made public. What we do know, however, is that the patient is seasonally employed through the Lockheed Martin Antarctic Support Contract, and that their illness could not be managed at the station. After consulting with outside medical professionals, the team decided that an emergency rescue was required to get the patient to a hospital in South America.
Easier said than done. This isolated base is located near the South Pole, about 1,500 miles from Rothera, a British Antarctic Survey Station on the Antarctic Peninsula. It takes about 9 hours to get from Rothera to the NSF base—a distance of over 1,500 miles. And as already noted, it’s now winter in Antarctica, where temperatures can drop to -76 degrees F (-60 degrees C).
For the rescue, a pair of Twin Otter aircraft were deployed to Rothera. These are the only planes in the world capable of withstanding midwinter Antarctic temperatures. Prior to taking off, the fuel, batteries, and hydraulics need to be warmed. Importantly, these bad boys don’t require a runway for landing.


Earlier today, one of these planes landed at the South Pole base and evacuated the patient (the other plane is there strictly as a backup). It’s now airborne once again, making its way back to Rothera. From there, the plane’s three-person crew and one medical team member will rest before embarking to South America.
No word yet on the health of the patient, but according to an NSF spokesman, “It went all according to plan.” It also appears that, in addition to the patient, two support crew employees were also evacuated, but this still needs to be confirmed.
[NSF, Guardian]

Michigan’s Attorney General Bill Schuette filed charges against two companies over the public health disaster that has unfolded in Flint’s water supply over the last few years. The charges include negligence, public nuisance, and fraud.
Flint’s water has been in trouble since 2014 when the state switched the city’s source to the Flint River. The water from the polluted river was made even worse by Flint’s aging and corroded pipe system, which leached lead into people’s drinking water. The city eventually switched back to Detroit’s water supply last year, but by then several health problems and even deaths had been linked to the poisoned water.


The suit, which you can read in its entirety here, was filed in Michigan’s Genesee County on Wednesday morning. The state of Michigan alleges that two water services and engineering companies, Veolia and Lockwood, Andrews & Newnam (LAN), were negligent in their oversight of Flint’s water pipe infrastructure. They failed to foresee the problems that could occur, and failed to address the public health crisis in a timely fashion.
In a statement, the Michigan AG said that the two companies “either knew or should have known” that the lead pipes, combined with Flint River’s unusually high chloride levels would cause the pipes to corrode and leak lead into the water. The AG goes on to say that these leaky lead pipes now “pose a threat to drinking water, [that] is ongoing with no end in sight.”


In the case of Veolia, the state is lobbing the additional charge of fraud. According to the Michigan AG:
The suit alleges fraud against Veolia for its false and misleading statements to the public regarding the safety of Flint’s drinking water and compliance with state and federal standards, in its taxpayer-funded analysis of the Flint water system.
Michigan wants compensation for the current catastrophe as well as for the public health problems that will continue to crop up for years into future. If Michigan’s suit is successful, the state says the companies could be on the hook for hundreds of millions of dollars.


The state also left the door open to further charges, saying that “additional claims” against Veolia and LAN, and perhaps even more companies, could be forthcoming.
[Michigan Attorney General via AP]


Update 5:40 pm: A LAN spokesperson emailed us responding to Michigan’s lawsuit, which they describe as having “blatantly mischaracterized the role of LAN’s service.”
Notably, they deny having been in charge of operating Flint’s water plant at all, saying that the city had been the one to refuse to add anti-corrosives to the water flowing through Flint’s lead-pipes:
The Attorney General specifically referred to a decision not to provide appropriate corrosion control, which resulted in a significant decline in water quality, a decision that was made by the City and the MDEQ, not by LAN. Contrary to statements by the Attorney General, LAN was not hired to operate the plant and had no responsibility for water quality, but, and although LAN was not asked, LAN had regularly advised that corrosion control should be added and that the system needed to be fully tested before going online.

For a frigid little space rock at the ass-end of the solar system, Pluto is full surprises. Ice volcanoes, hazy skies, vast plains of churning nitrogen, what’s next? Just maybe, a subsurface ocean.
Perhaps the most incredible discovery of the New Horizons Pluto encounter last summer was that the former ninth planet is geologically active, with widespread evidence of tectonic activity across its icy surface. This pretty much flies in the face of everything we’d expect for a world so small that sits so far from the sun, and planetary scientists have struggled to explain it for the better part of a year.


A modeling paper published this week in Geophysical Research Letters offers a simple but fascinating explanation: partial freezing within a subsurface, liquid water ocean.
“Our model shows that recent geological activity on Pluto can be driven just from phase changes in the ice—no tides or exotic materials or unusual processes are required,” lead study author Noah Hammond said in a statement.
The idea of a liquid water ocean on Pluto isn’t new. We now know that Pluto’s surface consists of a layer of so-called volatile ices, including nitrogen, methane, and CO2. It’s also widely accepted that these exotic ices are merely a dusting atop a much thicker, water-based mantle that extends all the way to a rocky core. Most of that mantle is probably frozen—but it’s possible that a layer hugging close to the hot core is still liquid.


What’s significant about the new study is that it finds evidence for a liquid water ocean today in the tectonic scarring seen on Pluto’s surface. Specifically, the absence of compressional tectonic features—which would form if the innermost layers of water had frozen into a dense form of ice known as ice II—suggests that Pluto may not be entirely solid.
“The formation of ice II would cause Pluto to experience volume contraction and compressional tectonic features to form on the surface,” Hammond explained. “Since the tectonic features on Pluto’s surface are all extensional and there is no obvious compressional features, it suggests that ice II has not formed and that therefore, Pluto’s subsurface ocean has likely survived to present day.”
If Hammond’s models turn out to be correct, they raise the exciting possibility that subsurface oceans are a common feature throughout the icy rocks littering the Kuiper Belt. Whether any of these exotic oceans could support life as we know it remains to be seen—but it’s all the more reason to keep sending space probes out there to explore.

Brace yourself for GATTACA comparisons. A powerful gene-editing tool that could pave the way for genetic engineering has been approved for use in humans to fight cancer.
Scientists will use the tool, called CRISPR cas-9, to change immune-system cells. That way, when they’re put back into the patient, the cells attack the tumor cells responsible for myeloma, melanoma, and sarcoma. It’s key to note that this experiment, proposed by scientists at the University of Pennsylvania, is somatic, meaning it will not create changes that can be inherited.


Still, the approval is a big step forward in the bioethics debate around CRISPR and its potential uses. Many have said that the technology brings us very close to designer babies, and there has been much debate on the pros and cons of being able to genetically engineer our children.
While it’s unlikely U.S. regulators would want CRISPR to be used for genetic engineering stateside, the worry is that other countries might not be so scrupulous—and if other countries start engineering kids to have higher IQs, the U.S. might have to start so we don’t fall behind. (That worry isn’t unfounded, since Chinese scientists have already edited the human genome of an embryo, creating changes that would be heritable though in this case they did not use viable embryos.)


So, CRISPR is an ethical minefield and the worries aren’t as outlandish as they might seem. But for now, no genome changes have happened and the approval is just for a cancer treatment, which is something almost everyone can get behind.


[Stat]
Last year, Chris Borland of the San Francisco 49ers announced he was quitting football because of the high risk of concussion and long-term brain damage, despite protective helmets. And he’s not alone: it’s a growing concern, particularly for teenaged athletes. But a new collar inspired by the humble woodpecker may help protect athletes from such trauma in the future .
Co-invented by David Smith, the “Q Collar” creates a kind of bubble wrap around the brain. It was the subject of two new studies published last week in Frontiers in Neurology and the British Journal of Sports Medicine, demonstrating significant decreases in signs of brain trauma in high school football and hockey players.


More than 60 percent of NFL players have had at least one concussion, and may suffer long-term brain damage as a result. Helmets protect them from skull fractures, but do very little to stave off concussion and related brain trauma, because that extra padding just increases the inertia, according to Greg Myer of the Cincinnati Children’s Hospital, lead author on the two new studies. That makes injury more likely, because the brain can slosh around inside the skull cavity, potentially damaging brain tissue and vital neural connections.
Smith was working on improving helmets used by the military when he came across several studies concerning the woodpecker and realized they might hold the secret to preventing concussions. Woodpeckers can hammer away at trees as much as 12,000 times a day during mating season, 18-22 times per second. And those sudden sharp blows can pack quite a wallop, boasting a deceleration force of 1200 g’s. (The more slowly you decelerate, the more the energy is dissipated over a longer period of time, and the less the impact, per every high school physics class ever.)
Yet they don’t suffer concussions because their heads serve as natural shock absorbers. Past studies involving CT scans showed that woodpeckers have thick muscles, spongy bones, and a third inner eyelid, all of which combine with the cerebrospinal fluid to help absorb the impact of all that frenzied pecking.


Woodpeckers also have a long tongue that can wrap around the head and pinch the jugular vein. This actually increases blood volume in the skull, creating a protective cushion—adding extra padding on the inside rather than outside of the skull.
The mechanics of that unusual tongue reminded Smith of an old military diagnostic test for spinal damage from the 1920s, whereby doctors would pinch the jugular vein of a patient to see if it created a corresponding increase in pressure further down the spinal column. If it didn’t, this was strong evidence of spinal injury.
Smith was sure he was onto something and began emailing Myer about his hypothesis. Myer admitted he was skeptical at first—“It is crazy sounding!” he told Gizmodo—but then he realized it made perfect sense from a physics perspective. And there was a way to test Smith’s idea, inspired by another animal that seems to have a natural protection from head-injury: head-ramming sheep, who migrate to higher altitudes.
Smith and Myer looked up all the data on head injuries among high school and professional football players and sorted it by the altitude of the various stadiums. They found a 30 percent decrease in concussion for high school players and a 32 percent reduction for NFL players at higher altitudes. Ironically, Denver—the so-called Mile High City—didn’t have the lowest rates of concussion. Myer said it’s because visiting players actually take supplemental oxygen between plays, reducing the positive protective effects of high altitude.
But how could they mimic this effect in an actual device? That’s where a company called Q30 Innovations comes in. There had been prior studies with rats wearing collar devices that showed significant protective benefits to the brain. That’s what led to the design of the Q Collar, a C-shaped device that fits around the neck.


The Q collar gently clamps down on the jugular vein, putting a “kink in the hose” to increase the amount of blood in the brain. So there is less room for the brain to slosh around, and less risk of traumatic brain injury. The effect is similar to padding the brain on the inside with bubble wrap.
It sounds a bit alarming, frankly—how can pressing on the jugular of athletes during games possibly be good for you? But Myer has spent the last several years making sure it’s a safe approach. “Basically, you’re putting a kink in the hose on the outflow,” said Myer. “That creates a backfill in the brain and increases the blood volume. We’re trying to mimic the same physiology as when we’re lying down. That’s a physiology we experience nearly eight hours every day.”
But does it work? The two new studies published last week suggest it does. One followed hockey players, while the other followed high school football players, monitoring head impacts with sensors attached to the helmets. The players’ brains were scanned before and after the season using diffusion tensor imaging, a form of MRI, to look for structural markers of damage to the brain’s white matter. Players who wore the collar showed no significant signs of brain injury, compared to players who did not wear the collar.


More research is needed before the Q Collar can seek approval from the Food and Drug Administration. But one day soon it could change not only how we protect athletes from injury, but also how we design car seats and seat belts. “I think this is a paradigm shift,” said Myer. “It has a lot of implications beyond sports.”

[British Journal of Sports Medicine, Frontiers in Neurology]

There’s a new form of chocolate out there that wants to replace candy as we know it. The reason it’s not going to is the same reason all substitute foods keep failing to deliver on their promises: Accurately replicating food is almost impossible.
In a study published today in PNAS, physics researchers at Temple University describe a new chocolate-making technique that let them cut the fat content—which usually made-up half or more of the bar—by 20 percent. Previous attempts at cutting the fat by that much had resulted in a chocolate so chunky and slow-flowing that it clogged the machines. The new chocolate, however, flowed as easily as the original.


Researchers accomplished the trick by electrorheology, a technique in which an electric field is set in the same direction as a moving liquid. The field flips the particles—in this case, cocoa solids—into chains that move together, making the liquid flow easier.
Lead researcher Rongjia Tao of Temple University noted that, although the method had never been used on food before, it wasn’t an entirely new technique.


“Dark chocolate, basically, is a mix of cocoa solids and the liquid is cocoa butter. It’s a liquid suspension,” Tao told Gizmodo. “[The same technique] is also used to reduce the viscosity of crude oil in the pipeline, the crude oil is also a liquid suspension.”
Tao’s hunch paid off when his low-fat chocolate moved easily through the machinery without a hitch. But chocolate, even at its worst, is not crude oil. It’s not enough for it to flow through machinery without clogging it, it also needs to taste and feel just right. In a statement, Tao had described the flavor as “wonderful,” adding that many in his lab called it “better than the original.”
That’s where the problems start. “Better” is not only a subjective judgement of taste but also another way of saying that something just tastes different than the original. And that difference—whether you happen to find it more or less palatable—is the basic problem that all food substitutes keep running into. When a new fake-meat burger or lab-grown chicken breast or a low-fat candy comes out, they don’t promise a taste that’s better than the original. They promise an identical one—and over and over, they fail to deliver it.
Elaborating on the question of the difference in taste of his chocolate to Gizmodo, Tao said, “I myself couldn’t find the difference in flavor. But some people find the flavor more concentrated. It’s stronger.”
Flavor, though, as important as it is, is just one part of the experience. In fact, for chocolate, it might even be considered secondary to its texture in your mouth. Last year, for the first time, researchers were able to isolate the flavor of fat independent of its feel. The results were not particularly pleasing, with many respondents referring to the taste as gross and, even more disappointingly, surprisingly “unfatty”.
There are five acknowledged tastes: sweet, sour, bitter, salty, and (slightly more controversially) …
The unhappy reactions to the taste, and the difficulty synthesizing it all, point to a basic fact about fat. Fat doesn’t taste good because of its flavor, it tastes good because of its feel. It makes our foods creamier, silkier, meltier. And that experience—even if you can manage to make the chocolate quite smooth, like Tao says his method can—is almost impossible to replicate.


Replicating foods while subtracting a primary ingredient—say, the fat from a chocolate bar or the meat from a burger—is an almost impossible task. It demands that every sensory experience, not just the taste, by reproduced practically flawlessly.
Even when pulled off quite well, the results of foods copies often seem to fall more into a food uncanny valley than true duplicates. Perhaps scientists should just forget about making copies and instead move their research towards truly novel foods that stand on their own. We have enough replicant foods that are almost (but never quite) right.

A compound called nicotinamide mono nucleotide (NMN) has been shown to slow down the aging process and extend the lifespans of mice. We’re about to find out if it does the same thing to humans.
A planned clinical trial devised by researchers from Washington University in St. Louis and Keio University in Japan is set to test the effectiveness and safety of the compound. Starting next month, about 10 healthy people will be administered NMN to see if can improve bodily function and stave off the effects of aging. Should it work, it would become the first bona fide anti-aging intervention available on the market.
NMN is an organic molecule, or nucleotide, found in a variety of nutritional sources, including milk. Previous studies have shown that it’s instrumental in slowing down the aging process, and it does so by activating sirtuin in the body—a class of proteins whose functions get weaker as the body ages.


Research by Shinichiro Imai of Washington University revealed that NMN activates the gene responsible for sirtuin. In one experiment, mice fed a steady diet of NMN experienced experienced improvements to age-related declines in metabolism and eyesight. In other experiments, NMN improved their glucose intolerance and lipid profiles. For mice, it’s like an elixir of life, but we still have no idea if it’ll work the same way in humans.
Biologists have successfully extended the life spans of some mice by as much as 70%, leading many…
Scientists have good reason to believe it won’t. Mice studies, particularly those involving aging, don’t translate well to humans. It’s unlikely that NMN will work as profoundly on humans as it does on mice—a tiny creature with a remarkably “plastic” lifespan.


That said, NMN could have a positive effect on human physiology, and a measureable one at that. Even if the effects aren’t as dramatic on humans as they are on mice, this compound could still be used to boost human health.
[The Japan News]

Beneath the hum of ship traffic and the chatter of marine life, another sound is emanating from the Caribbean Sea. It’s far too low pitched for humans to hear, but its signature can be detected from space. Scientists have never seen—or heard—anything like it.
Located southeast of the Gulf of Mexico, the Caribbean Sea features a large basin bounded by South America, Central America, and the Caribbean Islands. It’s a critical cog in the global circulation belt, forming currents that feed directly into the Gulf Stream. But when researchers at the University of Liverpool decided to study the dynamics of the Caribbean Sea, they noticed something odd.


“We were looking at ocean pressure through models for quite different reasons, and this region just didn’t work,” Chris Hughes of the University of Liverpool told Gizmodo, explaining how his models kept yielding large, inexplicable pressure oscillations across the basin. “It felt like a sore thumb.”
After spotting the weird oscillations in models, Hughes and his colleagues decided to see if they could observe the phenomenon in the ocean. Sure enough, they did. Combining pressure readings collected from the bottom of the Caribbean Sea between 1958 and 2013 with tide gauge records and data from NASA’s Grace satellite, the researchers discovered that the basin of Caribbean Sea acts like a giant whistle.


“You have a current that flows east to west through the Caribbean Sea,” Hughes explained. “It’s very narrow and quite strong. Just like a narrow jet of air, it becomes unstable and creates eddies.”

When those waves strike the western boundary of the basin, they die out and reappear at the eastern edge. This phenomenon, flashily named the “Rossy wormhole,” was first described several years back. Scientists now know that waves of certain shapes and sizes will resonate when they hit that western wall, just as certain frequencies resonate when you blow into a whistle. In both cases, the resonant frequency produces a sound.


But because the basin of the Caribbean Sea is so vast compared with an actual whistle, the resonant frequency is extremely low. It takes 120 days for waves to propagate east to west in the basin, yielding an A-flat tone that’s roughly 30 octaves below the bottom of a piano. A pitched-up version of that excessively eerie sound can be heard in the clip above.
Dubbed the “Rossby Whistle” in a paper accepted for publication in Geophysical Research Letters, the phenomenon can be detected from space owing to fluctuations in Earth’s gravity field as pressure changes propagate across the entire basin. The researchers plan to keep monitoring the Rossby Whistle, with the hope that the signal might be used to predict times of the year when coastal flooding is more likely.


So, if you ever find yourself out alone at night on the Caribbean, and the world feels completely still, just remember: it isn’t. The ocean is always speaking to you.
Hard to believe, but these two birds pictured above are the same age. The only difference is that the one on the right grew up in an urban environment. It’s an observation that’s raising questions about the health of birds and other urban animals—including humans.
Researchers from Lund University in Sweden have shown that birds of the species Parus major, commonly known as the nesting great tit, are at an increased risk of dying young when they’re reared in an urban environment. Biologist Pablo Salmón and team demonstrated that early exposure to an urban environment can disrupt the normal development of birds—with potentially irreversible effects on life expectancy.


“Although there are advantages to living in cities, such as the access to food, they seem to be outweighed by the disadvantages, such as stress—at least in terms of how quickly the cells of the great tits age,” said Salmón in a press statement. By stress, he’s referring to such things as noise and light pollution, and close proximity to humans (not to mention cats).
Salmón’s team discovered that the lengths of telomeres in urban great tits are shorter than those found in their country counterparts. Telomeres are located at the tips of each DNA strand in the body’s chromosomes, and they’re best described as a kind of age biomarker. Short telomeres imply short life expectancy, both in humans and great tits. This new study shows that the environment in which a bird is reared in can determine the length of their telomeres in a profound way.


The researchers studied a group of closely related great tits. Half of them grew up in the city of Malmö, Sweden, while the other half grew up in the country. After just two weeks, the difference in telomere lengths between between the two groups was already pronounced. Normally, genetics determines telomere length, but this study shows—for the first time ever—that growing up in a stressful environment can have an even greater impact.


“The impact that urbanization has on wildlife must be studied much more, or we won’t be able to understand the threats that birds are exposed to in urban environments, and won’t be able to do anything about them,” said Salmón. “Our results also raise questions concerning the aging of other animals affected by urbanisation, and humans for that matter.”
This study highlights the need for further research to assess the impacts of urban stress on other populations. It would be interesting to know if telomere lengths in humans are constrained by similar factors, for example.
However, bear in mind that only one species of bird was studied. Other birds, such as pigeons, robins, and blackbirds, seem to do well in city environments, as do animals like raccoons. The issue, it would seem, pertains to animals who are suffering from habitat loss, and who don’t fare well in cities.
[Biology Letters]
Bentley Yoder was born with his brain outside his skull. Doctors said he didn’t have a chance, but he not only survived—he thrived. Now, some seven months later, Bentley has undergone reconstructive surgery to move his brain back into his skull.
Bentley’s parents, Sierra and Dustin, both 25, found out something was wrong when they went in for a routine ultrasound at 22 weeks. Still in the womb, he was diagnosed with a rare condition called encephalocele, or cranium bifidum, in which parts of the brain protrude outside of gaps that have formed in the developing skull. The parents were told that their baby likely wouldn’t survive very long after birth, or that if he did he wouldn’t have any brain function; he was simply “incompatible with life.”


As Sierra told the Washington Post, “We had no hope whatsoever.” The parents were unwilling to terminate the pregnancy, saying they wanted at least one chance to meet him before saying goodbye.
To virtually everyone’s surprise, Bentley came out on his due date, October 31, 2015, kicking and screaming. After the first 36 hours, Sierra and Dustin had to take him home wearing the only onesie they bothered to purchase. Over the course of the next few weeks and months, Bentley continued to march on, save for a staph infection in his lungs.


Aside from the large sac containing critical parts of his brain atop his head, Bentley developed normally. He continued to grow, and cried when he was hungry. The doctors were incredulous, and insisted that the growth above his head was just “damaged tissue,” and that “there’s no way it could be functioning,” but Bentley’s behaviors and normal developmental trajectory suggested otherwise.
When Bentley turned four months, Sierra and Dustin took him to the Cleveland Clinic where a surgeon agreed that the infant was using his brain, but warned that it may not be possible to put it back in the cranium.
From there, they sought out Dr. John Meara at Boston Children’s Hospital, whose surgical team sees a few cases of severe encephalocele each year. After taking a look at Bentley, the surgeons realized that the parts of his brain located within the pouch could not be removed because they were responsible for cognitive functions such as motor control, problem-solving, and vision. The brain had to go back in, so they developed a plan.
Using 3D-printed models, the surgeons planned out and practiced the pending procedure. Bentley had 100 cubic centimeters of brain outside his skull, so the surgeons had to expand his cranium to accommodate it. Before the surgery, Meara had the benefit of working with a plastic model, which he sliced-up, and then sent back to the lab to assess how much more brain matter his team could fit inside the skull.
On May 24, the surgery began. This date was carefully chosen because Bentley’s skull was sturdy enough to withstand the surgery; any later, however, and the encephalocele might rupture. The first step was to drain the cerebrospinal fluid from Bentley’s brain. The surgeons made further cuts into the cranium, and then gently eased the brain back into his head. Leftover bone from the cuts were used to close the gap. The whole thing took about six hours. The surgery went well, though Bentley had to return for a pair of follow-up procedures to add a shunt and to drain excess fluid from his brain.


Nearly a month after the surgery, Bentley appears to be doing fine, but no one can be sure what his future holds. It’s quite possible that his vision is impaired, but it’s not clear to what degree. He will begin physical therapy next month. “Because of how different his brain really is, [we] have no one to compare him to,” Sierra told WaPo, adding, “We just have to take it step by step.”
[Washington Post, STAT]
Do you get squeamish when someone dies on Game of Thrones? Or maybe you’re worried your favorite character is about to get killed, and you can’t bear to watch. Researchers at MIT have developed an algorithm that can predict what’s going to happen next in a video, giving you an opportunity to look away first.
The algorithm, developed at MIT’s Computer Science and Artificial Intelligence Laboratory, is slowly trying to learn a skill that humans spend their entire lives refining and perfecting. Through countless interactions and experiences with others, we’re able to accurately predict what will happen when two people meet or depart—be it a handshake, a hug, or a kiss.

To give an algorithm the same intuitions on human behavior as we all have, the researchers had it analyze countless hours of YouTube, as well as TV series like The Office and Desperate Housewives. When given a still frame from one of those videos, the algorithm searches for patterns and recognizable objects—hands, human faces, etc.—and attempts to predict their motion in order to conclude where they’ll end up, and what they might do there. For example, two faces getting closer frame-by-frame is a good indicator that two people are about to kiss.


How does it do? After analyzing some 600 hours of raw video (with no explainers or descriptors) the CSAIL algorithm could correctly predict the correct action (hugs, handshakes, high-fives, or kisses) about 43 percent of the time when shown a video that’s one second before it actually happening.
What does this mean for you? Nothing yet. The researchers hope that one day algorithms like this could help improve how robots interact with humans. But we’re going to hold out for automatic video captioning letting us know that when a sword is drawn on Game of Thrones, you’d better look away fast if you don’t want to see heads flying.
[MIT CSAIL]
A classic 18th century astronomy catalog of galaxies and nebulae is the inspiration for Deep Sky Companion, a series of 110 pairs of paintings and photographs of objects visible in the night sky by artist Lia Halloran, currently on exhibit at Caltech in Pasadena California.
The daughter of a physicist, Halloran’s work has always been informed by science. For Deep Sky Companion, she drew inspiration from the catalog of objects compiled by French astronomer Charles Messier in the 18th century. Messier actually made the catalog out of frustration. He was hunting for comets and wanted to rule out other objects in the night sky that might impede his search. He had no idea he was observing entire galaxies and interstellar nebulae.


When her father gave her a Celeron telescope one Christmas in college, Halloran discovered the joy of amateur astronomy. As she writes in the exhibition catalog:
“Viewing Saturn from my rooftop was somehow far more impactful on me than the jaw-dropping images from the Cassini satellite because I could experience space, and understand that I was in fact a space traveler on a celestial rock, looking out at another rock traveling in space. Observing the Orion Nebula and nearby galaxies seemed to create a fold in time between myself and Messier. I would imagine his observing sessions and the drawings he made through his telescope to classify the natural world and make sense of the unknown above him.”
There’s science behind her method of creating the pieces too. For the current exhibit, Halloran used the same cyanotype printing process she used for Your Body is a Space That Sees, an homage to women astronomers throughout history, from Hypatia and Caroline Herschel, to Cecelia Payne, Henrietta Leavitt, and Jocelyn Bell.


She started by creating paintings of the Messier objects—all 110 of them—using blue ink on drafting film. Then she used that as negative to make positive prints of her paintings on photosensitive paper using the conventional black-and-white darkroom printing process. It just happens to mimic early astrophotography using glass plates.

When it came to displaying her work in Caltech’s signature Cahill Center, the building’s unique architecture presented a challenge, with its slanted ceilings and odd asymmetric planes. The solution: crop the paintings into a series of circles and scatter them throughout Cahill’s exotic stairwell, bringing a sense of what it’s like to view objects in deep space to the experience.
Deep Sky Companion will be on exhibit at Caltech’s Cahill Center for Astronomy and Astrophysics through December. You can check out more of Halloran’s work on her website.
A closer examination of the fossilized remains of a 110-million-year-old snake-like creature suggests that snakes evolved in the water, and not on land as previous research suggests.
Scientists aren’t sure if snakes evolved on land or in the water, but the recent discovery of a remarkable fossil in Brazil seemed to suggest a terrestrial origin story. Last year, a group of scientists led by Nicholas R. Longrich put out a study arguing that this snake-like creature, named Tetrapdophis amplectus, was a terrestrial animal.


But a new study published in Cretaceous Research challenges this assumption. The authors argue that T. amplectus was more closely related to aquatic lizards, and that these snake-like forebears evolved their long bodies for eel-like swimming.
Aside from its four paddle-like limbs, this Cretaceous-era animal had a head and body that closely resembled those of modern snakes. But it also featured a short tail, which the earlier research suggested was indicative of a creature capable of burrowing into the ground. According to this interpretation, T. amplectus was a worm-like digger that evolved to live underground. The authors said its tiny arms and legs weren’t used for locomotion, but for grasping on to prey.


But Robert Reisz and his colleagues at the University of Toronto at Mississauga have interpreted the fossil a bit differently.
“The limbs are most striking in being short, but paddle shaped, ideally suited for swimming and steering, but definitely not for digging,” he told Gizmodo. “I think this animal was quite happy in the water.” What’s more, Reisz says it shares features with aquatic lizards from the Late Cretaceous.
Reisz says that this animal’s long, slender tail, along with its four slender legs, isn’t consistent with characteristics seen in burrowing snakes and lizards alive today. What’s more, its limb bones appear weak and poorly ossified, i.e. the process in which cartilage is transformed into bone.
Both of these traits, says Reisz, are characteristics of ancient marine lizards such as mosasaurs. He believes this creature is likely a close relative of snakes, but it’s probably “not a snake proper.”


Reisz and his colleagues believe that the stubby little legs are highly specialized because of its shape, and not because of this animals’ small size. Plenty of animals develop long, slender bodies for swimming, not only snakes. Reisz points to fish, salamanders, and lots of extinct ancient amphibians and extinct and extant reptiles as examples.


“There is, in fact, a group of ancient snake-like amphibians that went back to the water secondarily, only a few million years after vertebrates ventured for the first time on land,” he said. But as to why this animal abandoned aquatic life in favor of a limbless existence still remains a mystery.
This examination was performed on the only known fossil of Tetrapdophis amplectus, which was discovered in the Crato Formation in Brazil. Scientists are going to need more samples, and possibly the remnants of other snake-like ancestors, to get a clearer picture of where these ancient creatures came from, and why snakes evolved their long, limbless bodies.
[Cretaceous Research]

Researchers from the University of Washington are the first to visualize the insidious way that the flu virus latches onto a cell and plows its way inside, causing an infection.
Using advanced electron microscopy, a team led by Kelly Lee sequenced the stages of membrane fusion—the process in which two separate biological entities merge to become one. Specifically, they chronicled the merger of the influenza virus and a small lipid vesicle (or liposome), which was used as a stand-in for a cellular membrane. (Using a whole cell was impractical for the type of microscopy used in the study.) Their results now appear in the latest edition of the Journal of Virology.
“What we’ve done is to image the different steps that take place as the virus’ fusion machinery start to manipulate the target membrane barrier so as to be able to open up a hole and spill its genome cargo into the cell,” Lee told Gizmodo.
This process occurs over the course of several stages. First, the flu virus throws out short peptide segments that essentially work like grappling hooks. These peptides grab onto the target membrane, and then alter their structure to pinch together the two membranes.


The virus then snuggles up against its target, creating even larger zones of contact between the two objects. These contact sites begin to unzip and break down, opening up a channel from the virus into the interior of the liposome. The virus then delivers its genome cargo to start a new infection.
“Basically, these viruses have evolved nanoscopic machines that respond to triggers and change their structure like transformers,” said Lee. “They really are tiny machines that carry out surgery at the nanoscopic biological scale.”
The researchers say the exact same process happens when the virus attacks and infiltrates a real, full-sized cell. Any virus that has a membrane—such as the flu, herpes, HIV, measles, and ebola—is equipped with similar molecular machinery. This enables them to invade cells— and they do so by ripping open the membrane barriers that are in its way.


Antibodies can target this machinery, locking them into place so that the virus can’t change its structure, or preventing it from binding to the target.
In addition to helping with research into these antibodies, Lee hopes that his team’s work will also help to improve the understanding of other critical biological functions, such as sperm-egg fertilization and signaling across nerve synapses.
[Journal of Virology]

The US Centers for Disease Control and Prevention has granted clinical trial approval for an experimental Zika vaccine. The drug, which will be tested on a small sampling of human participants, arrives a mere five months after the World Health Organization declared Zika a public health emergency.
The vaccine, named GLS-5700, is a collaborative effort between Inovio Pharmaceuticals of Pennsylvania and GeneOne Life Science of South Korea. Earlier today, the companies announced a phase I study with 40 healthy subjects to evaluate the safety, tolerability, and efficacy of the drug.


“We are proud to have attained the approval to initiate the first Zika vaccine study in human volunteers,” noted Inovio CEO J. Joseph Kim in a statement. “As of May 2016, 58 countries and territories reported continuing mosquito-borne transmission of the Zika virus; the incidences of viral infection and medical conditions caused by the virus are expanding, not contracting.”
The company plans to start clinical trials in a few weeks and expects to report the results later this year. Should things go well, the vaccine will be promoted to phase II clinical trials. It certainly appears that things are moving quickly—and they most certainly are as far as these things go—but it could still take years before GLS-5700 can be used in the field.


During preclinical testing, this vaccine proved its worth in animal models, “demonstrating the product’s potential to prevent infection from this harmful pathogen in humans.”
Here it is, folks—our first glimpse of that abominable virus that’s been wreaking havoc in parts of …
It’s pretty remarkable that clinical testing for a disease that only attained emergency status a few months ago has already been slated for clinical testing. Up until recently, scientists knew very little about this obscure virus that was deemed largely harmless. But as we now know, Zika can cause severe birth defects, including microcephaly. Clearly, the urgency of the situation has prompted the pharmaceutical industry to push things forward.


It also helps that Zika, as a mosquito-spread flavivirus, is similar to Dengue and West Nile—disease for which vaccines are already under development. Scientists did not have to start this experimental new Zika vaccine from scratch.
[Inovio]
Every doting cat owner will attest to the innate intelligence of their beloved pet, and now Japanese scientists say they have evidence that felines have a rudimentary grasp of cause and effect. They described their results in a new paper in Animal Cognition.
“Cats use a causal-logical understanding of noise or sounds to predict the appearance of invisible objects,” lead author Saho Takagi of Kyoto University said in a statement.


Past studies have shown that hearing may dominate vision in cats. Takagi co-authored a study last year demonstrating that cats use their keen sense of hearing to infer the presence of an object even when they can’t see it. That conclusion was based on the fact that cats in the earlier study looked at a container longer when it rattled when being shaken. But there was still the possibility that visual and other environmental cues were skewing the results. So Takagi designed a new study to remedy that.
The latest experiment involved 3o domestic cats, most housed in “cat cafes” (a trend now spreading across the globe), along with eight house cats whose owners volunteered their services. Each cat was taken to a private room in a familiar setting—either their cat cafe, or a private home—and one of the researchers (or cat owner in the case of private pets) held the cat in place for the experiment.
Then one of the scientists shook a plastic container containing an object made of three iron balls in front of the cat. Sometimes there was a rattling sound, sometimes there was not, thanks to a switch-controlled electromagnet that, when pressed, caused the iron object to stick to a stainless steel plate at the top of the container.


When the container was turned over, sometimes the object fell out, and sometimes it didn’t (thanks to that handy electromagnetic switch). The cat’s reaction was videotaped as it was then allowed to freely explore its environment.
There were four experimental conditions: a rattling sound where an object fell out of the container, a rattling sound where no object fell out, no rattle and no object, and no rattle and an object falling out.
The results: All the cats were most interested in containers that rattled. But they also spent more time watching those containers that did not conform to the usual laws of cause and effect (a rattle but no object, and no rattle with an object). For Takagi, this suggests the cats use sound to predict whether an object would fall out when the container was turned over, and puzzled over the incongruity when the conditions didn’t match that causal logic.
Why would cats have developed a rudimentary causal reasoning based on sound cues, in contrast to, say, great apes, who seem to rely heavily on visual cues? Takagi et al. argue that the development of such a cognitive ability makes sense because cats need to be able to detect the presence of prey while hunting in environments where visibility is limited. “These ecological restrictions may promote formation of representations of unseen objects from their noises,” the authors write.


So it seems that cats are great intuitive physicists, at least when it comes to basic concepts like cause and effect—and possibly gravity. But the kitty contingent won’t be coming up with a theory of quantum gravity any time soon. Lest you start to think your fabulous feline is a genius, here is an adorable kitten fiercely fighting its own reflection in a mirror (also check out that same kitten watching itself fight itself in the mirror—so meta):

[Animal Cognition]
Blue Origin just launched its crew capsule into space—and then intentionally brought it in for a very soft crash.
Blue Origin’s reusable rocket, which just made its fourth trip to space, hit an apogee of 331,501 feet. It then touched down easily, like we’ve seen in previous flights. But the real action on this test was to see what happened to the crew capsule it was carrying.
Blue Origin is launching its crew capsule today—and then they’re going to take out its parachute…
Instead of using three parachutes to soften its landing, Blue Origin intentionally failed one to see how it would do with just two. Blue Origin’s commentators during the event said that it would hit the ground at a speed of just 1-2 miles per hour, but the company’s speed monitor appeared to show it at around 20 miles per hour as it hit the ground.


Still—despite that heavy cloud of dust it kicked up at touchdown—the capsule appeared intact at the end. Although, for a full-workup of how the capsule did, we’ll need to wait until Blue Origin retrieves it and checks it out. Assuming all went well, that same rocket and capsule will go back up in a future test flight.
Update 6/20, 10:15 am: Blue Origin spokesperson Julie Arnold contacted us to say that the landing speed shown by Blue Origin’s speed monitor—which in their broadcast is shown as going directly from 19 mph to 0 mph—was not its actual landing speed.
“The retro rocket fires a fraction of a second before touchdown. The mph on the screen did not update fast enough to show the true speed at touchdown,” said Arnold in an email. The speed after the retro rocket fire, says Arnold, was 1-2 miles per hour.
Blue Origin is launching its crew capsule today—and then they’re going to take out its parachute and see what happens. You can watch it happen at 10:15 am ET.
As we noted on Friday, this livecast is a first for the company that has typically preferred to conduct its launches in secret. It’s also notable for the fact that seven minutes into the flight, Blue Origin will intentionally fail one of the parachutes designed to safely land the capsule. Although the company hopes back up measures will safely guide it to the ground all the same, a crash is still a pretty probable outcome.
Blue Origin, the notoriously-secretive space company, is launching its New Shepherd crew capsule…
The webcast will kick-off thirty minutes prior to the launch at 9:45 am ET this morning. You can watch the whole thing right here.

We’ve all noticed how those last few Cheerios in the cereal bowl seem to cluster together in the center and along the edges. It’s called the “Cheerios effect.” Now an international team of physicists has discovered a reverse Cheerios effect. They described their results in a new paper in the Proceedings of the National Academy of Sciences.
The Cheerios effect may not be an especially exotic phenomenon—we also see it in pollen floating atop a pond, and the foamy heads of beer—but the actual physical mechanisms at work weren’t clearly outlined until a 2005 paper in the American Journal of Physics. The culprits: buoyancy, surface tension, and something called the “meniscus effect.”


Buoyancy is what determines whether something will sink or float, while surface tension is a property arising from water molecules pulling on one another in a dance of mutual attraction. The liquids essentially cling to each other so tightly that they form a kind of skin over the top of the liquid.
The meniscus effect is what happens when you place a single Cheerio in a bowl of milk. Its mass will form a dent in the milk’s surface. Place a second Cheerio in the bowl, and it will do the same. If the two Cheerios are close enough together, they will drift toward each other. It’s a microcosm of general relativity, whereby the mass of the Sun warps the fabric of spacetime, pulling the planets into orbit around it. Place yet another Cheerio near the edge of the bowl, and it will follow the curve of that meniscus, looking for all the world like it’s clinging to the edge of the bowl.


And now there’s a way to get an inverted Cheerios effect, by swapping the roles of Cheerio and liquid. This latest work explores what happens when you have liquid drops resting on a soft solid surface. Even better, the physicists discovered they could actually control how those liquid drops clustered together across that surface, simply by making the surfaces softer or harder, or changing the thickness of that soft layer.


“The droplets deform the surface on which they live, and due to this deformation, they interact—somewhat reminiscent of general relativity, from which we know that galaxies or black holes interact by deforming space around them,” co-author Stefan Karpitschka, now at Stanford University, said in a statement. “What is remarkable about our case though is the fact that the direction of the interaction can be tuned by the medium, without modifying the particles themselves.”

The original Cheerios effect led to advanced materials and insight into how galaxies collapse via gravity. Its inverse also has lots of potential applications, according to co-author Lorenzo Botto of Queen Mary University of London. “[T]he physical phenomena we have highlighted in this paper suggest ways to design surfaces that prevent fogging or control heat transfer,” he said. This would make it possible to “create car windows that are always transparent despite high humidity or surfaces that improve heat management in conditioners or boilers.”
[Proceedings of the National Academy of Sciences]
Why exactly do cheerios stick to each other in milk? Doomed love between Os? Tiny magnets?…
Do you enjoy eating mussels? Cool, same. Something, however, is happening to mussels as we know them. And it’s changing them in a pretty horrifying way.
A team of researchers from the University of Chicago has been comparing the shells of live mussels pulled from the Pacific coast today with historical shells, some of them thousands of years old. They’ve come to an alarming realization: Mussel shells are getting thinner and thinner.


Shells collected that are over 1,000 years old are on average 27 percent thicker than today’s shells, the researchers note in new paper in Proceedings of the Royal Society B. Thick shells were the norm until about the 1970s, when shells were 32 percent thicker than they are today. Then, things suddenly started to get thin fast.
The unsettling cause for the thinning shells is the rapidly acidifying waters of the Pacific Ocean. Essentially, the mussels are in the process of a slow dissolve in the acid bath they now spend their lives stewing in.


If the thought of being slowly consumed from all around as you swim isn’t quite horrifying enough, the researchers project that this is only the beginning of the bad news for yummy shellfish. With an ocean that’s only growing more and more acidic, we could easily see mussels—with their new brittle bodies—die out.


[Royal Society B]

Blue Origin, the notoriously-secretive space company, is launching its New Shepherd crew capsule this weekend. And, for the first time, you’re going to be able to watch it happen—right up to a pretty probable crash-landing.
The plan is to launch New Shepherd using one of its BE-3 rocket engines and begin some maneuvering tests of the capsule. But, seven minutes into the flight, something alarming is going to take place: one of the capsule’s parachutes is going to fail. On purpose.


Although New Shepherd is designed as a crew capsule, it will be empty on this run, which is an attempt to stress test the capsule. Like the old Apollo flights, New Shepherd uses a triple parachute combo to add drag to the capsule as it comes in for a touchdown.
In 1971, Apollo 15's crew capsule experienced exactly the same parachute failure scenario, with one of the three failing to open as it splashed down into the Pacific Ocean. All the crew members inside were unharmed, but the capsule did go through what NASA described as a “hard impact.”


Blue Origin CEO Jeff Bezos said in an emailed statement that he believes his capsule will be capable of “safely handling” a parachute failure and even a resulting crash-landing, thanks to a shock-absorbing crushable structure. The intention, though, is to use the capsule’s “retro rocket” system—which kicks in when New Shepherd is just feet above the ground—to avoid the crash altogether.
“On this flight, we’ll intentionally fail one string of parachutes on the capsule. There are three strings of chutes and two of the three should still deploy nominally and, along with our retrothrust system, safely land the capsule,” said Bezos. “Works on paper, and this test is designed to validate that.”
But, despite those measures, as he also tweeted this morning, “And of course–development test flight–anything can happen.”
The New Shepard launch was originally supposed to take place today, but a leaky gasket in the capsule’s nitrogen gas pressurization system grounded the capsule. The launch was instead pushed to Sunday morning.
Previous Blue Origin launches have been heavily-shrouded from the public, with the launches often remaining secret until well after they had been successfully-completed. Competitor SpaceX used the opposite approach, releasing not just livecasts of all its launches—crashes and all—but also typically multiple views.


In just the last few months, Blue Origin has started to open up its process slightly, letting reporters into its facility for the first time. This, however, is the first launch that it will share with the public directly and not after the fact. And it’s no coincidence that it’s starting with a test of the New Shepard capsule.
Bezos has said that he wants to start operating space tourism flights within the next two years, by 2018. The New Shepard and the BE engine series that is launching it this weekend is exactly the same combination he’s identified as the probable vehicle for those tourism goals, shuttling up flights of six tourists at a time to experience brief bouts of weightlessness.
As the time when Blue Origin is going to attempt to book customers draws closer, broadcasting what is—essentially—an abilities-showcase and a safety test for that capsule/engine combination makes sense. We’ll be back on Sunday to see how it goes.


Correction: It is actually the BE-3, and not Blue Origin’s new BE-4 rocket engine, that will be flying on Sunday.

In news that offers hope that human civilization won’t end up drowning in soda bottles and plastic wrap, Chinese chemists have developed a remarkably efficient method for converting polyethylene into liquid fuel. If it proves scaleable, it could make a real dent in global plastic pollution.
Polyethylene is the most common plastic on Earth. Worldwide, our factories churn out some 100 million tons of the stuff each year. Composed of carbon and hydrogen atoms linked together in long chains, polyethylene is a remarkably inert substance, meaning it doesn’t react with much of anything, and therefore doesn’t degrade in the environment.


People have spent decades trying to figure out a better method for disposing of polyethylene, to replace our current approach of just letting it tumble into the ocean. You can stick plastic in a furnace and burn it at high temperatures, but that process is energy intensive, polluting, and results in a slew of nasty byproducts that are often just as hard to degrade as polyethylene itself. The recent discovery of plastic-munching microbes has ignited hopes that we might be able to degrade polyethylene naturally, but so far, biological degradation has proven difficult to scale up.
Zheng Huang, an organic chemist at the Chinese Academy of Sciences, has spent the last four years developing a different approach. Writing today in Science Advances, Huang and his colleagues describe their method for degrading polyethylene at temperatures as low as 150 degrees Celsius, by adding an organometallic catalyst—a small, commercially available organic molecule doped with the metal iridium—to the reaction. The catalyst weakens bonds responsible for polyethylene’s stiff structure, accelerating its breakdown into a liquid product.


“Our products are much cleaner than those obtained by conventional [combustion] methods,” Huang told Gizmodo, adding that his method is also easier to control and can be used as a diesel fuel. It’s been proven on small samples of plastic bags, bottles, and food packaging.


The challenge, of course, will be scaling up from grams to tons if we want to make a dent in the mountains of plastic waste that litter our planet. “The first challenge is the efficiency of the catalyst,” Huang said. Right now, his procedure works well at a plastic-to-catalyst ratio of roughly 30 to one. “That’s not good enough if you want to commercialize,” he continued. “We want to see ten thousand to one, or a million to one.”
Huang’s team is also looking into replacing iridium—a rare and precious metal in the platinum family—with a cheaper alternative, although this may prove more difficult, given the highly specific nature of metal catalysts.
“We think that the future potential is there—as long as we can improve the efficiency and reduce the cost of the iridium,” Huang said. “Hopefully, very soon we can scale up the process from gram scale in the lab to kilogram and even ton scale.”
I hope so, too. A vehicle that runs on 100 percent recycled LEGO bricks sounds rad. The alternative — a future where the oceans contain more plastic than fish — sounds bleak as hell.

Good news alien hunters! A Kickstarter to fund a year-long investigation into KIC 8462852—the star voted most likely to harbor an advanced alien civilization—just got funded. Alien megastructure or not, we may finally get to the bottom of this bewildering, flickering star.
This crowdfunding campaign was set up in May by Yale astronomer Tabby Boyajian, and it managed to meet its $100,000 goal in just 30 days. A $10,000 surge in the last 100 minutes of the campaign managed to put the project over the top. The next step is to figure out the logistics, but Boyajian, who’s been leading the research into KIC 8462852, says observations could start as early as later this summer.


The ultimate goal of the project will be to determine why this star’s light dims at such irregular intervals, and at times by as much as 20 percent. These huge dips in luminosity are way too large to be a passing planet, hence the suspicion the anomaly is being caused by swarms of comets, a distorted star, some unknown astronomical phenomenon—or an advanced alien civilization in the process of building a gigantic solar array around the star.
KIC 8462852 has quickly become one of the biggest astronomical mysteries of the decade. It’ll be…
Boyajian will now be able to secure year-long access to the Las Cumbres Observatory Global Telescope Network. Should the system spot any further anomalies, an alert will be sent out to other astronomers, who will then turn their own telescopes to the star.


The most important thing right now is for astronomers to get more consistent data, and to replicate existing findings. KIC 8462852 was first flagged by citizen scientists who were perusing through troves of data collected by NASA’s Kepler Space Telescope between 2009 and 2013. Some fresh observations—particularly incoming signals in real-time—would be nice. Should new dips in luminosity be detected, astronomers should be able to pick out patterns.
Last year, speculation mounted over whether or not KIC 8462852 might be an alien megastructure, perhaps a Dyson sphere. The star is probably not enveloped by a Dyson sphere, but that shouldn’t preclude scientists from looking for signals that may prove or disprove its existence. If this star is being obstructed by a megastructure under construction, it should emit detectable signals in the form of blackbody thermal radiation. The point of a Dyson sphere is to collect solar energy, but leakage is still likely to happen. If a partial Dyson sphere is there, we should still be able to detect it in the form of irregular, but discernable, radiation signatures.
[Kickstarter]

Last Friday, Joanne Barnaby went mushroom picking in a forest near Fort Smith in the Canadian Northwest Territories. It was an inauspicious beginning to what would end up being a 12-hour ordeal, one involving a desperate wolf, swarms of mosquitoes, an unwitting bear cub—and a can of beer.
Barnaby, along with her dog, Joey, and friend Tammy Cauldron, went looking for morel mushrooms in a forest recently ravaged by wildfires. The two friends eventually became separated, leaving Barnaby alone with Joey. Once her pail was full, she headed back towards her truck—and that’s when the trouble started.
“I heard this growl behind me,” she told the CBC. “There was a long, tall, very, very skinny wolf. A black wolf. And his legs were spread and his hair was standing, and he was growling and baring his teeth.”


Joey charged, but the wolf didn’t back down. Barnaby saw that the wolf was desperate, telling the CBC that he looked weak, old, and unhealthy. “I don’t think Joey expected that,” she said.
The wolf began to force the duo away from the truck and highway. And then it dawned on Barnaby: the wolf was deliberately trying to wear her down and separate her from Joey. Over the course of the next 12 hours, the wolf remained relentless, pushing the two further and further away from the truck. “I was in trouble,” she said.


She soon became dehydrated, and her calves and thighs began to ache. The only thing she had with her was a can of beer, which she later described as a “silly choice.” Adding insult to injury, the wolf wasn’t the only thing she had to contend with. “I was going crazy with mosquitoes,” she said. “There were zillions of mosquitoes.”
Then, around 4:30 in the morning, she stumbled upon a bear cub. She made the incredibly risky move of approaching the cub, knowing the mother was nearby. She thought the mother might tackle the wolf if she felt it was a threat, so she made the harrowing choice of walking towards the cub. Incredibly, her plan worked. After luring the wolf to the cub—and then making a hasty exit—shit hit the fan.


“I heard this big crashing behind me and realized that the mama bear had attacked the wolf, or maybe the other way around, I don’t know, but they were fighting and I could hear the wolf yelping and I could hear the mama bear growling and I could hear all this crashing and I just took off!,” she told the CBC.

That was the last she heard of the wolf, but not the mosquitoes, which were still driving her insane. Barnaby and her dog found eventually found a lake, where they were able to replenish themselves. The empty beer can became handy after all, and Barnaby joked that it actually saved her life. They later found a road and were rescued soon thereafter by the Royal Canadian Mounted Police. And as you can tell from the photo she sent to the press, Barnaby was very happy to get back to civilization.
[CBC]
Next week, a federal advisory committee is set to review a proposal to use CRISPR—the cheap, powerful and buzzy gene-editing tool—on human patients for the first time.
The Recombinant DNA Advisory Committee, a panel that works with the National Institutes of Health, will examine a proposed cancer treatment experiment that uses CRISPR/Cas9 technology, according to a blog post from the NIH. The experiment involves removing T cells from cancer patients. Then, using CRISPR, researchers would genetically modify the T cells so that when they’re put back into the patient, they go after myeloma, melanoma, and sarcoma tumor cells.


MIT Tech Review reports that the proposal comes from researchers at the University of Pennsylvania, and indeed, a draft of next week’s agenda includes a presentation from Edward Stadtmauer, a professor of medicine at UPenn. A biotechnology company called Editas Medicine had said it would begin its own CRISPR trial in 2017, but it now appears UPenn might get there first.
Gene editing in humans has been done before, but the new CRISPR/Cas9 technology is theoretically easier and more efficient to use.


“Researchers in the field of gene transfer are excited by the potential of utilizing CRISPR/Cas9 to repair or delete mutations that are involved in numerous human diseases in less time and at a lower cost than earlier gene editing systems,” the NIH said in its blog post.


It’s important to note that in UPenn’s proposed experiment, the gene therapy is somatic, not germline, which means that whatever genetic alterations are made won’t be heritable. This generally falls in line with NIH’s previous calls for caution around using CRISPR technology to mess with the human gene pool.
If you’re excited about the future of gene editing in humans and want to tune in, the RAC meeting will be publicly available via livestream which can be found here.
[MIT Tech Review]
Most people have a modest two-octave vocal range when they sing, but some rare talents can manage five octaves or more. Think the late great, Freddie Mercury of Queen, or Guns N’ Roses’ Axl Rose, although composer-singer Tim Storms holds the Guinness World Record for the largest vocal range: a whopping 10 octaves.
It’s all the more impressive when you consider that singers accomplish this using just two strings—the vocal cords—compared to, say, a piano’s 88 strings. But what determines that vocal range in the first place? A new paper in PLOS Computational Biology suggests that it all comes down to the stiffness and “stretchiness” of the vocal cords, which can be thought of as a bit like two guitar strings glued together with gelatin.


“It’s absolutely amazing how nature has created a compound, laminated string to cover a pitch range that is difficult, by any stretch of the imagination, to cover with one string,” lead author Ingo Titze, director of the National Center for Voice and Speech at the University of Utah, said in a statement.
The vocal cords really are an impressive bit of anatomy, human or otherwise. As I wrote for Scientific American back in 2011:
The most critical component of the vocal tract is the larynx, or voice box. Attached to the trachea just behind the Adam’s apple, the larynx is made of various types of cartilage and a single bone called the hyoid. Together they provide a framework for the vocal folds, flaps of mucous membrane attached to muscles either side of the larynx. Sound is produced when air from the lungs flows through the trachea past the vocal folds and sets them vibrating. Contracting the muscles alters the shape, position and tension of the vocal folds, which in turn change the pitch of the resulting sound: the stiffer the vocal folds, the faster they vibrate and the higher the pitch they produce.
When we’re born, our vocal cords are mostly gelatinous, but we develop fibers within that gel as we age. So mature vocal cords are more like guitar strings laminated with gelatin, with cross-linked fiber layers that can stretch and contract. Some layers might have more tension than others when vocalizing, but because of those cross-links, they still all vibrate together.
Working with Midwestern University’s Tobias Riede and Ted Mau of the University of Texas Southwestern Medical Center, Titze studied the larynges of 16 species, from mice to humans to elephants.


Larger animals have larger bodies, and hence larger vocal tracts, so it’s not surprising that the researchers found a strong correlation between body size and the average frequency (mean pitch) a given animal could produce. But they found size was not a good basis for a model to predict a given animal’s full vocal range.
“What’s going on inside the larynx that allows this quite different outcome for pitch range across species, where the mean pitch is so well correlated with size?” Titze wondered.
It turns out that measuring how far an animal’s vocal cords can stretch is a much better predictor of its vocal range. The other predictive factor is stiffness, determined by all those fibers within.
According to Titze, this research could lead to better exercises for singers to increase their vocal ranges. It may also ultimately lead to better treatments for damaged vocal cords. When the character Chloe develops nodes on her vocal cords in the 2012 hit film, Pitch Perfect, she opts for surgery, which destroys her upper vocal range. Better treatments could help singers like Chloe regain most of their range after surgery.
[PLOS Computational Biology]
A team of researchers just confirmed the presence of oxygen in a galaxy 13.1 billion light years away—the furthest oxygen has ever been detected. Their findings suggest that this may have been the first oxygen to form in the early universe.
Hailing from the National Astronomical Observatory of Japan and a number of Japanese universities, the scientists based their conclusions on observational data collected by the Atacama Large Millimeter/submillimeter Array (ALMA) observatory. They discovered the galaxy, SXDF-NB1006-2, just four years ago, and have been trying to identify the elements that are present ever since. They describe their findings in a new paper published in Science.


As expected, the galaxy contained hydrogen. But the team was much more curious about the potential presence of oxygen, which they hoped would give key information about how the element formed in the first place.
If oxygen was present, their models of the galaxy suggested that it would be undergoing the process of cosmic re-ionization, where space radiation ionizes clouds of gas. As the gas re-ionizes, it also releases a tremendous flare of light, like you see happening in this simulation of the process over a 5 million year timelapse:

Video: S. Chon / University of Tokyo


Because the flare is so bright, researchers hoped that, even at a distance of 13.1 billion light years, they would still be able to detect it with ALMA. Their hunch payed off: A sweep with ALMA found a telltale flare showing that oxygen is present.
That doesn’t mean it’s anything close to the oxygen we breathe today. For starters, there’s just not that much of it. The amount is fairly tiny—less than one-tenth of the oxygen found in the sun. This has implications for the age of that oxygen.
“The small abundance is expected because the universe was still young and had a short history of star formation at that time,” co-author Naoki Yoshida of the University of Tokyo said in a statement. “In fact, our simulation predicted an abundance ten times smaller than the Sun.”
On Earth, the presence of oxygen is tied to the presence of life, especially our own. The discovery of oxygen so far away raises questions about the possibility of life out there—either native life forms or perhaps an environment ripe for colonization by us. But this oxygen wouldn’t be something we could breathe.


“The detected oxygen is actually doubly-ionized oxygen atoms, and not oxygen molecules which we breathe,” lead researcher Akio Inoue of Japan’s Osaka Sangyo University told Gizmodo. “So, we could not breathe in the 13.1-billion-light-year-away galaxy we observed if we were there.”
Although this oxygen couldn’t support life as we know it, Inoue said that this discovery does lead us down a fascinating path: It helps answer the question of where—and when—oxygen formed in our universe in the first place.


“These oxygen atoms we found are a kind of the first oxygen ever produced in the Universe, because oxygen did not exist at the Big Bang. In fact, all elements heavier than lithium are produced inside stars and are spread out the Universe when they die,” Inoue told us. “And oxygen and other elements make up dust particles which eventually make up planets and possibly life on them. Therefore, our finding shows the origin of oxygen, one of the most important elements for humans, in this Universe.”
Now that the researchers have confirmed the presence of oxygen, their next step is to try and figure out how that oxygen moved away from that galaxy. With that information, they hope untangle even more about just what the presence oxygen means to life in our universe.
A new study published in the New England Journal of Medicine suggests that Zika-infected women who are in their third trimester have virtually no chance of having children with microcephaly. Troublingly, the same study shows that women who exhibit no symptoms can still give birth to babies with brain abnormalities.
The Zika virus has been at epidemic levels in South and Central America since the summer of last year, yet many questions remain unanswered. The disease has been linked to microcephaly and other birth defects in offspring, though it’s not clear why Zika affects some fetuses and not others. A new study conducted by scientists in Colombia—a country that has reported over 65,000 cases of Zika thus far—is helping to answer some of these questions, though they admit the results are still preliminary.


The researchers looked at 1,850 pregnant women who were infected with the Zika virus between August 9, 2015 and April 2, 2016. Their research shows that women who are infected with Zika during the third trimester (week 27 until the end of the pregnancy) have virtually no chance of giving birth to a baby with birth defects. When the researchers looked at a subgroup of the pregnant women who had given birth and had knowledge of the precise week of their Zika infection, more than 90 percent who were infected during the third trimester had given birth—yet not one of them gave birth to a baby with microcephaly or any other detectable brain abnormalities. That’s a relief.
It’s important to point out, however, that many of the women involved in the larger study are still pregnant. A follow-up study in the coming months will paint a clearer picture of how Zika affects fetuses in the first and second trimesters. Given that the first trimester is critical for neuronal development, this is likely the time when fetuses are most vulnerable. But little is known about the disease’s impact during the middle part of the pregnancy.


Of significant concern, however, is the observation that asymptomatic mothers (i.e. mothers who were infected with Zika but displayed no obvious symptoms) can still give birth to babies with birth defects. Four of the babies looked at in the study had microcephaly, yet their mothers showed no signs of the disease.


This is a real problem because symptoms only appear in about one in five people infected with Zika. Symptoms include fever, rash, joint pain, and headache, and they typically disappear after about a week. But for most people, they have no idea they even have it.
For those couples who are actively trying to get pregnant and may have had exposure to Zika, these CDC guidelines should answer any questions.
[New England Journal of Medicine]

On May 23rd, something extraordinary happened at the South Pole. For the first time in 4 million years, carbon dioxide concentrations cleared 400 parts per million (ppm). It’s the last climate-monitoring spot on Earth to pass the historic milestone.
The South Pole is experiencing the same relentless warming trend as the rest of our planet, but owing to the fact that most of humanity’s carbon emissions are occurring far, far away in the northern hemisphere, the atmosphere at the bottom of the world takes a little time to catch up. It finally has, according to new data from the South Pole Observatory.


“The far southern hemisphere was the last place on earth where CO2 had not yet reached this mark,” Pieter Tans, the lead researcher at NOAA’s Global Greenhouse Gas Reference Network said in a statement.
Carbon dioxide concentrations rise and fall annually, but we’ve also witnessed a steady upward trend since we began collecting round-the-clock observations at Hawaii’s Mauna Loa Climate Observatory in 1958. That station, which recorded CO2 levels of a cool 310 ppm in the late 1950s, broke 400 ppm for the first time in 2013. Since then, 400 ppm readings have become the frightening norm—the world passed that threshold for an entire month last year, and thanks in part to El Niño, 2016 will likely be the first year in the history of our species where global average CO2 concentrations exceed 400 ppm.


It’s possible that the South Pole Observatory will see its carbon readings dip below 400 ppm in the future. The same cannot be said for the planet at large. Barring a large-scale geo-engineering effort, the atmosphere will remain carbon-loaded for thousands of years to come, even if everybody on Earth stops using fossil fuels tomorrow.
As climate scientist Ralph Keeling recently put it, “we are now in a new era of Earth history.” It’s up to us to decide just how different that new era will look.
[NOAA]

Astronomers have detected a small asteroid that doesn’t seem to want to go away. Called a quasi-satellite, this new companion circles around the Earth as it orbits the sun—and it’s going to stay that way for the next few hundred years.
Technically speaking, this newly discovered asteroid, dubbed 2016 HO3, is in orbit around the sun. But as it makes this annual trek, it’s also circling around the Earth. It’s far too distant to be considered a true natural satellite of our planet, but it’s a good example of a quasi-satellite, or near-Earth companion.

This little guy, which measures somewhere between 120 to 300 feet (40-100 meters) across, never ventures too far from Earth. As it orbits the sun, asteroid 2016 HO3 spends about half of the time closer to the sun than Earth, and passes ahead of our planet. The other half of the time it falls behind.


It’s also in a tilted orbit, which causes it to weave up and down on the orbital plane like a bob on choppy waters. As NASA’s Paul Chodas put it in a press statement, “In effect, this small asteroid is caught in a little dance with Earth.”
Over the course of many years, the asteroid starts to drift inwards and outwards, but Earth’s gravity is strong enough to ensure that its new companion doesn’t venture too close or too far. It never gets further than about 100 times the distance of the Earth to the Moon, and never closer than about 38 times the distance of the moon, or about 9 million miles (14 million km). So it’s not a threat to our planet.
Asteroid 2016 HO3 was detected in late April by the Pan-STARRS 1 asteroid survey telescope in Hawaii. Calculations suggest that the asteroid became a quasi-satellite about a hundred years ago, and that it’ll stick around for centuries to come.


Seeing as that’s the case, can we please give it a better name than 2016 HO3?
[NASA]
It’s always fun to melt your brain from what looks like the laws of physics breaking. Therefore, it’s always fun to see a pilot pour water up into a cup while upside down in a fighter jet. It’s something we’ve seen plenty before, but this view is especially cool. You get to see the entire process happen so clearly: the pilot pours the water while the plane twists around, the pilot drinks the water while it flips around, and then he holds the cup of water out for good measure as the plane goes upside down and doesn’t miss a single drop.
It’s a neat effect! And there’s no magic behind it. Wired explained it quite well:
If you could just see the water from a stationary reference frame (maybe a floating hot air balloon), you would see the water indeed falling down. Now, I remember that I said “falling down” and not “moving down”. The water actually might be moving up. The key is that even though it is moving up, it is accelerating down. The plane also is accelerating down. As long as the downward acceleration of the plane is greater than the water, the water will move into the cup above it.
If you want an even more detailed break down, head there for it.


On the list of things you’re not advised to do in closed quarters with a limited oxygen supply, lighting a fire definitely ranks high. But this week, NASA did exactly that: the agency intentionally ignited a “large scale fire” aboard a spacecraft.
Has our benevolent space agency finally lost its mind? Not exactly. NASA has been planning the pyrotechnic experiment, dubbed Saffire I, for some time now. The fire was ignited remotely yesterday evening, aboard an Orbital ATK Cygnus resupply vehicle that undocked from the ISS stuffed full of space trash several hours earlier. It was the first in a series of three planned fire experiments, which, as Gizmodo reported in March, seek to better understand the dynamics of fire in microgravity so that our astronauts will be well-prepared should they ever come face-to-face with this nightmarish possibility.

The experiment took place in a 3-feet-by-3-feet-by-5-feet sealed box containing a sheet of cotton fiberglass test material. Images and a slew environmental data—including temperature, O2 and CO2 levels—are now being transmitted to Orbital ATK and engineers at NASA’s Glenn Research Center, who will be analyzing the results over the coming weeks. Two additional Saffire experiments are scheduled to fly aboard future resupply missions.


Although the space agency has yet to release images, a press release issued this afternoon calls the experiment a “success.” We are going to assume that’s code for “there is no large, out of control, flaming ball of space trash whizzing overhead faster than a speeding bullet right now.”
While we wait for photographic proof, NASA has released some, er, teaser graphics. I guess you could say the journey to Mars is going to be lit.
Update 6/16/16:  NASA has just received video footage from the aforementioned space fire. The flashing green light is from LEDs installed in the flow duct to aid with exposure. Preliminary data indicates that the test sample burned for approximately 8 minutes.

[NASA]
The results of a FDA inspection into a Whole Foods prep kitchen—which mixes up those ready-to-eat meals and snacks perfect for an impulse buy—have been revealed. Prepare to be nauseated.
The agency released a copy of the warning letter it sent to Whole Foods about the sorry state of a prep kitchen that makes the foods served in 74 different Whole Foods locations all along the US Northeast.


The warning letter describes conditions in which condensation from the roof and pipes was dripping directly into food prep areas—often around uncovered foods, including veggie trays, mushroom quesadillas, and some kind of unspecified pesto-pasta mix. Investigators also noted a number of problems with the kitchen set-up and equipment. Most alarmingly, some kitchen equipment tested positive for non-pathogenic forms of Listeria—and that meant that conditions were also ripe for the formation of the Listeria associated with food poisoning.
The FDA says they first contacted the grocery retailer with a written list of concerns in February. Whole Foods responded at the time, but this week’s warning letter from the FDA complains that the company’s response didn’t include specifics about fixes for the problems:
FDA has serious concerns that our investigators found your firm operating under these conditions. Further, your response includes retraining of employees as a corrective action for most of the observed violations but you failed to mention adequate supervision over your specialized food processing operations and how retraining will ensure sustained compliance. We do not consider your response acceptable because you failed to provide documentation for our review, which demonstrates that all your noted corrective actions have been effectively implemented.
Whole Foods responded by saying that it was “surprised” to receive the letter and had already taken “thorough and tangible steps” to solve the problems—although it didn’t give details on what those steps had been.


The grocer now has 15 business days to provide those details for every problem outlined—along with the documentation to back it up—to the FDA.
Six months after researchers in China bioengineered monkeys to have autism, a Japanese team of scientists has used the same technology to create monkeys with Parkinson’s. It’s a scientific first, and it could lead to effective treatments—but do the ends justify the means?
As reported in New Scientist, a team led by Hideyuki Okano from the Keio University School of Medicine in Tokyo has used genetic engineering to create a marmoset monkey with Parkinson’s disease. The researchers unveiled the monkeys last month at a meeting in Alpbach, Austria, and say they’ve also bioengineered monkeys to mimic Alzheimer’s disease and motor neurone disease. These monkeys are now three years old, and they’ve already started to exhibit the tell-tale signs of Parkinson’s.


As fellow primates, monkeys are ideal candidates for this type of medical research. As noted, scientists in China have already built autistic monkeys, and thanks to the CRISPR gene-editing tool, there are plans to create monkeys with an assortment of other human-specific diseases, including schizophrenia and severe immune dysfunction.
These animals are increasingly being seen as viable research subjects because humans and monkeys share similar brains and bodies. At the same time, medical experiments on great apes are being phased out, while research on mice is limited in scope. Also, the lack of public support for primate research in North America and Europe is not shared in Asia. As it stands, there are currently 40 breeding companies working in China which have collectively produced nearly 300,000 monkeys, all of which could be used for scientific research.


To create the Parkinson’s monkeys, Okano’s team isolated a mutated version of a human gene called SNCA, which is linked to the disorder. Writing in New Scientist, Andy Coghlan explains what this modified gene is doing to the marmosets:
In the three years since the engineered marmosets were born, they developed Parkinson’s symptoms in the same way people do. This began with signs of sleep disturbance in their first year, followed by the appearance of a-synuclein-associated globules, known as Lewy bodies, in their brain stems the next year.
By their third year, the monkeys began to show the characteristic tremors associated with the condition. As further evidence of how similar these monkeys are to humans with Parkinson’s, Okano showed that their tremors could be eased by giving them L-DOPA, a drug given to people with Parkinson’s to make up for the lack of dopamine.
Some scientists are excited about the opportunity to study Parkinson’s in a nonhuman model, but critics say there’s no guarantee these results will translate to humans. It’s also worth pointing out that most human diseases aren’t caused by a single faulty gene, so these monkeys will likely be of limited clinical relevance.


Finally, there’s the ethics of it all. Given the severity of Parkinson’s symptoms, this type of animal experimentation is both cruel and unusual. As Princeton bioethicist Peter Singer has said, “Animals are an end unto themselves because their suffering matters.”


[New Scientist]
For the second time this year, physicists at the Advanced Laser Interferometer Gravitational Waves Observatory (LIGO) are giddy with excitement. They’ve just confirmed the second detection of gravitational waves, ripples in the fabric of spacetime proposed by Albert Einstein a century ago. It seems we’ve officially entered the age of gravitational wave astronomy.
In February, LIGO physicists made history when they announced that a large spacetime ripple had swept across their detectors in Livingston, Louisiana and Hanford, Washington on September 14th, 2015. The ripple emanated from the final stages of two merging black holes located 1.3 billion light years away and weighing 29 and 36 solar masses, respectively.
Since Albert Einstein first predicted their existence a century ago, physicists have been on the…
LIGO’s second gravitational wave signal came just three months after the first, on December 26th. Again, it’s the result of the spinning dance of a binary black hole pair on the brink of merging, although this duo weighed only 8 and 14 solar masses. When they coalesced at a distance of 1.4 billion light years, they created a black hole 21 times the mass of the sun, while transforming another sun’s worth of mass into a burst of gravitational energy.


The discovery was announced this afternoon at a meeting of the American Astronomical Society in San Diego, CA, and has been accepted for publication in Physical Review Letters.

“Just the fact that we’ve now seen more than one [gravitational wave source] is very exciting,” said MIT’s David Shoemaker, who led the Advanced LIGO construction program. “It takes us out of the ‘gee whiz, could it be true?’ mindset to yes, this is a tool that we can use.”


When the heaviest objects in our universe slam together in the most powerful collisions, they send shockwaves, not unlike ripples in a pond, emanating across spacetime. Called gravitational waves, these cosmic jitters are incredibly faint, on the order of a billionth the diameter of an atom. But they’re happening around us; offering a window into our universe completely unlike that which we observe via the electromagnetic spectrum. If electromagnetic waves are the universe’s visuals, gravitational waves are its music.
That, at least, has been the theory for the past century. But ripples this small require highly precise experiments to detect, and the most advanced experiment on Earth—LIGO, which uses laser beams to measure tiny wobbles in distance between mirrors separated by several kilometers—didn’t have the chops until recently. LIGO first came online in 2002, but turned up nothing definitive for years. Then, following five years of upgrades from 2010 to 2015, LIGO was reborn as Advanced LIGO, which boasted three times the sensitivity of its predecessor. When Advanced LIGO began collecting data last fall, it detected gravitational waves almost immediately.


“The first event was huge—it knocked us off our feet,” Shoemaker said, referring to the waveform picked up at LIGO’s twin detectors in Hanford and Livingston in the wee hours of the morning on September 14th.
“My first thought was that it was a test,” Gabriela Gonzales, a physics professor at Louisiana State University and spokesperson for LIGO Livingston, told me in February. “Within a matter of hours, we figured out that it was not.”
Still, the team spent the next five months meticulously validating the discovery, determined to rule out every possible source of environmental disturbance or human error before going public. (A few physics tweeps had some trouble keeping their mouths shut.)
Excited rumors began circulating on Twitter this morning that a major experiment designed to hunt…
The second signal, which came just three months later, was different. “The objects are about as far away but because they are lighter, it’s a much weaker signal,” Shoemaker explained. “We had to be more careful to look for airplanes, lighting strikes, seismic noises, people dropping hammers—all the things that could go wrong.”


Although trickier to distinguish from the background hum of the Earth, gravitational waves produced by weaker collisions do have one advantage when it comes to detection: they move more slowly. It took the spacetime ripple on December 26th a full second to pass through LIGO’s detectors, as opposed to the previous signal, which coursed through our planet in a fraction of that time.
“This is significant because we were able to start describing what was happening during the extraordinary event,” said Federico Ferrini, director of the European Gravitational Observatory (EGO), which hosts VIRGO, a gravitational wave detector located in Italy.


In fact, the signal was so stretched out that researchers observed one black hole spinning about the other, making approximately 50 rotations while in the band of LIGO’s detectors. Spin can tell us about an object’s formation history—perhaps this twirling vortex of darkness used to be a neutron star, before consuming matter from its surroundings, gaining angular momentum, and collapsing into a black hole. But we’re going to need to survey many more pairs of black holes in order to fully understand their formation history and dynamics.
And with a proven gravitational wave detector, we can now do exactly that. “The first event was realizing a dream,” Ferrini said. “Now we have a second, and in the future we’ll have more. It means we’ve really entered the era of gravitational wave astronomy, and we can start to do statistics.”


With just two events, LIGO has already yielded important insights into the size distribution of black holes and the frequency of mergers. Before the first detection, nobody was sure that 30 solar mass black holes even existed. The second event is also rather exceptional compared with the black holes humans have identified via x-ray observations, which are all in the range of several solar masses. Every subsequent event will constrain our theoretical predictions even further.
Gravitational waves also offer a first-of-its-kind tool for observing the behavior of cosmic objects that emit no light. “Gravitational waves have such a weak interaction with everything that they come in a straight line from their source to us,” Shoemaker explained. “Consequently, we can see the deep interior motion of objects [like black holes and neutron stars], in a way we can’t with electromagnetic radiation.”
Or, as Jorge Cham of PhD Comics so deftly put it, “Imagine your whole life you had been deaf until one day your hearing was restored.”


What can we expect to hear in the months and years to come? Advanced LIGO’s first observational run ended in January, and the experiment is currently undergoing more improvements. Its next run is slated to begin this fall, and with slightly better sensitivity, it’ll be able to listen for gravitational waves over a broader swath of space. (A nice property of living in a three-dimensional universe is that if we improve the sensitivity of a detector by a factor of two, we can scan a volume of space eight times larger.)
Around the same time, Advanced VIRGO, the EGO’s souped-up detector, is expected to come online with a sensitivity close to that of LIGO. Adding another detector halfway around the world will allow scientists to better localize the source of gravitational waves in the sky. “With three observational points thousands of kilometers apart, triangulation in the sky is much more precise—from a few hundred square degrees to tens of square degrees,” Ferrini said.


That means in the future, astronomers might be able to turn their telescopes in the direction of a gravitational wave signal and actually pinpoint the source.


“It will be exciting, as we get more detections and do further analyses in the years to come, to disentangle the clues about where these black holes come from,” Penn State physicist and LIGO collaborator Chad Hanna said. “Now that we are able to detect gravitational waves, they are going to be a phenomenal source of new information about our galaxy and an entirely new channel for discoveries about the universe.”
Gizmodo will be interviewing several LIGO and VIRGO researchers at the AAS meeting later this afternoon. The interviews will be streamed on Facebook Live, and this post will be updated with a video. Stay tuned!
Update: here’s the Facebook Live!


The disturbing Fermi Paradox suggests we should have made contact with an extraterrestrial civilization by now, yet we haven’t. By applying a 500-year-old philosophical principle, a Cornell University researcher has shown that the Great Silence is not unexpected—we just need to give it more time.
In a new study that will be presented at an American Astronomical Society meeting later this month, astronomers Even Solomonides and Yervant Terzian combine the Fermi Paradox with the Mediocrity Principle to show that we shouldn’t expect to hear from aliens for another 1,500 years. The reason has to do with the vastness of the Milky Way Galaxy, the time it takes radio signals to propagate through space as well as the apparent “averageness” of humanity in the larger scope of things.
Most people take it for granted that we have yet to make contact with an extraterrestrial…
“It’s possible to hear any time at all, but it becomes likely we will have heard around 1,500 years from now,” noted Solomonides in a press statement. “Until then, it is possible that we appear to be alone—even if we are not. But if we stop listening or looking, we may miss the signals. So we should keep looking.”
As physicist Enrico Fermi noted nearly a half-century ago, the Milky Way may be huge and full of stars—200 billion give or take a few—but there’s been more than enough time for aliens to have made their presence known in one form or another. Many solutions have been posited to answer this apparent paradox, but nothing conclusive.


The mediocrity principle, devised by the 16th century mathematician Copernicus, suggests there’s nothing unusual or special about Earth, humanity, and our place in the cosmos, and that if anything we’re actually quite banal in large scheme of things.
“Even our mundane, typical spiral galaxy—not exceptionally large compared to other galaxies—is vast beyond imagination,” said Solomonides. “Those numbers are what make the Fermi Paradox so counterintuitive. We have reached so many stars and planets, surely we should have reached somebody by now, and in turn been reached... this demonstrates why we appear to be alone.”
It’s because of this incredible vastness, says Solomonides, that we haven’t received a signal from an alien civilization. Take our situation here on Earth, for example. For the past eight decades, we’ve been broadcasting radio signals, and they’ve been spreading out into space like an expanding bubble. Aliens who receive our radio messages would have to detect them first and then recognize them as being alien. And then they’d have to go about the daunting task of deciphering our signals. That said, Earth’s radio broadcasts have reached every star within about 80 light-years of the sun, reaching about 8,531 stars and possibly as many as 3,555 Earth-like planets.


This might sound like a lot, but Solomonides says this is a drop in the bucket. It only represents about 0.125 percent of the planar area of the Milky Way. Logically, these same parameters applies to alien intelligences. So, for us to have been reached by alien signals so far, we would need to be in a rather special, proportionally tiny area of the galaxy. “And we know we’re not special,” write the researchers.
Realistically, therefore, we shouldn’t expect to hear from another alien civilization until at least half of the Milky Way has been signaled, which won’t happen for another 1,500 years. That’s not to say we won’t make contact by then, or that if we don’t, aliens don’t exist. The researchers simply claim that it’s “somewhat unlikely that we will not hear anything before that time.”


The researchers also took the age of the Milky Way Galaxy into consideration, and calculated that humanity is somewhere in the median 90 percent of the population of galactic species as far as broadcasting history is concerned. This means humanity is not among the first nor last five percent of civilizations to develop radio transmitting technology. Quite pessimistically, they figure that there have been fewer than 210 intelligent communicating civilizations in galactic history, implying that we are among the first to develop radio broadcasting technology. The researchers also figure that the average civilization has been broadcasting for about 80 years, and that the upper limit for radio broadcasting is about 1,600 years.
“[We] expect to have heard from an alien civilization when approximately half of the galaxy has been reached,” write the researchers in their study. After applying the Mediocrity Principle to the Drake Equation (an open-ended calculation that seeks to predict the number of radio transmitting alien civilizations in the Galaxy) and other factors, they calculate that alien radio signals would need to propagate out for about 1,580 years before half of the galaxy is reached. Should we not hear from aliens by that time, the researchers say it would be “disconcerting,” and the Fermi Paradox would emerge as a relevant problem.
An interesting conclusion, to be sure, but this study—which has yet to be published in a peer reviewed journal—has some problems. First, it exclusively assumes classical SETI is the mode of interstellar communication. As time passes, we’re learning that there are a significant number of ways for alien intelligences to make their presence known to one another.
For the past 50 years, our efforts to detect extraterrestrial civilizations have largely focused on …
Second, Solomonides and Terzian grossly underestimate the degree to which radio signals degrade over vast distances. For an alien civilization to detect a radio signal thousands of light-years away, they’d have to focus massive arrays of radio antennas for protracted periods of time (from months or years at a time) at a single spot in the sky. Seems unlikely, and a horrible waste of resources.


Finally, the researchers also fail to address an important aspect of the Fermi Paradox, namely the suggestion that aliens eventually embark on interstellar colonization. Previous calculations have shown that the Milky Way, due to its extreme age, could have been colonized many times over by now (recent work shows it should take less than a billion years, perhaps even as little as a few tens of millions of years). This possibility is completely overlooked in the new paper.
So while encouraging, this paper doesn’t offer a definitive solution for the Great Silence. The Fermi Paradox is still a relevant problem, one that even the Mediocrity Principle can’t sufficiently address.
[arXiv]

After a string of successful ocean landings, SpaceX’s latest Falcon 9 rocket crashed hard right into its drone ship.
A pair of satellites is going up this morning on one of SpaceX’s Falcon 9s. Will the rocket pull…
Just as the Falcon 9 was touching down on the Of Course I Still Love You drone ship, SpaceX’s feed cut out, leaving both those watching at home and the company clueless as to whether or not the rocket had landed safely. The rocket was visible upright on the pad for a moment between the smoke clouds. But something happened (perhaps a tip-over, like we saw earlier this year, or it simply came in too hard or fast), and the rocket was destroyed, according to SpaceX.
SpaceX’s Falcon 9 came very close to sticking the landing on a drone barge earlier today, but…
SpaceX had chalked up a streak of successful drone ship landings—including a few tough ones from geostationary orbits—so this crash may seem like a step backwards, but that’s not quite the case. Every landing SpaceX has attempted has been slightly different as the company experiments with different orbits and methods. Crashes are nothing new for the company—they’re almost an expected part of the process as the engineers figure out how to adjust those orbits for the highest possible success.
Yes, we could watch that gif of the Falcon 9 rocket landing itself on a drone ship all day long.…
Although this rocket didn’t stick its landing, both satellites attached to the rocket were successfully deployed into space. We’ll update you on just what happened, as we find out the details.


Update 10:15 am: It appears the problem with this landing stems from insufficient thrust from one of the rocket’s three engines. Elon Musk  described the problem on Twitter as an “RUD=Rapid Unscheduled Disassembly :)”.
Engineers have apparently already begun working on a solution that would let the other engines compensate for such problems. Musk estimates that the fix should be ready before the end of the year.
Update 10:40 am: Although the rocket may not have emerged from today’s launch, the satellites both did quite nicely. Here’s some lovely footage of the ABS satellite as it heads off into space.


Musk also said that the footage of the crash, which he described as “maybe [the] hardest impact to date”, from the drone ship’s POV is on its way later today.
The drone ship, fortunately, emerged from its encounter unscathed.


Many of us keep our coffee beans in the fridge or freezer to keep them fresh, but a new study suggests there’s added benefit to this practice: more flavorful coffee.
Scientists from the University of Bath, in collaboration with a local cafe, studied the effects of grinding beans at different temperatures—from room temperature all the way down to a chilly -196°C. (I guess they figured some people like to store their coffee beans in vats of liquid nitrogen.) As the researchers point out in their ensuing study, now published in Scientific Reports, we get more bang for the buck when we grind cold coffee beans. That’s because the particles within coffee beans get tighter as the temperature gets lower. So during the brewing process, we get more flavor from the same amount of coffee.


Like almost anything in the kitchen, brewing coffee is an act of chemistry. Ideally, we’re trying to coax as many tasty organic molecules from the roasted bean, which has been ground into tiny bits. The flavors that come of of these coffee bean particulates depend on a number of factors, including water chemistry, the accessible surface area of the coffee, and as the new study shows, the temperature of the bean when it was ground. As the researchers point out, small and uniform coffee grounds allow for better extraction of the flavor compounds, which allows for more coffee per bean, and consequently more flavor.
“What you’re looking for is a grind that has the smallest difference between the smallest and largest particle,” noted Christopher Hendon, a chemistry PhD student at the University of Bath. “If you have small grinds you can push flavor extraction upwards. We found that chilling the beans tightens up this process and can give higher extractions with less variance in the flavor—so you would have to brew it for less time or could get more coffee from the same beans.”


Hendon said this alters the taste of coffee because “subtle changes in particle size distributions make a huge difference in rate of extraction.” His team’s research also suggests that the temperature of the bean needs to be more constant to achieve consistent grinds, and that cooler temperatures maximize surface area, allowing more of the coffee bean to be utilized.


Study co-author Maxwell Colonna-Dashwood, the co-owner of Colonna & Smalls, believes this will have a major impact on the coffee industry, both in terms of how baristas might choose to brew their coffees, and how providers will store and ship their goods to vendors.
“All of this will impact on how we prepare coffee in the industry, I bet we will see the impact of this paper in coffee competitions around the globe, but also in the research and development of new grinding technology for the market place,” said Colonna-Dashwood. For example, this might mean that it’s okay to cryogenically store coffee.
Interesting study! It certainly bolsters the idea that we should keep our coffee beans as cool as possible. As with any study involving taste, a truly good cup of coffee lies in the taste buds of the beholder. In this context, more flavor doesn’t necessarily imply better. But who likes bland coffee?
[Scientific Reports]

A pair of satellites is going up this morning on one of SpaceX’s Falcon 9s. Will the rocket pull off a double-satellite launch and ocean landing as neatly as it pulled off its singles? Let’s watch and find out!
This particular Falcon 9 will be pulling double duty. It’s launching two separate communication satellites within 5 minutes of each other, first one from Eutelsat and then one from ABS.


The Falcon will be delivering those double satellites into a high, geostationary orbit. That means the rocket is coming back to the Of Course I Still Love You drone ship hot, fast, and with not a lot of extra fuel to spare. It’s also a new experimental orbit so—while SpaceX has had a pretty solid run of previous landings from geostationary orbits—success at this one is likely to be, by the company’s own admission, “difficult.”
When SpaceX managed to safely land its 3rd Falcon 9 rocket ten days ago,  Elon Musk tweeted that…
SpaceX has been teasing that an upcoming launch will use one of those previous, successfully-landed Falcon 9's that are now piling up in their hangar. That milestone, however, isn’t coming today. Elon Musk has suggested instead that we could finally see a Falcon 9 re-launch sometime in September or October, but no firm date is set as of yet.


Watch along with us right here at 10:29 am EDT, when the Falcon 9 and its two satellites blast off. If all goes well, we should see used-rocket number 5 piling up in the SpaceX hangar shortly after.


Volcanic lightning is one of nature’s most epic displays, but what exactly causes the phenomenon is a longstanding mystery. Now, by studying high-speed footage of electrified volcanic outbursts at Mount Sakurajima, scientists have arrived at an answer—and it points to a new method for predicting powerful eruptions.
Most of us are familiar with how lightning forms in thunderclouds, when negatively charged particles at the bottom of the cloud are drawn to positively charged particles on the surface of the Earth. Eventually, this electrostatic attraction can overcome the insulating properties of the air, producing a giant electric spark.


While similar in terms of its physical characteristics, volcanic lightning is different in the sense that it forms much closer to the ground within erupting volcanic plumes, and doesn’t necessarily propagate downwards. A team of researchers at Ludwig-Maximillian University in Munich have conducted a detailed study of volcanic eruptions at Japan’s Mount Sakurajima, one of the most active volcanoes on Earth, to figure out why.
Combining high-speed video footage of eruptions and acoustic measurements of Mount Sakurajima’s electromagnetic field, the researchers determined that volcanic lightning occurs due to the electrification of rising ash particles by magma. They further showed that volcanic lightning (top video) is generally restricted to the lower part of a developing ash plume—within a few hundred meters of the crater’s rim—where turbulent jets of magma produce a complex charge distribution. Only in one instance (bottom video) was lighting observed in the upper “buoyant” part of the plume.


“At Sakurajima as well as at other volcanoes the electrification seems to be primarily determined by the plume dynamics,” the researchers write in their paper, which appears this week in Geophysical Research Letters.


The study also revealed an unexpected correlation between the frequency of lightning flashes and the total volume of ash released. The amount of ash a volcano will spew out is hard to predict during an eruption, but not so for electrical discharges. “This is a parameter that can be measured—from a distance of several kilometers away and under conditions of poor visibility,” lead study author Corrado Cimarelli said in a statement.
This means that, eventually, scientists could start using volcanic lightning to predict the size of an ash cloud and issue early warnings about air quality following eruptions. Even if you don’t live in a volcanically active area, there’s cause to be excited about this: it means plenty more stunning photos of volcanic lightning to come.
[Geophysical Research Letters]
Okay, poster. You make a compelling argument—sign us up!
True, there will be obstacles: For one, the Martian corps that these recruitment posters from Kennedy Space Center are attempting to enlist us in does not exist. Also, as of yet, no human has ever stepped foot on the surface of the red planet, much less worked some kind of shadowy night-watch position, that (rather terrifyingly) appears to require the constant use of a space harpoon.


But, no matter! The can-do spirit of these WWI- and WWII-influenced posters has already inspired us. We will be teachers, and welders, and farmers, and satellite technicians, and guards against the Martian night-octopuses that presumably overrun its lunar plains. Just let us know when those enlistment rolls open up.
Full resolutions, suitable for printing on your own, are also publicly available right here.
All images via Kennedy Space Center
Using some of the world’s most sophisticated telescopes, a pair of astronomers has discovered a first-of-its-kind organic molecule in an enormous star-forming cloud thousands of light years away. And it could shed light on one of most poorly-understood properties of life on Earth.
The molecule, propylene oxide (CH3CHOCH2), is chiral, meaning it can form “left-handed” and “right-handed” versions that are perfectly symmetric and have identical physical properties. Chiral molecules will be familiar to anybody who’s taken an intro biology course—they form the backbone of DNA and the building blocks of proteins. But oddly enough, the chiral molecules underpinning our biology are either left- or right-handed, never both.


How this pattern of single-handedness, or “homochirality,” emerged on Earth is a mystery. Now, the first discovery of chiral molecules beyond our solar system could lead to answers.
“Chirality is really important for biology,” said Brandon Carroll, one of the two lead authors on the study published today in Science. “All amino acids [on Earth] are left-handed, and it lets them build really big and interesting proteins. DNA’s double helix structure is based entirely on the fact that it uses right-handed sugars for the backbone.”
While the biological advantages of homochirality are obvious, what’s less clear is how this unique property of life emerged and why certain molecules exist in the left- or right-handed version. Given that the building blocks of life—simple chains of carbon, hydrogen, and oxygen—probably came from outer space, studying patterns of chirality beyond Earth offers a tool for peering into our distant past.


To date, astrobiologists have found chiral molecules buried in meteorites on Earth and in samples collected on the surface of comets. “The link between chiral molecules in space and life on Earth is the evidence we see in meteorites, where there’s a slight excess in [left-]handed amino acids,” Carroll said. “If you want to understand where that excess comes from, studying interstellar clouds is the earlier link.”
Which is exactly what Carroll, and his co-author Brett McGuire, have spent the last the last few years doing. They’ve focused their research on Sagittarius B2, a cloud of interstellar dust that weighs as much as 250,000 suns and is situated some 28,000 light years away toward the center of our galaxy. SagB2 is something of a Holy Grail for astrobiology—the vast majority of the molecules ever discovered in space have been spotted in its swirling, radiation-bombarded dust. “It’s just the best place to find molecules,” McGuire told Gizmodo.
Piggybacking on years worth of radio emissions data on SagB2 collected by the National Radio Astronomy Observatory, Carroll and McGuire recently began a search for propylene oxide, one of the smallest and simplest chiral molecules. After identifying some promising spectral features in the dataset, they independently confirmed the presence of propylene oxide using the Parks Radio Observatory in Australia.
“If you add up all of the propylene oxide we found, it weighs about four fifths of an Earth,” Carroll said, adding that while this sounds like a lot, it pales in comparison to the size of the SagB2 cloud, and is just at the limit of our detection threshold. Larger, more complex chiral molecules are expected to be even rarer, and will prove more difficult to spot.


But we may not have to find other chiral molecules in interstellar space to glean important insights into the origins of homochirality on Earth. “Even if we can’t detect other chiral molecules, if we can measure an excess of handedness in propylene oxide, that’ll be useful for understanding the processes driving chiral molecules in one direction or another,” Carroll said.


It may be that because of how organic molecules form in interstellar clouds, any life that emerges anywhere in our galaxy is always going to be biased toward certain patterns of chirality. Perhaps left-handed proteins and right-handed genetic code are fundamental traits of life everywhere. Maybe the patterns that emerged on Earth are influenced by more local processes. Or maybe they’re just random.
To start distinguishing these possibilities, McGuire and Carroll are now trying to determine the chirality of the propylene oxide they’ve observed. “The technology exists, but the observations are time intensive and take a lot of effort,” McGuire said, explaining that chemists use polarized light to determine the chirality of organic molecules in the lab all the time. “Nobody has ever tried to do this in astronomy.”
But it’s a worthy challenge, not just because of what it could reveal about our past, but because of its implications for humanity’s future. If and when we discover life on other worlds, will it be built according to a similar or different blueprint? Will it be “compatible” with our biology?


These are the sorts of question science fiction authors have been playing with for years, and the answers could have real consequences for our ability to survive on other planets. As Carroll put it, “If you ate a cheeseburger on a world that was a different chirality, I don’t know if it would be poisonous, or you just wouldn’t digest it—but it wouldn’t be compatible at all.”


“Homochirality is a very useful tool, and it’s not unreasonable to expect life to exploit it elsewhere,” McGuire said. “By studying these astrophysical processes, we may eventually be able to look at a star and say whether life on the planets around it should be this or that handed.”
And hey—any research that’ll help humans determine whether a planetary system is fit for colonization or a wasteland of indigestible lunch meats sounds like a solid investment in our future.

See that tiny speck just to left of the bluish orb? That’s a planet. It’s one of the best direct images of an exoplanet we’ve ever seen, and it’s made all the more remarkable given that it’s a whopping 1,200 light-years away.
Although you can’t see it, there are actually two planets in this remote star system, dubbed CVSO 30. Four years ago, astronomers used the transit method (where an orbiting planet causes a dip in the host star’s brightness) to detect the first planet, which is parked quite close to its host star. This inner planet requires just 11 hours to make a complete orbit and is located a mere 0.008 au (744,000 miles) from its T-Tauri star (a young, bright star that hasn’t quite entered into its main sequence).
Astronomers have now detected a second planet (the one shown in the photo), and they did so using direct imaging. To do it, they combined data from the ESO’s Very Large Telescope (VLT) in Chile, the W. M. Keck Observatory in Hawaii, and the Calar Alto Observatory facilities in Spain.
Unlike its companion, this second planet, dubbed CVSO 30c, is exceptionally far from its star. In fact, it’s so far that astronomers aren’t entirely sure if it even belongs to this planetary system. It’s at a distance of 660 au, requiring a mind-boggling 27,000 years to complete a single orbit. For comparison, Neptune is located 30 au from our Sun. The astronomers speculate that the two planets may have interacted at some point in the past, shooting one away while the other settled in its tight orbit.


Given its brightness, there’s a good chance it’s a Jupiter-like planet. Rocky planets tend to be darker and not very reflective.
If scientists are able to confirm that CVSO 30c orbits this star, it’ll be the first star system to host two planets that were detected by two different techniques, the transit method and direct imaging.
[ESO]

Winemaking is always an exercise in uncertainty. You don’t really know just what the wine will taste like until the very end of the process, which is sometimes decades long. A new technique, however, could help predict what wine will taste like before it’s even made.
A paper out today in mBio from researchers at the University of California Davis details an extensive survey undertaken of over 700 different Napa and Sonoma wines, beginning in 2011. Before the fermentation process began—when the future wine was just grape juice—the researchers DNA sequenced the juice to identify the mix of microbes present within it. They then compared those results with analyses of their finished wines and found that they were able to link chemical compounds associated with flavor and taste to the microbial juice profiles.


Senior author of the paper David Mills of the University of California Davis’ Mills Laboratory said that this information suggested a new avenue for how we describe the tastes of wine. “Wineries often communicate to their consumers via vintage descriptions in terms of vineyard location, combined with specific weather and grape qualities of that particular harvest,” Mills told Gizmodo. “Perhaps the microbial ‘vintage’ profile might be similarly discussed in the future.”
The information isn’t just descriptive, however. Mills also suggested that the microbial profiles could eventually help winemakers in replicating particularly good vintages or, alternately, avoiding bad ones.


“By tracking this routinely, winemakers might be able to score ‘good’ vs. ‘bad’ microbes associated with grapes that might influence their wine,” Mills said. “Winemakers might change things ahead of time if they see microbes associated with bad outcomes or manipulate vineyard conditions to get the right regionally-linked microbial consortia on their grapes.”


Of course, the microbial profile of juice is one of many factors that shapes a wine’s overall flavor. Still, it puts us one step closer to untangling just what it is that gives a good wine such a unique taste.

Until recently, only six frog mating positions had been documented—which is still five more than most people would have ever expected—but as New Scientist points out, a seventh froggystyle position has been found. It’s messy.
Before you go taking sex advice from the Bombay Night Frog, let it be known that the “dorsal straddle” position, as the newly discovered mating style is called, involves no actual genital contact. I guess frogs are kinky like that. Instead, the male frog grabs onto the limbs of the female and covers her back in sperm. As she lays her eggs the sperm drips down, fertilizing them. Good luck getting that image out of your head.


The new position was discovered over the course of 40 visits to the Western Gnats of India between 2010 and 2012 by a team of researchers led by Professor SD Biju from the University of Delhi. Males were located by their mating calls and were then filmed with an infrared camera once they had found a suitable female to straddle dorsally. The findings showed that, while this new position might not increase fertility, it’s probably a more expedient means of mating since it leaves the frogs less vulnerable to predators while they’re getting it on.
Frogs, as scientists have been learning for some time, are horny as hell. Their mating rituals are bizarre, and failing the ability to impress a fellow member of their species, they’ll screw just about anything. Other frog positions include the“head straddle,” which is exactly what it sounds like, and the “independent,” which has two frogs touching butts in what one can only assume is deeply ungratifying intercourse. Stay kinky, you slimy weirdos.


[PeerJ via New Scientist]

Say goodbye to the Bramble Cay melomys, a small rat-like creature that lived on a tiny island near the north coast of Australia. Significantly, it marks the first time that a mammal has been declared extinct anywhere in the world, and the cause has been attributed to human-induced climate change.
In a new report co-authored by researchers from Queensland’s Department of Environmental Protection and the University of Queensland, the “root cause” of the melomys extinction was sea-level rise. But the real culprit here is anthropogenic global warming.
These creatures, which used to number in the thousands, lived on the island of Bramble Cay, which measures a mere 1,115 feet (340 m) across and 300 feet (150 m) wide. This Torres Strait island sits just 10 feet (3 m) above sea level at its highest point, making it exceptionally vulnerable to severe weather and rising waters. The scientists said that the island has been inundated with water on multiple occasions, killing the Bramble Cay melomys and destroying their habitat. Birds on the island have also been affected.
The melomys hadn’t been seen since 2009, prompting the investigation. For the past two years, the researchers looked high and low on Bramble Cay for any trace of the rodent. Traps and cameras were placed around the island, and the researchers investigated every nook and cranny. No traces of the animal were found, prompting a recommendation that the status of the melomys be changed from “endangered” to “extinct.”


In their ensuing report, Ian Gynther, Natalie Walker, and Luke Leung didn’t mince words about the cause.
“For low-lying islands like Bramble Cay, the destructive effects of extreme water levels resulting from severe meteorological events are compounded by the impacts from anthropogenic climate change-driven sea-level rise,” they wrote, adding that “this probably represents the first recorded mammalian extinction due to anthropogenic climate change.” Other mammals have been driven to extinction by extreme weather before, but the researchers say it’s the first time it has happened due “solely (or primarily) to anthropogenic climate change.”


Over a period of 10 years, the melomys lost 97 percent of their habitat, with vegetation declining from 2.2 hectares in 2004 to just 0.065 hectares in 2014. Globally, average sea levels have risen by almost (7.8 inches) 20 cm, but sea levels around the Torres Strait have risen at almost twice this rate.
In response, the Queensland government is recommending that no recovery actions be taken: “Because the Bramble Cay melomys is now confirmed to have been lost from Bramble Cay, no recovery actions for this population can be implemented.”
A new study suggests that thousands of species on Earth going extinct at a rate that far exceeds…
Sadly, experts say this is just the beginning. We are now in the early stages of a mass extinction. A recent report found that a sixth of the world’s species face extinction due to climate change. The next mammal to go could be the white lemuroid ringtail possum. Back in 2005, this fragile creature, which is endemic to a single Australian mountain range, was nearly wiped out by a heat wave. As these severe weather events increase, and as habitats continue to dwindle, we can expect more of this.


[Queensland Government & The University of Queensland via The Guardian]
If you opt for the convenience of disposable diapers over their more environmentally-friendly cloth alternatives, you probably don’t stop to think about the science that allows them to keep your baby dry at night. But engineerguy Bill Hammack has, and in a new video, he explains why you’re actually wrapping your baby’s butt in a brilliant piece of engineering.

Elastic walls designed to contain your child’s bowel movements are certainly part of the innovation at play, but the real genius comes with a set of three layers that whisk liquids away, prevent them from re-surfacing and touching your baby’s skin, and then storing them for up to 12 hours overnight.


If you’ve got a little one in diapers, take a minute to appreciate those disposable diapers you rely on, because the next time you go to change them you’ll probably be concentrating on cleanup instead.


[YouTube]

The monster El Niño of 2015-2016 is finally gone, but scientists are still coming to terms with its impacts on the planet. Among those impacts: charging up the global carbon cycle and pushing atmospheric CO2 levels above 400 parts per million (ppm) for an entire year—a first in human history.
Humans are constantly adding CO2 to the atmosphere, a reality which has been carefully chronicled at the Mauna Loa Climate Observatory since 1958. Over the past 60 years, the CO2 concentration at Mauna Loa has risen and fallen on an annual basis, owing to the uptake of carbon by plants for photosynthesis, and subsequent release of carbon during decomposition. But we’ve also watched baseline carbon levels climb by approximately 2.1 ppm annually. That’s thanks to the 10 billion-odd tons of fossil carbon our cars and factories spew skyward each year.
This past year was special. As Gizmodo reported in March, carbon concentrations at Mauna Loa rose 3.76 ppm between February 2015 and February 2016; the single largest jump in recorded history. The previous record rise, of 2.82 ppm, occurred during the 1997-1998 El Niño. In both cases, scientists believe that emissions spiked due to a combination of warming and drying in the tropics, which can accelerate soil carbon decomposition, and large, drought-fueled fires.


The result is that atmospheric CO2 levels have been hovering comfortably above 400 ppm—a level that was unprecedented in our records until 2013—for months. While CO2 levels may dip below 400 ppm this fall, a study published today in Nature Climate Change finds that 2016 is now on track for an atmospheric average of 404.45 plus or minus 0.53 ppm. In other words, it’ll be the first year in the history of our species that we can truly say we’ve been living in a 400 ppm world.
And it’ll be this way for the rest of our lifetimes, barring large-scale deployment of carbon capture and storage technology, an idea which scientists are starting to take seriously in light of our apparent inability to give a shit about climate change. So, what does it mean to live and breathe a 400 ppm atmosphere? We’re not entirely sure yet, but the geologic past can offer clues. For instance, the last time the Earth was a 400 ppm world—the mid-Pliocene—sea levels were an estimated 50 to 80 feet higher than they are today, meaning Florida, much of the Gulf Coast, and countless other coastlines worldwide did not exist in their current form.


Whether we’re poised to see a repeat of the mid-Pliocene, or something more dramatic, depends largely on our actions this century. Ralph Keeling, the climate scientist who put the first data points on the Mauna Loa CO2 curve in the 50s and 60s, captured both the significance and uncertainty of the 400 ppm milestone in a quote to Climate Central last fall: “400 ppm is not a magic number for climate, but it does nicely symbolize that we are now in a new era of Earth history.”

We know our food is incredibly well traveled, but just where does your food come from? A new set of interactive charts help you trace the often serpentine route from farm to table.
Researchers at the International Center for Tropical Agriculture have completed an effort to trace just how far food travels across the planet. In a new paper in Proceedings of the Royal Society B, they share their finding that, on average, nearly 70 percent of the food consumed worldwide crossed at least one national border to get to where it was eaten.
The far more pressing question for most people, though, is usually not about what’s on the average plate. It’s about what’s on your own—and that’s where these maps and charts come in. Along with the paper, ICTA released a series of interactive charts and maps (which are an update to an earlier effort from last year) that you can use to see not just where the food you eat comes from, but also which foods your area is sending out.


Beyond a simple look at the mileage your food is accumulating, though, there’s something else important here.
Farms are getting more specialized worldwide, and it’s now fairly common for all of the farms around you to be growing the same few crops. This means that we depend on global food trade not only to have enough food but also to have a basic amount of variety in our diet.
An investigation into several locavore restaurants revealed that what was written on the menus…
That farm specialization is one reason there’s such a gap between the imagined local diet and what it looks like in reality. If we wanted to switch to more localized diets, it’s not simply a matter of changing where we shop. It would mean a transformation in what we eat, too.


[Proceedings of the Royal Society B]
Carbon nanotubes have been pegged as the wonder material that could finally allow us to build a space elevator. A discouraging new study suggests these microscopic strands aren’t as resilient as we thought—and all it could take is a single misplaced atom to bring the whole thing crashing down.
Carbon nanotubes (CNTs) are tiny hollow cylinders made of interlocked carbon molecules. When woven together they exhibit extraordinary properties, including tensile strengths up to 100 gigapascals (GPa). To put that into perspective, a single strand the width of a thread could support an entire car. In theory, CNTs could be strong enough to support the tremendous strain exerted by a space elevator—a massive structure that would reach up into space from Earth’s surface.


CNTs are considered one of the strongest materials around, but efforts to manufacture the material have only yielded ropes with strengths of 1 GPa. As reported in New Scientist, Feng Ding of the Hong Kong Polytechnic University wanted to find out why, so he and his colleagues simulated CNTs with a single atom out of place. This converted two of the hexagons into a pentagon and heptagon, creating a malformation in the tube. This one simple alteration was enough to reduce the ideal strength of a CNT from 100 GPa down to 40 GPa. Naturally, this effect was exacerbated when they introduced more misaligned atoms. New Scientist explains:
The team’s simulations show that the kink acts as a weak point in the tube, easily snapping the normally strong carbon-carbon bonds. Once this happens, the bonds in the adjacent hexagons also break, unzipping the entire tube. The effect on CNTs spun together into fibers is similar–once one CNT breaks, the strain on the others increases, fracturing them in sequence.
This means that just one misplaced atom is sufficient to weaken an entire CNT fiber. In terms of a potential space elevator, imagine a cable running up from the Earth’s surface into space, and then suddenly ripping apart like a run in a lady’s stocking. That would be... bad.


Given the primitive state of CNT manufacturing at this stage, a bad tube is practically guaranteed. As Ding said, “Most mass-produced CNTs are highly defective, and high-quality CNTs are hard to produce in large quantity.”
As humanity slowly ventures out into the cosmos, we are struggling to overcome the challenge of…
This is definitely a setback in the effort to design and build a space elevator, which will require cables with tensile strengths reaching 50 GPa. If these skylifts are ever going to happen, engineers are going to have to figure out a way to make CNTs perfect at the atomic level—and that’s a daunting proposition.
[ACS Nano, New Scientist]

Birds are capable of extraordinary behavioral feats, from solving complex puzzles to tool making. There may be good reason for that. A new study shows that, pound for pound, birds pack more neurons into their small brains than mammals, including primates.
Published in the Proceedings of the National Academy of Sciences, this study is the first to systematically measure the number of neurons in the brains of more than a dozen bird species, from tiny zebra finches to the six-foot-tall emu. By doing so, neuroscientist Suzana Herculano-Houzel and her team at Vanderbilt University discovered that avian brains contain more neurons per square inch than mammalian brains.


This means that birds pack more brain power per pound than mammals, offering an explanation for their remarkable cognitive talents. What’s more, the study shows that evolution has found more than one way to build a complex brain.
Scientists have long wondered how birds—with their teeny-tiny brains—are capable of exhibiting many complex behaviors, some of which were thought to the be exclusive domain of larger primates. Birds can manufacture tools, cache food, plan for the future, pass the mirror test, use insight to solve problems, and understand cause-and-effect. They’ve also been observed to hide food in front of other birds, and then relocate that food when the other birds aren’t looking. This suggests that birds have a “theory of mind,” which means they’re capable of inferring what other birds are thinking. Very few animals can do that.

Prior to this, scientists just figured that avian brains were simply wired in a completely different way compared to primate brains. But this theory hasn’t been borne out empirically; studies have shown that avian brains are structured quite similarly to mammalian brains.


Now the tired old notion that birds are stupid is starting to fall by the wayside. “We found that birds, especially songbirds and parrots, have surprisingly large numbers of neurons in their pallium [or forebrain]: the part of the brain that corresponds to the cerebral cortex, which supports higher cognition functions such as planning for the future or finding patterns,” said Herculano-Houzel. “That explains why they exhibit levels of cognition at least as complex as primates.”
The parrot, for example, has as many neurons in its walnut-sized brain as the macaque monkey, which has a larger brain about the size of a lemon. When the functional connectivity of avian brains are mapped, it looks similar to what’s found in mammals, such as mice, cats, monkeys, and even humans.
But by packing these neurons in such a dense fashion, birds have been endowed with higher cognitive power per pound than mammals.
“In designing brains, nature has two parameters it can play with: the size and number of neurons and the distribution of neurons across different brain centers,” said Herculano-Houzel, “and in birds we find that nature has used both of them.”


This means that evolution has found more than one way to build a powerful brain. Previously, neuroscientists thought that, as brains grew larger, neurons had to grow bigger as well in order to be able to connect over large distances. The new study shows that there are other ways to add neurons, namely by keeping them small and locally connected, while allowing a small percentage to grow large enough to make longer connections. This keeps the average size of neurons down, which allows for a smaller brain.
The researchers aren’t sure which of the two brain types evolved more recently. It’s possible that the super-compact avian brains came first, and that mammals evolved a “different” kind of brain. Or perhaps birds, who are descended from dinosaurs, evolved their highly efficient brains as a requisite for flight, since birds need to be light and agile.
A grassroots movement has recently emerged in which a number of scientists, philosophers, ethicists …
More conceptually, a growing number of scientists, bioethicists, and legal scholars have been making the case that highly sapient and cognitively complex animals should be awarded personhood status, which would afford them special protections. So, in addition to all great apes (a group that includes humans), whales, dolphins, and elephants, we should also include certain birds, such as corvids and parrots.


[PNAS]
Quasicrystals are unusual materials in which the atoms are arranged in regular patterns that nonetheless never repeat themselves. Most are man-made in the lab; only one case of naturally occurring quasicrystals has been found thus far. And now physicists believe they’ve figured out how that happened.
In a paper published today in the Proceedings of the National Academy of Sciences, Caltech’s Paul Asimow and his co-authors describe how subjecting certain rare materials to extremely strong shock waves produces quasicrystals. Their results suggest that quasicrystals may form in rocky bodies during collisions in the asteroid belt, before falling to earth as meteorites.


What makes quasicrystals so special? Crystals are usually defined by their precisely ordered atoms, forming periodic patterns that repeat over and over again within a lattice (honeycomb) structure. The cells of quasicrystals, however, don’t repeat in an identical pattern. There are small variations in neighboring cells. And yet they follow clear mathematical rules, akin to the famous Fibonacci sequence, where each number is the sum of the two numbers that precede it (1, 1, 2, 3, 5, 8, 13, 21, and so on).
You can see this sort of pattern in the gorgeous medieval mosaics of the Alhambra Palace in Spain, for instance. Think about tiling a bathroom floor, using just tiles in the shape of triangles, squares or hexagons. There can’t be any gaps or overlapping tiles, which means the five-point symmetry of a pentagon, for instance, just won’t work. Except apparently it can, if there’s a way to fill in the gaps with other atomic shapes to get the whole shebang to stick together.
Quasicrystals were first spotted in 1982 by Israeli physicist Daniel Schechtman (then at Technion-Israel Institute of Technology), who was studying a sample of an aluminum-manganese alloy under an electron microscope and noticed that telltale odd aperiodic pattern. “Eyn chaya kao (“there can be no such creature”),” he muttered to himself in Hebrew. Yet there it was.


“The rules of crystallography had been around since 1820,” Asimow told Gizmodo. “So they were completely unexpected when they were discovered.”
Poor Schechtman endured a lot of mocking from his peers—the head of his laboratory sarcastically advised him to re-read his crystallography textbook—and was even asked to leave his research group at one point, but he got the last laugh. His discovery sparked a revolution in crystallography, and he won the 2011 Nobel Prize in Chemistry. More than 100 different types of quasicrystals have since been made in laboratories around the world. They’re used in non-stick cookware, in LED lights, and surgical instruments, among other applications.
But nobody had found a naturally occurring quasicrystal until Princeton physicist Paul Steinhardt stumbled upon one in 2007 while combing through museum rock collections. He tracked it down to a meteorite that landed in the Koryak mountains in Russia, even forming an expedition there to find more quasicrystal samples. He concluded quasicrystals literally came from outer space.
For Asimow, this amazing find raised two key questions. First, how is it even possible for quasicrystals to form in nature? And second, why are they so insanely rare? He got his first clue when Steinhardt mentioned he’d found some strange textures (in the form of iron metallic beads) in the grains from the Khatyrka meteorite. He thought they looked a lot like the kinds of textures that formed in materials during shock compression experiments.


Shock compression is when scientists place samples of material in a special steel chamber and fire a projectile at it, subjecting it to incredibly high pressures. It’s a means of exploring how those materials behave in extreme environments.
Steinhardt’s hypothesis seemed plausible, since scientists had already determined that the Khatyrka meteorite had undergone some kind of shock event, long before it fell to Earth—most likely from a collision with another object in the asteroid belt the early days of our solar system. So Asimow took a sample of copper-aluminum alloy—similar in composition to the icosahedrite found in the meteorite—put it into the chamber, and shocked it with a tantalum capsule to produce the equivalent of 200,000 atmospheres.
And voila! when he and his colleagues analyzed the sample afterwards, they observed the telltale pattern of a quasicrystal—now with extra iron in the copper-aluminum alloy.


“We knew the meteorite had been shocked, we speculated that the shock might be the magic ingredient you needed, and it worked the first time we tried it,” said Asimow. “That suggests to us that it might not be that hard [to make naturally occurring quasicrystals], if you have the right starting materials and a shock of about the right strength.”


His results provide a basic mechanism, although the precise details of exactly when the quasicrystals formed during shock compression have yet to be discovered. As for why it’s so rare to find quasicrystals in the wild, Asimow suggests it’s partly due to the rarity of that copper-aluminum alloy. It doesn’t show up in any other meteorites studied so far, and these are two metals with very different chemical behavior that aren’t normally found together.
But that doesn’t mean other such meteorites don’t exist. The space rocks used to be quite rare until the 1970s, but now number in the thousands, with more being collected all the time. The best places for hunting meteorites are Antarctica and the Sahara Desert, where the black rocks are easy to spot against the white snow and lighter sand, respectively.


Asimow is now fine-tuning his own experiments, partly to determine where the iron traces came from. He has already run two more control experiments to remove potential iron sources in his first experiment—the most likely being that tantalum capsule. He hasn’t analyzed the data yet, but fully expects them to fail to form quasicrystals. And then he’ll run numerous variations on his original experiment, to hone in on the precise conditions under which quasicrystals can naturally form.
For now, he’s happy his first attempt has answered his initial questions. “It explains the mechanism for making natural quasicrystals, and why we haven’t found any others,” said Asimow. “We have a unique starting material, and we have a unique environment. Now the biggest mystery is why there were copper aluminum alloys in that meteorite in the first place.”

[Proceedings of the National Academy of Sciences]
Almost 30 years after Daniel Shechtman noticed something weird in his lab, he finally won a Nobel…
Astronauts typically need a couple of days to get used to microgravity. But as Tim Peake demonstrates in this new video, astronauts eventually develop an extreme tolerance to all that spinning and floating.
Not surprisingly, the body’s vestibular system, which is responsible for coordinating movement and balance, goes a bit squirrely in microgravity. Eventually, after about 24 to 48 hours, it (mercifully) shuts down and lets the eyes do the work. And thank goodness for that. Once astronauts become acclimatized to space, they can function and work without feeling nauseous or dizzy.

With the pause button pressed on the vestibular system, astronauts can tolerate some rather nasty physical conditions. In this new ESA video, Tim Peake and fellow ISS astronaut Tim Kopra, conduct a neat space-based experiment in which Peake is spun around and around in a cannonball.


It looks just awful, but he’s able to withstand the intense spinning. What’s more, it takes him just a brief moment to regain his bearings once it’s all over. He barely looks phased by the experience, demonstrating that once you finally get used to space, it’s quite hard to get dizzy.
[ESA]

Breathing is important. There’s really no disputing that. But when Apple announced its new breathing app at WWDC 2016 today, it included an endorsement from one of the biggest spewers of feel-good pseudo-scientific garbage, Deepak Chopra.
The new app, Breathe, is part of WatchOS 3, and will help guide you through meditation and breathing exercises on your Apple Watch. That’ll yield long-term health benefits, according to this quote from Chopra displayed during the WWDC keynote:
Well, yes, breathing is a good idea, one might say it is critical for staying alive. But when it comes to your “body-mind”? Hmmm. We’ve looked in depth at Chopra’s questionable medical advice, which, thanks to his active social media presence, has actually helped spread misinformation. Like the fact that your body can hear bacteria. Hey Apple, where’s the app for that!?
Holistic health advocate Deepak Chopra is at it again, this time spouting his patented food…
Again, this is not to say there is anything wrong with breathing—you should absolutely do it. Gizmodo 100 percent recommends. But using Chopra’s “authority” as an argument for Apple Watch users to download this app is not the most medically sound way to make that argument.

The world’s most powerful rocket launched this weekend carrying... well, we’re still not quite sure what it was carrying (although speculation suggests a super secret spy satellite). What we do know is this: it launched, and it looked incredible.
ULA Launch’s Delta IV Heavy is currently the most powerful and largest rocket in operation. Even it, however, is no match for the power of gathering storm-clouds, which forced the rocket into a several-hours-long holding period during its initial launch attempt last Thursday.
We don’t know the type or purpose of the new spy satellite being launched by the US National…
Saturday afternoon, the US National Reconnaissance Office took a second, more successful stab at launching their secretive cargo. For now, this photo series shows the most powerful rocket launch you can see—and it is, indeed, an impressive sight to behold.


But as our plans for space get bigger and further so do our rocket designs to allow for the possibility of trips further out, even to Mars. Newer designs are already on their way to dethrone Delta IV, like SpaceX’s Falcon Heavy. When it finally launches, perhaps as early as this year, it will be twice as powerful as the Delta IV.

In a revelation that shouldn’t surprise anybody, Peabody Energy, the United States’ largest coal company, has been bankrolling think tanks, corporate lobbyists, trade associations, and individual scientists at the heart of the climate denial movement, a new Guardian investigation reveals.
Fossil fuel companies aren’t exactly a progressive bunch when it comes to climate action, but few have manipulated the facts of global warming as consistently and egregiously as Peabody, which refers to carbon dioxide in glowing terms and asserts that by cranking up its concentration in our atmosphere, the company is fertilizing the planet for the benefit of mankind. Or, as a Peabody lobbyist once put it, doing “the Lord’s work.”
Several months back, Exxon’s public image took a well-deserved nosedive after an investigation by…
But Peabody hasn’t been preaching alone. Rather, documents released last month after the company filed for bankruptcy protection reveal a network of beneficiaries that have been doing everything in their power to cast doubt on basic climate science and fight even modest environmental regulation, such as the Obama administration’s Clean Power Plan.


“These groups collectively are the heart and soul of climate denial,” Kert Davies of the Climate Investigation Center told the Guardian. “It’s the broadest list I have seen of one company funding so many nodes in the denial machine.”
The more than two dozen beneficiaries include: the Center for the Study of Carbon Dioxide and Global Change, which calls carbon emissions an “elixir of life,” the George C. Marshall Institute, which claims there is not “the slightest evidence that more CO2 has caused more extreme weather or accelerated sea level rise,” and Willie Soon, a researcher at the Harvard-Smithsonian Center For Astrophysics who, it was revealed last year, has received over $1.2 million in funding from the fossil fuel industry.
While the filings obtained by The Guardian don’t list amounts of money or dates of individual contributions, the evidence places Peabody at the center of a widespread misinformation campaign—which, again, not terribly surprising given the company’s previous attempts to rebrand coal as the cure to global poverty.


Ironically, Peabody’s support for the climate denial movement is now coming to light because the company is broke. America’s coal industry is quickly losing ground to natural gas, which last year became our nation’s most popular energy source for electricity. And the transition off coal is going to have to continue, if we’re to have any hope of preventing the worst consequences of climate change from unfolding.
It would be heartening to see a fossil fuel enterprise acknowledge this reality and take a leading role in developing the energy sources of the future. Sadly, like the compressed dinosaur remains they’ve made their fortunes from, most of these companies seem more interested in burying their heads in the sand and staying there.


[The Guardian]

Using machine learning, researchers from MIT have developed a system that produces sound effects that are so realistic they even fool human listeners.
The new algorithm, developed by researchers from MIT’s Computer Science and Artificial Intelligence Laboratory, can predict the precise acoustical qualities of a sound, and then simulate it in an extremely realistic way. When analyzing a silent video clip, such as an object being hit by a drumstick, the system can produce a sound for the hit that’s realistic enough to fool human listeners.

To make it work, PhD student Andrew Owens and his team applied a technique known as “deep learning” that enables computers to pick out important patterns buried in massive amounts of raw data completely autonomously. Over the course of several months, the researchers recorded about 1,000 videos of an estimated 46,000 sounds that represented an array of objects being hit, scraped, and prodded by a drumstick. (The drumstick was chosen because of its ability to produce consistent sounds.) A deep-learning algorithm then analyzed the videos, deconstructing the sounds according to pitch, loudness, and other acoustical qualities.


“To then predict the sound of a new video, the algorithm looks at the sound properties of each frame of that video, and matches them to the most similar sounds in the database,” noted Owens in MIT News. “Once the system has those bits of audio, it stitches them together to create one coherent sound.”
Incredibly, the algorithm was able to simulate—with a surprising degree of accuracy—the fine acoustical details of various hits, including the sounds of the drumstick on metal, wood, rocks, dirt, and even leaves. The synthetic sounds were so good that test subjects picked the fake sounds over the real ones twice as often. Materials like leaves and dirt were particularly difficult to distinguish from the real thing, mostly because these objects tend to have less “clean” sounds than other objects.


This research will do more than put foley artists out of work. In future, this system could improve robots’ abilities to evaluate and interact with their environment.
“A robot could look at a sidewalk and instinctively know that the cement is hard and the grass is soft, and therefore know what would happen if they stepped on either of them,” said Owens. “Being able to predict sound is an important first step toward being able to predict the consequences of physical interactions with the world.”


[MIT News, arXiv]

Football has been rocked by the “Deflategate” scandal, swimming banned full-body “super suits,” and now the sport of curling—yes, curling—has its own raging controversy. Dubbed “Broomgate,” much of the fuss centers on a new kind of curling broom called the icePad, manufactured by Hardline Curling.
It’s not that the players are opposed to new technology in general; they’re just worried the icePad and similar high-tech equipment are altering the fundamentals of the sport in troubling ways by drastically reducing the level of skill required. The World Curling Federation temporarily banned the icePad for the 2015/2016 season, and is now considering new regulations to address this growing concern among players.
As a game, curling is pretty simple—kind of like bocce ball on ice. One person on a team slides a heavy granite stone (or “rock”) down the ice. Then two other team members madly sweep the ice in front of the stone with little brooms, trying to get as close as possible to the center of a target area made up of four colored, concentric rings. The more you sweep, the longer the stone will travel and the less it will curl.


Sometimes you want it to curl, or don’t want it to travel as far. It depends on the initial throw. So the sweepers are guided by the “skip”: a player who watches how the stone is moving and instructs the sweepers on how to adjust their sweeping to keep the stone on the best trajectory. The teams take turns throwing eight curling stones each, per “end” (there are usually eight to ten such “ends” in a game). Whoever gets the most stones closest to the target center wins.
To understand why “Broomgate” is such a big deal, you need to delve into the physics involved in the sport. Mostly, it comes down to inertia, momentum, and friction—and the fact that, for curling purpose, the ice isn’t smooth, it’s “pebbled.” As I wrote for Scientific American in 2014:
Once a stone is thrown and gets some momentum, it can slide quite a long ways before the friction builds up enough to slow it to a stop. The better players can control the friction, the better they can control the curl of the stone as it travels down the ice and position it right where they want it in the house. The ice itself is special: the surface is sprayed with droplets that then freeze, forming a pebbled surface that reduces friction. as does a circular “running band” along the bottom of the stone — the only part of the stone that actually touches the pebbled ice, because the stone’s weight is concentrated on a very small area compared to regular flat ice.
The frenzied sweeping with the little brooms helps reduce friction even further, slightly heating that segment of the ice very briefly before it refreezes. The stone curls more if you leave it alone. The point of the sweeping is to make the stone curl less and travel further. How much or how little you sweep depends on where you want to the stone to end up. There’s a lot more skill involved than you think, which is why the sport is sometimes dubbed “chess on ice.”
Why should the icePad make such a difference? Usually, the curling stone travels on top of the pebbled surface of the ice. Traditional brooms use foam or hair, which surround a given pebble and generate extra friction, making the sweepers work that much harder. In contrast, according to the Hardline website, the icePad “isolates the friction caused by brushing only where the running surface of the rock has contact with ice—on top of the pebble—with little resistance.”


That means sweepers have unprecedented control over the direction the stone is moving—maybe too much, according to many players. There’s a strong belief in the sport that it’s the players throwing the stones, not the sweepers, who should have the strongest influence on individual shots.
“It took a lot of the skill away from the throwers and put it in the hands of the sweepers and the person who was calling the sweep,” curler Brad Gushue, a former Olympic gold medalist, told NPR. “It’s just allowed top players too much control to the point where it is actually difficult to miss some shots on the line.” And where’s the challenge in that? As another Olympic gold medalist, Ben Hebert, told the Ottawa Citizen, “When you throw a great rock, we want you to make the shot, and, when you don’t throw a great rock, I don’t think you deserve to make the shot.”
So the World Curling Federation held a “Sweeping Summit” a few weeks ago, whereby eleven top curlers and scientists from Canada’s National Research Council tested over 50 different curling brooms to determine their impact on the trajectory of the curling stones along the ice. Aided by lasers and a robotic stone thrower, the collected data will be analyzed and used to determine how the current regulations should be updated in light of these technological innovations. A vote is expected in September.
Maybe next the WCF can tackle the ongoing debate about why a curling stone curls in the same direction (rather than the opposite direction) that you spin it.

[Mental Floss]
We’ve seen exoskeletons before, but nothing quite like this one. The new brace, developed by Spanish researchers, will help children with spinal muscular atrophy.
The 26-pound device consists of long support rods and are adjusted to fit around a child’s legs and torso. A series of motors mimic human muscles in the joints, endowing the patient the required strength to stand upright and walk. A series of sensors, along with a movement controller and a five-hour battery, complete the system. The aluminum and titanium device can also be expanded and modified to accommodate children between the age of 3 and 14.

The device was developed by the Spanish National Research Council, and it does more than just help children walk (sometimes for the very first time); by getting them to move, the device will prevent the onset of scoliosis, which results from loss of agility. Spinal muscular atrophy is a degenerative illness that affects about one in 10,000 babies. Eventually, it’s hoped that this pint-sized exoskeleton will move outside of hospital settings, and into the patients’ homes.


[Spanish National Research Council via GizMag]
Using the CRISPR gene-editing tool, scientists from Harvard University have developed a technique that permanently records data into living cells. Incredibly, the information imprinted onto these microorganisms can be passed down to the next generation.
CRISPR is turning into an incredibly versatile tool. The cheap and easy-to-use molecular editing system that burst onto the biotech scene only a few years ago is being used for a host of applications, including genetic engineering, RNA editing, disease modeling, and fighting retroviruses like HIV. And now, as described in a new Science paper, it can also be used to turn lowly microorganisms into veritable hard drives.
Think the memory card in your camera is high-capacity? It's got nothing on DNA. With data…
Scientists have actually done this before, but in a completely artificial way from start to finish. In these prior experiments, information was encoded into a DNA sequence, the DNA synthesized, and then that was it—all the information remained outside the realm of living organisms. In the new study, a Harvard research team led by geneticists Seth Shipman and Jeff Nivala went about DNA data storage in a completely different way.


“We write the information directly into the genome,” Nivala told Gizmodo. “While the overall amount of DNA data we have currently stored within a genome is relatively small compared to the completely synthetic DNA data storage systems, we think genome-based information storage has many potential advantages.” These advantages, he says, could include higher fidelity and the capability to directly interface with biology. For example, a bacterium could be taught to recognize, provide information, and even kill other microorganisms in its midst, or provide a record of genetic expression.
“Depending on how you calculate it, we stored between about 30 to 100 bytes of information,” said Nivala. “Which is quite high compared to the previous record set within a living cell, which was ~11 bits.”
To do it, the researchers used the bacteria’s built-in immune system—in the form of CRISPR—to write data directly onto the genome of the bacterial cells. This allowed the modified bacteria to pass on this customized information to the next generation, making this form of biological data storage extremely efficient and powerful.


Shipman and Nivala leveraged the power of bacteria’s built-in immune system, a.k.a. CRISPR, to make this possible. Whenever a virus attacks a bacterium, CRISPR diligently records the event in the DNA, which it can then reference in the event of a renewed viral attack. It does this by storing tiny sequences of the viral DNA itself, called spacers. In their experiment, the researchers wanted to see if these spacers could be added in a particular sequence, which would create a timeline of when these spacers were added.
The researchers figured that this temporal ordering of spacers could form the basis of a molecular recording device. During the experiment, loose segments of DNA were injected into a strain of E. coli bacteria equipped with CRISPR/Cas1-Cas2. But these bits of DNA weren’t arbitrary—they contained specific strings of data that contained specific sequences of letters chosen by the scientists. These segments were introduced one at a time, and the bacteria systematically integrated them in a linearly coherent manner to reflect the order in which they were introduced.


The researchers only added a few spacers to demonstrate their theory. But given that other spacers are available, there’s an absolutely staggering number of possible combinations.
“These experiments lay the foundations for a recording system that could be used to monitor molecular events that occur over long time periods,” said Nivala. “For instance, it could eventually help us answer questions like what happens to the gene regulation inside a cell as it goes from a healthy to disease state. Or it could also be used to record information on the cell’s outside environment, for example the presence of specific chemicals, toxins, or pathogens.”
Moving forward, the team would like boost the system so that data can be stored more completely at the level of single cells, instead of having to use a population of cells to encode/decode the information.
Note: An earlier version referred to the use of CRISPR/Cas9. The researchers actually used CRISPR/Cas1-Cas2 for the experiment. As Jeff Nivala pointed out: “The Cas1-Cas2 complex is an integrase (inserts spacers of DNA into the genome), while Cas9 is a nuclease (cuts the genome).”


[Science]
Our world is getting brighter, as we turn more and more lights on across the planet. But all that light shining from the ground makes it harder to see the lights shining from the sky. It’s now gotten so bad that the Milky Way is almost impossible to see in most of the United States.
A team of international researchers has created the most complete global atlas of light pollution ever created to show just what you can—and, increasingly, can’t—see in your own patch of night sky. They detailed their results today in a paper in Science Advances. In addition to tracking global light pollution, their new atlas also focuses on the slow global fade of the world’s most iconic dark sky object: the Milky Way.


In the US, 80 percent of people on the ground cannot see the Milky Way anymore because of light pollution. Worldwide, the number is less extreme, with 30 percent of the population unable to see the Milky Way, but the percentages veer wildly up and down when you look at individual countries, with some having almost no night sky visibility.
Singapore was found to be the most light-polluted of all countries, with skies so bright over the whole country that no spot of the country was dark enough at night for human eyes to adapt to night vision. Though the atlas shows how bad the problem has gotten today, it’s actually been a long time coming.


“My sense is the the growth in artificial sky brightness began to accelerate after WWII, tracking fossil fuel consumption,” co-author of the study Chris Elvidge of NOAA told Gizmodo. “Fossil fuels provide the electricity for the lights and the mobility to facilitate urban sprawl.”
Elvidge recommended a number of counter measures to counteract the problem. Those included switching to motion-detector lights at night, turning off lighted-signs at night, and replacing street lamp fixtures with lights that shine only down, not up. Especially important, however, could be changing from traditional lightbulbs to amber-colored bulbs.
“The color which is most highly scattered is blue. This is the blue sky effect you see during the day,” Elvidge explained. “By cutting down on emissions in the blue, light pollution can be reduced. There is already a large stock of amber lights installed worldwide—high pressure sodium lamps.”
Another possibility for Americans who are still hoping to catch a glimpse of the Milky Way is to use this interactive map that the researchers have released to find the remaining dark sky patches closest to them.
Be forewarned, though: Those dark patches are not likely to be above you. Instead, dark skies can increasingly be found only on public lands or exceptionally remote areas. “Some of our national parks are just about the last refuge of darkness—places like Yellowstone and the desert southwest,” co-author of the paper Dan Duriscoe of the National Park Service service noted in a statement.


Still, when you look at America’s skies in contrast with some of the areas even more hard hit by light pollution—like Berlin, which you can see inside of a “light dome” in this night photo of the city below—these islands of remaining darkness amidst the swelling light almost seem lucky. For now at least, some Americans can still see the Milky Way. It’s just a bit of a trek to get there first.
[Science Advances]
Discovered in an ancient shipwreck near Crete in 1901, the freakishly advanced Antikythera Mechanism has been called the world’s first computer. A decades-long investigation into the 2,000 year-old-device is shedding new light onto this mysterious device, including the revelation that it may have been used for more than just astronomy.
The Antikythera Mechanism is one of the most fascinating and important archaeological discoveries ever made, one that reveals the remarkable technological and engineering capacities of the ancient Greeks as well as their excellent grasp of astronomy. This clock-like assembly of bronze gears and displays was used to predict lunar and solar eclipses, along with the positions of the sun, moon, and planets. It wasn’t programmable in the modern sense, but it’s considered the world’s first analog computer. Dating to around 60 BC, nothing quite like it would appear for another millennium.
Since its discovery at the bottom of the Mediterranean, scientists have sought to understand its purpose. No user manual exists, but more than a dozen pieces of classical literature make mention of similar devices. Scientists are having to figure it out by looking at it, both inside and out.


Yesterday, in an event held at the Katerina Laskaridis Historical Foundation Library in Greece, an international team of researchers announced the results of a decades-long investigation into the technological relic. Their analysis reaffirms much of what we already knew about the Antikythera Mechanism, while also providing some tantalizing new details.
The machine’s physical parts are reasonably well understood, so in an effort to learn more about its intended function, the researchers took a deeper look into the tiny inscriptions meticulously etched onto the outer surfaces of its 82 surviving fragments. Some of these letters measure just 1.2 millimeters (1/20th of an inch) across, and are engraved on the inside covers and visible front and back sections of the device. To do it, the researchers used cutting-edge imaging techniques, including x-ray scanning.
“The original investigation was intended to see how the mechanism works, and that was very successful,” noted team member Mike Edmunds, a professor of astrophysics at Cardiff University. “What we hadn’t realized was that the modern techniques that were being used would allow us to read the texts much better both on the outside of the mechanism and on the inside than was done before.”
In total, researchers have now read about 3,500 characters of explanatory text within the device.


“Now we have texts that you can actually read as ancient Greek, what we had before was like something on the radio with a lot of static,” explained team member Alexander Jones, a historian from New York University. “It’s a lot of detail for us because it comes from a period from which we know very little about Greek astronomy and essentially nothing about the technology, except what we gather from here.” Jones added, “So these very small texts are a very big thing for us.”
The researchers described the machine as a kind of philosopher’s instructional device. The new analysis confirms that the mechanism displayed planets, while also showing the position of the sun and the moon in the sky. But while the device had a definite astronomical purpose, it appears the machine was also used to see what the future holds. The researchers suspect this because some of the inscriptions on the device refer to the color of a forthcoming eclipse.
“We are not quite sure how to interpret this, to be fair, but it could hark back to suggestions that the color of an eclipse was some sort of omen or signal,” said Edmunds. “Certain colors might be better for what’s coming than other color. If that is so, and we are interpreting that correctly, this is the first instance we have in the mechanism of any real mention of astrology rather than astronomy.”
That being said, the researchers clarified that the primary purpose of the device was astronomical, and not astrological. If anything, it was like a textbook, or what today we’d call a tablet.


“It was not a research tool, something that an astronomer would use to do computations, or even an astrologer to do prognostications, but something that you would use to teach about the cosmos and our place in the cosmos,” added Jones. “It’s like a textbook of astronomy as it was understood then, which connected the movements of the sky and the planets with the lives of the ancient Greeks and their environment.”


In terms of the researchers’ other findings, it appears that the device was made on the island of Rhodes, and it probably wasn’t the only one made. Slight variations in the inscriptions suggests that at least two people were involved in its construction. It’s also likely that others were recruited to manufacture the gears
“You get the idea that this perhaps came from a small workshop rather than one individual,” said Edmunds.
[Reuters, Fox News]

Six British warships stationed in the Persian Gulf are breaking down because the water is too hot. This week, members of the British Navy testified to the UK’s Defence Committee that their Type 45 destroyers keep losing power because of high ocean temperatures. When the ships’ turbines get overheated, they can’t generate as much energy, resulting in electrical failures.
The makers of the billion-dollar warships, including Rolls-Royce and BAE Systems Maritime, claim that the ships were not designed to be used in that kind of environment for an extended amount of time, although they are supposedly engineered for a wide range of temperatures from sub-Arctic to tropic. The Persian Gulf is a very shallow body of water that absorbs more heat than the open ocean, and it’s situated in one of the hottest places on Earth. Water temperatures regularly range from 75 to 90 degrees Fahrenheit.


Normally this the part of the story where I would say something like, in an exceptionally hot year on an exceptionally hot planet, the Gulf States have recorded many of their most extreme heat waves in recent months. A “heat dome” stretching from Dubai to Beirut resulted in the second-highest heat index ever recorded on Earth; the air in the Iranian city of Bandar Mahshahr felt like 165 degrees Fahrenheit. Due to climate change, this is likely to become the norm: A recent study noted that the Persian Gulf region will not be fit for human habitation by the end of the century because of regular, relentless heatwaves.
Instead, I’d like to end with this thought: This news might be just the kind of thing that wealthy governments need to hear. Because if there’s anything that will motivate a country to take action around climate change, it’s when climate change starts to interfere with their ability to effectively kill other humans.


[CNN]

Every driver has experienced the frustration of traffic jams that develop out of thin air on the freeway—no accident, no lane closure, no presidential motorcade. Just a sudden, maddening, inexplicable slowdown. Now you can explore this phenomenon firsthand with an online interactive simulation.
It’s the creation of Martin Treiber of the Dresden University of Technology in Germany, who studies these so-called “phantom traffic jams.” He designed the interactive model to demonstrate how the interplay of perturbations and bottlenecks together with a high traffic flow will cause various types of traffic. The ultimate goal is to figure out clever ways to reduce traffic jams without having to add lanes or widen roads.


Currently, you can play around with a simple “ring road” system with cars shown in red and trucks in black, varying the average density of vehicles—one of the most critical variables at play when it comes to the physics of traffic, along with the average distance between cars, and average speeds.
The simulation looks an awful lot like a 2008 real-world experiment conducted by a team of Japanese scientists at Nagoya University. They had 22 cars drive around a circular track, asking the drivers to move at a steady 19 MPH. Despite the drivers’ best efforts, there were still tiny fluctuations of braking and speeding up, and this reverberated around the track. The result: occasional brief standstills.

The Japanese team concluded that phantom traffic jams arise because there are just too many cars on the road. It’s a density problem. There’s a certain critical density threshold for traffic, and once it’s reached, even tiny fluctuations can cause a chain reaction that eventually results in a jam.


That’s in line with a traffic model developed by Boris Kerner of the Daimler Benz Research Institute in Stuttgart, Germany, who found that traffic follows the physics of self organization. There are three categories: freely flowing traffic, jammed traffic, and an intermediate state called synchronized flow, in which densely packed cars become “highly correlated,” meaning that they move in unison. This creates a feedback mechanism in which a tiny perturbation—a single driver braking unexpectedly—will send little ripples of corresponding slowdowns through the entire chain of cars behind him/her.
Even a simple thing like a one-second delay in driver reaction time can have a major impact, particularly at faster speeds. According to University of Exeter mathematician Gabor Orosz, a vehicle dropping its speed from 80 MPH to 65 MPH may cause a ripple that later vanishes, while dropping its speed from 80 MPH to 62 MPH may cause a ripple that is amplified and leads to traffic jams.
Treiber’s interactive simulation shows much the same thing. He plans on adding more interactive simulations in the future, allowing users to explore how other variables impact traffic flow: on-ramps, rules for changing lanes, and speed limits or lane closings.
[Boing Boing]
A few days ago, a drone captured this eye-popping video of the world’s worst traffic jam on the G4…
Astronomers have discovered a newly born “hot Jupiter” in a distant star system that’s locked in a slow death spiral. It may only be a matter of time before this poor baby planet gets torn to shreds.
Located 1,100 light years away in the constellation of Orion, this star system is just two million years old. That’s a blip in cosmological terms. Just to give you some perspective: Earth is 4.5 billion years old, and the first genus of Homo emerged in Africa about 2.8 million years ago. That means this star is actually younger than the most ancient humans.


And one of its planets is already dying. As described in the Astrophysical Journal, this newly born planet—about twice the size of Jupiter—is spinning around its host star at ludicrous speed, requiring just 11 hours to make a complete orbit. As it spins around in this tight orbit, gravity from the host star is pulling away its outer layers.
According to the Rice University researchers who led the study, it’s an extreme case of an “evaporating hot Jupiter.” Scientists have observed short orbits before but never in a planet quite so young.
Astronomers from Wesleyan University have detected the shock waves produced by a high-speed “hot…
In fact, it’s one of the youngest planets ever discovered. To date, astronomers have detected more than 3,300 exoplanets, the majority of them orbiting middle-aged stars like our sun. Earlier this year, astronomers announced the discovery of a massive planet in tight orbit around a star so young it still features a disk of circumstellar gas and dust. This new planet, dubbed PTFO8-8695 b, rivals that in terms of its youth.


As for the fate of this new planet, the astronomers can only speculate.
“We don’t know the ultimate fate of this planet,” noted study lead researcher Christopher Johns-Krull in a statement. “It likely formed farther away from the star and has migrated into a point where it’s being destroyed.” He pointed out that there are many close-orbiting planets around middle-aged stars that are in stable orbits, but his team doesn’t know how quickly this young planet is going to lose its mass and “whether it will lose too much to survive.”
Spectroscopic observations revealed that the planet is only about three to four times the size of the star—but its hydrogen emissions are almost as bright as the emission emanating from the star.
“There’s no way something confined to the planet’s surface could produce that effect,” said Johns-Krull. “The gas has to be filling a much larger region where the gravity of the planet is no longer strong enough to hold on to it. The star’s gravity takes over, and eventually the gas will fall onto the star.”
[Astrophysical Journal]
A Dalek standing in the foyer of the BBC’s broadcasting building in London was recently found to contain an interesting compound that could be used to solve an ongoing medical crisis.
Bacteria that cause dangerous infections are become increasingly resistant to drugs, leading us inexorably towards the so-called antibiotic apocalypse. A recent report warned that antibiotic-resistant superbugs could kill upwards of 10 million people a year by 2050 if nothing is done about it.
More and more diseases are becoming resistant to antibiotics. Within a few decades, we’ll enter the …
In an effort to develop new drugs, scientists are searching far and wide for bacteria and other microorganisms that might be used to combat superbugs. Scientists are currently on the hunt for undiscovered critters that may lurk at the bottom of the ocean or in our soil.


Or, as a recent BBC Inside Science episode reveals, on a Dalek standing guard at the reception area of the BBC Broadcasting House.
In what could be an incredible stroke of luck, scientists may have stumbled upon some rather helpful bacteria after conducting a microbial sweep of the London building. The effort is part of a project called “Swab and Send” where people are being asked to take samples of their everyday environments and send them to a lab for analysis. The hope is that some of these microbes might yield new antibiotics that can be turned into new medicines.

Looking to take part, BBC Radio 4 Inside Science host Dr. Adam Rutherford partook in the experiment, taking samples from around the building, including microphones, door knobs—and the eyestalk of the iconic Doctor Who villain. The collected samples were cultured, and the resulting bacterial colonies analyzed.


Earlier today, Rutherford told the BBC Today program that, “The Dalek provided not one, but four potential novel antibiotics.” These samples, unlike the others, produced unique colonies of bacteria that appear to be producing antibiotics that could, in theory, be developed as medicine.


“We’ve got at least three different types of bacteria from the Dalek that were able to ‘exterminate’ our Micrococcus indicator strain,” added Dr. Adam Roberts, the founder of the Swab and Send project.
Ah, we see what he did there. Nicely done, sir.
It’s not immediately clear why this particular object is home to such potentially valuable microbes. It could be completely random. Or, in direction violation of the sign next to it that says, “do not touch,” visitors are in fact putting their grubby little hands all over it, spreading their germs all over this thing.
[Radio BBC 4, RadioTimes]
A discouraging new study concludes that most antidepressants are ineffective for children and adolescents, and may even be harmful in some cases. But the researchers caution that the low quantity and quality of clinical trials are obscuring the true effects of these drugs.
For the new Lancet study, researchers analyzed 34 trials involving over 5,000 participants aged nine to 18. Out of the 14 antidepressant drugs scrutinized, only fluoxetine (aka Prozac) was more effective at relieving the symptoms of depression than a placebo. Shockingly, venlafaxine (branded as Effexor and Lanvexin) was actually associated with an increased risk of suicidal thoughts and attempts when compared to a placebo and several other antidepressants. Patients found that imipramine, venlafaxine, and duloxetine had such negative effects that they were likely to stop taking the drugs.


“The balance of risks and benefits of antidepressants for the treatment of major depression does not seem to offer a clear advantage in children and teenagers, with probably only the exception of fluoxetine,” noted study co-author Peng Xie of Chongqing Medical University in China.
In light of these findings, the researchers recommend that children and teens who are taking antidepressants be monitored closely, regardless of which drugs they are taking, and especially at the beginning of treatment. The researchers stopped short of suggesting that children be taken off their meds; previous research has shown that withholding antidepressants from children and teens can be dangerous.
But the researchers caution that the true effectiveness and risks of these drugs remain unclear due to the disturbingly small number of clinical trials, many of which are flawed. Selective reporting of findings in published trials and clinical study reports were also blamed.


Indeed, there appears to be some selectivity at play here, and no small amount of reporting bias. Of the 34 trials analyzed, 65 percent were funded by pharmaceutical companies. The researchers ranked nearly 30 percent of the trials as being at high risk of bias, 59 percent as moderate, and just 12 percent as low.
“Without access to individual-level data it is difficult to get accurate effect estimates and we can’t be completely confident about the accuracy of the information contained in published and unpublished trials,” said lead author Dr Andrea Cipriani, who works out of the University of Oxford. “It has been widely argued that there needs to be a transformation of existing scientific culture to one where responsible data sharing should be the norm.” Cipriani said that scientists should be given access to raw clinical trial data in order to validate and replicate existing findings.
Publication bias in pharmaceutical research is a known problem. Back in 2004, biotech giant GlaxoSmithKline not only failed to show treatment effectiveness for off-label use of the anti-anxiety drug Paxil among children and teens, it also failed to note a possible increased risk of suicidal tendencies in this age group.
But Big Pharma doesn’t deserve all of the blame—the current publishing model is likewise culpable. It’s easier to publish positive results than inconclusive results, leading to yet another form of publication bias. As Cipriani and her colleagues rightly point out, something has to change.
[Lancet]
We don’t know the type or purpose of the new spy satellite being launched by the US National Reconnaissance Office. What we do know is that its launch, aboard the world’s largest rocket, is happening today at 1:59 p.m. EDT—and it’s definitely going to look spectacular. [Update: The launch is now on Saturday, on account of weather.]
As is appropriate for a super-secret-spy mission, details of the mission are very shadowy. The NRO has described satellite NROL-37 simply as a “national security payload” designed by the NRO, the United Launch Alliance (who builds the Delta IV series), and the Air Force.
They also released this mission patch, which they explained cryptically as a “mission Patch [that] depicts a knight standing in front of the US flag in a defensive posture. The eagle on the chest represents freedom.”


Although details on what it will carry are sparse, details on the rocket itself are much clearer. Currently, ULA’s Delta IV Heavy rocket is the world’s most powerful rocket. When SpaceX’s Falcon Heavy rocket gets off the ground this year, though, it will scoop that title away from the Delta IV.
The Delta IV Heavy will be blasting off from Florida’s Cape Canaveral Air Force Station. It’s scheduled to lift off at precisely 1:59 pm EDT (weather permitting), although the livecast kicks off 20 minutes earlier at 1:39 pm. You can watch the whole thing right here.
Update 1:00 pm: The weather is still looking a little dicey, as you can see in this shot below from this morning. But the launch is on-schedule and the rocket is loaded onto the pad to head out in the next hour.


Update 1:54 pm: With just five minutes to spare, launch control pushed the schedule back to 2:55 pm EDT, on account of the weather. There are some fears of a lightning storm in the area, and they’re hoping it clears up by then.
Update 2:45 pm: Another pushback on the launch window to 3:05 pm, while they try and figure out if it can still make it up today.


Update 5:50 pm: And it looks like we’ll see a launch in 8 minutes!
Update 6:05 pm: With 50 seconds to spare, the launch was called off and re-scheduled, due to weather conditions. It’s set to go back up at 1:51 pm on Saturday.
In preparation for the upcoming Olympics in Brazil, a British long jump champion is planning to freeze his sperm just in case he contracts Zika. It’s meant as a precaution to prevent any future children from developing birth defects, but in reality it’s a complete overreaction based on unfounded fears.
Writing in Standard Issue Magazine, Susie Verrill, explains why she’s not flying to Rio with her partner, Greg Rutherford, and why they’ve decided to freeze his sperm:
The Zika news has caused no end of concern if we’re totally honest. We’re not ones to worry unnecessarily, but after more than 100 medical experts stressed the Games should be moved to prevent the disease from spreading, this was a huge factor in us choosing to stay put.
We’ve also made the decision to have Greg’s sperm frozen. We’d love to have more children and with research in its infancy, I wouldn’t want to put myself in a situation which could have been prevented. Specialists still also don’t know the ins and outs of Zika, so even though it looks as though there’s no real issues should Milo get bitten, it’s just another thing we don’t want to chance.
What may seem like a harmless “just in case” sort of thing may actually do more harm than good. This couple is being a bit hysterical, and they’re actively engaging in fear mongering (and perhaps evensome cloaked self-promotion). As Verrill herself admitted, “there’s no real issues,” so why bother?
A study out today from the Center for Disease Control confirms what many researchers already…
The Zika virus, we now know, causes birth defects, such as abnormally small heads, among other health issues. There’s no question that sexually active men and their pregnant partners should take the necessary precautions. Here’s what the US Centers for Disease Control has to say on the matter:
Men who have traveled to or reside in an area with active Zika virus transmission and their pregnant sex partners should consistently and correctly use condoms during sex...or abstain from sex for the duration of the pregnancy. This course is the best way to avoid even a minimal risk of sexual transmission of Zika virus, which could have adverse fetal effects when contracted during pregnancy.
In light of these recommendations, some journalists are backing out of the Olympics. Earlier this week, Today anchor Savannah Guthrie announced that she’s pregnant, so she’s not going to Rio—but for the right reasons. As the CDC has noted, “Zika virus infection is of particular concern during pregnancy.”


For men and women who have been diagnosed with Zika and who are actively trying to get pregnant, the CDC advises:
In other words, Zika is not a long term problem for couples who are planning on having children in the future. Moreover, nothing in these guidelines, nor in the numerous scientific studies that have followed in the wake of this epidemic, suggest that men should have their sperm frozen. There’s no reason to believe there will be any lingering effects of Zika once symptoms are gone and all virus particles have been cleared from the body.


As for Greg Rutherford and Susie Verrill, they can obviously do what they want. But sadly, their high profile status may influence others to do the same—and for no good reason.


[CDC (here and here), Standard Issue Magazine]
One of the most incredible things about black holes is how much bigger they are than almost anything else out there. Now, a new image taken at the Atacama Large Millimeter/submillimeter Array (ALMA) Observatory shows that we’ve been totally wrong about how they manage to grow so large.
An international research team looking at black holes with ALMA snagged this photo of a super-massive black hole, 300 million times the size of our sun, right in the middle of a giant meal.
The rare photo shows the black hole in the process of swallowing three huge clouds of cold gas—each one with more material than a million suns and moving at speeds of 800,000 miles per hour.


Black holes were previously thought to feed solely on a slow, steady diet of hot gases that surround them. That’s still believed to be the main way that black holes feed themselves. But somehow black holes manage to attain sizes that are much bigger than that method would suggest. So researchers came up with a second, odd theory. On rare occasions, black holes go into a feeding frenzy, where they swallow up huge amounts of giant, cold clouds of gas.
Up until now, that was simply one of several theories about how black holes manage to get so big. But this photographic evidence seems to show that it’s a real phenomenon. Still, the question of how common it is remains.
This feeding frenzy most likely only happens under very specific weather conditions—like the ones present when the photo was snapped. So far, only those three giant clouds of cold gas have actually been seen feeding a black hole. Still, researchers believe there could be as many as thousands of similar clouds around this particular black hole alone, ready to be devoured when the time is right.

Bones and teeth belonging to the ancestors of the short-statured human lineage known as “the Hobbits” have been discovered on the Indonesian island of Flores. The fossils, which date back 700,000 years, are offering fresh insights into the origin of this mysterious species.
In two new papers in Nature, researchers from Australia’s University of Wollongong describe the fossilized remains of three small-bodied hominins thought to be the distant ancestors of Homo floresiensis, an extinct species of ancient human popularly known as the “Hobbits.” The fossils, which include an adult mandible and several teeth, are the first skeletal remains to be discovered on the Indonesian island of Flores outside of Liang Bua—the cave in which paleoanthropologists discovered the original Hobbit remains.
These ancient humans were brought to the world’s attention when the remains of a single adult individual—who would have stood a mere 3½ feet tall—were discovered on Flores in 2003. Since then, another nine specimens have been recovered, including one complete skull. These remains date back to between 95,000 and 50,000 years ago and belong to an entirely new species of nascent humans, one dubbed Homo floresiensis.


Scientists have speculated that their miniaturized characteristics were the result of insular dwarfism, which happens to animals that have become isolated on small islands with limited access to food. This evolutionary process caused the bodies and brains of these early humans to shrink down in size, but they retained their ability to stand upright and use basic stone tools.
The precise origin of these Hobbit-like humans remains a mystery. One theory is that these individuals evolved from an isolated population of large-bodied Homo erectus, and then dwarfed over time. The second theory is that these early humans were descended from another member of our genus, such as Homo habilis. Complicating matters further is the suggestion that they’re not a distinct species at all, and that these individuals were suffering from some sort of congenital disease that caused their short stature.

Based on a morphological analysis of the new fossils, it now appears that these so-called Hobbits were in fact descended from H. erectus. About a million years ago, a band of these early humans got stuck on the island of Flores. Then, over the next 300,000 years, they gradually dwarfed in size, living on the island’s savannah-like grasslands alongside elephants, rats, and Komodo dragons until their mysterious disappearance some 50,000 years ago.


The new fossils were uncovered by Gerrit van den Bergh and his colleagues in 2014, after the researchers performed a series of test excavations to identify which stratigraphic layer was most likely to yield the remains.
The fossils, which include an adult lower right jaw fragment and several teeth, were found in layers of sedimentary rock at a site called Mata Menge. These finds pre-date the bones discovered at Liang Bua by more than half a million years, dramatically extending the timeline of the Hobbits on Flores. Using several dating techniques, the researchers say the fossils are about 700,000 years old. The recent discovery of one million-year-old stone tools pushes back their time on the island even further (unless, of course, these tools were made by some other group of humans).
“This find has important implications for our understanding of early human dispersal and evolution in the region and quashes once and for all any doubters that believe Homo floresiensis was merely a sick modern human,” said van den Bergh. “Human diversity was far greater than we ever realized.”
Interestingly, the adult individual was about two-thirds the size of later Hobbits, which means these ancestors were either equal to or smaller than their descendents. That means these insular humans obtained their small stature in just 300,000 years. That may sound like a long time, but it’s not much in evolutionary terms. The process of insular dwarfism, it would appear, works quickly.


How a group of full-bodied H. erectus made their way to the remote island of Flores remains a matter of speculation. These early humans, who could just barely forge stone tools by smashing them together, couldn’t possibly have had the technological capacity to make boats. Speaking at a press conference yesterday, van den Bergh said they might have been swept to the island by a tsunami, where they remained marooned and isolated. This region is known for volcanic and tectonic activity. What’s more, the 2004 Indian Ocean earthquake and tsunami swept individuals out into the sea as far as 38 miles—including a woman who was seven weeks pregnant, and later rescued.
Another possibility is that this newly found lineage pre-dates the first hominin arrival on Flores, and that it wasn’t H. erectus that got stranded on the island. This would mean that some immediate group of hominin ancestors came through the north from Asia, possibly via Sulawesi.
“That’s another hypothesis that we have to keep in mind,” said van den Bergh.


[Nature 1, 2]
Dance meets geometry in this evocative short film, in which a pole dancer manipulates a projected screen behind her to create constantly shifting geometric patterns. Dubbed “Genese” (“Genesis”), it’s by the French performance art group U-Machine.
As Giaco Furino writes at The Creators Project:
U-Machine sets out to explore what they describe on their Facebook page as, “l’interaction entre l’organique et le numérique,” which translates from French to, “the interaction between the organic and the digital.” With a projected screen that reacts to movement thanks to motion sensors, the dancers in this video are able to seemingly stir up the world around them as they move.
Artistic interpretation is highly subjective. Furino sees something akin to the “deconstruction of the human form” in this short piece. But to my eyes, it looks eerily like the dancer is twisting and warping the fabric of spacetime.

[Laughing Squid]
If you’ve ever been frustrated at your inability to complete a level of Super Mario Brothers, here’s a little something to cheer you up. Computer scientists have demonstrated that solving a level in the popular video game is tantamount to solving some of the hardest problems in computational science.
They’re known as “NP hard” problems, as opposed to the class known as “P” problems, which are relatively easy to solve. A classic example of an NP hard problem is the Traveling Salesman problem: the salesman must find the shortest route to visit 100 cities.


It turns out that navigating the levels of Super Mario Brothers can be equivalent to solving these very difficult mathematical equations, according to MIT computer scientist and engineer Erik Demaine. One caveat: Demaine and his colleagues haven’t shown that the actual levels in commercial versions of Super Mario Brothers meet this standard—only that it is possible to construct levels that are NP hard using the raw materials of the game world, a task that’s actually possible with Super Mario Maker. More on this in a second.
Computer scientists are particularly interested in NP problems, because they’re the cornerstone of cryptography. As MIT’s Larry Hardesty explained in 2009:
Computer science is largely concerned with a single question: How long does it take to execute a given algorithm? But computer scientists don’t give the answer in minutes or milliseconds; they give it relative to the number of elements the algorithm has to manipulate.
Imagine, for instance, that you have an unsorted list of numbers, and you want to write an algorithm to find the largest one. The algorithm has to look at all the numbers in the list: there’s no way around that. But if it simply keeps a record of the largest number it’s seen so far, it has to look at each entry only once. The algorithm’s execution time is thus directly proportional to the number of elements it’s handling — which computer scientists designate N.
So if you’ve got an algorithm to find the largest number in a list of 100 numbers (N=100), the time it takes to complete the task is proportional to N—let’s say one second per operation. Things get more complicated if your algorithm is tasked with, say, figuring out the distances between a given number of airports on a map (where N is the number of airports). It takes longer—three hours rather than one second—because for every airport on the map, the algorithm must calculate the distance to all the others. The real trouble comes with exponential algorithms—say, to factor a 1000-digit number. Then it would take a whopping 300 quintillion years to complete the task.


That’s how long it takes to solve such a problem on its own, but if a computer is given the answer, it can quickly verify that the answer is correct. Think of it as being like a riddle: it’s hard to guess the answer, but once we’re told, the answer seems obvious.
So what does all of this possibly have to do with Super Mario Brothers? A couple of years ago, Demaine and his colleagues examined a generic version of a video game structure they dubbed a “locked door.” This version had two possible states for a path through the game: it’s either safe to use that path, or it is not. Those two states, open or closed, can correspond to the 0s and 1s of computer memory bits.
Demaine et al. demonstrated that any computational problem could be represented by locked doors organized in just the right configuration. If a given problem is exponentially hard, so, too, will be figuring out how to complete that game level. In other words, that problem is NP hard.
Using the raw materials of the game world, they figured out how to construct these kinds of locked doors in Donkey Kong Country. They failed to do the same for Super Mario Brothers. They thought building a locked door in Super Mario was impossible and concluded that the game was at least as hard as the most difficult NP problems. But they couldn’t definitively prove that it was harder. For mathematicians, that’s a key distinction.
At the International Conference on Fun with Algorithms taking place this week in La Maddalena, Italy, Demaine will describe how the key to building a locked door in Super Mario Brothers is to exploit a monster called a “spiny.” A spiny can move between two barriers in the game but can’t leap over them—not without Mario’s help, anyway. If Mario bumps the floor just as the spiny approaches the barrier, it pops right over. The locked door Demaine et al. eventually constructed is based on which side of a barrier the spiny is on. If it’s on one side, the path is open; if it’s on the other side, the path is closed. And there are separate paths that allow Mario to bump the spiny from one side to the other.


And here’s why it’s not just about video games. Mathematicians and computer scientists often talk about proving the general statement that P does not equal NP. If P does not equal NP, then there is no fast, general way to solve NP hard problems. Conversely, if P does equal NP, that would mean that even seemingly difficult problems could have fast, easy solutions. We just haven’t found them yet. And that has enormous implications for cryptography. All our protected data would become vulnerable. (For what it’s worth, most mathematicians believe it’s far more likely that P does not equal NP.)
Confused? Here’s Simon Singh, author of The Simpsons and Their Mathematical Secrets, giving his own take on P vs NP, illustrated with short clips from The Simpsons and Futurama:

For such an arcane mathematical concept, P vs NP gets cited a lot in popular culture. It’s served as a plot point in Elementary. And Charlie Epps, the brilliant mathematician played by David Krumholtz in Numb3rs, used the game Minesweeper to explain the concept to a group of FBI agents in an early episode.


Demaine has taught a class on such hardness proofs using video games, and thinks this can be an effective educational approach. “My hope is through this class and these kinds of papers to encourage more people to do this, because it really does build up a lot of expertise that makes it easier to conquer problems,” he said in a statement. “The more practice we get as a collective, the better we are at solving these types of problems. And it’s important to know the limits of algorithms.”


[MIT]
We don’t usually think of fish as being particularly smart, but a new experiment reveals that at least one species of tropical fish is capable of distinguishing between human faces. Scientists have never seen fish do this before, and it’s changing our understanding of these creatures and how brains work.
A new study published in Scientific Reports shows that archerfish are capable of learning and recognizing human faces with a high degree of accuracy. This feat reveals that this complex task doesn’t necessarily require a complex brain with a sophisticated neocortex, a highly evolved part of the brain responsible for sight and hearing in mammals.


Fish, it would now appear, are more intelligent and more “aware” of their environment than we assumed. The idea that fish don’t feel pain, for example, is gradually falling out of favor (pdf). And recently, it was discovered that manta rays, which are a type of fish, are capable of passing the mirror test, which is considered an important measure of self-awareness.
Now, it may not sound like much, but the ability to distinguish human faces is more complicated than it sounds. Most faces tend to share some basic features, such as a pair of eyes, a nose, and mouth, and in predictable orientations. In order for us to tell people apart, therefore, we need to look for distinguishing features.


“It has been hypothesized that this task is so difficult that it can only be accomplished by primates, which have a large and complex brain,” said lead researcher Cait Newport from Oxford University in a press statement. “The fact that the human brain has a specialized region used for recognizing human faces suggests that there may be something special about faces themselves.”


To test this idea, Newport and her team sought to determine if another animal with a smaller and simpler brain—and with no evolutionary need to recognize human faces—could still accomplish this task. Their resulting study shows that fish, despite lacking the sophisticated visual cortex of primates, are capable of distinguishing one face from a sample of 44 new faces. In a word, that’s incredible.

The researchers used archerfish in their experiment, a tropical fish that spits jets of water to knock down aerial prey. The archerfish were shown either a previously learned face or a series of new faces. Using food rewards, the archerfish were trained to choose between the two faces, which they did by shooting jets of water at the familiar face.
To the surprise of the researchers, the archerfish consistently picked the familiar face (which set them up for a reward) even when more obvious features, such as head shape and color, were removed from the images. The fish correctly recognized 81 percent of faces out of a possible sample pool of 44 faces. This rose to 86 percent when facial features, such as brightness and color, were standardized.


“Fish have a simpler brain than humans and entirely lack the section of the brain that humans use for recognizing faces,” said Newport. “Despite this, many fish demonstrate impressive visual behaviors and therefore make the perfect subjects to test whether simple brains can complete complicated tasks.”
Indeed, this experiment shows that fish, or at least archerfish (who likely evolved their powerful visual abilities to help them hunt), are capable of making very fine visual distinctions in their environment. Fish did not evolve the ability to recognize human faces, but it now appears that their visual skills can be leveraged for this very purpose. What’s more, this study demonstrates that complicated brains and a neocortex aren’t necessarily required for facial recognition tasks.
As a final note, human facial recognition has been previously demonstrated in birds. But unlike fish, they possess neocortex-like structures, which gives them the ability to discriminate human faces.


[Scientific Reports]
After the full impact of the Flint water crisis was revealed, it was almost inevitable that more cities would start to see the same problems when it came to lead in their water supplies. Now it’s been proven that dozens of utilities are underreporting the amounts of lead in their water: 33 cities in the US have been found to have “cheats” built into their lead-testing policies.
The fact that we’d be seeing more water utilities in this situation was a prediction made by Yanna Lambrinidou, a medical ethnographer who served on the EPA’s Lead and Copper Rule task force and one of the researchers on the Virginia Tech team that first revealed what was happening in Flint. “Lead in drinking water is grossly underestimated,” Lambrinidou told Gizmodo this week. “The vast majority of water utilities should not be trusted to protect the public from lead in water.”
In January, I began investigating what we should do to protect ourselves from lead. At the time, I gave some tips for how you might test and filter your water if you had concerns. But as these types of disheartening reports continue to surface, it appears that the best thing to do might be not to worry as much about the testing process—which, as you’ll see, is flawed—and simply take the necessary precautions to remove lead from your water, especially if you have pregnant women, babies, or young children in the house.


The water that leaves your local treatment plant is rigorously tested and may well be perfectly suitable for consumption. It’s the infrastructure that delivers the water to your home which is the issue. Cities that have aging lead pipes have two options for dealing with them: Replace them, or treat the water running through them with anti-corrosives that prevent the pipes from breaking down (in Flint, this anti-corrosive was removed when the city switched water sources). Most cities have used lead lines in their mains at some point, but many don’t know the location or status of those pipes. And even if you don’t have lead pipes, tiny pieces of lead solder or lead rust still might make their way into your water.
A bigger challenge for people who rent is that it’s tough to know for sure if you have lead pipe or solder in the service lines going from the mains to your sink. “Up until 1986 there were pretty lax restrictions, if any,” said Tim Heffernan of The Sweethome, who edited a new report on water filters. Regulations that year set standards for the acceptable amounts of lead in the “wetted surfaces” of a supply system, but it would probably be hard for you to find any kind of documentation for pipe replacement in your building. If you live in a building that’s very new, say 2011, you’re pretty much in the clear. If not, it’s probably not worth finding out. “You couldn’t figure that out even if you tested your water,” said Heffernan. “You’d have to take a scrape of your pipe and run it through a mass spectrometer.”


But even if you’ve determined that your pipes are lead-free, it’s still difficult to know with certainty that your water is completely free of lead. “Because lead in water can release sporadically, you could test now and find 10 parts per billion, and test 10 minutes later and get 1,000 parts per billion, and test tomorrow and get 4,000 parts per billion,” said Lambrinidou.
Marc Edwards, the environmental engineer from Virginia Tech who is heading up Flint’s investigation, calls this the “Russian roulette” phenomenon—you can go to the same tap and collect water 10 times in a row and have no detectable lead at all. Then the 11th time, it’s at levels that are uncomfortably high. That’s not even due to a cheat in the testing—that’s just how lead works, and that’s also how you could be consuming it.
Sweethome recently tested multiple water filters for their lead removal capabilties. The top water filter recommendation after testing for everything from taste to pH is the PUR Classic 11-Cup, which Heffernan has grown to love even more in the months since testing ended. The MAVEA Elemaris XL was Sweethome’s second-choice pick. (Brita filters, which became a fridge staple during the 1990s, are basically bullshit.)
No filter removes lead completely. But NSF International does certify filters for their effectiveness in removing various contaminants, including lead, said Heffernan. “It means the filter lowers contaminant levels to below a specific, very low concentration that meets or improves upon what the EPA considers safe.” PUR is still the winner here with 10 NSF certifications; Mavea has 7. (Brita has 3.) But none of those pitchers received NSF lead certification, so Heffernan’s team came up with their own test, using shavings from a fishing weight to create a lead concentration 16 times higher than the NSF test concentration. From the review:
Despite this heavy concentration, the PUR was able to reduce the lead levels by 97 percent to 0.073 mg/L. That is still seven times higher than the NSF Standard 53 requirement of 0.010 mg/L, but it’s way down from the highly elevated starting point. The MAVEA substantially reduced the lead concentration as well—by 73 percent, down to 0.635 mg/L (60 times higher than NSF certification levels).
“Basically, that’s damn good performance by the PUR under brutal conditions,” said Heffernan. “But neither our test conditions nor the results resemble the NSF’s, and we made sure to be absolutely clear on this.” If you want to check the NSF’s recommendations, the organization has prepared a detailed guide just for lead.


Another thing to note is that all the filters reviewed by Sweethome were gravity filters. This means the water you pour in the top of the pitcher is funneled down through a carbon filtration system of granulated activated charcoal to remove pesticides, then through an ionic exchange filter that grabs the heavy metals. There are also under-the-counter filtration systems that use a single block of charcoal, and, of course, in-fridge filters that can be either type. They were not reviewed by Sweethome, but you can check their effectiveness on the NSF list.
One type of filter you’ll want to steer clear from is anything that promises to reduce “total dissolved solids” or TDS. Some filters claim to remove them all, which is not only bogus, it’s not what you want, since TDS are good for you. “Total dissolved solids are the calcium and sodium that comes out of the literal rocks that your water comes from,” said Heffernan. “If you drank water from the lip of a glacier at the top of the Himalayas, it would have total dissolved solids.”
As for additional tips, letting the water run cold every time you fill up your filter will help flush any additional sediment, including potential lead solder. And a few times a year, especially if you live in a place with a water tank on the roof, take this low-tech maintenance step: “Unscrew your little mesh filter on your faucet, because it is most likely filled with rust,” said Heffernan.


Finally, if you do decide you want to replace your pipes, or simply want to make the investment to improve your home’s value, you’ll need to choose between copper or PVC. Copper is, of course, pricier which is why some people only use copper for “inlet” pipes, and PVC for drains, said Heffernan. “I will say that PVC is louder and it can rattle.”


The bottom line: As cities get their acts together when it comes to more rigorously testing for lead, assume that your faucet might somewhere be connected to lead-bearing pipes and take precautions on an ongoing basis. “I don’t know if testing is even needed since the testing can miss what you are being exposed to, and the testing itself can be misleading,” Lambrinidou said. “Just protect yourself.”
Update: This post has been updated to correct some errors about the testing process. Read the entire water filter review at The Sweethome.

One of the most impressive aspects of the Apollo space program was how NASA worked around the limitations in computer power. The smartwatch on your wrist eclipses what the Apollo space craft’s computers were capable of, so NASA’s engineers often had to rely on clever ingenuity to solve difficult problems.

As engineerguy Bill Hammack explains, in order to properly align the Lunar Module’s guidance system (before GPS and other electronic aides existed) the Apollo astronauts relied on an Alignment Optical Telescope that used techniques devised by Archimedes to be simple, lightweight, but absolutely essential to getting to the moon and back again.


[YouTube]
A planned space-based gravitational wave observatory is one step closer to becoming a reality because a critical technological component just passed a series of tests with flying colors. The LISA Pathfinder collaboration announced the results of these experiments at a press briefing in Madrid this morning, along with a paper published in Physical Review Letters.
Gravitational waves are ripples in the fabric of spacetime caused by the most energetic events in the universe—supernovae, black hole mergers, and the like. There’s been so much (well-deserved) excitement over LIGO’s direct direction of gravitational waves earlier this year that it’s easy to forget LIGO isn’t the only game in town. The era of gravitational wave astronomy is just beginning. There’s an entire spectrum of gravitational waves, much like there are many different kinds of light, of varying wavelengths, in the electromagnetic spectrum.


So there are other collaborations tailored to hunt waves at frequencies beyond what LIGO is designed to detect (the millisecond regime). Launched last December, the LISA Pathfinder mission is one of those collaborations. It’s the first phase of the European Space Agency’s (ESA) planned full-fledged space-based mission to detect gravitational waves, known as the Laser Interferometer Space Antenna (LISA).

“LISA bridges the gap in gravitational wave frequency between pulsar timing arrays and LIGO so it is absolutely critical if we are to characterize the full gravitational wave spectrum,” West Virginia University’s Maura Mclaughlin— who studies gravitational waves at very low frequencies, and is not a member of the LISA Pathfinder mission—told Gizmodo. “Not building it would be like having radio and gamma-ray telescopes but no infrared or optical. We need all of these to get the complete picture of sources.”


Although it is a space-based interferometer, LISA Pathfinder isn’t designed to actually detect gravitational waves. Rather, it’s a prototype observatory to test the detector technologies needed for the full-blown LISA mission. As Gizmodo’s Maddie Stone wrote last December:
Its goal is simple: using laser interferometers, the spacecraft will attempt to precisely measure the relative positions of two 1.8 inch gold-platinum cubes in free fall. Housed in separate electrode boxes a mere 15 inches apart, the test objects will be shielded from the solar wind and all other external forces, such that the tiny motions caused by gravitational waves can (hopefully) be detected.... Eventually, the ESA plans to build a large space-based observatory that takes precise measurements on test objects separated by hundreds of thousands of miles.
The LISA Pathfinder spacecraft has thrusters that fire as needed to ensure the cubes remain in free fall under the influence of gravity and nothing else. Even sunlight can disturb that free fall motion sufficiently to drown out any signals from gravitational waves. The mission’s scientists have spent the last few months working to understand limits on the laboratory’s measurement precision, including stray electrostatic forces, cosmic rays, and even the random motion of molecules within the test masses themselves.
The results far exceeded expectations: the two cubes are in free fall and almost motionless with respect to each other, and the scientists were able to determine the distance to less than the diameter of an atom—five times better than the goal for LISA Pathfinder, according to Martin Hewitson of the Albert Einstein Institute and Leibniz Universitat Hannover.
It’s a hugely important proof of principle, demonstrating that it is possible to implement a gravitational wave observatory in space. Mclaughlin declared it “a spectacular achievement,” adding, “This result has shown that the primary challenge has been surmounted. It would now be very surprising if LISA did not achieve its full projected sensitivity.”


The full LISA mission will consist of three spacecraft in a triangular configuration, each containing two gold-platinum cubes in free fall. Conceptually, it will work much like LIGO, using high powered lasers to measure tiny changes in the distance between those test masses. But to detect gravitational waves at such low frequencies, LISA’s three spacecraft need to be even further apart than the Earth-bound LIGO detectors in Louisiana and Hanford, Washington. LISA should also be better able to resolve directional sources of gravitational waves within an arc-second.
As for the kinds of events LISA might detect, Stefano Vitale of the University of Trento, and principal investigator for the LISA Pathfinder mission, said the most exciting thing would be capturing a small black hole falling into a supermassive black hole. The full-blown LISA observatory would enable physicists to precisely map the gravitational field around a black hole, thereby testing the predictions of general relativity to an unprecedented degree.
“The results reported by the [Lisa Pathfinder] team are, quite simply, a tour de force in precision measurement,” David Reitze, executive director of LIGO, wrote in a viewpoint for APS Physics. “[These] experiments firmly establish that the precision needed by LISA for measuring test-mass displacements are well in hand, setting the stage for the next era in gravitational wave detectors.” The ESA currently hopes to launch the full LISA mission in 2034.


[Physical Review Letters]

Space is not the soundless vacuum movies would have us believe. In fact, judging by these eerie recordings of the music being thrown off by the oldest stars in the Milky Way, space actually sounds like a bit of a party.
The recordings were created by a team of scientists led by Andrea Miglio of the University of Birmingham, using data from NASA’s Kepler missions. After measuring the acoustic oscillations of some of the furthest known distant stars in the Milky Way’s M4 star cluster, the researchers were able to use that data to recreate the sounds and get an idea of just what noises the stars are throwing off. It’s a cacophony, for sure—but a surprisingly musical one that could slide pretty seamlessly into an ambient house track of your choice. (Free idea, DJs.)


Besides being excellent listening, the sounds are also scientifically useful. Measuring the tones from each star let the researchers derive a formula, which they’ve published today in Monthly Notices of the Royal Astronomical Society, to get more precise measurements of star masses and ages. Since the stars are so old, in some cases up to 13 billion years, researchers hope to use the sounds to get even more information about what the universe was like way back then.
“The stars we have studied really are living fossils from the time of the formation of our galaxy,” Miglio explained in a statement. “And we now hope be able to unlock the secrets of how spiral galaxies, like our own, formed and evolved.”


The researchers have also put together a wonderful visualization, which lets you play the individual sounds coming from each star. Or you can listen to the four tracks below right here.


[MNRAS]

Watching dry ice sublimate (turn into gas instead of liquid) still manages to make me feel like a kid again. The kind of kid who is unsure of the difference between science and magic. Okay, not quite ... I’m old now and it’s impossible to ever look at things so innocently anymore. But when I see the carbon dioxide gas immediately escape the frozen dry ice, I can’t help but be entranced. Especially when it’s shot up close like this.
I wish I could see the world like a kid again, but I guess I’ll just have to settle for watching dry ice.


In his writings, naturalist and intrepid explorer Alexander von Humboldt recounted how natives in Venezuela used horses to lure and trap electric eels. Many scientists thought it was just a tall tale, but  a new paper lends credence to Humboldt’s account of eels aggressively leaping up and stunning the horses with a series of high-voltage discharges.
According to Kenneth Catania, a biologist and neuroscientist at Vanderbilt University, electric eels can be up to eight feet long, weigh as much as 44 pounds, and can deliver up to 600 volts of electricity to stun and kill their prey. That’s what has made them of such keen interest to scientists for centuries.


On March 19, 1800, Humboldt and his traveling companion, naturalist Aime Bonpland, decided they wanted to conduct experiments on these fascinating creatures. So they went to the South American village of Rastro de Abaso in Veneuela and enlisted the help of natives there in obtaining live specimens.
Electric eels like to burrow down deep into the slime of marshes and shallow waters, making them difficult to catch using typical fishing techniques. One option was to toss some Barbasco root into the water to stupefy them, but Humboldt wanted the eels feeling energetic for his experiments, so he nixed that idea. The natives suggested “horse fishing” as an alternative. They caught many wild horses and forced them into the water. All that stamping and snorting alarmed the eels so much, they attacked, pressing their long bodies to the horses’ bellies and letting loose with volleys of electric shocks.
Whenever the horses would try to escape, the natives forced them back into the water. Two horses drowned in the first five minutes, and Humboldt was convinced that all would perish. But then the eels got tired from all those electrical discharges, the horses calmed down, and the exhausted eels were easily caught with small harpoons on ropes as they slithered toward the shore.


It’s a gripping account, but nobody had observed similar behavior in electric eels for over 200 years. That’s why so many have voiced skepticism about Humboldt’s story (one naturalist dismissed it as “tommyrot” in a 1947 article for Atlantic).
Catania himself thought it was just “tales” until he noticed how the eels in his lab behaved when being transferred from their home cage to a chamber used for experiments. The scientists used a net with a metallic rim and handle to do so, but whenever the net came close, the eels would swim toward it and leap up, pressing their chins against the metal rim while discharging a series of electric shocks.
Intrigued, Catania decided to investigate further. He placed electric eels in a small aquarium and submerged a conductive rod and metal plate. Sure enough, the eels leapt up as the plate entered the water, bending their necks to maintain contact with it as they released high-voltage pulses. Catania repeated the experiment with LED lights mounted on a fake alligator head, attached with strips of conductive tape, to better visualize those discharges. Once again, the eels attacked aggressively.
Writing in the Proceedings of the National Academy of Sciences (PNAS), Catania argues that these results support von Humboldt’s story. According to Catania, this kind of aggressive attack is well-suited for when the eels find themselves stranded in small bodies of water as water from heavy rainfall recedes dramatically once the dry season arrives. The aquarium conditions in Catania’s lab mimic this environment. And under such circumstances, an aggressive attack may be the eels’ best option.


In fact, Catania believes it’s more effective than simply discharging electric shocks in the surrounding water, citing Michael Faraday’s 1838 experiments with electric eels. Faraday found the water quickly dissipated the high-voltage discharges, such that he only felt mild shock. “A motivated terrestrial predator, harrying a trapped eel from above, may not be deterred before an eel is exhausted,” Catania writes.
These new results build on Catania’s prior work on how electric eels can vary the degree of voltage administered in their electrical discharges. Specifically, they use lower voltages to hunt for prey and higher voltages to stun and kill their prey. In a 2015 paper in Nature, Catania reported that the eels can also use those higher voltages to sense and track potential prey, much like how bats use echolocation to navigate and hunt.

[Proceedings of the National Academy of Sciences]
NASA’s Solar Dynamics Observatory just released a stunning video showing a pair of magnetic fields as they duel for supremacy on the surface of the sun.
The video, shot in extreme ultraviolet light, highlights a small but increasingly active region on the stellar surface. Shot over the course of a single day (May 30, 2016), the spidery magnetic fields are seen connecting and reconnecting as each struggles to overtake the other.

To capture images and videos like this, the SDO uses telescopes that image the sun in the ultraviolet spectrum. As these beams of this invisible light pass into the telescope, a special mirror is used to amplify the light’s otherwise poor reflection. The incoming photos are recorded as pixels, and then recoded as electrical signals.
Earlier this year, NASA produced a map showing the complex configurations expressed by the sun’s magnetic fields. These lines are in constant flux, changing in response to the sun’s movements, both inside and on the surface. As shown here, many of the field lines link one active region to another.


[NASA Solar Dynamics Observatory]
An astronaut just completed the very first walk (float?) into the ISS’s inflatable space house—and it neither popped nor floated away while he was inside. Success! [UPDATE: And here’s the footage from inside.]
Astronaut Jeff Williams became the first person to enter Bigelow Aerospace’s expandable space structure, BEAM, early this morning at 4:47 a.m. EDT.
No need to panic, just because a frail human body—made up of eminently breakable bone, skin, and…
Williams’ first impression of the place was that it was very dark, very cold, and very clean. Williams described the structure as “pristine,” which is perhaps not much of a surprise as no person had been inside ever before. Importantly, it appears that the structure was dry, assuaging concerns that condensation may have been forming inside.


Williams stayed long enough to take an air sample and download data from the structure’s sensors. Shortly after Williams entered, Russian cosmonaut Oleg Skripochka also floated into BEAM. After a few minutes, the two exited and closed up the hatch.
The description of the room from the first visit—cold, dark, clean—does sound a little more like a walk-in freezer than a new little house, but it’s an important step forward. If the test is successful, Bigelow is already looking at more elaborate future designs, which would include entertainment centers, a fitness center, and individual crew quarters. If BEAM does well, we could see more—not only on the ISS, but also on future space missions.
Update 2:30 pm EDT: NASA has released the footage of the short visit, which you can see below, via the light of Williams’ headlamp.

They like to do things big in Dubai, including a newly-approved concentrated solar power project that will generate 1,000 megawatts of power by 2020—and a whopping 5,000 megawatts by 2030.
The Dubai Water and Electricity Authority (DEWA) has announced the launch of the world’s largest concentrated solar power (CSP) project. Located on a single site within the Mohammed Bin Rashid Al Maktoum Solar Park, the plant will consist of five facilities. The first phase of the project is expected to be completed either in late 2020 or 2021, at which time it’s expected to generate 1,000 MW of power. By 2030, this plant could be churning out five times that amount—enough to raise the emirate’s total power output by 25 percent.


By comparison the Ivanpah CSP in California (which is currently the world’s largest) generates about 392 MW of power. Morocco’s Ouarzazate solar power plant will provide about 580 MW of power once it’s complete in 2020.
Concentrated solar power plants, unlike solar energy drawn from photovoltaic cells, use a large array of mirrors (called heliostats) to concentrate a large area of sunlight onto a small area, typically on top of a tower. Electricity is generated when the concentrated light gets converted to heat, which drives a steam turbine connected to an electrical power generator. An advantage of CSP is that thermal heat can be stored easily, making it possible to produce electricity after sunset.


The Dubai plant will have several thousand heliostats located around a tower. The resulting heat-transfer fluid will power a steam turbine to generate electricity. Incredibly, the new plant will deliver power at less than 8 cents per kilowatt-hour, down from the typical 15 kilowatt-hour rate. Once complete, the solar park is expected to reduce 6.5 million tons of carbon emissions each year. A typical coal plant produces around 3.5 million tons of CO2 per year.
The new plant is part of Dubai’s Clean Energy Strategy 2050, which will see the emirate generate seven percent of its total power from clean energy by 2020, followed by 25 percent in 2030, and 75 percent by 2050.
[Gulf Business, Renewal Economy]

In an effort to tackle the organ donor shortage, researchers in the United States have successfully created part-human, part-pig embryos and implanted them into a sow. Eventually, these animals could act as incubators for human organs, which concerns some ethicists.
As reported by the BBC, researchers from the University of California, Davis, injected human stem cells into pig embryos to create the chimeras (the word “chimera” is derived from mythology, but it’s the scientific term used to describe an animal that has genetic information from more than one species). The human-pig embryos were then implanted into a sow, where they will be allowed to develop for 28 days before the pregnancies are terminated (the full gestation period for pigs is 114 days). The scientists will analyze the fetal tissue to make sure everything is developing normally.
In news that sounds straight out of a dystopian Margaret Atwood novel, surgeons managed to keep a…
In September of last year, the US National Institutes of Health said it would not fund this type of research until more was known about the implications. Even though the pigs are supposed to develop as normal pigs—save for the human organs—there’s fear that something unforeseen could happen, and that the pigs would somehow be humanized. There’s particular concern that the genetic material from humans might cause the chimeric pigs to develop human-like brains, but experts believe this is unlikely.


Undaunted by the NIH’s concerns, several labs are now working to make this a reality. Human-pig embryos have been created before, but this marks a first for the UC Davis researchers.
To create the human-pig embryos, the researchers used CRISPR to knock out the genetic information required for the fetus to grow a pancreas, resulting in a genetic “niche.” To fill the void created by process, the scientists then injected human induced pluripotent (iPS) stem cells into the embryo. Theoretically, this should cause the pig embryo to grow a human pancreas. In the future, such pigs would be allowed to mature, and would later have their human organs harvested. In short, they’d basically serve as incubators for human organs. The current work is focused on the pancreas, but other organs could also be grown, including hearts, livers, kidneys, lungs, and corneas.


There’s no question that something needs to be done about the ongoing organ donor shortage, but this solution already seems a bit anachronistic. This concept, originally known as xenotransplantation, has been around since the 1970s. By the 1990s, there was hope that GMO pigs could be used en masse to provide an almost unlimited supply of organs for patients, but research stalled due to fears that humans might be infected with animal viruses. The advent of CRISPR has revitalized this line of research because biologists can now selectively weed out these undesirable retroviruses.
Needless to say, animal rights advocates aren’t thrilled with this approach. As Peter Stevenson from Compassion in World Farming told the BBC’s Panorama program: “I’m nervous about opening up a new source of animal suffering. Let’s first get many more people to donate organs. If there is still a shortage after that, we can consider using pigs, but on the basis that we eat less meat so that there is no overall increase in the number of pigs being used for human purposes.”
The waiting list for organ transplants is growing at an alarming rate while the number of potential …
He’s not wrong; this quasi-dystopian solution seems like a major step backwards. And indeed, there are other research efforts currently underway that won’t require the use of animals, such as bioprinting, advances in cold storage, and the promising field of regenerative medicine where biologists can literally grow a patient’s organs in the lab.


So yes, let’s continue this line of research into human-pig chimeras—it’s probably the best short term solution that we have. Research into this area is developing quickly, and it’ll likely be available sooner compared to the other research efforts. But let’s go about this with the understanding that it’s a stop-gap measure and not a long term solution.
[BBC]

No need to panic, just because a frail human body—made up of eminently breakable bone, skin, and sinew—is about to step into the vacuum of space, protected only by a reinforced bouncy castle. EVERYTHING IS FINE.
After finally getting its inflatable space house up and running on the second try, NASA is about to hit another milestone: It’s going to send a person inside to see how it looks in there. On Monday, astronaut Jeff Williams will become the first person to float foot into BEAM, Bigelow’s test expandable space unit, which is currently screwed to the side of the ISS.


This first inflatable space walk is actually happening a little off-schedule. It was supposed to have happened yesterday. But, after BEAM refused to expand more than a couple inches outward in NASA’s first attempt last week, they called a temporary halt until they could figure out the source of the unit’s lost pressure. Finally on Saturday, they were able to get BEAM fully expanded.
The first order of business on Monday will be for Williams to run an air sample and install sensors to test how the unit is handling the barrage of radiation and space trash that regularly flings itself against the ISS. Assuming that all goes well over the two-year test, similar and more elaborate space houses (as you can see from the picture, the inside of BEAM is currently pretty spartan) may one day be deployed to the ISS and even further into space.

Every week, a quarter of Americans take a painkiller that could be dampening our collective feelings of empathy. In a paper published online this week, scientists claim that acetaminophen, Tylenol’s main ingredient, makes people more likely to think that other people’s pain isn’t a big deal.
Researchers from the National Institutes of Health and Ohio State University published their findings in Social Cognitive and Affective Neuroscience after studying the effects of the drug on between 80 and about 120 college students across three different experiments.


One group of students drank a liquid with 1,000 mg of acetaminophen, while another took a placebo. An hour later, everyone read short stories about situations such as feeling emotional pain from the death of a parent, or physical pain from a knife that had cut through to the bone. The students who drank the acetaminophen assigned lower ratings for perceived pain and distress than the students who didn’t.
In the second experiment, participants socialized with other people and then, while alone, watched a game supposedly involving three of the people they had just met. The game showed two people excluding the third from an activity, and asked students to rate how hurt the excluded member was. Again, students who took the painkiller assigned lower pain ratings.


The third experiment was less conclusive: the subjects received two-second blasts of white noise and then rated how unpleasant it was for themselves, and how unpleasant it would be for an anonymous other participant. The students who took the painkiller gave lower pain ratings for others when compared to the students who didn’t—but they also gave lower pain ratings for themselves.


There are a few important things to note before blaming Tylenol for yesterday’s family fight: The sample size is quite small and the team doesn’t know why this effect happens, though they theorize that it is because there is an overlap in our ability to experience pain and our ability to empathize with others. Acetaminophen has numerous effects on the human body. Earlier studies have shown that it makes people less likely to feel joy and that it can help help treat anxiety and existential dread.
Given how common acetaminophen is (it’s present in more than 600 products) it’s worth looking into what the researchers have called its “broader social side effects” and whether other painkillers could have similar results.
Up next? They plan to study ibuprofen.
[Social Cognitive and Affective Neuroscience, via Washington Post]
Scientists from the University of Texas at Arlington used planetarium software to recreate the night sky of ancient Greece, the better to peg the date when lyric poet Sappho penned one of her most famous verses. They describe their findings in a new paper in the Journal of Astronomical History and Heritage.
“This is an example of where the scientific community can make a contribution to knowledge described in important ancient texts,” lead author Manfred Cuntz said in a statement. “Estimations had been made for the timing of this open in the past, but we were able to scientifically confirm the season that corresponds to her specific descriptions of the night sky in the year 570 B.C.”


The poem in question references the Pleides, a cluster of stars that are especially prominent during winter nights in the Northern Hemisphere. References to them abound in ancient texts all around the world, in part because they were useful for navigation at sea.
In Greek mythology, the stars represented the so-called “Seven Sisters,” daughters of the titan Atlas. In some versions of the tale, Zeus transformed them first into doves, and then into stars, after they collectively committed suicide in grief at their father being forced to carry the heavens on his shoulders. The nearby constellation, Orion (the Hunter), was said to pursue the sisters across the night sky.
So naturally Sappho would find inspiration in the star cluster for her “Midnight Poem”:


The moon has setAnd the Pleiades;It is midnight,The time is going by,And I sleep alone.(trans. Henry Thornton Wharton, 1887)
Cuntz and his co-author, Levent Gurdemir, used the software of the UT-Arlington planetarium, where Gurdemir serves as director, to recreate the night sky of ancient Greece for 570 B.C. They found that the Pleiades would have set at midnight on January 25 of that year, and would set earlier and earlier as the year progressed.
Cuntz admitted that timing was tricky, since the ancient Greeks relied on water clocks, not mechanical time keepers. But the latest date that the setting of the Pleiades would have been visible from the isle of Lesbos was March 31. So they concluded that Sappho would have written her poem between mid-winter and early spring of that year—just as historians had estimated.
The UT-Arlington scientists are following in the footsteps of Donald Olson, a self-described “forensic astronomer” at Texas State University, who has used his expertise to analyze meteor precessions that inspired a painting by Canadian astronomer Gustav Hahn and a poem by Walt Whitman.


Then there was Olson’s intriguing hypothesis that the moon may have contributed to the sinking of the Titanic. He helped clear up confusion among historians as to the precise location of Julius Caesar’s landing site when the Roman general invaded Britain in 55 B.C. He showed that Mary Shelley was probably telling the truth about a moonlit “waking dream” that inspired her to pen Frankenstein. And he’s studied astronomy-related aspects of Chaucer’s Canterbury Tales, the photography of Ansel Adams, and Edvard Munch’s “The Scream.”


Clearly, Texas is a good place to be if you’re interested in the budding field of forensic astronomy.
[Journal of Astronomical History and Heritage]
A self-assembling space habitat, a deep sleep chamber to shuttle astronauts on long journeys, and a protective magnetic force field are the latest projects NASA is embarking on.
NASA’s Innovative Advanced Concept (NIAC) Program is responsible for funding futuristic space concepts that could, as NASA puts it, “change the possible.” It’s not enough to merely be a cool concept, though—projects are also screened for technical plausibility. In its latest round of funding, NIAC’s Phase II program has selected eight projects to move ahead. Among the most promising ones are three focusing on how to build livable future habitats in space.
To travel further into space, it would be helpful to have outposts to stop at along the way. These early stage Growth-Adapted Tensegrity Structures would seed chosen outpost points with building robots that could not only create the initial rotating space outposts, but could modify them for future needs as well. The current project will start by looking at the feasibility of setting one up outside of the lunar orbit, but researchers add that, if successful, these structures could someday be almost anywhere.
Colonizing Mars will be anything but simple, and one of the main challenges will be landing on the surface without crashing or burning up. This magnetic space shell—aptly called the Magnetoshell—would throw a magnetic field around a Mars-bound spacecraft. As it fell through the planet’s atmosphere, researchers hope that the resulting interaction can act almost as a second set of brakes, slowing down the craft enough that the actual landing protocol would need less fuel. Early designs were focused on putting together initial plans for landings on both Mars and Neptune. Now, researchers intend to look at how a Magnetoshell might work for crewed missions even beyond that, to locations all over the solar system.
Many of the recent proposals were dedicated to what happens when we get into deep space. But to arrive, you first have to make the journey—and that could take years. That’s where this deep sleep chamber comes in. It’s not a cryo-sleep chamber, researchers emphasize, at least not yet. Instead, the idea here is to first build a chamber capable of medically-supporting astronauts who are in a deep sleep.


In addition to these three, you can look at the full slate of approved NIAC Phase II projects right here.
Earlier this week, over a hundred scientists, lawyers, and entrepreneurs gathered to discuss the radical possibility of creating a synthetic human genome. Strangely, journalists were not invited, and attendees were told to keep a tight lip. Which, given the weighty subject matter, is obvious cause for concern.
The idea of creating a synthetic human genome is qualitatively different than gene editing. Instead of scientists patching a gene here and a gene there, they would use chemicals to manufacture all the DNA contained in human chromosomes. Synthetic genomics, unlike genetic modifications, in that it doesn’t use naturally occurring genes. Instead, it relies on the custom-designed base pair series. This opens to the door to a greater array of possibilities, as geneticists wouldn’t be bound by the two base pairs produced by nature.


Currently, scientists see synthetic genomics as a way to build novel microbes and animals, but the same principle applies to humans. It thus raises the prospect of custom-designed humans, or even quasi-humans, without any parents. It’s a massive bombshell of a topic—one requiring serious rumination and discussion. But for reasons that aren’t entirely clear, this futuristic endeavor appears to be getting off on the wrong foot.
As science writer Andrew Pollack reports in the New York Times, the prospect of synthetic human genomes was discussed at a secret meeting held at Harvard Medical School this past Tuesday. Pollack says that those in attendance were told “not to contact the media or to tweet about the meeting.”


According to George Church, a professor of genetics at Harvard medical school and a key organizer of the proposed project, the whole thing is an unfortunate misunderstanding. Church says the meeting wasn’t really about synthetic human genomes, but rather it was about efforts to improve the ability to synthesize long strands of DNA, which geneticists could use to create all manner of animals, plants and microbes. Church was quoted in the NYT as saying: “They’re painting a picture which I don’t think represents the project. If that were the project, I’d be running away from it.”


This is all very interesting because, as Pollack points out, the original name of the project was “HGP2: The Human Genome Synthesis Project.” What’s more, an invitation to the meeting clearly stated that the primary goal would be “to synthesize a complete human genome in a cell line within a period of ten years.” Later, the organizers changed the name of the meeting to “HGP-Write: Testing Large Synthetic Genomes in Cells.” The reason for the change, they said, was that the original name was meant to be headline-grabbing. Which is a super strange thing to say given that the meeting was closed to the press.
As for why the meeting was held behind closed-doors, Church says it’s because his team has submitted a paper to a scientific journal, and they’re not supposed to discuss the idea publicly before publication. Again, a very strange excuse; why hold a meeting on such an important topic before the paper gets approved for publication? Wouldn’t it have made more sense to hold the meeting after? In fact, the press are often invited to read papers prior to publication under the embargo system. Journalists are already in the habit of keeping quiet as a matter of protocol and journalistic ethics.
As noted, Church hopes to build a complete human genome in a cell line within ten years, which is quite ambitious. The last effort in this regard was Craig Venter’s group, who synthesized a simple bacterial cell. But building an artificial human cell, well that’s considerably more complex. The ten-year timeline seems unrealistic, but at least it’ll afford us plenty of time to ruminate on this hugely important prospect.
Indeed, this topic is definitely far from resolved, and we’ll be watching this story as it unfolds. In the meantime, I highly encourage you to read Pollack’s entire article at the New York Times, and a provocative essay published in Cosmos Magazine about the ethics of synthesizing a human genome. Here’s a short clip:
In a world where human reproduction has already become a competitive marketplace, with eggs, sperm and embryos carrying a price, it is easy to make up far stranger uses of human genome synthesis capacities.
Would it be OK, for example, to sequence and then synthesise Einstein’s genome? If so how many Einstein genomes should be made and installed in cells, and who would get to make them?
Taking a step back, just because something becomes possible, how should we approach determining if it is ethical to pursue?
Given that human genome synthesis is a technology that can completely redefine the core of what now joins all of humanity together as a species, we argue that discussions of making such capacities real, like today’s Harvard conference, should not take place without open and advance consideration of whether it is morally right to proceed.
I have reached out to Dr. George Church for comment, along with an attendee of the meeting. We’ll update this post should their responses come in.


[New York Times, Cosmos Magazine]

There was lots of exciting news this week about the much-anticipated Hyperloop, a high-speed train that would be able to make the trip from San Francisco to Los Angeles in just 35 minutes.
A startup called Hyperloop One (formerly Hyperloop Technologies) built the first full-scale test track for the transportation system in the desert outside Las Vegas and tested its propulsion system for the first time this week. Meanwhile, another startup called Hyperloop Transportation Technologies announced that it had licensed a promising technology known as Inductrack from Lawrence Livermore National Laboratory for its own Hyperloop design.


Confused? Here’s a short explainer video on the physics of the alternate approaches. Will we have a working Hyperloop in the near future? Only time will tell.


The discovery of ancient artifacts and mastodon bones in a submerged sinkhole shows that humans first inhabited the southeastern corner of North America 1,500 years earlier than previously assumed.
A collaborative research team has pulled up dozens of stone tools and the remains of extinct animals from the Page-Ladson site in Florida, a 26-foot-deep sinkhole located in the Aucilla River just outside of Tallahassee. It now represents the oldest known site of human life in the southeastern United States, dating back approximately 14,500 years. It’s also the oldest submerged archaeological site in all the Americas, and one of the oldest sites on continent.


The discovery shows that a population of pre-Clovis hunters—possibly with the assistance of dogs—hunted mastodon in what is now Florida. This research has been published in the latest edition of Science Advances and was conducted by a multidisciplinary team of scientists from Florida State University, Texas A&M University, and the University of Michigan.
Clovis hunters originated south of the large ice sheets that covered Canada near the end of the last glacial period. They are the direct descendants of the earliest people who arrived in North America some 15,000 years ago. Numerous sites around the continent date to around 13,000 years ago, but only a small handful in all of North and South America are older. This new discovery shows that a population of pre-Clovis people adapted to the region much earlier than previously assumed.
Back in the 1980s and 1990s, the Page-Ladson site was investigated by archaeologists James Dunbar and David Webb, who retrieved several stone tools and a mastodon tusk with cut marks. But their discovery didn’t receive much attention because the finds were considered too old to be credible and because they were found in such an unusual setting.
It’s unusual to find artifacts submerged under nearly 30 feet of water, but it does happen. Landscapes can change quite dramatically over long time scales, often obscuring traces of human habitation. This particular settlement was buried under 13 feet of sediment during the late Pleistocene, a condition that also left the site submerged.


Eager to give the site another try, Jessi Halligan from FSU and Michael Waters from Texas A&M re-visited the water saturated sink hole between 2012 and 2014. Working in near-zero-visibility waters, they managed to pull up dozens of artifacts, including stone tools and the bones of extinct animals. They even discovered a so-called biface: a knife with sharp edges on both sides that was used for cutting and butchering animals.
The researchers also conducted a more thorough investigation of the mastodon skull discovered decades earlier. The skull features obvious signs of cutting, including deep, parallel grooves on the surface of the tusk. So Dunbar and Webb were correct in their assessment: humans were hunting mastodons in Florida nearly 15,000 years ago.
Daniel Fisher from the University of Michigan, a co-author of the study, said the tusk was probably removed so that the hunters could gain access to edible tissue at the base. Fisher has firsthand experience doing this himself, as he’s excavated mammoths and mastodons in North America and Siberia.
The pulp cavity of each tusk contains about 15 pounds of tender and nutritious meat. Meanwhile, the deliberate nature of the cuts into the side wall of the tusk socket shows the pre-Clovis hunters knew exactly what they were doing and that they had a rudimentary understanding of mastodon physiology. The ivory itself was likely used to forge weapons.
“These grooves are clearly the result of human activity and, together with new radiocarbon dates, they indicate that humans were processing a mastodon carcass in what is now the southeastern United States much earlier than was generally accepted,” said Fisher in a statement. This is strong evidence against the so-called “Blitzkrieg” hypothesis, which suggests that early humans hunted mastodons to extinction at a rapid rate.


This evidence, along with traces of sporormiella (a type of fungus), shows that humans and “megafauna” coexisted for at least 2,000 years. Many of these large animals, including the mastodon, became extinct around 12,600 years ago.
“The stone tools and faunal remains at the site show that at 14,550 years ago, people knew how to find game, fresh water, and material for making tools,” said Waters. “These people were well-adapted to this environment. The site is a slam-dunk pre-Clovis site with unequivocal artifacts, clear stratigraphy and thorough dating.”


The discovery adds to our growing knowledge of how and when North America was first settled. Data collected by other teams suggests that people were also adapting to living in Texas, Washington, Oregon, Pennsylvania, Wisconsin, and South America around the same time.
“Clearly, people were all over the Americas earlier than we thought,” said Halligan.


[Science Advances]
Bacteria are becoming resistant to antibiotics far more quickly than humans are discovering new ones. That’s why a DARPA-funded research team is exploring a fascinating new way we might win the war against germs: not with drugs, but with predatory bacteria that sound like monsters from science fiction.
Lions, sharks, and Schwarzenegger flicks are more likely to come to mind when you hear the word “predator,” but certain bacteria are also fearsome hunters, voraciously consuming their fellow single-celled organisms. In fact, predatory bacteria have no trouble annihilating some of the most drug-resistant bugs. Microbiologist Daniel Kadouri hopes we can use these killers to our advantage.
This week’s episode of Meanwhile in the Future gets very scary, very quickly. And we’re not going…
“Every agency out there—the WHO, the CDC, the NIH—have all figured out that drug resistant pathogens are as big a threat as global warming,” Kadouri said when I spoke with him at a DARPA technology expo this week. “We’re trying to see if we can do things differently, by using predatory bacteria as live antibiotics.”
For the past few years, Kadouri and his colleagues have been conducting laboratory experiments that pit two specific predators—bacteria from the genera Bdellovibrio and Micavibrio—against some of the deadliest human pathogens.


“Bdellovibrio attacks biofilms,” Kadouri said, referring to the sticky bacterial secretions that become the spawning ground of drug-resistant infections. “They’ll attach to the biofilm, drill themselves inside the cells, and start dividing. From one [Bdellovibrio] cell entering you can get about 80 cells breaking out. It’s like something from the movie Alien.”
Micavibrio uses a totally different but equally horrifying mode of attack, attaching itself to the outside of its prey like a vampire. “Basically, they suck other bacteria dry,” Kadouri said.


Kadouri’s research has shown that each of these micro-monsters can attack a wide range of disease organisms, including Pseudomonas, which causes wound infections, and Vibrio cholerae, the little varmint behind cholera. And a bug that’s resistant to antibiotics is no big deal. “Becoming drug resistant doesn’t interfere with their attack because it’s a totally different pathway,” Kadouri explained.
At this point, you might be wondering whether swallowing a pill filled with one of nature’s most efficient killing machines might have some, erm, unfortunate side-effects on the host. Kadouri and his colleagues have considered this possibility too, which is why they’ve just completed a battery of studies testing Bdellovibrio and Micavibrio in live animals and human cell lines. “They’re completely benign,” Kadouri said, explaining that in no experiments did either predatory bacteria have a harmful effect on animal tissue.
There’s still the possibility that an over-zealous predator might wreak havoc on our native gut flora. While preliminary research suggests that Bdellovibrio and Micavibrio tend to leave our friendlies alone, it’s a possibility that researchers are continuing to investigate. Antibiotics can definitely wreak havoc on our microbiomes, however, so if predatory bacteria are less harmful in this respect, that’s a major selling point.


It’ll be years before doctors are prescribing live bacteria to combat infections—Kadouri and his colleagues are now conducting efficacy tests to determine the best way to administer such a treatment—but the fact that scientists are beginning to consider real alternatives to antibiotics is very promising. Even scaling back our use of antibiotics a little bit will ensure that these life-saving drugs last longer.
“The important thing is to start building an arsenal of other therapeutics,” Kadouri said. “We need to get out of the mindset that it’s just about antibiotics.”
And, you have to admit that for a “natural” alternative, swallowing a bunch of predators to boost your immune system sounds pretty badass.

Xylitol is an artificial sweetener found in everything from toothpaste to peanut butter to sugar-free gum. And, it turns out, it’s poison for dogs.
The FDA just dropped a new warning that, while it’s just fine for people, the sweetener has proven fatal for dogs. Not giving your dog sugar-free gum may already seem like intuitive advice, but xylitol has found its way into plenty more products as of late. Some of those products, while not intended for dogs, end up being eaten by them anyway. It’s in toothpaste (although not pet toothpastes), baked goods, and even the peanut butter that pet owners sometimes use to hide their dogs’ meds.


The problem starts with a sudden rush of insulin that hits dogs (although not humans) after they eat something that contains xylitol. This can send their blood sugar levels fatally low. Once a dog has eaten something with xylitol in it, the symptoms—which include vomiting, staggering, seizures, and even death—hit hard and fast within a day.
Even before the FDA warning, veterinarians had already started trying to warn people of the danger to their pets. But this is the first official advisory and should go much further in spreading the word about the danger. Remember: just because something is safe for you to eat doesn’t mean that it’s safe for your dog.
In an effort to curb the dangerous trend of vaccine avoidance, the Liberal government in Ontario wants parents seeking vaccine exemptions for their kids to attend a mandatory education session. It’s a good idea, but getting anti-vaxxers to change their opinions will probably require more than that.
The Liberals in Ontario are pursuing an amendment to the Immunization of Schools Pupils Act that would require anti-vaxxers to attend a science class at their local public health unit. Which is a damn awesome idea. It would do anti-vaxxers well to learn about the latest science, how vaccines work, and why their reluctance to vaccinate their children puts other children at risk.


“Choosing to vaccinate your child protects them from disease, and it protects vulnerable children who can’t get vaccinated for medical reasons. That’s why it’s important for parents to keep their children’s immunizations up to date,” Ontario Minister of Health Eric Hoskins said in a statement. “If passed, the proposed amendments to the Immunization of School Pupils Act would help parents and guardians make informed decisions about vaccination.”
Here, here!


Anti-vaccination beliefs cause actual harm, as witnessed by the recent measles outbreak in both the United States and Canada. We need to attain so-called “herd immunity,” to immunize enough people that no sustained chains of transmission are possible. This would protect us from some of the worst blights, like diphtheria, tetanus, polio, measles, mumps, rubella, pertussis (whooping cough), and meningococcal disease.
It's not just the myth about autism that's driving down vaccination rates. Many parents…
The trouble is, Ontario’s proposed education sessions will likely fall on deaf ears. Many anti-vaxxers actually know how vaccines work, and they know the arguments in favor of vaccinations. But they remain resistant to modern medicine. The reason, says Durham University anthropologist Thom Scott-Phillips, is that many anti-vaxxers are drawn to what psychologists call “naïve” or “folk” theories.


“Naïve theories of all kinds tend to persist even in the face of contradictory arguments and evidence,” writes Scott-Phillips. “Interestingly, they persist even in the minds of those who, at a more reflexive level of understanding, know them to be false.”
These memes, he says, are particularly “sticky” and hard to shake off. Exposing anti-vaxxers to the science is a great start, but it’s surely going to require a larger cultural shift to change things in a meaningful way.


[CBC]
Dung beetles have this really neat trick by which they’re able to use the positions of the stars to orient themselves along a straight line, making them the only known animal to use the Milky Way for navigation. Exactly how they do this has remained a mystery—until now.
For food, dung beetles famously detach a chunk of poop from a pile of dung, then shape it into a ball and roll it away. To protect their meal from competitors, dung beetles have to make their getaway as quickly as possible—and even these insects know that the shortest route between two points is a straight line. Accordingly, dung beetles relocate their precious balls of poop by rolling them in remarkably straight lines.
A few years ago, researchers from Lund university showed that dung beetles rely on an internal compass that orients the bug according to the positions of the stars and Moon. A follow-up study showed they even use the thick band of the Milky Way for navigation. But the mechanism that enables them to use these stellar cues remained unknown. Now, this same team of dung beetle-obsessed researchers say they’ve finally figured it out. These insects are able to look up into the night sky and take a “celestial snapshot,” which they store as a map inside their brains. The research now appears in Current Biology.


To demonstrate this, a research team led by Basil el Jundi experimented with dung beetles in simulated conditions. Instead of exposing them to the real world and the real night sky, the researchers created an artificial firmament. They were able to mess with the dung beetles by regulating the amount of light and by changing the positions of the celestial bodies. This allowed the scientists to compare how the beetles were compensating and potentially altering their trajectories based on the placement of the artificial stars and Moon.
Despite these simulated conditions, the beetles were still able to orient themselves. This research shows that, even if the night sky represents a physical impossibility, dung beetles are still able to maintain their bearings—but only if the stars, or cues, are still visible when the snapshot was initially taken. When the stars were removed or altered, the dung beetles were out of luck, and their orientation skills suffered accordingly. Tellingly, a similar effect happens to them in the real world when the sky becomes overcast.

To initiate the process, the dung beetle climbs to the top of its ball of poop and performs a “dance” whereby it rotates about its vertical axis. It’s during this dance that a beetle takes its snapshot, which it stores in its brain for future reference. When the beetle starts to roll its ball of poop, it’s able to move in a straight line by matching the internally stored image of the sky with its current environment. As the researchers conclude in their study, it’s “a simple but efficient mechanism for straight-line orientation.”


Very cool, dung beetles, very cool.


[Current Biology]
Lead is a relatively soft metal, and the fact that it deforms on impact is what makes lead bullets so deadly. It expands inside whatever it hits causing more damage to the surrounding area. But there are metals much softer than lead, and their effects on contact are even more pronounced—so naturally someone made them into bullets.
In a previous video, The Backyard Scientist filled some shells with sodium and potassium and tested them by shooting the bullets into a fish tank. In that experiment, the softer metals expanded and deformed much faster than lead, blooming into a sort of underwater mushroom-shaped blast. But because their kinetic energy was expended almost immediately the penetrating power was considerably less intense than with traditional bullets.


Thankfully, we aren’t going to find out what that reaction looks like inside a person. But using a watermelon as an analog, a softer target explodes immediately. And it’s goddamn terrifying! Don’t be deceived by the pyrotechnics. Consider that lead bullets snap right through a cinder block with ease, while the softer metals hardly made a dent.
The sodium doesn’t react with all that water inside the melon. Luckily, a couple aerosol cans are thrown in to feed your hunger for explosions.


Cast your mind back to high school chemistry and you might remember the van der Waals force: The weak bond between molecules, caused by the way their electrons shift at the atomic level. Now, for the first time, those tiny forces have been measured between two atoms.
Van der Waals forces are caused by fluctuating electric fields around molecules and atoms, which can cause small attractive or repulsive forces to be generated. While they’re considered weak at the atomic level—ionic and covalent bonds are much stronger—they can add up to be surprisingly useful, allowing geckos to climb walls and strapless bras to provide support.


But researchers from the Swiss Nanoscience Institute and the University of Basel wanted to measure these forces between single atoms. To do that, they embedded different noble gas atoms—including argon, krypton and xenon—into a molecular grid made of copper atoms. The team refers to the voids within these grids as “nano-beakers of copper atoms in which the noble gas atoms are held in place like a bird egg.”
Then, using an atomic force microscope, the team was able to measure the small changing forces between the noble gas atoms when they were placed at different distances from each other. When comparing their measurements to those predicted by theoretical calculations, the team found their results to be broadly consistent—though there were instances where the forces between xenon atoms were twice what was expected. The team reckons this could be the result of weak covalent bonds forming, rather than unusually high van der Waals forces being generated. The research is published in Nature Communications.


These are the smallest forces ever detected between individual atoms, and the team will be able to use the results to understand the physical behavior of atoms better than ever.


[Nature Communications via PhysOrg]
The Amer­ican artist Peter Halley has taken over 5,000 square feet of the Schirn Kunsthalle exhibition hall in Frank­furt, turning its huge rotunda into a futuristic exploration of architecture and space that’s inspired in part by the LHC.
Best known for his Day-Glo paintings from the 1980s, Halley uses similar vivid glowing colors in this instal­la­tion too. While developing it, he apparently thought about other structures that shared the geometry of the Schirn’s rotunda, settling on the Large Hadron Collider. He apparently “imag­ined the Rotunda itself as a high-energy collider full of explo­sive energy bathed in light,” according to the Schirn.


Called The Schirn Ring, the installation is open to the public from May 12th to August 21st.
[Schirn]
The destructive power of nuclear bombs has been seared into our collective memory, thanks to archival images of the devastation of Hiroshima and Nagasaki. There’s the blast itself, and then all the radioactive fallout to contend with. A new interactive map shows what the damage from fallout would be if nuclear bombs were dropped on target cities today.
It’s the result of a collaboration between the Future of Life Institute (FLI)—a volunteer organization dedicated to decreasing existential threats to the human race co-founded by MIT physicist Max Tegmark—and Alex Wellerstein, a science historian at the Stevens Institute for Technology in New Jersey who developed the hugely popular NUKEMAP a few years ago. (Wellerstein was also the technical consultant for the stellar—and tragically cancelled—TV series, Manhattan.)


A few months ago, the National Security Archive released a 1956 US list of 1,100 nuclear targets in the Soviet Union, Eastern Bloc, China, and North Korea. FLI digitized the entire dataset, and approached Wellerstein about adapting NUKEMAP to the digitized targets. He realized he could use the new data to model nuclear fallout and possible casualties from detonated bombs.
Wellerstein ran two equally terrifying scenarios. First, he wondered what would have happened if bombs were dropped on all 1,100 targets on a single day: April 29, 2016. Second, he simulated how the direction of the radioactive fallout would change if bombs had been dropped on those targets on three consecutive days (April 29, April 30, and May 1, 2016).


There are many different factors that influence the extent of nuclear fallout, notably weather conditions and the size of the bomb. Wellerstein was able to draw on data from OpenWeatherMap to give his model realistic weather conditions on the days in question. But it also matters if the bomb detonates high in the air or on the ground; with the former, there is far less downwind fallout.
“This is because the fallout that makes the distinctive, high-radiation plume downwind of the weapon is largely made up of dirt or debris particles that have been sucked up into the radioactive fireball, and ‘fall out’ rather soon (within a few hours) after the blast,” Wellerstein told Gizmodo. “If the fireball avoids vaporizing dirt or debris, the radioactive products (the remains of the split atoms) stay hot and light longer, and thus in the upper atmosphere longer. They have longer to decay before they fall to the Earth, so the really radioactive stuff ‘burns out’ sooner and diffuses over a larger area.”
All the heavy fallout plumes in his visualization assume surface bursts, when in reality, there would likely be a mix of surface and airbursts, depending on the target. Bunkers or airfields, for instance, need heavier pressure to destroy, so those targets would probably require surface bursts. In contrast, homes and civilian buildings wouldn’t needed as much pressure, so airbursts would suffice for those kinds of targets.
There would also probably be more than one nuclear bomb per target in reality, since the military would expect that not every bomb would reach its target. NUKEMAP’s estimator assumes single detonations. So the really large casualty estimates in particular should be taken with a grain of salt, since there is likely to be some double counting of victims. But it’s probably a good ballpark figure if you add in longer-term casualties from fallout and the destruction of crucial infrastructures.


Those caveats aside, Wellerstein thinks the project still manages to illustrate the scope and magnitude of nuclear fallout from bombs dropped on those targets. Lest you think this is just an academic exercise: the declassified 1956 list of targets probably isn’t much different from the current US list, according to the FLI. And while most nuclear nations agree that less than 300 nuclear weapons are sufficient to achieve deterrence, the US alone has about 1900 warheads ready for deployment within 30 minutes. Russia’s not far behind. The threat of nuclear winter is closer than you might think.
“Despite the fact that nuclear weapons issues are in the newspaper almost daily, for most Americans they have sunk into the background of things,” said Wellerstein. “A lot of this happened when the Cold War ended and we all congratulated ourselves on ‘winning.’ But the weapons have stuck around. I think people are starting to remember that, bit by bit. I like to think my work is playing a small part in that.”


[Motherboard and Nuclear Society]
Comets brush by us all the time, but they’re usually not close enough for us to catch anything more than a glimpse as they streak through the sky. But, thanks to one very close comet, Hubble just got an incredible insider view.
Last month, Comet 252P/LINEAR came within a little over three million miles of earth. This was one of the closest approaches to our planet by a comet ever, and it gave the Hubble telescope an unusual opportunity for a little close range photography. Besides our own moon, this comet is the closest object the Hubble telescope has ever photographed.


That up-close view paid off with the time-lapse you see above showing the nucleus of the comet moving around like, as NASA describes it, a high-powered lawn sprinkler. Although the nucleus measures just one mile across, the comet still manages to kick all manner of interstellar dust in every direction.
Seeing all that internal movement, it’s no wonder that—even from so far away—debris from passing comets still makes it through our atmosphere as meteor showers. In fact, Comet 252P/LINEAR was so active that, although there’s no regular meteor shower associated with it yet, NASA has flagged it as having the potential to rain down a future one.
When I asked Johnny Matheny if I could shake his hand, I was admittedly a little nervous. The soft-spoken Floridian lost his lower left arm to cancer eight years back. His new arm—an advanced, mind-controlled prosthetic developed by DARPA—can crush a human human skull like a child squeezing a clementine.
Of course, Matheny is a professional, and he gave me a very controlled, firm handshake. While you’d never mistake the robotic, carbon fiber arm for its flesh-and-blood counterpart, in terms of dexterity, the two are pretty darn close. If we’re talking raw strength, the synthetic arm is far superior.


“This thing has as good a range of motion as a natural hand,” Matheny said in his charming southern twang, explaining how he could greet you with his right hand while opening a car door behind him with his left. “The only thing it can’t do is the Vulcan V,” he added, referring to the universal nerd pride gesture popularized by Star Trek.
We've known for a few years now that DARPA-funded prosthetics research is yielding some pretty …
Matheny is a bonafide cyborg—one of the most advanced in the world. The “Modular Prosthetic Limb” he was wearing when we met at a DARPA technology expo this week is a highly articulated, computer-driven device designed for full neural integration. That means it’s capable of receiving signals from the human brain and, paired with the right surgical implants, transmitting signals to the brain.

This is a far cry from the rigid, strap-on prosthetics tens of thousands of men and women wear today. Pairing an artificial limb with a organic brain is a dream straight out of science fiction, something DARPA proudly acknowledges. (In fact, DARPA and the company DEKA are working on another mind-controlled prosthetic arm that’s nicknamed “Luke” after Luke Skywalker.)
Amputees may one day regain actual feeling thanks to Darpa and researchers at Case Western…
“The goal is really to capture the brain’s intent and turn it into motion very naturally,” said Justin Sanchez, director of the Biological Technologies Office at DARPA. Sanchez, who was at the Pentagon helping DARPA show off its badass prosthetics this week, explained that the Myo armband Matheny was wearing around his upper arm picks up electrical signals from his muscles. Those signals are transmitted via Bluetooth to a computer inside the prosthetic arm, which drives motors inside the device.
Matheny has been test-driving prosthetics for DARPA since 2011, and his ability to interface with machines has gotten some major upgrades along the way. Years ago, he received targeted muscle reinnervation (TMR), a surgical procedure that reassigns nerves in a residual limb to make better use of a prosthetic replacement. In the spring of 2015, Matheny became the first American with TMR to undergo osseointegration, another surgical procedure that allows him to connect prosthetic devices directly to the bone of his upper arm. When he first attached the Modular Prosthetic Limb via osseointegration last fall, the transformation was immediate. “Before, I had limited range; I couldn’t reach over my head and behind my back,” Matheny said at the time. “Now boom, that limitation is gone.”


And all of this is just the beginning. Pointing to his robotic fingertips, Matheny explained that they already contain tactile sensors capable of detecting texture, pressure, and temperature. But in order for Matheny to feel what his prosthetic arm feels, those signals have to reach his brain. In the not-too-distant future, another surgical procedure may enable this.
It entails implanting two small devices along nerves bundles in Matheny’s chest and back. These nerves, which are wired directly to the brain’s somatosensory cortex (a region where sensations are processed), would be stimulated based on information beamed wirelessly from the prosthetic hand. In essence, DARPA wants to create a closed circuit that melds synthetic and biological wires.
DARPA is working hard to fine-tune those sensory implants, in addition to implants that transmit information the other way to replace wearable devices like the Myo armband. “The Myo band has to be calibrated every day, and it only offers so much control,” said Doug Weber, program manager at DARPA’s Biological Technologies Office. “Once you have smaller sensors that can be implanted into many muscles, you can get many more control channels. Instead of having to do things sequentially: moving my elbow, wrist, then fingers, I can do all of those things together.”
Early versions of these implantable devices are already being tested in humans. So far, the result are promising: the technology not only restores a sense of touch, it can dramatically reduce the phantom limb pain experienced by many amputees.


The life-changing impact of DARPA’s mind-controlled limbs was clear after spending just a few minutes with Matheny—as was the fact that we’ve barely scratched the surface of this technology’s potential. Devices like the Modular Prosthetic Limb may be expensive and experimental for now, but it’s not hard to imagine them becoming widespread in the future. In fact, I can’t help but wonder whether our cyborg descendants—sporting modular arms that fit tools of all shapes and sizes—will look back on the early 21st century and wonder how humans ever got on with two flimsy, organic meat sticks, equipped with only ten fingers each.
Researchers from the University of Illinois at Urbana-Champaign think mimicking nature is the best way to help robots take flight. So with the help of a 3D printer they’ve created a flying robotic bat complete with a layer of fake silicone skin for the wing’s membranes. It somehow manages to make real bats look almost cute in comparison.

Weighing in at just 92 grams thanks to a carbon fiber airframe, the Bat Bot—or B2, for short—uses five motors on board to control the flapping and articulation of its wings. It’s intelligent, too, with an onboard microprocessor and sensors that allow it navigate a room without the need for an exterior motion capture system keeping it out trouble.
After watching the videos of this creation in flight, there’s only one real question we have for the team of researchers: can this technology be scaled up to realize our Batman fantasies, and how soon can you deliver it?


[YouTube]
In a universe full of planets, 2007 OR10 is something special. It’s big, just slightly smaller than the size of Pluto. And it’s close, within our very own solar system. So how did it still manage to take astronomers by surprise?
Researchers from Konkoly Observatory just revealed in the Astronomical Journal that they had uncovered new details about planet 2007 OR10 that show it to be the third largest dwarf planet ever seen in our solar system. New planets are uncovered all the time, thanks to Kepler. In fact, the mission just unearthed a stash of more than 1,200 new exoplanets, bringing its total haul to over 3,200. 2007 OR10 has a diameter of 955 miles, which makes it a relative monster. The only larger dwarf planets in our solar system are Pluto, which has a diameter of 1475 miles, and Eris, which has a diameter of 1445 miles. 2007 OR10 is the third biggest dwarf planet in our solar system—and the largest unnamed planet of any kind within our solar system.
Even dwarf planets that are considerably smaller, like Haumea and Makemake, are considered big enough to need names.


Researchers have known a planet was out there since 2007, but they vastly underestimated just how big it is. The reason its tremendous size wasn’t determined until recently lies in both the planet’s dark surface and its strange orbit. The surface of the planet is an incredibly dark red, perhaps due to a ever-changing covering of methane ice. That lack of reflective light made it hard for Kepler to even spot the planet, much less know its true size. The planet also has an incredibly slow rotation time that gives it a 45 hour day, one of the solar system’s longest. That slow rotation, plus a long, elliptical orbit, made it hard to spot the planet for long—although Kepler managed to catch brief glimpse in 2014, as you see here:

The dwarf planet could have easily continued to evade astronomers examination if the Konkoly researchers hadn’t thought to pair NASA Kepler data with ESA Herschel data. By combining information about the amount of light the planet was reflecting from Kepler with information about its heat radiation from Herschel, researchers were finally able to calculate an accurate size measurement. The finding also suggests an avenue for learning much more about all those little (or perhaps not-so-little) new planetary discoveries that are popping up all the time now.


For 2007 OR10, these results mean both that we’re finally aware of the existence of one of the largest dwarf planets nearby and that we know more about what that planet is like. With the new size measurements confirmed, the Palomar Observatory astronomers who discovered the planet back in 2007 have also already begun contemplating possible names. From there, the dwarf planet will begin the process of being recognized by the International Astronomical Union, which could take a while to finally wrap up. Still, it means that 2007 OR10 won’t be keeping that designation for long.
European scientists have unveiled an ice drill designed to penetrate three to six feet into the frigid lunar surface. According to plan, this device will start drilling into the Moon’s south polar regions in 2020.
Developed for the European Space Agency (ESA) by tech company Finmeccanica in Nerviano, Italy, it’ll be the first drill to penetrate the Moon’s frozen “regolith.” Once it bores through the ice, it’ll autonomously deliver samples to a chemical laboratory, which is currently under development by engineers at the UK’s Open University.


The Moon’s southern polar region is exceptionally cold, with some areas completely obscured from the Sun. These polar regions, which feature shadowed areas and permanently dark craters, likely contain water ice and other frozen materials. The purpose of the mission is to prospect for elements and investigate the potential use of these resources. Looking ahead, this survey could lead to a habitable base on the Moon’s far side.

The development team has already tested a prototype of the drill under simulated lunar conditions reaching -140 degrees C (-220 F). But the permanently shadowed regions of the Moon are likely much colder, reaching lows of -240 degrees C (-400 F). The ice drill will have to reach those tolerances in subsequent tests if it’s going to work.


The plan right now is to get the drill to the Moon’s south pole on Russia’s Luna-27 lander, which is scheduled to launch in 2020. But due to recent budget cuts at the Russian space agency Roscosmos, we may have to wait until 2025.
[ESA]
Like snowflakes, no two planetary systems are the same. Astronomers have now observed one of the most unique planetary arrangements ever seen: four miniature Neptunes locked in perfect synch with each other—and it’s been like this for billions of years.
Astronomers discovered the Kepler-223 star system several years ago using the Kepler Space Telescope, at which time they catalogued four Neptune-like planets spinning close to their star. And by close they mean it; all four of these gaseous planets are orbiting at a distance closer than Mercury is to our sun. But that’s not even the most interesting part. Researchers from UC Berkeley and the University of Chicago have now learned that this quartet of miniature Neptunes is locked in an orbital dance that’s never been seen before.
Here’s how this particular planetary resonance works: Each time the innermost planet orbits eight times, the next planet down the chain orbits exactly six times, followed by orbits of four and three respectively. More simply, these synchronized orbital periods can be expressed as the ratio 8:6:4:3. Put another way, Kepler-223’s two innermost planets are in a 4:3 resonance, the second and third are in a 3:2 resonance, and the third and fourth are in a 4:3 resonance. Astronomers have observed extrasolar systems containing two or three planets in resonance but never four.


“This is the most extreme example of this phenomenon,” noted study co-author Daniel Fabrycky from the University of Chicago in a release.
Cool, right? And it’s been this way for billions of years, which is just as strange. Usually, these delicate arrangements are jostled out of place by the gravitational pull of neighboring celestial objects, such as other planets and large asteroids. Extreme tidal forces can do the same.

Over the course of millions of years, the orbits have turned from elliptical to circular, and then back again. The resonance ratio may not change, but the planets’ gravitational effect on each other most certainly does. A simulation provided by the researchers (shown in the above video), chronicles millions of years of this orbital evolution. This planetary resonance can even be expressed in musical form:

Resonant orbits aren’t uncommon. In fact, Neptune and Pluto are caught in a 3:2 resonance. Each time Neptune orbits three times, Pluto completes its orbit of the sun twice. But four planets caught in this cosmic dance? That’s almost unheard of.


Almost. Astronomers theorize that our solar system once featured a four-planet resonance between the four gas giants, Jupiter, Saturn, Neptune, and Uranus. But at some point in their 4.5-billion-year history, these planets got knocked out of their elegant arrangement.
Kepler-223 is helping astronomers understand how our solar system and other star systems formed. It could even solve the question of whether planets stay in the same place where they formed, or whether they migrate inwards or outwards from their host star over time.
“Basically, this system is so peculiar in the way that it’s locked into resonances that it strongly suggests that migration is the method by which the planets formed—that is, migrating inward toward the star after forming farther out,” noted study co-author Howard Isaacson in a Berkeley release.
In the case of Kepler-223, these planets could have assumed their resonant positions around their star within a few 100,000 to 200,000 years. Soon after forming, two of the planets began to migrate toward the star, but then got stuck together, and then continued their inward migration together. Then they locked onto a third planet, and so on until all four planets were synchronized and locked into stable stellar orbits.


But the astronomers suspect that there are other circumstances that permitted the resonance to persist for six million years, namely the absence of other celestial bodies.
“These resonances are extremely fragile,” noted Fabrycky. “If bodies were flying around and hitting each other, then they would have dislodged the planets from the resonance.” Kepler-223’s planets, it would appear, somehow managed to dodge this scattering of cosmic bodies.


[Nature]
The leading cause of death worldwide isn’t an infectious disease or cancer. It’s air pollution. And despite our best efforts to control it, smog is still increasing at an alarming rate worldwide, posing a health risk to over 80 percent of all city dwellers.
The smog hovering over many major cities is not just an unhealthy inconvenience. Breathing that air …
That’s the sobering conclusion of an update released today by the World Health Organization, whose global air pollution database tracks annual mean concentrations of fine particulate matter—tiny particles of sulfates, nitrates and carbon that bury themselves deep in human lungs. The WHO was able to compare information on particles smaller than 10 or 2.5 microns (PM10 and PM2.5) across 795 cities in 67 countries between 2008 and 2013.


Since the WHO’s last global analysis, cities around the world have seen an eight percent growth in outdoor air pollution. A whopping 98 percent of cities in low and middle income countries do not meet the WHO’s air quality standards, placing residents at a greater risk for stroke, heart disease, and acute respiratory illnesses. In wealthy countries, the number of cities with unclean air falls to 56 percent.
Overall, the worst air pollution was seen in India, southeast Asia, and the Middle East, where annual mean levels of particulate matter often exceeded WHO limits by a factor of 10. But the dirtiest air in the world goes to Onitsha, a trading city in southern Nigeria where PM10 concentrations average nearly 600 micrograms per cubic meter. The safe recommended limit is 20.


“We have a public health emergency in many countries,” Maria Neira, director of public health at the WHO in Geneva told The Guardian. “Urban air pollution continues to rise at an alarming rate, wreaking havoc on human health. It’s dramatic, one of the biggest problems we are facing globally, with terrible future costs to society.”
All of this is, of course, can be tied to rapid population growth, urbanization, and industrialization. When countries impose stricter emissions regulations on power plants and vehicles, and when cities make greater investments in public transit, walking and biking networks, the drop in air pollution is immediate and dramatic. In fact, if you live in a country whose industrial revolution took place over a century ago, it can be easy to forget that air pollution is still such a problem today.
But whether it’s your backyard or not, this is something we all need to worry about. The more resources we have to spend fighting a public health crisis that claims up to 5.5 million lives a year, the harder it is to double down on the investments in clean energy infrastructure we need to keep our global atmosphere safe for future generations.
[WHO via The Guardian]
Many of us have experienced prolonged stretches of driving where we’re seemingly oblivious to our surroundings, and we’re left dumbfounded that we didn’t get into a serious accident. A new study suggests that a specific brain function protects us from these bouts of absentminded driving—but that it completely breaks down while texting.
In 2014, over 3,000 people were killed as a direct result of texting while driving, while another 431,000 were left injured. And there are other forms of distracted driving that are worthy of attention, such as absentminded driving, or driving while upset. A team of scientists from the University of Houston and the Texas A&M Transportation Institute recently embarked on a project to study the various ways drivers become distracted, and how it affects their performance.
Their results, which now appear in Scientific Advances, shows that absentminded driving, or driving while angry or upset, is not nearly as bad as previously assumed—and in some instances, can actually improve our driving (up to a point). The reason, said the researchers, has to do with a part of our brain that acts like a “sixth sense,” protecting us from distractions. At the same time, this cognitive process becomes impaired when we’re incessantly looking up and down at our smartphones—an observation that reaffirms just how dangerous texting-and-driving really is.
The purpose of the study, led by Ioannis Pavlidis from UH and Robert Wunderlich of TTI, was to measure the effects of three distinct factors in driving performance. The team wanted to know how drivers behave when they’re absentminded, emotionally charged, or texting.


The researchers recruited 59 participants and put them in a driving simulator. Each of them was asked to drive the same segment of highway four times, but under varied conditions. These included “normal conditions” and three specific distractions: driving while being asked challenging questions (like annoying math problems), driving while being asked emotionally charged questions, and driving while texting. The order of these driving experiences were randomized to prevent bias.
Using thermal imaging and other biofeedback instruments, the researchers analyzed the mental states of the drivers at every point in time to see how this affected their performance. Unlike previous studies, this research considered variables that related both directly and indirectly to sympathetic nervous system responses, making it one of the most comprehensive studies ever done on distracted driving.


Results showed that all three interventions—absentminded, emotional, and texting—impaired the drivers’ ability to handle the wheel, or what the researchers described as “jittery handling.” But this jittery behavior only resulted in serious problems, such as clumsy lane deviations and unsafe driving, when the participants were texting. In the case of absentminded and emotionally charged instances, the jittery steering actually resulted in slightly straighter trajectories compared to normal driving. The researchers suspect this apparent paradox is likely a function performed by a specific part of the brain called the anterior cingulate cortex, or ACC.
Pavlidis says that the ACC is compensating for our distractions, and it automatically kicks in when the need arises. In the case of driving, the ACC counterbalances a strong jitter to the left with an instant and equally strong jitter to the right, and vice versa. The ACC works to offset all this veering, resulting in exceptionally straight driving. Remarkably, we’re largely unaware that this is even happening.


“This appears to be a sort of ‘auto-pilot’ we are endowed with,” Pavlidis told Gizmodo.
Here’s the thing about the ACC, however. It needs support from the driver’s eye-hand coordination to work. During texting-and-driving, this loop breaks down, and the ACC fails. The jittery handling of the steering wheel is left unchecked, which results in significant lane deviations. The other problem with texting, of course, is that it’s literally diverting a person’s attention away from the primary task of driving.
“The driver’s mind can wander and his or her feelings may boil, but a sixth sense keeps a person safe at least in terms of veering off course,” Pavlidis said. “What makes texting so dangerous is that it wreaks havoc into this sixth sense. Self-driving cars may bypass this and other problems, but the moral of the story is that humans have their own auto systems that work wonders, until they break.”


At the same time, Pavlidis said we shouldn’t reach to the glove compartment, or get physically distracted while we’re emotionally engaged or absentminded. “The ‘corrector’ will fail that moment and because the underlying steering wheel handling is jittery—due to hidden stress—this will lead to a large and dangerous lane deviation,” he said.
I hate being tailgated. Once, I surprised the hell out of myself when I initiated an exceptionally…
This is not to suggest that emotional states don’t affect driving performance—they most certainly do. But until a certain threshold of agitation or annoyance is attained, emotional states don’t really compromise our driving ability. At least that’s what this research suggests.


Pavlidis and Wunderlich next want to take their research outside the lab to test drivers in real world conditions. One of their goals is to create a “stressalyzer,” that monitors a driver’s biosignatures, and alerts them when they’re becoming too distracted.
“It’s like you’re boiling something, and you have the lid tight, so it’s safe,” Pavlidis said. “But if at any point in time something should happen, the lid will basically blow up—so we don’t want this to go on. We want to bring things back to a pre-boiling point, and we’re looking into countermeasures, and we’re looking at biofeedback to do it.”
[Scientific Advances]
We know that mixing sodium with water causes awesome explosions. We know that skipping rocks across a lake is very probably one of the funnest things you can do outdoors. Next time, we’re all bringing a pound of sodium to the lake so we can watch it explode over and over again as it skips its way across the lake. It’s the simple things in life, you know.


In a story that keeps on getting weirder, a scientist familiar with the Mexican region where a Canadian teen claims to have discovered a lost Maya settlement says at least one of these features is either an abandoned cornfield—or a marijuana operation.
Ever since we and other outlets published the story yesterday about a Canadian teen, William Gadoury, who used star maps to triangulate the position of a lost Maya city, a number of experts have claimed it’s anything but. Consensus is that these rectangular green features—which were observed in satellite images—are actually relic milpas, or abandoned corn fields. Trouble is, none of the experts we talked to actually visited the site, leaving the true identity of these objects a mystery.


We’ve now heard from an anthropologist from the University of California San Diego’s Mesoamerican Archaeology Laboratory who’s actually seen this area with his own eyes. “We’ve visited them, and my grad students know them quite well,” explained Geoffrey E. Braswell to Gizmodo. “They’re not Maya pyramids.”
Braswell and his colleagues are familiar with this remote part of Mexico because they’re collaborators on a German-Mexican archaeological project near the area, one led by Nikolai Grube from the University of Bonn and Antonio Benavides from Insitituto Nacional de Antropología e Historia.


One of the images (above in the banner) shows two rectangular features on the southeast edge of a dried seasonal lagoon. Braswell says it’s the Laguna El Civalón in southeast Campeche, Mexico (located at 17o 56’ 42” N by 90o 10’ 0” N). He says the pair of features are not Maya pyramids, but rather small fields filled with weeds.


“They’re either abandoned cornfields, or active marijuana fields,” he told Gizmodo. Intriguingly, marijuana operations are common in the area.
The second image shows a small seasonally dried patch of swamp about 1,640 feet (500 m) north of the Laguna El Manguito, also known as San Felipe (located at 17o 53’ 44” N by 90o 6’ 35” W). Again, not an ancient pyramid, but there is an interesting colonial archaeological site nearby.
“I personally recognized it just by looking at the image, and then by confirming it on Google Earth,” said Braswell. “I’m like, ‘Yeah, I know that one.’”


The key issue with this kind of remote sensing, says Braswell, is what’s called “ground truthing.”
“You look at images from space and God knows what they are—you have to go there and see for yourself,” he said. “Nine times out of 10 it’s nothing, every once in a while it’s something. But by pure luck we’ve actually been there, and [so have] many members of the German-Mexican project that we’re a part of.”


Importantly, archaeologists have been exploring these areas since the 1930s. In fact, these vast stretches of jungle in the Yucatan have been photographed from the air for decades, including contributions from none other than Charles Lindbergh. “It’s been known for quite some time,” said Braswell.
The world’s oldest axe—dating back at least 46,000 years—has been uncovered in Australia. And, already, there’s a mystery surrounding it.
The axe—by this time reduced to mere flakes, which you can see below—was originally found in a dig during the ’90s. But researchers from Australian National University only recently managed to identify and date the object, the results of which they published in Australian Archaeology. It’s the first instance ever found of an axe with a handle attached. The next one doesn’t show up in the archaeological record for over another 10,000 years.
The real question, though, is what was this early axe used for? The vast majority of very old axes found by archaeologists are eventually pinned down as agricultural tools. This axe, however, predates the widespread advent of agriculture by about 30,000 years. Archaeologists have already posited a few possible explanations, including the rather meta-explanation of it being for the purpose of making smaller blades, or perhaps as an early tool to take down trees.


Still, as of now, the axe’s purpose remains unknown. Whatever that purpose was, it must have been a rather limited one. Although axes may have originated with this early example, archaeologists were unable to find any evidence that later examples of the technology had spread from this earliest finding.
The FDA just announced plans to rethink its definition of “healthy” food. So, what does that “healthy” label you’re seeing right now mean? Not as much as you might think.
The FDA has been in a year-long scuffle with KIND granola bar makers over the company’s insistence on sticking a “healthy” label its products. Now, although nothing has changed in the granola bars, the agency has given permission for the company to keep the word on its package. But in light of the controversy, the FDA says it will also “reevaluate regulations concerning nutrient content claims, generally, including the term ‘healthy’.”


Unlike “natural” food labels—which exist in a lawless, post-apocalyptic food wasteland where anything goes—the FDA established a pretty clear definition for “healthy” years ago. The current FDA definition for “healthy” insists, not unreasonably, that any food labeled as such must be within the bounds of FDA dietary recommendations for total fats, saturated fats, cholesterol, and other nutrients.
A box of powder-cheesed macaroni? Natural! A candy bar? Sure, why not: natural! A can of 7-Up? All…
It was that definition that made the agency investigate KIND granola bars for their “healthy and tasty” label last spring. In an admirable show of restraint, the FDA left the tasty part to individual determination. The agency did, however, issue a devastating point-by-point take down of the KIND health claims, explaining that none of the company’s products met minimal standards for being considered healthy.


KIND has now managed to get around the warning by convincing the FDA that “healthy” is not meant to be a literal nutritional claim in this context but rather a “corporate philosophy.” Essentially, it’s being used as a slogan—just like other food companies have long used “natural.” The difference is that “natural” was left open to food marketers, because it didn’t have an FDA definition. The term “healthy” does.
The FDA’s reevaluation of the definition could lead to stronger requirements that would keep “healthy” from going the way of “natural.” There’s already a move towards revamping “natural.” The FDA just wrapped up a request for comments on what people believed the “natural” labels on their food meant this week, perhaps as a first move towards defining it. Now, the agency will launch a similar process of scrutiny over the definition of “healthy.”
The agency revealed those plans in a statement:
Consumers want to make informed food choices and it is the FDA’s responsibility to help them by ensuring labels provide accurate and reliable nutrition information. In light of evolving nutrition research, forthcoming Nutrition Facts Labeling final rules, and a citizen petition, we believe now is an opportune time to reevaluate regulations concerning nutrient content claims, generally, including the term “healthy.” We plan to solicit public comment on these issues in the near future.
Just how far off that not-too-distant future remains is uncertain.


“There is no timeline right now,” an FDA spokesperson told Gizmodo, stressing that any new definition would still lean heavily on the existing one. “We would not characterize this as a ‘reversal’ [of the agency’s previous position]. The FDA expects companies to continue to meet the current requirements for nutrient content claims that include the term ‘healthy.’”
For now, if the word “healthy” is written on the label of your snack, remember that it’s not necessarily good for you.

A Canadian teen says he discovered a lost Maya city using ancient star maps and satellite images provided by NASA and Google. As the remarkable story went viral yesterday, a number of experts spoke out, saying it’s highly unlikely that these features are those of a forgotten Maya settlement.
News swept the internet yesterday that William Gadoury, a 15-year-old boy from Quebec, found a lost Maya city in Mexico by correlating the locations of known settlements with the positions of the brightest stars. He received help from the Canadian Space Agency (who provided satellite images, and who described Gadoury’s work as “exceptional”) as well as Dr. Armand LaRocque, a remote sensing specialist from the University of New Brunswick. The teenager won a medal of merit for his discovery and was invited to contribute an article to a scientific journal. Gadoury also received invitations to the national science fair at McGill University and an international conference in Brazil.


But other experts have expressed skepticism at Gadoury’s findings, saying the features shown in the space-based photos are merely abandoned corn fields. What’s more, they argue that the Maya people, though good astronomers, probably did not choose to settle in areas based on the positions of the stars.
“I applaud the young kid’s effort, and it’s exciting to see such interest in the ancient Maya and remote sensing technology in such a young person,” said Thomas Garrison, an anthropologist at the University of Southern California: Dornsife and an expert in remote sensing. “However, ground-truthing is the key to remote sensing research. You have to be able to confirm what you are identifying in a satellite image or other type of scene.”
In this particular instance, Garrison says the rectangular nature of the feature and the secondary vegetation growing back within it are “clear signs” of a relic milpa. A milpa is a crop-growing system used throughout Mesoamerica, primarily in the Yucatan peninsula area of Mexico (which is exactly where this supposed lost Maya city is located). The word milpa is taken from the Nahuatl term for “maize field.”


“I’d guess it’s been fallow for 10-15 years,” Garrison told Gizmodo. “This is obvious to anyone that has spent any time at all in the Maya lowlands. I hope that this young scholar will consider his pursuits at the university level so that his next discovery—and there are plenty to be made—will be a meaningful one.”
Garrison provided Gizmodo with this image of a similar feature in an area where he works in Guatemala. He says the milpa was abandoned quite recently:
David Stuart, an anthropologist from the Mesoamerica Center-University of Texas at Austin agrees, but his words were less kind. At his Facebook page he referred to Gadoury’s work as “junk science.”
“Seeing such patterns is a rorschach process, since sites are everywhere, and so are the stars,” he wrote. “The square feature that was found on Google Earth is indeed man-made, but it’s an old fallow cornfield, or milpa.”


Ivan Šprajc, a researcher from the Institute of Anthropological and Spatial Studies in Slovenia, also said the idea that the Maya correlated their settlements with stars is “utterly” unlikely.
“We do know that the Maya were very good astronomers and that they were interested in certain stars and asterisms,” he explained to Gizmodo. “But how could constellations reveal the location of Maya sites remains a mystery to me. Very few Maya constellations have been identified, and even in these cases we do not know how many and which stars exactly composed each constellation.”
As a result, Šprajc says it’s impossible to confirm whether any correlation exists between the constellations and the location of Maya cities. Moreover, anthropologists know of several environmental factors that did influence the location of Maya settlements in the central Yucatan lowlands, such as proximity to small lakes. (Also known as “aguadas,” these pools were the only fresh water sources in this karstic environment, which is landscape characterized by the dissolution of soluble rocks and underground drainage systems with sinkholes and caves.) The Maya cities were also positioned on slightly elevated grounds, and on the edges of wetlands called “bajos” which were appropriate for intensive agriculture.


“This is not to say that astronomy was not important to the Maya,” said Šprajc. “On the contrary, they were keen observers of the sky, they knew the eclipse cycles and were capable of predicting significant moments in synodic cycles of Venus and probably of other planets.”
Šprajc says that astronomy did play an important role in architecture and urban planning, but it was based on phenomena observed on the horizon, namely significant rising and setting points of some celestial objects, particularly the sun. This often dictated the orientation of important buildings, and sometimes even their placement relative to each other.


Lastly, Šprajc pointed out that the coordinates of the Maya city, which Gadoury claims is in northern Guatemala, is actually located in southern Campeche, Mexico. He also believes, like Garrison and Stuart, that the features shown in the satellite photos is an old milpa, abandoned years ago “but definitely not centuries ago.”
Based on these expert reactions, it seems unlikely that this Canadian teen’s green rectangles are lost Maya structures. But as Garrison pointed out, only a ground-based expedition to the area will confirm things one way or another. At the same time, while Gadoury’s enthusiasm and creativity should continue to warrant praise, the contributions of the Canadian Space Agency and from Armand LaRocque, the University of New Brunswick professor who corroborated the Gadoury’s research, deserve further scrutiny.
We’ve reached out to Gadoury, the Canadian Space Agency, as well as LaRocque for comment and will update this post if we hear back.
Update: 15:10: We received a response from Daniel De Lisle, Project Officer, RCM Data Utilization & Applications at the Canadian Space Agency, who assisted William Gadoury with his project.


We asked De Lisle to respond to the claims made by experts that this is “junk science,” and that the objects in the satellite photos are probably abandoned milpas. To which he responded: “The area of interest covers more than 78 square kilometers, and many linear features that appear manmade are visible from space.” Which is not much of an answer.
We also asked him if the CSA sought expert advice from Maya experts at any point during the project.
“CSA provides an opportunity to explore the enhanced capabilities of RADARSAT-2 and their potential contributions to various applications,” he responded. “This opportunity consists of a loan of RADARSAT-2 data to research projects. The main outcome pursued by CSA is to ensure that Canadian stakeholders benefit from the investment in this satellite, through research and development activities. Scientists are responsible of their research and must acknowledge the CSA provided the imagery in their publications.”


Again, not much of an answer.
“The only way to know is to organize an expedition on the site to validate,” he said. And on this point, he’s correct—but it’s looking damn unlikely there’s anything at the site of interest.
As the world continues to warm up, the ice at our poles melts and moves faster than ever. This satellite image reveals just how quickly ice is moving on the Antarctic Peninsula.
The data is taken from the European Space Agency’s Copernicus Sentinel-1A satellite. To measure how fast the ice moves, researchers compare pairs of radar images taken by the satellite, 12 days apart. Tracking features on the surface allows them to measure the speed at which the ice moves.


The color scale shows the speed of ice movement. Blue is slow, in the region of an inch per day, while red indicates that ice is moving at around 3 feet per day. Three freakin’ feet, per day.
The ESA explains what you can see in the image:
The vivid colours trace a complex network of channels along which streams of ice flow from the high mountains down towards the coast where the ice flow speeds up and spreads out into floating ice shelves.
[ESA]
The strongest El Niño ever seen is finally gone. But before it left it had plenty to throw at us: Storms, droughts, blackouts, thousands of pounds of dead fish. And we finally know just what it was that made El Niño so furious.
Researchers know a lot about how El Niño works once it starts up. But why a particular one either throws down storm upon storm or simple fizzles into the ocean with barely a whimper has been a mystery. A new paper out from NOAA researchers Aaron Levine and Michael McPhaden in Geophysical Research Letters finally has an answer for us on what happened to kick this particular El Niño into such a high gear. And it turns out that it actually has its origins in an entirely separate El Niño that never even managed to fully materialize.


The 2015-16 El Niño was so long and so full of terrible surprises that it almost wiped out the memory of all the uncertainty that came right before it. If you look back to 2014, though, conditions looked like El Niño was going to show up that year. Western winds were picking up along the equator and sea surface temperatures were heating up in a way that suggested El Niño would crash the party by that summer. Despite predictions, though, sea surface temperatures in 2014 never got quite warm enough for an El Niño to be officially declared.
That almost-El Niño was almost completely forgotten by late 2015 when the biggest El Niño ever roared onto the scene to utterly decimate all previous records. NOAA scientists just recently took a look back at what was going on in the year before. And it turns out though the 2014 El Niño didn’t quite make it through, it didn’t entirely fizzle out either. It left behind what researchers describe as a “reservoir of heat” in the water, and that hot water lasted clear through late 2015. This created a kind of stacking effect that let 2015's El Niño start out even hotter than usual and build up into the strongest one ever seen.


But, if you’re hoping that this information can be used to predict when the next monster El Niño will show up—throwing down hail storms and dead marine life in its wake—then NOAA has some disappointing news for you. El Niño’s strength is down to a number of different factors and predicting what one will look like is simply still far too complicated.


“The wildcard in all of this—the reason this is very probabilistic and we can’t say anything with certainty—is that some part of the winds are essentially random,” another NOAA climate scientist Michelle L’Heureux explained in a statement. “We can predict them five to seven days out, but that’s not going to give you much advance information on the growth of ENSO.”
Wildfires continue to ravage the Canadian province of Alberta, and experts say they could double in size and take months to extinguish. Here are the latest space-based images of this unprecedented natural disaster.
Fire crews in Fort McMurray say it’ll be weeks before the city is deemed safe. Wildfires began to spread through the city early last week, destroying nearly 2,500 structures.
The mass exodus from the Fort McMurray area in Alberta has widened as wildfires continue to spread…
Mercifully, around 85 percent of the city remains intact, including the hospital, municipal building, hotels, and all its schools. Around 80,000 residents of Fort McMurray were evacuated, of which 40,000 are in Edmonton. Adding insult to injury, a stomach flu is now making the rounds among the evacuees.
DigitalGlobe, a provider of hi-res Earth-imagery, provided Gizmodo with these photographs, which were captured by its WorldView-2 and WorldView-3 satellites last week.
WorldView-2 “sees” the world in eight spectral bands, four in the visible part of the spectrum, and four in the invisible, near-infrared part of the spectrum. Near-infrared imaging helps scientists understand the health of the vegetation on the ground; in these false-color images, the bright red areas represent healthy forest land. In the “after” images, the burnt-out areas show up as black and gray. The “before” images shown here were taken last year on May 29, 2015.
DigitalGlobe also imaged the Fort McMurray area on May 5, 2016, with its WorldView-3 satellite.
This satellite has the unique ability to peer through smoke using Shortwave Infrared (SWIR) technology to see where the fire is burning and how intensely it’s burning. In these false-color images, the yellow areas are those that have been burned by the fire, the purple areas are healthy vegetation, and the bright yellow spots are where the fire is actively burning.
The wildfire continues to blaze in the northern forests of Alberta, and conditions remain extreme. A province-wide fire ban is in place. NASA has released several photos of the wildfire’s smoke, which has drifted into the U.S., and seen as far as the Atlantic coast some 3,200 miles (5,000 km) away.
As of Sunday May 8, there are more than 500 firefighters battling the blaze in the Fort McMurray region. They’re being assisted by 15 helicopters, 14 air tankers, and 88 other pieces of fire-fighting equipment.
The fire is nearly 400,000 acres (161,000 hectares) in size, and it’s expected to grow. A total of 34 wildfires are burning, with at least five of them out of control.
[Globe and Mail, NASA 1, 2, 3, 4]
Wait, you thought the Kepler Space Telescope was dead? Think again. Today, NASA’s Kepler team announced the discovery of a whopping 1,284 new planets—the largest number of exoplanets ever reported at once. Kepler’s latest haul nearly doubles the number of confirmed planets beyond our solar system, bringing the total to roughly 3,200.
From 2009 to 2013, NASA’s Kepler Telescope stared at a fixed point in the sky, scouring 120,000 stars for faint planetary shadows called transit events. Kepler’s four year observational campaign collected a tremendous amount of information, which scientists have been trawling through ever since. Before today, the Kepler database had yielded roughly 4,700 planetary candidates and 984 confirmed exoplanets. Ground based telescopes have spotted hundreds more.
Kepler’s illustrious discoveries include Kepler 452-b, the very first probably-rocky planet that orbits in the habitable zone of a sun-like star, and numerous other rocky, habitable zone worlds, including Kepler-438b and Kepler-442b.


Now, using a statistical approach that determines the likelihood of a exoplanet candidate’s transit event being a false positive, the Kepler team has moved another 1,300 dots onto the bonafide planet roster. The new discoveries, reported today in The Astrophysical Journal, do not dramatically change the distribution of worlds Kepler has been building—the majority of planets found to date are still super-Earth and sub-Neptune sized. This is likely due to the fact that larger-than-Earth sized worlds are easier to see; from statistical calculations astronomers believe that Earth-sized and smaller planets are more common.
Today’s announcement also includes nine newly-minted habitable zone worlds that are less than twice the size of Earth (and therefore, probably rocky). One of those worlds, Kepler-1638b, is very close to us in size and just slightly hotter.
As incredible as the new discoveries are, Kepler is by no means finished. The team is expecting to produce a final catalog of confirmed exoplanets in October of this year. “It would not surprise me if we still have hundreds of new planet candidates to add to that roster” said Natalie Batalha, an exoplanet researcher at NASA’s Ames Institute.


And while all of the planets in the Kepler catalog are several hundred to over a thousand light years distant, the K2 mission, which repurposed Kepler in 2014, has since yielded hundreds of exoplanet candidate worlds that are just tens of light years away. As Gizmodo reported earlier this year, these K2 planets are among the first worlds whose atmospheres we’ll scour for signs of life with the James Webb Space Telescope and future missions. In a few decades time, if we’re very lucky, we might have found ourselves a second home.
The Kepler spacecraft came roaring back into the news last week, when scientists announced that the …
“When NASA decided to launch the Kepler Space Telescope, we did not know if small rocky planets were common or rare the galaxy,” said Paul Hertz, Astrophysics Division director at NASA Headquarters. “Thanks to Kepler, we now know that exoplanets are common, and that a reasonable fraction of the stars in our galaxy has potentially habitable planets. Knowing this is the first step toward addressing the question of are we alone in the universe.”
But we had so much snow this winter! But it’s only a couple degrees! But the temperature in my hometown feels fine! We’ve heard it all from climate change deniers. This elegant visualization sets the record straight.
The data supporting climate change is undeniable; we live in a hot world that’s getting hotter. And yet, even though that change is easy to document, it’s sometimes hard to get people to really see the overall climate trend when they’re thinking mostly about the weather they are personally experiencing. That’s why this mesmerizing new graph from climate scientist Ed Hawkins of the National Centre for Atmospheric Science at the University of Reading gives such an excellent overview of what’s really going on.


In the graph, Hawkins charts out every month’s temperature change since the 1850s into an outward expanding spirograph of climate data. Hawkins was also one of the contributing authors to the IPCC’s 5th climate assessment, which was full of plenty of alarming climate graphics and predictions of its own. This new presentation of that same climate data, though, lets the noise of tiny variations fade into the background while still showcasing, very simply, the undeniable trend.
“I think there is lots to see—variations from month to month and decade to decade,” Hawkins told Gizmodo. “I wanted to try and visualize the changes we have seen in different ways to learn about how we might improve our communication. The spiral appeared to present the information in an appealing and straightforward way. The pace of change is immediately obvious, especially over the past few decades. The relationship between current global temperatures and the internationally discussed target limits are also clear without much complex interpretation needed.”
A new generation of tabletop accelerators has the potential to accelerate electrons to near the speed of light, without the need for gigantic machines like the Large Hadron Collider. But that all-important energy beam is too spread out for optimal performance. An international team of physicists has figured out a way to address this shortcoming and described their method in a new paper in Physics of Plasmas.
Plasma wakefield accelerators are tabletop machines that are capable of accelerating electrons to very high energies over a few centimeters, compared to two miles for full-sized particle accelerators today. By firing intense, short pulses of laser light into a plasma (cloud of ionized gas), scientists can create a wave rippling through the plasma that leaves a bunch of charged particles in its wake, just like a speed boat racing across a lake churns up a wake of water in its path. Add a second laser pushing even more electrons into the plasma, and they can “surf” that wake, picking up more speed by drawing off the energy from the wakefield.


There’s just one problem: not all electrons are accelerated equally, because electrons catch the plasma wave at different times. The first ones have more time for acceleration, and they end up moving faster than the latecomers. The also don’t all catch the wave at the same place; some locations get bigger energy boosts than others. This matters because most applications for this technology require tightly focused (coherent) beams—such as building a tabletop free-electron laser for materials processing and manufacturing.
A team of Chinese, American, and South Korean physicists have proposed a way to make that acceleration more uniform by inserting a “plasma compressor.” This will squeeze the electrons together to limit their spread and form a shorter pulse in the beam. And for good measure, it will switch their order, so that the latecomer electrons jump to the front, giving them a chance to catch up to the early birds in terms of acceleration.


This should result in a tenfold improvement in beam quality for plasma wakefield accelerators. The next step: building a prototype device in the lab to experimentally confirm their proposed method.


[Physics of Plasmas]
Today’s particle accelerators are massive machines, but physicists have been working on shrinking…
Last year, a biotech startup called Clear Labs performed DNA testing on a bunch of hot dogs and discovered that they often contain more than the label advertises. The same company has now used its arsenal of molecular technologies to break down America’s other favorite meat-on-a-bun product: burgers. Once again, there are some unsavory surprises.
Clear Labs’ latest report—which included genetic and nutritional analyses of 258 samples of meat and veggie burgers—discovered “significant issues” in 14 percent of products. These included substitution of ingredients, glaring deviations from nutritional labels, several instances of food-borne pathogen DNA and rat DNA as well as one case of human DNA. Some of these findings should raise real concerns; others are the unappealing but inevitable consequence of using genetic sequencing technologies on lots and lots of products.


Clear Labs, a Silicon Valley startup that bills itself as “the world’s first food analytics platform for retailers and manufacturers,” has developed a next-generation DNA sequencing pipeline that can take any food item and deconstruct it into plant, animal, bacterial, and fungal ingredients. As I’ve reported previously, the analysis is semi-quantitative, meaning the company can say if an ingredient is present in trace amounts (as was the case for rat, human, and pathogen DNA) or if it constitutes a major substitution.
Trace ingredients are a hygiene and cleanliness issue, however. The presence of human DNA in just a single frozen veggie burger does not mean there’s something terrible going on at the bean burger plant. More likely, it means a person handled a sample without gloves before it went through Clear Labs’ pipeline. The same goes for the rat DNA that was present in just three samples. Yes, it sounds disgusting, but it almost certainly points to an unclean factory rather than a deliberate deception.
A startup called Clear Labs has genetically tested a bunch of hot dogs, and the results are about…
On the other hand, Clear Labs did find several instances in which burgers were “adulterated” with a significant amount of an unlisted ingredient—lamb or bison burgers that were laced with beef or chicken, for instance. The analysis also found one black bean burger that contained no black beans whatsoever, and 14 other veggie burger products that were missing an ingredient listed on the label.


“We were super surprised by the higher rate of problems in veggie products, because you normally think of veggie products as being safer” Clear Labs co-founder Mahni Ghorashi told Gizmodo. Ghorashi added that in addition to substitution issues, veggie burgers were more likely to contain snippets of DNA from known human pathogens. Overall, Clear Labs found evidence of bugs that cause illnesses including gastroenteritis and pneumonia in 12 samples.
But other experts caution that these pathogens may not be a real issue.
“The biggest concern, and they mention this in the report, is that the method cannot differentiate between live and dead cells,” said Michael Doyle, a professor of food microbiology at the University of Georgia. “The cooking process will kill most pathogens. I think their results may be a bit misleading in that sense.”
Clear Labs’ new report is salient given recent revelations of rampant substitutions in the seafood industry, and scandals including Ikea’s legendary horse-flavored meatballs. If genetic testing—which is rapidly becoming cheaper and more reliable—can help hold the meat industry accountable, then regulators should consider making it an industry standard.
Other aspects of Clear Labs’ analysis will require further refinement before they’re useful. Finding pneumonia DNA in a burger sure sounds awful. But whether this discovery is fodder for anything more than a media scare-fest remains to be seen.
Using an unprecedented technique of matching stars to the locations of temples on Earth, a 15-year-old Canadian student says he’s discovered a forgotten Maya city in Mexico. Images from space suggest he may actually be onto something—but experts say it’s something much simpler.
William Gadoury, a teen from Saint-Jean-de-Matha in Lanaudière, developed an interest in archaeology after the publication of the Maya calendar announcing the end of the world in 2012. After spending hours poring over diagrams of constellations and maps of known Maya cities, he noticed that the two appeared to be linked; the brightest stars of the constellations overlaid perfectly with the locations of the largest Maya cities. As reported in The Telegraph, no other scientist had ever discovered such a correlation.


Here’s how he discovered the lost city: After studying 22 different constellations, Gadoury noticed that they neatly corresponded to the locations of 117 Mayan cities located in Mexico, Guatemala, Honduras, and El Salvador. When looking at a 23rd constellation, he was able to match two stars to known cities—but a third star remained unmatched. Using transparent overlays, Gadoury pinpointed a location deep in the thick jungles of the Yucatan Peninsula in Mexico.
“I did not understand why the Maya built their cities away from rivers, on marginal lands, and in the mountains,” explained Gadoury in Le Journal de Montreal. “They must have had another reason, and as they worshiped the stars, the idea came to me to verify my hypothesis. I was really surprised and excited when I realized that the most brilliant stars of the constellations matched the largest Maya cities.”
Taking this idea further, Gadoury contacted the Canadian Space Agency, who provided him with space-based images from NASA and JAXA. These satellite images revealed a batch of undeniably geometric structures hidden under the jungle canopy. Gadoury, along with Dr. Armand LaRocque, a remote sensing specialist from the University of New Brunswick in Fredericton, believe it’s an ancient Maya pyramid surrounded by 30 smaller structures. The teen has named the city—which has yet to be explored and verified—K’aak Chi, which means “Mouth of Fire.” If confirmed, it would be among the largest Maya cities ever discovered.
LaRocque said the use of satellite images, as well as the contribution of digital image processing, helped to confirm the possible existence of this forgotten city. “Geometric shapes, such as squares or rectangles, appeared in these images, forms that can hardly be attributed to natural phenomenon,” LaRocque said.


Daniel de Lisle of the Canadian Space Agency said he was fascinated by the depth of Gadoury’s research, and that linking the position of stars and the location of a lost city “is quite exceptional.” He told The Independent that “There are linear features that would suggest there is something underneath that big canopy,” adding that “There are enough items to suggest it could be a man-made structure.”
What needs to happen now is a ground expedition, but that won’t come cheap, nor will it be easy. The location of the site is in one of the most remote and inaccessible areas of Mexico. And as LaRocque put it, “Expedition costs are horribly expensive.” Gadoury has contacted a team of Mexican archaeologists, and he’s hoping to take part in any subsequent mission to the site.
“It would be the culmination of my three years of work and the dream of my life,” said the cool teen.
So, uh, can someone get a Kickstarter going for this kid immediately please?
Update 2:56 pm: Some skeptics are voicing their opinions about this story. Here’s what David Stuart, an anthropologist from The Mesoamerica Center-University of Texas at Austin, had to say via his Facebook page:
Update: 3:25 pm: Thomas Garrison, an anthropologist at USC Dornsife and an expert in remote sensing, says these objects are relic corn fields. Here’s what he told Gizmodo:
I applaud the young kid’s effort and it’s exciting to see such interest in the ancient Maya and remote sensing technology in such a young person. However, ground-truthing is the key to remote sensing research. You have to be able to confirm what you are identifying in a satellite image or other type of scene. In this case, the rectilinear nature of the feature and the secondary vegetation growing back within it are clear signs of a relic milpa. I’d guess its been fallow for 10-15 years. This is obvious to anyone that has spent any time at all in the Maya lowlands. I hope that this young scholar will consider his pursuits at the university level so that his next discovery (and there are plenty to be made) will be a meaningful one.
Garrison provided Gizmodo with this image of a similar feature in an area where he works in Guatemala. This field has been abandoned more recently.
Update: 4:30 pm: We also reached out to Ivan Šprajc from the Institute of Anthropological and Spatial Studies in Slovenia. He says the Maya were very good astronomers, and that they were interested in certain stars and celestial objects, but he’s skeptical that these charts can be used to reveal the location of Maya sites. As he told Gizmodo:
Very few Maya constellations have been identified, and even in these cases we do not know how many and which stars exactly composed each constellation. It is thus impossible to check whether there is any correspondence between the stars and the location of Maya cities. In general, since we know of several environmental facts that influenced the location of Maya settlements, the idea correlating them with stars is utterly unlikely.
[Telegraph, Independent, Le Journal de Montreal]

If you want to time something accurately, you could do worse than this new optical clock. Because it can measure intervals of time with a precision of 270 quintillionths of a second (that’s 0.00000000000000027 seconds).
Optical clocks work by measuring the frequency changes in light that result from shifting energy states of electrons in molecules. Usually, they’re rather big clunky devices, about the size of a desktop computer, because they make use of large, reliable lasers. But a team from UCLA has been able to shrink down the hardware using silicon chip technology to create solid-state microresonators that perform a similar job. That’s allowed them to create a device that measures just 0.06 cubic inches. The research is published in Science Advances.


It’s not as precise as larger optical clocks, but it’s still pretty impressive. And perhaps most important is that it’s small. The team suggests that it could be used to measure the timescales of laser pulses with high degrees of accuracy, enabling it to provide more precise laser distance ranging. Given it’s so small, that means it could be used aboard mobile LIDAR systems such as those found in autonomous cars or surveying drones.
It’s worth noting that this clock isn’t the kind that can run for long periods and never lose time—rather, it’s very good at measuring intervals of time. If you never want to lose a second, you’ll currently need an atomic clock, which can run for 100 million years and only gain or lose about a second.


[Science Avances via PhysOrg]
Last week, SpaceX made its fastest ever successful rocket landing on its drone ship, despite having claimed that it was“unlikely” to be a success. Now you can watch it from three different angles.
SpaceX had already landed a Falcon 9 rocket on a drone ship before, but this time round it was exposed to far higher velocities and greater re-entry heating on its way back down. SpaceX still absolutely nailed it, as you can see.

[SpaceX via Engadget]
Mixing corn starch and water makes for a crowd-pleasing staple of science demos. The resulting substance looks like a liquid, but hardens instantly when you punch it—in fact, it’s possible to run across a pool of the stuff. Now physicists think they’ve figured out just what’s going on when this unusual material switches from a liquid to a solid, hopefully ending a long-running debate. They described their findings in a new paper in Physical Review Letters.
The mixture goes by many names, but the most common one is “oobleck,” a nod to the classic Dr. Seuss story, Bartholomew and the Oobleck. It’s really simple to make your own. Just combine two cups of corn starch—add three drops of green food coloring if you want that snot-like Seuss effect—and gradually mix in enough water to create a mixture that resembles pancake batter (usually about equal parts starch and water).
Non-Newtonian fluids are liquids that are also sort of solid but also sort of neither but also sort …
It’s a fine example of a so-called “non-Newtonian fluid.” Isaac Newton described the properties of an “ideal liquid” back in the 17th century, one of which is viscosity, loosely defined as how much friction/resistance there is to flow in a given substance. Oobleck is the opposite of an ideal liquid. As I wrote back in 2007:
The friction arises because a flowing liquid is essentially a series of layers sliding past one another. The faster one layer slides over another, the more resistance there is, and the slower one layer slides over another, the less resistance there is. Anyone who’s ever stuck their arm out of the window of a moving car can attest that there is more air resistance the faster the car is moving (air is technically a fluid).
That’s the basic principle. But the world is not an ideal place.... In Newton’s ideal fluid, the viscosity is largely dependent on temperature and pressure: water will continue to flow — i.e., act like water — regardless of other forces acting upon it, such as being stirred or mixed. In a non-Newtonian fluid [like oobleck], the viscosity changes in response to an applied strain or shearing force, thereby straddling the boundary between liquid and solid behavior.
Let the eleventh Doctor Who, Matt Smith, demonstrate:

That’s the big-picture explanation, but physicists have been arguing for decades about precisely what’s going on at the small scale, because experiments and computer modeling studies haven’t agreed. From a physics standpoint, we’re talking about microscopic particles suspended in liquid (colloids). On one side are physicists who think that friction between those suspended micro particles lock them in place to resist flowing like a liquid.


On the other are those who favor a hydrodynamical explanation: the micro particles are pushed close together with the impact, and the liquid between them is forced out, producing resistance that slows them down sufficiently that they briefly lock into so-called “hydroclusters.”
So who is right? Physicists at Georgetown University and the National Institute of Standards and Technology think they have the answer: both sides are right. The two competing theories are actually complementary. So it’s kind of a win-win for physics.
“This transition demonstrates that shear thickening is driven primarily by frictional contacts, with hydrodynamic forces playing a supporting role at lower concentrations of particles, when mixtures are less dense,” lead author John Royer of NIST said in a statement.

Okay, but why should we care? These kinds of effects “dictate how much stuff you can move and at what speed,” co-author Daniel Blair, a Georgetown University physics professor, said in a statement. “In the chemical processing industry, you’re looking for the most efficient way to move something through a pipe, without breaking a pump. To do that, you want to know as much as you can about shear thickening so you can control it.”


Shear-thickening fluids are already being used on prototype bullet-proof vests and sporting equipment, because their sensitivity to impact means they can better absorb the energy of a high-velocity projectile or hard impact, while still being flexible enough to wear comfortably. The US and Canadian skiers in the 2006 Winter Olympics wore a similar form of “smart armor” manufactured by a British company called d3o Labs.
[NIST, Physical Review Letters]
Life has been transforming Earth’s atmosphere since the first single-celled organisms evolved. But few instances of atmospheric terraforming compare with what went down 2.7 billion years ago, when air pressure seems to have plummeted to less than half of its current value. What could have caused the worldwide depressurization? According to a new hypothesis, the culprit was nitrogen-hungry microbes.
Scientists have long believed that our planet had a much thicker atmosphere in the distant past. This assumption comes from the observation that Earth had liquid oceans as early as four billion years ago, when the sun was only 70 percent as luminous as it is today. To compensate for the weaker sun, a thick, greenhouse-gas rich atmosphere could have kept the world from freezing over.


But the ancient Earth was also a volatile place, subject to abrupt changes in atmospheric chemistry and climate. New research led by Sanjoy Som of the University of Washington indicates that at one point in history, our planet had much less air, and that a major biological event may be responsible.
Writing in Nature Geoscience, Som and his colleagues describe the results of an analysis of trapped air bubbles found inside a 2.7 billion year old lava flow at the Beasley River in western Australia. Using high-precision X-ray scans, the team was able to measure a decrease in the size of air bubbles between the top and bottom of the lava layer. This size change corresponds to the pressure exerted by Earth’s ancient atmosphere as the lava was cooling.


Their analysis revealed that atmospheric pressure 2.7 billion years ago was at most only half of its present value—a result that flies in the face of our understanding of the Earth during the Archaean period.


Now, scientists have to figure out what it means. If the result can be corroborated with other geologic evidence, it suggests something dramatic took place about three billion years ago to reduce the size of the atmosphere. And Som has a hunch as to what that something might be.
Other geochemical evidence suggests that around 3.2 billion years ago, bacteria developed mechanisms for transforming atmospheric nitrogen (N2 gas) into ammonia (NH3), a biologically-useful form. This process, called nitrogen fixation, was utterly essential to the evolution of complex life. Without it, plants and animals would have no way of accessing the nitrogen our cells need to build proteins and DNA.
Essentially, Som and others suspect that the ability to strip-mine the atmosphere for nitrogen caused air pressure to take a temporary nosedive. A few hundred million years later, the system rebounded when other metabolic processes started releasing nitrogen back into the atmosphere.
The researchers emphasize that this is just a hypothesis—one that’s supported by a single striking result. But if correct, the implications go far beyond satisfying our curiosities about deep time. They could help us find life on other worlds.


By building an accurate picture of the gases present in our atmosphere when life was getting started, we’ll have a better chance spotting the signatures of life in the air of distant exoplanets. If Earth’s air pressure three billion years ago was way lower than we thought, then perhaps the surface was kept warm by a higher concentration of potent greenhouse gases like methane.
So, for the sake of the aliens, let’s hope geologists figure out what the hell Earth’s nitrogen-fixing bacteria were up to back in the day. And for our own sake, let’s be grateful they eventually settled down.


[Nature Geoscience h/t New Scientist]
Remember all that fuss last year about the supposed discovery of an alien megastructure? A new study is taking issue with some of the data used in support of the theory, claiming that the observations were tarnished by the inconsistent use of telescopes down here on Earth.
As you may remember, star KIC 8462852, also known as “Tabby’s Star,” attracted considerable because of its unprecedented flickering behavior. Normally, dips in brightness are taken as a sign that a planet is passing in front, but Tabby’s star is quite different. It features fluctuations consisting of dozens of uneven, unnatural looking dips that were measured over the course of a four-year period. These strange observations prompted Jason Wright of Penn State University to suggest that the star’s weird distortions might be the result of a massive alien megastructure, such as a Dyson Sphere.


Things got even weirder a few months later, when researchers from Louisiana State University claimed that the brightness of Tabby’s Star had dimmed by a whopping 20 percent over the last century—something that’s “completely unprecedented for any F-type main sequence star.” This new observation was difficult to explain by natural means, but it certainly gave credence to the megastructure idea.
It’s probably not aliens. Seriously guys, it’s very, very unlikely that it’s aliens. But the weird, …
Now, as reported in a new Astrophysical Journal study, there’s something seriously wrong with the LSU study. A team of astronomers from Vanderbilt University and Lehigh University, along with the help of an amateur astronomer and a NASA postdoctoral Fellow, decided to scrutinize the data used in the LSU study. They’ve concluded that there’s no credible evidence to support the idea that this star dimmed to such a dramatic extent over the past century.


The reason for their investigation had to do with the source of the data: Digital Access to a Sky @ Harvard, or DASCH. Using this innovative telescopic technique, Harvard astronomers were able to collect more than 500,000 photographic glass plates between 1885 and 1993. Trouble is, several different telescopes and cameras were used to collect this data over the course of the 108-year-long project.
“Whenever you are doing archival research that combines information from a number of different sources, there are bound to be data precision limits that you must take into account,” explained study co-author Keivan Stassun in a statement. “In this case, we looked at variations in the brightness of a number of comparable stars in the DASCH database and found that many of them experienced a similar drop in intensity in the 1960’s. That indicates the drops were caused by changes in the instrumentation not by changes in the stars’ brightness.”
D’oh! Well, this is how science works. On the bright side we can now throw the LSU study out of the window.
But the mystery of Tabby’s Star is far from over. Observations taken by the Kepler Space Telescope from 2009 to 2013 still needs to be examined further. There’s something weird going on around Tabby’s Star, and we still need an explanation. To date, some of the most credible theories include a swarm of cometary fragments, or an effect created by a distorted star. But until this mystery is finally solved, it’s a safe bet that people will continue to point their wishful thinking fingers at aliens.
[Astrophysical Journal]
The consequences of not getting enough sleep are evident to all of us—and yet we’re constantly staying up later than what our internal biological clocks are telling us. A new study shows the elusive nature of what’s to blame.
A new user data-driven study published in Scientific Advances is providing a fascinating glimpse into global sleep patterns, showing that the Dutch get about an hour more sleep each night than people in Singapore or Japan. The research also shows that women tend to get more sleep than men, and that the collective variability of our sleep patterns gets smaller as we age. What’s more, the study shows that social factors are preventing us from honoring our circadian rhythms, causing us to go to bed later than our internal biological clocks would like.


Back in 2014, a research team led by Daniel Forger of the University of Michigan released a free smartphone app called Entrain. His team has used the data collected by this app for the current study, which wasn’t strictly related to jet lag.
Entrain is an app designed by mathematicians at the University of Michigan and Yale University to…
This program is designed to help travelers get over jet lag faster, and it does so by recommending lighting schedules. When installing the app, users decide whether or not they’d like to anonymously share their data with scientists. About eight percent agreed. This allowed Forger’s team to collect about a year’s worth of sleep-related data, including a wide range of sunrises and sunsets and their relation to time spent awake or asleep.


Before we go any further it’s important to point out that the researchers were not dealing with a random sampling of people. Based on this method of data collection, the scientists were forced to deal with a rather narrow group of individuals. So, for example, everyone involved in the study uses this app to help them with their jet lag (so these folks travel a lot, and they’re clearly dealing with sleep issues), they’re technologically savvy, and they’re cool about sharing their data (which excludes 92 percent of all Entrain users).
That said, this research shows that mobile technology can be used to gather massive data sets and at very low cost. What’s more, the data jibed very well with theoretical predictions made by math-driven models. Using these models, the researchers could predict how sunrise and sunset isolation affects sleep, which they compared to the user-submitted data. According to the theoretical predictions, later sunrises and sunsets should shift wake and bedtime later, while later sunsets should increase sleep duration. And indeed, these same trends appeared in the user data.
But—and this is a big but—the effects of sunlight are weaker around bedtime than the model’s predictions. This is important because bedtime is the single biggest driving factor behind why some countries seem to sleep more than others.
“We find that social pressures weaken and/or conceal biological drives in the evening, leading individuals to delay their bedtime and shorten their sleep,” wrote the researchers.
But it’s not immediately clear what these “social pressures” are. Perhaps it has something to do with long hours spent at work, which prevents people from wanting to hit the sack “too early,” even though it’s quite late. It’s also possible that various forms of entertainment are only available later in the evening (though in this era of on-demand television, that’s hard to believe). Further work in this area is desperately needed.
The researchers also found that women tend to sleep more than men, about 30 minutes more on average. Women go to bed a bit earlier and wake up later, and this trend is most pronounced between the ages of 30 and 60. Also, middle-aged men get the least amount of sleep, often getting less than the recommended seven to eight hours. Interestingly, people who are regularly exposed to sunlight tend to go to sleep earlier, and they sleep longer than people who only get indoor light.
Finally, age was shown to be a major factor in sleep trends. As people get older, they tend to schedule sleep earlier, which means habits coverage as we age. Sleep schedules were quite similar among those older than 55, compared to those younger than 30. The researchers believe this has something to do with a smaller window of circadian times where older folks can fall and stay asleep. This means we need to be more careful about light and how it affects our internal biological clocks as we get older.
In terms of the global figures, people in Japan and Singapore get an average of seven hours and 24 minutes of sleep, while people in the Netherlands typically get about eight hours and 12 minutes. The time we choose to go to bed is the determining factor, as very few people extend their time of waking to compensate.


Ensuring that we get sufficient sleep is critical to our health. The Centers for Disease Control and Prevention says that one in three adults in the U.S. aren’t getting the recommended minimum of seven hours. Sleep deprivation is a known risk factor for such things as obesity, diabetes, high blood pressure, heart disease, stroke, and stress.
[Science Advances]

Students taking an online course at Georgia Tech’s School of Interactive Computing were duped into thinking one of their teaching assistants, named Jill Watson, was an actual human. And how can you blame them—the virtual TA managed to answer many of their questions with 97 percent certainty.
Now, being “certain” is not the same as being correct. But computer science professor Ashok Goel felt it was a sufficient level of confidence to allow the virtual TA, named Jill Watson, to answer student inquiries on her own. For nearly the entire month of April, Jill was responding directly to the class through an online student forum, but only when she was 97 percent sure her answers were correct.


The students weren’t told that they were interacting with a virtual TA until April 26. According to a Georgia Tech release, the student response was “uniformly positive.” One student said “her mind was blown” when the truth came out, while another jokingly asked if Jill could “come out and play.”
The course, titled Knowledge Based Artificial Intelligence (KBAI), is a core requirement of Georgia Tech’s online masters of science in computer science program. Around 300 students take the course each year, and they post roughly 10,000 messages in the online forums which is more than the course’s eight TAs can handle. To offset this workload, Goel and his graduate students built the virtual teaching assistant, which was built on IBM’s Watson platform (yes, the same Watson that defeated the world’s greatest Jeopardy players back in 2011).
It all started a couple of years ago when IBM's Watson, the computer voted most likely to…
To develop the system, Goel and his team collected roughly 40,000 questions that had been asked in the class forums since the course was launched back in 2014. They then fed Jill all these questions and answers.


“One of the secrets of online classes is that the number of questions increases if you have more students, but the number of different questions doesn’t really go up,” noted Goel. “Students tend to ask the same questions over and over again.”
This scenario is perfect for the Watson platform, a powerful natural language processor that specializes in answering questions with distinct, clear solutions.
When the project first got started back in January, Jill wasn’t very good at answering the questions and would often give strange and irrelevant answers. These responses weren’t shared with the KBAI students.
“Initially her answers weren’t good enough because she would get stuck on keywords,” said Lalith Polepeddi, one of the grad students working on the project. “For example, a student asked about organizing a meet-up to go over video lessons with others, and Jill gave an answer referencing a textbook that could supplement the video lessons—same keywords—but different context. So we learned from mistakes like this one, and gradually made Jill smarter.”
Eventually, Jill got so good at these tasks that the researchers were ready to post her answers directly to the KBAI student forum, which they started to do in late March.


Goel would like to replicate the project again next semester, but with a different name. The goal is to have the virtual TA answer 40 percent of all questions by the end of the year (just to re-iterate, no responses below the 97 percent certainty threshold were posted to the student forums).


Naturally, it’s upsetting to hear that bots could replace yet another job. But this might actually turn out to be a good thing, as many students drop out of classes because they don’t receive enough teaching support. Jill was developed with this exact need in mind. Of course, Jill, or her immediate digital descendants, won’t be able to answer more complicated or nuanced questions, particularly those posed in other courses (such as philosophy or the social sciences). So it’ll be a long time (if ever) before we see teaching assistants—or professors for that matter—completely replaced by artificial intelligence. But as this research clearly shows, the writing is most certainly on the wall.
[Georgia Tech]

For the first time, geologists have compiled a global map of the wave-like motions called “convective currents” inside Earth’s mantle. They found that those convective currents are moving roughly ten times faster than previously thought. The discovery can help explain everything from how Earth’s surface changes over time to the formation of fossil fuel deposits to long-term climate change.
“In geological terms, the Earth’s surface bobs up and down like a yo-yo,” geologist Mark Hoggard of Cambridge University said in a statement. Hoggard is lead author on a paper published today in Nature Geoscience.


Our planet’s deep interior is an enduring scientific mystery. Having never drilled more than a few miles beneath the surface of the Earth, geologists rely on indirect measurements and models to get a sense of what’s happening further down. The mantle is a nearly 3000 kilometer (2000 mile) layer of gooey, compressed rock, and convective activity within it has a big impact on Earth’s surface.
“In addition to the normal plate tectonics, the interior of the plates which should be quite boring are being forced up and down by mantle convection,” Hoggard told Gizmodo. “People have known that this occurs for a long time, but for the past 30 years we haven’t had the data to measure it.”


That’s changing, thanks to new high-resolution seismic reflection profiles created by the oil industry. Seismic reflection profiling is a technique geologists use to peer deep into Earth’s crust, by measuring the reflection and refraction of seismic waves as they travel downwards. The method can reveal fine-scale changes in the thickness of the crust, which in turn relates to mantle convection.
By analyzing over 2,000 seismic reflection measurements taken across the world’s oceans, Hoggard and his colleagues constructed the first global database of mantle convection. They were surprised to discover frequent changes in the thickness of seafloor crust, indicating that mantle convection is occurring far more frequently than we thought—think a vigorously bubbling pot of water instead of a slow-churning soup.
This insight into Earth’s deep interior can help explain all sorts of things closer to home. The formation of oil reserves, for instance, relies on the burial and compression of sediments that are chock full of decaying organic matter. “These motions help control how quickly rocks containing organics are buried and cooked into oil,” Hoggard said.
Mantle convection can also have a surprising impact on Earth’s climate, by affecting the large-scale ocean circulation patterns that move heat around the world. The Gulf Stream, for instance, carries warm water from the Gulf of Mexico to the coast of western Europe, before chilling out and sinking around Iceland.
“There are these narrow channels around Iceland that allow water to sink,” Hoggard explained. “If you elevate or depress them, you could really affect ocean circulation.” (Free plot idea for anyone looking to write a 2-in-1 sequel to the The Day After Tomorrow and The Core!)


Finally, mantle convection is responsible for forming geothermal systems, like Yellowstone, and island archipelagos, like Hawaii, that crop up in the middle of tectonic plates. Hoggard’s findings will shed light on how and why parts of the crust located far from plate boundaries are rising, falling, and cooking.


“It’s really a shift in view point,” he said. “A lot of geologists will look at places far away from plate boundaries and think they should be very stable. What we’ve shown is that regions that are often ignored are probably very active.”
It’s been a decade since the last rare but beautiful sighting of Mercury crossing the sun appeared. Today, the event is happening again, and you can watch it happen here between 10:30-11:30 am (EST).
Mercury’s transit is visible when the little planet crosses between us and our view of the sun. This perspective lets us watch the planet’s progress in realtime, like in the timelapse photo from 2006 above. It’s a relatively rare sighting (this happens only approximately 13 times a century) that requires that Mercury, Earth, and the sun all line up together.


The happening is more than just a good show. It’s also pretty useful to planetary scientists—though, curiously, the data they’re looking for is often not about Mercury at all. Instead, the slight drop in brightness from the sun blocked out by a planet, like Mercury, moving in front of a star, like our sun, lets researchers get a better view of dim exoplanets. At 1/285 the size of the sun, Mercury’s shadow during a transit may not seem like it would make a visible difference to the light of the sun, but it’s enough. Kepler scientists attribute at least a thousand planetary discoveries to observing similar drops in the brightness of stars during exoplanet transits.
With a few exceptions (which you can see in the map—sorry, Australia), the transit is visible pretty much everywhere on earth.
As always, staring at the sun is never a good idea. But there are plenty of other good ways to check out this event that don’t require special solar filter glasses. The European Space Agency and Slooh Observatory are both streaming the event in its entirety. You can watch Slooh’s feed from the Canary Islands right here with us. NASA will also be broadcasting the event on its main television channel from 10:30-11:30 am EST.


Mercury first edged across the border of the sun at 7:12 am EST, and it will take just under eight hours to make the full trek. The best time to watch the transit is between 10:30 - 11:30 am EST. That’s when Mercury will be hovering around the middle of the sun, where it will be most visible. The whole thing wraps up by 2:40 pm EST. But those final moments, just like the beginning ones, aren’t likely to be good viewing.

Of course, if you’re very, very impatient, you can also watch this NASA visualization of what the whole 7.5-hour event will look like condensed down into a tight 23 seconds. But the next two transits aren’t scheduled to come around again until 2019 and 2032 respectively, so you should check out the live version today while you can.

Update 10:45 am: NASA is also streaming a continuously updating gif of the transit. It’s not quite live, but it’s pretty close. Here’s Mercury’s progress so far:
Update 1:45 pm: Just one hour left to catch this thing, and the gifs are only getting better. Here’s a particular gorgeous one from NASA’s solar observatory:

It might not seem like music has much to do with cutting-edge physics at first glance. In his new book, The Jazz of Physics: The Secret Link Between Music and the Structure of the Universe, Brown University physics professor Stephon Alexander argues that using music as an analogy can shed light on some of the deepest mysteries in cosmology.
Alexander is not your typical physicist. Born in Trinidad and raised in the Bronx, he developed twin passions for jazz and physics at an early age. As a graduate student, he played the saxophone in jazz clubs and mastered Einstein’s equations. It’s a unique perspective that informs his approach to both; for instance, he views John Coltrane’s seminal Giant Steps album (1960), with its trademark “sheets of sound,” as the “sonic equivalent to Einstein’s bending of the space-time fabric.” Gizmodo caught up with Alexander to learn more about this hidden link.


Gizmodo: In some sense, this is the perfect timing for a book about the jazz of physics. There’s a lot of interest in sonification—turning raw scientific data into sound—both for creating unusual music, and as a unique means of spotting elusive patterns in the data. The LIGO collaboration just detected gravitational waves and turned that data into an audible “chirp.” We’re now listening to, as well as looking at, our world.
Stephon Alexander: Exactly. I believe that by reconnecting the disciplines of physics and music though analogy, we can begin to understand physics through sound. The universe has sound waves: harmony and resonance are universal phenomena that can be used to explain the dynamics of the early universe. When you hear it, it doesn’t sound musical. But [with sonification] you are informing that raw sound data with the question of the science at hand, and you’re using that to guide you to something new.
Then there’s the reverse of that. From a musical perspective, I can take my understanding of the physics of the cosmic microwave background radiation, for instance, or the raw sound map that we get from the WMAP data [from NASA’s Wilkinson Microwave Anisotropy Probe], and tweak that to make it musical. I’m working on a jazz album right now using some of the concepts in the book.


You write about how models of neural circuitry in the brain ended up informing your research on superconductivity and the large-scale structure of the universe when you were a graduate student in Leon Cooper’s group at Brown University. That’s a strong argument for understanding the math: it can reveal hidden corrections.
Alexander: It’s at the heart of my book. You see the wave equation in string theory, you see it in the cosmic microwave background radiation, and you see it in a guitar string. That equation applies to all these very different things that seem to have nothing to do with each other. The math is the connective tissue. There’s an intuitive aspect to physics; sometimes you have to make these crazy leaps. One of the thing I do [as a physicist] is try to make connections between things that people never thought to connect. If there’s something to it, the math will tell the truth. Some hidden equation will connect those things.
String theory in particular seems to resonate with people because of the musical analogy: our universe is “composed” of these tiny strings that make up matter at the most fundamental scale, and the different ways that they vibrate determine the properties of elementary particles and fundamental forces. As you say in the book, it’s like a scientific “music of the spheres.” But string theory has also run into some serious issues in recent years.
Alexander: It’s run into a multiverse of issues. I would say that string theory has gotten postmodern. Old string theory is to bebop as new string theory is to freeform. If it’s going to be a true theory, it must accommodate the fine-tuning problem.


For the benefit of our readers: there are about 30 numbers (called fundamental constants) that define the masses of elementary particles and the strength of the four fundamental forces. They have well-defined values, but change just a few of those numbers—even a little—and the universe would be a very different, far less complex and interesting place. And physicists don’t really know why those numbers have the values that they do. That’s the fine-tuning problem.
Alexander: Right. In jazz music, the whole point of improvisation is that you push the tradition. That is the tradition. Miles Davis, Ornette Coleman, and Coltrane were always pushing the boundaries. So let’s accept that string theory is a musical theory. How can we put improvisation into it?
I came up with this idea that the universe is like an improvisational system. There’s a cyclic universe [i.e., the universe regularly undergoes repeating “cycles” of big bangs and big crunches]. In that scenario, the coupling constants of nature are improvised, the same way that a jazz soloist improvises and gets a chance every cycle to get a different take on the improvisation.


This forces string theory to break one of its own rules: it doesn’t allow these things called “ghost fields.” [Editor’s note: in theoretical physics, the term “ghost” applies not to any supernatural phenomenon, but to an object that can be useful for calculations yet has no real physical meaning.] But if these coupling constants have to improvise, you need a ghost field. So to make string theory accommodate improvisation in the universe, the theory needs to be pushed beyond its own boundaries.
It’s risky to push boundaries, though, particularly when it comes to the more speculative aspects of 21st century cosmology. Do you ever worry that you might be veering off on the wrong track? What if you make a mistake?


Alexander: I only get worried in my research if I’m not making mistakes. That’s usually a sign that I’m not onto something interesting. I’m not pushing as hard as I should be. Again, there’s a metaphor to jazz: to improvise means to embrace making a mistake. So you play a wrong note. So what?
I had a music teacher once who was supposed to be giving me advanced lessons. Instead, he gave me a pattern of four notes to play in every key. I’m like, “What the hell are you making me do this for, man?” And he said, “Just get this under your finger. Like a dancer or acrobat, you will fall, you will play the wrong thing. That’s the whole point. This teaches you how to fall.” A good improviser is constantly falling, and then transforming that into a different pathway that’s interesting.
There has been much discussion of the need for greater diversity in physics, which is traditionally dominated by white men. Your success is evidence that the field is starting to change, but what else can physicists do to broaden their ranks?


Alexander: There’s certainly pressure out there to fit into a certain mold. We need to realize that the mold is kind of illusory. We could learn from other successful intellectual traditions. Jazz music is an American art form, and a big part of the driving force behind it was its inclusivity. What happens if someone says something stupid in front of a group of very smart physicists? What you don’t want to do is crush them. You want to inspire them to go rethink things and come back stronger.
There are souls out there who have a natural, intuitive talent for physics, but are not told that. I was one of those souls. The jazz tradition, and being mentored by musicians, is what kept me afloat in my pursuit to become a physicist. We tend to put precedence on one particular mode of thinking in physics, and we think that’s what a physicist is supposed to be. I’m trying to give more exposure to certain physicists who had different modes of thinking—people like Leon Cooper. Because some of my brightest students did not talk like the characters from The Big Bang Theory.


In my book, I talk about improvisation as a means by which physicists can engage in the unknown. Whether physicists know it or not, they’re improvising with their equations and concepts. There’s an inclusive space that they create for each other—and maybe don’t create for other people. Inclusivity is more explicit in the jazz tradition. It’s about allowing somebody to make a mistake on stage, and you hold the space for them, creating a structure so that wrong note sounds right. The field of physics can grow even further if we become more like Miles Davis, Charlie Parker, and Thelonius Monk—creating a space so that everyone can jump in and be part of the conversation.

Materials scientists typically rely on their eyes to analyze data, but soon they could employ their …

“Is science bullshit?” asked John Oliver on Last Week Tonight. “No, but there is a lot of bullshit currently masquerading as science.” And so began his hugely entertaining twenty-minute take-down of crappy scientific studies and the way they’re reported.
As ever, Oliver manages to inject huge quantities of wit into a totally serious subject. Pointing to conflicting study results, for instance, he explains that “coffee today is like God in the Old Testament: It will either save you or kill you depending on how much you believe in its magic powers.”


His whistle-stop tour of flaky science points out how not all research is created equal, how bias creeps into even the best work, and the ways in which the media—and even Universities—mis-represent scientific news. Also, you’ve probably never heard a more amusing description of p-hacking.
It’s well worth watching—though those of you outside the US may have to tune in via VPN.


[Last Week Tonight]

Yesterday, we listed the seven basic methods scientists use to get rid of gravity. Today, we’d like to go in the opposite direction, and look at a tool used to introduce a high amount of gravity to a test subject: a centrifuge.
Artificial gravity can be simulated by the centripetal forces due to rotation, and centrifuges can help us train astronauts, make cotton candy, and a lot of things in between.
Sometimes you just need to cut loose—from the Earth’s gravity. Want to feel what it’s like to be…
Centrifuges can be sorted out by their function: centrifuges are used in commercial applications, in laboratories, for aeronautics and astronautics testing, , geotechnical research and more.


But beware! This is a dizzying collection of 45 centrifuges, from the smallest to the largest:
Sometimes you just need to cut loose—from the Earth’s gravity. Want to feel what it’s like to be free from gravity, but can’t get yourself to the ISS? You’ve got some options.
There are tons of observations you can make of processes in zero or microgravity, especially in fields such as astrophysics, astrobiology, physics, chemistry, and others. It’s not always practical to sent people or equipment to space, but fortunately, there’s options here on Earth.


Micro-g circumstances can be created basically in seven ways:
NASA scientists can recreate weightlessness thanks to the 470 foot-deep underground vacuum chamber and the drop vehicle, which weighs about 2000 lbs. and makes a vertical nosedive for 5.18 seconds putting the experiments in a state of free fall.
Fallturm Bremen is a drop tower at the University of Bremen’s Center of Applied Space Technology and Microgravity (ZARM). Its 404-foot-high shaft is long enough to put experiments into free fall for 4.74 seconds, or for over 9 seconds with the use of a catapult. The impressive tower, made of a reinforced concrete shank, is 479 feet high.
The NASA Glenn 2.2 Second Drop Tower in Brookpark, Ohio began life as a 100-foot high fuel distillation tower. After conversion, it has been used for nearly 50 years to study the effects of microgravity for 2.2 seconds, a test time created by allowing the experiment package to free fall from the eighth floor to the first floor, a distance of 79 feet.
This is huge: the Russians’ drop tower can be used for testing full scale space hardware weighing up to 30 tons, dropping them from the top of the 98-foot-high vacuum chamber.
The giant tower of the Key Laboratory of Microgravity of Chinese Academy of Sciences is the center of microgravity research in China. Just like its Russian counterpart it allows full scale space hardware tests, required for China manned space program.
Micro-g environment can be created inside aircraft too, when a parabolic flight path relative to the center of the Earth is followed: the aircraft is in free fall at certain points of its flight path, so are the experiments or humans inside.

Huge indoor tanks and pools, such as the Neutral Buoyancy Laboratory in Houston, or its predecessor, the Neutral Buoyancy Simulator at Marshall Space Center (MSFC), can also help to simulate the weightlessness environment that astronauts experience during space missions. Thanks to the upward buoyant force exerted by water, it is possible to test hardware designed to operate in space, also practice techniques used in space to assemble structures.
These slim, low-cost, solid fuel propelled research rockets are designed to take experiments to the edge of space (from 31 up to 932 miles high) for a relatively short time during a maximum 30-minute-long sub-orbital flight. Beside recoverable satellites this method is the best alternative if you don’t have a first class ticket to a space station.
Satellites usually aren’t designed to come back to Earth in one piece, except retrievable scientific research satellites, like China’s bullet-shaped probe below, housing several experiments involving microgravity fluid physics, microgravity combustion, space material, space radiation effect, microgravity biological effect and space bio-technology. Thanks to its massive structure, shape and the ablative coating it can survive the controlled reentry after spending the planned time on orbit.
Dropping test objects from a height is a trustworthy way to put experiments into free fall. If drop towers and tubes are not enough, an alternative method is to use stratospheric balloons from which researchers can drop a container carrying the experiments. Below is a balloon-borne platform, which was developed by JAXA, the Japanese aerospace agency, in order to obtain microgravity, using a rocket-like device dropped from 40 kilometers in the air.
Ready for some mind-bending musical physics to take you into the weekend? A Capella Science is back with a new parody video, “Entropic Time,” set to Billy Joel’s classic pop hit, “The Longest Time.” The twist: if you look closely, the video footage is running in reverse—a visual play on the subject of the song.

Tim Blais, the mastermind behind A Capella Science, said on Twitter that he based the lyrics on this lecture about the arrow of time and the origins of the universe by Caltech physicist Sean M. Carroll. Since I’m married to Carroll, I’ve heard a lot over the years about the subject.


Why does time run forward and not backward? Blame the second law of thermodynamics. The universe has a general tendency toward disorder and decay, a phenomenon known as entropy. Entropy dictates an arrow of time that runs only in one direction: forward. Heat only flows in one direction, so a cooler body can’t pass heat to a hotter one, any more than a melted ice cube can refreeze of its own accord. Time, therefore, is what physicists call an “irreversible process.”


But mathematically, things are more complicated. Every major physics theory exhibits something called “time-reversal symmetry” in its equations. In other words, the value for time (T) can be either positive or negative. The equations allow for the possibility that time can flow forward or backward, even if real-world physics precludes it because of entropy. The math says there is no uniform direction in which time must always flow—in direct opposition to our daily experience.
That’s the arrow of time, or entropic time. Why is there such an arrow? It’s because the entropy of the universe is higher today than it was yesterday. And the entropy yesterday was higher than the entropy the day before, and so on, all the way back to the birth of our universe. As for why our universe started out in such a low-entropy state in the first place—well, that’s a question that physicists like Carroll continue to grapple with.


Blais also has a behind-the-scenes video showing just how they achieved the time-reversal effects in “Entropic Time.” Enjoy!

What do you get when you combine a Broadway musical about The Wizard of Oz with two giants of…
The American artist Andrew Wyeth found inspiration for his most famous painting in a neighbor woman who suffered from a crippling, mysterious disorder that baffled her physicians. Now a child neurologist at the Mayo Clinic thinks he’s found the correct diagnosis.
The woman in Christina’s World (above) is based on Anna Christina Olson, who lived near Wyeth and his wife Betsy in the summers and often served as the artist’s model, along with her younger brother. She was 55 at the time, and paralyzed below the waist. The artist watched her crawling across a field one day and was inspired to immortalize her on canvas. She died at 74.


Neurologist Marc Patterson has done a bit of medical detective work, reviewing her medical history and studying the various Wyeth paintings for which she posed. He concluded that she suffered from early-onset Charcot-Marie-Tooth (CMT) disease, a group of inherited neurological disorders that target the peripheral nerves just outside the brain and spinal cord. He talked about his diagnosis earlier today at the 23rd annual Historical Clinicopathological Conference at the University of Maryland School of Medicine, devoted to diagnosing the ailments of historical figures.
CMT usually strikes adolescents or young adults, affecting roughly 1 in 2,500 people in the US. It’s caused by genetic mutations, according to the National Institute of Neurological Disorders and Stroke:
A nerve cell communicates information to distant targets by sending electrical signals down a long, thin part of the cell called the axon. In order to increase the speed at which these electrical signals travel, the axon is insulated by myelin.... Myelin twists around the axon like a jelly-roll cake and prevents the loss of electrical signals. Without an intact axon and myelin sheath, peripheral nerve cells are unable to activate target muscles or relay sensory information from the limbs back to the brain.
CMT is caused by mutations in genes that produce proteins involved in the structure and function of either the peripheral nerve axon or the myelin sheath. Although different proteins are abnormal in different forms of CMT disease, all of the mutations affect the normal function of the peripheral nerves. Consequently, these nerves slowly degenerate and lose the ability to communicate with their distant targets.
The severity of the symptoms and progression of the disease varies from person to person, but it affects both motor and sensory functions. The feet and lower leg muscles are usually weak, triggering frequent falls or constant tripping. The feet can become deformed, with overly high arches and hammertoes, while legs may bow into an inverted bottle shape. As the disease progresses, patients may struggle with smaller coordinated movements in the fingers, hands, wrists, and tongue.


“This painting has long been a favorite of mine, and the question of Christina’s ailment was an intriguing medical mystery,” Patterson said in a statement. “I think her case best fits the profile of this disease.”
[Historical Clinicopathological Conference]
Need a pick-me-up on this dreary Friday afternoon? After checking out some of the nightmare-inducing life forms NOAA’s deep-sea diving robot discovered at the bottom of the Mariana Trench, sleep will be the last thing on your mind.
On April 20th, NOAA scientists working on the Okeanos Explorer dispatched their prized Deep Discoverer robot to scour the floor of the Mariana Trench, the deepest spot on the surface of the Earth. Little is known about the ecology of this seven-mile crevice—in fact, it’s often said that we know more about the surface of Mars.

Now, NOAA is revealing the secrets of the Mariana Trench to the voyeurs of the internet by livestreaming the footage collected on Deep Discoverer’s three cameras. For best effect, we suggest viewing the stream along with these recent audio recordings from the Mariana Trench, which are best described as a cacophonous blend of frenzied screeches and otherworldly moaning.
Deep rumbles, unearthly moans, high pitched screeching: these are but a few elements of the alien…
If you can’t quite handle that right now, updates from each dive, as well as photos and videos, are being posted regularly on NOAA’s website.


The 2016 Deepwater Exploration of the Marianas, which will continue until July 10th, has already revealed a slew of fascinating, bizarre, and in some cases downright disturbing life forms. (That mess of mutated wires pictured up top? A rare, gorgonocephalid basket star.) We’ve collected a few of our favorite critters below. But if you spot something on the live feed, please do not hesitate to share it in the comments. The weirder the better!
Piranha solution is nasty stuff. Composed of part sulfuric acid and part hydrogen peroxide, it eats through most organic matter with ease, and this hot dog shows that it’s frighteningly good at its job. So why does this video have some Explosions In The Sky-type post-rock music playing over it?
Even knowing full well that the hot dog is an easy analog for, say, a human finger, something about the way it floats merrily along to these chill-ass jams is incredibly relaxing. Meditative even. It’s just like they always say, “let your worries be as a hot dog in acid.” It’s an incredibly common idiom, so I don’t know why you’re looking at me like that.


And all of a sudden, the video just ends before the hot dog dissolves completely. Why it cuts off, and what the hot dog did to deserve this treatment are left a total mystery. Farewell, sweet prince of mystery meat.


Researchers have demonstrated a paper-based device that can detect the Zika virus within two to three hours. It’s affordable, effective, and practical for widespread use—particularly in countries with underdeveloped healthcare infrastructures.
As the Zika virus continues to ravage parts of South and Central America, healthcare workers are having a hard time knowing who’s infected and who isn’t. Developed by researchers from Harvard University’s Wyss Institute for Biologically Inspired Engineering, this new device could help solve this problem. They describe the device in a new paper just published in Cell.

Current tests involve taking a patient’s blood sample, and it can take days or weeks for the results to come in. What’s more, these tests, which hunt for the presence of certain antibodies, can’t discern between Zika and dengue. This is a problem, especially since because Zika has now been proven to cause birth defects in newborn babies.


To develop the kit, the researchers leveraged a similar system they developed to detect the Ebola virus. Inside a cartridge, tiny strips of paper are embedded with a synthetic gene network that senses disease-causing microbes, among other things.
Genetic circuits are equipped with dozens of genes, and include a batch of proteins capable of deciphering the information contained within. The system functions a bit the way computer programs work: together, the genes and proteins carry out a task. In this case, it’s detecting traces of the Zika virus.


Once the process starts, the paper changes color when a chosen target, like a specific sequence of RNA, is present. The diagnostic tool can screen for traces of the virus in blood, urine, or saliva samples. More work is needed to ensure the safety and efficacy of the tool before it’s deployed to the field, but the researchers say they’re not far off.
“The vivid images in the news stemming from the ongoing Zika crisis are heartbreaking,” University of Toronto pharmacologist Keith Pardee, a co-author on the paper, said in a statement. “We hope a tool like this can help reduce the impact of the outbreak until a vaccine can be developed.”


[Cell]
A few months back, Luxembourg—a tiny country better known for world-class pastries—announced its intention to become a leader in asteroid mining. Now, Luxembourg has revealed the first step in its plan to fill the banking vaults with space-grade platinum: a small, water-powered spacecraft.
It’s home to just a half-million people, but Luxembourg is not thinking small when it comes to the…
In partnership with the California-based asteroid mining company Deep Space Industries (DSI), the Luxembourg Government and national banking institution have just unveiled Prospector-X, a robotic spacecraft that’ll test technologies for prospecting and mining near Earth asteroids. The test vehicle, which DSI is hoping to launch next year, will remain in low Earth orbit. But the long term plan is to send fleets of spacecraft to lucrative rocks, carve out the valuable bits, and bring them back to Earth.
Asteroid mining is an emerging industry that blends starry-eyed futurism with profit-driven capitalism. It’s true that some of the thousands of near Earth objects are chock full of rare metals including platinum, iridium, and palladium, and that anyone able to tap these outer space rocks could wind up controlling one of the most lucrative markets on Earth. But it’s also the case that if we ever want to permanently settle in outer space, we’re going to need to mine asteroids for raw materials.


“Deep Space Industries’ ultimate goal is to be building huge structures in space that could house thousands of people,” DSI CEO Daniel Faber told Gizmodo. “To do that we need to get to the point of extracting asteroids and making those resources available.”
Many of us dream of living on other planets, but are two things we'll need before it can…
First things first, we need to start prospecting asteroids, something that DSI and the asteroid mining company Planetary Resources are now in a race to do. Planetary Resources has spent the last few years designing and building a series of prospecting craft, including the Arkyd 3, which deployed into low Earth orbit from the International Space Station last year.


The Prospector-X appears to be DSI’s answer to the Arkyds—a demonstrator vehicle that’ll test a range of technologies needed to mine asteroids. These include an optical navigation system that tells the spacecraft precisely where it is in relation to a near Earth object, and an avionics core designed to survive intense blasts of cosmic radiation. The most interesting and novel piece of equipment is a small thruster that runs on nothing but water.
“If you throw water out the back of your vehicle quickly enough, you get thrust,” Faber said. “This is important because, once we’re out at asteroids, one of the things we’ll have in abundance is water. However, no thrusters can currently use water in its native form.”


All of the technologies featured on the Prospector-X are in some level of commercial development, and DSI plans to make a side business selling these systems to the burgeoning satellite market. The first resources DSI mines from asteroids will remain in space, furnishing other companies with a cheaper supply of fuel and spare parts.
It’s not too surprising that Luxembourg—a small but wealthy country with limited terrestrial resources—has decided to take a gamble on space mining. Luxembourg is already home to several vibrant satellite operators, and the national space program has researched futuristic, deep space propulsion technologies like solar sails.
Of course, Luxembourg isn’t the only country interested in opening up the outer space commodities market. Last fall, Obama signed the US Commercial Space Launch Competitiveness Act, making asteroid mining fully legal in the United States. Although no company can claim ownership over a near Earth object under international law, there is now a legal framework in place allowing American companies to keep any minerals they manage to extract in space.
A new gold rush is coming—except this time, only those with a high tech gadgets and wealthy financiers can even dream of participating.

Newborn infants are supposed to be capable of imitating our facial expressions, like sticking out our tongues and opening our mouths. A new study in Current Biology suggests there’s no actual imitating going on—and that it’s all in our heads.
Parents are just going to have to accept the fact that this long-held truism about newborn behavior may actually be false. Those awesome things that your awesome baby is doing—well, they’re probably not getting it from you, and the data proves it, thanks to a study led by Virginia Slaughter of the University of Queensland. After studying the behaviors of over 100 babies over the first nine weeks of life, she’s now recommending that we modify or abandon the theory that imitation is a latent capacity of human newborns.


It’s been long assumed that imitation starts almost immediately at birth, which has influenced theories about human social cognition and learning. But evidence to support this claim is mostly anecdotal, and actual studies done on the subject have produced mixed results.
Looking to finally settle this question once and for all, Slaughter and her colleagues presented a total of 106 infants with a variety of facial expression, gestures, or sounds created by both human and non-human models. These behaviors included tongue poking, mouth opening, finger pointing, happy expressions, and sounds like “mmm” and “eee.” Each baby was tested at one, three, six, and nine weeks of age. The babies were exposed to each gesture for a full minute, while the researchers watched for a reciprocal response.
Over the course of the study, the researchers failed to find any evidence that the newborns were capable of copying these gestures, movements, or vocalizations.


The most common gesture exhibited by the babies was tongue poking, which they did in response to a number of other gestures. Turns out that tongue poking...is just what babies do.
“The results provided evidence against the view that certain human behaviours are innate,” said Slaughter in a statement. “Analysis indicated infants were just as likely to produce gestures in response to other stimuli as to matching models. Human children in later stages do copy others’ actions, but the controversial assumption that this occurs from the moment of birth needs to be rethought.”
So what’s going on? One possibility is the “observation selection effect,” a cognitive bias in which we unconsciously choose to ignore the things we’re not looking for, while only noticing the things we are looking for. In this case, we don’t notice or acknowledge gestures that are not imitations—but we certainly notice behaviors that are apparent imitations.
The human brain is capable of 1016 processes per second, which makes it far more powerful than any…
Another possibility is that the babies aren’t imitating us—we’re imitating them.


“When we interact with babies...we want to bring them into our world,” said Slaughter in an ABC News article. “We imitate them, and when we imitate them, this stimulates them to behave. We continue to imitate their behavior and this sets up a reciprocal interaction that looks like imitation and that ultimately becomes imitation but is driven by the parents or the adult’s behavior rather than the baby copying what somebody does perfectly from birth.”
But not everyone is convinced. Elizabeth Simpson from the University of Miami told ABC News that many of the modeled actions are rare or absent in newborns. “If an infant is unable to produce a given action, then of course she will be unable to imitate it. This isn’t a fair test,” she said. Simpson also believes the researchers didn’t give the babies enough time to respond.
This debate is far from settled. Parents probably won’t stop making silly faces at their babies, nor should they. It’s undoubtedly good for the baby to get all this attention. Just don’t delude yourself into thinking you’re being reflected back.


[Current Biology]

There’s a lot of superheroic spectacle in Captain America: Civil War, but one of our favorite moments has to be Scott Lang flying into battle on one of Clint Barton’s arrows. Unfortunately, according to those ever-delightful party poopers known as “scientists,” Scott would have a really unpleasant time while he’s doing it.
Sure the moment may be a loving homage to Ed Hannigan’s incredible cover to Avengers #223, but over on the Science Of blog Matt Brady did some thinking (and a whole lot of math) to figure out that as fun as it looks, Ant-Man is being ravaged by the perils of acceleration and g-forces as he hurtles through the sky in Tony Stark’s direction:
Okay – let’s sum this up: the arrow leaves the bow in 9.8 milliseconds, traveling at 278.7 mph. Just before the arrow was fired, its velocity was 0 mph, so in other words, the arrow went from 0 to 278.7 mph in 9.8 milliseconds, which is equal to an acceleration of 12,737.18 m/s2, or 1,299.7 g. A huge g force was experienced by the arrow for a very, very short time.
... A common (but gross) euphemism for individuals who experience a large acceleration over a short period is that they end up being a “bag of soup.” In this case, with the acceleration experienced by the arrow, anyone attached to it would pass right by the bag of soup stage, go right through paste, and end up as a stain.
Again, acceleration is not your friend.
Poor Scott. Or perhaps, more accurately, “poor pulpy stain that formerly was Scott.”


As Brady points out, it’s just a bit of fun—after all, it’s a superhero movie, and Scott’s inability to be affected by our own realities of physics can just be handwaved through the scifi magic of Pym particles. But the work that goes into Hardy’s equations is impressive, and a fun take on a delightful moment in the film. Check out the rest of his extensive workings at the link below.
[The Science Of...]
In a lush conservation park in central Kenya, the world’s last three northern white rhinos are unable to breed. When they die, the subspecies will go extinct. That is unless a complex, controversial plan involving tissue cryobanks and test tube embryos can actually work.
After decades of poaching, a subspecies which once numbered in the thousands across central Africa has been reduced to just three individuals: 42 year-old Sudan, his 26-year old daughter Najin, and her 15-year old daughter Fatu. Sudan has a low sperm count. Fatu has a disorder that prevents embryos from implanting in her uterus. Najin’s weak hind limbs render her unable to support the weight of another pregnancy. Thirty years ago, the northern white rhino would have been doomed to extinction. Today, synthetic biology may offer a future.
“We know it is going to be difficult, but we feel it’s important to try to prevent this animal from going extinct,” said Oliver Ryder, a geneticist at the San Diego Zoo. “And we think this is within the realm of possibility.”


Ryder is part of the international team of scientists behind a radical new effort to rebuild the northern white rhino population with lab-grown embryos created from frozen tissue. The project, outlined this week in the journal Zoo Biology, is experimental, expensive, and fraught with uncertainty. It raises tough questions about how we should be spending our conservation dollars. And if we can pull it off, it’ll be one of biotechnology’s greatest achievements.
Since the remaining northern white rhinos cannot breed naturally, the process must be started in the lab. The first step will be to obtain viable gametes (sperm and eggs). Although neither Fatu nor Najin can bear young, both rhinos can have their eggs harvested. For fresh sperm, grandpa Sudan is the only option, which is not ideal given his age and close kinship with both females. But the San Diego Frozen Zoo, a vast tissue bank built specifically for genetic conservation, contains the sperm of four other deceased males.
This is a start, but a population founded with only five males and two females—assuming both females’ eggs can be safely harvested—will be genetically impoverished. “Genetic diversity is crucial, and frankly, eggs from the surviving females and banked sperm are not going to be enough to accomplish our goals,” Ryder said.


Enter phase two of the plan: creating artificial gametes by reprogramming other rhinoceros tissues. About ten years ago, biologists discovered that they could turn skin cells into “induced pluripotent stem cells” (iPSCs) by adding the right combination of growth factors. Pluripotent stem cells are biology’s primordial matter: place them in the right environment, and they can transform into anything, from heart cells to bone marrow to gametes. “We basically have to turn these cells into animals,” Ryder said.


Viable cell lines from a dozen northern white rhinos are housed at the San Diego Zoo, the Leibniz Institute for Zoo and Wildlife Research in Berlin, and other tissue banks around the world. Back in 2011, scientists created the first rhinoceros iPSCs, using a fibroblast cell line generated from Fatu’s skin.
But turning iPSCs into sperm and eggs won’t be easy—like many experimental procedures, this has only ever been done in mice. It could take years to translate the technique to rhinos.
And acquiring viable gametes is just the first step. Next, sperm and eggs will be mixed in vitro to produce an embryo, which will then be implanted into a surrogate mother—ideally, a female of the closely related southern white rhinoceros subspecies.
Nobody has ever transplanted an embryo into a rhino uterus, and according to the researchers it’s going to be maddeningly difficult owing to the creature’s “highly convoluted and impenetrable” cervix. If the embryos cannot be implanted in female rhinos, they may have to be brought to term by horses, which have a shorter gestation period, and whose bodies may reject the foreign tissue.


If everything I’ve outlined so far proves doable, Ryder and his colleagues think it should be possible to produce a first generation of northern white rhino babies in ten years. Ten years later, they’ll be mature, breeding adults. Optimistically, we’re at least 50 years out from a small but stable northern white rhino population.
George Church, the Harvard geneticist who pioneered CRISPR technology and is now spearheading an effort to clone the wooly mammoth back into existence, told Gizmodo he believes all of the project’s cell biology goals are feasible. “I think the major challenge is not going to be the cellular technology, it’s going to be the captive breeding,” he said. “You can read between the lines in the paper just how hard it’s been to breed rhinos in captivity.”
Twenty five years ago, Michael Crichton captured our imaginations with the crazy idea that…
Ben Novak, a paleogeneticist at the nonprofit Revive and Restore, which seeks to restore lost genetic heritage to endangered species, agrees. “The real nail biter is going to be the pregnancy,” he told Gizmodo, adding that the San Diego Zoo is currently working with several southern white rhino females—potential surrogate mothers—to start making them more tame. “The more they can work with these animals when they’re conscious and awake, the better the project’s chances of success,” he said.


Not everybody’s thrilled by the idea of a half century-long biology experiment that’ll cost millions and might not work. Some conservationists argue that our resources would be better spent preventing poachers from wiping out the southern white rhino—more than 1,000 are being slaughtered for their horns each year.


Others take issue with the very idea of using biotechnology to prevent extinction. “This says we can let species go to the very brink of extinction and modern technology can bring them back,” Stuart Pimm, a conservation biologist at Duke University, told Nature News. “There is a very substantial moral hazard in that.”
Church falls somewhere in the middle. “I am sympathetic with prioritization, but I’m also sympathetic with the notion that it’s not always a zero sum game,” he said. “People could have said ‘Why waste time developing polio vaccines? We need to put all of our money into developing iron lungs.’ Clearly, that would have been shortsighted.”


And if we’re going to take the long view, we have to consider that the wheels of mass extinction have already been set in motion. Today, scientists estimate we’re losing species at over 1,000 times the background extinction rate. To Ryder, Church and others, herculean efforts like this one can accelerate technologies that’ll help rescue many more species in the future.
“We believe this will lead to technologies for preventing other species from going extinct,” Ryder said. “Ideally, we’d love to see conservation efforts apply these tools before reaching an end-game crisis management scenario.”
Correction 5/12/16: An earlier version of this article stated that the northern white rhino conservation plan was published in the journal Zoo Keys. The correct journal is Zoo Biology.

A lot of fresh fruit and vegetables spoil between the farm and your mouth. But a team of Tufts University researchers has developed a silk coating that could help keep fruit from turning without the need for refrigeration.
The team has developed a solution made from silk that it can use to coat fruit and vegetables. When exposed to just a little water vapor in a vacuum, the fibroin proteins in the silk bind with each other to form a protective film—called a beta-sheet—between 27 to 35 microns thick. The research is published in Scientific Reports.


And it seems to help keep what’s beneath fresh. The team coated strawberries with the stuff and compared them with uncoated specimens. After seven days, the coated berries were “juicy and firm,” but the uncoated berries “dehydrated and discolored.” Take a look for yourself:
Fiorenzo G. Omenetto, one of the researchers, explains in a press release:
“The beta-sheet content of the edible silk fibroin coatings made the strawberries less permeable to carbon dioxide and oxygen. We saw a statistically significant delay in the decay of the fruit.”
The researchers claim that the coating is odorless, biocompatible (meaning it won’t do bad things to you) and didn’t affect the texture of the fruit. One crucial test, however, is missing from their research—and that’s taste. The coating could be a wonderful idea if human taste buds can’t perceive it, but until that’s proven, the coating won’t be covering anything you eat.


[Scientific Reports via PhysOrg]
If, and by how much cellphones increase the risk of brain cancer is a long and disputed argument. No one study is going to settle anything, but one statistical analysis of data in Australia hints at cellphones being reasonably safe.
The study examines the incidence of brain cancer in the Australian population between 1982 to 2013. The study pitted the prevalence of mobile phones among the population—starting at 0 percent—against brain cancer rates, using data from national cancer registration data.


The results showed a very slight increase in brain cancer rates among males, but a stable level among females. There were significant increases in over-70s, but began in 1982, before cellphones were even a thing.
The data matches up with other studies conducted in other countries, but Australia is a particularly excellent example—all diagnosed cases of cancer have to be registered by law, creating consistent data to work with.


By the nature of the multiple variables, large samples and very long lead-time for cancer to show up, the cellphone-brain cancer conversation is always going to be contentious. But studies like this are increasingly showing that if you really want to be safer, forget your cellphones, and look both ways crossing the road.


[Cancer Epidemiology via The Conversation]
Even though it looks like the devil is reaching through the ground from underneath the Earth to grab a victim, you can’t look away. Even though it looks like some alien tentacle snake is burning itself and trying to attack you, you can’t help but stare. It’s the Pharaoh’s Serpent (or Black Snake firework) and it’s an old science experiment that’s always so, so gross to look at. The disgusting, growing mutant arm coil thing is actually just Mercury thiocyanate (Hg(SCN)2) getting lit on fire.
It starts off as a white power but when heated up, “a rapid exothermic reaction is started which produces a large mass of coiling serpent-like solid.” AKA that’s why there’s an ugly ass snake coming up from the ground.


I always liked lighting that Black Snake firework but this one is too real. You can learn more about the science here.

[Nile Red via Digg]

Chances are you’ve seen the gorgeous patterns that sound waves produce when sand is sprinkled on a vibrating metal plate. Now French physicists have produced inverse versions of these patterns using microbeads suspended in a liquid. They described their work in a recent paper in Physical Review Letters.
The original patterns are known as Chladni figures, after the late 18th century acoustics pioneer Ernst Chladni. Inspired by Robert Hooke’s experiments over a century earlier, Chladni sprinkled sand over a solid metal plate, and then ran a violin bow along the edge to make it vibrate. As if by magic, the grains of sand rearranged themselves into patterns corresponding to various frequencies. But it’s actually due to some intricate (and intriguing) physics, as Diana Cowern, a.k.a. the Physics Girl, explains with her own DIY demonstration:

Every material object has a natural resonant frequency (or set of frequencies) at which it vibrates, and the metal plate is no exception. We can’t see them, but the plate will only vibrate in certain regions, set off by lines where it won’t vibrate at all (the so-called nodal lines). Set the plate to vibrating at one of those resonant frequencies, and the sand will be pushed away from the vibrating regions and cluster along the nodal lines. As the frequency shifts, so do the locations of the vibrational nodes. That’s why you get different Chladni figures for different frequencies.


Chladni’s technique soon became a vital tool for violin makers, since the resulting patterns let them visualize just where those all-important modes of vibration fell in the back plates of the instruments. It’s still used by instrument makers today—and as a popular demonstration for physics classes.
Physicists at the University of Grenoble Alpes in France recreated Chladni’s seminal experiment, only they used polystyrene microbeads suspended in water instead of sand. And instead of a metal plate, they stretched a thin membrane of polysilicon across a circular opening (much like the skin of a drum) at the base of a standard “lap-on-a-chip” microfluidic device, injecting the microbeads in water. As the drum vibrated, a camera attached to a microscope recorded the changing positions of the beads at various frequencies.
Nothing happened at higher frequencies. The beads didn’t move, and no pattern emerged, because the membrane was so small and thin that higher frequencies just didn’t resonate. That changed when the frequencies shifted into the low ultrasound range. Then the beads started clustering into patterns. The researchers found they could switch the pattern almost instantly, just by altering the frequency.


Shift those vibrations just a little bit off the resonant frequency, and the microbeads begin to rotate in a circle, in a motion reminiscent of the farandole, a traditional French folk dance:

These are not the same patterns as Chladni figures, however. Chladni noticed that very fine particles, like those shed by his bow, didn’t get pushed to the nodes like the coarser grains of sand. They moved in the opposite direction, congregating at the so-called “antinodes.” The phenomenon is known as acoustic streaming, and as Derek Stein writes at APS Physics, it’s “the reverse of the process by which air flow generates vibrations in a musical instrument.”


That’s what makes this technique potentially useful for a variety of applications. Sound waves are already being used to mix and pump fluids in microfluidics devices. Scientists could also use them to manipulate living cells on a surface, getting them to form clusters and influence how they develop simply by changing the frequency of the sound waves. Right now, they must rely on prefabricated patterns, many of which require clean room conditions, and cannot be quickly and easily changed.
[Physical Review Letters]
An ongoing listeria outbreak has put eight people in the hospital and forced a recall of 358 different frozen fruits and vegetables. But although we know all these listeria cases are linked to the same source, just what that source is remains a mystery.
The FDA just released the results of its investigation into the latest outbreak of listeria, a foodborne infection that hits its victims with fever, muscle ache, and diarrhea. The very first case from this particular outbreak actually happened back in 2013. It was only in April of this year, though, that the outbreak was finally traced to frozen vegetables, sparking the recall.


The recall has targeted frozen fruits and vegetables, including broccoli, carrots, green beans, kale, peppers, potatoes, spinach, blueberries, cherries, peaches, raspberries, strawberries, and more, as contaminated. (You can see a full list of all the 358 recalled products, from more than 40 different brands, right here.) Although no source for the contamination has yet been identified, there is a clue as to where we might look for one.
The contamination is widespread across different foods, which suggests that the source could be from a contaminated surface somewhere in the factories, or along the supply line of the fruits and vegetables. The FDA found listeria on surfaces inside at least one factory, although whether it or some other source was the cause of the contaminated vegetables remains unclear.


Still, it’s a clue to how the outbreak may have begun—and to how we might finally be able to stop it.
An international team of scholars has just unveiled plans to science the shit out of Leonardo da Vinci, the man who gave us the Mona Lisa and envisioned futuristic technologies like helicopters and tanks 500 years ago. Goals of the fledgling “Leonardo Project” include recovering the famous Renaissance figure’s remains and reconstructing his genetic code.
The Leonardo Project brings together geneticists, genealogists, archaeologists, and art historians from Italy, Spain, France, the United States and elsewhere. “This is a fabulous, interdisciplinary project,” said Rhonda Roby, a geneticist at the Craig Venter Institute in California, who will be contributing its expertise in genomic reconstruction to the effort.


By examining everything from paintings and notebooks to the DNA of living relatives, the team hopes to glean new insights into Leonardo’s life, diet, physical appearance, and genetic predispositions. If they’re very lucky, the researchers may be able to reconstruct most or all of Leonardo’s genome.
And if all that weren’t enough to make you re-evaluate your life goals, the team intends to wrap the Leonardo Project in just three years on the 500th anniversary of the artist/inventor’s death. A project roadmap is published today in the journal Human Evolution.


Ten years ago, the idea of obtaining even a scrap of DNA from a man who died in the Renaissance would have sounded absurd. But major advances in genomics have since enabled the reconstruction of wooly mammoth and Neanderthal genomes from fragments of ancient material. Meanwhile, forensic scientists have been adapting these tools for recovery of DNA traces from hair, drops of blood, saliva, and even fingerprints.
“More and more techniques are being developed to recover DNA from people touching things,” Roby said, citing Leonardo’s multitudinous notebooks as possible source material for the inventor’s genetic blueprints. “I also think there’s a possibility of biological material inside paintings,” she added. “The challenge would be actually getting that material out without damaging the artwork.”


A related aspect of the project involves identifying and studying Leonardo’s living descendants. Alessandro Vezzosi, director of Museo Ideale Leonardo da Vinci, has already conducted an extensive reconstruction of Leonardo’s paternal lineage, and complementary efforts to trace his mother’s bloodline are now underway.
As Roy explains, these two sides of the family tree can yield different information. Since sons always inherit their father’s Y chromosome, the paternal lineage could lead us to men who have an exact replica of Leonardo’s own Y (or close—a few mutations can sneak in over 25 generations). Meanwhile, mitochondrial DNA is passed down through the mother. So by tracing his maternal lineage, we may discover descendants who share this portion of his heritage. DNA from modern relatives could then be compared with ancient samples in order to verify their identity.


There are myriad ways that Leonardo’s DNA can shed light on his life. Eye color, hair color, weight, height, predisposition to disease, and even the inventor’s famed visual acuity are all things scientists hope to learn more about.
“There are certainly individuals with exceptional senses,” Jesse Ausubel, director of the Program for the Human Environment at Rockefeller University and sponsor of the Leonardo Project’s 2015 and 2016 meetings, said during a press call. “People with exceptional sight and hearing, for instance. I think those qualities are among the genetic attributes we all have interest in.”
Another goal is to firmly identify and study Leonardo’s mortal remains. He is believed to be interred in the chapel Saint-Hubert at the Château d’Amboise, France, but the exact location of the grave is unknown. “Even if we had bones from that tomb, we would need to verify their identity by looking at the bones of his father, maybe the DNA on some of his artwork,” Ausubel said. “No single source of evidence is enough.”
While the project boasts a long list of academic partners, its goals are contingent on the cooperation of governments, private museums, and individuals. Bill Gates, for instance, is the owner of the famous Codex Leicester, an original collection of Leonardo’s scientific writings. Forensic scientists will have to court the billionaire’s favor in order to dust his $30 million book for fingerprints. Geneticists will need to convince the living relatives to participate in DNA studies that might reveal sensitive information. And the project will have to persuade the French government to grant it access to the historic chapel of Saint-Hubert.


It all sounds rather daunting, but Ausubel his colleagues are hopeful that the public will recognize the enormous scientific and cultural potential of their endeavor. Beyond shedding light on Leonardo’s life, the project might also serve as a testing ground for emerging technologies that can be applied to all manner of famous historic figures and artifacts.
“Overall, we feel this is an exciting frontier,” Ausubel said. “We hope the progress we make will be useful to museums around the world.”
“Leonardo himself is a person who loved puzzles,” he added. “He loved cryptology. I think part of the excitement and fun of this project is that it’s the sort of challenge he himself would have invented.”
The winners of the inaugural Data Stories Competition, which highlights some of the most creative and fascinating scientific data visualizations of the past year, have just been announced.
Sponsored by the Advancement of Science (AAAS), entries ranged from planetary science and oceanography to neuroscience and climate change. Three expert judges evaluated the submissions based on three key features: creativity, complexity and clarity. Here are the winning entries:
And you thought you didn’t care. It’s actually a much more complicated question than it sounds. R.J. Andrews from Info We Trust breaks it down for you:

Mars’ atmosphere ain’t what it used to be. This visualization by Daniel Gallagher from NASA’s Scientific Visualization Studio explains why:

This visualization was also the People’s Choice winner.
Ulf Aslak Jensen, a masters student at the Technical University of Denmark (DTU), put together this fascinating visualization showing how people mingle, interact, and generally go about their social lives.

Here are our favorite entries from the remaining list of candidates:
This sweet visualization by Tom Bridgman from NASA Goddard Multimedia depicts the sun’s numerous data signatures as single pie chart.

As NASA writes:
When we observe the sun with multi-wavelength imagers such as the Solar Dynamics Observatory (SDO), we are often challenged with understanding how the different wavelengths reveal different phenomena in the solar atmosphere. By assembling these ‘pie slices’ from the different wavelength filters, and moving them around the solar disk, it is easier to see the similarities and differences in how the solar plasma responds in the fields of the solar environment.
This submission by Kim Albrecht from the Center for Complex Network Research takes something that’s completely incomprehensible—the cosmic web that binds galaxies together—and presents it in a way that’s wholly understandable. Sort of:

The University of California, San Francisco’s Roger Anguera created this gorgeous visualization showing how brain signals travel through and around the brain. Each color represents source power and connectivity in a different frequency band, i.e. theta, alpha, beta, and gamma waves:

Using the latest research into gun violence, Gabriel Reilich from GOOD breaks down the growing problem in an engaging and provocative way:

Here’s what the current climate change anomaly would look like if it were a roller coaster, courtesy of NOAA’s Emily Greenhalgh:

The United States hasn’t experienced a landfall Category 3 hurricane or larger since 2005. Is that weird? Joy Ng from NASA Goddard Space Flight Center explains:

Here’s what all those floating patches of garbage in our oceans are actually doing. This sobering video was produced by NASA’s Data Visualization Studios:

This video by Alex Kekesi of GST, Inc tracks a surprisingly long-lived and benign tropical storm as it makes it’s way around the Pacific:

This stunning visualization by NASA’s Kel Elkins depicts dust from the Sahara Desert travelling across the Atlantic Ocean to the Amazon Basin:

On August 21, 2017—and for the first time in 40 years—the path of the moon’s shadow will pass through the continental United States. This NASA video shows what will go down on that highly anticipated day:

George Alger from the Center for International Forestry Research created a beautiful and informative video explaining why forests are a critical aspect of human well-being:

Where’d it all go? This NASA timelapse shows how ancient Arctic ice has declined in recent years:

Ocean currents are invisible to the naked eye, but this simulation by Los Alamos National Laboratory shows their intricate global reach:

More visualizations here.
The Eta Aquarid meteor shower is tonight, and it’s going to be a spectacular show. Here’s how, when, and where to watch the Eta Aquarids—and why they’ve been so unjustly ignored for so long.
The Eta Aquarids are a late spring meteor shower made up of the icy debris of Halley’s Comet. The comet is actually responsible for two separate meteor showers a year—this one and the Orionids, which occurs in October.


The Orionids typically overshadow the Eta Aquarids, but that shouldn’t be seen as a judgement on the latter’s quality. All it means is that people have been sleeping on a really excellent meteor shower for no good reason. Tonight is your chance to rectify that.
It’s true that the Eta Aquarids isn’t the most prolific of showers—NASA estimates that this time around we should see an average of 10-30 meteoroids per hour. But what it lacks in number of meteoroids, it more than makes up for in terms of how spectacular each is likely to be.


At 148,000 mph, the meteoroids are some of the fastest you’ll see all year. That means that their trails are long, sweeping across the expanse of the sky, and occasionally lingering for minutes.
These long trails significantly increase your chances of seeing meteors. It also means you’re more likely to see some of the stranger meteor shower effects, like exploding fireballs and meteor smoke trails. In fact, given the speed of the meteoroids, you could see these phenomena multiple times during the shower.
The Eta Aquarids’ season, the showiness of its individual meteors, and its wide scope make it one of the easiest meteor showers to view. There are still things you should keep in mind, though, for maximum viewing enjoyment.


Even with the warmer weather, being outside at night means you’re going to want a sweater and possibly even a blanket. A sky map (or an equivalent app), a flask, your choice of snacks, and another blanket to spread on the ground are also going to be useful.
The peak of the shower is tonight, but the couple of days surrounding the peak are often almost as good for viewing. Still, the best time to try is tonight, and the pre-dawn hours of tomorrow morning.
The point from whence the meteors seem to stream (called the radiant) is just above the constellation Aquarius and a lot of guides will recommend you start by looking there. But this is really about spotting those long Eta Aquarids trails, so I’m going to recommend you skip focusing on the radiant, even if you start out there, and instead find a good place to lay out where you can see whole the sky.
The Lyrids shower two weeks ago was almost entirely washed out by the bright light of the full moon. That won’t be a problem tonight; the moon should be barely visible. If you’re in a city, drive as far from the lights as you can for the best viewing.


Of course, in case of rain, clouds, or if you’re just lazy, there’s always Slooh’s reliably excellent livestream, which will begin broadcasting the view from the Canary Islands at 8pm (EST) tonight. But I recommend you skip the screen for your own patch of sky. Really, nothing else compares to it.

Will SpaceX manage their next (and even trickier) attempt at landing a rocket neatly on a drone ship? Let’s watch and find out.
In the coming late night/early morning hours, SpaceX will be launching another of its Falcon 9 rockets—this one carting a JCSAT-14 communications satellite—and then attempting to set it down gently on a waiting drone ship below. SpaceX made its very first drone ship landing just last month, when a different Falcon 9 rocket touched down on the drone ship Of Course I Still Love You minutes after having launched a resupply mission up to the ISS.


The touchdown came after a series of crashes, falls, and explosions as SpaceX figured out how to land on rocket on a ship. Now that the company has pulled off the feat, however, SpaceX has ushered in a new era for reusable rockets as well as the option to choose landing points almost anywhere on the ocean.
There is a catch. SpaceX says that this landing is “unlikely” to be a repeat of that success. Because this Falcon 9 is set for a geostationary transfer orbit, the rocket will be coming in much faster and hotter onto the Of Course I Still Love You than the last rocket. While it’s still possible SpaceX could manage a touchdown, the most likely outcome for this landing attempt is a crash.


The launch will take place at 1:21 am (EST) on May 6 (although the livestream will kick off about a half an hour prior). The launch was originally scheduled for that time yesterday, but was called off on account of weather. You can watch along with us right here.


Scientists have sustained human embryos in a petri dish for 13 days, shattering the previous record of nine days. The breakthrough will allow researchers to study early fetal development in unprecedented detail, and brings us one step closer to viable “artificial wombs.” But it’s adding fuel to an already heated ethical debate.
Two separate papers published this week, one in Nature and one in Nature Cell Biology, have reported culturing human embryos for nearly two weeks, going well beyond previous efforts. There’s no reason to believe that the embryos couldn’t have survived beyond the two-week mark, but the experiment had to be halted to adhere to the internationally agreed 14-day limit on human embryo research.
Artificial wombs are a staple of science fiction, but could we really build one? As time passes,…
Prior to this study, scientists had only been able to study this mysterious stage of human development until the seventh day. Then they had to implant the embryos into the mother’s uterus so it could survive and develop normally. Using a culture method developed at the University of Cambridge, the researchers were able to extend this to 13 days.


“Implantation is a milestone in human development as it is from this stage onwards that the embryo really begins to take shape and the overall body plan are decided,” Magdalena Zernicka-Goetz—who led both studies—said in a statement. “But until now, it has been impossible to study this in human embryos. This new technique provides us with a unique opportunity to get a deeper understanding of our own development during these crucial stages and help us understand what happens, for example, during miscarriage.”
What’s more, the technique could allow scientists to better understand the consequences of fetal alcohol syndrome, the causes of conditions like autism, and why certain chemicals affect embryonic development. It could also be used to study the neurological effects of transmissible diseases such as the Zika virus.
There are two important take-aways from this research. “First, advances in technology have allowed the growth of embryos in a lab past the time which many scientists thought possible,” said University of California cellular biologist Peter Donovan, who wasn’t involved in the study. Second, critical aspects of early fetal development aren’t dependant on it being attached to the mother. “So now science has a method to study a key period of human development that up until now has largely remained a black box,” added Donovan.


This new study is also rekindling the debate about the need for such experiments, and whether the 14-day rule should be revised and expanded. It’s challenging conventional notions of embryonic and fetal viability outside the womb.
At the 14-day mark, the embryo forms a structure called the “primitive streak” that signifies the time when it has developed a discernable head and tail end. Before this stage, the embryo is basically just a clump of cells that has the potential to split into multiple individuals. Thus, some say it’s the critical stage at which an embryo becomes a discrete individual.


Others argue that this “individuality,” or personhood, doesn’t arise until much later, such as the point of viability outside the womb (usually around 23 weeks). So the ability to sustain an embryo outside the womb at this early stage adds a new wrinkle to this often controversial and heated dialogue.
Unlike most countries in the developed world, the United States is still deeply mired in the…
Stanford School of Medicine legal expert Frank Greely isn’t convinced about the scientific efficacy of this research or the need to go beyond the 14-day limit.
“[If] we do not use a 14 day rule, what limit will we use? Twelve weeks or so as in many European abortion laws? Viability as in US abortion law?” he asked. “Human development is a seamless process, but ultimately lines need to be drawn even when—especially when—they do not naturally exist. I do not see a politically or, for most people, morally acceptable line after 14 days. Given the questionable scientific value of the research, no case has been made for even revisiting the line, let alone changing it.”
Greely is off the mark by claiming that this line of research has “questionable scientific value,” but he’s right in saying that rules should exist for this type of research. Rules, though restrictive, ensure safety and efficacy. Once scientists get a handle on the new bounds created by their research, restrictions can then be modified and extended further to allow science to continue.


It’s a conversation that can’t simply be swept under the rug. We’re inching closer and closer to the day when it’ll finally become possible to grow a baby entirely outside the human body.


[Nature, Nature Cell Biology]
The mass exodus from the Fort McMurray area in Alberta has widened as wildfires continue to spread in and around the ravaged oil town. Officials have had to re-evacuate fleeing residents, while relocating its emergency headquarters some 200 miles south of the city.
A state of emergency has been declared in the province of Alberta as a rapidly moving and frustratingly unpredictable wildfire continues to rage outside and within the city of Fort McMurray. As a massive wildfire continues to bear down on the Fort McMurray area of northern Alberta, officials have had to expand a mandatory evacuation order to neighboring communities, including nearby regions in which fleeing residents had sought shelter.

Nearly 90,000 people were forced to leave Fort McMurray earlier this week—some with just 30 minutes notice— making it the largest evacuation in Alberta history.


The growing fires also forced the city’s emergency operations center to move for the second time in one day. Officials have now set up camp some 185 miles (300 km) south of the ravaged oil town. By declaring a state of emergency, the province will be able to request additional resources from outside the province.

People were asked to leave areas south of Fort McMurray, including Anzac, Fort McMurray First Nation, and Gregoire Lake Estates. Hundreds of evacuees had sought refuge in these areas, but they now have to move yet again. Buses are expected to transport residents further south to Lac La Biche and Edmonton.

The fires are also making a serious dent on Fort McMurray’s massive oil industry. Suncor Energy had to trim production at its Sunrise facility down to 10,000 barrels of oil per day from 30,000. Royal Dutch Shell stopped production at two facilities, holding back 255,000 barrels a day of production. Other companies, such as Husky, Syncrude and Nexen, have likewise had to either shut down their facilities and pipelines or scaled-back production. These measures were done to help evacuate non-essential personnel and because of the sudden loss of the labor force. Fort McMurray is home to thousands of oil industry workers, but experts say the oil facilities are not at risk.

Fire crews in Fort McMurray continue to battle three distinct fires, one of which is creeping closer to the Fort McMurray International Airport. The other two are moving towards Parsons Creek and the Mackenzie Industrial Park. Mercifully, a cold front is expected to move through the area later tonight. It’s estimated that 1,600 homes have been destroyed, but the figure could be much higher. Some neighborhoods experienced as much as 80 percent damage.

The wildfires have also produced a massive plume of smoke—a giant pyrocumulus cloud so large that it could be seen from space. The plume has even generated its own lightning. The blaze is being partly blamed on El Nino, which is producing drier than normal conditions in the prairie provinces. Combined with high temperatures and strong winds, the situation in Fort McMurray was a time bomb waiting to explode. Experts warned several years ago that something like this could happen to Alberta’s aging forest.

At the same time, Prime Minister Justin Trudeau said people shouldn’t automatically blame climate change on the fires.


“It’s well known that one of the consequences of climate change will be a greater prevalence of extreme weather events around the planet,” Trudeau said. “However, any time we try to make a political argument out of one particular disaster… that can sometimes not have the desired outcome.”

[Globe and Mail, BBC, NYT]
Robot-assisted surgery is increasingly common in hospitals, but it’s always under the control of a human surgeon. Now, a robot’s sewn up incisions in a live pig’s gut, all by itself.
Getting robots to autonomously perform surgery on soft tissue—like, say, your guts—is tricky. First, it’s hard to tell some parts form others. Second, it’s damn slippery in there, which makes it hard to keep track of where everything is, compounding the problem.


The researchers at the Children’s National Medical Center in Washington DC haven’t let the robot carry out a full operation unguided, then. Instead, they added fluorescent tags to the surface of a pig’s guts, which allowed their Smart Tissue Autonomous Robot—or STAR to its colleagues (not the one pictured above)—to see exactly what was happening via 3D cameras and near-infrared imaging.
In fact, using information from those sensors STAR was able to stitch up a surgical cut in the gut of four different pigs, unaided. Comparison with human surgical work revealed that it was at least consistent, placing sutures more evenly than its meat-space counterparts.


But it was slow—really quite slow. A procedure that can be performed in 8 minutes by a human surgeon took the robot 50 minutes. Still, if it could speed up, the robot could be used to, say, finish up an operation while a surgeon preps for the next. The results are published in Science Translational Medicine.


Now, the team plans to develop STAR for testing in humans, where the researchers reckon the ‘bot could be used to help medics perform simple surgeries such as appendectomies. Don’t all sign up at once.
[Science Translational Medicine via New Scientist]
Remember when we told you that the Venus flytrap can actually count? That’s how this carnivorous plant knows the difference between the presence of prey in its trap and a false alarm. Now the same team of German scientists is back with insight into how the Venus flytrap turned the evolutionary tables to become predator instead of prey. They describe this work in a new paper in Genome Research.
As previously reported, the Venus flytrap has a pleasing fruity scent, the better to attract unsuspecting insects to its deceptively welcoming leaves. Those leaves are lined with ultra-sensitive trigger hairs that sense when something touches them. When the pressure is sufficient to bend those hairs, the leaves snap shut, trapping the prey inside with the aid of long cilia that act like fingers, grabbing and holding the insect in place. And then the digestive process begins.
Earlier this year, researchers at University of Wurzburg in Germany concluded that the Venus flytrap manages this feat by counting the number of times something touches its hair-lined leaves. Only after the fifth triggering stimulus would the flytrap begin excreting digestive enzymes.


They next planned to sequence the plant’s genome in hopes of uncovering further clues about traits specific to the flytrap’s penchant for meaty insects.
That’s where the new paper comes in. During their genetic analysis, the German team discovered that the same common plant defense systems that typically protect plants from being eaten by insects, are used by Venus flytraps for insect feeding. Somewhere along its evolutionary timeline, the Venus flytrap adapted that defensive gene activation pattern into an offense, effectively switching from prey to predator.
For instance, when the researchers compared the Venus flytrap with the non-carnivorous thane cress, they found that both plants produce a defensive hormone called jasmonate. But the thane cress does so in response to injury—say, from the bite of a hungry insect—while the Venus flytrap does so when its sensory hairs detect potential prey. And the hormone serves different purposes for each: for the thale cress, it produces poisonous substances or make its leaves harder to digest, while for the flytrap, it kicks off the digestive process.


And counting isn’t the only means by which the Venus flytrap tells the difference between an inedible object and actual prey. Most insects have a chitin exoskeleton; the flytrap has a chitin receptor enabling it to “taste” an insect. The plant will produce even more digestive enzymes in response to the presence of chitin.
“Contact with chitin normally means danger for a plant—insects that will eat it,” co-author Rainer Hedrich said in a statement. This in turn triggers key defense mechanisms. “In the Venus flytrap, these defensive processes have been reprogrammed during evolution. The plant now uses them to eat insects.”


[Genome Research]
The Venus flytrap is perhaps the best known of carnivorous plants — those that get essential…
We make many decisions every day, from choosing whether to buy skim or whole milk, to deciding which way to turn at an intersection. How confident you feel about your choices will influence your behavior.
But that subjective feeling of confidence stems from objective statistical calculations in the brain, according to a new paper in Neuron. This is contrary to prior studies concluding that the brain takes shortcuts when processing decisions—following rules of thumb and making approximations, rather than making precise statistical calculations.


The notion of confidence can be tricky to define. There’s the human emotion of feeling confident, of course, but there is also a concept of confidence used in statistics. The latter is something quantifiable that can be precisely calculated. Statisticians typically do this by sampling the data and using that subset to draw conclusions about the entire data set. Google’s AlphaGo uses an algorithm to objectively calculate its confidence in how likely it is that it will win the game at every step, although the way it does that computation is very different from a human brain.
Lead author Adam Kepecs, a neuroscientist at Cold Spring Harbor Laboratory, draws an analogy to poker to illustrate these two faces of confidence. A poker player with a big pot at stake must decide whether to call, raise, or fold. He or she can objectively calculate the odds—the statistical definition of confidence—but that decision also hinges on how the player feels about those odds. We think of the latter as a gut instinct, based in part on the player’s “read” of the other players at the table.
This latest study aims to quantify the connection between these two definitions. “The feeling of confidence and the objective calculation are related intuitively,” Kepecs said. “But how much so?”


To find out, he and his student, Joshua Sanders, built video games and rounded up human volunteers to play them. The first experiment involved listening to a steady stream of clicking sounds and trying to figure out which of the clicks were faster. Participants rated their confidence in their determinations on a scale of 1 (random guessing) to five (very confident).
Those self-reports were then compared to the statistical predictions of computer simulations. And they matched, indicating that how the brain produces those subjective confident feelings is very similar to how statistical analysis spots patterns in messy raw data. “This subjective feeling of confidence relies on a statistical computation,” said Kepecs.
One consequence of these new results is that the assumptions behind those earlier studies perhaps should be rethought. “Of course, it’s difficult to claim that people never use shortcuts, because ultimately the full statistical algorithm in complicated decisions has to be approximated somehow,” said Kepecs. “But should this be our foundation for future work?” Perhaps not.
The ultimate goal is to pinpoint the region of the brain where this inner statistician is located, and precisely track just how it processes all that data. According to Kepecs, there is evidence that rats have a sense of confidence, and that certain neurons in rat brains provide a neural basis for that. This latest work hints at a deeper connection between rodent and human behavior. So as a next step, “We can look at a rat brain and unravel the full circuits that are producing the sense of confidence and controlling associated behaviors,” said Kepecs.


Is it really possible to quantify such a squishy, subjective thing as feeling confident about our choices? Kepecs says it is, thanks to those dual definitions of the concept. “A lot of things that seem less lofty are actually more difficult to study,” he said. “Hunger is much more complicated to define. You can’t ask an animal what hunger is. I actually believe that fundamentally, most of these kinds of ideas in psychology have a related concept that is computational in nature.”
[Neuron]
Google’s AlphaGo computer may have bested a human in four out of five matches last month, but human …
Another May the 4th, another day of wishing scientists would hurry up and invent FTL propulsion already. But now, NASA has gone and given us the next best thing: a virtual trip to the center of the galaxy, stitched together from a stunning series of Hubble wide-field images.
In thirty seconds, you can take the dizzying 27,000 light year trek from Earth’s lonely vantage in the galactic boondocks to the Milky Way’s densely-packed core, where a million Suns are crammed into the volume of space between here and Alpha Centauri. At the center of our galaxy, stars swarm about the supermassive black hole Sagittarius A*, a bunch of giant fusion reactors popping off into abyss one by one.


It will leave you feeling very small and powerless, and also, wishing you had a control knob to enhance that damn black hole.

[Hubble]
If Planet 9 exists, it’s been through one hell of an ordeal. That’s the takeaway from a series of new studies that ask how in the name of Uranus a planet could have gotten itself into such a whacked-out orbit. This in turn might help explain the unlikely orbits of half a dozen Kuiper Belt objects.
Planet 9 is a hypothetical world roughly the mass of Neptune that orbits our Sun in a giant ellipse, at a distance of 40 to over 100 billion miles. Although astronomers have proposed hidden ninth planets for years, this latest version—the brainchild of Caltech’s Mike Brown and Konstantin Batygin—has gained quite a bit of traction since it was announced in January. The potential planet is so compelling that many astronomers have penned follow-up papers describing how we might find it and what it could look like.
Ten years ago, billions of humans had their worldview upended when a group of astronomers announced …
Almost as interesting as Planet 9's present location is how this behemoth wound up cooling its heels ten times further from the Sun than Pluto. Several new modeling efforts led by researchers at the Harvard-Smithsonian Center for Astrophysics are now attempting to answer that question.


There are essentially three competing hypotheses. The most likely, proposed by astronomers Scott Kenyon and Benjamin Bromley, posits that Planet 9 is a gas giant that formed in the inner solar solar system before straying too close to Jupiter and getting itself punted out.
“The odds that other gas giants were formed in the early solar system are very good,” Kenyon told Gizmodo, adding that the few first million years of our Sun’s life were a chaotic time, with young gas giants sucking up matter and crashing into each other all willy-nilly. “You could have made ten and Jupiter could have eaten a few.”
There’s just one problem: once gravity punted Planet 9 into the boondocks, what caused it to brake? Why didn’t it keep on going into interstellar space? One possibility, Kenyon said, is that the so-called “gaseous disk” that surrounded our Sun for the first 20 million years of its life produced enough friction to slow Planet 9 down. “If you have the right mass of planet and the right mass of gas, you can damp the orbit and circularize it,” he said.


Next, the two men proposed an even stranger possibility: maybe Planet 9 formed in place. In this scenario, Planet 9 is a giant snowball rather than a gas giant, that packed itself up in a very slow and very cold version of the accretionary process that formed the Earth.
“Our idea is that as the gaseous disk is going away, it develops a hole, which gets bigger and bigger until the disk is gone,” Kenyon said. “As this hole is getting bigger, material outside the hole sweeps up solid particles like a snowplow, and deposits them at a large distance.” Over the course of hundreds of millions of years, all of those plowed up ice shavings snowballed into one another, resulting in a jawbreaker about twice the size of the Earth.


Kenyon admits the idea is speculative. Fortunately, there’s a very good way to test these competing hypotheses—by observing Planet 9. “The nice thing about these two scenarios is that they predict different things for the planet,” he said. “If it’s a scattered gas giant, it’ll looks like a cold version of Neptune. If it’s an icy object that formed at 500 AU, it’d be a large version of Pluto.”
The final scenario sounds like a plot line from a B-list scifi movie, and it seems to be comparably unlikely. Planet 9 could be an extraterrestrial invader. “Planet 9 may be an exoplanet in our own solar system,” said Gongjie Li, another astronomer at Harvard’s Center for Astrophysics whose recent modeling paper explores this very possibility, among others.
Astronomers believe our star formed as part of a densely packed cluster that dissipated after about 100 million years. In the early days of the solar system, close encounters with neighboring stars would have been much more common. It’s possible—albeit unlikely—that the outer edges of our solar system once exchanged material, including planets, with another.
“This is a possibility, but I think everything has to work out just right,” Kenyon said. “It’s a very finely tuned scenario.”


Li’s models also reveal a small but significant chance that a passing star could have perturbed Planet 9's orbit without breaking it. This could explain why the planet is stuck in such an unusually stretched out ellipse today.


One could argue that all of this speculation will be moot if we never find a massive object lurking 100 billion miles away. On the other hand, it’s kind of awesome that the mere thought of Planet 9 is causing scientists to consider all the crazy shit that could have gone down in the early solar system. Even if our telescopes turn up nothing, a system where rogue exoplanets and larger-than-Earth-sized snowballs are possible is an amazing place to live.
Residents of Fort McMurray, Alberta—home to 83,000 people—have been ordered to leave as an out-of-control wildfire swept into the city. It’s the largest fire evacuation in the province’s history.
Fire officials in Fort McMurray are bracing themselves for what will undoubtedly be another challenging day. Fueled by record-breaking temperatures that hit 90 degrees F (32 degrees C), the fire swept into the city yesterday around 6:20 pm. A mandatory evacuation order was issued for the entire city, which is located 270 miles (435 km) north of Edmonton and is home to thousands of oilsands workers.

Fires could be seen burning through suburbs on Tuesday afternoon as the flames made their way towards the downtown area. Walls of flame erupted along a highway out of Fort McMurray as panicked residents plotted their safest routes out of town. Residents could hear the popping noises of exploding fuel tanks as they made their way down Highway 63. Emergency officials say entire neighborhoods have been wiped out by the wildfire. Exact numbers aren’t yet available, and the fire is burning in several areas in the city’s south end. It’s too early to tell, but this has the makings of a terrible disaster.

The situation became quite chaotic as residents took to the roads. Some people were only given 30 minutes notice and were told to leave everything behind. Gridlock was endemic. The speed of the fire’s advance left many people—including city officials—completely off guard.

“On the left was a big gas station; the flames jumped over the highway and blew up the gas station. It was torched,” noted Fort McMurray resident Cassie White in a Globe & Mail article. “People were driving on the shoulder. There were flames maybe 15 feet high right off the highway. There was a dump truck on fire—I had to swerve around it—and there was a pickup truck on fire as well. The entire trailer park on my right was in flames. Roofs were coming down.”


To which White added: “It almost looks like a zombie apocalypse.”

Officials have accounted for about 53,000 evacuees from from McMurray, many of them retreating southward towards Anzac and Lac La Biche. Around 18,000 of them fled to Edmonton. Hotels around the region are completely booked as evacuees desperately look for places to stay. Incredibly, no fatalities or serious injuries have been reported at this time.

The fire had been burning near the city since Sunday, covering an area nearly 10 square miles (27 square kilometers), but shifting winds in the early afternoon on Tuesday led to the dramatic turn of events.

The province has asked for military help, and it should receive it soon in the form of assistance from the Army and the RCMP. However, city officials will have to wait for an agonizing two days before the military can effectively respond. There are currently only 150 firefighters tackling the blaze, but they’re expecting about 70 to 80 reinforcement from Edmonton later today. The fires were so severe on Tuesday that the firefighters had to pull back.

“The wildfire behavior is extremely erratic and it isn’t safe for firefighters to be on the ground,” noted Laura Stewart, a wildfire information officer, in the Globe article. “It’s a very fluid situation, and things are changing by the moment.”


[Globe and Mail, Edmonton Journal]
You’ll never see a death certificate with the words ‘medical error’ as the cause of death. But a new study suggests that it could be considered the third biggest cause in the US.
An analysis of causes of death by researchers from the Johns Hopkins University School of Medicine suggests that medical errors—whether a surgical slip, poor prescription or dodgy diagnosis—account for as many as 250,000 deaths that occurred in 2013. That’s only beaten by heart disease and cancer, which each account for about 600,000 deaths per year.


It is, of course, incredibly difficult to gain an accurate handle on how many medical errors result in death. In this case, the team studied the medical literature about the prevalence of poor inpatient care in different areas of the medical profession. They then extrapolated those findings out to cover all medical care—though not nursing homes or out-patient care—provided across the US. Their final count of 250,000, published in the British Medical Journal, is therefore very much an estimate.
But the researchers use chance to make a fairly compelling argument: That even though it’s hard to talk about medical error, it would be incredibly useful to at least provide the chance to more easily report its occurrence as a contribution to death. It is of course impossible to eliminate human error from health care, but by creating an atmosphere in which it can be discussed more freely, it would be possible to develop better protocols and safety measures to avoid it in the first place.


It will, however, be hard to convince hospitals and doctors that the threat of litigation is worth that risk.


[BMJ via Medical Express]
For decades, quantum computing has been the preserve of research labs. But now IBM has made its working prototype quantum computer accessible via the internet—and literally anyone can use it.
The company has made a five-qubit quantum computer—which sits in a New York lab—remotely accessible using a piece of special software. It’s not for the faint-hearted: The user-friendly interface, shown below, still requires you to understand how quantum devices work, which is well beyond the comprehension of many of us.


Quantum computer simulators have been made available online before, but to my knowledge this is the first time that hardware has been opened up for widespread public use. Cynics may—quite rightly—suggest that the process allows IBM chance for a little self-promotion.
But the announcement’s more important than that. Opening access to a real quantum device for students, researchers and plain-old nerds that wouldn’t otherwise have the chance to play with the hardware means more person hours can be spent tinkering with the technology. Some people will undoubtedly spot an interesting quirk in beahvior or error with the device, and that way progress lies.
Progress is certainly what’s needed. Quantum computers can, theoretically, be so much faster because they take advantage of a quirk in quantum mechanics. While classical computers use bits that exist as a 0 or 1, quantum computers use “qubits” that can exist as 0, 1 or a superposition of the two states. That allows a single bit to potentially hold two values at once, or for two bits to hold four values at once. Keep scaling those numbers, and you quickly end up with a device that can process data exponentially faster than today’s computers.


But so far it’s proven hard to build quantum devices with more than a handful of qubits. There is, of course, the D-Wave quantum computer, which claims to handle hundreds of qubits—but the jury is still very much out on whether or not the computer actually takes advantage of true quantum effects.
IBM will be hoping that the insights it can glean from opening up its hardware will accelerate the process. Hopefully it does.
[IBM via Wired]

Remember that nifty Cycloid Drawing Machine making the internet rounds back in March? Its inventor, Joe Freedman, is back with a smaller, simpler version called the DuoGraph, making it easier than ever to create pretty swirling patterns reminiscent of Spirograph.
The Cycloid Drawing Machine is awesome, but it’s a complicated machine, and bulky to boot. The DuoGraph only has seven gears and measures 14-1/2 x 6-2/3 inches—small enough to fit on just about any desk. It’s actually a redesign of the first drawing machine Freedman ever built, called the Primograph because it exploited the relationship of prime numbers to produce so-called “Lissajous curves.”


What about the underlying math? Per Freedman’s Kickstarter page:
The turntable has 60 teeth. When combined with a drive gear that has 30 teeth you’ll get a pattern that has 2 nodes. Adding a prime number gear for the fulcrum makes the drawing into a non-repeating line. Using a stationary fulcrum the line will draw back onto itself after a number of turns.
Changing the penholder positions adds even more complexity to the drawings.... All of these drawings used the same setup: a 30 tooth gear as a moving fulcrum and a 41 tooth gear as the drive. The only difference is the position of the penholder. Infinite variations are possible. Imagine how many possibilities there are using the 16 gears in various combinations.
“One beta user called it cute. It is cute. And less forbidding than the Cycloid,” Freedman writes. “It’s there to have fun and not take itself too seriously!” His fans clearly agree. With 12 days to do in his Kickstarter campaign, Freedman has already raised more than $21,000—well above his original modest $1750 goal. But for now, he’s only making 100 of these ingenious contraptions, so if you’re interested, you have until May 15. DuoGraphs will begin shipping in June.


[Colossal]

The other day I saw a video of a guy who was pumped as hell to own a cycloid drawing machine. “What …
Quaker Oats is being sued over the big “100% Natural” label on the front of its box. What else is in that bucket o’ oats that makes the label a lie? Nothing, say the plantiffs—it is, indeed, just oats. Their complaint is that the oats were grown using pesticides. That, they claim, should be sufficient to keep the natural label off it.
There’s a much larger issue here than just the oats: it’s that “natural” food doesn’t mean anything—and that’s left the door open to all kinds of claims about what natural is and is not. It works in the opposite direction too. 7-Up, Welch’s Fruit Snacks, Cheetos, and Kraft Mac & Cheese have all at some point laid claim to the “natural” label.


The argument for the FDA not defining natural makes some sense on its surface. Everything we eat has gone through at least a little bit of processing, the agency reasoned, so really nothing counts as “natural.” Fair enough. The problem is that this leaves the definition open for anyone to declare what is or isn’t natural.
A box of powder-cheesed macaroni? Natural! A candy bar? Sure, why not: natural! A can of 7-Up? All…
That’s why the Quaker Oats lawsuit can call a plain bucket of oats with nothing added to it “unnatural,” while at the same time Chester Cheetah can proclaim his commitment to both an all-natural, whole food diet and  his undying affection for Flamin’ Hot cheese powder. There is no contradiction here. Both definitions are equally made up—and both are only able to exist because no pre-existing definition was there to stop them.


Late last fall, the FDA began collecting comments from people on what it was they thought “natural” meant and will keep collecting them right up until the end of this week. Hopefully, this will result in some kind of official definition. Until then, the definition of “natural” is a vacuum. If no official definition transpires, we could end up with one defined by courts and marketing executives instead of scientists.
Using state-of-the art microscopy, scientists have peered inside cardiac cells while they beat, revealing tube-like structures that buckle and then snap back into shape, much like shock absorbers. The details now appear in Science.
Inside each heart muscle cell are tiny structures called microtubules. Using high-resolution, high-speed microscopes, researchers from Perelman School of Medicine in Pennsylvania watched as these dynamic filaments—long thought to be quite stiff—buckled under the force of each cellular contraction before springing back to their original length and form. The videos are offering fresh insights into the mechanics of healthy beating hearts, and how the abnormal stiffening of heart cells might be contributing to heart disease.
Microtubules provide structural support and allow for the movement of cells as they transport their intracellular cargo. Scientists have struggled to observe all the moving parts within living heart cells, leaving their precise role and function a bit of a mystery. It also doesn’t help that a complete contraction of a heart muscle transpires in just one tenth of a second.
Co-author Benjamin Prosser and his colleagues were able to capture the inner workings of heart cells taken from rodents.


They found that the microtubules weren’t rigid rods as previously assumed, but were instead flexible filaments with the ability to buckle and bear pressure without snapping.
The researchers also learned that the degree to which a microtubule can buckle depends on a chemical group known as tyrosine. When they removed this chemical, the microtubules buckled more, making the contraction of the heart cells more difficult.
It’s an important bit of insight that could lead to new medicines for certain forms of cardiac disease, including patients with thickened heart muscle.


[Science]
If you’re having trouble sleeping, melatonin is a popular and easy remedy. It’s effective for many people, doesn’t have any serious safety issues, and is available as pills or gummies for pennies a dose. It’s also misunderstood, though: melatonin is not a traditional sleeping pill.
Sleep signals are complex, but the important thing to know about melatonin is that it doesn’t tell the body to sleep; it tells the body that it’s nighttime. That may sound like a subtle difference, but it means melatonin won’t knock you out like a sleeping pill, and it can’t cure every type of sleep problem—just certain ones that stem from an out-of-whack body clock.


Our actions throughout the day, like when we go to sleep and when we eat, are partly programmed by a system of brain signals and hormones that make up our body’s clock. Melatonin helps to keep the body clock synced with the earth’s cycles of night and day through the convenient sunlight detectors in the front of your face. You know, your eyeballs.


Some of the light that enters our eyes helps to signal a part of the brain called the suprachiasmatic nucleus (SCN). At nighttime, little to no light comes in, and the SCN tells the nearby pineal gland to make melatonin, which then circulates through our blood.
Melatonin supplements add to the amount of melatonin circulating in our blood. Even small doses from pills, around 0.5 milligrams, can boost the amount circulating in our body. Most melatonin pills are between 0.5 and 5 milligrams. Higher amounts aren’t necessary; the signal doesn’t seem to depend on dose. (Imagine shouting to someone that it’s nighttime, versus telling them in a quiet voice. They’ll get the message either way.)

For some people, some of the time, melatonin has a hypnotic (put you to sleep right away) effect. But its effect on shifting the body clock is much stronger and more reliable. That means that sometimes it can do the opposite of what you want. Take melatonin in the morning, for example, and you might end up staying awake later—because you just told your poor confused brain that day is night. Children’s sleep specialist Dr. Craig Canapari, of the Yale Pediatric Sleep Center, made the video above to show how the effects of melatonin change depending on when you take it.


This effect may be partly responsible for some of the confusion over how well melatonin works. Vox recently reported on several reviews of melatonin studies. One doctor described melatonin’s effect on insomnia as positive but weak; another said melatonin is “a lousy sleeping pill.”
These different studies may be hiding a real effect that only applies to people with certain body clock issues. Dr. Nitun Verma, a Stanford-trained sleep specialist and longtime friend of Lifehacker, says that “it’s difficult to say what percent of people will benefit from melatonin because some research studies look at a population who only have insomnia, or delayed sleep phase syndrome (DSPS), or a combination.”
Delayed sleep phase syndrome is common in young adults and people in the tech industry, Dr. Verma says, and people with DSPS are more likely to benefit from melatonin than people who just have insomnia.
If you have trouble sleeping, you're definitely not alone. More than half of US adults…
Besides DSPS, melatonin may help with other circadian rhythm disruptions. A Cochrane review found that melatonin is “remarkably effective” for travelers with jet lag, especially people traveling east. Another Cochrane review looked at drugs for shift workers, and found that while melatonin didn’t work very well, it was still better than other types of sleeping pills.
Even if your problem is one that melatonin can help with, melatonin isn’t the only answer. Exposing your eyeballs to sunlight and darkness at appropriate times also helps to sync up your hormones and retrain your brain. That’s why screens at bedtime can screw up your body clock: your brain gets the “daytime” signal when it’s really night. On the flip side, it’s not smart to take melatonin and then watch movies on your iPad while you wait to fall asleep.
Dear Lifehacker,I like to use my smartphone and tablet in bed. I know that screen time before bed…
Don’t forget to consider other reasons why you might be having trouble sleeping. Do you have a sensible sleep schedule and a bedtime routine that gets you in the mood to sleep? Make sure to cover those bases, too.
I've never had trouble waking up in the morning. When the alarm goes off, I'm up and…
Insomnia can also be a symptom of other medical or mental problems, including depression, anxiety, and sleep apnea. If insomnia is interfering with your life, and especially if you have other medical or mental issues that could be related, talk to a professional. Your regular doctor is a good place to start, or you can find a local sleep specialist with this directory from the National Sleep Foundation. They can help figure out if there’s an underlying cause for your insomnia, and they may be able to recommend more comprehensive support.
Great discussions are par for the course here on Lifehacker. Each day, we highlight a discussion…
Every drug has its risks, and thankfully melatonin doesn’t have very serious ones—at least as far as our current studies have shown. An Australian pediatrician warned last year that we shouldn’t assume melatonin is safe for children, since its long term effects haven’t been studied very well. One concern is that long-term use might affect the hormones involved in puberty. Melatonin has effects throughout the body, and Dr. Verma points out that it may also interfere with fertility, so he doesn’t recommend it for people who are trying to conceive.


Melatonin can also interfere with how your body processes other drugs, including birth control. As always, it’s wisest to discuss your situation with your doctor.
If you’d like to try melatonin, you can buy it as a dietary supplement in the United States and Canada. It’s considered a prescription drug in many other places, including much of Europe. Because it’s a supplement, our Food and Drug Administration doesn’t keep a close eye on how the pills are produced. Supplements are always a bit of a gamble, so keep that in mind.
Supplements aren't regulated like drugs. Their makers don't have to prove that…
I asked a few people who use melatonin regularly how they would describe the feeling. All agreed that its effect is more gentle than something like Benadryl, the infamously drowsy-making allergy medicine. “More like a warm glass of milk than being knocked out with a blunt object,” was a typical description. All agreed that it didn’t make them sleepy in the morning, either. One complaint I heard a few times was that it gave people extremely vivid dreams. It’s not clear if crazy dreams are a side effect of melatonin, or just something that happens when you catch up on sleep.


So melatonin is a real drug that may help you sleep—depending on exactly why you’re not sleeping. Don’t expect miracles, and do make sure to take it at the right time: ideally five hours before your intended bedtime. Because we don’t know a whole lot about potential risks, most sources I consulted for this article say to use the lowest dose that works (try 0.5 milligrams to start) and if you intend to use it long term, talk to your doctor.
Illustration by Angelica Alzona.

As a breed, labrador retrievers often have serious food-related issues—a behavioral quirk that often leads to over-eating and canine obesity. Researchers have finally figured out why, and the answer could influence the way we treat human obesity.
Many years ago, I had a friend who owned a labrador retriever. This dog was constantly begging for scraps and doing its darndest to sneak a quick meal. Once, I lobbed a morsel of food across the room to my friend, and his dog made an incredible leap for a timely mid-air chomp.


At the time, I ascribed this over-the-top food-seeking behavior to this one dog, but dog experts have long observed that labrador retrievers always seem to be interested in food. In an effort to learn why, veterinary surgeon and geneticist Eleanor Raffan from the University of Cambridge conducted a genetic study of the breed. “Whenever there’s something more common in one breed than another, we think genetics are involved,” she said in a statement. Those results now appear in Cell Metabolism.
For the first part of the study, Raffan and her colleagues analyzed the genetic profiles of 15 obese and 18 lean labrador retrievers. Of the three obesity-related genes analysed, one particular gene—the POMC gene—stood out.


This particular gene appeared to be a bit messed up among the obese labradors, such that they are unable to produce special appetite suppressing neuropeptides. These small protein-like molecules are involved in switching off feelings of hunger after eating a meal. So these dogs are always hungry, even after gobbling down a bowl full of kibble. This mutation was absent from other breeds (except the related flat-coat retreiver).
Raffan’s team also looked at a larger sample of 310 labradors, and they noticed a significant number of canine behaviors associated with the impaired POMC gene. Not all labradors with the DNA variation were fat, but the mutation was definitely associated with higher weight. And dogs with the impaired gene exhibited more food motivated behaviors, such as begging more frequently, paying more attention during meal time, and scavenging for scraps more often. On average, the POMC deletion was associated with a 4.4 pound (2 kg) weight increase.
“We’ve found something in about a quarter of pet labradors that fits with a hardwired biological reason for the food-obsessed behavior reported by owners,” said Raffan. “There are plenty of food-motivated dogs in the cohort who don’t have the mutation, but there’s still quite a striking effect.”
Only about one in four labradors have this mutation (same for the flat coat retriever), so other factors may be involved. However, the mutation was found to occur in about three out of every four assistance dogs. It’s possible that these dogs are more likely to be selected for assistance-dog breeding programs, because their insatiable desire for food makes them more trainable.
There could be potential therapeutic implications for human obesity. The canine POMC gene works similarly in humans, unlike the way it functions in rats and mice. “Further research in these obese Labradors may not only help the well-being of companion animals, but also carry important lessons for human health,” said Stephen O’Rahilly, a senior author on the study.


Raffan said that it’s still possible to own a dog with this mutation and keep them slim. She advises owners to be more rigorous about portion control, and to resist their “big brown eyes” when they plead for food.


[Cell Metabolism]

As if the oceans needed more terrible news, scientists have learned that the coral reefs surrounding the Florida Keys are dissolving. The culprit—ocean acidification—wasn’t expected to start hitting reefs hard for another three decades.
“We don’t have as much time as we previously thought,” oceanographer Chris Langdon of the University of Miami said in a statement. “The reefs are beginning to dissolve away.”


When carbon dioxide dissolves in seawater, it produces acid, causing the pH to drop. Since the beginning of the industrial revolution, the pH of ocean surfaces worldwide has fallen by about 0.1 units, representing a 30 percent increase in acidity. The oceans will continue to become more acidic as long as humans keep pumping carbon into the air.
Acidification is bad news for reefs, shellfish, and pretty much all “calcifiers,” organisms that secrete a calcium carbonate skeleton. Most of these critters live in waters that are “supersaturated” with respect to calcium carbonate, making it easy for them to pull out the building blocks for their shells from those waters. But acidification leads to “undersaturation,” where ocean chemistry no longer favors the formation of limestone minerals. All things made of calcium carbonate start dissolving.


For years, biologists have accumulated evidence of marine calcifiers losing their shells during bouts of undersaturation. But a new study is the first to show that acidification is already leading to widespread reef dissolution, indicating a more permanent and devastating problem.
Writing this week in Global Biogeochemical Cycles, Langon and his co-authors describe the results of a two-year field campaign that surveyed a 124-mile stretch of the Florida Reef Tract north of Biscayne National Park to the Looe Key National Marine Sanctuary. Their conclusion? The reefs, which support a $7.6 billion fishing industry, are wasting away.
“From laboratory studies, we thought that the reefs wouldn’t start to dissolve until the CO2 in our atmosphere rose to 550 or 600 parts per million,” Langdon told Gizmodo. (Our atmospheric CO2 load is presently hovering around 400 ppm.) “It was a real surprise to see that it could be happening sooner.”
The reason, Langdon says, has to do with the fact that the water directly surrounding corals in the Florida Keys is more acidic than the overlying seawater. Corals are often encircled by beds of seagrass, which die off and decompose every winter, releasing additional CO2.
Acidification is not an easy challenge to solve—once the pH of the ocean changes, it takes a long time to revert. And while Langdon’s study is the first to show a reef system on a permanent downward spiral, the problem could already be widespread.


“I wouldn’t be surprised to find that a lot of reefs are closer to net dissolution than we thought,” Mark Eakin, a coral reef expert with the National Oceanic and Atmospheric Administration told Gizmodo. Eakin notes that Florida’s reefs, like many around the world, have also been hit with two of the worst years of back-to-back bleaching, another result of humans messing with the atmosphere.
Earlier this week, we learned that Earth’s coral reefs are in the midst of a massive dieoff,…
Langdon is currently involved with an effort to identify genetic variants of coral that are more resistant to acidification, with the hope that we can breed strains that’ll fare better in the harsher world we’re creating. But he admits that this will at most buy corals a little time.


Over the long run, the very foundation on which the Florida Keys reefs is built—the compressed skeletons of old reefs accumulated over tens of thousands of years—is also getting eaten away. If this foundation disappears, new corals will not be able to permanently settle down.
“Restoration and breeding efforts are only first aid because the actual framework of the reefs is dissolving away,” he said. “It’s buying time, but we need to solve the problem of rising CO2 in the atmosphere.”
For the past several years, doctors have been sounding the alarm about the overuse of antibiotics. For all the concern, however, no one quite knew how much of the antibiotics prescribed in the United States were unnecessary—until now. And the problem goes even deeper than suspected.
A new study published in the Journal of the American Medical Association for the first time gives us numbers for how wide the problem of unnecessary antibiotic use has become. To get the figure, researchers compared the number of prescriptions handed out for antibiotics with the number of prescriptions that national guidelines said should have been handed out. Of the antibiotics prescriptions written, a full 30 percent of them were determined to have been unnecessary.


In most cases, these extra antibiotics were simply an unnecessary step for a condition that got better on its own. They don’t come without a cost, though—and it’s not just money that’s lost. The gratuitous use of antibiotics also means that antibiotic resistance is becoming more and more common. And that’s making it harder and harder for antibiotics to be effective when we really need them, particularly as only one major new antibiotic has been found in the last 30 years.
“The use of antibiotics is the single most important factor leading to antibiotic resistance around the world,” lead author of the report, Dr. Katherine Fleming-Dutra of the Centers for Disease Control (CDC) told Gizmodo. “To combat antibiotic resistance we have to use antibiotics appropriately—only when needed and, if needed, use them correctly.”


Not only does this study represent the first comprehensive look at the exact scope of antibiotic overprescription, but it also fills in another important missing piece of the puzzle. While researchers could previously makes guesses at what kinds of ailments were getting the bulk of unnecessary treatment, now they have hard data. The data shows that antibiotics were overprescribed the most for respiratory conditions which were more than twice as likely to be treated with antibiotics than guidelines suggested.


“Half of antibiotic prescriptions for acute respiratory conditions are unnecessary, such as antibiotic prescriptions for the common cold, acute bronchitis, and viral sore throats,” said Fleming-Dutra. “Even many sinus and ear infections can resolve without antibiotics.”
Knowing the size and scope of the problem is a big step forward, but the question of what comes next still remains. Part of the solution, of course, will lie with doctors and patients. But with a problem of this size, the solution is also going to need to be on a much larger scale—and it’s going to need to be coordinated far beyond the individual doctor and patient.
“It really is going to take the entire healthcare community to tackle and solve the problem,” Dr. David Hyun of the Pew Charitable Trusts and co-author of the report told Gizmodo. “Doctors, patients, professional societies that provide guidance to physicians, health system and plans that provide data and resources to assess antibiotic use, and also federal, state, and local public health agencies. Now that we have these national targets set, we can set benchmarks for how to reduce unnecessary use.”
Earlier this year, scientists confirmed the presence of gravitational waves, a cosmological feature first predicted by Albert Einstein. In recognition of this remarkable achievement, the scientists involved in the study have won the $3 million Special Breakthrough Prize.
The Special Breakthrough Prize was created by Russian billionaire Yuri Milner along with several technology pioneers, including Facebook founder Mark Zuckerberg and Google co-founder Sergey Brin. The award gets handed out in the event of a particularly meaningful scientific breakthrough, and this one—the confirmation of gravitational waves—most certainly applies.


On February 11, researchers at the Laser Interferometer Gravitational-Wave Observatory (LIGO) confirmed the presence of gravitational waves, ripples in the universe caused by highly energetic cosmological events. The source of this particular signal sprouted from a supermassive black hole collision that occurred some 1.3 billion years ago. Einstein predicted gravitational waves back in 1916, but it was LIGO that made an actual discovery possible.
Since Albert Einstein first predicted their existence a century ago, physicists have been on the…
“This discovery has huge significance: firstly, as evidence for general relativity and its predictions of black hole interactions, and secondly as the beginning of a new astronomy that will reveal the universe through a different medium,” said physicist Stephen Hawking, who won the Special Breakthrough Prize in 2013. “The LIGO team richly deserves the Special Breakthrough Prize.”


The three founders of LIGO —Kip Thorne, Rainer Weiss, and Ronald Drever—will each share $1 million. The 1,012 scientists and engineers who contributed to the project will split the remaining $2 million and will each receive roughly $2,000 each. That group includes many of those involved in LIGO and its sister experiment, the Virgo Collaboration.
Hallelujah to that. These days, major scientific breakthroughs are rarely the result of a single individual or small team, so it’s nice to see all the people involved in the project get rewarded. What’s more, it’s good to finally see scientists get the recognition and financial compensation they deserve.
“For us to spend basically a half-century since the three of us started working in this field, to have it actually be pulled off successfully in the manner we dreamed—it was really remarkable and wonderful,” noted Thorne in a Reuters article. “I’m forever grateful to the team that got it done.”
The winners will be honored at the 2017 Breakthrough Prize ceremony to be held later this year.
[Breakthrough Prize, Reuters]

Space agencies in Europe and Russia have sadly announced that their next mission to the surface of Mars with a rover will be delayed by two years, from 2018 t0 2020.
The rover is to be part of a two-pronged ExoMars mission by the European Space Agency and Roscosmos. The first stage has already been successfully launched into space. That mission is actually made up of two robotic probes—the Trace Gas Orbiter (TGO) and the Schiaparelli entry, descent, and landing demonstrator. The second launch, however, is destined to put a full-size rover on the surface of the Red Planet, capable of drilling 6 feet down into the Martian crust.


The BBC reports, however, that both Russian and European engineers have struggled to keep to the project’s schedule. Sadly, missing the 2018 launch date requires waiting for the next instance of favorable planetary alignment, which means waiting for 26 months.
Rolf de Groot, head of ESA’s Robotic Exploration Coordination Office, explained to the BBC:
“What we have been doing lately is seeing if we could shorten the assembly, integration and testing (AIT) phase to something that would be acceptable from a risk point of view, but still make the 2018 launch.
“Very recently, we have concluded that this is not possible without adding a large amount of additional risk to an already risky mission. So, we decided the only responsible thing to do was move to the 2020 launch date.”
The project’s seen many setbacks since its approval in 2005. What started as a modest demonstration mission became a full-blown exploration of Mars, which introduced its own delays. Since, it’s struggled for money, too, with both NASA and Roscosmos helping out at various stages of the project.


Hopefully the 2020 launch will go ahead.
[BBC]
Unsurprisingly, humans and nuclear reactors don’t mix well. So what do you do when you have to maintain the inside of an experimental fusion reactor? Deploy Wall-E’s more competent cousin, of course.
Tom Scott took a look at the maintenance machines that do the repairs inside the UK’s nuclear fusion research reactor. They’re not autonomous robots, but rather remotely controlled arms with a truly scary level of precision, similar to the surgical robots already in use.

The interesting thing here isn’t so much the robot, but rather the control system being used. Virtual reality is known right now as a gaming technology, but it’s not difficult to envision VR headsets making this kind of job much easier, and remotely controlled machines way more popular.


https://www.youtube.com/watch?v=Lsiq_3…
[YouTube]
New research shows that temperatures are set to skyrocket in parts of the Middle East and Africa, making human habitation next to impossible. In a region that’s home to 500 million people, that could trigger a climate-exodus of epic proportions.
These new climate projections, compiled by researchers from the Max Planck Institute, tell an incredibly scary story—like, apocalyptic Mad Max scary. According to Johannes Lelieveld and colleagues, even if Earth’s average temperature were to increase by two degrees Celsius compared to pre-industrial times, the summer temperature in these regions would still increase more than twofold by the midpoint of the century. Combined with prolonged heat waves, decades-long megadroughts, and windblown desert dust, these environmental conditions would be intolerable for humans, forcing many to migrate.
By 2050, summer temperatures in parts of the Middle East and North Africa would stay above 86ºF (30ºC) at night. During the day, temperatures during the hot seasons are predicted to rise to 114ºF (46ºC). By the end of the century, midday temperatures would reach 122ºF (50ºC). By comparison, the average maximum summer temperature in Eastern California’s Death Valley is 115ºF (46ºC).


Heat waves will likely occur ten times more frequently than they do now, and they’ll last much longer. Prior to 2005, there were about 16 excruciatingly hot days per year on average. According to the new models, it will be unusually hot for about 80 days per year—a figure that will jump to 118 days by the end of the century.
And if all this wasn’t bad enough, the researchers also found that desert dust in the atmosphere is increasing over Saudi Arabia, Iraq, and Syria. They’re attributing this to an increase of sand storms as a result of protracted droughts. Climate change will exacerbate this even further.
Needless to say, this will have a dramatic effect on people who live in these areas.


“Climate change will significantly worsen the living conditions in the Middle East and in North Africa,” noted Lelieveld in a statement. “Prolonged heat waves and desert dust storms can render some regions uninhabitable, which will surely contribute to the pressure to migrate.”
For the study, the researchers based their calculations on two scenarios, one in which global emissions of greenhouse gases start decreasing by 2040 (i.e. we succeed at meeting the climate target set at the recent UN Climate Summit in Paris), the other based on the assumption that greenhouse gases will continue to increase unabated (usually referred to as the “business-as-usual scenario.”). In the latter scenario, the mean surface temperature of our planet will increase by more than 4ºC compared to pre-industrial times.


Unfortunately, both scenarios yielded dramatic temperature rises in these desert regions, particularly during the summer months when it’s already very hot. Parched desert surfaces cannot cool by the evaporation of groundwater, and since the balance of surface energy is controlled by heat radiation, this makes the greenhouse gas effect even worse.
[Climatic Change]
Nanomachines could revolutionize technology and modern medicine, if only we had viable power sources to make them move where we wanted them to go. Now scientists at the University of Cambridge have built the world’s tiniest engines, powered by light, as described in a new paper in the Proceedings of the National Academy of Sciences.
Dubbed “ANTs” (for actuating nano transducers), these itsy-bitsy devices could one day realize the vision of the 1966 classic film Fantastic Voyage, in which a miniaturized submarine crew travel through the body of an injured scientist to repair a blood clot in his brain—except there would be no need for shrunken human pilots. Like real ants, these nano engines can produce very large forces relative to their weight, according to lead researcher Jeremy Baumberg.


It works a bit like a spring mechanism. At the heart of the device are lots of charged gold nanoparticles, held together by a polymer gel that responds to changes in temperature. The gel is heated by zapping it with a laser. The polymer gel responds by expelling all its water in a fraction of a second and collapsing, much like coiling a spring. This stores elastic energy as the gold nanoparticles are smushed together into tight clusters.
As the device cools, the gel will re-absorb water to expand just as quickly, releasing that stored energy to push the gold nanoparticles apart with tremendous force.
Lead author Tao Ding likened the effect to an explosion. “We have hundreds of gold balls flying apart in a millionth of a second when water molecules inflate the polymers around them,” he said in a statement.


That explosive effect is due to so-called Van der Waals forces between molecules. These forces are usually not significant in our everyday lives, but very small micro- and nano-scales they are tremendous. Geckos are able to scale walls so easily thanks to billions of tiny hair-like structures on the bottoms of their feet that can sense those forces.
The ANTs convert energy from the molecular attraction between heavy metal particles into elastic energy to create a kind of nano-spring—a true transducer. But to make a bona fide actuator, the researchers need to figure out how to focus the forces—which currently push in every direction—into something more akin to a piston in steam engine.
While the prototype device uses gold nanoparticles, any dense metal could be used, including silver, nickel, or copper. “The gold is nice because it gives us a color, which can be used to infer the separation of the nanopartices,” Baumberg told Gizmodo. “It is like a ruler, on the nanometer scale.”
As for real-world applications, the ANTs could indeed power tiny nanobots someday for things like targeted drug delivery or robotic surgery. In the short term, the Cambridge team is tackling the far simpler goal of making tiny light-controlled pumps and valves for better microfluidic chips—the sort used in diagnostic kits and biosensors. “No electric wires would be needed, so we could put many on a small chip,” said Baumberg.
[Proceedings of the National Academy of Sciences]
New research shows that the mere presence of a first class cabin on an airplane—plus the added experience of having to shuffle through this cabin while boarding—contributes to “air rage,” both among economy and first class passengers.
Air rage typically describes disruptive or violent behavior committed by passengers and airplane crew. Flight attendants often have to bear the brunt of these outbursts, which can involve everything from refusing to sit down and buckle up to outright hostility and belligerence. It can also include “rule breaking” behavior, such as smoking in the bathroom.
By analyzing an international airline’s database of thousands of incident reports, researchers from the University of Toronto’s Rotman School of Management have found that cases of “air rage” among passengers in economy class are more frequent on flights when there’s a first class cabin. And cases of bad behavior are higher in both first class and economy class when economy passengers have to perform the walk-of-shame through the first class section while boarding.


This research, which now appears in the Proceedings of the National Academy of Sciences, shows the degree to which our everyday physical environments—and our prevailing sense of inequality—can sometimes turn us into complete jerks. The findings can be extended to other domains, including cruise ships, trains, sporting events, concerts, and office spaces.
As lead researcher Katherine DeCelles explained to Gizmodo, airplanes are like a miniature version of class-based society. “It’s a small world of the greater society that we live in, though one that’s greatly concentrated,” she said.


Traveling by plane is stressful enough, but DeCelles believes that seating inequality on airplanes often serves as “the straw that breaks the camel’s back,” and that air rage can be partly explained and understood through the lens of social inequality.
By looking at a comprehensive collection of incident reports from a large, international airline, DeCelles, along with her colleague Michael Norton, sought to determine if seating inequality had a noticeable effect on passenger behavior. The researchers looked at data circa 2010, spanning some 1 to 5 million flights over several years.


DeCelles and Norton considered two forms of inequality: the sense of inequality on airplanes caused by the presence of a first class cabin (i.e. “physical” inequality), and the sense of inequality experienced by needing to board the plane from the front and having walk through the first class section (i.e. “situational” inequality). Temporary exposure to both physical and situational inequality contributed to antisocial behavior.
The presence of a first class cabin caused a noticeable spike in air rage incidents among economy class passengers. The chances that an economy class passenger will become unruly or noncompliant is 3.84 times greater when a first class section is present. The researchers say that’s equivalent to a 9-hour flight delay in terms of its psychological effect on passengers. In terms of actual numbers, the presence of a first class cabin will result in about two inflight incidents per every 1,000 flights.
When passengers have to board the plane from the front, the chances of an inflight incident among economy class passengers is 2.18 times greater compared to when they board from the middle, which is equal to a 6-hour flight delay. Surprisingly, when passengers board from the front, the odds of an incident happening among first class passengers jumps nearly 12-fold compared to when boarding happens at the middle of the plane.
The researchers took care to prevent extraneous factors from creeping into their analysis. Their controls included the most commonly invoked explanations for air rage, including leg room, seat width, flight delay amount, cabin space, and other factors such as flight distance, number of seats, and whether or not the flight was international. “Our effects are above and beyond the effects that you’d expect to see from those things,” DeCelles said.


The researchers also observed different types of air rage depending on where the passengers were seated. First class incidents were more likely the result of belligerent behavior, often involving a passenger’s expression of anger (36 percent among first class passengers compared to 27.8 percent among economy class). DeCelles calls this “entitled reactions.” Alcohol is served free in many first class sections, which may partly account for these bad behaviors. In economy class, the incidents tended to be the result of emotional outbursts, such as those stemming from stress, fear, anxiety, and so on.
Anger fuels aggression, but it doesn’t always have to cause a flare-up. When properly managed, it…
Most incidents involved individual travelers—mostly males—lashing out against a flight attendant, not other passengers.


“The sense of inequality really relates to perceptions of unfairness, deprivation, frustration, agitation, and anger, which can in turn give rise to aggression and violence,” DeCelles said. “People are not trying to get into first class—that’s not what we’re seeing—we’re generally seeing people’s emotional reactions, and what could be framed as a frustration reaction. And then being packed into a plane will intensify how you’re emotionally feeling and reacting.”
DeCelles said it’s not feasible to get rid of first class cabins. But there are things that can be done to reduce the salience of class differences, such as eliminating the use of curtains, and removing red carpets from first class cabins. In one extreme case, Decelles recalled a trip when first class passengers were treated to freshly baked chocolate chip cookies, and the enticing aroma wafted back to the economy section. “Those things can be changed,” she said.


[Proceedings of the National Academy of Sciences]

Researchers just uncovered an incredible fact about liquid water on Mars. It’s not just flowing; it’s also boiling. And that discovery also solves one of the major mysteries about the surface of the red planet.
The results of a new experiment published today in Nature Geoscience detail how scientists made the finding and what it means. Researchers built a chamber simulating the conditions and atmosphere of Mars, then put ice in there to melt. The ice did melt and the water from it flowed—but there was also a surprise. The surface of the water boiled as it flowed, and that boiling was strong enough to move not just the water but also dirt and debris surrounding the streams. Importantly, temperature was not the major factor in this boiling water, it was due to the pressure of the atmosphere.


“The atmospheric pressure on Mars is very low compared to that on the Earth, which means that water boils at a much lower temperature than it does on Earth,” co-author of the paper, Susan Conway, told Gizmodo. “On the Martian surface the pressure is five to 10 millibars meaning that liquid water boils no matter what the temperature is.”
But, surely if the surface of Mars had boiling water etching out its plains, we would have seen it in more than just experimental conditions, right? That’s where the most exciting part of the research comes in. It turns out, we’ve already seen it happen. We just didn’t know what we were looking at.


Even before scientists confirmed the existence of flowing water on Mars, they’d long suspected it, particularly due to some images showing landscapes on the planet changing with the seasons. In these images, you can even observe the water as it (very, very slowly) flows from season to season, like in this gif showing Martian slopes transitioning from spring to summer.
The warmer it gets, the further the water flows, even though, technically, the summer temperatures should be too cold. This is because, instead of the water we’re used to seeing in our own streams and rivers here on Earth, the water that flows on Mars is a salty-brine which lowers the freezing point of the water, kind of like antifreeze. Even that explanation, however, still leaves a major unanswered question—and one that, until now, scientists were pretty unsure about how to solve.


We know that water flows on Mars today, and the salty brine explanation gives us a method by which it can happen. But, the changes we’re observing are huge, big enough to observe in pictures snapped from far away from the planet. Meanwhile, the amount of water flowing is fairly small and, from the looks of it, rather slow. So how does water manage to carve out the landscape so quickly and visibly?
The boiling water theory solves this problem. Because the water hits a boiling stage along its surface, it kicks up dust and dirt and debris in the water’s wake. In their experiment, the research team saw the boiling water move debris, but they also saw collapses along the sides of the flows. It’s not just the water flow. The boiling and the disturbance it causes etches those lines on Mars out clearly enough for our satellites to glimpse them.
New discoveries about water on Mars are never just about water, though. The research also gives us hints about the presence of life. However, the news is not great for the existence of life there, says Conway.


“[Our results] show much less water is needed and that the water that is produced is very short-lived—therefore not a fabulous environment for micro-organisms,” she told Gizmodo.
Still, even if it may make life already on Mars less likely, it is something to keep in mind for future life, namely our own colonization plans.
“If a future Mars colony wanted to build canals on Mars,” said Conway, “then they would have to be careful to design them in order to avoid this boiling effect, which could result in erosion of the canal banks.”


That’s pretty far in the future, though. In the meantime, we can now watch the water flowing on Mars with a much better understanding of just how it’s moving around up there.
In a few years, powerful new telescopes will usher in a search for habitable worlds outside our solar system. And TRAPPIST-1—a dim, tepid star just a smidge larger than Jupiter—is one of the first places we’ll look. It’s only forty light years away, and it’s home to several promising, Earth-sized exoplanets.
Three siblings, described today in the journal Nature, are the first exoplanets ever discovered around an “ultracool dwarf” star. And they’re a jackpot when it comes to the search for alien life. Each planet is similar in size to Earth or Venus and probably rocky. The planets all skirt the edge of the so-called habitable zone. Finally, these potential Earth twins are so close to us that we can begin studying their atmospheres right now.


“This is basically a paradigm shift,” study co-author Julien de Wit told Gizmodo. “If these planets have atmospheres, they really are the best places to look for life.”
So far, the search for exoplanets has focused on hot, bright stars, both because they are easy to spot in the sky and because we expect to find planets like Earth around stars like our own. But stars that are very cool and faint compared with the Sun are abundant throughout the galaxy. And when it comes to finding habitable worlds, these dim bulbs have one big advantage: their light doesn’t swamp out the signal of small, rocky planets.


“It is easier to study the atmospheres of exoplanets orbiting dim stars,” de Wit said, explaining that as a star gets smaller, a larger fraction of its light can pass through a planet’s atmosphere. What’s more, dim stars tend to be bright in the infrared, which is the best part of the spectrum for picking out key atmospheric features like water vapor and oxygen.
With this in mind, a team of astronomers led by the University of Liège’s Michaël Gillon put together a prototype telescope several years back to hunt for exoplanets around ultracool dwarfs, a group of dim objects teetering on the edge of starhood. Called TRAPPIST, the 0.6-meter scope sits at the La Silla Observatory in Chile, studying 60 nearby stars that can’t be seen with the naked eye. Like the Kepler Space Telescope, TRAPPIST searches for dips in infrared light—called transit events—that occur when a planet passes between its star and the Earth.


Now, after surveying just 15 of its 60 targets, the telescope has yielded a major discovery: three Earth-sized exoplanets orbiting a Jupiter-sized star 40 light years away in the constellation Aquarius. Dubbed “TRAPPIST-1,” the star is only 8 percent the mass of the Sun and 0.05 percent as luminous.
Two of the system’s planets, TRAPPIST-1b and TRAPPIST-1c, are in very tight orbits, making a complete rotation around TRAPPIST-1 in less than three days. Although they’re orbiting at a distance much closer than Mercury, these planets only receive a little more sunlight than Venus. TRAPPIST-1d is in a wider orbit, receiving less sunlight than the Earth and perhaps even less than Mars.


We don’t yet know the masses of the planets, which makes it impossible to determine their composition. But based on their sizes and close orbits, de Wit says, we can be pretty sure they’re made of rock and ice.
TRAPPIST-1b and 1c are past the inner edge of the habitable zone where liquid water oceans can develop. TRAPPIST-1d, meanwhile, is teetering on the habitable zone’s outer rim. Nevertheless, portions of all three planets might be able to support life, thanks to a strange quirk of their orbit.
Unlike the Earth, which spins about its axis as it circles the Sun, planets in very close orbits become tidally locked—stuck in a particular orientation, with a permanent day side and a permanent night side. This is thought to be the case for the planets orbiting TRAPPIST-1. While the daysides of TRAPPIST-1b and 1c are too hot to support life as we know it, a twilight band between day and night may offer balmy temperatures and Earth-like weather.


TRAPPIST-1d’s exact orbit isn’t well constrained. If this planet receives as much solar energy as the Earth, the entire surface could be habitable. If it’s colder than Mars, the world may be covered in a thick sheet of ice. Even in the latter case, it’s possible TRAPPIST-1d has liquid water oceans and squirming life forms just beneath the surface.
“Life could still exist on a frozen planet, it would just be extremely hard to pick up remotely,” said Lisa Kaltenegger, an exoplanet research at Cornell University who was not involved with the study. “That’s the reason we have to fly to icy moons like Europa to see if there is life elsewhere in our solar system.”
Traveling to the TRAPPIST-1 system is out of the question—but we may be able to pick up signatures of life from afar, by scouring the atmospheres of these planets for chemicals like carbon dioxide, water vapor, and oxygen. When starlight passes through a planet’s atmosphere, different fractions are absorbed based on the molecules present, resulting in a distinct spectra. This spectra can reveal the planet’s atmospheric chemistry, including any signatures of life.
Twenty years ago, discovering another Earth sounded like a science fictional dream. But within a…
Peering into the skies of exoplanets to hunt for biosignatures is beyond state of the art—but not by much. The first telescope able to do so for nearby stars will be the James Webb, a 6.5-meter wide exoplanet hunting beast that blasts into orbit in 2018. Meanwhile, de Wit and his colleagues are getting a better look at the TRAPPIST-1 planets right now using the Hubble Space Telescope, which can determine if they have any atmospheres at all.


Even if none of the TRAPPIST-1 planets is habitable, the discovery of three Earth-sized worlds around an exotic star will help us round out our understanding of exoplanet diversity.
“It is exciting to fill in the gaps and learn what rocky planets would be like if they get more sunlight than Venus, or less than Mars,” Kaltenegger said.
Whatever we wind up finding around TRAPPIST-1, it’s clear we live in an incredibly exciting time when it comes to studying planets beyond our solar system—and that the biggest discoveries are still ahead of us.

It’s been eight months since New Horizons made its historic flyby of Pluto, but data keeps on trickling in from the intrepid space probe. Scientists have now produced a new composite map, creating the sharpest and most detailed look at the dwarf planet yet.
The updated black-and-white global map of Pluto includes all resolved images of the surface acquired by New Horizons between July 7 to 14, 2015. Some of the images spliced into the map were received as recently as April 25 (it’ll take over a year for New Horizons to transmit all the data it collected during the flyby due to bandwidth limitations).
The new map is our sharpest view yet of Pluto, with pixel resolutions ranging from 18 miles (30 km) on the Charon-facing side (left and right edges of the map) to 770 feet (235 meters) on the side facing New Horizons when it made its closest approach on July 14. The blurry non-encounter side is shown in less detail owing to the greater distances at which the images were captured. NASA is continuing to add photos as it receives them, and it’s also working on improved color maps.
NASA also released this shaded relief view (below) of the region surrounding the left side of Pluto’s distinctive heart-shaped feature, informally dubbed Sputnik Planum.
The image shows a vast expanse of Pluto’s icy surface, which is on average about 2 miles (3 km) lower than the surrounding terrain. Chunks of water ice with angled and sharp corners can be seen “floating” amid the bright deposits of softer, denser solid nitrogen.


[NASA]

Convinced that when your cat meows, it’s truly trying to tell you something? Now there’s a 3D printed talking cat collar to pick up on Fluffy’s varied vocalizations and “translate” them via an app on your smart phone. Yes, just like the one worn by Dug the talking dog in Pixar’s Up (“Squirrel!”).
It’s called the Catterbox, and it’s the creation of the feline-friendly folks at Temptations Lab (a division of Temptations Cat Treats). The aim: to “inject some serious fun into cats’ lives.”
We believe that if people understood cats better they’d see just how awesome they really are. Studies have shown that adult cats meow when talking to humans, not to each other. We’ve analysed these cat sounds and created a program that detects a cat’s meow and matches it to a human voice. We then put this technology inside a sleek 3D printed collar which connects seamlessly to our app where you can choose your cat’s new voice.
You can find out more in the video below, and watch clips of “talking cats” at the Temptations Lab website—just in case you don’t have anything better to do this weekend.

[Laughing Squid]
If the current frontrunners in this year’s presidential race just don’t appeal to you, perhaps you’d like to really think outside the box. Seattle lawyer Andrew Basiago is also running for president, as an independent. And he cites his extensive experience traveling through time as one of his strongest qualifications for office.
That’s right: a candidate for the highest office in the land is a self-professed time traveler—excuse me, “chrononaut”—who used his access to this secret technology to advise past presidents. He also claims to have teleported to Mars in the 1980s along with a young Barack Obama (who naturally is part of a government cover-up to keep the American public from learning the truth).


And Basiago swears he’s going to win: “I have prior knowledge that not only will I run for president, but that during one of the elections—which would have to be between 2016 and 2028, because I’m not running past that—I’m either elected president or vice president.”
Basiago announced his candidacy last December during an appearance on the syndicated radio show Coast to Coast, to very little media fanfare. But he first came forward in 2004, with the news that he had been the first American child to teleport back in 1967. He’s been lurking on the fringes, lobbying for the declassification of so-called “Tesla teleportation,” ever since.


He also believes in aliens and Bigfoot. Per the Huffington Post, if elected, Basiago will “disclose how extraterrestrials are visiting Earth and discuss the ramifications of the advent of ET-human contact within the first 100 days.”
It’s a plot worthy of a classic scifi B movie. His father, Raymond Basiago, was an engineer with the Ralph M. Parsons company, allegedly involved with “Project Pegasus,” a CIA intelligence program that used children to test various time travel and teleportation technologies. Basiago claims to have made his first “jump” at the age of six, teleporting from New Jersey to New Mexico.
Among the highlights of Basiago’s time traveling exploits: hearing Abraham Lincoln’s Gettysburg address first-hand when he traveled back to 1863 at the tender age of 10.
And just what were these top-secret technologies with “quantum access capability” that made such feats possible? Basiago claims there are two versions: one that lets you physically travel through time (courtesy of Nikola Tesla’s secret papers), and another—dubbed “Chronovision”—that works more like a hologram or magic mirror, enabling you to connect with a time or place (past or future) without being physically present.


Writing at Inverse, Neel V. Patel cast about desperately to find a positive spin to all this crackpottery, and decided it makes Basiago the most tech-friendly candidate this election cycle. “The only real suspicious thing about Basiago’s campaign is that it’s starting as he wraps up work on a book he hopes will be a best seller,” he concluded.
Really, dude? That’s the only suspicious thing? Not the fact that any self-respecting physicist will tell you that there’s no such thing as “quantum access capability” and that time travel to the past is pretty much impossible? Never mind the fact that NASA/JPL actually has a rover on Mars right now, and there’s been no sign of advanced alien life forms on the red planet. And honestly, someone who has traveled to the year 2054 should probably know for sure what year he will be elected, and to which office.


If you really feel like delving into the crackpottery, the folks at Exopolitics ran a two-part “investigative” piece in December asking the burning question: “Is Basiago a heroic whistleblower disclosing the existence of extraterrestrial life and secret space programs, or part of a CIA sanctioned psychological operation to manipulate the disclosure process?” Just bear in mind that this is also the site breathlessly warning us last week that “Reptilian Aliens Helped Nazi Germany Build Secret Space Program in Antarctica.”

[Oddity Central]
For six years, an underground garbage fire has been steadily burning outside of Saint Louis, Missouri, right next to a landfill filled with nuclear waste buried in the mid-70s. So why hasn’t anyone managed to extinguish it yet?
The AP reports that the EPA handed down a series of measures designed to stem the fire, including temperature monitors, cooling loops, and a giant smothering tarp. Those new measures aren’t being instituted because the fire has spread closer to the nearby waste site, officials said. Rather, the measures are merely to make sure it doesn’t.


But what’s going on with this fire, and why isn’t it just being put out? The problem is that no one seems to have a plan for how to extinguish it. In fact, nobody even knows what’s causing the fire.
The state of Missouri sued the burning landfill owners, Republic Services, three years ago, but the case is stuck in court. Even the EPA’s newest measures still wouldn’t actually put out the fire. They would merely keep it from spreading. What happens if the fire does spread, despite the efforts?


The answer is unclear. Last year, EPA officials told residents that even if the fire did spread to the waste, it was unlikely to be dangerous. However, agency scientists also issued a report admitting that they didn’t really know exactly what else was buried along with the nuclear waste all those decades ago.


Since no one seems to have had any luck in figuring out how to put out the fire yet, the idea of just digging up and moving the waste has also been floated. The EPA’s decision about whether it will actually do that, however, isn’t set to come down for another year. So for now, the fire continues to burn.
Rosalind Franklin, the British scientist whose research enabled the discovery of DNA’s double helix, will be getting a biopic if spec script Exposure is made. Fingers crossed, because not only would a feature film bring Franklin some much-deserved recognition—her life would make for quite a dramatic movie.
It's commonly believed that James Watson and Francis Crick discovered the double helix shape…
Throughout her career—which ended tragically early, when she died of ovarian cancer in 1958 at age 37—she faced sexism at nearly every turn. The fact that she was a woman didn’t just affect the way her work was received—it also meant, for example, that she couldn’t access certain “men’s only” spaces where she worked at King’s College in London. She also happened to be Jewish, which heightened prejudice against her.
Franklin has previously been the subject of a NOVA documentary on PBS, as well as a play, Photograph 51, which was performed in London last year with Nicole Kidman in the lead role.


We’ve seen a lot of movies about groundbreaking, rule-breaking, boundary-busting male scientists, with The Imitation Game and The Theory of Everything being two high-profile recent examples. And we do see women as fictional scientists quite a lot, particularly when space travel is involved (think Gravity, The Martian, etc.) But movies about real-life female scientists are less common. Now that we’ll be getting Hidden Figures, about the African American women who were instrumental in building NASA’s space program, and maybe Exposure, too—it seems a welcome new trend may be emerging.
A first-of-its-kind space rock filled with pristine material from the formation of the Earth itself has returned to the inner solar system, after billions of years in the cosmic boondocks. And it could help us piece together our planet’s origin story.
Four and a half billion years ago, chunks of the same material that formed Earth and the other rocky planets are thought to have been flung into the Oort cloud, a ring of icy debris encircling the outermost edge of the solar system. Untouched, they’ve been preserved for eons in the deep freeze of space. Now, astronomers have spotted one of these fossils nearby, marking the very first observation of a rocky object from the Oort cloud.


“This is super exciting, because it could be a piece of what formed the Earth” Olivier Hainaut—an astronomer at the European Southern Observatory and co-author on the new Science Advances study describing the discovery—told Gizmodo.
The object, dubbed PANSTARRS, was spotted in 2014 by Pan-STARRS1, a Hawaiian telescope used to identify rogue comets and asteroids in our planet’s backyard. The telescope routinely surveys the entire sky and turns up thousands of uninteresting hunks of debris. But as soon as PANSTARRS’ orbit had been calculated, Hainaut and his colleagues realized they had found something exceptional.


The shape of the orbit was indicative of a long period comet—an icy body that fell into the inner solar system from the Oort cloud. But as comets from the Oort cloud hurl toward the Sun, they release a long tail of sublimating ice and dust. This one didn’t.
Curious, the astronomers decided to take a closer look using the European Southern Observatory’s Very Large Telescope in Chile. And things got even stranger. By studying the faint light reflected off PANSTARRS, Hainaut and his colleagues learned that it is not filled with ice at all, but with rocky material. In terms of composition, it’s a classic S-type asteroid, similar to those found main asteroid belt between Mars and Jupiter.
“If you’d shown me the spectrum, I would have just said this is another stupid asteroid,” Hainaut said. “If you showed me the orbit, I’d say yea, it’s a standard long-period comet. But you don’t at all expect to find a rocky asteroid on an Oort cloud orbit. That’s wrong.”
One possible explanation is that an asteroid was flung into the Oort cloud somewhat recently, before falling back toward the inner solar system. But it soon became apparent that this wasn’t the case. “When we observed it very carefully, its spectrum showed that the rocks hadn’t been baked by the Sun,” Hainaut explained. “They’re primordial.”


Eventually, the astronomers concluded that PANSTARRS was formed in the inner solar system long ago, before being ejected into the Oort cloud as the rocky planets themselves were coalescing. That makes it a potential building block of Earth, Venus, Mercury, or Mars.


“This one is the first uncooked asteroid we have found: it has been preserved in the best freezer there is,” lead study author Karen Meech of the University of Hawaii said in a statement.
Now that PANSTARRS has caught our attention, astronomers are hoping to find more objects like it. There are several competing theories about how the solar system formed, and they predict different ratios of icy to rocky objects in the Oort cloud. “Depending on how the planets migrated, the number of rocky planetesimals in the Oort cloud will change dramatically,” Hainaut said. “Just by counting these objects up and doing statistics, we can say which theories are completely wrong and which ones survive.”
PANSTARRS has already made its closest approach to the Sun, and it’s now on its way back to the outer solar system. But if we get lucky, one of its cousins may whiz even closer to Earth, allowing astronomers to get a detailed look at its composition. This could lend insight into the exact conditions under which our planet was formed. Our history is flying around out there, and if we’re patient enough, we’ll find it.
A single shale oil field in the United States is responsible for a significant upsurge in global atmospheric levels of ethane, a dangerous gas that has been linked to climate change and pollution. It’s yet more evidence that fracking is screwing up our planet.
Researchers from the University of Michigan have determined that the Bakken Formation—an oil and gas field in North Dakota and Montana—is spewing about two percent of the planet’s ethane into the atmosphere. That translates to about 250,000 tons each year. This explains why ethane levels suddenly began to increase after years of steady decline. The scientists described their findings in a new paper in Geophysical Research Letters,
“Two percent might not sound like a lot, but the emissions we observed in this single region are 10 to 100 times larger than reported in inventories,” lead author Eric Kort said in a statement. “They directly impact air quality across North America. And they’re sufficient to explain much of the global shift in ethane concentrations.”


Ethane is a greenhouse gas, and the third-largest contributor to human-caused global warming after carbon dioxide and methane. The gas reacts with sunlight and other molecules in the atmosphere to form ozone. It can cause respiratory problems, eye irritation, and other ailments, while also damaging crops. When levels get too high, safety advisories warn people to stay indoors.
This latest upsurge in ethane is troubling because global atmospheric levels of this gas had been decreasing from 1984 to 2009. Ethane escapes into the atmosphere via leaks caused by fossil fuel extraction and processing. The noticeable downswing in ethane emissions was attributed to less venting and flaring of gas from oil fields, among other factors. But in 2010, European scientists noticed a significant uptick, which they blamed on the burgeoning practice of hydraulic fracturing, or “fracking,” in the United States. Fracking is the process of drilling and injecting fluid into the ground at high pressure to fracture shale rocks, which releases the gas and oil inside.

To determine if fracking was the reason behind the upswing, the Michigan researchers flew over the Bakken Formation and sampled the air in May 2014. This particular oil field was a good place to start: from 2005 to 2014, oil production at Bakken jumped by a factor of 3,500, and gas production by 180 (though production has plateaued in recent years). Their measurements showed that the field’s ethane emissions—about 0.23 teragrams per year—cancel out about half of the global decline rate.


“These findings not only solve an atmospheric mystery—where that extra ethane was coming from—they also help us understand how regional activities sometimes have global impacts,” said NOAA environmental scientist and study co-author Colm Sweeney. “We did not expect a single oil field to affect global levels of this gas.”


This revelation is sure to inflame an already heated debate about the practice of fracking, which has already been linked to ground and surface water contamination, air and noise pollution, and even earthquakes.
[Geophysical Research Levels (pdf)]

You know how much money you spend on food, but just where does that money go once you spend it? The answer, right down to the fraction of the cent, is here.
The USDA has released an update to its “food dollar” breakdown—a division of a single dollar into the exact amount every link in the long chain of people who bring you your food gets. So what’s new in the latest dollar compared to last year’s update? There’s a series of changes, all of which indicate a trend towards the same point: America is cooking for itself less and less.
The evidence for America’s declining cooking habits lies in which segments increased and decreased their share of the food dollar. The biggest increase was in the food service piece. Meanwhile, actual farming production costs remained precisely stable. The categories that dropped off to make room for the increase in food service costs weren’t on the farm—the biggest drops came in packaging, transportation, and wholesale trades, which are all costs that would be associated mostly with shopping at grocery stores.


Looking at other data backs up this idea. 2014 was also the year Americans crossed the threshold into spending more money eating out than eating at home. The trend seems to show no signs of slowing.
There are plenty of methods for coping with email overload, and you probably have one or two tricks of your own to try and reach inbox zero. But what about tips backed up by proper scientific research? These nuggets of advice are all based on recent studies of our email habits.
Of course, there’s no one-size-fits-all solution to email, and some of these studies have pretty small sample sizes. That said, if you’re after some inbox strategies that have emerged from genuine research, both for sending and receiving email, try taking the following suggestions on board.
If you’re checking your email first thing in the morning, last thing at night, and all through the day, then you might want to think about changing your habits. A 2015 survey of 2,000 UK workers found heightened feelings of pressure and stress linked to both having an email app open all day and having push notifications for emails switched on.


“Our research shows that email is a double-edged sword,” said Richard MacKinnon, one of the researchers on the team. “Whilst it can be a valuable communication tool, it’s clear that it’s a source of stress and frustration for many of us. The people who reported it being most useful to them also reported the highest levels of email pressure.”
While there are ways to cut down on incoming email, you’re not always responsible for how many emails arrive in your inbox. If you want to maintain peace of mind, then part of the secret is knowing your limitations and not feeling like a failure because you can’t reach inbox zero, according to a 2010 study of 26 information workers.


“The evidence shows that most people think it is just their own individual failing that they can’t keep up both with the technology and the amount of communication they are having to deal with,” said Dr Melissa Gregg, who was in charge of the email research—and that attitude tends to lead to stronger feelings of stress and anxiety.
Research carried out in 2010 discovered that spelling and grammatical errors inside emails could hurt your reputation. The recipients of emails filled with mistakes and typos tend to think of the sender as less conscientious, less intelligent, and not as trustworthy compared with those who’ve properly proofread their messages before sending.
However, it’s not such a serious matter when you’re dealing with friends and family. We tend to judge spelling mistakes and grammar errors more harshly when the messages are from people we don’t already know—probably because we don’t have any other reference points to judge the character of the person at the other end of the line.
If you don’t want wordy, lengthy emails filling up your inbox, keep your own missives short. Data collected in 2015 from some 16 billion anonymized emails found that short emails begat shorter replies, so keeping conversations brief to begin with is a handy way of trying to minimize the amount of text you have to wade through.


There were plenty of other useful stats from the research. Older people respond to increasing levels of email by replying to fewer messages, for example, whereas younger people tend to send the same number of replies but keep them shorter. Plus, the best time to email someone if you want a response is during a weekday morning.
There have been several studies looking at how we’re not really multitasking when we think we’re multitasking—we’re actually doing several things less efficiently than we would be if we tackled them one by one. This principle also applies to email and how often you’re tempted to check in for new messages arriving in your inbox.


A study carried out back in 2002, which monitored the habits of 16 employees over 28 days, found that the average ‘recovery time’ from an email interruption was 64 seconds. That means it’s taking you more than a minute to properly get back to whatever it was you were doing before you decided to flick over to your email client.
Research published in 2015, based on a study of 124 adults, backs up the previous point. Setting specific email breaks rather than constantly dipping in and out of your inbox reduces daily stress and improves general well-being. In the experiment in question, participants limited themselves to three email checks per day.


“We found that during the limited email use week, participants experienced significantly lower daily stress than during the unlimited email use week,” wrote the researchers, from the University of British Columbia in Canada. “These findings highlight the benefits of checking email less frequently for reducing psychological stress.”
[Header image: Melpomene/Shutterstock.com]

Producing drugs is usually a time-consuming process that requires several large factories each handling a different step in the process. But for smaller on-demand batches, MIT has developed a portable pharmacy that’s only about the size of a commercial-grade fridge and promises much faster turnarounds.
The new device isn’t designed to be a replacement for mega factories that can produce large amounts of a drug at a very low price point. Instead, MIT envisions it being used for emergency situations where a very specific medication is quickly needed to help contain an outbreak of a rare disease, or when power outages threaten the supply and production of a specific drug.


Ironically, the compact size of the fridge-sized factory enables it to turn out drugs at a faster pace. It’s actually easier to generate and precisely control the the high-pressures or extreme temperatures needed to synthesize some drugs when the batches are smaller. But the DARPA-funded “pharmacy on demand” is still able to produce 1,000 doses of one of four different drugs—Benadryl, lidocaine, Valium, and Prozac—in just 24 hours.
The machine still needs access to the proper ingredients in order to produce a given drug, and it takes about an hour to reconfigure the first step of the process to accommodate the different medications it can create. But it can be packed up into a shipping crate and sent anywhere in the world to provide instant medical support during a crisis.


[MIT via Gizmag]
Over the weekend, SpaceX delivered the International Space Station’s first inflatable module—but there’s more where that came from. United Launch Alliance and Bigelow have announced that they plan to put entire inflatable space stations into orbit by as soon as 2020.
The pair announced last night that they hope to launch a 12,000-cubic foot inflatable space station—called B330—aboard the ULA’s Atlas 5 rocket within the next four years. That’s about 30 percent of the size of the ISS. It will, they claim, “support zero-gravity research including scientific missions and manufacturing processes,” but also add that it could have “potential as a destination for space tourism and a craft for missions destined for the Moon and Mars.”


Bigelow has already made prototypes of these kinds of inflatable space structures, and in fact made the one that arrived at the ISS over the weekend, which is known as BEAM. They’re constructed of strong, kevlar-like materials—hopefully strong enough to withstand space junk—and are inflated upon arrival. The benefit is obvious: The structures are much smaller and lighter than the usual space station modules that get fired into space.
It’s not yet clear who might use the B330 when it’s in space. “We are exploring options for the location of the initial B330 including discussions with NASA on the possibility of attaching it to the International Space Station (ISS),” explained Robert Bigelow, founder of Bigelow Aerospace, in a press release. “The working name for this module is XBASE or Expandable Bigelow Advanced Station Enhancement.”


We’ll have to wait and see if NASA wants to play ball.


[PR News Wire and Reuters via Engadget]
Researchers working off the coast of Panama have captured unprecedented footage showing thousands of red crabs swarming together in the oxygen-deprived waters just above the seafloor.
Led by Jesús Pineda of the Woods Hole Oceanographic Institution (WHOI), the team captured the video a year ago during a month-long expedition to the Hannibal Bank Seamount off the coast of Panama. The disquieting video shows a huge number of red crabs shuffling and bobbing along the seafloor in a scene right out of some kind of twisted science fiction movie.

Here’s how Pineda described it in a press statement:
When we dove down in the submarine, we noticed the water became murkier as we got closer to the bottom. There was this turbid layer, and you couldn’t see a thing beyond it. We just saw this cloud but had no idea what was causing it. As we slowly moved down to the bottom of the seafloor, all of the sudden we saw these things. At first, we thought they were biogenic rocks or structures. Once we saw them moving—swarming like insects—we couldn’t believe it.
The crabs were observed along the northwest flank of the seamount at depths of 1,164 to 1,263 feet (355 to 385 meters), and in an area of hypoxic (i.e. low oxygen) water. Seamounts are exactly that—mountains in the sea—and they serve as ecological “hot spots” to thriving communities of unique species. To date, scientists have only documented less than one percent of the ocean’s seamounts. And as this video shows, there’s still lots to learn about what’s going on in this ecological systems.
The observation is unique on two counts. First, this species has never been seen wandering this far south before. They typically hang out off the beaches of Baja, California, and along the California Current. So this region now represents a new southern territorial bound for the species. Second, this bizarre swarming behavior has never been documented before in red crabs.
Scientists have observed them in hypoxic waters before, prompting the researchers to wonder if low oxygen waters provide a refuge for this species from predators. These creatures are a staple food source for other fish, birds, and other marine animals.


[PeerJ]
Charles Darwin famously imagined evolution as a tree full of branches, a metaphor that biologists have since used to depict how life is structured. Now, researchers have given the tree of life another overhaul.
A team of scientists from the University of California, Berkeley, have been collecting the genomes of new microbial species over the last few years, and wanted to know how they fit on the existing tree of life. The old tree contained three mains “trunks”: eukaryotes (which includes animals, plants, fungi, protozoans, and us), bacteria, and collections of microbes that live in extreme environments.


The team from University of California, Berkeley took the genome data from 2,072 existing species along with 1,011 of their new species to work out where the newly discovered species fit in. They used a supercomputer to imagine different configurations of the tree and work out which made most sense, reports the New York Times.
Their findings reinforce findings made in earlier trees, which showed the whole of the eukaryote section—that’s the one in which we can find our own species—as a single, spindly branch. But the new tree shows that the branches made up of bacteria overshadow the eukaryotes more than ever, meaning there’s even more diversity in bacterial life than previously thought.


Many of the new species with such amazing diversity were found in rather mundane places, such as Californian meadows, while many are also incredibly simple creatures. But while that suggests we may yet see the tree grow further, scientists speaking to the Times seem to disagree about whether or not the tree of life is reaching its limits.
[Nature Microbiology via NYT]
Twenty six hundred years ago, a band of Judahite soldiers kept watch on their kingdom’s southern border in the final days before Jerusalem was sacked by Nebuchadnezzar. They left behind numerous inscriptions—and now, a groundbreaking digital analysis has revealed how many writers penned them. The research and innovative technology behind it stand to teach us about the origins of the Bible itself.
“It’s well understood that the Bible was not composed in real time but was probably written and edited later,” Arie Shaus, a mathematician at Tel Aviv University told Gizmodo. “The question is, when exactly?”


Shaus is one of several mathematicians and archaeologists trying to broach that question in a radical manner: by using machine learning tools to determine how many people were literate in ancient times. Their first major analysis, which appears today in the Proceedings of the National Academies of Sciences, suggests that the ability to read and write was widespread throughout the Kingdom of Judah, setting the stage for the compilation of Biblical texts.
Although parts of this conclusion remain controversial, the technology behind the study could revolutionize our understanding of literacy and education in Biblical times.


Most scholars agree that the earliest Biblical texts—including the Book of Joshua, Judges, and the two Books of Kings—took shape during what’s known as the late First Temple Period, before Jerusalem fell to the Babylonian king in 586 BCE. But the circumstances surrounding the writing of these texts, including when they were first penned and by how many authors, remain unclear. Curiously enough, texts that have nothing to do with the Bible may shed light on the matter.
For instance, during this time period people wrote a wide variety of information down on ceramic pottery shards called ostraca. “These texts are very mundane in nature,” Shaus said, citing military commands and supply orders as some of the more popular topics of discussion.


Aside from how much wine Judahite soldiers required, however, there’s another layer of information we can extract from ostraca: how many people knew how to write. That’s exactly what Shaus and his colleagues did, analyzing a group of 16 well-preserved ceramic shards from a remote military fortress located near the southern border of Judah. Most of these ostraca date to around 600 BCE, practically the eve of the kingdom’s fall.
The first step of this analysis involved the researchers using novel image processing tools to restore characters that had been partially rubbed away. They then developed machine learning algorithms that could compare and contrast the shape of the ancient Hebrew characters in order to identify statistically distinct handwritings. In principle, this is similar to the algorithms tech companies use for digital signature detection.


“Handwriting analysis is a big area that’s seen a lot of research in recent years,” Shaus said. “Nevertheless, we had to develop our own tools and this was quite challenging. The medium is very deteriorated and so is the writing.”
Eventually, the team devised a handwriting recognition tool that worked beautifully on modern Hebrew, and they decided to put it to the test on ancient inscriptions. All in all, their analysis revealed at least six different authors behind the 16 ostraca. Examining the contents of the text itself, the researchers concluded that these authors spanned the entire military chain of command. “The commander down to the lowest water master could all communicate in writing,” Shaus said. “This was an extremely surprising result.”
It’s a result that the researchers say points to a “proliferation of literacy” throughout Judahite society by 600 BCE, implying that the educational infrastructure to support Bible writing almost certainly existed.
But not everyone is comfortable with all aspects of this conclusion.


“This is a highly innovative and important study,” Christopher Rollston, an expert on archaeology and Bible studies at George Washington University told Gizmodo, noting that there’s ample archaeological evidence portions of the Bible were written as early as 800 BCE. But who was really able to write at that time?


“I think that literacy was confined to elites, basically scribes, high military officials, and priests,” Rollston said, adding that by the late First Temple Period, it’s possible reading and writing had spread to more of this upper class.
Perhaps the most important aspect of Shaus’ work is the introduction of sophisticated image recognition technology to the study of ancient texts. The Tel Aviv research group is keen to share their tools for reconstructing letters and deciphering handwriting with other archaeologists. By applying these methods more broadly, we might be able to hone in on when, where, and by whom history’s most enduring book was first written down.


“We’re bringing new evidence to the game,” Shaus said. “Now, we’ll see what else comes out.”
The signs of human impact in the tropics are often stark. Vast tracts of forest leveled for pasture. Fires in the Amazon that are visible from space. A colossal oil spill that’s been festering for decades. But even the rainforests we set aside for preservation are slowly transforming.
This is something conservation biologists have instinctively known for years. But a paper published in the Proceedings of the National Academies of Sciences today offers the strongest evidence yet. After forty years of study, a team of ecologists has concluded that Los Tuxtlas, a famous reserve located in the northernmost tropical forest in the Americas, is experiencing severe ecological deterioration. It’s not that we’re harming the forest per se—it’s what we’re doing in the land around it. And unless we take action, these bastions of diversity could become as biologically impoverished as the land we’ve impacted directly.


“Our tropical protected areas are rapidly becoming islands, surrounding by a hostile sea of human-dominated landscapes,” Bill Laurance, the director of the Centre for Tropical Environmental and Sustainability Science at James Cook University, told Gizmodo.
The study, led by José Sarukhán of the University of Mexico, seems to crystallize Laurance’s conclusion. The Los Tuxtlas reserve, about 700 hectares of forest located near the Gulf Coast in the Mexican state of Veracruz, started becoming an island decades ago as the surrounding forest was divvied up for agriculture. As more people moved into the region, hunting pressure increased, leading to a loss of key herbivores including tapirs, peccaries, and deer. “This led to a big upset of the whole system, which resulted in an explosion of palm,” Sarukhán explained.
Sarukhán’s data shows that a combination of deforestation around the reserve and hunting has turned the understory palm species Astrocaryum mexicanum into a rather aggressive weed. The palm’s numbers have increased some 350 percent over the past forty years, edging out other tree species, depressing biodiversity, and leading to a cascade of ecological changes. “The forest is still there, but it’s moving toward a kind of zombie state,” Sarukhán said.


“This study is not the first to make these arguments,” said Laurance, who has overseen similar research in other tropical forests. “But it’s the first I’ve seen that has actually done this sort of experiment over a long time scale and shown this 1-2 punch of a fragmentation effect and a hunting effect.”
Every tropical rainforest on Earth faces different existential threats. Some, including the eastern Amazon, are getting hit with the combined effects of deforestation and fire. Others, such as the Queensland rainforests of northeast Australia, are expected to see widespread extinction due to climate change. Regardless of the specific danger, it’s clear that simply setting a bit of land aside here and there isn’t going to be enough to safeguard tropical biodiversity.
“We need to try to limit human impacts around the fragments, and keep the protected areas as large and interconnected as we possibly can,” Laurance said. “In the future, species will need to migrate. If they’re surrounded by a hostile sea, they’re not going to be able to.”
Sarukhán adds that conservation strategies need to start focusing on teaching locals to become land stewards. Some 70 percent of forested lands in Mexico are communally owned. If locals were trained to use the forests more wisely—hunting only in designated zones, actively managing timber resources—it would go a long way toward ensuring their survival.


“Preserving a forest means a very active plan and monitoring,” Sarukhán said. “There are few places in the world that are really void of people. We need to start working with them.”

For the first time ever, researchers have peered into the brains of people tripping out on LSD. The groundbreaking scans reveal the dramatic extent to which the psychedelic drug affects normal brain function, while pointing towards therapies for similar psychological disorders.
In a new paper published in Proceedings of the National Academy of Sciences, a research team led by Robin Carhart-Harris from Imperial College London, as part of the Beckley Foundation/Imperial Research Programme, has demonstrated the sweeping ways in which LSD affects normal brain function—accentuating the power of certain brain regions, while diminishing the function of others. In addition to assisting with consciousness studies, these fresh insights are poised to increase interest in the use of psychedelic drugs for therapeutic purposes and for disease modeling. It could also further inspire other researchers to study LSD and its effects on the human brain.
Lysergic acid diethylamide, more commonly known as LSD or acid, was first synthesized by Swiss scientist Albert Hofmann in 1938. Since that time, very little scientific work has been done to study this psychedelic drug and its effect on the brain. Research stalled during the late 1960s when the drug was criminalized, but there has also been a strong social stigma associated with such a potent “hard drug.”


Consequently, it’s been difficult for researchers to get past regulatory hurdles and to convince ethical boards of the need to study the effects of LSD on the human brain. This taboo is beginning to wane, sparking a new era in neuroscientific research.
“People are starting to realize that it’s not impossible to do this sort of research, it’s just very difficult,” explained Carhart-Harris to Gizmodo. “I think once a few people have done it, then they can tell others how to do it. It’s simply a momentum effect.”
The researchers recruited 20 volunteers. Carhart-Harris told Gizmodo that the recruitment phase was “the easiest part of the project” as volunteers jumped at the opportunity. All participants were healthy, and they all had prior experience with LSD, which was an important safety concern. Putting someone in a brain scanner—which can be claustrophobic and noisy— who has never done LSD before sounds like a recipe for disaster.
The researchers used several different imaging techniques, including fMRI and magnetoencephalography (MEG). Each participant was injected with either 75 micrograms of LSD (a standard “hit”) or a placebo consisting of a saline solution (the control group). As the volunteers tripped out in the brain scanners with their eyes closed, the machines recorded the inner workings of their acid-addled brains. Afterwards, each participant rated their visual hallucinations and altered states of consciousness.


These brain scans were done back in 2014. Since that time, Carhart-Harris and his colleagues have been pouring over this unprecedented trove of data.
The researchers were particularly struck by the way LSD affected the primary visual cortex, the part of the brain that helps us process our environment and helps us perform such basic tasks as identifying color, seeing contrasts and lines, and helping with spatial orientation.
Ordinarily, most neural communication within the visual cortex is confined and restricted to this web-shaped network. But when a person is on LSD, this area expands its power and scope, producing vivid hallucinations. Users typically describe seeing such things as crawling geometric shapes, radiant colors, and objects that appear to ripple or “breathe.”
“Under the influence of LSD, the network within the visual cortex experiences a striking expansion of communication,” said Carhart-Harris. “It becomes much less restricted and confined to the visual system, resulting in more of the brain contributing to visual processing and the visual experience.”


Another major finding had to do with the phenomenon of ego dissolution, or what some LSD users refer to as “ego death.” Most of us take it for granted that we have a constant and immutable sense of self. It provides us with purpose and drive, while allowing us to see ourselves as being distinct from others. But on acid, these associations are weakened; the normal sense of self is broken down. For some, this translates to feelings of universal connectedness, which is why some users describe their acid trips as being transcendent or religious-like.


“Psychedelics are a stark reminder that the sense of self that we have is kind of precarious,” said Carhart-Harris. “Under LSD, consciousness is still intact—but what’s missing is this sense of self, a sense of having an ego.”
The reason for this, he said, has to do with a particular network in the brain that’s responsible for self-awareness, namely the parahippocampus and retrosplenial cortex. When on LSD, this network experiences decreased connectivity, resulting in a disintegrated sense of self. “The greater this effect, the greater our participants described the experience of ego dissolution,” said Carhart-Harris. Once the effects of LSD subsided, the sense of self—and normal brain function—was restored.
So LSD does quite a number on the brain. Carhart-Harris said its sweeping effects has something to do with the way that LSD affects synaptic transmissions within the brain. LSD mimics serotonin (a neurotransmitter that influences mood), and it hijacks the serotonin system in some interesting ways. When the drug binds or sticks to one particular serotonin receptor (the serotonin 2A receptor to be exact), it changes the shape of the receptor, and that leads to a number of downstream effects, such as hallucinations and altered states of consciousness. The flexibility of consciousness is being modulated by LSD, which is done through the receptor.


“What this tells us is there is something special and something important about these serotonin 2A receptors and how they modulate consciousness,” explained Carhart-Harris. It’s not the quantity of consciousness that’s being altered, he explained, but rather its quality.
People on LSD also experience emotional and behavioral shifts. When high on acid, some users tend to think in hyper-associative ways (i.e. linking things or concepts that don’t necessarily have a connection), they mix stimuli together, and they become more open to influence. The transition from an ecstatic mood to utter panic can happen in a snap.
Carhart-Harris says many of these characteristics are reminiscent of psychological disorders. “This study tells us not just about what LSD does, but also the nature of normal brain function,” he said. “You need these systems to be intact in order to have [the senses] we rely on.”


Acid trips bear a striking resemblance to certain psychological disorders, including early stage psychosis, schizophrenia, and depression. In all these cases, a certain inflexibility exists in the brain. Carhart-Harris hopes that certain drugs—including psychedelics—can be used to “reboot” the brain as a way to remove this inflexibility. But he admits this could take time; it’s still very early days.
Elyn Saks first started noticing that something was wrong when she was 16. One day, and without…
“Consciousness research is a relatively young science,” he told Gizmodo. “In terms of psychedelic research, brain imaging of psychedelics is still pretty embryonic. So in order for us to really understand these findings, we need to slot it in a network of understanding, and we don’t really have that network yet. We’ve got a treasure trove of data, and we’ve got the beginnings of an understanding of what all this means, but we’re still really only scratching the surface.”


[PNAS]
Late last week, an absolutely ginormous python was found caught under a tree that had fallen near a Malaysian construction site. Its length has been pegged at 26 feet (8 meters), which, if verified, would make it the longest snake ever captured.
The snake, a reticulated python, was spotted from the air during a flyover in Paya Terubong, a district of Penang. Malaysia’s civil defense force was called in to deal with it (yes, really), and it took them a half hour to trap it. Sadly, it died on Sunday after giving birth, three days after it was captured. Or at least that’s the story we’re being given.
A member of the defense force told The Guardian that the python measures 26.2 feet (eight meters), which would be a world record. Currently, Guinness Records recognizes the longest snake ever in captivity as Medusa, another reticulated python, which currently lives in Missouri. This behemoth measures 25.1 feet (7.67 meters) and weighs 350 pounds (158 kg). That’s over 200 pounds (90 kg) lighter than the new Malaysian specimen.


It’s possible that larger snakes live in the wild. Back in 1912, a 32-foot-long (10 meter) python was reportedly discovered in Indonesia.
[Guardian, BBC]
For the first time, astronomers have discovered a class of exoplanets whose atmospheres have been seared away by heat, removing any doubts about what happens when a rocky object wanders too close to a star.
Theorists have long speculated that exoplanets snuggled right up next to their host stars would be subject to “stripping,” or erosion of the atmosphere by high-energy radiation. Now, using data collected by NASA’s Kepler Space Telescope, a team of astrophysicists at the University of Birmingham is reporting the very first observational evidence of these shriveled raisins. The findings are published today in Nature Communications.


“Our results show that planets of a certain size that lie close to their stars are likely to have been much larger at the beginning of their lives,” study co-author Guy Davies said in a statement. “For these planets it is like standing next to a hairdryer turned up to its hottest setting.”
The planets Davies and his co-authors studied are “super Earths,” rocky worlds larger than Earth but smaller than Neptune that are abundant in the cosmos but curiously absent from our own solar system (although that might change if and when astronomers discover Planet nine).


Despite how exotic these blistering hellscapes sound, they may foreshadow what’s to come in our own distant future. After all, as the Sun grows hotter and brighter over the next billion years, the extra radiation will start to cook our fragile biosphere, eventually boiling away the oceans and rendering the entire surface of the Earth uninhabitable. Whether our planet will eventually be stripped of its atmosphere too isn’t certain—but given the mounting evidence we’re beginning to see all over the galaxy, I don’t think we want to be around to find out.


[Nature Communications]
Rain means clouds and clouds mean less sunlight. That’s bad news for most solar cells, but a new design can actually make use of rain drops that fall on its surface, allowing it to generate electricity even when the weather’s bad.
The new solar cell has been developed by researchers in Qingdao, China. Unlike most solar cells, this device has a single sheet of graphene on its upper surface. The clever part is that rainwater isn’t pure: It contains compounds like ammonium, calcium and sodium, all of which become ions when they’re in solution.


When that water sits on top of a layer of graphene, it creates what the researchers call a ‘pseudocapacitor’—spots of unbalanced charge where electrons are donated from one side to the other. Unbalanced charge is basically just a voltage, which means that the researchers can use the process to capture electricity.
Sadly, we won’t be coating every solar cell in graphene just yet—and not only because of the expense. The solar cell created by the team is just 6.5 percent efficient in optimal solar conditions, which compares pretty damn badly to the best solar cells, which are around 20 percent efficient. Meanwhile, mere microvolts are generated by the raindrop capacitors.


Still, the idea’s a good one, as it would make solar power far more versatile in environments where the weather is a mixed bag. Now the researchers just need to make it work a little better.


[Angewandte Chemie via Science News Journal via Engadget]
It’s an exciting time to be alive if you’re keen to watch humans get off this planet. A private space race is taking off, opening new pathways to orbit while sparking a burst of technological innovation. Even better, thanks to the magic of internet live streaming, we’re watching history unfold in real time.
Speaking of history—did you catch that SpaceX Falcon 9 rocket landing on a fucking ocean barge yesterday like it was no big deal? Watch it again if you already did. It gets a little more awesome each time. Remember, you’re watching a forty meter-tall aluminum tank land softly on a giant autonomous raft minutes after separating from a payload (including an inflatable space habitat) in low Earth orbit.


A brave new future of reusable rockets is upon us. But what are the next big milestones for the private space industry? Here are five things to look forward to in the months and years ahead.
Sending a rocket into orbit and bringing it back to Earth is a huge accomplishment. But what good’s a reusable rocket unless you start, well, re-using it? Musk has already decided that his first “reusable” Falcon 9 will be a museum piece, although SpaceX did test fire the engines after the rocket landed, and things seemed to check out. The rocket could probably fly again. It’s unclear what SpaceX plans to do with its latest space veteran—although if I had to guess, I’d wager they’re going to try to launch it again.


Blue Origin, Jeff Bezos’ private space tourism company, has also made huge strides toward reusable rockets. Last week, the notoriously tight-lipped rocket company brought a New Shepherd rocket to the edge of space and back for the third time in a beautiful, control descent.
SpaceX isn’t busting its ass on reusable rockets to haul NASA’s luggage to the ISS every six months: it wants to blast all kinds of stuff into orbit for all kinds of customers, and it’s already got launch requests up the whazoo. To meet them, the company is cranking up Falcon 9 production big time, from six to eight rocket cores per year to over thirty, according to SpaceX COO Gwynne Shotwell. Likewise, we can expect other private space companies to accelerate rocket production once they’re ready for prime time.
Later this year, SpaceX plans to debut the Falcon Heavy, which will, according to the rocket company, “be the most powerful operational rocket by a factor of two.” The rocket is specifically designed to ferry astronauts into orbit, and eventually, to Mars. We can’t wait to see this thing in action.
Speaking of humans—right now, if you’re an astronaut who’d like to get to the ISS, Russia’s Soyuz spacecraft is the only game in town at the moment. But that could change very soon: last year, NASA has granted commercial crew contracts to SpaceX and Boeing. Per the contracts, each company will send anywhere from one to six crewed flights into orbit, beginning as early as next year. Before that happens, both companies need to complete a rigorous certification process and assure NASA that their spacecraft have adequate safety measures in place. Orbital ATK and Sierra Nevada were also recently contracted by NASA to ferry supplies, and perhaps an extra astronaut, to the ISS.
While SpaceX, Boeing, Orbital ATK, and Sierra Nevada are all chasing government contracts to take supplies and personnel up to the ISS, some companies have their sights set on a different audience: people willing to pay bank to fly into suborbital space. After a setback two years ago when its SpaceShipTwo crashed, Richard Branson’s Virgin Galactic has been working hard to get back on track, unveiling the VSS Unity earlier this year. But Blue Origin might be the first to open up the space tourism market: earlier this year, the company announced its intentions to begin flying private citizens as early as 2018.
Of course, we all know Elon Musk’s end game here—colonizing Mars! The billionaire tech entrepreneur has made his feelings on this matter clear: “I think the wise move is to make life multiplanetary while we can,” Musk told a huge crowd of scientists and space enthusiasts at the American Geophysical Union annual meeting last December.


Still, it’s going to take some time. While NASA has spent the last year doing its darnedest to convince everybody it’s got a journey to Mars in the works for the 2030s, the space agency’s actual plans remain nebulous. As private rocket companies continue to break new ground, it’s looking more and more likely that any crewed journey to Mars will be a public-private partnership.
SpaceX has hinted that it’ll be unveiling its own roadmap for Martian settlement—and perhaps more details on how we’re going to terraform the Red Planet?—later this year, so stay tuned.
Remember when we shared those fantastic photographs of BB-8 visiting NASA’s Jet Propulsion Lab? (That’s the adorable rolling droid from Star Wars: The Force Awakens, for anyone who’s been living under a rock the last few months.) Now the folks at Disney have released the video footage from BB-8's visit, whereby the plucky little droid meets Maggie, the twin sister of the Mars Curiosity rover, and “chats” with a JPL scientist.
We can never get enough BB-8. Apparently neither can NASA.

Not so long ago, in our very own Milky Way galaxy, a plucky little droid named BB-8 roamed the…
There’s a wonderful irony to the fact that every single snowflake is a unique masterpiece, but they’re too small for the human eye to enjoy. Thankfully they can also be grown in a lab, by scientists like Dr. Kenneth Libbrecht, the “Snowflake Consultant” for Disney’s Frozen, who also films his microscopic creations so they can be studied, shared, and made into captivating GIFs.
[YouTube via Laughing Squid]

SPLOID is delicious brain candy. Follow us on Facebook, Twitter, and YouTube.
Mosquitoes love to breed inside discarded car tires. So why not use this against them? Such is the thinking of Canadian researchers who have developed a DIY mosquito trap that’s already proving its worth in field tests.
The trap is called Ovillanta, and it was developed by researchers from Laurentian University with help from Mexico’s National Institute of Public Health (plus a little money from the Canadian government).
The egg trap is constructed from two 20-inch (50 cm) sections of discarded rubber car tires. The bits of tire are fashioned into a mouth-like shape, and a fluid release is added to the bottom.Once it’s ready and hung on a wall or tree, a non-toxic solution is added. A chemical pheromone is added to attract the mosquitoes. A wooden strip or paper floats in the artificial pond, where the female lays her eggs.


Twice a week, the strip is removed so that it can be analyzed, and the eggs that have been collected are destroyed using fire or ethanol. The solution is recycled back into the tire, but over time it collects even more mosquito pheromones, making it even more irresistible. From a mosquito’s perspective, it’s actually quite diabolical.
The researchers recently conducted a 10 month trial of the system in Guatemala where it worked to reduce virus-carrying Aedes mosquitoes. These mosquitoes are responsible for spreading viruses like Zika, dengue, yellow fever, chikungunya, West Nile virus, and others. Population control measures to reduce the number of mosquitoes are an important aspect of combating these blights.
Over the course of the 10 months, the Ovillanta system worked better than traditional ovitraps, which are usually made from one-liter buckets. During the field trial, the team collected and destroyed over 18,100 Aedes eggs per month using 84 Ovillanta traps in seven neighborhoods. That’s seven times more efficient than traditional traps. At the same time, no new cases of dengue were reported in the regions where the traps were set up, but the researchers caution that this is merely an anecdotal observation. It’s also important to point out that this study is still awaiting peer review. That said, this area of Guatemala typically records about 24 to 36 cases during the same months.


Neat, right? Nice to see low-tech solutions perform so well. It’s cheap, easy to make, and environmentally friendly. On it’s own, the system likely won’t be able to completely curb the spread of mosquito-borne viruses, but when used with other population control strategies, it could contribute significantly to the cause.
[F1000Research]
Something strange is happening to our planet. Around the year 2000, the North rotational pole started migrating eastward at a vigorous clip. Now, scientists at the Jet Propulsion Laboratory have figured out what’s going on—and you’ll be shocked to learn that humans are behind it.
The rotational axis of any planet, including our own, is in constant flux. That’s because planets aren’t perfect spheres, but bumpy, pitted things whose mass is always on the move. “If you take a chunk of material from some area, you are breaking the symmetry, and the spin axis starts moving,” Surendra Adhikari of the Jet Propulsion Laboratory told Gizmodo.


Through careful observations and mathematical models, Adhikari has discovered that our planet’s recent polar wanderlust has two causes: the melting of the Greenland and West Antarctic ice sheets, and changes in the global distribution of water stored on land. Both of these are related to a single underlying phenomenon.
“The bottom line is that climate change is driving the motion of the polar axis,” Adhikari said. His findings are published in Science Advances today.


Scientists have taken careful measurements of Earth’s spin axis since 1899. Prior to the 21st century, the pole wandered toward Hudson Bay, Canada, moving at a rate of about seven centimeters a year. This long-term migration is believed to be related to the loss of the Laurentide ice sheet, which blanketed Canada and much of the northern United States during the last ice age.


But around the turn of the century, our spin axis charted a new course. The planet’s north rotational pole is now heading east, along the Greenwich Meridian, and it’s moving twice as fast as it was before. “Scientists believed that this must be related to the melting of the Greenland ice sheet,” Adhikari said. “That’s been the general understanding.”
But it turns out ice sheets don’t tell the full story. By combining mass distribution models with data from NASA’s Gravity Recovery and Climate Experiment (GRACE) satellite, Adhikari teased out another critical factor: the storage of water on land, and in particular, across Eurasia. Humans move tremendous volumes of groundwater through pumping, but also indirectly via climate change, which is causing some places to become drier and others wetter.
Taken together, these changes are causing our planet to tip over ever so slightly.


Land water storage is also directly related to another curious feature of our planet’s spin axis: a decadal oscillation from east to west. The poles don’t migrate along a straight line—rather, they trace a sine curve that wobbles back and forth. “Here, for the first time ever, we have presented a plausible physical mechanism for this,” Adhikari said.
And that mechanism points to an important reason for studying polar wander—reconstructing past climate. We have polar migration records stretching back to the beginning of the 20th century, and now, we know that these records are related to patterns of wetness and dryness.


“This means, you can start answering questions like, during the 20th century, was there an intensification of drought or wetness in some region of the planet,” Adhikari said. Which is exactly what Adhikari is now starting to do, in collaboration with hydrologists at the JPL.
Perhaps most importantly, the findings offer a powerful new piece of evidence humans have become the dominant force of nature on the planet. Later this year, a group of scientists will formally review a proposal to move us into a new geologic epoch—an age of humans and machines dubbed “the Anthropocene.” I can’t help but feel like the revelation that we’re shifting the very axis on which our world spins only strengthens the case.
Just one year after scientists in China made history by modifying the DNA of human embryos, a second team of Chinese researchers has done it again. Using CRISPR/Cas9, the researchers introduced HIV-resistance into the embryos, showcasing the tremendous potential for gene-editing.
In that earlier work, the Chinese scientists modified a gene responsible for a fatal blood disorder, but the embryos were quickly destroyed after the experiment. It was a watershed moment in biotechnology, showcasing the tremendous potential of CRISPR—a powerful gene editing tool—to alter our offspring at the genetic level. Should this technology ever reach the clinical stage, it could be used to eliminate all sorts of genetic diseases, but it could also be used to introduce entirely new capacities.
Last week’s historic summit on human gene-editing has come to a close, and its organizing committee …
Now, as reported in Nature News, a research team led by Yong Fan at Guangzhou Medical University has used CRISPR to introduce a beneficial mutation that cripples an immune-cell gene called CCR5. Some humans naturally have this built-in immunity to HIV, making it impossible for the virus to infiltrate human immune cells.


For the study, the researchers collected 213 fertilized human eggs, donated by 87 patients. All of the embryos were unsuitable for in vitro fertilization because they contained an extra set of chromosomes. The researchers destroyed the embryos after three days.
Of the 26 human embryos targeted, only four were successfully modified; a significant number of embryos experienced unintended mutations. Like the previous Chinese study, this research shows how far we still are from being able to use CRISPR in a precise way, without triggering these “off target” mutations.
Experiments like this are not without controversy. There’s still some unease about modifying human embryos in the lab, even if they’re not used to facilitate a pregnancy. Some critics of the new study say scientists shouldn’t be “playing” with human embryos like this, arguing that embryos derived from primates would serve just as well. Also, there’s significant concern that, in future, these germline modifications might be passed down to the next generation, which would could result in unforeseen consequences. And of course, there’s the inhibition about “designer babies” and the prospect of human enhancement.


A strong case can be made that this latest research, in which an immunity to HIV was conferred to the embryos, resulted in an enhancement. Technically speaking, the researchers weren’t trying to treat a genetic disease. Rather, they added an immunity to a virus. So in a sense it’s like a vaccination, but one done at the genetic level—and one that could, in theory, be passed down to the next generation. Regardless, this study shows how difficult it’s going to be to discern therapy from enhancement.
Late last year, the International Summit on Human Gene Editing decided that it was okay for U.S. researchers to edit human embryos, so long as it doesn’t result in a pregnancy. Exact guidelines on how American scientists are to proceed are expected later this year. Similarly, a British team was recently given the greenlight to modify human embryos for research into fetal development. Progress in this area is thus set to advance in the U.S. and the U.K., but clearly the Chinese are ahead of the game—whether you agree with their methods or not.


This study also comes on the heels of new research showing that CRISPR can be used to edit HIV out of immune cells (though not without some difficulty). This suggests that CRISPR could still be used to combat HIV in the absence of germline modifications.
[Nature News]
The astronomical community is abuzz with the possibility that a ninth planet exists in the far reaches of the solar system. A new study by European scientists imagines what this hypothetical planet might look like, revealing important insights as to how we might actually find it.
To quickly recap, astronomers haven’t actually proven the existence of Planet Nine, but its existence is inferred by the unlikely orbits of distant Kuiper belt objects. This data strongly suggests that something is way out there far beyond Pluto, leading scientists to wonder what it might look like and how we might ever be able to find it.
Ten years ago, billions of humans had their worldview upended when a group of astronomers announced …
Astrophysicist Christoph Mordasini from the University of Bern and his PhD Student Esther Linder are planet modeling specialists, and they recently applied their expertise to the figuring out what Planet Nine might look like. Their ensuing analysis, which has been accepted by the science journal Astronomy & Astrophysics, paints a fascinating portrait of a dark and cold planet in the far reaches of the solar system.


The purpose of the exercise was to create ballpark estimates for the planet’s radius, temperature, brightness, and most importantly level of thermal radiation. The last item is of particular interest because while Planet Nine may be too dim to be seen with our current telescopes, it’s thermal signature might be detectable by other means. Encouragingly, the simulations created by Mordasini and Linder suggest this may very well be the case.
With very little data to go on, the researchers decided to simulate several different scenarios. For the study, the astrophysicists assumed that Planet Nine is a smaller version of Uranus and Neptune. They modeled hypothetical planets that were five, 10, 20 and 50 times heavier than Earth, and at distances of 280, 700, and 1,120 AU from the Sun (1 AU being the average distance of the Earth to the Sun; for comparison, Pluto is about 40 AU from the Sun). One particular simulation jumped out at the researchers as plausible.
“For me candidate Planet Nine is a close object, although it is about 700 times further away as the distance between the Earth and the Sun,” noted Linder in a statement. The “ideal” Planet Nine, according to the models, features a mass ten times heavier than Earth, and a radius 3.7 times wider than our planet. Similar to Uranus and Neptune, it has an outer envelope of helium and hydrogen, a layer of gas (also consisting of helium and hydrogen), a water ice layer, a silicate mantle, and an iron core.


The models also projected a temperature of 47 Kelvin (-374 degrees Fahrenheit, -226 degrees Celsius). Planet Nine is bitterly cold—but this data suggests that it’s being heated from the inside.
“This means that the planet’s emission is dominated by the cooling of its core, otherwise the temperature would only be 10 Kelvin,” explained Linder.“Its intrinsic power is about 1,000 times bigger than its absorbed power.”


So, Planet Nine’s reflected sunlight contributes a very tiny part of the total radiation that could be detected on Earth (it’s exceptionally dim, less than 1 percent as bright as Jupiter). But it also means that this nominal planet is much brighter in the infrared than in the visual. As the researchers put it, Planet Nine is a “self-luminous planet.”
That’s good news for astronomers, who can now scan the heavens for these thermal signatures. All this is quite remarkable; even though we’ve never actually seen this thing, it’s actually starting to take shape.
[Astronomy & Astrophysics (pre-print version here)]
The vibrant colors of many of Vincent van Gogh’s most famous paintings—including his Sunflower series—have been fading over the last 100 years. Now a team of Italian scientists has come up with an explanation as to why the lead chromate dyes favored by the artist when mixing his pigments degrade so much under light. They described their work in a new paper in Chemical Science.
Other canvases from the same period (e.g. works by Renoir) are also prone to fading, but Van Gogh’s paintings are especially vulnerable. That’s just one reason why his work is proving to be a particularly rich resource for scientists interested in studying how certain fragile pigments degrade over time. Not only was he incredibly prolific—producing close to 1000 paintings in just ten years—but he was obsessed with pigments, describing his favorites and how he used them when mixing paints for his canvases in letters to friends and family. So there’s an extensive historical written record of his practices.


Last year, Belgian scientists (led by Koen Janssens from the University of Antwerp) used x-ray diffraction mapping combined with tomography at the DESY synchrotron in Hamburg, Germany, to study the discoloration in the red lead oxide pigments in Van Gogh’s “Wheat Stack Under a Cloudy Sky.” As I wrote at Scientific American the time:
Sometimes it turns into plattnerite or galena, blackening the color, and other times it might convert to red lead or lead sulfite, bleaching it out. [They]... discovered a very rare mineral called plumbonacrite in the van Gogh canvas that seems to play a role in the bleaching process of the pigment. Over time, light triggers CO2 absorption, which causes plumbonacrite to form, eventually turning into white-hued lead carbonate.
The same team was also behind a 2011 study of the yellow pigment the artist favored. Chrome yellow was the new hotness among late 19th century artists, so it was a natural choice for van Gogh, who loved strong vibrant colors.
But exposure to strong sunlight makes the color change from bright yellow to a dull brown. Janssens suggested that the chromium in the pigment reacted particularly strongly with compounds like barium and sulfur.


It just so happens that barium and sulfur were key ingredients in the white paints common in van Gogh’s time—and the artist often blended his yellows with whites, thereby brightening his colors. Two of the paintings they studied contained barium sulphate, likely used to make the paint go further, according to Janssens.
Still, the precise reasons why this would make the dyes so unstable remained unclear. That’s where Ana Munoz-Garcia and his colleagues at the University of Naples Federico II come in. They modeled the chemical structure of the dyes to figure out if the fading is just something happening at the surface, or whether it’s an innate structural issue. The bad news: it’s the latter, which means there’s very little art conservationists can do for now about the fading, apart from limiting the paintings’ exposure to sunlight.
“Pure sulfate is the bad guy of the story,” Munoz-Carcia told Chemistry World. “All the sulfates want to be together to minimize stress in the material. So because of the segregation, you generate that sulfate. And because the sulfate absorbs in the UV, you get degradation.” Bright yellow chromium turns into a dull green.
How does Janssesns feel about this latest study? He’s understandably cautious, particularly since these are theoretical predictions based on computer simulations. “We have some experimental data on this and can now confront their predictions with reality,” he told Chemistry World. “A more systematic verification is now very useful to do.”
[Chemistry World]
The work of Vincent Van Gogh may be among the greatest artistic achievements in human history, but…
The case that we’re all just highly organized lumps of space candy keeps getting better. For the first time, scientists have created ribose—the key sugar underlying RNA—in laboratory conditions simulating the cold, radiation-blasted vacuum of outer space.
The early origins of life are one of the murkiest chapters in our planet’s history. One major point of debate is whether life’s building blocks—things like amino acids, lipids, and sugars—formed spontaneously here on Earth or rained down on our planet via comets and asteroids. With no fossil records to guide us, scientists use experiments to simulate the formation of our goopy, pre-biotic heritage.


These experiments trace all the way back to the 1950s, when Stanley Miller and Harold Urey famously demonstrated that several organic compounds could form spontaneously in conditions simulating our planet’s early atmosphere. Fast forward sixty years, and our ability to mimic both the primordial Earth and outer space environments has grown far more sophisticated.
In the latest experiment, which appears in Science today, a team of chemists led by Cornelia Meinert of the University of Nice Sophia Antipolis recreated the ices found abundantly on comets and in interstellar clouds to see if complex organic molecules could form. The researchers cooled water, ammonia, and methanol to -195 degrees Celsius in a vacuum, then subjected their ice crystals to UV light to simulate the radiation output of a young star.


All in all, the team was able to produce 55 organic molecules, most notably ribose, a critical sugar found in the RNA molecules that transmit DNA’s genetic instructions. RNA possesses the unique ability to pass along genetic information and self-replicate, leading many researchers to suspect that the earliest forms of life on Earth were in fact RNA-based. The possibility that RNA molecules, or at least, many of their ingredients, could have emerged off-Earth has never looked better.


Today, experiments like this one are complemented by detailed analyses of comets and cosmic dust clouds. Last year, the European Space Agency announced that it had discovered a slew of simple organic molecules on Rosetta’s comet. And the evidence has been mounting for years that amino acids, the building blocks of proteins, can form spontaneously in high-radiation interstellar environments.
For these reasons and more, my colleague Adam Clark Estes would like to offer a solution to the Fermi Paradox: the aliens are all just cotton candy.
[Science via Science News]

Would you plug a random USB stick into your computer? According to a new study by researchers from the University of Illinois Urbana-Champaign, plenty of us are still morons and would do exactly that.
To work out just how dumb we are, the team littered 297 USB drives around their university’s grounds—in lecture theaters, parking lots, cafes, study areas and what have you. Then, they... waited.


On the USB stick were a series of HTML files that were disguised to look like regular old files of notes, documents and photo albums. But if someone inserted a drive into their internet-connected computer and opened the files, the researchers were alerted. And alerted they were, because 45 percent of the USB stick were dutifully picked up, inserted into computers and rummaged through. (They may have missed some, of course, if the computers weren’t online at the time.)
The schmucks that had opened files were told in a browser window that they were part of an experiment at this point and asked to fill out a survey. Less than half did, and excuses for picking up the stick ranged from simply being nosey to, err, needing a USB stick. But generally the team found that most people simply wanted to reunite the stick with its owner—or at least, that’s what they claimed in the survey. The findings are being presented at the 37th IEEE Symposium on Security and Privacy in California


So, are the staff and students of Illinois Urbana-Champaign just not particularly tech-savvy? Not according to the team. “These individuals are not technically incompetent,” write the researchers, “but are rather typical community members who appear to take more recreational risks than their peers.” The study certainly showed that many understood the risks involved: While some people did use their own computer to open the files, many used library computers for the job. Not good for the University, but some small victory for personal security.


It goes without saying that you should not insert random USB sticks into your computer.
[University of Illinois Urbana-Champaign via Science Alert]
Who needs memory cards when you have DNA? A team of scientists has been able to store images within the life-defining molecules then retrieve them perfectly.
Researchers from the University of Washington have been working out how to take digital files and convert them into strings of DNA that can be easily read back. Luis Ceze, one of the researchers, explains in a press release:
“Life has produced this fantastic molecule called DNA that efficiently stores all kinds of information about your genes and how a living system works — it’s very, very compact and very durable. We’re essentially repurposing it to store digital data — pictures, videos, documents — in a manageable way for hundreds or thousands of years.”
To do it, they first have to convert ones and zeroes that make up a digital file using the four basic building blocks of DNA— adenine, guanine, cytosine and thymine. Sounds easy enough, but much of the researchers’ time has been spent working out how to squeeze as much data into as short a string as possible without any errors.


That’s done using Huffman coding, a fairly normal approach for lossless data compression. You can read more detail about it in the researchers’ paper, but the results look a little like this:
Once the team’s determined how to represent a file, they then synthesize artificial DNA based on their calculations. It’s the pink stuff in the tube above, but it can equally be dehydrated so that it can be stored for use at a later time.


Reading the data is made easier by distinctive markers that the team place within the strands of DNA. The team can sequences the sample, then use these markers to finds the starting point of a file. Then they simply read back the combination of adenine, guanine, cytosine and thymine, use the Huffman coding to convert it back into digital data and—voila!—the files is restored.
The team has shown that they can successfully encode—and then retrieve— the images you see at the top of the page, but they suggest that they can go much further, storing video, audio and any other kind of digital file. In a press release, they claim that it could be possible to “shrink the space needed to store digital data that today would fill a Walmart supercenter down to the size of a sugar cube.” Impressive.


But don’t throw your hard drives out just yet. The technique is currently expensive, requiring some serious lab kit to synthesize the DNA and recover the data from it. But if that can be made affordable, DNA data storage could help us file away the vast amounts of information we continue to generate.
[University of Washington]
Cheese, aubergine, ham, and tortillas are tasty in their own right, but in the hands of artist Matthew Herper, they also make beautiful music. He uses laser-etching to make edible—and still playable—record albums to explore the acoustical properties of food.
The project is called Edible Sound, commissioned by London’s Science Gallery. It’s for a good cause: to raise awareness of food production, nutrition, and waste. His focus is on ingredients often used in processed food, with sugar being one of the worst culprits:
Often consumed without consideration of the levels being ingested, sugar in particular, is a primary component in processed foods with direct links to obesity, diabetes and other health issues. Herbert’s project spotlights this ingredient (amongst others), at a time when the negative impact of high dietary sugar levels on our health, medical services and the economy is a hot topic. Herbert’s interest in sugar stems from its ability to entice consumers in spite of the increasing evidence of its damaging effects.
Herper tweeted about his edible tortilla 33 rpm record last month, declaring it “playable on normal hifi. unlikely to be delicious.” His work closed the Science Gallery’s months-long exhibit, FED UP: The Future of Food, with a live performance on March 17 at The Guy’s Chapel in London. Per The Vinyl Factory: “Equipped with a larder of ingredients used in processed foods, he laser-etched aubergine, onion, celeriac, potato, ham, cheese, tortilla and sugar into playable, edible records which were then fed to the audience at the end of the performance.”


Try doing that with vinyl. Incidentally, Herper is not the first to make a playable record out of a tortilla. He’s just taken the next logical step forward.
[Boing Boing]
Scientists are excited about the prospect of using CRISPR, a powerful gene-editing tool, to combat HIV. A discouraging follow-up study shows that HIV is capable of developing a resistance to the genetic attack—but scientists say CRISPR’s battle with HIV is far from over.
To quickly recap, scientists have started to use the CRISPR/cas9 gene-editing system to pluck out viral DNA from HIV-infected T-cells. It may be years before we see this technique used on actual patients, but if it ever reaches the clinical stage, it could eliminate the need for antiretroviral drugs, which are costly and don’t actually cure HIV. Sadly, a new study published in Cell Reports shows just how hard it’s going to be to finally defeat this virus. It turns out that HIV-1 is capable of adapting to CRISPR.


HIV, like all retroviruses, copies its genome into host cells in order to replicate, which is why scientists are so stoked about using CRISPR to fight it. This system can scan an infected strand of DNA, locate the viral parts, and strip it out. Over the past several years, nearly a half-dozen papers have been published on the subject, including a recent study conducted by virologist Chen Liang at McGill University in Montreal.
Two weeks after the initial experiment, Liang noticed that his modified T-cells were churning out new copies of HIV-1, a sign that some cells had managed to evade CRISPR’s genetic attack. While single mutations had successfully inhibited viral replication, others actually conferred unexpected resistance. The problem is that HIV is really good at surviving mutations—and it’s really, really good at turning certain mutations into an advantage. This case being no exception.
The clues to the problem lay in Liang’s initial experiment. He used CRISPR to chop-up the viral DNA that had made its way into the host cell. Afterwards, the cell managed to repair the broken part of the genetic sequence, leaving a “scar tissue” that should, in theory, prevent the viral DNA from functioning.


And for the most part, that worked. But in some instances, the scar tissue made the virus stronger (such as the ability to replicate even faster). Not only that, the scar tissue didn’t resemble the old genetic sequence, so the CRISPR/cas9 system couldn’t recognize it anymore, rendering it useless. In essence, HIV developed a kind of immunity to CRISPR.
“Some mutations are tiny—only a single nucleotide—but the mutation changes the sequence so Cas9 cannot recognize it anymore,” said Liang in a statement. “Such mutations do no harm to the virus, so these resistant viruses can still replicate.”
This bit of insight has given the scientists another idea. As Liang told New Scientist, they could still use CRISPR to “carpet bomb” the viral DNA residing in the host cells. “The key could be using multiple viral sites for editing,” Kamel Khalili of Temple University told New Scientist. “This would reduce any chance for virus escape or the emergence of virus resistant to the initial treatment.”
So in the ongoing battle to defeat HIV, don’t count CRISPR out just quite yet.
[Cell Reports via New Scientist]
Trap-jaw spiders hunt by sneaking up on their prey and rapidly snapping their mandibles shut, but scientists weren’t entirely sure about the mechanics involved. Using high-speed video, researchers from the Smithsonian’s National Museum of Natural History have chronicled just how these spiders manage such an impressive combination of power and speed. The details can now be found in Current Biology.
“This research shows how little we know about spiders and how much there is still to discover,” said co-author Hannah Wood in a statement. “The high-speed predatory attacks of these spiders were previously unknown. Many of the species I have been working with are also unknown to scientific community.”
Scientists previously observed similar behavior in some ants, but this marks a first for arachnids. The high-speed strike has evolved at least four different times within this family of spiders in an excellent example of what evolutionary biologists call “convergent evolution.”


Trap-jaw spiders belong to the Mecysmaucheniidae family. They’re native to New Zealand and southern South America, and they spend most of their time on the forest floor searching for prey. Wood and her colleagues captured high-speed videos—as high as 40,000 frames per second—of 14 species of Mecysmaucheniidae, revealing a great range of closing speeds. The fastest spider species could snap its mouth-parts shut more than 100 times faster than the slowest species, clocking in at a blazing 20 miles an hour.
A kind of rubber-band like movement enables the whipping motion, but the researchers aren’t sure where all the energy is coming from. The power produced by the spiders’ muscles aren’t enough to produce the high-speed snap. The researchers speculate that other structural mechanisms must be responsible—but they’re not entirely sure what that is. But whatever it is, it’s releasing stored energy in a way that’s amplifying the power. The researchers are currently conducting a follow-up investigation to learn more.
Animated gif courtesy Andrew Liszewski.


[Current Biology]
History has a way of repeating itself. Humans are currently conducting a grand experiment with Earth’s climate, but the outcome of that experiment may be foretold. According to Penn State climate scientist Richard Alley, the future—or a somewhat diluted version of it—happened 55.9 million years ago.
Geologists have long considered the Paleocene-Eocene Thermal Maximum (PETM) the most direct analog to modern climate change. During the PETM, some 2,000 and 4,500 billion tons of carbon were offloaded into the atmosphere over thousands of years, for reasons that are still being debated. Today, carbon concentrations are rising even faster, and the scientific debate over who’s responsible ended long ago.
Carbon hasn’t entered our atmosphere this quickly in at least 66 million years—since an asteroid…
What exactly does this mean for us? Writing in Science today, Alley argues that many of the climactic and ecological changes that occurred 55.9 million years ago are likely to repeat.


Here is a non-exhaustive list of stuff that happened during the PETM:
Scientists estimate that the total amount of carbon added to the atmosphere during the PETM was similar to what humans could add today if we burned all of our fossil fuel reserves. But as Alley notes, PETM emissions were drawn out over a much longer timescale—perhaps giving life on Earth some chance to adapt. For that reason, he concludes, “the biological impacts of the PETM were likely less severe than those of human-caused emissions under a business as-usual scenario.”
If we burned all the coal, oil and gas that’s left in the ground, we’d melt Antarctica and global…
Scientists are not oracles. But did any of the items on Alley’s list look eerily familiar to you? They should—what happened during the PETM is starting to happen today. It would seem our safest course of action is to try and prevent more of that ecological nightmare from unfolding.


To that end, the United States, China, and other leading carbon offenders will take a major step later this month, by signing the Paris climate accord into effect. But a lot more needs to be done.
In the immortal words of the Sacred Scrolls, all of this has happened before. Unless we act fast, all of it could happen again.
[Science]

The U.S. Food and Drug Administration has approved an injectable pacemaker that doesn’t require wired leads, which often lead to complications.
The one-inch long Medtronic-built device, called the Micra Transcatheter Pacing System, is about a tenth the size of traditional pacemakers—making it the smallest in the world.


It’s intended for patients with atrial fibrillation (an irregular or rapid heart rate) and other dangerous arrhythmias, including bradycardia-tachycardia syndrome. The FDA approved the device in light of a Medtronic clinical trial involving 719 patients who were implanted with the device. After six months, around 98 percent of the patients experienced adequate heart pacing. A small fraction (7 percent) of patients experienced major complications, such as cardiac injuries, device dislocation, and blood clots.


Conventional pacemakers, which are surgically implanted, require wired leads that run from the pacemaker to an implant located just below the collarbone. These leads run through a vein directly into the heart’s right ventricle, delivering electrical impulses to treat irregular or stalled heart beats. The problem with these wires, aside from the clunkiness of it all, is that they sometimes malfunction. They can also cause problems when infections develop in the surrounding tissue, requiring a surgical procedure to replace the pacemaker.
Micra doesn’t use wired leads at all. The device latches onto the heart using small hooks, where it delivers electrical pulses that keep the heart beating more regularly. The device is implanted through a thin 41-inch-long (105 cm) tube inserted into a vein in the patient’s groin. It travels through the vein, making its way to the heart’s right ventricle. Micra only paces the lower chamber of the heart, so it can’t be used for patients who need pacing in both the upper and lower chamber.


“As the first leadless pacemaker, Micra offers a new option for patients considering a single chamber pacemaker device, which may help prevent problems associated with the wired leads,” noted the FDA’s William Maisel in a press statement.
The FDA said it shouldn’t be used for patients who already have implanted devices, as they could interfere with pacemaker function. It also can’t be used for people who are severely obese, or who are intolerant to materials in the device or the blood thinner heparin.


[FDA, Medtronic]
A 42-year-old man from New Jersey recently showed up in an emergency ward following a seizure. After looking at the data collected by his Fitbit Charge HR, the doctors decided to reset his heart rate with an electrical cardioversion. It’s the first time in history that a fitness tracker was used in this way.
When the patient arrived at Our Lady of Lourdes Medical Center in Camden, the clinical team noticed he had an atrial fibrillation (an irregular and fast heart beat), but they weren’t sure if it was chronic, or if the seizure triggered it (the seizure happened 20 minutes prior to the patient’s arrival in the ER).
This bit of information is crucially important because it will determine whether or not the medical staff can electrically cardiovert the patient to alleviate the arrhythmia (a cardioversion uses electricity to reset the heart rate back to normal). If it was chronic, the cardioversion could dislodge an appendage clot, sending it up the aorta and possibly triggering a stroke. But failure to treat the arrhythmia could also result in a stroke. Thankfully, the medical staff noticed that the patient was wearing a fitness tracker.


Here’s what the clinical team wrote in their ensuing report, which now appears in the Annals of Emergency Medicine:
During the patient’s examination, it was noted that he was wearing a wrist activity tracker (Fitbit Charge HR, Fitbit, San Francisco, CA), which was synchronized with an application on the patient’s smartphone, recording his pulse rate as part of a fitness program. The application was accessed on the patient’s smartphone and revealed a baseline pulse rate between 70 and 80 beats/min, with an immediate persistent increase to a range of 140 to 160 bpm at the approximate time of the patient’s seizure. The pulse rate remained elevated until administration of the diltiazem in the field.
The patient’s Fitbit confirmed that the atrial fibrillation was in fact triggered by the seizure, which meant they could go ahead and perform the electrocardioversion.

Up until this point, activity trackers have only really been used by doctors and health care providers to encourage or monitor patient activity. This marks the first time in medical history that the information in an activity tracker-smartphone system was used to assist in specific medical decision-making.
Patients are increasingly bringing their fitness-tracker data to their checkups. Not only are…
The incident shows the great potential that these devices have to inform medical staff of serious problems. These trackers aren’t perfect, and they’re certainly not medical grade in terms of quality, but they can track data in a way that’s meaningful—data that doctors can use in emergency situations just like this one. Looking to the future, wearables could even trigger alarms when a health emergency happens, like a patient having a heart attack. It’s still early days for these devices, but they’re already turning out to be life savers.


[Annals of Emergency Medicine via Medgadget]
Whether you’re counting by calories, pounds, or dollars, the world is wasting a huge amount of food. But there’s also another way to measure it: The quantity of resources we burn up for nothing at all.
The UN estimates that growing our food accounts for about 5 billion (and climbing) tons a year of carbon emissions; that’s about one fifth of the global carbon emissions. Within that number, you can also break down smaller sections: How much comes from just ranching, or how much comes from Uruguay, for example. What hasn’t been broken down until now, though, is how much carbon we’re releasing for food no one is eating. Researchers from Germany’s Potsdam Institute for Climate Impact Research have a study out today in Environmental Science and Technology that answers that question.


Wasted food accounts for one tenth of all agricultural carbon emissions today, they say—and the projections for what that will look like in the coming decades are even worse both in terms of food wasted and carbon emissions.
“During the last 50 years, global average food waste per person has increased from 310 calories a day to 510 calories a day. The food waste problem is increasing in the recent decades,” study co-author Prajal Pradhan told Gizmodo. “If the current trend continues, GHG emissions associated with food waste will increase by four to five times between 2010 and 2050.”


Pradhan attributes part of that increase to to the higher proportion of wasted food overall. But it also comes down to changes in our diets themselves, especially a global shift towards shift towards eating more meat. “Diet changes towards a larger share of animal products could over-proportionally increase greenhouse gas emissions associated with food waste because animal products have a higher emission intensity in comparison to crops,” he said.
By 2050, Pradhan and co-author Jürgen Kropp project that carbon emissions from food waste alone could top over 2 billion tons a year. As huge as that sounds, the true environmental cost is actually even bigger. This measurement only counts carbon emissions; it doesn’t even begin to touch the amount of water, land, time, and sheer effort it takes to grow food that is ultimately thrown away.


The obvious solution is to reduce food waste itself, but unfortunately, that’s a complicated problem. Do you focus on the manufacturers and farmers to make things more efficient? Or maybe the grocery stores and restaurants that sell our food? Or perhaps you go even smaller, to the fridges and cupboards where our lettuce wilts and our cereals go stale.
The ultimate answer is that we need to do all of the above. Food waste is a distribution problem, a consumption problem, and a planning problem, and so to have any hope at stopping it, we’ll have to reduce waste at every link in that chain.
NASA’s Jet Propulsion Laboratory has a long and colorful history in rocketry and space exploration, from early missiles and rockets, to landing on the moon and remotely navigating rovers on Mars. Behind all the prominent men who spearheaded the programs was a group of unsung women.
The forgotten women of JPL now have their own book, Rise of the Rocket Girls: The Women Who Propelled Us, From Missiles to the Moon to Mars, thanks to microbiologist turned author Nathalia Holt. Recruited in the 1940s and 1950s, these mathematically gifted women defied the cultural gender roles of the period to serve as human “computers.” It was their job to crunch the numbers that made all those missions possible. Gizmodo caught up with Holt to learn more about how she brought their remarkable stories to life.


Gizmodo: What inspired you to write a book about these women?
Nathalia Holt: It was a random coincidence. We were trying to decide on a name for our daughter when we came across Eleanor Francis Helin—an incredible astronomer [in JPL’s Near-Earth Tracking program] who discovered all these comets and meteors. She died in 2009. I never met her, but I couldn’t stop thinking about her. It’s because of her that I ended up learning about the women “computers” [at JPL]. I became obsessed with them. I didn’t think about a book at first. I just wanted to learn more. I was very lucky to be able to find so many of these women—there are very few records [in the archives].


Something magical happened there. But these women really haven’t gotten the recognition they deserve. At the fiftieth anniversary of Explorer I, the women who were in Mission Control [at the time] weren’t even invited. So in 2013 I held a reunion [of the JPL computers], and they flew in from all over the country, revisiting the buildings and Mission Control where they all have such fond memories. It was nice to see their contributions honored.


How did you manage to track them down? It can’t have been easy.
Holt: It was quite difficult. The JPL archives had all these great photographs, but they didn’t know who was in the pictures, and they had very little information about them. I ended up calling a ridiculous number of people. I like to joke that if your name is Barbara, Virginia, or Helen, it’s very likely that I’ve called you. I called something like 50 Barbara Paulsons. It was so exciting when I finally found the right one. And once I found a few key members, it all fell into place, because they are all still friends today.
This was a unique period for women in American history, with so many women going to work while the men were fighting overseas. Apparently NASA was no exception.


Holt: Yes. You could see it happening at NASA centers all over the country: women filling these roles that they would not have gotten otherwise, because of their expertise in mathematics. Other women at NASA centers ended up losing their jobs for the most part when IBMs [computers] came along. What was different at JPL is that they didn’t leave once the men came back from the war. They had very long careers. One of them still works there as NASA’s longest serving woman: Sue Finley. She turns 80 this year and is still working on the Juno mission to Jupiter. She doesn’t want to retire until it’s completed. Even after that, I’m not entirely sure she’ll retire. She loves working there.
One of the most powerful stories in the book is that of Janez Lawson, the sole black woman in the group at a time when even black men struggled to find work as scientists and engineers.


Holt: [Lawson] was an incredibly bright young woman who graduated from the University of California, Angeles, with a degree in chemical engineering. When she first came to JPL, there were questions, because this was the first African-American they were hiring in a technical position at the lab. They wondered if she would fit in. Macie Roberts was the supervisor of the group and vouched for her. She wanted to make sure her education and expertise wouldn’t go to waste, so [Lawson] was one of only two women sent to the IBM [computer] training program. Unfortunately she passed away before I had the chance to talk to her, but was able to track down friends and family.
She certainly had much more to contend with than the other women, not just because of the color of her skin, but because of the geography of where she lived. She commuted from Los Angeles to JPL every day—quite a long commute, with freeways being what they were at the time. She went on to have an amazing career in chemical engineering.
I assume this group of women faced many issues that are still relevant today, from sexual harassment and overt discrimination, to juggling work and family, and encountering gender bias. How did they deal with all of that?


Holt: There [are stories of] sexual harassment in the book—aeronautical engineering is a very male-dominated field, even today— but this was a strong group of women with a woman supervisor. I think they did a remarkable job looking out for each other. And the men at the lab came to accept them as colleagues. Some male engineers even brought them onto studies and included them as co-authors on publications. At the time that was not common at all, and it really changed their career options.
Most of the women I talked to felt very strongly about the role of mentoring the next generation. I was especially impressed with the case of Helen Ling, who supervised the computers in the later years. She made a point of bringing in women who didn’t have the education to be hired as engineers. She encouraged them to go to night school and watched them be promoted out of her group [after they graduated] to become engineers. [At the reunion] there were so many women who came up to thank her for what she had done.
Your book features a quote by pioneering female astronaut Sally Ride: “I did not come to NASA to make history.” Why did you choose to include it?


Holt: Most women in the 1960s didn’t work outside the home. What speaks to me about that epigraph is that they were there because they loved what they were doing. They were very skilled, very good at math, but they were a humble group of women who just loved being part of NASA missions. They didn’t come to NASA to make history.
Ten years ago, billions of humans had their worldview upended when a group of astronomers announced that the solar system only contains eight planets. Now, the same guys are trying to rewrite our childhood mnemonics once again. A ninth planet may exist after all, and it isn’t Pluto.
In January, Caltech’s Konstantin Batygin and Mike Brown (the astronomer credited with killing Pluto) shared compelling evidence of a planet larger than Earth and over five hundred times further from the Sun. Planet nine hasn’t been spotted—its existence is inferred by the improbable orbits of a handful of distant, icy objects. A race is on to find the mysterious world, and help is coming from all corners of the astronomical community.


“I’ve never seen anything like this happen before,” Brown told Gizmodo. “People look at the evidence and they are convinced. It almost makes me worried.”
Planet nine’s overwhelmingly positive reception is indeed rather odd. This isn’t the first time astronomers have speculated about a distant world sitting in or beyond the icy ring of primordial rocks known as the Kuiper belt. They’ve been doing so for decades. As Brown puts it, “Anytime anything funny happens in the outer solar system, somebody will jump up and down and say planet.”
But in every prior instance when astronomers have cried planet, the case has unraveled upon further analysis. This time, the evidence has only grown stronger. The first hint came in 2003, when Brown spotted a 600 mile-wide object circling the Sun on a highly elliptical path, far beyond the outer limit of the Kuiper belt.
Sedna, named after the Inuit goddess of the sea, was the coldest, most distant known object to orbit the Sun, and nobody could explain how it got there. In a paper published the following year, Brown and his colleagues speculated Sedna could have been dragged into its extreme orbit by a passing star or an unseen planet. For more than a decade, it remained an isolated curiosity.


Then in 2014, astronomers Chad Trujillo and Scott Sheppard announced the discovery of another distant object on a Sedna-like orbit, followed by a set of six Kuiper belt objects that share a bizarre orbital feature. Each of these icy rocks traces an elliptical path that loops out in the exact same part of the solar system. What’s more, all of their orbits are all tilted the same direction, pointing about 30 degrees down relative to the ecliptic plane (the plane in which planets orbit the Sun).
Based on our understanding of Kuiper belt dynamics, any one of these orbits is extremely unlikely. The chance of all six being some sort of grand cosmic coincidence? Approximately one in 14,000.
That’s when Batygin, a theoretician, and Brown, an observer, decided to put their heads together. “Our initial goal was to demonstrate that this was not a planet—that it’s some other dynamical effect,” Batygin said.
And yet, after two years of calculations and supercomputer simulations, a planet is what they found in the math. It turns out Sedna, all six Kuiper belt objects, and a handful of other weird rocks that orbit perpendicular to the plane of our solar system, can all be explained by a distant planet roughly ten times the mass of the Earth. “What we’re really predicting here is not just the existence of a planet, but a physical process through which the shape of the outer solar system is explained,” Batygin said.


According to Batygin and Brown’s calculations, Planet nine sits in an elongated, “anti-aligned” orbit—its point of closest approach to the Sun is directly opposite that of all other planets. It takes the frigid world 10 to 20 thousand years to complete a full orbit, and at its furthest point, it’s roughly 1,200 Earth distances (a hundred billion miles) away.
In January, Batygin and Brown published their findings in the Astronomical Journal. The announcement that a ninth planet may exist after all was not only embraced by the millions of laypersons who could finally fill the dark, Pluto-shaped holes in their hearts, but also by the scientific community. Folks with expertise ranging from the Big Bang to Saturn’s rings started asking whether a phantom planet may be lurking in their data.
At this point, if astronomers are correct about Planet nine, it’s only a matter of time before we find it.
The obvious way to prove the existence of a planet is to actually see the thing. In Planet nine’s case, that’s going to be tricky, because objects thirty times further from the Sun than Neptune on a good day don’t reflect a lot of light. But Brown, who’s built a career around finding small, distant Kuiper belt objects, is optimistic that Planet nine can be spotted.


“In principle, this is exactly the same thing we do to look for KBOs,” Brown said. “You take a picture, go back, take another picture later, and see if something moved. If you told me exactly where Planet nine was, I could find it pretty easily.”
The trouble is, we don’t know where Planet nine is, and its entire orbit is freakin’ enormous. And while astronomers can bag hundreds of random Kuiper belt objects by simply pointing a telescope at the sky, finding a specific object way off in the cosmic boondocks is going to be tougher.
“For KBOs, we’re interested in a statistical sample,” Brown said. “For Planet nine, we just want to find it. So we have to be very systematic about surveying the sky, and we can’t leave any patch undone.”


The best instrument for this job—both in terms of sensitivity and wide field of view—is Subaru, an 8.2 meter optical-infrared telescope located on the dormant volcano of Mauna Kea, Hawaii. Batygin and Brown have already put in a request for time on the popular telescope this fall. Meanwhile, several of their colleagues are bringing the southern hemisphere into the planet hunt, using a well-placed dark energy camera at an observatory in Chile.
But you don’t need to be good with a telescope to help find Planet nine. Agnès Fienga, a planetary dynamicist at the Nice Observatory in France, has an entirely different take on how we can locate the beast— NASA’s Cassini probe.


Since 2003, Fienga and her colleagues have used radio ranging data collected by the Cassini probe’s navigational system to precisely track the motion of Saturn. By doing so, they’ve constructed detailed models of the movement of all planets and major asteroids in the solar system. When Batygin and Brown published an orbital trajectory for a ninth planet, Fienga realized that her models could help narrow the search. “It’s not too complicated to add a supplementary planet and just test the theory,” Fienga told Gizmodo.
By sticking Planet nine in a solar system model calibrated with over ten years of Cassini data, Fienga and her colleagues have already ruled out half of the planet’s possible positions in the sky. “This study is awesome,” Batygin said, noting that the positions Fienga’s team eliminated include perihelion—the planet’s closest approach to the Sun. This independently confirms Batygin’s view that the planet currently sits in a more distant orbit.
Meanwhile, Nick Cowan of McGill University has thought of yet another way we can detect Planet nine—through its heat signature. Even an icebox of a planet like this one emits a small amount of energy at millimeter radio wavelengths. This turns out to be the same type of energy cosmologists use to study the birth of the universe.
“I am not an expert on Planet nine at all, nor am I a cosmologist,” Cowan, who studies the composition of exoplanet atmospheres, told Gizmodo. But when his colleague Gil Holder suggested that Planet nine’s heat signature might be detectable with the instruments used to study the cosmic microwave background (CMB)—the ubiquitous energy signature left over from the Big Bang—Cowan’s interest was piqued.


“I did a calculation, and came up with a surface temperature of 20 to 40 Kelvin,” Cowan said. That’s insanely cold, and it means Planet nine radiates about 2,000 times less heat than Uranus or Neptune. “I thought this crackpot idea would be over at this point,” he said.
When Cowan brought his calculations back to Holder, he learned he was mistaken. “Turns out, we use Uranus and Neptune to calibrate CMB [experiments] because they’re really bright,” he said. “2,000 times colder is totally doable.”
Cowan, Holder, and Nathan Kaib of the University of Oklahoma wrote up a paper on the idea, which is currently in review at The Astrophysical Journal. Cowan is hopeful that next-generation cosmology experiments will be able to detect Planet nine, or at least narrow the search. And if we’re really lucky, that faint heat signature might already exist in somebody’s CMB data.


Batygin, for his part, continues to run model simulations. Several weeks back, those models got a big boost when Michele Bannister of the University of Victoria, Canada, revealed yet another Kuiper belt object on the same funky orbit as Planet nine’s original flock of six. “Our biggest worry was that the next set of objects we discover are going to destroy the pattern—that our brains had somehow tricked us,” Batygin said. “Instead, the first new object is exactly where our models say it should be. It basically falls on the mean.”


Although we should save the champagne for hard proof, most astronomers agree that the case for a large, unseen planet beyond the Kuiper belt has never looked better. “I am not one hundred percent sure if there is a planet or not,” Fienga said. “But I think in a year we should have almost a definite answer.”
And if we do discover a Planet nine? It’ll certainly expand our perspective on the solar system, just as discoveries of Kuiper belt objects did in the early 2000s. It’ll help us piece together our celestial history—how the planets formed, why they’re all so different, and how they arrived in their present orbits. And it’ll shed light on the diversity of worlds we can expect to find orbiting other stars.


“The most exciting thing about Planet nine to me is that it’s uncharted territory,” Cowan said. “You do the math and realize, you could easily hide a planet out there, maybe more than one. Nature is amazingly good at making planets, and she puts them wherever the hell she wants.”
Batygin agrees. “I think the one thing we we can be certain of,” he said, “is that the solar system hasn’t run out of mysteries.”
Correction 4/9/16: An earlier version of this article stated that Batygin and Brown published their recent findings on Planet nine in the Astrophysical Journal. In fact, it was the Astronomical Journal. The text has been corrected.
YouTube scientist Mark Rober and molten metal obsessive BackyardScientist teamed up to answer a simple question: is a grenade deadlier on land or under water? But in order to answer that, we need to understand exactly what a grenade does.
The metal casing of a grenade is designed to fracture at specific points so that, when detonated, it essentially becomes irregularly shaped bullets that fly in all directions. Getting hit by those is bad! But there’s also a pressure wave thats created from the explosion itself.


On dry land, laying down—feet towards the blast—at least 15 feet away minimizes your chances of getting hit by shrapnel. But underwater the drag force is much, much higher than air, so shrapnel, high-powered bullets, and bad swimmers don’t travel very far.
The explosion also causes a serious pressure wave, however. Air can be compressed much more than water, which means that the explosion dissipates easily on land. Underwater though, it travels straight through the water and hits you full force where it meets something that it can compress—specifically, the air in your lungs and other organs. As you can guess, that’s really bad news for your lungs if you like them unruptured and lunging normally. At 15 feet you would be 100 percent dead.


Of course, the most advantageous version of this scenario is being underwater while the explosion occurs on land. It happens in just about every action movie, which is how you know its true.


Metal foams are light and surprisingly tough. Actually, make that very tough: In this video, a composite metal foam turns an armor-piercing bullet to dust on impact, as if it were a piece of chalk.
The experiment was performed by researchers from NC State, led by Afsaneh Rabiei. It saw a M2 armor-piercing projectile—0.3 inches in diameter—being fired at a lump of metal foam. Rabiei explained to PhysOrg what happened:
“We could stop the bullet at a total thickness of less than an inch, while the indentation on the back was less than 8 millimeters. To put that in context, the National Institute of Justice standard allows up to 44 millimeters indentation in the back of an armor.”
Which, wow.


These metal foams can be made in many different ways. Some are manufactured by bubbling gas through molten metal, while others cast metallic alloy around hollow metal spheres to provide voids.
Either way, metal foams—which have existed in one form or other for decades now–seem to finally be coming of age.
[Composite Structures via PhysOrg]
Food labels are notoriously confusing—but what if they simply told you how long it might take to burn off the calories you’re about to consume?
That’s the suggestion of the UK’s Royal Society of Public Health, at least, which is suggesting that food packaging could feature labels that show how many minutes of walking, running, cycling or swimming are required to use up the calories they contain. You can see some examples of how it might look in the images above. They call it “activity equivalent” calorie labelling.


“This is not meant to scare people, or to create a society of obsessives,” writes Shirley Cramer, Chief Executive of the Royal Society of Public Health, for the BBC. “But instead it is meant to show to the public very clearly just how active we need to be if we are to consume the diets we do and not put on weight. Or how we might need to readjust our diets to match our inactive lives.”
It’s not a bad idea—especially given last week’s news that more people worldwide are now obese than are underweight. But there is a small problem: The rate at which we burn calories can vary rather a lot from person-to-person, based on weight and other physiological factors. These labels, then, would simply show an average.


It is for now just a suggestion. But as Cramer points out, it doesn’t have to require legislation to become prevalent—just for food manufacturers to dare tell us how long we need to jog for to counteract the candy.


[BBC]
What do you get when you combine a Broadway musical about The Wizard of Oz with two giants of physics? You get “Defining Gravity,” the latest music mashup video from A Capella Science.
As any Broadway aficionado can tell you, Wicked (the musical, as opposed to the book) focuses on the unlikely friendship between two young girls at school: Elphaba—who grows up to become the Wicked Witch of the West—and Galinda, who becomes Glinda the Good Witch. “Defying Gravity” closes Act I, when the two best friends must go their separate ways.


A Capella Science has brilliantly re-imagined this critical scene to focus on the two great physicists behind the theory of gravity: Isaac Newton (Dianna Cowern, a.k.a. The Physics Girl) and Albert Einstein (Malinda Kathleen Reese). The lyrics celebrate how each man changed our understanding of this fundamental force of nature, and Einstein’s dream of one day unifying all four fundamental forces in a single theory (“the world around me traced in geometric means”).
The wigs and Reese’s fake mustache alone make it worth your while. (You can watch the Broadway version here.)

Are you tired of hearing about how awesome it is that we’ve discovered gravitational waves? LIGO is …
Non-Newtonian fluids are liquids that are also sort of solid but also sort of neither but also sort of both? They’re very thick liquids or very giving solids, depending on what you want to call it. That’s why they’re so fun to do science experiments with. The Backyard Scientist went and filled up balloons with non-Newtonian fluids and ripped a chainsaw through them, shot a BB-gun at them, and fired off a golf ball cannon at them too.
He wanted to compare how non-Newtonian fluid would react vs regular ol’ water in the same situation. Let’s just say the non-Newtonian fluid explosions were so much better (and they acted like a solid).


The adorable gray mouse lemur weighs just 1.5 to 3 ounces, but its tiny frame belies its impressive strength. French researchers put the creature’s grip to the test and found, on average, that mouse lemurs can pull more than ten times their own body weight.
While the species (Microcebus murinus) thrives only in Madagascar in the wild, there is a large captive population of gray mouse lemurs at ENS de Lyon in France. Graduate student Pauline Thomas wanted to explore just how these tiny animals managed to hang onto tree branches so tightly with their itsy-bitsy arms, so she and a few colleagues designed an experiment to measure the mouse lemurs’ grip strength. Their results were recently published in the Journal of Zoology.
They collected 62 mouse lemurs, male and female, and had them grip a lemur-sized iron bar mounted to a force plate. This measured just how much force the lemurs could exert on the bar as they were forcibly tugged in the opposite direction. Those numbers were then compared to the creatures’ body measurements.


The lemurs proved to be quite the remarkable athletes, able to pull ten times their own body weight. For comparison, mice can manage less than one-quarter their body weight, while rats look like utter weaklings, able to pull just 7 percent of their body weight. The longer a lemur’s forearms, and the heavier its body, the more force it could exert with its grip. The older the animal, the weaker its grip. There were no significant strength differences between males and females.
Why does such a small animal need such a mighty grip? Co-author Anthony Herrel hypothesized that it might be an evolutionary adaptation to their tree-branch centric lifestyle. “To walk on narrow branches you need to be able to grip really well, as otherwise you will topple sideways,” he told Discover.
[Journal of Zoology via Discover]
SLAC’s National Accelerator Laboratory is already home to the world’s brightest X-ray laser—but it’s getting an upgrade. The $1 billion project will see the device become 10,000 times brighter and 8,000 times faster.
The X-ray laser will eventually throw out up to a million pulses per second. That will allow it to probe the the atomic world in unprecedented detail—analyzing, for instance, how bonds form, the way in which reactions take place or the movement of electrical charge.

The facility will be built alongside the existing X-ray laser. But instead of creating laser pulses by accelerating electrons down copper pipe, it will push them through niobium metal cavities held at minus 456 degrees Fahrenheit. That process creates “an almost continuous X-ray laser beam with pulses that are 10,000 times brighter, on average, than those of [the original laser] and arrive up to a million times per second,” according to SLAC.


“[It]will take X-ray science to the next level, opening the door to a whole new range of studies of the ultrafast and ultrasmall,” explained SLAC’s Mike Dunne in a press release. “This will tremendously advance our ability to develop transformative technologies of the future, including novel electronics, life-saving drugs and innovative energy solutions.”
[SLAC]
Artist David Hockney once stirred up controversy by asserting that many of the great Dutch masters—folks like Vermeer and Ingres—had relied on optical drawing aids to create their masterpieces. Now everyone can channel their inner Dutch master with the LUCY drawing tool.
It’s designed by Les Cookson, an artist and inventor who has been building, researching and designing optical toys and tools for over 10 years. Conceptually, LUCY is based on the camera lucida, an optical artist’s aid invented by an English physician named William Wollaston in 1807.


The earliest camera lucida was basically an extendible tube with a reflecting prism and sighting lens, mounted on a stick that could be attached to a drawing table or surface. The prism was deliberately shaped and oriented so that the rays of light from the scene were reflected twice within the prism before reaching the eye.
This way, the eye sees the image the right way up, rather than inverted, which is what happens with your typical camera obscura (i.e., a simple pinhole camera). When the stand is adjusted so that the prism half covers the pupil of the eye, the artist has the illusion of seeing both the object – which is reflected through the prism – and its outlines on the drawing board.
According to Cookson’s Kickstarter page, “When you look through the LUCY’s view hole, optical mirrors create a transparent “ghost” image of the scene in front of you reflected down onto your canvas or paper. Just draw or paint over the reflected image to get the correct perspective, foreshortening, proportion, position, overlap, shape.”


This isn’t the first company, or even the first Kickstarter, to offer a modern take on the camera lucida: back in 2014, art professors Pablo Garcia (Art Institute of Chicago) and Golan Levin (Carnegie Mellon) designed the NeoLucida and sold the drawing aid for about $50.
Cookson outlines several benefits of LUCY over similar tools. You can adjust the brightness of the image as needed, as well as the the height. And it’s flexible enough that you use the device while sitting at an easel (or a table), or while standing.
One caveat: even these modern incarnations of the camera lucida require a bit of skill to use. Remember, it doesn’t actually project an image of the subject onto paper; the image seems to appear on the drawing surface only when the artist looks straight down into the prism. And even slight movement of the head will cause the image to move, disrupting the accuracy of the tracing.
That’s why NeoLucida has a special instructional page for users that really emphasizes this particular point: “Don’t look into the prism! Instead, look down past the edge of the prism. You should be looking at your real hand, and see a ghost image of your subject. Looking straight down is absolutely critical to using a camera lucida properly! If you don’t see your pencil and paper, you’re not looking straight down. If you see your subject upside-down, you’re not looking straight down.”
Got that?


The LUCY Kickstarter closes in a couple of days, but Cookson has already raised more than $66,000—far above his original $12,000 goal—and expects to start shipping the tools in July.


[Boing Boing]
In 1820, a sperm whale attacked and sank the Essex, a whaling ship from Massachusetts. The incident inspired Herman Melville to write Moby Dick, and marine biologists have been wondering ever since if the whales actually engage in ramming behavior. A fascinating new study suggests this may be the case.
Sperm whales have the most unique foreheads in the animal kingdom. It consists of two large oil-filled sacs known as the spermaceti and the junk (yes, really). These sacs are stacked on top the other, extending for one-third of the total length of the whale and accounting for more than a quarter of its mass. A new study published in PeerJ demonstrates that this structure is tough enough to be used by males in ramming combat.
The so-called “ramming hypothesis” has been around since the 19th century, but very little data, exists to support it (aside from some anecdotal accounts). The basic idea is that male sperm whales engage in combat to gain access to females. There may be some truth to this; only the males boast the prominent forehead.


Aside from the dearth of empirical evidence, a central problem with the theory is that the spermaceti performs a number of valuable functions. It contains sensitive anatomical structures required for echolocation, acoustic sexual selection (the famous whale song of the sperm whales), acoustic prey debilitation, and buoyancy control. These structures could be seriously damaged during ramming events, calling the hypothesis into question.
Humpback whales are renowned for their ability to produce songs of remarkable beauty, complexity,…
But the researchers say it’s the junk—and not the spermaceti—that gets in the way during ramming combat. According to Australian evolutionary morphologist Olga Panagiotopoulou and her colleagues, the junk acts like a powerful shock absorber—one that significantly reduces the stress placed on the bones and skull during impacts. Her team’s analysis shows that the connective tissue partitions within the junk reduces stresses across the entire skull.
Using computer models and structural engineering principles, Panagiotopoulou demonstrated that this was in fact the case. By simulating ramming impacts, the researchers were able to record where ramming impacts would produce the most stress. What’s more, when the vertical tissues that comprise the junk were removed, the overall stress exerted on the skull increased by 45 percent.


“Although the unique structure of the junk certainly serves multiple functions, our results are consistent with the hypothesis that the structure also evolved to function as a massive battering ram during male-male competition,” wrote the researchers.
A mechanical explanation isn’t sufficient to prove function or behavior, but other clues exist. Marine biologists have previously observed scar tissue in surface areas corresponding to the male whales’ junk (no, not that junk, the other junk). And back in 1997, wildlife pilot Sandra Lanham actually saw males engaging in ramming combat. Here’s her account:
The converging whales swam to one another without obvious speed changes or deviations in course, making occasional shallow dives. About 20 feet from one other [sic], the smaller one shallow dove and a split second later, the big one did also. Leveling under water, they rammed head to head. There was surprisingly little splash on the surface. One slid to the side of the other so that their heads and upper third of their bodies overlapped. They rolled slightly, turning their bellies toward one another. It appeared that each had his mouth opened wide. It was my impression that they were trying to lock jaws or to bite one another’s head. At the exact moment their heads touched, I took another waypoint.
It took the whales about 11 to 12 minutes to reach one another and ram, which means they were probably travelling about 10 to 11 mph (16 to 19 km/hr) when they hit. Flying directly above, Lanham was in a perfect position to observe the event. As Panagiotopoulou noted in a Plos Blog article, “When ramming events occur in shallow depths, a human observer has to be directly above the surface of the water to watch it happen. The observation from 1997, coupled with the reports of ramming attacks on 19th century whaling ships, suggests that sperm whales do sometimes participate in ramming contests.”
This study doesn’t prove beyond a shadow of a doubt that male whales engage in ramming behavior, but it certainly makes a strong case. Clearly, more observations from the field will be required before we know for sure.


[PeerJ via Plos Blogs]
Two months ago, astronomers picked up and then pinpointed a location of a weird burst of radio waves from space, prompting heated debate about just what was sending them. Now, new data has finally revealed that source.
“Part of the scientific process is investigating findings to see if they hold up. In this case, it looks like there’s a more mundane explanation for the original radio observations,” Harvard astronomer Peter Williams said in a statement. He is co-author (along with Harvard colleague Edo Berger) of a paper that has just been accepted by Astrophysical Journal Letters. That “mundane explanation” turns out to center around a supermassive black hole.


For the last nine years, astronomers have been documenting a series of weird pulses of radio waves sent from somewhere far, far away. These aptly named Fast Radio Bursts (FRBs) last only milliseconds. They’re almost always detected after they’re over, which makes figuring out where they came from a challenge.
That’s why it was so surprising when scientists were able to not only find an FRB happening in real time, but that they were also able to quickly identify its location: a galaxy 6 billion light years away. A debate quickly followed over the root source of these FRBs, and others like it. Skeptical scientists posited alternate explanations for the tracked FRB—and now, it turns out that one of the skeptics might be right.


After the FRB was documented, Williams and Berger from the Harvard-Smithsonian Center for Astrophysics quickly used the Very Large Array’s group of radio telescopes to get a better look at the galaxy where the signal originated. They were surprised to find that the signal was still going strong.


If it had, indeed, been a FRB, then the signal should have dwindled out rapidly after the burst. Instead, what they were seeing was cyclical, with radio emissions becoming stronger before dimming again. The source also soon became a clear: A massive black hole at the galaxy’s center, which was spewing out bursts of radio waves. Think of it as kind of a black hole afterglow.
What it most certainly is not, is a FRB. There’s still a long record of these odd cosmic signals going back years. In those cases, the origin remains a mystery.

If we want to know what sorts of creatures will survive the next mass extinction, the best place to look is the fossil record. After examining the bones of Lystrosaurus, a vertebrate that famously thrived during the worst apocalypse in the history of life on Earth, a team of paleontologists think they know how it managed to adapt.
A new study suggests that thousands of species on Earth going extinct at a rate that far exceeds…
Lystrosaurus is a lineage of mammalian ancestors that flourished some 250 million years ago. If you know your Earth history, you’ll know that timeframe coincides with the end Permian extinction, wherein a series of volcanic eruptions sent billions of tons of carbon into Earth’s atmosphere, triggering runaway climate change and the largest extinction event of all time. Some 70 percent of all terrestrial species and 80 to 96 percent of all marine life perished as our planet transformed into a noxious hellscape.


A study published today in Scientific Reports sheds light on how Lystrosaurus defied death, earning itself the nickname “disaster taxon.” Analyzing the bone microstructure and body size distribution of Lystrosaurus fossils both before and after the Permo-Triassic boundary, paleontologists at the Field Museum learned that these ancient animals survived radical climate change by radically altering their life history strategy. Their lifespans shortened, and they shrank hundreds of pounds, from the size of a pygmy hippo to that of a large dog.


“Before the Permo-Triassic extinction, the therapsid Lystrosaurus had a life span of about 13 or 14 years based on the record of growth preserved in their bones,” study co-author Ken Angielczyk said in a statement. “Yet, nearly all of the Lystrosaurus specimens we find from after the extinction are only 2 to 3 years old. This implies that they must have been breeding when they were still juveniles themselves.”
These changes seem to have paid off. Combining their fossil findings with ecological simulations, the study’s authors showed that by breeding younger, Lystrosaurus may have increased its chance of survival by up to 40 percent. As Earth’s land masses emptied of biodiversity, Lystrosaurus spread far and wide, becoming the most abundant vertebrate on the planet.


This mammalian forerunner’s ancient evolutionary win is relevant in light of our current global predicament. Almost a year ago, scientists confirmed that we’re definitely in the early stages of a sixth mass extinction event—a very rapid die-off of species that could lead to ecological collapse. Hopefully, the transition from the Holocene to the Anthropocene won’t be as catastrophic as the end Permian, but one does have to wonder if the survivors will learn to live fast and die young.
History does, after all, have a way of repeating itself.
[Scientific Reports]
Using genetic techniques and a chemical cocktail, scientists managed to sustain a pig’s heart inside a baboon for 945 days, establishing a new benchmark for cross-species transplantation. If extended to humans, the technique could be used to ease the ongoing organ shortage.
Cross-species transplantation, or xenotransplantation, is proving to be a tough challenge. The primary obstacle for researchers has been the strong immune reaction of recipients, resulting in organ rejection. To date, typical survival times for species-to-species transplants—such as pig hearts being transplanted to baboons—have been limited to the 180 to 500 day range, which is frustratingly brief.


Now, as a new Nature Communications study reports, an international team of researchers has finally extended organ survival time to beyond the two-year mark, and they did so using a hybrid technique involving both genetics and powerful new immune-suppressing drugs. In future, a similar technique could be applied to humans, easing the demand for organs for transplants. In the U.S., there are about 122,000 people on the transplant waiting list at any given time, of which thousands die each year. Pig hearts are ideal candidates for transplantation owing to our similar biologies, and our extensive knowledge of porcine DNA.
For the experiment, cardiologist Muhammad Mohiuddin from the National Institutes of Health in Bethesda, Maryland, and his colleagues implanted a pig heart into a baboon. The pig organ did not replace the baboon’s heart, but was instead connected to the baboon’s circulatory system where it was monitored for more than two years. Baboons are typically used in studies like this because they’re closely related to humans; if it works in a baboon, it’ll likely work in a human.


To help the baboon avoid organ rejection, the researchers used a previously established line of donor pigs with three key genetic modifications. These genetic tweaks were baboon-friendly, allowing a significant degree of immune tolerance among the primates. To supplement this, the researchers improved a treatment based on antibodies and drugs to control the baboon’s immune system.


In the study, five baboons received pig’s hearts. The implanted organs were maintained as long as the recipients were administered the immune-suppressing drugs. Of the five baboons, one managed to keep its implanted heart for a whopping 945 days. The median across the study was 298 days, so clearly more work needs to be done. Looking ahead, the researchers would like to use the same technique to replace a baboon’s heart outright.
As promising as this result appears to be, it may not represent the future of organ transplants. Aside from the ethical issues of growing organs in nonhuman animals, the rejection issue continues to be a problem. Even if this technique is eventually applied to humans, it would require human patients to stay on immune-suppressing drugs for the rest of their lives.
At the same time, there are several other methods currently under development that could solve the organ donation shortage, including regenerative medicine (e.g. growing your own organs from your own stem cells), bioprinting, and advances in cold storage (which would prolong the shelf life of donated organs).
[Nature Communications]
Rovers on Mars have captured images of dust devils before, but this might be the best one we’ve ever seen.
NASA’s Opportunity rover, which has been exploring the surface of Mars since 2004, snapped a stunning new dust devil pic on March 31, 2016. Like our planet, Mars features these columns of rotating hot air that pick up the sand and dust around them once they spin fast enough, making the vortex visible.
This almost artistic view of the dust devil looks back at Opportunity’s tracks leading up the “Knudsen Ridge,” which forms part of the “Marathon Valley.” During its trip up the slope, Opportunity managed a tilt of 32 degrees, which is the steepest for any rover.


Dust devils have largely eluded Opportunity during its mission. Its twin rover, Spirit, managed to witness a number of dust devils during its tenure on Mars. These mini-twisters are fairly common on the Red Planet and were portrayed with dramatic effect in The Martian. But as we can now see from photos of actual Martian dust devils, the special effects were pretty close to the real thing.
[NASA]
They may just be plastic, metal and wires, but robots can elicit... physical responses in humans. That’s according to a new study by researchers who analyzed what happened to volunteers when they touched automatons in areas that would be thought of as intimate on an actual human being.
A team of scientists from Stanford University has set up a series of experiments using a small Nao robot, reports The Guardian. The robot—whose shell is plastic—was programmed to ask ten different participants to either point to or touch one of 13 parts of its body. As that happened, the team also measured skin conductance of the participants, which correlates with physiological arousal.

The team found that the strongest signals of arousal were observed when participants were asked to touch the areas on the robot that would usually be home to genitals or buttocks—what the team amusingly call “body parts with low accessibility.” Being asked to point didn’t register any response, while touching more innocuous body parts created low-level responses. The research is being presented at the International Communication Association in Japan this June.


Speaking to The Guardian, Jamy Li, one of the researchers, explained:
“It shows that people respond to robots in a primitive, social way...Social conventions regarding touching someone else’s private parts apply to a robot’s body parts as well. The research has implications for both robot design and the theory of artificial systems.”
And, one suspects, implications for rather more... pragmatic players in the robotics industry.


[The Guardian]
The diode is a simple-sounding electronic device that allows current to flow easily in one direction but not the other. It’s a fundamental part of modern electronics and now the world’s smallest has been manufactured from DNA.
The new diode has been created by researchers from the Ben-Gurion University of the Negev and University of Georgia. There’s no such thing as a perfect diode, of course. In an ideal world, infinite current could flow along the component in one direction and zero in the other; in reality, the devices can’t carry infinite current and always allow at least a little to pass in the opposite direction, too.


The new diode is made from a single strand of DNA that’s just 11 base pairs long with a small molecule called coralyne inserted at strategic points along its length. That carefully designed set-up allows the scrap of DNA to work as a diode should, allowing a current 15 times larger to flow in one direction than the other. The research is published in Nature Chemistry.
How well a diode works is, of course, characterized—in part, at least—by the ratio of the forward and backward currents. This one isn’t as impressive in that regard as other single-molecule diodes that have gone before it. A team from Columbia University recently created one that allows just 1/250th of the forward-flowing current to to flow back through it.


But this new device does take the “world’s smallest” title, and offers up the possibility of shrinking down modern electronic systems to the molecular level—which is pretty damn exciting.


[Nature Chemistry via EurekAlert]
Your shirts may yet be spared your clumsy eating. A team of scientists has created a new kind of super slippery coating called X-SLIPS that can shed all kinds of water- and oil-based products—like ketchup and mustard!
The new coating has been developed by researchers from Pennsylvania State University and University of Illinois at Urbana−Champaign. It’s inspired, apparently, by the waxy coating the interiors of Nepenthes pitcher plants. That’s replicated in the lab by adding a 2.5-micron thick layer of fluorinated silane to a material’s surface, before adding a mist of DuPont’s Krytox lubricant, which is a bit like Teflon. Voila, mustard be gone.
In tests, which used foodstuffs like ketchup and mustard as well chemicals like kerosene, the coating allowed the the material it’s applied to to neatly shed the offending liquids. These gifs show the coating in action. The coating is also tough: The team damaged it using 40-grit sandpaper, but found they were able to restore its properties by simply heating the surface, which caused the silane to fill in gaps created by the damage all by itself.


It may be a while until it’s used to coat your shirt, sadly. But the team reckons it could be used to coat the lining of ketchup packs, to make the stuff slide out a little more easily.
[Applied Materials & Interfaces via Chemical & Engineering News]

On the list of first-world problems, not being bothered to plug in your Tesla is very near the top. Luckily for lazy Model S owners, the Department of Energy is on it.
Wireless charging has been around for years in cellphones, but it’s never really caught on, due to its low efficiency, lack of universal compatibility, and occasional stupidity. But for cars, it makes a ton of sense: unlike phones, we tend to leave our cars in exactly the same space when we’re not actively using them.


Unfortunately, wireless charging for cars is more difficult than phones, due to the higher wattage necessary. The Department of Energy’s Oak Ridge National Laboratory has made a recent breakthrough on that front that shows promise, with a proof-of-concept 20kW charger working at 90 percent efficiency. That’s enough to put 60 miles of charge into a Tesla every hour, right on par with Tesla’s own home chargers.
Wireless charging isn’t ready for the prime time yet—the ORNL’s proof of concept is still just that—but it’s likely to be an important stepping stone for getting more people interested in electric vehicles.


Without major leaps in battery technology sometime soon, charging a battery is going to remain slower than filling a tank with gas, so anything that can make topping up an EV’s battery easier will be welcome. No-one’s going to bother plugging in a car while they run into a drug store, or wait in line at a drive-through, but wireless charging would do just that, without any effort from the driver.


There’s also autonomous cars to consider. A self-driving car than needs a human to plug it into the wall would be annoying, or require some Roomba-esque docking system. But with wireless chargers, autonomous cars would be free to roam and recharge as needed, all without human intervention. Even Skynet needs wheels sometimes.
[ORNL]
The placebo effect is real, we all know that. Our bodies can be tricked into getting better and healthier even when we’re take taking sugar pills or fake drugs or undergoing treatment that isn’t even supposed to help us get better. If we believe it will help, it sometimes really does help. Ted-Ed dives in a bit on the mystery behind the phenomenon and how the placebo effect is proof of how the human body is extraordinary but also how it’s not always a good thing.

Animals have evolved all sorts of different ways to carry around their young, but scientists have never seen anything quite like this before.
This bizarre creature lived about 430 million years ago in what is now England. It goes by two names, the formal Aquilonifer spinosus and the informal “Kite Runner,’ named in honor of the 2003 bestselling novel of the same name. The researchers who discovered the creature thought the name was apt given its unique brooding style, in which it carries around its young in tiny pods tethered to its body like kites. The details of this discovery can now be found in the Proceedings of the National Academy of Sciences.
Normally, crustaceans protect their eggs and embryos by attaching them to their limbs, or by enclosing them with a special pouch. But this particular brooding style is completely new to scientists. As noted in a press statement by Yale paleontologist and lead author Derek Briggs, “Nothing is known today that attaches the young by threads to its upper surface.”


Only one fossil exists of A. spinosus. The lone adult specimen measures less than a half-inch long, and features an eyeless head covered by a shield-like structure. It lived on the seafloor during the Silurian period along with sea sponges, brachiopods, worms, snails, and mollusks. The fossil also contained 10 juvenile arthropods at different stages of development. Each of them were connected to the adult by a single thread.
The scientists considered the possibility that the tiny creatures were actually parasites, but the unwieldy configuration couldn’t have been conducive for sucking up nutrients. The only viable explanation for the tethered configuration was a novel form of brooding.
“As the parent moved around, the juveniles would have looked like decorations or kites attached to it,” noted Briggs. “It shows that arthropods evolved a variety of brooding strategies beyond those around today—perhaps this strategy was less successful and became extinct.”


[PNAS]
It makes sense that a warming planet would have warmer winters with less snow and more rain. But a new report points to how a disturbing trend of increased winter rain is actually endangering the year-round water supply in some parts of the country.
A new Climate Central report out today examined 65 years of winter precipitation data in 42 states. In every single region there was a decrease in the amount of precipitation that fell as snow, including some disturbing decreases in certain high elevations of the Northwest which depend on deep snow to replenish water supply.
The biggest concern about warm winter precipitation is that it can bring about a disastrous phenomenon called “rain on snow” where rain falls on previously accumulated snowpack. Normally this happens in spring, when it’s simply part of the hydrological process of breaking down the snow and moving it into streams that transport the water down to lower altitudes. But when it happens too soon, it melts the snowpack prematurely. And you want that snow to stick around for as long as possible so it melts slowly, releasing water into local streams long into the warm summer months.


There are a lot of other reasons why rain that should be snow is bad. Too much winter rain can destabilize the ground, leading to more floods and mudslides. Stream flows can be disrupted by both too much and too little water, which messes with the habitats of fish and other wildlife. And less snow on the ground come spring means overall reduced soil moisture, leaving forests drier and making conditions more dangerous for wildfires.
There as was a lot of talk about rain on snow this winter as part of the gamble of pinning drought relief on El Niño’s warmer-than-average storms. It’s true that the El Niño-affected Northwestern states of Washington, Oregon, Idaho, and Montana saw the biggest increase in winter precipitation that fell as rain in this particular study. But it’s unlikely that this is just a temporary El Niño thing, something you can easily see evidenced in the rapidly retreating glaciers of Glacier National Park over the last few decades. Since 1896, winters in the contiguous US have warmed by about 2.5 degrees Fahrenheit and as we’ve seen over the last few years, the planet has no immediate plans to cool down.
[Climate Central]

Approximately half of the content on the internet is cat videos, but the BBC managed to capture one that’s truly remarkable: high-speed footage of a wild Caracal as it deftly manages to spin itself around midair in order to land safely on its feet.
Even if you’ve seen every last cat video on the web, you’ve never seen anything like this.

The footage was captured for a new BBC series, Life in the Air. The clip reveals how a cat’s unique flexible spine, which can rotate in two different directions at the same time, allows it to flip around mid-flight to ensure its legs are always pointing down for a safe landing.


Cats also use a technique that figure skaters rely on to increase the speed of their mid-air spins. They pull their front legs in as they’re twisting, increasing the speed of the spin, which eventually causes their whole spine to align when their hind legs are pointing in the right direction. It’s Mother Nature’s engineering at its finest, and even if you’re not a feline fan, the footage is still jaw dropping.
[YouTube via Neatorama]
For more than fifty years, astronomers have pointed radio receivers to the sky and listened for signs of intelligent life—mostly, around stars like our own. Since that doesn’t seem to be working out so well, a team of SETI researchers is now proposing something radically different: scanning the oldest and dimmest stars in the galaxy.
Red dwarfs comprise roughly three quarters of all stars in the Milky Way. But despite their abundance, they’ve been given short shrift by researchers hunting for signs of extraterrestrial intelligence. Not anymore. Over the next two years, the SETI Institute’s Allen Telescope Array will scrutinize the vicinities of some 20,000 red dwarf stars, in one of the largest alien manhunts to date.


For decades, astronomers assumed that red dwarf stars—at best, only 10 percent as luminous as the Sun—simply cannot harbor life as we know it. A planet would have to be closer than Mercury is to the Sun to potentially support liquid water. And in such a tight orbit, that planet would be tidally locked: one side constantly lit and roasting, the other frozen in eternal darkness.
But in the past few years, new exoplanet studies have suggested that the prospect of finding a habitable world around a red dwarf star may not be as bleak as we thought.


“Based on the Kepler data, researchers have extrapolated that between 1 in 6 and 1 in 2 red dwarf stars might have a planet in the habitable zone,” Seth Shostack, a senior astronomer at the SETI Institute, told Gizmodo. What’s more, new theoretical work indicates that even if such a planet was too hot on its day side and too cold on its night side, a twilight band in between could be downright balmy.


And from a SETI perspective, if life is able to gain a foothold on planets orbiting red dwarf stars, it could mean red dwarf systems are the best places to search for advanced life forms. That’s because these stars are both extremely abundant (more chances for life to evolve), and on average, very old (more time for intelligence to emerge).
From a list of 70,000 candidate stars, astronomers will be scanning 20,000 over several of the so-called “magic frequencies.” These are spots on the radio dial that are related to basic mathematical constants, which an intelligent civilization might use to send out a deliberate signal.
A pessimist could argue that this survey, like the many before it, is extremely unlikely to turn up anything more than the background chatter of the cosmos itself. We have no way of knowing if intelligent life is out there, to say nothing of its interest in communicating with a bunch of barely space-capable mammals who seem to be teetering on the verge of a planetary apocalypse of their own making.
But we’ve only searched a tiny sliver of our cosmic backyard. “When you look at what’s been done, the total number of stars that have been examined carefully is a few thousand,” said Shostak. “This is a lot more.”


And what if we hit the lottery and discover a much older, wiser civilization that actually wants to chat? Maybe we can glean some knowledge about how to survive the next century. One can dream.
Scientists have theorized for decades that an additional state of matter exists, but despite tantalizing hints to its presence, details about this mystery state have remained elusive—until now.
A new paper in Nature Materials by researchers at Oak Ridge National Laboratory and the University of Cambridge details how physicists were finally able to catch a glimpse of the predicted quantum spin liquid, and the strange fermions that accompany it.


So, how did they do it—and just what is quantum spin liquid? Quantum spin liquid is a phase where electrons actually fracture apart—and begin to behave very strangely. As Gizmodo previously reported:
“We usually consider electrons to be fundamental particles, that is, indivisible into smaller components. But things get weird when you get down to two dimensions. In this space, quantum mechanics allows an electron to split into two (or three) smaller components, each carrying a fraction of the charge. They’re like bubbles that form in a quantum liquid.”
This video shows how similar processes work:

Normally, electrons in a magnetic field will align themselves so that as the material’s temperature approaches absolute zero, the electron poles will eventually face the same direction. Quantum spin liquids throw all of that out the window with the presence of Majorana fermions, which occur when electrons in a quantum spin state literally break apart. This creates strange patterns so hard to predict that, until this experiment, scientists weren’t even sure just what those patterns might look like.


By using neutron scattering on a graphene-like material, however, researchers were able to get a look at that pattern, and to finally confirm what paper coauthor Johannes Knolle described in a statement as “a new addition to a short list of known quantum states of matter.”
So, just what can we do with this new quantum state of matter—besides start updating our textbooks? The researchers also say that the Majorana fermions could eventually have some major quantum computing applications although, at least for now, simply even managing to see them is still an incredible challenge.
Since the early 19th century, many chess grandmasters have come and gone, some better than others. This elegant data visualization by Abacaba shows which players were the very best, and how long they were able to maintain their dominance.
Chess has been around for thousands of years, but it wasn’t until the early 19th century that the rules were finally solidified. Over the years, various systems have been used to rank professional chess players, including EDO (1809-1920), CMR (1915-2005), and the now convention ELO (2000 to current). To show how the world’s best players have performed over time in relation to one another, Abacaba placed these ratings along the vertical y-axis, as the x-axis charts their progress over time. The end result is as revealing as it is hypnotic.

As the visualization clearly shows, chess players have been getting progressively better over time, but who was the greatest of all time remains an open question. Wilhelm Steinitz held the mantle for nearly 28 years (1886-94, 1872-94, 1866-94), while Emanuel Lasker was the world’s best for nearly 27 years (1894-1921). More recently, Garry Kasparov held the title for 15 years (1985 to 2000).
Another way of measuring a player’s greatness is the discrepancy between first place and second place. The greatest gap between the top ranked player and the rest came in 1972 when United States-born grandmaster Bobby Fischer leapt way above the competition, achieving an ELO score just shy of 2900.
Looking at Garry Kasparov’s timeline (below), it’s clear he was no slouch either. Today, Norway’s Magnus Carlsen is dominating in similar fashion, which is why some chess experts say we now live in the Carlsen era.
Unfortunately, the Abacaba video does not include computers. It would have been neat to see the grandmasters compared to machines like Deep Blue, Rybka, and Pocket Fritz 4.


If you enjoyed this video, you’ll probably get a kick out of a similar visualization produced by Abacaba showing the top Go players in history.

[Abacaba]

With research that will make you wish you had studied a little harder in high school science class, engineers at MIT have revealed some delicious-looking experiments.
The latest batch of research at MIT hopes to better predict how thick the shell produced by a liquid coating will be. Inspired by master confectioners, who use melted chocolate to coat the inside of a candy mold, engineers were able to derive a specific formula that accurately predicts the thickness of a shell created by drizzling a liquid polymer solution over a dome-shaped mold.
Based on their data, the researchers developed a simple formula to estimate the final thickness of a shell, which essentially equals the square root of the fluid’s viscosity, times the mold’s radius, divided by the curing time of the polymer, times the polymer’s density and the acceleration of gravity as the polymer flows down the mold.
In simpler terms, it takes more time for liquids to flow around a larger mold, resulting in a thicker shell. But if the liquid takes a longer time to harden, more of the the fluid will eventually drain off the mold resulting in a thinner shell.

In addition to possibly revolutionizing the chocolate bunny industry, the research will eventually make it easier to precisely customize the thickness of the shells on pharmaceutical capsules for more effective delivery of medications. It even has the potential to change how airplane or rocket fuselages are created. Perhaps most importantly, it might also help ensure that one day all candies melt in your mouth—not in your hand.


[MIT News]
Earlier this year, we learned that Pluto’s heart-shaped region may have been formed when an asteroid the size of Manhattan smacked into the dwarf planet. Apparently, that violent origin story was just the beginning. Scientists now believe Pluto’s heart is so heavy that it caused the entire world to tip over millions of years ago.
Ever since New Horizons zipped past Pluto in July, we’ve marveled over the dwarf planet’s complex…
That’s the latest wacky hypothesis on our favorite dwarf planet’s most charismatic feature, which New Horizons researchers presented at the recent Lunar and Planetary science conference in The Woodlands, Texas. As New Scientist reports, the first clue that the Pluto we know and love may have suffered a terrible fall came from the observation that the west side of the heart—the smooth, crater-free surface known as Sputnik Planum—seems to line up perfectly with the tidal axis linking Pluto to its large moon, Charon.


You can think of this axis as an imaginary line connecting two worlds locked in a gravitational embrace. Sentimental folk may find it romantic that Pluto bears its heart at its celestial companion. But nature is cruel, and physics is unyielding. It’s more likely that Charon forcibly yanked Pluto into its present position, causing the entire planet to swivel hundreds to thousands of kilometers over millions of years.


At least, that’s exactly what we’d expect to happen if Sputnik Planum is indeed denser than the rest of Pluto’s surface. And several teams of researchers now think that Sputnik Planum is unusually dense due to its thick coating of nitrogen ice, or because the region is swollen with water from the mantle. Same result either way: Pluto got clobbered, its heart grew heavy, and it tipped over. If anything, Charon was an accomplice.
More work is needed to confirm the hypothesis. But if one thing’s clear, it’s that this little dwarf planetary system will continue to surprise us with its violent and storied past.


[New Scientist]
As many bartenders know, one of the secrets to a tastier drink is playing with fire.
Flaming an orange (or any citrus, really) is an old trick that looks impressive, but why does it work? First off, there’s a lot of flavor stored in the peel—that’s the whole reason you order drinks “with a twist.” That flavor comes from volatile oils stored in the skin’s many pores, including a compound called limonene. Besides having a strong orange aroma, limonene is a hydrocarbon just like petroleum, making it extremely flammable.


As for the introduction of a miniature fireball, its the same principle as many other foods: caramelization. Heat is what makes toast better than regular bread (if you disagree, fight me), and what turns a one-note orange flavor into a complex addition to a negroni variant. It’ll also impress the hell out of your friends.


Using stem cells, Japanese scientists have grown artificial skin that contains sweat glands and hair follicles. These highly realistic skin patches could eventually be used to treat burn victims and replace animals in the testing of chemicals.
Previous efforts to develop artificial skin have been limited in terms of realism and functionality, including an absence of hair follicles and glands that can secrete oil and sweat. A research team from the RIKEN Center for Developmental Biology, along with several other Japanese institutions, have jointly overcome these limitations, creating lab-grown skin that very closely approximates the function of normal tissue. The details of this work can now be found in Science Advances.
To create the artificial skin, the researchers took cells from mice and used chemicals to transform them into induced pluripotent stem cells (undifferentiated cells that can turn into any type of cell in the body). These cells were then transformed into skin cells by recreating the skin’s chemical environment. To create the desired functionality, batches of cells were produced to replicate real skin, including the epidermis, dermis, and subcutaneous fat layer.
After the tissues matured and differentiated, they were transplanted onto the skin of living hairless mice, where they developed normally. Not only that, the artificial skin made normal connections with the surrounding muscle nerves and fibers, allowing for normal function—including hair growth.


The researchers still need to iron out a few problems. For example, the new tissue can connect to nerve fibers, but it can’t make them. This could be a problem for patients with severe nerve damage. Also, the hair that grows on the transplanted skin doesn’t always align with the skin that appears on the rest of the body. In some cases, white-haired mice had black hair growing out of their new skin.
Realistically, it could be about a decade before this technique is used in clinical settings. But as lead researcher Takashi Tsuji noted in a press statement, “We are coming ever closer to the dream of being able to recreate actual organs in the lab for transplantation, and also believe that tissue grown through this method could be used as an alternative to animal testing of chemicals.”
[Science Advances]
You’re young and single and looking for love in New York City, and the usual online dating services haven’t panned out. A new matchmaking service has a crazy idea: It wants to let you choose a lover by letting you smell a bunch of t-shirt samples.
I know, it sounds like an April Fool’s prank. But apparently it’s real—albeit more akin to a fun project at the moment than a viable commercial business. Smell Dating is the creation of artist/teacher Tega Brain and editor/researcher Sam Lavigne. The idea is based on the science of pheronomes, chemicals secreted when the body sweats, which scientists believe play a role in mate selection in many species.


According to the Smell Dating website’s FAQ, “Unlike sight and sound, smell is interpreted first in terms of memory and emotion before being mapped to language. When it comes to long-term romantic partnership, it may actually be riskier to ignore the powerful signal of scent than to rely on it.” Here’s a promotional video, complete with classy boom-chick-a-bow-wow soundtrack:

One hundred “clients” forked over a one-time $25 fee to participate. New York University graduate student Jesse Donaldon is one of the people who signed on for Smell Dating’s trial run because he felt services like Tinder and OK Cupid were too much like online shopping. And as he says in the promotional video, “If I get a match, why not? At the very least it will be an interesting evening.”


This isn’t the first time someone has come up with the idea of matching potential partners by their pheromones. As Oddity Central points out, a few years ago, so-called “pheromone parties” were all the rage among the singles set. Guests would fork over an admission fee for the privilege of sniffing stinky t-shirts in Ziploc bags, in hopes of finding that special someone through their unique scent.
In fairness, there’s some solid science behind this rather wacky idea. Specifically, a famous 1995 experiment on the role of smell in human mate selection by Swiss biologist Claus Wedekind, dubbed “the sweaty t-shirt study.” There was also a 2011 Polish study in the European Journal of Personality, which looked at how well people could make assessments about key personality traits using just their sense of smell. Researchers from the University of Wroclaw had a group of 30 men and 30 women sleep in the same white t-shirt for three consecutive nights before sealing it in a plastic bag. Then they brought in a team of 200 “sniffers” to take a whiff of each shirt and guess how anxious, dominant, or extroverted the wearer might be.
The results weren’t exactly a slam dunk, but the sniffers were just as accurate in their personality assessments as the control group, who based their assessments on viewing videos of the subjects in an earlier study. “It’s possible that fear, stress, and positive emotions are each related to the production of specific substances that influence body odor,” psychologist Scott Barry Kaufman wrote about the study at Scientific American. “For instance, maybe neurotics sweat a lot, and sweat has a particular smell.” But he pointed out that there could be lots of other variables affecting one’s personal scent as well.
But seriously now—can you really find true love by smelling someone’s sweaty t-shirt? University of Queensland’s Phillipp Kirsch thinks not. “It is a sensible or plausible way to identify a partner if the only important criteria is how this partner smells when your eyes are closed, and the sole purpose is sexual,” he told Oddity Central in 2014.
That’s probably good enough for some people.

[Oddity Central]
In its ongoing exploration of Comet 67P/Churyumov-Gerasimenko, the Rosetta spacecraft captured this stunning silhouette of the two-lobed mass from a distance of 200 miles. Wow.
The Philae comet lander may be dead, but its valiant mothership lives on. Rosetta recently ventured away from the comet to study its wider coma, tail, and plasma environment. At one point, when it was 200 miles (329 km) away, the spacecraft, comet, and sun aligned together at an angle of about 159 degrees. It was a perfect opportunity to take a picture.
The top portion of the comet is brilliantly illuminated, but the dark patches reveal the comet’s freaky two-lobed shape. Scientists theorize that the comet got its shape in the wake of a gentle, low-velocity collision between two objects. Visual evidence shows that certain layers on the comet are oriented in different directions, which indicates that two objects fused to form a single, though oddly shaped, comet.


Just to put the size of this thing in perspective, here’s what it looks like relative to the city of Paris.
In other Rosetta-related news, the European Space Agency just released 984 new NAVCAM images of the comet taken between December 16, 2015 to February 9, 2016. You can check them out here.


[Rosetta Blog]
Tucker the turtle can’t swim underwater because he has an abnormal build-up of bubbles in his body. To treat his “buoyancy problem,” researchers at Seattle’s Virginia Mason hospital put him in a hyperbaric chamber, making him the first nonhuman patient to receive such treatment.
Last December, Tucker was found clinging to life along the coast of Oregon, far away from his natural warm-water habitat near California and Mexico. The 20-year-old endangered olive sea turtle was rescued and treated for pneumonia, among other complications. But the eventual goal of releasing him back into the ocean were put on hold after Seattle Aquarium staff learned that he suffers from a rather unfortunate condition: Tucker basically has the bends, which is causing him to float too much.

This turtle’s buoyancy problem, which is likely caused by an excess or enlargement of bubbles in his gastrointestinal tract, prevents him from diving or remaining underwater. The Guardian quoted a Seattle Aquarium spokesperson as saying, “It’s almost like the turtle is wearing a life preserver.” Sadly for Tucker, these bubbles aren’t subsiding on their own. The inability to dive and swim underwater is catastrophic for sea turtles, which prevents them from finding meals and evading predators.
To make Tucker seaworthy again, a multidisciplinary team decided to put Tucker in a hyperbaric chamber at Virginia Mason’s Center for Hyperbaric Medicine—a first for a non-human animal. (Virginia Mason donated its services to the cause.) Normally, these chambers are used to treat scuba divers with decompression sickness, also known as the bends. But the same principle applies; the medical staff used the same protocols on Tucker as the ones used to treat divers with “gas bubble disease.” Basically, they wanted to squeeze the bubbles down to a normal size.
Once in the chamber, the turtle was administered pure oxygen and exposed to about 2.8 atmospheres of pressure, which is the same amount of pressure found under 60 feet (18 meters) of water. A veterinarian ensured that he was getting enough oxygen, while his temperature and heart rate were continuously monitored. The whole thing took about two-and-a-half hours.


After treatment, Tucker was returned to his aquarium. He’s scheduled for a CT scan in the next few days to see if the air pockets decreased. At this point, it’s not clear if he can be returned to the ocean, or when. Either way, we hope Tucker is feeling better now that all that gas is gone.
[Seattle Times, Guardian]
A devastating fungal disease that has killed millions of bats in eastern North America has now reached Washington State, prompting serious concern among wildlife officials.
It has been referred to as the worst US wildlife crisis in recent years. Since 2007, this blight—known as white-nose syndrome (WNS)—has spread to 28 U.S. states and five Canadian provinces, killing an estimated 5.7 million to 6.7 million bats in the process, most of them little brown bats (Myotis lucifugus). In some regions, losses have exceeded 98 percent of local populations. Until now, this point the disease has been relegated to the eastern half of North America, but it now appears that it’s made a rather big jump to the other side.


The fungal disease was detected in North Bend, Washington, which is about 30 miles (48 km) east of Seattle. It’s the first time that WNS has been detected in the western United States.
“The discovery of the disease almost 1,300 miles [2,092 km] from the previous westernmost detection of the fungus in Nebraska is devastating news,” noted Katie Gillies, Director of Imperiled Species for Bat Conservation International, in a press statement. “Such a massive jump in geographical location leads us to believe that we humans are most likely responsible for its most recent spread.”


The disease causes a fuzzy white fungus to grow on the faces and wings of hibernating bats. This growth makes the bats repeatedly wake from their slumber, which causes them to burn through their fat stores, resulting in starvation and often death. Bat Conservation International said this is “a dire wakeup call” as experts expect the disease to spread from this new viral epicenter.
Given the presence of the virus in the west, conservationists are under added pressure to have the bat listed under the Endangered Species Act. This status, which would afford the ecologically-critical species special protections, is currently under review by the U.S. Fish and Wildlife Service.
“This is a terrible new chapter in the fight against WNS,” added Gillies. “We have as many as 16 western bat species that are now at risk. We have always feared a human-assisted jump to a western state. Unfortunately, our fears have been realized, and western North America—a bastion of bat biodiversity—may now expect impacts like we have seen in the East.”
Earlier this months, scientists discovered that bats in Asia are resistant to WNS.
[Bat Conservation International, BBC]
The world is getting fatter. But now a study by researchers from Imperial College London suggests we’ve reached a new milestone, with more people in the world being classified as obese than underweight for the first time.
The finding is based on the study of BMI data from nearly 20 million people in 186 different countries, recorded between 1975 to 2014. Extrapolating obesity rates from their data, the researchers claim that the number of obese people has risen from 105 million in 1975 to 641 million in 2014. Meanwhile, the number of underweight people has grown from 330 million to 462 million.


The result show that 10.8 percent of men and 14.9 percent of women were classified as obese in 2014—up from 3.2 percent and 6.4 percent, respectively, in 1975. In contrast, the percentages of those being reported as underweight have dropped, from 14 percent to 9 percent among men and from 15 percent to 10 percent for women, over the the same time period. In total, the study claims that there are 41.7 million obese men and 46.1 million obese women in the US. The findings are published in The Lancet.
Of course, BMI isn’t a perfect measure to assess whether someone is overweight or not, but for now it’s what the medical profession uses, so it’s the best we have. And at any rate, we shouldn’t necessarily be taking this study personally, but instead hoping that it changes national health policies.


“We hope these findings create an imperative to shift responsibility from the individual to governments and to develop and implement policies to address obesity,” explained Professor Majid Ezzati, one of the researchers, to the BBC. “For instance, unless we make healthy food options like fresh fruits and vegetables affordable for everyone and increase the price of unhealthy processed foods, the situation is unlikely to change.”


The World Health Organization aims to ensure that obesity levels are no higher in 2025 than they were in 2010. This study, the researchers claim, suggests that will be virtually impossible.
[The Lancet via BBC]
There’s only one confirmed Viking settlement in North America, far north on the Canadian coast. But if a new team of space archaeologists and their satellite data is to be believed, that’s all about to change.
A PBS program set to broadcast next week has the story of a potential Viking site much further south, on the southwest tip of the Canadian island of Newfoundland. It was found using infrared satellite imagery by Sarah H. Parcak, a leading space archaeologist. She used the satellite images to identify “hotspots”, which were narrowed down to one site at Point Rosee.


Further excavations have revealed a Viking-style turf wall, which radiocarbon tests date back to the Norse era. The evidence is still circumstantial, however, and it’s positive proof of a new Viking settlement in North America.
In either case, it’s already a validation of new technology in very old history. Aerial images have long been used to track ancient structures and burial mounds, but infrared satellite imaging gives archaeologists a valuable new tool. Maybe the next Indiana Jones movie will involve fewer boulders, and more time spent digitally enhancing images.


The documentary will stream online next Monday on PBS at 3.30PM Eastern.


[New York Times]
Image credit: DigitalGlobe
Male peacocks are justly admired for their brilliantly colored plumage. Canadian photographer Waldo Nell has captured the underlying microscopic structure behind those stunning hues in extraordinary detail in his latest photographic series.
It all comes down to a phenomenon called iridescence, which can also be seen in the wings of butterflies, dragonflies, cicadas, and in certain species of beetle. Structurally, it’s akin to photonics crystals. These materials boast a highly precise lattice structure that causes light to reflect off the surface in such a way as to create the perception of color in the human eye. They block certain frequencies of light and lets others through, so what color you see depends on the angle of reflection.


But certain naturally occurring photonics crystals—like those found in the wings of kingfishers, or the Queen of Night tulip—don’t have the same dependence on viewing angle. They scatter light selectively, much like a diffraction grating. The effect is similar to what happens when light hits the tiny grooves etched into a CD, causing flashes of rainbow color. The interlocking barbules of peacock feathers also have this unique structure—hence their many-hued iridescence.
Nell had photographed peacock feathers before, albeit at lower magnification. This time around, he wanted to capture more of that microscopic structure, showcasing “how each individual segment on a barbule can have a different color,” he told Gizmodo. He didn’t have an electron microscope, but his trusty Olympus BX 53 microscope proved up to the task. The instrument was limited in its depth of field, so in order to image the entire field of view, he used a technique called photo stacking: taking dozens of images from various focal points and stacking them together.


Nell is a software engineer by day in British Columbia, but he’s been fascinated by photography since he was a child. It wasn’t until he bought his first digital camera in 2000 (a 2.1MP Fujifilm) that he had the chance to fully explore his creative inclinations. He’s been avidly taking photographs ever since,“from the tiniest bacterium to Venus in transit across the sun, and everything in between. You can see more of his work here.
[Colossal]
Shattering bats might look cool, but they’re really dangerous for both the players and the fans. Why does that happen, and how come bats always seem to snap in the same way?
Consider the following: baseball bats are made of wood, and being a natural material, wood has certain innate structural flaws. One of the most popular bat woods—ash—has porous holes that run along the grain (grain being those different colored lines that result from a tree’s growth rings). Lots of tiny holes creates weakness, and weakness can cause bats to break, which is why manufacturers put their logos perpendicular to the grain on ash bats.


However, Barry Bonds caused a boom in popularity in maple bats, which neatly coincides with the uptick in shattering bats. Maple has a totally different grain structure to ash, and although it has grain like any other wood, the weakest points in a maple tree run radially from the center (think of someone chopping firewood). Because players were using the same grain-perpendicular striking surface, these maple bats turned into wooden shrapnel with staggering regularity.
Recently, bat-makers have started rotating their logos by 90 degrees on maple bats, as well as marking the grain on the handles. Bat breaks have gone down about 50 percent as a result, making fans and players less prone to accidental spear-related injury. Which is always a good thing.


Nearly all fossils are stripped of their original color. But as a new study from Irish paleontologists shows, that doesn’t necessarily mean the colors aren’t still there. You just have to know where to look.
Normally, fossils are devoid of any color, forcing paleontologists to make educated guesses about their specimen’s actual appearance. In some rare cases, melanin (a pigment that gives color to skin) manages to retain its organic nature over long timescales, revealing dull pigments of browns, blacks, and muddy reds. No other pigments are able to survive fossilization.


But where there’s a will, there’s a way. Paleontologists from the University College Cork in Ireland analyzed a 10 million-year-old snake fossil found preserved in calcium phosphate. They found that the colors of the long-extinct snake could still be gleaned even when the actual colors aren’t there any more. This latest study now appears in Current Biology.
The researchers mapped the location and shape of each pigment cell on the snakeskin fossil. Depending on the specific shape of the pigment cell, they were able to derive certain colors, including yellows, greens, blacks, brown, and even iridescence. To be clear, the pigments are long gone, but the cell shapes—which are specific to each type of pigment—still retain enough information to reconstruct the former colors. “For the first time, we’re seeing that mineralized tissues can preserve evidence of color,” lead researcher Maria McNamara said in a statement.
According to McNamara’s analysis, the 10 million-year-old snake, a member of the Colubridae family, featured three types of pigment cells in various combinations. Its skin contained melanophores, xanthophores, and iridophores. Translated to color, this means the snake was a mottled green and black, with a pale underside. The scientists suspect that this particular color scheme allowed the snake to camouflage itself during daytime.
This study suggests that other similar fossils may yield similar clues. As McNamara said, “It’ll mean re-evaluating a lot of specimens that might have been overlooked.”


[Current Biology]
Here it is, folks—our first glimpse of that abominable virus that’s been wreaking havoc in parts of South America and the Caribbean. This near-atomic scale view of Zika’s external structure could guide scientists as they work to develop effective antiviral treatments and vaccines.
Zika was discovered in Uganda back in 1947, but it wasn’t considered dangerous, hence its longstanding designation as a neglected tropical disease. But things have changed dramatically since last October when the virus began to make the rounds in Brazil and elsewhere. The mosquito-borne virus has now been potentially linked to microcephaly, a condition in which fetal brains grow abnormally small, and Guillain Barre syndrome, which can cause temporary paralysis.


Scientists have been working feverishly over the past several months to learn more about this virus. In the latest breakthrough, a team led by Purdue University researchers have become the first to visualize Zika’s structure, the details of which can now be found in Science. Their new atomic-scale map displays surface features that could be exploited by scientists as they work to create treatments and vaccines.
“This breakthrough illustrates not only the importance of basic research to the betterment of human health, but also its nimbleness in quickly addressing a pressing global concern,” said Purdue President Mitch Daniels in a statement. “This talented team of researchers solved a very difficult puzzle in a remarkably short period of time, and have provided those working on developing vaccines and treatments to stop this virus a map to guide their way.”
Purdue researchers Richard Kuhn, Michael Rossmann, and colleagues, created their picture of a mature Zika particle using a technique called cryo-electron microscopy. After freezing virus particles, the scientists fired a stream of high-energy electrons through the sample to create tens of thousands of 2D electron micrograph images. This allowed them to create a single, high-resolution, 3D composite view of the Zika virus. Typically, researchers use X-ray crystallography to visualize viruses, but the new technique is faster and more accurate.


The first thing the scientists noticed was how similar it appeared to other flaviviruses—viruses that are transmitted via infected mosquitoes, such as dengue, West Nile, and yellow fever. Zika, like other flaviviruses, features an RNA genome surrounded by a fatty membrane inside an icosahedral protein shell. This is actually good news because it means that ongoing efforts to create vaccines for viruses like dengue and West Nile could be applied to Zika.
But the Zika particle did feature a rather notable difference in one key surface protein, called E glycoprotein. About 180 of these stubbly objects protrude from the surface of the particle (shown in red), allowing the virus to attach itself to certain human cells, including antibodies and host receptors. These protrusions appear on dengue as well, but the unique characteristics of the Zika E glycoprotein could explain why it’s able to attack nerve cells and critical cells required for normal fetal brain development.
“If this [surface feature] functions as it does in dengue and is involved in attachment to human cells, it could be a good spot to target an antiviral compound,” noted Rossmann. “If this is the case, perhaps an inhibitor could be designed to block this function and keep the virus from attaching to and infecting human cells.”
Alternately, a vaccine could be developed that targets the glycoprotein. Moving forward, the team would like to locate more potential exploits, and to develop therapeutic compounds.


[Science]
Fermilab outside Chicago will soon begin its Deep Underground Neutrino Experiment (DUNE), and what it hopes to accomplish is as brilliant and confusing as the book of its namesake.
The experiment starts with accelerating protons close to the speed of light. That beam of super-fast particles is measured and then shot out through 800 miles of rock, where it will pop back up in South Dakota to be measured at the Sanford Underground Research Facility, home of the largest neutrino detectors on Earth.


All the data gathered by both facilities will be analyzed by a team of 800 scientists across 150 institutions. Hopefully some conclusions can be reached about not just the elusive nature of neutrinos, but about how stars function and even why matter exists. Regardless, the experiment itself sounds cool as hell.

It’s not often you come across a real-life mad scientist. They’re usually just over-the-top antagonists in comic books, but Colin Furze is the real thing. He has a penchant for building things that often blow up—on purpose—like this impossibly dangerous-looking thermite cannon.
Not familiar with thermite? It’s an especially nasty chemical composition made of metal power and oxide that burns as hot as 2,500 degrees celsius. If it ignites, you don’t want to be anywhere near it, which is why a cannon that puts a lot of distance between you and a flaming thermite grenade isn’t the world’s worst idea.

It should go without saying that building your own thermite cannon is a very dangerous undertaking. But watching a trained... err... professional like Colin build his is still quite entertaining. And you might even learn something about why thermite isn’t exactly something you want to be playing around with.


Physicians from Johns Hopkins Medicine have performed two landmark organ transplantations involving an HIV-positive liver and kidney. It’s a historic precedent that will do much to alleviate the ongoing organ shortage, while paving the way towards similar transplants involving other diseases.
The doctors, who announced the surgeries yesterday, used organs donated by the family of an HIV-positive woman who died earlier this month. Her kidney and liver were successfully transplanted into two recipients, both of whom are HIV-positive. This ends a 25-year-stretch in which it was illegal in the US to use HIV-positive organs for transplants. The surgery involving the liver was a world’s first, while the kidney transplant was the first in the United States.


“This is an unbelievably exciting day for our hospital and our team, but more importantly for patients living with both HIV and end-stage organ disease,” noted head surgeon Dorry L. Segev in a press statement. “For these individuals, this could mean a new chance at life.”
Segev says that deceased HIV-positive patients represent an important new source of critically-needed organs for transplants. He estimates that 500 to 600 donors are available each year, which could save over a thousand lives. What’s more, these donations would do much to address the ongoing donor shortage in the United States; there are about 122,000 people on the transplant waiting list in the US at any given time, of which thousands die each year.


The surgery was made possible with the passage of the HIV Organ Policy Equity Act of 2013 and the recent approval from the United Network for Organ Sharing. The policy reversal was motivated by recent advances in antiretroviral drugs and other therapies which have done much to lessen the toll of HIV/AIDS (though it’s important to point out that these therapies often cause liver or kidney failure). Furthermore, surgeons have developed techniques and protocols to make sure that the HIV virus doesn’t spread to the medical team.
The waiting list for organ transplants is growing at an alarming rate while the number of potential …
Future transplants could involve other organs, such as lungs, pancreas, and intestines. Moreover, this milestone could influence similar surgeries for patients infected with other communicable diseases, such as hepatitis C. And in fact, surgical teams from two different US universities are planning to use hep-C-infected kidneys for transplants later this year.


[NPR, LA Times]
Wood is a great material because it’s cheap, renewable, and versatile. But this crazy transparent wood that scientists in Sweden brewed up is nuts. It could replace glass for some seriously eye-catching architecture, and even be used in cheap solar panels or windows.
Researchers at the KTH Royal Institute of Technology in Sweden developed the material, which they say is suitable for mass production. The transparent wood could be used to build houses that let in more natural light, thus cutting your electric bill. Their findings were published in the American Chemical Society journal, Biomacromolecules.


The process begins by removing the organic compound that makes the wood brown. “The difference compared with timber is that we have removed lignin, but added a polymer to increase strength and provide transparency,” Lars Berglund, who led the study, told Gizmodo. “We can create veneer from this material and then laminate it into larger structures, such as load-bearing panels and beams.”
It’s not the first time wood has been used in surprising ways: Last year, researchers at the University of Wisconsin used wood to make computer microchips. This week’s development out of Sweden takes a natural, millennia-old material from the earth, and turns it into a futuristic, low-cost, renewable alternative to glass. Now, I’m eagerly awaiting moving into my ghostly, scifi, transparent log cabin.


[American Chemical Society and KTH via ScienceDaily]
Every year, FixNation, a Los Angeles animal charity, holds an auction of designer cat houses to raise money. This year’s Fan Favorite is “Cat in the Fishbowl.” It’s very nice, but we’re pretty sure any cat will ignore it in favor of the box it came in.
FixNation is a remarkable charity which attempts to reduce the population of feral cats by fixing stray cats so they won’t reproduce. Every year they hold an even more remarkable event. They partner with Architects for Animals and hold an auction of cat houses. Various firms design their own cat houses, and auction them off to raise funds.


We’re staring at Cat in the Fishbowl, the most popular entry in the auction, designed by Abramson Teiger Architects. We’re also staring at the most incredible thing of all—the fact that a photographer caught the brief moment of time when a cat is interested in the beautiful and specially-designed habitat you’ve just bought for it. (Half a second later, that cat was playing with a piece of tape left over from the box the house was transported in, and we all know it.)
If you want to take a look at all this year’s houses, check out the Architects for Animals site.
Scientists have documented Indian dancing frogs for over a century. For that century, they’ve found only adult frogs. At last, a team of biologists have found the tadpoles that develop into frogs—and they’ve found them underground.
Micrixalus herrei, one of a number of “dancing frogs” in India, spends its days in fast-moving streams. It gets its name from the fact that it extends its arms and legs in a sort of stylized dance as a way to get the attention of potential mates. It’s gotten the attention of many biologists over the years, but its life-cycle has remained mysterious. No one had ever seen the tadpoles in the streams and ponds the frog frequented.


This turns out not to have been surprising. The tadpoles didn’t live in the water. They were underground. A group of scientists from University of Delhi, University of Peradeniya, and Gettysburg College found these tadpoles burrowing in the sand beneath the streams.
These tadpoles live an “entirely fossorial life,” meaning they spend their entire youth burrowing and only emerge onto land once they’ve achieved their adult forms. As they burrow, they take in sand and digest the organic matter within it.

The tadpoles are adapted for their underground life. They’re more muscular, so they can fight their way through the sand. They have ribs, which is rare for frogs. The ribs give the muscles reinforcement and protect the internal organs from the pressure of the sand. Living their lives underground, they have no use for eyes, so their eyes develop later than those of other frogs. Those eyes still need to be protected, which means that the tadpoles have thick skin over each eye-bud. Finally, they have what are called “lime sacs”—sacs containing calcium carbonate, the mineral that helps build bones and shells.


Only in late metamorphosis do these blind, eel-like things venture out of the ground. At that point they look like frogs with tails. That tail shrinks, the frog gets bigger, and eventually it’s dancing around, trying to find a mate and make blind, burrowing eel-babies of its own.
[PLOS ONE]
When the Laser Interferometer Gravitational Wave Observatory (LIGO) announced the first direct detection of gravitational waves, it was the culmination of 50 long years of hard work and perseverance in the face of skepticism. In her new book, Black Hole Blues, and Other Songs from Outer Space, astrophysicist Janna Levin gives us a ringside seat to how it all went down. Gizmodo sat down with Levin to learn more.
Gizmodo: The LIGO collaboration made its announcement just last month, so the timing of your book is impeccable. But of course, you started working on it years ago.


Levin: And it’s two years late! It was due in 2013. I set out to write a book about black holes. I know that subject upside down. Wake me up in the middle of the night and that’s what would be in my head. But it just wasn’t working, because I got so caught up in the LIGO story. I had this hideous monster on my hands. It was partly expository and partly narrative, and I was burying so much of the narrative, because these are my friends. I didn’t want to write about them. Kip [Thorne] is someone I admire tremendously, who has been extremely kind to me scientifically, ever since I was too young to have earned any respect. To write about him like an external object was strange. It was a terrible barrier for me to overcome, psychologically. My editor said, “Why are you burying this incredible story?” It look me a long time to admit I was writing a totally different book. Once I did that, the writing went really fast.
The day of the LIGO discovery, September 14, 2015, I had sent a printed draft copy of the manuscript to Rai [MIT’s Rainer Weiss] and [Caltech physicist] Kip [Thorne]. Rai asked, “What if there’s a discovery? Are you going to have to rewrite the whole thing? Maybe you should wait.” But the plan was always just to write an epilogue. I did not change the book at all. You can’t pretend to not know the ending if you know the ending. There’s so much about their anxiety, about whether or not LIGO would succeed, all those years invested and still not knowing if a discovery is coming soon or is still 10 years away. Rai had said to me in August, “If we don’t hear black holes, the thing’s a failure.” The drama would have been gone if I’d known the truth.


When did you know about the LIGO detection?
Levin: They finally told me about it in December [2015]. I’m the only one they told officially, and it was such an honor. They knew about the book and they wanted me to have the proper ending. It was in a private message. The first thing I saw was “Confidential communication from LIGO” and I leapt up out of my seat. I was, like, “I know that what I’m about to read is going to change everything.” And then I couldn’t tell anybody! It’s always more wonderful when it’s someone else’s discovery. You don’t have all this baggage about it.
How did the LIGO discovery impact your own work as a theoretical physicist?
Levin: First of all, the black holes are much bigger than we expected, and most people didn’t think black hole detections would be first. So we theorists started scrambling to explain why LIGO saw black holes first and why they are so big. And then there was a possible electromagnetic counterpart [for the event].
You know how when you’re listening for your phone, it’s really hard to find? But if you can see it, you know exactly where it is. Telescopes have a very tight field of view, but the gravitational wave detectors are kind of, eh, it’s from over there. So [LIGO] sent the [scientists manning these] telescopes a map: “It’s kind of over there.” And the telescopes did their best within that map to find something. There was a claim from one of the many instruments of a flicker of gamma rays in the same general area. So we were also scrambling to explain how two black holes could produce light. They’re dark—that’s the whole point. Twelve papers came out about that, none of which were mine. Other people are always faster than me. I want to do a calculation, maybe sleep on it. I’ll probably write a paper next year.


One of the most heartbreaking stories in your book is the tale of Joseph Weber, the physicist who tried to detect gravitational waves in the 1950's and 1960's using “Weber bars.” He claimed to have succeeded in 1969, but nobody could replicate his results. He died in 2000.


Levin: It’s a terrible story, decades of abuse followed. It’s everybody’s worst nightmare as a scientist. I don’t think he did anything dishonest. [The LIGO signal] is a very distinct wave form. You can actually hear the masses, you can hear the ring down if you slow the recording down. Weber’s instrument was just a resonance machine. It resonates in response, like a tuning fork. But it doesn’t have that structure. So it’s a lot easier to have false alarms. [His instrument] was ringing a lot. Nobody knows why. If you imagine spikes in the data, it was easy to align them between different detectors, but the false signal was huge and the statistical analysis wasn’t sophisticated enough yet to eliminate that. He thought he heard something from SN 1987A. Maybe he did, I don’t know. There were no confirming experiments. That was the problem. Everyone else’s machines were dead quiet.
It’s heartbreaking because I think he was a great scientist in some ways. He was involved with the first conceptual version of the maser, which preceded the laser. The sheer boldness of trying to get this into the laboratory to measure the changes in spacetime—nobody else would have dared [at the time]. He was the pioneer. He was Ernest Shackleton and he got stuck on a metaphorical ice floe. [The Shackleton expedition] brought the wrong equipment, the wrong animals, the wrong food—it’s hard to be the first. If you read the LIGO paper, [the collaboration] credits him and I like that. It was really decent of them.


You know, there’s a small group of LIGO “truthers” out there, convinced it’s all just one big conspiracy by fame-hungry scientists to hoodwink the public.


Levin: No! Really? That’s hysterical. This detection was much louder than anyone expected. LIGO heard it clear as day. If anything it’s too clear.
So clear that the LIGO collaboration seriously considered the possibility that it was a malicious hack—a fake injected signal.


Levin: Yes. Rai said, “Look, we went through every possible scenario for how you would inject a false signal, and tried to do it ourselves.” There were only a few people in the entire collaboration with sufficient access and knowledge to do something like that, and they interrogated them all. And you have to physically attach stuff, you can’t just do this telepathically, so they looked for little black boxes and things like that. It was like a C.S.I. experiment. So there’s no physical evidence. It would be very hard to fake a signal without being caught. And I don’t think anyone in the collaboration has that sophisticated a criminal mind. In fact, when they did a [deliberate] blind injection during the test run [of the earlier version of LIGO], they screwed it up a little. They got the orientation wrong.
When Hubble [Space Telescope] takes a photograph, people don’t say, “I don’t trust the math.” Even though most of it is false color—[data for] that image has been translate and analyzed and stuff has been subtracted—when you see it, you just go, “There it is.” The visual sense, it’s so immediate, and we’re so reliant upon it. But you can hear [the LIGO signal] clear as day if they slow it down. I think eventually people will feel the same way [about LIGO signals] as they do about a photograph from the Hubble telescope, or from a radio telescope.

We humans are doing a bang-up job of messing up our home planet. But who’s to say we can’t go on to screw things up elsewhere? Here, not listed in any particular order, are 12 unintentional ways we could do some serious damage to our Solar System, too.
Wild speculation ahead...
By accidentally unleashing exotic forms of matter from particle accelerators, we run the risk of annihilating the entire solar system.
Prior to the construction of CERN’s Large Hadron Collider, some scientists worried that collisions created by the highly energetic accelerator might spawn such nasties like vacuum bubbles, magnetic monopoles, microscopic black holes, or strangelets (a.k.a. “strange matter” — a hypothetical form of matter similar to conventional nuclei, but also containing many of the heavier strange quarks). These concerns were condemned by the scientific community as “rubbish” and nothing more than rumors spread by “unqualified people seeking sensation or publicity.” Moreover, a 2011 report published by the LHC Safety Assessment Group concluded that the collisions presented no danger.


Anders Sandberg, a research fellow who works out of Oxford University’s Future of Humanity Institute, a part of the Oxford Martin School, agrees that a particle accelerator disaster is unlikely, but warns that if strangelets were to be somehow unleashed, “it would be bad.” As he explained to io9:
The Oxford Martin School at the University of Oxford - Research, policy and debate for a more…
Converting even a planet like Mars to strange matter would release a fraction of the rest mass as radiation (plus perhaps splatter strangelets). Assuming a conversion acting on a hour timescale and releasing just 0.1% as radiation gives a mean luminosity of 1.59*10^34 W, or about 42 million times the sun. Most of which would be hard gamma rays.
Ouch. Obviously, the LHC is incapable of producing strange matter, but perhaps some future experiment, either on Earth or in space, could produce the stuff. It’s hypothesized, for example, that strange matter exists at high pressure inside neutron stars. Should we artificially create those conditions, it could end the show real quick. (Image credit: The Core.)
We could also wreck the Solar System by severely damaging or altering the Sun during a stellar engineering project, or by screwing up planetary dynamics in the process.
Some futurists speculate that future humans (or our posthuman descendants) may choose to embark upon any number of stellar engineering projects, including stellar husbandry. Writing in Interstellar Migration and the Human Experience, David Criswell from the University of Houston described stellar husbandry as the effort to control the evolution and properties of stars, including attempts to prolong their lifespans, extract material, or create new stars. To make a star burn less rapidly, and thus last longer, future stellar engineers would work to remove its excess mass (big stars expend fuel faster).


But the potential for a catastrophe is significant. Like plans to engage in geoengineering projects here on Earth, stellar engineering projects could result in any number of unforeseen consequences, or instigate uncontrollable cascade effects. For example, efforts to remove the Sun’s mass could create bizarre and dangerous flaring effects, or result in a life-threatening decrease in luminosity. It could also have a pronounced effect on planetary orbits. ( Image credit: NASA/JPL-Caltech/GSFC)
Some thought has been given to the prospect of turning Jupiter into a kind of artificial star. But in the attempt to do so, we could destroy Jupiter itself and wipe out life on Earth.
Writing in the Journal of the British Interplanetary Society, astrophysicist Martyn Fogg proposed that we stellify Jupiter as a first step to terraforming the Galilean satellites. To do so, future humans would seed Jupiter with a tiny primordial black hole. The black hole would have to engineered perfectly so that it not fall outside the bounds of the Eddington limit (an equilibrium point between the outward force of radiation and the inward force of gravity). According to Fogg, this would produce “energy sufficient to create effective temperatures on Europa and Ganymede that would be similar to the values on Earth and Mars, respectively.”


Lovely, except for what would happen if things go askew. As Sandberg told io9, it would work fine at first — but the black hole could grow and eventually absorb Jupiter in a burst of radiation that would sterilize the entire Solar System. With life extinguished and Jupiter sucked up into a black hole, our neighborhood would be a complete mess.
Should we start to mess around with the location and mass of planets or other celestial bodies, we run the risk of upsetting the Solar System’s delicate orbital balance.
The orbital dynamics in our Solar System is surprisingly fragile. It has been estimated than even the slightest perturbation could result in chaotic and even potentially dangerous orbital motions. The reason for this is that planets are subject to resonances, which is what happens when any two periods assume a simple numerical ratio (e.g., Neptune and Pluto are in a 3:2 orbital resonance, as Pluto completes two orbits for every three orbits of Neptune).


The result is that two orbiting bodies can influence each other even when they’re quite distant. Regular close encounters can result in the smaller object getting destabilized and cleared right out of its original orbit — and even the Solar System altogether!
Looking to the future, such chaotic resonances could happen naturally, or we could instigate them by fidgeting around with the Sun and planets. As already noted, there’s the potential for stellar engineering. The prospect of moving Mars into the habitable zone, which could be done by decaying its orbit with asteroids, could likewise upset the orbital balance. Alternately, if we build a Dyson Sphere using material extracted from Mercury and/or Venus, we could alter orbital dynamics in a very profound and dangerous way. It could result in Mercury (or what’s left of it) being tossed from the Solar System, or Earth having an uncomfortably close encounter — or even a collision — with a large object like Mars. (Illustration: Hagai Perets.)
A spaceship driven by a warp drive would be awesome, no doubt, but it would also be incredibly dangerous. Any object, like a planet, at the destination point would be subject to massive expenditures of energy.


Also known as an Alcubierre engine, a warp drive could someday work by generating a bubble of negative energy around it. By expanding space and time behind the ship, while squeezing space in front of it, a ship could be pushed to velocities not limited by the speed of light.
Regrettably, however, this energy bubble has the potential to do some serious damage. Back in 2012, a research team crunched the numbers to see what kind of damage an FTL drive of this nature could inflict. Writing in Universe Today, Jason Major explains:
Space is not just an empty void between point A and point B… rather, it’s full of particles that have mass (as well as some that do not.) What the research team...has found is that these particles can get “swept up” into the warp bubble and focused into regions before and behind the ship, as well as within the warp bubble itself.
When the Alcubierre-driven ship decelerates from superluminal speed, the particles its bubble has gathered are released in energetic outbursts. In the case of forward-facing particles the outburst can be very energetic — enough to destroy anyone at the destination directly in front of the ship.
“Any people at the destination,” the team’s paper concludes, “would be gamma ray and high energy particle blasted into oblivion due to the extreme blueshifts for [forward] region particles.”
The researchers added that, even for short journeys, the energy released is so large “you would completely obliterate anything in front of you.” And by anything, that could be an entire planet. Moreover, because the amount of energy is dependent on the length of the journey, there is potentially no limit to its intensity. An incoming warp ship could do considerably more damage than just wreck a planet. ( Image: Mark Rademaker.)
Using wormholes to sidestep the constraints of interstellar space travel sounds great in theory, but we’ll need to be extra careful when tearing a hole in the space-time continuum.


Back in 2005, Iranian nuclear physicist Mohammad Mansouryar outlined a scheme for creating a traversable wormhole. By producing enough amounts of effective exotic matter, he theorized that we could theoretically pierce a hole through the cosmological fabric of space-time and create a shortcut for spacecraft.
Mansouryar’s paper is opaque, and it’s not immediately clear if he’s onto something, but as Anders Sandberg pointed out to io9, the negative consequences could be severe:
First, wormhole throats need mass-energy (possibly negative) on the scale of a black hole of the same size. Second, making time loops may cause virtual particles to become real and break down the wormhole in an energy cascade. Likely bad for the neighborhood. And besides, dump one end in the Sun and another elsewhere (a la Stephen Baxter’s Ring), and you might drain the Sun and/or irradiate the solar system if it is large enough.
Yes, killing the Sun is bad. And by irradiation we’re once again talking about the complete sterilization of the Solar System.
Should we choose to relocate our Solar System in the far future, we run the risk of destroying it completely.


In 1987, Russian Physicist Leonid Shkadov proposed a megastructure concept, since dubbed the Shkadov Thruster, that could literally move our solar system and all that’s within it to a neighboring star system. In the future, this would allow us to reject our older, dying star in favor of a younger version.
Writing in  Popular Mechanics, Adam Hadhazy explains how it works:
The Shkadov Thruster setup is simple (in theory): It’s just a colossal, arc-shaped mirror, with the concave side facing the sun. Builders would place the mirror at an arbitrary distance where gravitational attraction from the sun is balanced out by the outward pressure of its radiation. The mirror thus becomes a stable, static satellite in equilibrium between gravity’s tug and sunlight’s push.
Solar radiation reflects off the mirror’s inner, curved surface back toward the sun, effectively pushing our star with its own sunlight—the reflected energy produces a tiny net thrust. Voilà, a Shkadov Thruster, and humanity is ready to hit the galactic trail.
What could go wrong, right? Clearly, lots. We could miscalculate and scatter the Solar System to the cosmos, or even smash directly into the other star.


Which brings up an interesting point: If we develop the capacity to move between stars, we should also be able to figure out how to manipulate or influence the plethora of small objects located in the outer reaches of the solar system. We’re definitely going to have to careful here. As Sandberg warns, “Ah, destabilizing the Kuiper belt or Oort cloud: whoops, we got zillions of comets slamming into everything!” ( Image credit: Steve Bowers.)
If the advocates of Active SETI have their way, we could soon be transmitting messages to space in the hopes of alerting aliens to our presence. You know, because all aliens must be nice. (Image credit: Mars Attacks.)
Say we send out a fleet of exponentially self-replicating von Neumann probes to colonize the Galaxy. Assuming they’re programmed very, very poorly, or somebody deliberately creates an evolvable probe, they could mutate over time and transform into something quite malevolent.
Eventually, our clever little space-faring devices could come back to haunt us by ripping our Solar System to shreds, or by sucking up resources and pushing valuable life out of existence. ( Image: Babylon 5.)
Somewhat similar to self-replicating space probes, there’s also the potential for something much smaller, yet equally as dangerous: exponentially replicating nanobots. A grey goo disaster, where an uncontrollable swarm of nanobots or macrobots consume all planetary resources to create more copies of itself, need not be confined to planet Earth. Such a swarm could hitch a ride aboard an escaping spaceship or planetary fragment, or even originate in space as part of some megastructure project. Once unleashed in the Solar System, it would quickly turn everything into mush.
One of the dangers of creating artificial superintelligence is that it has the potential to do much more than just snuff out life on Earth; it could spread out into the Solar System — and even potentially beyond.
The oft-cited paperclip scenario, in which a poorly programmed ASI converts the entire planet into paperclips, conveys the urgency of the problem. Should an out-of-control ASI emerge, it’s obviously not going to produce paperclips ad nauseam, but it could do something else, like produce an endless supply of computer processors or turn all available matter into useable computronium. An ASI may even devise a meta-ethical imperative it feels it must enforce across the entire Galaxy. (Image credit: Stevebidmead/Pixabay/CC.)
Which we would do by going extinct. (Image credit: Udra11/Sutterstock.)

Weather can get pretty rough here on Earth, but there’s a rocky exoplanet located about 40 light-years away that features some of the most extreme temperature fluctuations ever seen by astronomers—reaching temperatures so high that lava flows directly on the surface.
Dubbed 55 Cancri e, this rocky planet is the equivalent of about eight Earth masses, qualifying it as a super-Earth. 55 Cancri e is the innermost planet in its solar system, and it requires less than 18 hours to complete a full orbit. Earlier this year, NASA’s Hubble Space Telescope detected traces of hydrogen and helium in its atmosphere, marking the first time that astronomers were able to analyze the atmosphere of a super-Earth. (The atmospheres of large Jupiter-like planets have been scanned before owing to their tremendous size.)


Now, in another first, astronomers have compiled a weather map for this super-Earth, revealing its extreme meteorological and surface conditions. The results of this study now appears in Nature.
The new thermal map, compiled by astronomer Brice-Olivier Demory and his team from Cavendish Laboratory in the UK, shows that the planet is very hot as a whole, but it experiences dramatic temperature differences between its dayside and nightside. Like our moon, 55 Cancri e is tidally locked, which means its dayside surface is always facing the sun. It’s very likely, therefore, that this super-Earth experiences geological processes—such as high winds, lava flows, and volcanism—similar to what’s found in our own solar system.


Using the Spitzer Space Telescope Infrared Array Camera, the researchers found that the planet’s nightside temperature is around 1,107 degrees Celsius, while its dayside temperature is about 2,427 degrees Celsius. That’s a dayside/nightside difference of a stunning 1,027 degrees Celsius. Such large fluctuations produce some rather bizarre conditions on the surface.
The researchers detected a peculiar hot spot on the surface at 41 degrees east from the substellar point (the point at which the sun is directly overhead), leading to two very different explanations.
One possibility is that the planet has a thick atmosphere that’s producing strong, hot winds exclusively on its dayside. But for this hypothesis to work, the atmosphere would have to be dominated by reflective high-temperature vapors like silicates, and a nightside that drops to below freezing so that gases can condense. But looking at the temperature data, this scenario seems unlikely.
Alternatively, the hotspot can be explained by molten lava on the surface of the planet’s dayside. At a temperature of 2,427 Celsius, silicate-based rocks (which are common on 55 Cancri e) can be quite viscous, so this melted rock is probably flowing like water does at room temperature. As for the nightside, the silicate rock would remain cool enough to sustain a surface that’s partially to mostly solid surface.
The planet’s tidally locked nature and orbital velocity is insufficient to explain these extreme temperatures, suggesting that some other source of heat is being generated within the planet. It appears that this remarkable exoplanet—one of the first to ever be discovered—still has many secrets to tell.


[Nature]
Laser hair removal might be the most requested cosmetic procedure, but how does it work?
As Veritasium explains, dark hair contains melanin, a pigment that helps protect us from the sun by absorbing many wavelengths of visible and ultraviolet light. Bursts of high-energy laser light are absorbed much better by these unwanted hairs than by the surrounding skin, and the hairs start to increase in temperature when the laser hits them. Like popcorn, moisture inside the hairs evaporates rapidly which makes them look a bit... crispy.


Once they hit 60 degrees Celsius or so, the hairs becomes irreparably damaged—cellular bonds start to break down in a process called denaturation. Cause enough damage and those hairs can’t grow back. And remember, this all takes place in a split second.
Up closer and slowed day down, it’s hard not to feel bad for the tiny hairs you just cooked.


You might not know the name Charley Harper, but it’s possible that the midcentury artist’s colorful work introduced you to many wonders of the natural world. Now many of his pieces are available as furniture to bring Harper’s flora and fauna into your living room.
Harper’s beautiful illustrations of the animal kingdom appeared in a wide range of publications, from elementary school science books to grown-up travel magazines.

My introduction to Harper was through my copy of The Giant Golden Book of Biology. I’ll never forget looking at this page over and over and over, trying to piece together how humans fit into the grand evolutionary scheme of things:
A new collaboration with Land of Nod brings Harper’s work to life as a series of the most adorable quilts, rugs, and posters, all produced in collaboration with designer Todd Oldham (who also collected many of Harper’s pieces into a gigantic monograph in 2011; Harper died in 2007).
What made Harper’s work so stunning is that although his work was simple and stylized, he always remained scientifically accurate. That’s also what is so lovely about these pieces: they are exceptionally true to Harper’s original art, right down to the color and detail. Here are a few of my favorites, which are all available starting today.
[Land of Nod]
AdrenaCard is meant to help people who are both unfortunate enough to need an epinephrine injection for serious allergic reactions—and human enough that they regularly forget their “epi-pen” when they’re going out. It’s a small epinephrine injector that fits inside a wallet.
Most people with serious allergies have had an encounter with epinephrine. When the body reacts to bee stings, bug bites, or other extreme allergies, the muscles around the airway and the blood vessels tighten up, choking the person’s breath and throttling their blood supply. Epinephrine relaxes the muscles and lets the person breathe again.


People who have severe allergic reactions often carry “epi-pens,” highlighter-sized syringes that can deliver fast, easy injections of epinephrine. Unfortunately, due to their size and the infrequency of their use, many severe allergy sufferers don’t carry them all the time. The AdrenaCard is meant to make keeping medication on hand a lot easier.
The AdrenaCard, made by a company of the same name, measures 100 millimeters by 50 millimeters by eight millimeters. This is about 15 millimeters longer and twice as thick as the average credit card—so it wouldn’t fit in any wallet. It would, however, fit in pocket-sized vertical wallets or other, slightly larger wallets. Hopefully, this means it will always be there when a person needs it, unlike traditional epinephrine injectors.


There’s nothing wrong with the mechanism of epi-pens, but if a person has to use them only every once in a while, they can get left in old purses or backpacks, forgotten at home, or stashed in the glove box of a car. Everyone forgets their injector every now and then. While people can go for years without needing to treat a bee sting with an epi-pen, few people go more than a few hours without needing their wallet. The AdrenaCard is meant to be something a severe allergy sufferer will always have on hand, without consciously thinking about it.
The card comes with a safety band. During an emergency, the person would pull the band off, place it against the sufferer’s leg, and push. The mechanism is similar to a regular epi-pen. Right now, the card is going through FDA testing. If all goes well, it will be on the market by 2018.
[AdrenaCard]
A robot anesthesiologist designed by Johnson & Johnson is going off the market. Only three years after approval, the company has stopped production on the Sedasys machine due to poor sales.
The Sedasys machine was designed to provide anesthetic to patients undergoing routine surgeries. The American Society of Anesthesiologists was especially alarmed because anesthesiology is one of the riskier aspects of many surgeries. The machine, which administered the drugs while monitoring the patient’s vital signs, was originally considered for use on a number of surgeries.


Johnson & Johnson agreed to use it only for procedures like endoscopies, colonoscopies, and esophagogastroduodenoscopy. By mid-2015 it was being used in four hospitals. Apparently, that was not enough to justify its continued manufacture.
It’s always unsettling to think that a robot could put a whole profession out of a job—especially when that profession involves years of training and expensive education. Apparently, no one is entirely safe. On the other hand, more and more people are facing astoundingly high healthcare costs. The Sedasys system cost one tenth as much, per procedure, as a human anesthesiologist.


[Washington Post]
Everyone learns in grade school that you can’t divide by zero, but few of us ever learn (or fully understand) why. The stock answer is that it gives you an answer of infinity. The truth is a bit more nuanced than that, and an old mechanical calculator offers the perfect illustration.
Try to divide a number by zero with a standard calculator, and you’ll just get an error message. But as Eric Limer shows us over at Popular Mechanics, check out what happens when someone tries to do this on a Facit ESA-01 mechanical calculator, with the cover helpfully removed so all the internal workings are exposed:

The machine pretty much goes insane, its gears and cogs hammering away in a nonstop frenzy of clacking. WTF?


It has to do with how such machines work, and also with the nature of division—it’s basically just “glorified subtraction,” as the folks at Numberphile will tell you. To divide 20 by 4, the mechanical calculator perform a sequence of steps: 20 minus 4 is 16, 16 minus 4 is 12, 12 minus 4 is 8, 8 minus 4 is 4, and 4 minus 4 is 0. Voila! It takes five steps, so 20 divided by 4 equals 5.
But 20 divided by zero is just subtracting nothing from 20 over and over again. The calculator never arrives at an answer because it would take an infinite number of steps. And infinity is really more of a concept than an actual number.
As Limer explains: “The underlying cause for the freakout is that the poor machine is trying to hammer out an infinite sequence of commands, one by one. A computer will always do exactly what you tell it to do, even if that will take literally forever.”


[Twisted Sifter via Popular Mechanics]
We tend to think of calculators as devices house in dull plastic boxes, but these calculators show…
Sip your morning coffee suspiciously, friend—it may not be what you think.
The Washington Post chatted with the creators of a new testing method for coffee beans, which double checks that the name on the label of your beans matches what you’re actually getting. Although existing tests can already identify the types of coffee beans, the new method is more precise, as well as quicker and easier to perform outside of the lab.


The need for the more efficient testing has cropped up because coffee is becoming an increasingly common target for food counterfeiters. What’s really interesting about this particular case, though, is that it combines so many different food counterfeiting methods. Coffee has a mislabeling problem, like salmon and other fish. It also suffers from the diluting of better varieties with cheaper, more plentiful ones, as in the case olive oil.
There’s also one other commonality with other recent food fraud cases. Like so many other foods, part of the root cause of the counterfeiting is climate change. Coffee, particularly in Brazil, has been hit hard by the sweeping droughts we’ve experienced recently. Late last year, I noted that given what we were seeing with both global markets and on coffee farms, a global coffee shortage was coming. The question wasn’t if, but when it would happen. With tightening stores from a looming shortage, rising prices, and more and more emphasis on specialty coffees, it’s no wonder that counterfeit coffee is becoming a problem big enough to need faster, easier testing.


So beware, that $8 coffee you just picked up might not be the fancy, single-origin product you think it is.

Astronomers have captured video evidence of a collision between Jupiter and a small celestial object, likely a comet or asteroid. Though it looks like a small blip of light, the resulting explosion was unusually powerful.
As Phil Plait of Bad Astronomy reports, the collision occurred on March 17, but confirmation of the event only emerged this week. An amateur Austrian astronomer used a 20-centimeter telescope to chronicle the unexpected event, but it could’ve been some kind of visual artifact.

A second video taken at the same time with a 28 cm telescope in Ireland has now confirmed it as an actual impact.

Plait says that the asteroid or comet wasn’t very large, probably measuring only a few hundred feet in diameter. But when it comes to celestial collisions, it’s not the size of the impactor that counts. Owing to Jupiter’s huge mass, the object must’ve have been accelerating rapidly, releasing a tremendous amount of kinetic energy on impact. Plait explains:
On average (and ignoring orbital velocity), an object will hit Jupiter with roughly five times the velocity it hits Earth, so the impact energy is 25 times as high. The asteroid that burned up over Chelyabinsk, Russia, in 2013 was 19 meters across, and it exploded with the energy of 500,000 tons of TNT.
Now multiply that by 25, and you can see how it doesn’t take all that big a rock to hit Jupiter for us to be able to see it from Earth.
Incidentally, at these huge speeds, hitting the atmosphere is like slamming into a wall. A lot of people get understandably confused how an asteroid can explode due to air, but the pressures involved as it rams through the atmosphere at these speeds are ridiculously huge. The air and rock heat up, the rock starts to fall apart, and each chunk then gets hot, and so on, creating a very rapid cascade that releases the energy of motion in just a second or two.
The result, says Plait, was a “very, very big bang.”


This is not the first time we’ve seen Jupiter get struck by an object. Back in 1994 it was hit by cometary fragments from Shoemaker-Levy 9, and again in 2010 and 2012. Plait says the gas giant gets hit by something big enough to see from Earth about once a year.
[Slate]
After ten grueling months of ISIS occupation, the ancient city of Palmyra has been liberated. Syrian government troops, backed by Russian air support, encircled Islamic State militants, forcing them to flee into the interior eastern desert. With the extremists gone, experts have had the opportunity to perform a preliminary assessment of the damage inflicted upon the UNESCO World Heritage site. The news is both good and bad.
According to Syrian archaeologist Maamoun Abdelkarim, 80 percent of the artifacts in Palmyra appear to be largely intact. There is extensive damage—make no mistake—but many of the iconic columns remain upright, along with several key temples and monuments. Speaking to the LA Times, Abdelkarim said that there’s damage to the streets, baths, and some temple fences, but “the panoramic view that tourists know of Palmyra remains.” Encouragingly, he said that a significant portion of the restoration work could take just five years.
Islamic State militants occupied the historic city last May, and they took it upon themselves to destroy some of the city’s most distinctive monuments, including the Arch of Triumph, the Baalshamin Temple, and the Temple of Bel. They chiseled away the faces of statues and reliefs, declaring them blasphemous pagan icons. The militants also beheaded and crucified Khaled Asaad, a prominent Syrian archaeologist. The vandalism inflicted onto Palmyra, an important stop for traders moving between China, India, Persia, and the Roman Empire during the first and second centuries AD, was greeted with global outrage, leading some to declare the actions of ISIS a serious war crime.
Preliminary assessments, some done by aerial drones, show that the Lion of Al-Lat—a 15-ton statue—is still standing, as are the famous columns. Experts will continue to investigate the site over the coming weeks and months as they prepare a report for UNESCO. The area is reportedly strewn with landmines and boobytraps left by Islamic State militants, so the investigation will be slow, tedious, and dangerous. Bomb-disposal crews assisted by Russian engineers and robots will help.

The quality and extent of the pending restoration will depend on previous records kept of the artifacts, which in some cases are non-existent or of poor quality. It’ll also depend on the ongoing civil war in Syria, which is now raging in its fifth year. In all it could take about two to three decades before Palmyra is set right.


“The damage done to Palmyra architectural monuments is enormous, but it has not been razed to the ground completely,” noted Russian archaeologist Mikhail Piotrovsky in RT. “The main symbol of the city—the famous columns, they are standing, and we now have to inspect the site accurately to determine, what else is left there.”
[LA Times, RT]
We live in an era of accelerating change, when scientific and technological advancements are arriving rapidly. As a result, we are developing a new language to describe our civilization as it evolves. Here are 20 terms and concepts that you’ll need to navigate our future.
Back in 2007 I put together a list of terms every self-respecting futurist should be familiar with. But now, some seven years later, it’s time for an update. I reached out to several futurists, asking them which terms or phrases have emerged or gained relevance since that time. These forward-looking thinkers provided me with some fascinating and provocative suggestions — some familiar to me, others completely new, and some a refinement of earlier conceptions. Here are their submissions, including a few of my own.
Futurist and scifi novelist David Brin suggested this one. It’s kind of a mash-up between Steve Mann’s sousveillance and Jamais Cascio’s Participatory Panopticon, and a furtherance of his own Transparent Society concept. Brin describes it as: “reciprocal vision and supervision, combining surveillance with aggressively effective sousveillance.” He says it’s “scrutiny from below.” As Brin told io9:
Folks are rightfully worried about surveillance powers that expand every day. Cameras grow quicker, better, smaller, more numerous and mobile at a rate much faster than Moore’s Law (i.e. Brin’s corollary). Liberals foresee Big Brother arising from an oligarchy and faceless corporations, while conservatives fret that Orwellian masters will take over from academia and faceless bureaucrats. Which fear has some validity? All of the above. While millions take Orwell’s warning seriously, the normal reflex is to whine: “Stoplooking at us!” It cannot work. But what if, instead of whining, we all looked back? Countering surveillance with aggressively effective sousveillance — or scrutiny from below? Say by having citizen-access cameras in the camera control rooms, letting us watch the watchers?
Brin says that reciprocal vision and supervision will be hard to enact and establish, but that it has one advantage over “don’t look at us” laws, namely that it actually has a chance of working. (Image credit: 24Novembers/Shutterstock)
This particular meme — suggested to me by the Institute for the Future’s Distinguished Fellow Jamais Cascio — has only recently hit the radar. “It’s in-vitro fertilization,” he says, “but with a germline-genetic mod twist.” Recently sanctioned by the UK, this is the biotechnological advance where a baby can have three genetic parents via sperm, egg, and (separately) mitochondria. It’s meant as a way to flush-out debilitating genetic diseases. But it could also be used for the practice of human trait selection, or so-called “designer babies”. The procedure is currently being reviewed for use in the United States. The era of multiplex parents has all but arrived.
Babies with three parents are no longer the stuff of science fiction. A British ethics board has…
In three to five years, a baby will be born with two genetic mothers and one father. This could…
A number of years ago we reported on how a "three-person IVF" procedure could be used to…
Futurist and scifi novelist Ramez Naam says we should be aware of the potential for “technological unemployment.” He describes it as unemployment created by the deployment of technology that can replace human labor. As he told io9,
For example, the potential unemployment of taxi drivers, truck drivers, and so on created by self-driving cars. The phenomenon is an old one, dating back for centuries, and spurred the original Luddite movement, as Ned Ludd is said to have destroyed knitting frames for fear that they would replace human weavers. Technological unemployment in the past has been clearly outpaced (in the long term) by the creation of new wealth from automation and the opening of new job niches for humans, higher in levels of abstraction. The question in the modern age is whether the higher-than-ever speed of such displacement of humans can be matched by the pace of humans developing new skills, and/or by changes in social systems to spread the wealth created.
Indeed, the potential for robotics and AI to replace workers of all stripes is significant, leading to worries of massive rates of unemployment and subsequent social upheaval. These concerns have given rise to another must-know term that could serve as a potential antidote: guaranteed minimum income. (Image credit: Ociacia/Shutterstock)
In the future, people won’t be confined to their meatspace bodies. This is what futurist and transhumanist Natasha Vita-More describes as the “Substrate-Autonomous Person.” Eventually, she says, people will be able to form identities in numerous substrates, such as using a “platform diverse body” (a future body that is wearable/usable in the physical/material world — but also exists in computational environments and virtual systems) to route their identity across the biosphere, cybersphere, and virtual environments.
We're still decades — if not centuries — away from being able to transfer a mind to a…
Last month, researchers created an electronic link between the brains of two rats separated by…
“This person would form identities,” she told me. “But they would consider their personhood, or sense of identity, to be associated with the environment rather than one exclusive body.” Depending on the platform, the substrate-autonomous person would upload and download into a form or shape (body) that conforms to the environment. So, for a biospheric environment, the person would use a biological body, for the Metaverse, a person would use an avatar, and for virtual reality, the person would use a digital form.
It’s time to retire the term ‘Technological Singularity.’ The reason, says the Future of Humanity Institute’s Stuart Armstrong, is that it has accumulated far too much baggage, including quasi-religious connotations. It’s not a good description of what might happen when artificial intelligence matches and then exceeds human capacities, he says. What’s more, different people interpret it differently, and it only describes a limited aspect of much broader concept. In its place, Armstrong says we should use a term devised by the computer scientist I. J. Good back in 1967: the “Intelligence explosion.” As Armstrong told io9,
If you want to know about the future of artificial intelligence then you must read documentary…
It describes the apparent sudden increase in the intelligence of an artificial system such as an AI. There are several scenarios for this: it could be that the system radically self improves itself, finding that as it becomes more intelligent, it’s easier for it to become more intelligent still. But it could also be that human intelligence clusters pretty close in mindspace, so a slowly improving AI could shoot rapidly across the distance that separates the village idiot from Einstein. Or it could just be that there are strong skill returns to intelligence, so that an entity need only be slightly more intelligent that humans to become vastly more powerful. In all cases, the fate of life on Earth is likely to be shaped mainly by such “super-intelligences”.
At some point in our future, an artificial intelligence will emerge that's smarter, faster,…
Image credit: sakkmesterke/Shutterstock.
While many futurists extol radical life extension on humanitarian grounds, few consider the astounding fiscal benefits that are to be had through the advent of anti-aging biotechnologies. The Longevity Dividend, as suggested to me by bioethicist James Hughes of the IEET, is the “assertion by biogerontologists that the savings to society of extending healthy life expectancy with therapies that slow the aging process would far exceed the cost of developing and providing them, or of providing additional years of old age assistance.” Longer healthy life expectancy would reduce medical and nursing expenditures, argues Hughes, while allowing more seniors to remain independent and in the labor force. No doubt, the corporate race to prolong life is heating up in recognition of the tremendous amounts of money to be made — and saved — through preventative medicines.
Biotechnologist Craig Venter — the first scientist to map the human genome and create synthetic…
Google has announced Calico, a new company that will focus on health and well-being. But its…
This concept was suggested by our very own Annalee Newitz, editor-in-chief of io9 and author of Scatter, Adapt And Remember. The idea of repressive desublimation was first developed by by political philosopher Herbert Marcuse in his groundbreaking book Eros and Civilization. Newitz says:
It refers to the kind of soft authoritarianism preferred by wealthy, consumer culture societies that want to repress political dissent. In such societies, pop culture encourages people to desublimate or express their desires, whether those are for sex, drugs or violent video games. At the same time, they’re discouraged from questioning corporate and government authorities. As a result, people feel as if they live in a free society even though they may be under constant surveillance and forced to work at mind-numbing jobs. Basically, consumerism and so-called liberal values distract people from social repression.
Sometimes referred to as IA, this is a specific subset of human enhancement — the augmentation of human intellectual capabilities via technology. “It is often positioned as either a complement to or a competitor to the creation of Artificial Intelligence,” says Ramez Naam. “In reality there is no mutual exclusion between these technologies.” Interestingly, Naam says IA could be a partial solution to the problem of technological unemployment — as a way for humans, or posthumans, to “keep up” with advancing AI and to stay in the loop.
With much of our attention focused the rise of advanced artificial intelligence, few consider the…
This is another term suggested by Stuart Armstrong. He describes it as
the application of cost-effectiveness to charity and other altruistic pursuits. Just as some engineering approaches can be thousands of times more effective at solving problems than others, some charities are thousands of time more effective than others, and some altruistic career paths are thousands of times more effective than others. And increased efficiency translates into many more lives saved, many more people given better outcomes and opportunities throughout the world. It is argued that when charity can be made more effective in this way, it is a moral duty to do so: inefficiency is akin to letting people die.
On a somewhat related note, James Hughes says moral enhancement is another must-know term for futurists of the 21st Century. Also known as virtue engineering, it’s the use of drugs and wearable or implanted devices to enhance self-control, empathy, fairness, mindfulness, intelligence and spiritual experiences.
This one comes via Max More, president and CEO of the Alcor Life Extension Foundation. It’s an interesting and obverse take on the precautionary principle. “Our freedom to innovate technologically is highly valuable — even critical — to humanity,” he told io9. “This implies several imperatives when restrictive measures are proposed: Assess risks and opportunities according to available science, not popular perception. Account for both the costs of the restrictions themselves, and those of opportunities foregone. Favor measures that are proportionate to the probability and magnitude of impacts, and that have a high expectation value. Protect people’s freedom to experiment, innovate, and progress.”
Jamais Cascio suggested this term, though he admits it’s not widely used. Mules are unexpected events — a parallel to Black Swans — that aren’t just outside of our knowledge, but outside of our understanding of how the world works. It’s named after Asimov’s Mule from the Foundation series.
Another must-know term submitted by Cascio, described as “the current geologic age, characterized by substantial alterations of ecosystems through human activity.” (Image credit: NASA/NOAA).
Unlike Moore’s Law, where things are speeding up, Eroom’s Law describes — at least in the pharmaceutical industry — things that are slowing down (which is why it’s Moore’s Law spelled backwards). Ramez Naam says the rate of new drugs developed per dollar spent by the industry has dropped by roughly a factor of 100 over the last 60 years. “Many reasons are proposed for this, including over-regulation, the plucking of low-hanging fruit, diminishing returns of understanding more and more complex systems, and so on,” he told io9.
Natasha Vita-More describes this as the ability of a species to produce variants more apt or powerful than those currently existing within a species:
One way of looking at evolvability is to consider any system — a society or culture, for example, that has evolvable characteristics. Incidentally, it seems that today’s culture is more emergent and mutable than physiological changes occurring in human biology. In the course of a few thousand years, human tools, language, and culture have evolved manifold. The use of tools within a culture has been shaped by the culture and shows observable evolvability-from stones to computers-while human physiology has remained nearly the same.
“This is any device, whether biological or technological, that allows humans to reproduce without using a woman’s uterus,” says Annalee Newitz. Sometimes called a “uterine replicator,” she says these devices would liberate women from the biological difficulties of pregnancy, and free the very act of reproduction from traditional male-female pairings. “Artificial wombs might develop alongside social structures that support families with more than two parents, as well as gay marriage,” says Newitz.
Artificial wombs are a staple of science fiction, but could we really build one? As time passes,…
Whole brain emulations, says Stuart Armstrong, are human brains that have been copied into a computer, and that are then run according to the laws of physics, aiming to reproduce the behaviour of human minds within a digital form. As he told io9,
These days, people worry about robots stealing our jobs. But maybe we should be more concerned…
There's an ongoing debate among neuroscientists, cognitive scientists, and even philosophers…
They are dependent on certain (mild) assumptions on how the brain works, and requires certain enabling technologies, such as scanning devices to make the original brain model, good understanding of biochemistry to run it properly, and sufficiently powerful computers to run it in the first place. There are plausible technology paths that could allow such emulations around 2070 or so, with some large uncertainties. If such emulations are developed, they would revolutionise health, society and economics. For instance, allowing people to survive in digital form, and creating the possibility of “copyable human capital”: skilled, trained and effective workers that can be copied as needed to serve any business purpose.
Armstrong says this also raises great concern over wages, and over the eventual deletion of such copies.
Ramez Naam says this term has gone somewhat out of favor, but it’s still a very important one. It refers to the vast majority of all ‘artificial intelligence’ work that produces useful pattern matching or information processing capabilities, but with no bearing on creating a self-aware sentient being. “Google Search, IBM’s Watson, self-driving cars, autonomous drones, face recognition, some medical diagnostics, and algorithmic stock market traders are all examples of ‘weak AI’,” says Naam. “The large majority of all commercial and research work in AI, machine learning, and related fields is in ‘weak AI’.”
What will happen in the days after the birth of the first true artificial intelligence? If things…
Naam argues that this trend — and the motivations for it — is one of the arguments for the Singularity being further than it appears.
Imagine the fantastic prospect of creating interfaces that connect the brains of two (or more) humans. Already today, scientists have created interfaces that allow humans to move the limb — or in this case, the tail — of another animal. At first, these technologies will be used for therapeutic purposes; they could be used to help people relearn how to use previously paralyzed limbs. More radically, it could eventually be used for recreational purposes. Humans could voluntarily couple themselves and move each other’s body parts.
In what might be the first documented case of technologically-assisted interspecies telepathy, an…
This refers to any situation in which new algorithms can suddenly and dramatically exploit existing computational power far more efficiently than before. This is likely to happen when tons of computational power remains untapped, and when previously used algorithms were suboptimal. This is an important concept as far as the development of AGI (artificial general intelligence) is concerned. As noted by Less Wrong, it
signifies a situation where it becomes possible to create AGIs that can be run using only a small fraction of the easily available hardware resources. This could lead to an intelligence explosion, or to a massive increase in the number of AGIs, as they could be easily copied to run on countless computers. This could make AGIs much more powerful than before, and present an existential risk.
Luke Muehlhauser from the Machine Intelligence Research Institute (MIRI) describes it this way:
Suppose that computing power continues to double according to Moore’s law, but figuring out the algorithms for human-like general intelligence proves to be fiendishly difficult. When the software for general intelligence is finally realized, there could exist a ‘computing overhang’: tremendous amounts of cheap computing power available to run [AIs]. AIs could be copied across the hardware base, causing the AI population to quickly surpass the human population.
This post was originally published on March 17, 2014.
If scuba diving in the Great Barrier Reef is on your bucket list, you might want to book tickets soon. This week, marine biologists dropped some horribly depressing news: the Great Barrier Reef is dying. The world’s largest reef is in the midst of a widespread coral bleaching event, and scientists aren’t sure whether it will fully recover.
Over the past few days, Terry Hughes of James Cook University has led aerial surveys of more than 500 reefs from Cairns to Papa New Guinea, including the most pristine sections of the Great Barrier Reef. Everywhere Hughes traveled, he was met with a nightmarish scene—the ghostly white remains of a once vibrant ecosystem. All told, Hughes estimates that 95 percent of the northern Great Barrier Reef is “severely bleached,” marking the worst such event on record.


“Almost without exception, every reef we flew across showed consistently high levels of bleaching, from the reef slope right up onto the top of the reef,” Hughes said in a statement. “This has been the saddest research trip of my life.”
Coral reefs are extremely temperature-sensitive, and when the water gets a bit too toasty, they expel their symbiotic algae, called zooxanthellae. When this happens, the coral loses both its vibrant color and its ability to feed itself. Bleaching leaves reefs more susceptible to disease and starvation.


Coral bleaching events used to be infrequent and geographically restricted, but recently, they’ve become much more common, widespread, and devastating. The first global bleaching event occurred during the 1997-1998 El Niño and killed a whopping 18 percent of corals across the planet.
Since 2014, we’ve been witness to a souped-up repeat of that event. Corals are bleaching everywhere, because the planet has been too damn hot for too many months on end. In the fall, the National Oceanic Atmospheric Administration (NOAA) predicted that the current global bleaching epidemic would impact nearly 40 percent of all reefs. In February, NOAA added that this year’s monster El Niño was exacerbating the die-off which might not end until 2017.
Coral bleaching in the Great Barrier Reef is a piece of a much bigger picture, and it shows us that even the most pristine ecosystems on Earth are susceptible to the impacts of climate change. The real concern is that these reefs—which provide habitat to roughly a quarter of all marine species—won’t be able to muster a full recovery. “You have reefs getting hammered time and time again, year after year,” NOAA oceanographer Mark Eakin told Gizmodo last month. “Recovery at this point is very limited.”
Like I said—make sure you get that scuba trip in soon.


[BBC]
The radio spectrum is a mess: It’s congested, expensive, and there’s no room for expansion. But DARPA has a plan to change that, by building a system where radio waves can work together using artificial intelligence, rathe than fighting for space.
DARPA launched its latest Grand Challenge last week, and it plans to encourage researchers around the world to develop “smart systems that collaboratively, rather than competitively, adapt in real time to today’s fast-changing, congested spectrum environment... to maximize the flow of radio frequency.” That sounds exciting, because making radio frequency flow more easily means—theoretically, at least—faster data rates, fewer dropped signals, and cheaper connections.


How does DARPA plan to do it? Mainly by removing the human from the equation. That might not be too bad an idea, given the frequency allocation chart actually looks something like this (or at least, it did in 2011):
Instead, DARPA wants researchers to allow the waves themselves to work out how they should fit into the spectrum. It explains:
The primary goal... is to imbue radios with advanced machine-learning capabilities so they can collectively develop strategies that optimize use of the wireless spectrum in ways not possible with today’s intrinsically inefficient approach of pre-allocating exclusive access to designated frequencies. The challenge is expected to both take advantage of recent significant progress in the fields of artificial intelligence and machine learning.
In other words, the new approach would see waves themselves working out what needs to be sent—when, where, and how. So, for instance, safety critical packets of data may receive priority passage across the network, while other signals might barter between each other depending on their relative priorities and importance to agree optimal sharing of the networks.


Taken out of human hands, the signals can be made to act rationally—which means these situations could actually be made to play out optimally, for the network as a whole, if not for each individual user. Researchers from the University of Oxford, for instance, has already shown in a project called ALADDIN that such machine-t0-machine resource allocation like this can theoretically speed up the average arrival time of emergency services across a city.
How this all works in practice, though, is to be decided by the thousands of engineers who will work on projects connected to the DARPA challenge. But the results may be pretty damn exciting.
[DARPA via GizMag]
Remember Sea Monkeys? Remember how disappointed you were when you found out they weren’t really humanoid organisms, but boring old brine shrimp? Now there’s a nifty alternative: the Dino Sphere, a decorative glass sphere that houses thousands of plankton. Swirl the sphere a little at night, and those plankton will emit a bright blue glow.
In essence, it’s “an interactive living world,” with no need for batteries or electricity, according to BioPop, the San Diego-based company that created it. Yes, these are the same folks who brought you the bioluminescent Dino Pet in 2013. Both the Dino Sphere and Dino Pet get their glow from a phenomenon called bioluminescence.

Bioluminescence really is pretty awesome. Large concentrations of bioluminescent bacteria are behind an ocean phenomenon called the “Milky Seas”: glowing white patches of sea water stretching across an expanse as large as Hawaii. Some algae have this ability, too. Other marine organisms—most notably, dinoflagellates—glow in response to some form of physical stimulation. When physically agitated, dinoflagellates give rise to the telltale sparkling wakes that get churned up behind boats at night, like those in the famed Bioluminescent Bay in Vieques, Puerto Rico.


The live dinoflagellates for the Dino Sphere are contained in a Blue Dino Food formulation. Just add to the sphere with water—much like Sea Monkeys—and make sure to maintain the sphere at moderate room temperature and away from direct sunlight. Come nightfall, the blue glowy fun begins—and the later it gets, the brighter the glow. (The plankton won’t glow during the day, even if you take them into a dark room.)
The Dino Sphere is reasonably affordable at $59.95. You can now pre-order one of your very own, for an expected June delivery.
A Canadian company has come up with an algorithm that can read texts, and then accurately answer questions about them. The software is meant to help people by scanning and responding to their questions about boring technical texts—but there could be so many other great ways to use it.
The company, Maluuba, is interested in “building systems that replicate how human beings learn to read, understand, and reason using state-of-the-art deep learning techniques.” If that summary leaves you with some questions, Maluuba’s software might be just the thing to get the answers.


The software is meant to read through the long, boring texts that we don’t want read—like the instructions for a new household appliance. We’d love a computer program that could read boring texts and answer our questions and it’s possible that one day the software could read your notes and schedules, understand them, and make suggestions to keep your prepared for the next day.
The software is fairly proficient at reading stories as well. Specifically, the company had their Machine Comprehension System read Harry Potter and the Philosopher’s Stone, and answer some basic questions about it. The machine managed to answer the questions with 70 percent accuracy. This video shows the testing process:

The machine has to integrate information from different sentences. It also has to discount certain sentences, such as those describing the scene where the sorting hat is deciding whether to put Harry into Slytherin or Gryffindor, because the narrative twists and moves on. Granted, the computer is only completing a multiple choice test, but it’s a good start.


But there’s so much more that could be done. We’d like a computer that could read its own manual and fix itself. How about computer that could scan the comments section of any website and alert you as to which commenters you could avoid and/or fight with, depending on your mood? And what about something that could read ahead and blank out spoilers for movies we haven’t seen yet? This could be the start of a glorious age of non-reading.
[MIT Technology Review, Maluuba ]
A very active volcano erupted in Alaska yesterday afternoon, sending a giant ash cloud up 37,000 feet in the air. Although the eruption is diverting some flights in the area, it will likely only serve as the subject of some beautiful photos—unless a bunch of ash gets sucked into the jet stream.
Located at the very tip of the Aleutian Islands, Pavlof Volcano is one of the most consistently active volcanoes in the region, according to the Alaska Volcano Observatory. Pavlof saw eruptions of similar size in 2013 and 2014.

Although this sort of thing is relatively common, this morning the volcano alert level was raised to “warning,” meaning it’s a potentially hazardous eruption with significant emissions being spewed into the atmosphere. The USGS also raised the aviation code to “red,” meaning that flights are being re-routed to avoid the ash plume. Incredible shots are being captured by the local scientists and by passengers on planes that traveled near the volcano before the alert was raised.

According to volcanologist Ben Edwards, there’s a possibility that Pavlof could morph into something more menacing, but that has to do more with our weather than the eruption. Right now, the plume is moving towards the northeast, towards mainland Alaska. Most of the flights in this area are regional or commuter planes, some of which are being canceled.

However, if the ash gets funneled into the jet stream, which is moving right over the volcano right now, predictions show that the ash could be blasted down over Canada and along the West Coast of the US. It’s a lot like the way smoke from the Alaskan wildfires blew into the Midwest last summer. Except ash from volcanoes is way, way worse for planes.

The last volcano to achieve red alert status was Iceland’s Bárðarbunga, which erupted in 2014. But that volcano didn’t throw the entire planet into global chaos like Eyjafjallajökull did back in 2011, when some people were stranded in Europe for weeks. Luckily, we’re better at modeling ash clouds now so we can predict how they might behave.


[Alaska Volcano Observatory]
Alton Brown has been the world’s preeminent food science wizard since the early days of the Food Network, and he’s about to embark on his second tour. What better way to celebrate than with a big vat of ice cream?
The Jet Cream is essentially three water cooler bottles duct taped together. On one end is a CO2 fire extinguisher, on the other there is a pressurized spray of liquid ice cream. In between, there are a few vent holes to prevent spontaneous explosions.


Brown explains that the ice cream mixture rushing towards an extremely cold gas in a (mostly) closed environment causes a Joule-Thomson effect. All you need to know about this is that the CO2 rushing into the water cooler jugs is about 100 degrees below zero, and because the ice cream mix is a spray, each of those tiny droplets is getting bombarded by all sides by really cold gas and freezing almost instantly. Bonus: The result is carbonated!
Does this work with other beverages? A jet-blasted frozen mojito sounds great right about now.

(If the video is being wonky, just watch it over at Pop Sci)

Washing clothes is boring; being outside in the sun is fun. So this new kind of fabric, which uses light to degrade the organic compounds that make up your filth, can’t be turned into clothes fast enough.
Developed by researchers from Royal Melbourne Institute of Technology at the University in Melbourne, Australia, the fabric contains nanostructures made from copper and silver. Unlike the anti-odor silver nanoparticles you might have been promised would keep your socks smelling fresh, these structures are actually grown directly into the cotton textiles that researchers have been experimenting with. Then they’re fixed in place by a dunk in several fixative solutions.


When sunlight hits the metallic structures, high-energy electrons are released which can break down organic molecules. Experiments showed that deliberately placed stains disappeared within around six minutes. The research is published in Advanced Materials Interfaces.
However, the researchers admit that the fabric still can’t remove the kinds of stains that most of us might be interested in, like tomato sauce and red wine, from its surface. If they can crack that problem, however, our washing machines may get a little less use, because the team reckons the technique is easy to scale up for use at an industrial scale.


[Advanced Materials Interfaces via PhysOrg]
Dealing with people who exhibit passive-aggressive behavior is easily one of the most challenging aspects of our social lives. Here’s what you need to know about this annoying personality quirk and how you can handle people who express their hostility in indirect and backhanded ways.
Interacting with passive-aggressive (PA) people is something many of us are all too familiar with. As a behavior, it manifests in many different ways — some of them quite backhanded and subtle — which can make it difficult to recognize.


Simply put, passive-aggressiveness is a way of expressing hostility, albeit through typically muted, seemingly apathetic, and indirect channels of negative behavior. It can involve everything from the passive resistance of everyday social and work-related tasks (e.g. procrastination, learned helplessness, deliberate inefficiency, and forgetfulness) through to stubbornness, resentment, and contradictory behavior (e.g. appearing to be enthusiastic about something, but purposefully acting in a way that’s unhelpful and sometimes damaging).
Though no longer recognized by the American Psychological Association (APA) as a formal personality disorder (more on this later), it’s something we all have to deal with — both as something that happens to us, and as something we do to others. While it’s crucial to avoid the pathologization of every single behavior that makes us feel bad, threatened, or irritated, it’s important that we still be able to recognize PA behavior when it happens, and understand the most effective ways to deal with it.


But before we get into that, let’s take a look at the rather surprising history of this thing we call passive-aggressive behavior.
Passive-aggressive behavior was first documented during the Second World War when it was used to describe soldiers who refused to comply with their officers’ demands. A 1945 U.S. War Department memo complained about soldiers who were shirking duty through willful incompetence. These soldiers weren’t being openly defiant, noted the memo, but they were expressing their aggressiveness “by passive measures, such as pouting, stubbornness, procrastination, inefficiency, and passive obstructionism.” The War Department construed their behavior as an “immaturity” and a reaction to “routine military stress.”
Over the course of the following decade, this terminology took hold in the military medical literature — and was then passed on to the American psychology community at large. As noted by Northwestern University psychologist Christopher Lane:
Having logged the quirks of servicemen, however, psychiatrists soon began applying the same charges virtually unaltered to civilians. As it readied the first edition of the Diagnostic and Statistical Manual of Mental Disorders for publication in 1952, the APA simply copied the relevant phrases from the military memo and gave them diagnostic codes. Indeed, it adopted the same practice for a large number of behaviors and ailments, making the temporary frustration of the U.S. War Department a basis for establishing lasting pathologies in the population at large.
So, instead of being concerned about soldiers’ disobedience, the APA applied the concept to conflicts at work and home. Psychologists began to construe struggles in the workplace or family as aggressiveness meted out “by passive measures, such as pouting, stubbornness, procrastination, inefficiency, and passive obstruction.”


The effect of this was more sinister than it might appear on first glance. The APA was turning fairly common behaviors into actual disorders of personality; “reactions” to many conflicts were defined as symptoms of “personality,” which were in turn assessed as being pathologic. As Lane explains, the
APA soon broadcast that the businessman or housewife with a “passive aggressive personality” revealed a pathologic “trait disturbance.” Marking a clear deviation from normalcy, their behavior was thus a syndrome that might recur if left untreated. The APA was not simply overdramatizing routine behaviors; it was relabeling them malfunctions of biology and neurology, the direction in which American psychiatry overall was heading.
By DSM II, published in 1968, the APA was defining mental illnesses as lifelong conditions that were independent of the contexts in which bad ‘traits’ were surfacing. Such behaviors were considered maladaptive, and psychologists took the stance these conditions should be treated. Adding insult to injury, the second DSM added two sentences that significantly increased the probability of (mis)diagnosis:
This behavior commonly reflects hostility which the individual feels he dare not express openly. Often the behavior is one expression of the patient’s resentment at failing to find gratification in a relationship with an individual or institution upon which he is over-dependent. (APA, 1968, p. 44, code 301.81)
In the words of Lane, “Not only had the DSM outlawed pouting, then; it left large numbers of people with unfulfilling jobs vulnerable to a psychiatric diagnosis, too.”
The standard was thus set. For nearly four decades, “passive-aggressive personality disorder” (PAPD) was considered a formal DSM pathology.


It was finally dropped from the DSM-IV in 1994. After much debate, it was agreed that, as a personality disorder, it was too narrow, situational, and behavioral to warrant a full-blown diagnosis. What’s more, the APA didn’t think there was enough scientific evidence to back it as a distinct disorder and that it significantly overlapped with other disorders.
Instead, the disorder was diluted, renamed Negativistic Personality Disorder (NEGPD), and appendicized in the DSM for future consideration and study. Symptoms continued to include passive resistance to routine social or work tasks, complaints of being misunderstood, a disdain for authority, envy, and resentment. But under the new name, it could also include negative moods and other non-specific personality issues.
Since then, some psychologists have expressed their dissatisfaction with the omission.


Psychologists Christopher Hopwood and Aidan G. C. Wright say the re-classification and focus on “negativistic ideas” has done much to undermine and undervalue the condition formerly known as PAPD. They claim that the focus on negativity, both in PAPD and NEGPD, has both altered and diminished the usefulness of the concept at the clinical level.


To back their claim, the researchers recruited 1,453 undergraduates who were asked to complete the Personality Diagnostic Questionnaire that corresponds to the DSM. Results showed that the change from PAPD to NEGPD was “substantial” and that the diagnostic criteria has become way too broad. The researchers would like to see Passive-Aggressive Personality Disorder returned to its former status, along with a renewed research focus on the core dimensions of passive aggressive personality, including “irresponsible behavior, inner feelings of inadequacy and need for acknowledgment, and ruminative resentment about and contempt for authority figures.”
A 2009 study in the journal Psychiatry reached a similar conclusion, arguing that “PAPD is a useful clinical construct that deserves careful consideration in clinical assessment and may merit further consideration in discussions of [personality disorders].


With all due respect to these studies, it’s safe to say that PA behavior is problematic and annoying. But whether it deserves to be defined as a bona fide mental illness — and subsequent stigmatization in society at large — seems debatable. Calls to restore its place as a formal pathology are indicative of the struggles of psychiatry to justify its (often qualitative, normative) definitions of mental illness. It’s important to draw a line between pathologizing PA behavior and figuring out how to deal with difficult individuals in one’s life. What’s more, it risks pathologizing compliant defiance in the face of authority, whether it be work-to-rule actions, the Occupy Movement, or (sadly) a potentially abusive home or work environment.
All this said, there’s no denying that passive-aggressive behavior exists and that it poses a challenge for many of us in our daily lives. Though expressed in different ways, it typically involves non-verbal aggression that manifests as negative behavior. Examples include answering “yes” or “no” to an either/or question, deliberately “forgetting” to send an email attachment, or avoiding communication when there’s clearly something important or problematic to be discussed and resolved (storming off or leaving notes are prime examples).
An article from the New York Times offers some other real-world examples:
A 45-year-old college instructor in Hawaii recently broke off a long relationship with a man she said was a “wonderful, devoted listener, an extremely sensitive person.”
But in time, she said, it was apparent that he was also passive-aggressive. On one occasion, she said, he gave away her seat on an airplane while she was finding a storage compartment for her luggage, saying he thought she had taken another seat. On others, he would arrive home early from work and finish off meals they normally shared, without explanation. And when he was in one of his moods, the listening ceased; she may as well not have been in the room.
As noted in the NYT post, one of the most challenging things about living/coping with a passive-aggressive person is that one struggles to understand what they did wrong.


According to Out Of the FOG, a website for family members of people with personality disorders, PA behavior looks like this:
Withdrawal - of material support, contribution to shared goals, Re-prioritizing alternate activities and goals, “go-slow’s”, procrastination or targeted incompetence.
Silent Treatment - inappropriate “one-word” answers, inattention, making yourself generally “unavailable”.
Off-line Criticism - propagating gossip or criticism to a third party in an attempt to negatively influence the third party’s opinion of a person.
Sarcasm, Critical and “Off-Color” Jokes - Humor which targets a specific individual is a form of Passive-Aggressive communication.
Indirect Violence - shows-of-strength such as destruction of property, slamming doors, cruelty to animals in the sight of another is passive-aggressive.
The APA says PA can be detected by four (or more) of the following behavioral traits:
As an aside, passive-aggressive personalities often bear resemblance to pathological narcissism, including the expression of such traits as an exaggerated sense of self worth, lack of impulse control, an inability to empathize, and a sense of entitlement.


http://io9.com/narcissism-is-…
The word “narcissist” is used so much these days that you might think we’re in the midst of an…
The precise causes of passive-aggressive behavior are not known, but it’s likely on account of both environmental and social factors.


In a 2001 study, the heritability of passive-aggressiveness was estimated at 50% in school-age twins (a highly contentious conclusion, to be sure). It has also been associated with a number of social/environmental factors, including ineffective parenting behavior, child abuse, harsh and apathetic parenting, and neglect.


Perhaps counterintuitively, PA behavior also occurs in people who have grown up in loving but demanding families. Benedict Carey from the New York Times explains:
First-born children are prime candidates, [says Dr. Lorna Benjamin, co-director of a clinic at the University of Utah’s Neuropsychiatric Institute in Salt Lake City]. [W]hen younger siblings are born, the oldest may suddenly be expected to take on far more extra work than he or she can handle, and over time begin to resent parents’ demands without daring to defy them.
This hostile cooperation is at the core of passive-aggression, she and other researchers say, and in later in life it is habitually directed at any authority figure, whether a boss, a teacher or a spouse making demands. These passive-aggressive people, Dr. Benjamin said, “are full of unacknowledged contradiction, of angry kindness, compliant defiance, covert assertiveness.”
In terms of risk factors, PAPD has been associated with an increased risk of depression, anxiety disorders, and substance abuse.


As noted, it also shares characteristics with narcissistic personality disorder (NPD). This is interesting because NPD has been linked to fear and decision making processes. Both conditions (such as they are) are characterized by avoidance. In the case of NPD, it’s the fear of dark and negative self-experiences; in the case of PA, it’s the avoidance of direct confrontation and the preference for passive, hostile acts.


Neurologically, there may be something going on in the amygdala, the part of the brain that controls processes like the detection of emotionally arousing and relevant stimuli. There may also be a connection to the prefrontal cortex, the part of the brain responsible for control and our ability to act in socially appropriate ways. Biological alterations or damage could contribute to any number of socially problematic behavioral patterns.
In order to deal with passive-aggressive people, it’s important to know why they’re acting that way.
Here are seven reasons why people use PA behavior, according to Signe Whitson:
Living, working, and interacting with passive-aggressive people is not fun. Thankfully, there are some things you can do to intervene.


First, it’s critical that you identify passive-aggressive behavior when it happens. This isn’t always easy by virtue of the act itself, which is meant to be indirect. Things to look for include people who avoid an argument, fight, or conflict at all costs, being put into “never win” scenarios, constantly having to please a person by telling them what they want to hear, and listening to incessants complaints that “no one wants to know how I feel” or “understand how I feel.”
Second, you need to look at your own behavior and how you’ve been dealing with the passive-aggressive behavior directed towards you. Specifically, it’s important to evaluate whether you’ve contributed to the conflict and determine if your actions have worked to either escalate or de-escalate the confrontation. (At the same time — and this is not easy — it’s important that you not feel responsible for another person’s PA words or actions.)
The College of Education + Human Development says that:
One good reflection of what works and does not work are your feelings after a conflict. If you end up feeling helpless, powerless, angry, and confused, your methods have not worked and you should change them. If you end up feeling calm, the [PA person] has regained composure and you believe that they may have learned something to help improve behavior, your methods are an effective way of dealing with [them]. In short, drop what is not working and identify methods which are working.
Other tips: Don’t allow yourself to be manipulated, stay emotionally calm, and don’t respond with your own set of passive-aggressive tactics. Also, do something healthy and productive for yourself.


Another way to deal with passive-aggressive people is to disarm them with honesty and focus the conversation on the real issue. Writing in her blog, Trulia, Mallory Carra says we should open up communication immediately rather than storming off or engaging in reciprocal passive-aggressive behaviors. She quotes marriage and family therapist Lisa Bahar who says:
Generally, the feeling that you feel from the individual that is acting out passive-aggressive can give you some information on what they are trying to communicate; however, the goal is to not trouble yourself with reading into the implied message. The idea is to communicate in an assertive way. Be matter of fact, avoid gossip, cold shoulders, huffing and puffing.
Indeed, sometimes it’s best to initiate the conversation and tell the other person that they can always speak directly to you if they have an issue. The practice of leaving notes or hinting at things in an obfuscating or abstract way doesn’t really help the situation.


It’s also important to realize that you probably won’t be able to change the person. What you can do, however, is establish the normative parameters as it relates to your interactions with them. Your PA friends, co-workers, and family members may eventually learn that the best way to engage with you and address contentious issues is to avoid passive-aggressive behaviors in favor of more direct methods. But this will only be possible over time and with great patience and consistency on your part. That said, it’s important to model constructive behavior, hand out heaps of positive reinforcement, and cooperate and negotiate in ways that’s fair to both of you.
Additional reporting by Levi Gadye.


This article originally appeared at io9 on January 22, 2015.


Sources: NYT (2) | APA: DSM5 | C. J. Hopwood et al.: “The Construct Validity of Passive-Aggressive Personality Disorder” 2009 | CEHD | C. Lane: “The Surprising History of Passive-Aggressive Disorder” 2009 | Out of the FOG
Galactic collisions are a relatively common occurrence in the universe, but every once in a while an entire cluster of galaxies will smash into another one in a massive celestial bang up. And as this new Hubble photo attests, the results can be quite dramatic.
MACS J0416 looks like a single object, but it’s comprised of two separate galaxy clusters on the cusp of merging. It’s located in the constellation Eridanus some 4.3 billion light-years away, and collectively boasts a mass 420 times greater than the Milky Way galaxy.
In the image, it looks like the two clusters have already collided, but the evidence suggests it hasn’t quite happened yet. For starters, traces of dark matter are still aligned with the blue-hued hot gas. If the clusters had already slammed into one another, the dark matter and the gas would have separated. Also, MACS J0416 contains a compact core of hot gas, which would also have been disrupted in the event of a collision.


Interestingly, the massive weight of this object is strong enough to bend light, creating an effect known as gravitational lensing. This cosmological quirk allows astronomers to peer behind the object and catch a glimpse of galaxies that existed only hundreds of millions of years after the Big Bang.
[NASA]
The barren wilderness that is Antarctica—where temperatures drop below -100 degrees Fahrenheit and winds whistle by at 200mph—is a raw but majestic spot for a picnic. But spare a thought for Floris van den Berg, the guy in this photo—because he won’t see sunlight for months.
See, van den Berg is one of a small team of researchers stationed at the Concordia research lab in Antarctica. This picnic—including a bottle of champagne, by the looks of things—was a chance to soak up some sun before it finally disappears for good. Between April and August, the moon and the aurora australis are the only sources of natural light at the Concordia lab.


But as a doctor tasked with researching the effects of the extreme conditions on the human bodies of the other team members, van den Berg will have plenty to keep him busy. Let’s hope he enjoyed the picnic.
[ESA]
Two years ago, a Phoenix-based photographer teamed up with physicists at Princeton University to explore the unusually uniform rings a drop of whisky leaves behind when it dries. Now those same physicists have published their findings in Physical Review Letters.
Inspired by his wife’s love of whisky, photographer Ernie Button began photographing various samples—notably, the intricate complex patterns that would form in the bottom of the glass as the liquid evaporated. He used different colors of light to highlight those patterns. Over time, he noticed that only certain whiskies would leave behind those telltale rings (aged Scotch, American, or Irish whiskies). So he contacted Princeton physicist Howard Stone, who agreed to investigate why this happened.


You may have noticed those uneven stains that develop on your coffee table when thoughtless guests forget to use coasters. It’s called the “coffee ring effect”: the pattern you get when a single liquid evaporates and leaves behind a ring of previously dissolved solids. In the case of coffee, that would be the coffee grounds. The ring occurs because the liquid evaporates more quickly at the edges of the drop than at the center. So the remaining liquid at the center will flow outward to the edges to fill in the gaps, dragging particles like coffee grounds with it.
Whisky is a so-called “binary liquid,” meaning that it is about 60 percent water and 40 percent ethanol. Scientists already knew that mixing a solvent like water and alcohol could reduce the coffee ring effect, but usually this only works for really tiny drops.


Whisky is different. Button’s photographs showed that you could get uniform stains from larger drops of whisky. Coffee rings are darker at the edges than in the middle, whereas whisky dries into complex ridge pattern at the bottom of a glass.
Stone and his colleagues ran several experiments, and found that there are two types of molecules at work here. One type acts as a surfactant, while another polymer type serves to keep particles stuck to the surface, rather than being carried along with the flow. As Michael Schirber writes at Physics Focus:
As a drop evaporates, the surfactants collect on the edge, creating a tension gradient that pulls liquid inward (the so-called Marangoni effect). In addition, plant-derived polymers stick to the glass, helping to channel particles to the substrate where they adhere. To confirm this picture, the researchers showed that whisky-like liquids lacking either polymers or surfactants did not produce uniform stains.
The Marangoni effect is also behind the phenomenon of “tears of wine”—that ring of clear liquid that forms near the top of your glass, just above the surface of the wine.
Stone’s group gave a presentation at a 2014 physics conference reporting on their initial results, “but it took some time to complete the detailed measurements, write the work up for publication, and see [it] through the review process,” he told Gizmodo. Stone admitted that they were not able to identify the precise ingredients in whisky that are associated with these surfactant and polymer effects—the chemistry of whisky is pretty complicated— but they do have a few possible suspects.
There are some practical applications for this work, namely improving the uniformity of coatings in various industrial applications—like 3D printers, which use a technique called liquid deposition to buildup layers upon layers during printing.


“Our work suggests minimal ingredients to obtain nearly uniform coatings of particles,” said Stone—that is, you want to use as few ingredients as possible in your mixtures for coatings.
Mostly, though, it’s a charming example of how science and art can work together in symbiosis, each side gaining something from the interaction. For Stone and his colleagues, it was an intriguing science question that led to the recently published paper. Button learned a bit of useful science and produced some genuinely striking photographs. You can check out the entire whisky-inspired series here.
[Physical Review Letters]
On March 25, 1921, the USS Conestoga departed San Francisco’s Golden Gate en route to Hawaii with 56 officers and sailors aboard. It was never heard from again. Now, after 95 years, the ship has been found at the bottom of the Pacific, finally ending this enduring maritime mystery.
NOAA and the US Navy announced the official discovery of the USS Conestoga (AT-54) yesterday. The First World War-era tugboat disappeared without a trace after setting off for Tutuila, American Samoa, by way of Pearl Harbor, Hawaii. Its discovery shows that the ship never made it very far, sinking in stormy weather just 30 miles (48 km) from its departure point. Until now, now one knew where the wreck was located, or what happened.


“After nearly a century of ambiguity and a profound sense of loss, the Conestoga’s disappearance is no longer is a mystery,” noted deputy NOAA administrator Manson Brown in an emailed statement. “We hope that this discovery brings the families of its lost crew some measure of closure and we look forward to working with the Navy to protect this historic shipwreck and honor the crew who paid the ultimate price for their service to the country.”
No one realized that the ship was missing until more than a month had passed and it failed to show up at Pearl Harbor on its anticipated arrival date. The US Navy dispatched a massive air and sea search around the Hawaiian islands consisting of 60 ships and dozens of planes covering 300,000 square miles. Several weeks later, on May 17, a battered lifeboat was discovered with the letter “C” on its bow off the coast of Mexico, dramatically shifting the location of the search. The mysterious disappearance of the USS Conestoga gripped the nation for months. Finally, on June 30, 1921, the ship was declared lost, with all 56 crew members presumed dead. It would be the last time a U.S. Navy ship was lost without a trace during peacetime.


Seven year ago, the NOAA Office of Coast Survey discovered a probable, undocumented shipwreck near the Farallon Islands off San Francisco. In September 2014, NOAA launched a two-year investigation. Last October, with the help of an archaeologist from the Naval History and Heritage Command and several senior Navy officers, the Conestoga’s identification and location was confirmed. But more work was required to ascertain the conditions under which the ship sank.
The USS Conestoga is currently resting largely intact under 189 feet (57 meters) of water, three miles from Southeast Farallon Island. Based on its location and orientation, experts believe it sank as officers and crew desperately tried to reach a protected cove on the island. According to weather logs around the time of the ship’s departure, wind in the Golden Gate area had increased from 23 mph (37 km/h) to 40 mph (64 km/h), and the seas were choppy with high waves.
“This would have been a desperate act, as the approach is difficult and the area was the setting for five shipwrecks between 1858 and 1907,” notes NOAA’s report. “However, as Conestoga was in trouble and filling with water, it seemingly was the only choice to make.”
Cameras mounted on remotely operated vehicles show the wreck lying on the seabed. The tug’s wooden deck and upper features have collapsed into the hull owing to corrosion and age. White plume anemones now drape the hull’s exterior, while wolf eels, ling cod, and rockfish frequent the wreck.
Video evidence displayed features consistent with the Conestoga, including the number of portholes, the size of the 170-foot long ship ship, and the presence of mooring bits, two porcelain marine heads, and a single, 3-inch, 50-caliber gun mounted on the main deck, among many other clues.
NOAA did not disturb the wreck, nor does it plan to. Under the Sunken Military Craft Act of 2004, no one is allowed to perturb sunken military vessels or planes owned by the US government, or foreign sunken military vessels that lie within US waters.


The USS Conestoga was originally built to tug coal barges for the railroad, but the US Navy bought the ship in 1917 for service in World War One. During the conflict, the tugboat operated off the Atlantic coast and the Azores, performing convoy and other duties. After the war, it was sent to Norfolk, Virginia, for harbor service, after which time it made its way to the Pacific performing similar duties.
[NOAA]
Behold syn3.0, a synthetic bacterial genome that’s smaller than anything found in nature. Biologists hope it will further our understanding of the fundamentals of life and inspire the creation of new synthetic life.
Dubbed JCVI-syn3.0 (or just syn3.0 for short), the new genome was designed and built by researchers from Synthetic Genomics and the J. Craig Venter Institute. It’s known as a “radically minimalist” genome because it has just 473 genes—the minimal number required for this bacterial cell to sustain the most basic functions of life, including reproduction. The details of this extraordinary achievement can now be found in the latest edition of Science.
It may sound like a strange endeavor, but there are some very good reasons for wanting to create a minimal genome. Evolutionary biologists will study it to better understand the processes under which complex organisms evolved from simpler ones. It could be used to explore the core functions of life, and to categorize essential genes within cells.


It also represents an important step in the nascent field of synthetic biology and the effort to build artificial organisms. Researchers could use this as a basic template to construct novel organisms with functions not seen in nature, including bacteria that can eat plastic and toxic waste, microorganisms that function like medicines inside the body, and biofuels comprised of organic components. More conceptually, this work could help astrobiologists predict what kinds of alien lifeforms might exist elsewhere in the cosmos.
This project, led by synthetic biologist Craig Venter and microbiologist Clyde Hutchison, dates back nearly 20 years to the very first sequencing of a bacterial genome. At the time, biologists began to speculate about a hypothetical minimal genome (HMG) for cells and other simple organisms. In 1995 it was theorized that a minimal bacterial cell genome would consist of 256 genes. Venter and his pals decided to test that assumption.


As Venter explained during a press briefing yesterday, “The only way to understand the minimal genome is to actually synthesize a genome.” Six years ago, his team accomplished that goal when it designed, constructed, and generated a self-replicating, synthetic bacterial cell derived from the Mycoplasma mycoides bacterium (so technically speaking the synthetic cell wasn’t designed from scratch). At the time, Venter described it as “the first species...to have its parents be a computer.” The experiment proved that genomes can be designed in a computer, then chemically created in the lab and transplanted into a recipient cell, and that these cells retain their capacity for self-replication.
The next step was to parse M. mycoides down to its essential elements. Venter thought it would take his team about a year, but the process turned out to be incredibly arduous, requiring four more years than initially planned. “Even with the sequence in hand, deciphering the operating system of the cell was a daunting task,” said Venter.
Early on in the process, every design failed, so they decided to try a new approach. The researchers constructed their synthetic cell from eight genetic segments, each of which could be tested independently within a genome that was seven-eighths complete.


They classified genes as being essential, quasi-essential (i.e. genes required for growth, but not absolutely required for life), or nonessential, and they established rules for removing genes from the genome design without disturbing expression of the remaining genes.
To deliberately knock out genetic function, the researchers inserted foreign genetic sequences, called transposons. This process was repeated until no more genes could be disrupted, and the genome was whittled down to the smallest size possible.
The researchers eventually came up with a new self-replicating cell. Of syn3.0's 473 genes, 438 encode proteins and 35 encode annotated RNAs. They were able to delete 428 genes from the starting total. The synthetic genome lacks all DNA-modifying and restrictions genes, and also genes responsible for encoding lipoproteins (proteins that transport fat or other lipids in the blood plasma). The researchers said it’s a “working approximation to a minimal cell,” with a genome “smaller than that of any autonomously replicating cell found in nature.” By comparison, the naturally occurring Mycoplasma genitalium bacterium has 525 genes.
During the process, however, the removal of some genes classified as “non-essential” caused unforeseen problems. Certain genes had to be retained in the minimal genome, despite having no known or obvious function. In total, the researchers were unable to determine the function of 149 genes, which is almost a third of the entire genome.


Based on analogous genes in other organisms, the researchers suspect that these genes have something to do with the encoding of universal proteins. But they’re not entirely sure.
This proved to be a rather eye-opening revelation, and the researchers said this is a high priority for the next stage of the project. It also shows how much there is still to know about whole-gene expression and design. As Venter put it, “The next stages are not going to be trivial.”
This lack of understanding shows how important it is to have a genome-centric view of the fundamentals of life, rather than a reductionist gene-specific view. “Life is more like an orchestra than a single piccolo player,” said Hutchison. “Sometimes you don’t discover essentiality until you remove a second [gene].”


In addition retaining some genes of unknown function, the researchers also had to include a significant number of quasi-essential genes required for robust growth, but not required for the basic functions of life. Technically speaking, the genome could have been stripped down even further, but cellular growth would have been so painstakingly slow as to render the cell useless for scientific experimentation. This shows that, during the miniaturization process, there’s a tradeoff between genome size and growth rate.
Syn3.0 represents a minimal genome for M. mycoides under ideal laboratory conditions. In all likelihood, it would not survive outside the lab. Any “adaptive” traits it might have had were removed. Also, other bacteria would undoubtedly have a different minimal genome, which is dependant on physical characteristics and environmental conditions. “Minimum is a relative term, based on your definition of traits and functions of a cell,” said Venter. “So if you want a cell to have [say] photosynthetic properties, there will be totally different set of genes to support those functions.”
At any rate, the point of the experiment was to create a baseline genome that scientists can use to study life, and to use as a “chassis” for adding new sets of genes. In theory, syn3.0 can be used to construct virtually any kind of cell with custom-built properties. As study co-author Dan Gibson explained, the long term vision is “to design and build synthetic organisms on demand,” and to “add functions and predict outcomes.” He said it could be used in many industrial applications, including medicine, biochemicals, biofuels, nutrition, and agriculture.


Venter and his colleagues are toying with the idea of launching a contest to see who can devise the most beneficial and innovative “gain of functions” for their minimal genome. In the meantime, they are filing patents, both on syn3.0 and the process used to create it.
[Science]
This cute little styrofoam cup is meeting its gruesome end with a brave face.
Seriously though, the way acetone eats through styrofoam cups is mind-boggling, both in how fast it works, and because the cup seems to just disappear as if it’s slipping through some weird chemical portal. How’s it doing that?


The short answer is that acetone is a really good solvent, especially of polystyrene—and styrofoam is just polystrene and a lot of air. When it dissolves it seems to disappear because styrofoam contains so little actual material. That said, no amount of scientific knowledge will help me feel less bad for that poor, evaporating smiley face.

