
Before Steve Bannon was Donald Trump’s campaign advisor, a right-wing media mogul, or a conservative Hollywood documentarian, he helped a group of climate scientists steer a controversial experiment in the Arizona desert back from financial chaos. Twenty-five years ago, a New Agey-experiment called Biosphere 2 set out to recreate life on another planet with eight people locked in a giant glass habitat. But it ended bitterly with allegations of financial fraud, scientific goof-ups, and a power struggle outside the dome.
Now some of the scientists who worked on Biosphere 2 hope that Bannon—who has been dogged by allegations of ties to the white nationalist alt-right movement—might steer Trump back from the edge of climate denial, and perhaps forge a better deal between the US and other nations intent on reducing heat-trapping greenhouses gases. That might seem far-fetched for someone whose website, Breitbart News, calls climate change a hoax and those who study it corrupt. But these scientists point to Bannon’s time as a successful turn-around manager of Biosphere 2 in the mid-1990s as proof that he understands climate science—and may not be as much of a climate denial zealot as the folks who write for his website.
Biosphere 2 was designed to replicate life on Earth. Inside a massive enclosed glass structure, environmental scientists built separate chambers or biomes stocked with plants from desert, forest, grassland, and ocean habitats. They wanted to create a self-sustaining ecosystem—90 feet high, with 3.14 acres under glass—that required no inputs from the outside. If the researchers could figure out how to keep the giant hothouse sustainable, perhaps they could one day grow food on the Moon, Mars, or a long-distance space journey.
Funded by billionaire Ed Bass, Biosphere 2 (Biosphere 1 being planet Earth) got off to an auspicious beginning in 1991. Eight so-called biospherians—four men and four women dressed in matching blue jumpsuits—embarked on a two-year "mission" inside the dome, along with 4,000 plant and animal species. The crew maintained daily contact with scientists and managers through a direct video link, but otherwise slept, ate, and worked together just as they would on a separate planet. The scientific mission was to see if the team could grow their own food, keep the flora and fauna alive, and maintain a balanced air supply.
After a while, weird ecological things started happening. The atmospheric oxygen levels inexplicably dipped from 20 percent to below 15 percent, forcing the project's doctor to pump almost 21,000 pounds of liquid oxygen into the dome. The crew couldn't raise enough food, and lost weight. Fish and pollinating species died, while ants and cockroaches proliferated and took over the three-acre ship-in-a-bottle. One biospherian who left the habitat for medical reasons may have returned with duffels stuffed with supplies.
Steve Bannon backstage after a campaign event for Donald Trump in Phoenix, AZ on October 29, 2016.
After the crew of eight emerged in September 1993, the scientists set out to fix the atmosphere problems. Two scientists at Columbia University figured out that microbes in the soil were consuming excess organic matter and respiring extra carbon dioxide, while the biosphere's exposed beams were consuming the CO2 along with an extra oxygen molecule from the air and turning it into calcium carbonate.
With the case of the missing oxygen solved, the Biosphere managers recruited a second team of biospherians. But that’s when things got weird outside the dome. All of the changes had put the Biosphere an estimated $20 million in debt. So Bass, the owner, hired Bannon—then a Wall Street investment banker a few years out of the Navy—to right the struggling bio-ship.
Bannon was all business. In late 1993, he audited the books and submitted a plan that called for removing the on-site managers. Bannon left the Biosphere 2 project in September 1993, but returned when Bass decided to put Bannon in charge and stop cost overruns on the order of $1 million per month.
On April 1, 1994, Bannon arrived at the facility outside Oracle, AZ, with a pair of federal marshals to enforce a court order turning the whole place over to him. Inside, the biospherians were inside taking air samples, feeding the remaining animals, and running environmental science experiments. Bannon hired off-duty police to patrol the site and keep the ousted leadership away. But two former biospherians who had been fired in the Bannon coup, Abigail Alling and Mark Van Thillo, broke the seal to warn the new crew that they were in danger—they believed Bannon was going to cut funds that maintained the environmental systems. Alling wrote a five-page memo detailing her concerns, a memo that Bannon later threatened to “ram down her – throat.”
The dispute got legally nasty. Bannon pursued criminal charges against Alling and Van Thillo, while the pair sued over their dismissal. Eventually, the former leadership dispersed. Alling and Van Thillo formed an environmental research group called the Biosphere Foundation, and sailed the Pacific in a boat called Mir. Bannon took over and continued to improve operations at the biosphere.
“There was mistrust and probably some poor management of the finances by the people who were in there before,” says Tony Burgess, one of the few scientists who worked for both Bannon and the former leadership. The biosphere's culture, at the beginning, was that of idealistic space hippies building a better world. But Bannon shifted the focus, as a clear-eyed financier of climate research. “Steve came in and tried to change it around," says Burgess. "It was costing $3 million a year just to cool the place, and the idea was to see how could it pay for itself. That began a long struggle to see how a closed system could justify itself in mainstream terms.”
Bannon never expressed personal opinions about climate change, but he did sell the idea of Biosphere 2 as a climate laboratory to the press and potential investors, including in a 1995 interview with C-SPAN. “What a lot of the scientists who are studying global change and the effects of greenhouse gases, many of them feel the Earth’s atmosphere in 100 years is what Biosphere 2’s atmosphere is today,” Bannon said in the interview. “This allows them to study the impact of enhanced CO2 on humans, plants, and animals.”
With the Biosphere 2 bleeding money, Bannon decided to shut down the crew habitat. He persuaded a timber company to remove one of the biomes and replant it with poplar trees in one habitat to measure how quickly commercially harvested trees would grow in a carbon dioxide-rich atmosphere. “They shot right up,” says Burgess. At times, Burgess said, carbon dioxide levels reached up to 4,000 parts per million inside the biosphere, ten times current levels on Earth.
Bernd Zabel, who managed construction of the dome in the late 1980s and spent six months inside the dome, compared Bannon to a “hot-shot” fireman who parachutes into a forest fire. “Everyone understood his mission,” says Zabel, now a retired engineer living in the Tucson area. “He was sent in by the owner to see what can be done with Biosphere 2. Steve was the one with idea to get more scientists involved.” With more than 100 employees, Biosphere 2 wasn’t just a backyard fantasyland. It added a conference center, café, and links to academia.
“I liked him,” said Zabel. “We had a good working relationship. He was fair. He was type-A personality on overdrive. He was breathing, sweating, thinking Biosphere 2. There was nothing else.”
Bannon left Biosphere 2 after Columbia University agreed to take over management of the facility, which is now run by the University of Arizona. In the two decades since then, Bannon made a lot of money on Wall Street and became enamored of right-wing politics. He produced flattering films about Sarah Palin, Michelle Bachmann, and Ronald Reagan. And more recently, he's taken over as publisher of Breitbart News, giving a platform to populist and white nationalist viewpoints, critics say. He outlined his political views in a 2014 talk in Vienna and the “global war against Islamic fascism.”
People’s views change over time, and it’s possible that Bannon’s understanding of the science of climate change has now drifted into climate denial. InsideClimateNews recently documented the connections between Bannon, Breitbart articles, and fossil-fuel executives working against climate regulations. But the researchers he worked with at Biosphere 2 nearly 25 years ago seem to have hope that Bannon may be less ideological than he appears.
Bruno Marino, an isotopic chemist who helped track atmospheric compounds inside Biosphere 2, spent a lot of time working with Bannon in 1994 and 1995. He remembers him keeping a private office at the Arizona compound stocked with dozens books about climate science, including The Biosphere, a 1926 book by Russian mineralogist Vladimir Vernadsky that first sketched out the scientific theory that living things, including humans, can change the planet, just as much as geological or physical forces.
“At the time I didn’t think much of it,” says Bruno, who now runs a small environmental consulting firm in Cambridge, Mass., and last saw Bannon about 10 years ago. “It may mean he was interested in climate issue more broadly. I don’t know. I hope maybe he will have some role to play in Trump’s climate policy moving forward.”
Bannon’s statements on politics, race, and religion have been dissected for clues of what a Trump White House will do in the coming four years. The question is whether Trump’s climate policies will reflect the views of Brietbart Bannon—or Biosphere Bannon.
On Sunday, the US Army Corp of Engineers blocked the Dakota Access Pipeline's passage through Sioux Standing Rock reservation. This marks a victory for protestors who have been camped out for eight months on the Cannon Ball Native American tribal land—the $3.7 billion dollar pipe was supposed to pump 450,000 barrels of crude oil a day under the Missouri River just north of the reservation. If the pipeline were built, it could burst and threaten the tribe's water.
This is the third time the Army Corps has rerouted the DAPL. You might not have known that, because those other two times were not preceded by national outcry. They happened, though, for the same essential reasons: because the Army Corps decided that the pipe's route was environmentally unsafe. Which is probably going to be a problem no matter where the Army Corps gives the DAPL's owners permission to build. The pipeline has to cross water at some point, and wherever it does, it is—like all oil-moving operations—likely going to put another community's water at risk.
“You certainly can’t build a pipeline for hundreds of miles across the West without running into rivers," says Carl Weimer, executive director of Pipeline Safety Trust, an organization that advocates for fuel transportation safety. “River crossings can be problematic because rivers move a lot of dirt, and the Army Corps has to plan those crossings well so the pipeline doesn't get scoured out by the river."
Long before the Standing Rock dissent, DAPL was proposed to run past Bismarck, North Dakota's largest city and capital. But the US Army Corp of Engineers squashed the plan in 2014, because the pipe would have been too close to the city’s municipal water supply: Its contents could seep into the groundwater and contaminate taps. So the pipeline’s operator, Energy Transfer Partners, rerouted the pipeline through the less populated Standing Rock reservation—which, obviously, didn’t really solve the problem. The Army Corp’s decision Sunday will be the start of yet another lengthy review for a new route, which will likely delay pipeline completion.
Police set up barbed wire on Turtle Island after protesters assembled a bridge to access it in Cannon Ball, ND on November 25, 2016.
The DAPL's goal is to connect North Dakota's Bakken oil fields to another, older pipeline in Pakota, Illinois—which goes south to refineries in the Gulf Coast. Now, pipelines are actually the safest way to move vast volumes of oil. Compared to other transportation modes, like trains and trucks, they are also much cheaper. But what's safest for people isn't always so for the environment.
During the plotting stages, civil engineers start with a straight line between two points, and then route around trouble spots. Dense, populated regions have strict regulations: Running a pipe through the area would mean high operational fees and higher property costs. Companies will also try to avoid difficult geology, like water crossings.
Oil moves through water systems differently depending on its viscosity—so the type of oil going through the pipeline influences where it’s routed. The light, sweet crude that could leak out of the Dakota Access Pipeline is actually much more hazardous than the heavy tar the Keystone XL pipeline would have shipped. Spilled DAPL lubricant would stay on the surface, moving faster through a water system than the thick, dense tar sands oil. It’s also easier for the DAPL's oil to leak into the groundwater supply. “Both of the oils will soak up down into the groundwater," says Weiner. "But the tar sands won’t soak into the groundwater quite as quickly. When it comes out of a pipeline the diluted part evaporates out, and the rest of the oil is so dense it turns into a wax or peanut butter-like paste." So companies have to be more considerate when designing routes for pipelines carrying light crude.
A water protector sits by the Cannon Ball River at the Oceti Sakowin camp near Cannon Ball, ND, on November 30, 2016.
All of these environmental considerations are enforced by state and federal regulatory agencies. For the most part, pipeline operators deal with each state's oil pipeline rules: “Some states have a decent process and some have none, in which case, it might fall down to the county level,” says Weimer. And companies will go to great lengths to avoid going across federal lands and large rivers, because that means the US Army Corp of Engineers has to get involved.
In North Dakota, the Public Service Commission assessed all the private land DAPL ran through—which, in this case, was everything except the Missouri River crossing in both Bismarck and Standing Rock. Because it is so large, the Missouri falls under the Army Corps' jurisdiction, which makes its routing decisions after conducting an environmental assessment plan of potential spill impacts. At the time of publication, the Army Corps had not returned a request for comment about its plans for Standing Rock. But the company, state, and Army Corps will try to avoid cities, rivers, and other environmentally sensitive areas.
The Dakota Access Pipeline is almost complete: It already meanders through four states and 1,170 miles. But Energy Transfer Partners, the pipeline's owner, can't ship a drop of oil until the Army Corps clears a new river crossing. Then, the North Dakota Public Service Commission has to once again assess all the parts in between. “We wouldn’t map the rest of it without knowing where they’re going to cross the river,” says Stacy Eberl, the agency's spokesperson. No matter what route they choose, protestors will probably be standing by: Any pipeline crossing will impact *some *water supply somewhere.
If Sammy Jo Wilkinson had a spirit animal, it would be Marty McFly. For the past four years, the 51 year-old California resident has been using stem cell therapy to beat her secondary progressive multiple sclerosis back into remission. Gone is the paralysis to the left side of her face and the numbness in her fingers. In February, she walked for the first time in years. “I’m living in a future that everybody will have some day,” says Wilkinson, who co-founded the patient’s rights group Patients for Stem Cells. “We’re trying to tell everybody the solution is here now, we just need a logical way to bring this to patients sooner rather than later.”
According to Congress, that logical way is the 21st Century Cures Act, a labyrinthine bill that would make the most significant changes in decades to how medical treatments are tested and brought to market. Politicians are working overtime to pass it before the new year—it’s the number one priority for the lame duck session, passing the House on November 30 and advancing through the Senate last night. Final passage is expected to follow later this week.
In some ways, the legislation lives up to its name: It includes ambitious goals to advance biomedical science, and will inject $4.8 billion into a long-stagnating National Institute of Health budget. But attached to those promises is a roadmap for abandoning the gold standard of medicine in favor of an expedited “middle path” for drugs, medical devices, and regenerative therapies. Critics say it’s deregulation in sheep’s clothing—and worry that both science and patients are going to suffer.
Whether you applaud or decry the legislation, it’s almost certain to pass and be signed into law, if not by President Obama, then by the incoming administration. Which means regenerative medicine is headed for prime time. Welcome to the era of “inject and see.”
In 2012, Wilkinson flew to Houston to receive her first stem cell treatment at Celltex Therapeutics. Technicians there extracted adult stem cells from her fat tissue, then cultured them for 13 days, allowing the population to expand before injecting the cells back into Wilkinson. The effects, she says, were immediate. She had less pain, more energy. But a few months later, the US Food and Drug Administration ruled that Celltex was violating a 2006 rule change that allowed the FDA to regulate expanded cell populations as drugs. They would need to get agency approval before being used in treatments.
These actions became the most visible confrontation in a bitter, decade-long battle between regulators and patients regarding the legality of regenerative therapies. While some companies, like Celltex, moved their operations to Mexico to skirt regulations, other small clinics with lower profiles rushed to fill the void. The FDA has been slow to investigate the proliferation of these clinics and the therapies they market. Today there are close to 600 businesses in America selling stem cell solutions for everything from deafness to Alzheimer’s and autism, all without FDA approval, according to a study published in February by Paul Knoepfler and Leigh Turner.
Turner, who is a bioethicist at the University of Minnesota, was surprised by the scale of exploitative behavior he found. “Anyone can buy a domain name and create a website and make grandiose therapeutic claims that have no basis in reality whatsoever," he says. The situation has prompted scientists and policy wonks to dub stem cell clinics “medicine’s wild west." The 21st Century Cures Act will change that—not by reining in unproven, unregulated treatments, but by providing a direct path to medical acceptance. Under the act, the FDA would have the authority to grant accelerated approval for regenerative medicines, skipping straight from animal models and safety trials, over efficacy testing in humans, to post-market review. The new laws would also compel the FDA to update its regulations for such products.
That, Turner says, could be a disaster for traditional stem cell research. “If you legitimize these therapies and allow businesses to commercialize them, then it becomes difficult to recruit individuals for actual phase 3 clinical trials,” he says. Clinical trials have guidelines about who can and can't participate—these inclusion/exclusion criteria helps to produce reliable results. People who go onto the marketplace and get an unapproved therapy won’t be able to participate because their inclusion criteria becomes compromised. “They’ll be lost to science,” says Turner.
Knoepfler, who is a stem cell researcher at UC Davis, is worried about an even more troubling outcome: What happens once people get hurt by these therapies, either physically or financially? Phase 3 studies typically include a much larger number of participants to enable statistical assessment of clinical benefit and detection of any unusual risks not discovered in smaller studies. Eschewing this step places those risks and uncertainties squarely on the shoulders of paying patients. Because treatments aren't covered by public or private insurers, patients can spend a fortune in their quest for a cure (Wilkinson has spent $90,000 out of pocket). Or worse, develop a tumor, go blind, or have a stroke and die.
“I think we’re going to hear a lot more about that in the next few years,” says Knoepfler. Which is unfortunate timing, since that’s when he expects real, rigorously tested therapies to be coming online. Stem cell treatments that help diabetics grow new insulin-making pancreatic cells, halt the progression of ALS, and strengthen cardiac muscle cells in people suffering from heart failure are just some of the therapies advancing steadily down the full clinical trial pathway. "There’s real hope, he says. "And my worry is that the dark echo of the clinics will negatively impact the perception of the whole stem cell arena.”
But people like Wilkinson don’t have that kind of time. “Facebook is more like an obituary page some days, and I’m just tired of watching my friends die,” she says. Her organization was instrumental in getting a record number of comments during the FDA’s public hearings on draft guidances for stem cell therapies in September. She says she’s not paid by Celltex or anyone else to be a voice for the technology, and really just wants the FDA to stop telling her what she can and can’t do with her own cells.
While patients and regenerative medicine investors celebrate and researchers raise alarms, top FDA officials are holding their ground. In an article published in the New England Journal of Medicine last Wednesday, FDA Commissioner Robert Califf expressed skepticism about the safety and efficacy of stem cell treatments. “The current excitement over the potential for stem cell therapy to improve patient outcomes even cure disease is understandable,” he wrote. “However, to ensure that this emerging field fulfills its potential promise to patients, we must first understand its risk and benefits and develop therapeutic approaches based on sound science.”
The timing of the article suggests the FDA won't be wielding its authority to accelerate approvals any time soon. Won't, or perhaps can't. The 21st Century Cures Act doesn't exactly spell out how it will provide the necessary resources to implement all that it asks of the agency. Currently, strict conflict of interest rules and a draconian hiring process hinders the agency’s ability to attract top talent. “The FDA has had a hiring shortage problem for over a decade,” says David Gortler, a former FDA senior medical officer. He says there are small ways to speed up the review process here and there, but nothing on the scale people are imagining. “Mark my words. Nothing will happen,” he says.
If so, the agency will be living up to its reputation as a creaking thorn in the side of forward progress. But according to Turner, the FDA is just a convenient scapegoat. The real thorn is simply the reality of being human. ‘We’re trying to develop truly safe and efficacious cell based therapies for what throughout human history have been intractable diseases,” he says. “Human biology is the challenge, not bureaucratic inertia.”
And not even a plutonium-charged Delorean can change that.
REDWOOD CITY, CA — Vin Diesel is a close talker. Plus he mumbles, and takes an unselfconsciously long time to answer questions for someone being gang-interviewed on the red carpet. So when he says things like: "I hope being here is a demonstration, or statement, to all future scientists that their cinematic heroes think that they are heroes," you get the sense that this action hero didn't just show up to the 2017 Breakthrough Prizes as a favor to Mark Zuckerberg. It seems the man sincerely idolizes nerds.
Then again, the guy is an actor. But whether he's in character or not is besides the point. He is here—along with other celebrities like Sienna Miller and Alicia Keys—to transfer some of his star power to recent, important discoveries in the fields of theoretical physics, life sciences, and mathematics. The so-called "Oscars of Science," held for the past five years in a makeshift hangar at NASA Ames Research Center, are meant as a demonstration, or statement, to society that the most celebrated people on the planet ought to be scientists.
In that frame, the whole night is a delicate balancing act. The celebrities attempt to illuminate—but not outshine—the awardees. So: Vin Diesel waxing reverently about nerdiness; Jeremy Irons pontificating on empirical research's crucial role in society; Alex Rodriguez on his passion for science, "because it has never been more connected to baseball." Real, live scientists also walk down the red carpet. The event's media handlers are diligent about harpooning awardees past and present and roping them into conversations with relevant (i.e., science or technology-focused) media representatives. But how is a member of the press supposed to muscle through an interview with, say, theoretical physics awardee Cumrun Vafa talking about string theory as a way to unify relativity and quantum mechanics when—oh shit, it's Morgan Freeman!
And because this is Silicon Valley, a tech billionaire like Yuri Milner gets semi-circled with a Brad Pitt-worthy thicket of microrecorders when he approaches the velvet rope. Milner is one of the Breakthrough Prize's cofounders. Together with his wife Julia, Mark Zuckerberg, Priscilla Chan, Sergey Brin, Anne Wojcicki, Jack Ma, and Cathy Zhang, Milner created the prizes to inspire more awe and respect for the sciences. Since 2012, they have awarded more than 70 $3 million prizes to standout researchers.
And while many of the prizes go to people who have already been recognized by some other award—the Venn diagram of Nobel and Breakthrough laurates has a considerable middle bulge—the Breakthroughs distinguish themselves in several ways. One, they are based in Silicon Valley, the single wealthiest region in America. And the very significant reason number two is that the awards don't have any restriction on the number of prize recipients. Hence, this year's special prize for Fundamental Physics went not just to Ronald Drever, Kip Thorne, and Rainer Weiss for their work on the LIGO gravitational wave detection, but the more than 1,000 other researchers who contributed work to that massive project.
And difference number three is the red carpet glamour. Which is no shield from the patina of gloom filming over the fate of science in the wake of the recent election. In each session with reporters, Milner answers some version of the same question: Does he think Donald Trump's ascendance has heightened the importance of private science funding? "I think the trends we are facing are not something we've seen in another administration." He's not alone in his worry. Most of the guests coming down the red carpet share their Trump-vs-science concerns.
But all that worry belies one interesting fact: The Breakthrough Prizes do not have a category for climate science, the one family of research Trump has specifically targeted for cut backs. "We've decided to focus on the natural sciences, what used to be called the natural philosophies," says Milner, when asked about whether he and his co-founders would consider creating a Breakthrough Prize category to recognize earth science. "We don't have plans to go beyond that."
Past the red carpet is a bar. A sequence of curtains hang from its ceiling, the bottom of each cut like a curve—they are supposed to invoke a gravitational wave. Keep walking, into the main banquet hall. Caterers from Thomas Keller's French Laundry float between the tables, placing appetizers ("a composed salad of french pumpkin and golden beets") and filling wine glasses. After the main course ("grilled supreme of organic chicken served with a fricassée of root vegetables"), the lights dim and the voice of Morgan Freeman fills the room, exalting, God-like, the glory of science. "There was a time when a scientist was the most celebrated person on the planet, as it should be."
The whole ordeal is being filmed live, and broadcast on the National Geographic Channel (owned by Rupert Murdoch's 21st Century Fox). After Freeman's sermon, the awards cut to commercial, and 90 seconds later a disembodied female voice exhorts the room to applaud as the feed goes live once again. Then onto the awards proper. To announce each category, a celebrity is paired with a tech billionaire. Will.i.am and Priscilla Chan. Kevin Durant and Susan Wojcicki. Vin Diesel and Mark Zuckerberg. Those latter two banter like skit performers at church camp. Zuckerberg ribs Diesel about whether the muscled star will be able to describe without fumbling the scientific process being awarded (a protein test that can detect over 200 different viral families from a single drop of blood). Diesel says it's no problem: "After all Mark, I'm the geek, and you're the cool one."
The deference of coolness before science doesn't always work so well. Earlier in the night, a reporter tried to offer one awardee a little red carpet treatment. "What are you wearing?" said the smiling journalist, extending her microphone to Deanna See, a high school student from Singapore who won $400,000 in scholarships, lab equipment, plus an endowment for her biology teacher. The teen glanced down at her black gown for just a moment before answering, "A dress."
The 2017 Breakthrough Prize winners
Life Sciences(Each of the five Life Science winners will receive a $3 million prize.)
Fundamental Physics(The three winners will share a single, $3 million prize.)
Joseph Polchinski, UC Santa Barbara; Andrew Strominger, Harvard University; and, Cumrun Vafa, Harvard University, for transformative advances in quantum field theory, string theory, and quantum gravity.
2017 Special Breakthrough Prize in Fundamental Physics(The three will share a $1 million prize; and 1,012 of their team members will share $2 million.)
Ronald Drever, physicist emeritus at the CalTech; Kip Thorne, CalTech; and, Rainer Weiss, physicist emeritus at MIT, for their observation of gravitational waves, opening new horizons in astronomy and physics (The LIGO experiment).
2017 Breakthrough Prize in Mathematics(He will receive a $3 million prize.)
Jean Bourgain, mathematician at the Institute for Advanced Study, Princeton, New Jersey, for his multiple transformative contributions to analysis, combinatorics, partial differential equations, high-dimensional geometry and number theory.
The last time we checked in with engineering professor Kit Parker, his students had finished building a brisket-smoking robot. It's easy to see why they did that: Brisket is tasty, brisket is hard to cook, and Harvard kids are wicked smaht.
His latest project is no less impressive, but it requires greater mental gymnastics to parse. Here's the easily understood cool part: A team led by Parker created artificial stingrays that use a rat's heart cells as motors, and the rays can be controlled with a blinking light. Here's another cool part that's harder to grok: One day, the team's techniques could help build artificial human organs.
Parker, the Tarr Family Professor of Bioengineering and Applied Physics at Harvard University, often draws inspiration from animals and seemingly random objects. His past projects include spinning artificial tissues out of modified cotton candy machines, camouflage clothing that changes colors like a chameleon, and cyborg jellyfish.
As fascinating as those things are, Parker’s real goal is to build an artificial four-chamber heart that can help diagnose ailments and replace malformed hearts in babies and young children. Parker, a researcher at SEAS, looks to the seas for ideas. “In the ocean, most creatures with the exception of crustaceans, almost all their musculature exists to pump fluids," Parker says. "Either to swim through water or pump it through their body."
Parker sees a link between sea critters and how the human heart works. "Most muscular pumps—stingrays, jellyfish, the heart—do have similar design features," he says. You see a jellyfish, and Parker sees a simple muscular pump. A few years ago, his team built an artificial jellyfish using a rat’s heart cells, a relatively easy feat compared to the cyborg rays. The jellyfish didn’t have any type of navigational control. A trip to the aquarium with his daughter Caroline inspired this far more complex project.
The New England Aquarium features a petting tank of rays and small sharks. Children can feel the fish as they swim by. That's how it's supposed to work, anyway. When Caroline, who was 4 at the time, put her hand in the tank, a ray that wasn't in a petting mood easily evaded her with a quick flip of its wing. “When I saw it happen, it hit me like a lightning strike,” Parker says. “The musculature in that fin, in order to change direction, must have been like the musculature we see in the endocardial surface of the heart, the inside layer of the heart. If I could replicate or build this, then I might have a deeper understanding of why the heart is built the way it is.”
The recipe for the artificial sea creatures consists of a pinch of breast implant, a pinch of gold, and a pinch of rat.
Like most people, Parker lacks the skills to build a light-guided tissue-engineered stingray using rat parts, even if he does have a background in biomedical and mechanical engineering. But he knows people who do have those skills—specifically, Sung-Jin Park, who'd recently started his postdoctoral fellowship on Parker’s disease biophysics team at SEAS. Finding Park was easy; convincing him was a different matter.
“I said, 'Hey, Sung-Jin, we’re going to take a rat, tear it apart, and rebuild it as a stingray. We can publish it in Science, and we’re going to get the cover,'" Parker says. "He looked at me like a hog staring at a wristwatch. It took me about a year to convince Sung-Jin that it wasn’t professional suicide.”
Within three years, the project went from a far-out scheme to, yes, the cover of Science. Park was able to steer the mini rays—about one tenth the size of the real deal—through obstacle courses using a pulsing blue light. The team worked with Stanford researcher Karl Deisseroth on the optical genetics to make heart cells "see." When the creatures sense a certain wavelength of light, their heart muscles contract, flap their wings, and make them swim.
The recipe for these artificial sea creatures consists of “a pinch of breast implant, a pinch of gold, and a pinch of rat,” says Parker. The bodies are made of polydimethylsiloxane, the flexible outer coating of a breast implant. It also provides a friendly substrate for the rat heart cells. That gold isn’t just to give the rays baller status; it provides a spring-loaded skeleton, one that makes its wings recoil to a ready position after each muscle contraction. The artificial tissues containing the rat’s heart cells are built into a layer of polydimethylsiloxane; they flap the stingray’s wings upon contraction and recoil due to the golden skeleton.
So how does this impressive creature advance the greater goal of building a full-on artificial heart? Parker calls it a training exercise, a way for scientists and engineers to practice their craft and build a control experiment. And Parker hopes the light-guided portion can lead to a kinder, gentler pacemaker. Instead of having to insert electrodes into a heart, brief flashes of light could help it keep the beat.
He also sees this as the first step toward safer drug testing, as researchers could test potentially toxic pharmaceuticals on an artificial human heart. Pharmaceutical companies, regulators, and physicians could see the effect of cancer treatments and experimental drugs without endangering anyone. But the primary goal remains building a full tissue-engineered heart.
“We’re doing a crawl, walk, run approach to building the heart,” Parker says. “Replacing a heart, that is a long term goal. That’s blue sky, way off in the future. But along the way we can replace parts of a baby’s malformed heart with something tissue-engineered. It might be valves, it might be a ventricular chamber.”
At the moment, it’s simply a sweet light-guided cyborg mini-stingray with high hopes. One you won't find in any aquarium's petting zoo.
Listen, you’ve got things wrong about spiders. First of all, they’re not all out to destroy you and your family. Second, they’re not all the web-builders that you think. Meet the jumping spiders, which instead of spinning homes, actively stalk their prey. And boy, are they good at it. Check out this week’s episode of Absurd Creatures to learn more!
Find every episode of Absurd Creatures here. And I’m happy to hear from you with suggestions on what to cover next. If it’s weird and we can find footage of it, it’s fair game. You can get me at matthew_simon@wired.com or on Twitter at @mrMattSimon.
Composer Darren Fung watched the weirdly stretched-out sea lions swimming across a screen and imagined the music that would best suit them. In mid-November, he’d signed on to work with filmmaker Adam Ravetch on a virtual-reality short, filmed underwater. Viewers would feel like they were swimming with the puppies of the sea—but for now, Fung was stuck with the flat, warped image on a regular video screen, trying to put himself in his audience’s shoes.
What would he feel, what did the filmmaker want the audience to feel, and what would the audience feel on their own? His music needed to nudge, and augment, those limbic responses.
Emotionally scoring the natural world, and human study of it, is something Fung has become expert in. Recently, Fung—who composed the Canadian Screen Award-winning soundtrack for the anthropological miniseries The Great Human Odyssey and is currently musicalizing Equus, a project about how horses have changed history—has somewhat accidentally found himself swimming in such science documentaries.
And although he at first didn’t know how his music could interact with this genre, he now hears the soundtracks that swell behind science films like any others. Scientific topics, like love triangles or bank heists, are all about drama, emotions, and humans—centuries of claims of dispassionate objectivity notwithstanding—and that’s what the chords and chromatics are all about.
It took a while for Fung's love of music to crescendo into a career composing for films. At McGill University, Fung found that students and teachers tended toward “avant-garde, artsy-fartsy, academic music.” For a while he did, too. But he soon realized he wanted to write more accessible music for movies—big, soaring melodies that can make your chest feel like it’s full of fire while at the same time you hardly notice them.
After college, he offered his services to the film student artistes. He and his college buddies would go to the university’s concert hall at midnight and record the scores. “We were going and doing these short films with these big scores,” Fung says. “It got to the point where I went to a party one night and one of my friends said, ‘Oh shit, it’s Darren. He’s going to ask us to play for free again.' I gave them pizza and beer.”
Soon, small paying gigs turned into indie feature films turned into television turned into a move to Los Angeles, five years ago. And then came the science. The projects are different—–the pizza and beer and camaraderie have stayed the same.
In 2011, Fung worked on Lost Years, a documentary that uses the story of Chinese-Canadian Kenda Gee’s family to explore racism and the Chinese diaspora. Its co-director Tom Radford ran a production company with anthropologist and documentarian Niobe Thompson—who was a fan of the notes undergirding Lost Years. “He heard my work and said, ‘Holy shit, that’s really good,’” says Fung, who likes to say “shit.”
Thompson was working on a project called The Great Human Odyssey, a three-part series about how humans came to be and then keep being and then take over the planet, and he asked Fung to compose the score. Fung was hesitant at first. He’d never done a science documentary. “How do you translate that into cinematic film-score world?” he wondered. Usually, when he met with a director to talk music, he asked the filmmaker what he wanted to audience to feel. “When you think about it for science, where is the emotion in that?” he remembers thinking.
But when he learned more about the actual great human odyssey, he realized something: The swings of this scientific plot were no different from those of any other twisting and turning narrative. “You talk about how humans have survived through all this adversity through all the years,” he says. “There were some a pretty shitty things humans had to go through. That whole ice age was pretty crappy.” (True story, dude.)
Fung watched people free-diving, jumping across ice floes, migrating from Africa to Europe—footage that had been filmed over the course of 18 months with ultraHD 4K cameras. This documentary seemed to have it all: “Wonderment, adversity, despair: That’s what makes a soundtrack,” he says. “You’re not scoring science. You’re not scoring DNA structures. You’re not scoring evolution. You’re scoring the emotions that are behind that.”
And in that scoring, he had to try to match the awesome timbre of the natural environment: up in the air, down in the ocean, in a genetics lab. According to the Canadian Screen Awards committee, he did a good job. Hear for yourself.
The tone of his new VR project—headed up by Adam Ravetch, who’d been an underwater cinematographer on Odyssey—will likely sound a bit different. As Fung watched the ocean puppies careering about and considered which audience emotions he wanted to bolster, he knew he had options. “Looking at these sea lions playing around, you could play it in a lot of different ways,” he says.
Playful, though, won out. Ravetch did, after all, give the project the working title Dogs in Rubber Suits.
While composing, Fung had to remember that viewers would have an extra dimension of perception, so his music should, too. It should surround them, and feel like it was organic to that fully realized underwater world, not superimposed. Dolby Atmos—which helps sound sound like it’s coming from three dimensions when it bursts from speakers—helps.
“Multisensory technology is really changing how we work in music,” he says. And in fact, most composition tech has changed since Fung’s early days, when he had to physically draw the stems of his own notes and top them with neat, dark ovals, instead of composing on the computer. His subject matter and style have evolved, too. But one thing hasn’t: The power of a live orchestra, playing notes he put together one way or another, to pull your feelings out of you and then turn up their volume.
Dive deep enough under the surface of the ocean, and light reigns. Some 90 percent of the fish and crustaceans that dwell at depths of 100 to 1,000 meters are capable of making their own light. Flashlight fish hunt and communicate with a flashing Morse code sent by light pockets that pulse under their eyes. Tubeshoulder fish shoot luminous ink at their attackers. Hatchetfish make themselves appear invisible by generating light on their underbellies to mimic downwelling sunlight; predators prowling below look up to see only a continuous glow.
Original story reprinted with permission from Quanta Magazine, an editorially independent division of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences
Scientists have indexed thousands of bioluminescent organisms across the tree of life, and they expect to add many more. Yet researchers have long wondered how bioluminescence came to be. Now, as explained in several recently released studies, researchers have made significant progress in understanding the origins of bioluminescence—both evolutionary and chemical. The new understanding may one day allow bioluminescence to be used as a tool in biology and medical research.
One longstanding challenge has been determining how many separate times bioluminescence arose. How many species came to the same conclusion, independent of one another?
Though some of the most familiar examples of light from living organisms are terrestrial—think of fireflies, glowworms and foxfire—the bulk of evolutionary events involving bioluminescence took place in the ocean. Bioluminescence is in fact markedly absent from all terrestrial vertebrates and flowering plants.
In the deep ocean, light gives organisms a unique way to attract prey, communicate and defend themselves, said Matthew Davis, a biologist at St. Cloud State University in Minnesota. In a study released in June, he and his colleagues found that fish that use light for communication and courtship signaling were especially diverse. Over a period of about 150 million years—brief by evolutionary standards—such fish proliferated into more species than other groups of fish. Bioluminescent species that used their light exclusively for camouflage, on the other hand, were no more diverse.
Courtship signals can change relatively easily. These changes can in turn create subgroups in a population, which eventually split into unique species. In June, Todd Oakley, an evolutionary biologist at the University of California, Santa Barbara, and one of his students, Emily Ellis, published a study in which they found that organisms that use bioluminescence in courtship had significantly more species, and faster rates of species accumulation, than closely related organisms that do not use light. Oakley and Ellis studied ten groups of organisms, including fireflies, octopuses, sharks and tiny crustaceans called ostracods.
The study by Davis and his colleagues was limited to ray-finned fishes, a group that includes approximately 95 percent of fish species. Davis estimated that even in that single group, bioluminescence evolved at least 27 times. Steven Haddock, a marine biologist at the Monterey Bay Aquarium Research Institute and an expert on bioluminescence, estimated that across all life forms bioluminescence evolved independently at least 50 times.
Comb jellies may reveal the genetic instructions that make bioluminescence possible.
In nearly all shining organisms, bioluminescence requires three ingredients: oxygen, a light-emitting pigment called a luciferin (from the Latin word lucifer, meaning light-bringing), and an enzyme called a luciferase. When a luciferin reacts with oxygen—a process facilitated by luciferase—it forms an excited, unstable compound that emits light when it returns to its lowest energy state.
Curiously, there are far fewer luciferins than luciferases. While species tend to have unique luciferases, many share the same luciferin. Just four luciferins are responsible for most of the light production in the ocean. Of close to 20 groups of bioluminescent organisms in the world, a luciferin called coelenterazine is the light-emitter in nine.
Yet it would be a mistake to assume that all coelenterazine-containing organisms had evolved from a single luminous ancestor. If they had, asked Warren Francis, a biologist at Ludwig Maximilian University in Munich, then why did they develop such a wide variety of luciferases? Presumably the first luciferin-luciferase pair would have survived and multiplied.
It’s more likely that many of these species don’t make coelenterazine themselves. Instead, they get it from their diet, said Yuichi Oba, a professor of biology at Chubu University in Japan.
In 2009, a group led by Oba discovered that the deep-sea copepod—a tiny, near-ubiquitous crustacean—makes its own coelenterazine. These copepods are an extremely abundant food source for a wide range of marine animals—so much so that “in Japan, we call copepods ‘rice in the ocean,’” Oba said. He thinks copepods are key to understanding why so many marine organisms are bioluminescent.
Oba and his colleagues took amino acids believed to be the building blocks of coelenterazine, labeled them with a molecular marker, and loaded them into copepod food. They then fed this food to copepods in the lab.
After 24 hours, the researchers extracted coelenterazine from the copepods and looked for the labels they had added. Sure enough, the labels were there—definitive proof that the crustaceans had synthesized luciferin molecules from the amino acids.
Even the jellyfish in which coelenterazine was first discovered (and named after) was later found not to produce its own coelenterazine at all. It obtains its luciferin by eating copepods and other small crustaceans.
Researchers have found another clue that might help explain the popularity of coelenterazine in deep-sea animals: the molecule also exists in organisms that don’t emit light. This struck Jean-François Rees, a biologist at the Catholic University of Louvain, in Belgium, as odd. It’s already surprising “that so many different animals rely on exactly the same molecule for producing light,” he said. Perhaps coelenterazine had another function besides luminescence?
In experiments with rat liver cells, Rees showed that coelenterazine is a powerful antioxidant. His hypothesis: perhaps coelenterazine first proliferated in marine organisms living in surface waters. There, an antioxidant would have provided much-needed protection against oxidative stress from harmful sun rays and high rates of respiration.
When these organisms began colonizing deeper layers of the ocean, where the need for antioxidants is lower, coelenterazine’s ability to emit light became useful, Rees theorized. Over time, organisms evolved different strategies—like luciferases and specialized light organs—to enhance this property.
Still, researchers have not discovered how organisms other than Oba’s copepods make coelenterazine. The genes that encode for coelenterazine are also completely unknown.
Enter the comb jelly. These ancient sea creatures—thought by some to be the first branch off the animal family tree—have long been suspected of being able to produce coelenterazine. But no one had been able to confirm that, much less track the genetic instruction kit at work.
In work reported last year, however, a team of researchers led by Francis and Haddock homed in on a gene that might be involved in synthesizing the luciferin. To do this, they looked at comb jelly transcriptomes, which provide a snapshot of the genes an animal is expressing at any given time. They were searching for genes that encoded for a group of three amino acids—the same amino acids Oba fed to his copepods.
Across 22 species of bioluminescent comb jellies, the scientists found a group of genes that fit their criteria. Those same genes were absent in two other non-luminous species of comb jellies.
“It’s very strong, but still circumstantial, evidence” that these genes might be involved in the production of coelenterazine, Haddock said. As techniques for working with comb jellies in the lab become more advanced, he thinks it may soon be possible to test his team’s findings with gene-manipulation experiments.
The genetic machinery of bioluminescence has applications beyond evolutionary biology. If scientists can isolate genes for a luciferin and luciferase pair, they can potentially engineer organisms and cells to glow, for various reasons.
In 1986, scientists at the University of California, San Diego, modified and inserted the firefly luciferase gene into a tobacco plant. The study was published in the journal Science with an image of one of these plants glowing eerily against a dark background.
The plant didn’t create light on its own, however—it contained luciferase, but needed to be watered with a solution containing luciferin to glow.
Thirty years later, scientists are still unable to genetically engineer self-luminous organisms because they don’t know the biosynthetic pathways for most luciferins. (The one exception is in bacteria: researchers have identified the “lux” genes that encode for the bacterial luciferin-luciferase system, but these genes need to be modified to be useful in any non-bacterial organism.)
One of the biggest potential uses for luciferin and luciferase is in cellular biology research—inserting them would be akin to installing lights in cells and tissues. “This type of technology can be used to track anything from where a cell is, to gene expression, to protein production,” said Jennifer Prescher, a professor of chemistry at the University of California, Irvine.
Uses for bioluminescence molecules would be similar to those of the green fluorescent protein, which has been used to follow the fate of HIV infections, visualize tumors and track nerve-cell damage in Alzheimer’s disease.
Currently, researchers who use luciferin for imaging experiments must create a synthetic version or purchase it at $50 per milligram. Delivering externally produced luciferins into cells can also be somewhat challenging—a problem that wouldn’t exist if cells could be engineered to make their own luciferin.
While recent studies are narrowing in on the evolutionary and chemical processes of how organisms produce light, so much of the bioluminescent world still remains in the dark.
Original story reprinted with permission from Quanta Magazine, an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.
Click through the gallery to see this week’s helping of the best the universe has to offer. And if you need more when you’re done but can’t wait until the next one, here’s the entire collection.
The Dry Valleys are home to some of the unfriendliest terrain that humans could contemplate setting foot on. It’s frigidly cold, incredibly dry, and its rust-colored soil is practically lifeless. Yet, despite all appearances to the contrary, these valleys are not 33 million miles away on Mars. They’re right here on Earth—and they’re facing down a very Earth-bound problem.
“A cold day in the Dry Valleys is like an average day on Mars," explains University of Texas geophysicist Joe Levy, who has been visiting and studying Antarctica’s Dry Valleys since 2004. Those cold temperatures, which regularly dip below -55 degrees Celsius, combine with some of the driest dirt on Earth to form an Earth-based Mars lab.
There (along with a couple other Martian analogues in the Arctic—more on those in a moment) researchers test their ideas about how life, whether something native or a human colonist, could survive on Mars, all within the relative comforts of their home planet. But now, these windows into life on the red planet could be closing. “We’re just beginning to appreciate that the Dry Valleys are on the threshold of this major change,” says Levy. That shift is happening in the context of a much larger rise in global temperature. Just this month, the World Meteorological Organization confirmed, to no one’s surprise, that 2016 was on track to snatch 2015’s title as the hottest year ever recorded.
So far, the permafrost in the high-elevation interiors of the Antarctic Dry Valleys—where the terrain is exceptionally dry and cold, like Mars might see today—has remained largely untouched by the upward swing of global temperatures. But the Dry Valleys are also home to something else just as incredible: a lower, coastal region that mirrors the wetter, warmer Mars that existed millions of years ago.
“There’s a time machine element to the Dry Valleys,” explains Levy. “When you head out into the coastal Dry Valleys, it’s like you’re headed back in time on Mars.”
It’s in that ancient-Martian twin—where researchers hope to find answers about how water once flowed on the planet—that Levy has been tracking signs of accelerating collapse. Since he first arrived over a dozen years ago, he’s observed melting ground ice and an increase in the rate of both melt and breakage in the ice along the coastal deltas. “There’s a risk of seeing a loss of the usefulness of the low parts of the Dry Valleys," says Levy. “The big question in those warmer, wetter parts is are we going to see more precipitation, or even a change from snowfall to rainfall, that turns a very clear Mars analogue into something that’s just more Arctic-like.”
The upper-region of the Arctic is home to its own set of Martian-cognates—although, not quite as close to Mars in terms of either temperature or dryness as the Antarctic Dry Valleys. Those upper-Arctic regions, however, are providing scientists with a real-time example of just how fragile these mirror environments can be once collapse begins.
NASA researcher Chris McKay has been visiting Martian parallel environments both in Antarctica and the upper-Arctic since the 1980s. In almost four decades, he’s seen “remarkable" changes in the Arctic’s Martian counterparts, including fast-thawing permafrost and melting sea ice. “In 10 years, it’s not going to be like this,” says McKay, “so study it now.”
The McMurdo Station research center serves as a hub for scientists studying Antarctica's Dry Valley.
While the melting in the Arctic’s Martian-equivalents has proceeded along a swift, continuous upward trajectory, the Antarctic Dry Valleys have experienced more fluctuations in temperature, even seeing periods of extended cooling in the 1990s. Today, McKay says that the high-elevation area of the Dry Valleys where he conducts the bulk of his research still feels “just as damn cold as it did 40 years ago.” That’s good news for scientists with questions about how life on Mars might work today. “If you’re an astrobiologist, the [upper elevation] Dry Valleys are definitely the best analogue by far of Mars,” says McKay. “It’s the place to go to test ideas for how life survives and how we might test for life on Mars.”
But while most of the changes appear to be limited to the low-elevation coasts of the Dry Valleys, that’s no guarantee that they will stay confined there—particularly as world temperatures continue to rise. "We are seeing signs in the coastal thaw zones of accelerated global melt,” says Levy. “They haven’t got too far inland yet, but really all it takes is a few degrees in warming or a change in the amount of sunlight hitting the ground to start thawing them in ways that would make them un-Mars like.”
Besides giving scientists a local testing-ground to look for answers to questions about the geology, climate, and history of Mars, the analogues also offer a place for equipment tests that could someday help the first colonists survive on Mars. Engineers have driven a test Martian-vehicle through the Arctic to see how it stood up to the cold, stress-tested Mars-bound drill bits in the Dry Valleys’ permafrost, and even carted up pieces of a Martian-lander prototype to check its performance.
Losing these Mars-like environments, or seeing them become less Martian, would leave researchers with very few options to answer their questions about Mars, and how our instruments might perform up there. "There is nowhere else like them,” says Levy. "At that point, we’d just have to go to Mars.”
Last night, the ONEMI (Oficina Nacional de Emergencias) and SERNGEOMIN (Chilean Geological Survey) in Chile raised the alert status for the area around Cerro Hudson in the southern Andes. Normally, raising the alert status like this is due to an acute change, when the behavior of the volcano shifts suddenly. However, this time, the elevation to Yellow alert status at Cerro Hudson is due to accumulated events over the past month.
Dozens of small earthquakes have occurred since the start of November, none stronger than M3.2. But their location (in geographic space and depth) are similar to those before the last eruption of Hudson in 2011. The number of earthquakes hasn't increased much above the baseline activity at an active volcano like Hudson, but energy released by the largest earthquakes has been increasing over the past few months. Combine that with the fact that the earthquakes have the character of those associated with magma movement, and the SERNAGEOMIN and ONEMI decided to treat Hudson with an abundance of caution, setting up a 3.5 kilometer exclusion zone around the volcano.
Hudson is a fairly unknown volcano to most people, but it did produce one of the largest eruptions in the latter half of the 20th century. The 1991 eruption was a VEI 5 event, which is on the same scale as Mount St. Helens in 1980 (and a bit smaller than the much more famous eruption of Pinatubo that had happened earlier that year). Even the 2011 eruption, which was VEI 2, opened three new vents on the volcano and covered the ice-filled summit caldera with dark grey ash. So, any unrest like this at Hudson bears close watching.
In other volcano news:
Mexico's Popocatépetl had some of its strongest explosions of the year—large enough to force the closure of airports around Mexico City. The explosive plumes reached ~5 kilometers (~15,000 feet) and spread ash on the region. It was the removal of the ash from the runways that caused the Puebla Airport to close. You can watch all the rumblings and explosions at Popocatépetl on the webcam pointed at the volcano.
What do Donald Trump and a bee hive have in common?
While this might sound like the setup to a bad joke or bit of political punditry, it’s an important and meaningful academic question. To a collective behavior scientist, electing a president or choosing a new nest site are both choices that arise from the interactions of a large number of individuals.
Joe Bak-Coleman (@jbakcoleman) is a Ph.D. candidate in ecology and evolutionary biology at Princeton University, where he is studying collective behavior.
When bees need to find a new nest site, scouts will visit several potential locations. When they return, if they like the site they dance excitedly in a way that tells others where it is located. This dancing may recruit more scouts to check out the site, who likewise visit the site and start dancing to express support for the location. Bees will butt heads with dancers advocating for an opposing location. Through these interactions, they eventually settle on a nest site, often a very good one. The amazing thing is that this process allows a hive to measure the relative quality of nest sites, without any single bee knowing which is best.
It's not hard to draw parallels between selecting a nest and selecting a president. We each have a candidate we support, often without full information about the variety of options, and we still excitedly post to Facebook. Our goal is to recruit others to in turn support our candidate and spread our beliefs.
On face value, this is encouraging. If bees can find the best nest, can't we find the best presidential candidate? Indeed, animal groups often make extraordinary collective decisions that go far beyond the abilities of any single individual. The idea that groups can make collective decisions more successfully than individuals is known as the "wisdom of the crowd" and is arguably why we vote, have juries, and fill boardrooms.
Unfortunately, the power of collective decision-making is fickle. For instance, if individuals are wrong on average, their collective decision-making processes select the worse of two options. In complex environments with multiple sources of information, sometimes small groups are better than large ones. Even individuals with no preference whatsoever can have striking impacts on the group-level decisions. These are just some of the myriad of ways in which the wisdom of the crowd isn’t so straightforward.
Imagine for a moment, that exactly half of the bees see dances for one site, and half for another. Without crucial interaction between both sides, since they're split evenly they risk becoming deadlocked. If they are forced to decide, their selection would likely be random, even if the original quality difference was massive.
How the Science of Swarms Can Help Us Fight Cancer and Predict the Future
The Startling Science of a Starling Murmuration
Could the same thing happen with elections? It's well known that companies like Google and Facebook measure the political leanings of their users, something that makes financial sense. But what do they do with this data? Even seemingly benign decisions could have disastrous collective consequences.
Centering is arguably one of the more commonplace and generally innocuous data science procedures. It involves removing the average from your data so that it is split evenly around zero. Many machine-learning algorithms, such as those that are likely used by Facebook and Google, rely on centered data and behave poorly without it. A reasonable data scientist might apply centering to political leanings, particularly in a bipartisan society. But what happens if they then use this centered metric to preferentially display news stories?
Going back to our honeybee example, this practice is effectively the same as dividing the hive evenly into two groups and only showing either side one option. It's possible that such a simple, reasonable data science decision could push the system toward evenly split political beliefs. Beyond simply creating an echo chamber, this would explicitly remove all leaning of the system toward a better option, making election results effectively random. A line of code could shift an electorate.
Unfortunately, most social media sites aren't open source, so it's impossible to know what decisions they've made. Centering, echo chambers, and fake news represent only a few of many plausible ways in which social media might have meaningful and unexpected consequences. The notion that social media has no measurable impact on elections is beyond far-fetched. The elephant in the room is whether or not they make for better, worse, or simply more random collective choices. Where are they taking us?
What is alarming is that we simply have no idea. Tackling these types of questions is at the heart of the quickly growing field of collective behavior. Scientists are developing tools and mathematical models to make sense of the very complex data inherent to these systems. Whether or not we solve global warming, reduce human suffering, and avoid nuclear war are all ultimately questions about collective behavior. The importance of understanding how we make decisions, and how these decisions are shaped by technology, is difficult to overstate.
One of the more beautiful and haunting collective phenomena is that of ant mills, or "death spirals." When separated from the trail, large groups of army ants occasionally begin to march in a circle until they die of starvation, each dutifully following the pheromone trails of the ants laid out ahead of them. The simple rules that they've evolved to follow, which generally lead to astonishing feats of collective behavior, can ultimately doom them under the wrong circumstances.
Today, it's not clear if social media is pushing humanity into a death spiral or pulling us out of one. Understanding how technology shapes human collective behavior is a very hard scientific problem. Swarms, flocks and schools provide valuable insight into how individual decisions lead to group action. It has never been more important to understand what humans and bees have in common.
Chicken breast is a ubiquitous weeknight dinner item, but there's a fine line between crispy, juicy yum and overcooked cardboard yuck. One crowd pleasing technique is to just deep fry it—mmm, crunchy goodness. But then you're looking at a messy, labor-intensive, and fattening extravaganza. You can get the same satisfying crunch using just a pan and some basic ingredients, without the mess and added fat of deep frying. So let Cook's Science editor Dan Souza walk you through a few fail-safe tips for crispy chicken that seals in its own juices to make for a satisfying weeknight throw-together.
The trick is to start with a piece of chicken with its skin still on: That's what's going to crisp up in the pan and give you that crunchy outer layer. Souza pokes the chicken with a sharp, small knife several times, opening up channels that allow the meat's fat to escape as it heats up in the pan. Then he pounds the chicken flat to break down the protein fibers in the meat, which softens it for a more tender bite. As the fat renders out of those channels, the skin is going to fry in it, which gives it that nice crunchy texture.
This is where things get a little tricky. Chicken skin is delicious, but it's also full of collagen, the structural protein that gives it its stretchy strength. When exposed to heat, collagen proteins contract and tighten up, which is why the skin will shrivel if you just throw a chicken breast right into a hot pan. Pounding the chicken out before you cook it helps weaken that collagen. But Souza also puts a cast iron skillet over the chicken when it's cooking. The added weight forces the chicken to stay stretched out as it cooks, so you get a bigger piece of crispy chicken skin that stays splayed out across the breast.
To further prevent the chicken skin from shriveling and the meat from toughening up, Souza also recommends starting with a cold pan. I know, I know—every other cook book you've ever read told you to start with a hot pan, but Souza's endless tinkering at America's Test Kitchen ultimately led him to the discovery that the collagen in chicken skin causes it to recoil and shrink back from sudden heat the same way a person would snap their finger back if they accidentally touched a hot pan. Stretching out the skin by pounding out the breast, weighing it down with the cast iron skillet, and slowly bringing it up to temperature is the ultimate trifecta of tough-meat prevention. Together, it breaks down those tough collagen proteins and holds them down until they're cooked to a golden crisp in the rendered fat.
Kourtney Kardashian hawks its health benefits. Counterfeiters and chemists labor to unlock its molecular secrets. And now it’s at the center of an international branding war.
It’s honey, but not just any honey. It’s Manūka honey, a sweet extravagance from New Zealand that sells for a sticky $2.50 an ounce—six times the cost of conventional honey—and has attracted a slew of famous fans. Kardashian, who has a promotional contract, claims Manūka is responsible for her robust health and soft skin. “On our show when we’re filming, our crew would eat Manūka by the spoonful,” the reality show star recently told Amazon’s style channel.
More than 7,000 miles away from Hollywood, biologist Simon Williams is trying to help Australia cash in on the Manūka craze. He treks through the Australian bush searching for trees in the same genus as Manūka, dodging wildlife at every turn. “One wombat kept trying to give me love bites on my feet,” he says.
Ready for #Worldkissingday2016 thanks to my @ManukaDr lip enhancer #BeeingKourtney 💋 #ManukaAmbassador
A photo posted by Kourtney Kardashian (@kourtneykardash) on Jul 6, 2016 at 7:12am PDT

But not everyone thinks that the trees Williams is surveying are legitimate sources of Manūka honey—created by bees who gather their nectar. Real Manūka, they say, can only come from New Zealand, which is why that country’s Manūka Honey Appellation Society recently submitted a certification trademark application for the words “Manūka Honey.” If the application succeeds, New Zealanders will have exclusive use of the international brand, in the same way that only sparkling wine from a certain region of Northern France can legally be called champagne.
Manūka honey has more than just the lure of exclusivity. While there’s no evidence it protects Kardashian from the common cold, Manūka does have useful antibacterial properties. Most honeys kill some bacteria because they contain peroxide, which eats away at the bugs’ protective cell walls. Manūka honey, by contrast, can attack a bacterium in many ways: disrupting communication, inhibiting movement, and destroying digestive enzymes, as well as breaking down its cell walls. This intricate attack strategy could make Manūka honey more effective against antibiotic-resistant bacteria like MRSA.
Beyond its antibacterial benefits, Manūka honey (and other honey) has some wound-healing properties. When health-care workers put strips of honey over burns, for example, researchers found they healed four to five days faster. “They draw the infection out of the wound, they kill the infection, and they heal the wound underneath so the tissue regenerates,” says Peter Brooks, a biochemist who advises Williams at the University of the Sunshine Coast in Australia. He currently studies Manūka’s anti-inflammatory properties.
With these health benefits and celebrity endorsements, demand for Manūka is growing fast—the country’s honey exports leapt to $285 million in 2015 from $202 million in 2014. To no one’s surprise, New Zealand is fighting to keep the coveted brand for itself. John Rawcliffe, a representative of New Zealand’s Unique Manūka Factor Honey Association, refers to Australian Manūka as “Tea Tree” or “Jellybush” honey.
But the Aussies aren’t convinced there’s any meaningful chemical difference between Aussie and Kiwi Manūka. “The active ingredients in the honeys are the same,” says Brooks.
Brooks is confident because so much work has already been done to identify the key chemical components of Manūka honey—mostly because Manūka honey producers have to protect against counterfeiters. Dishonest honey makers have been known to mix Manūka with other honeys, or mislabel the honey altogether. They also sometimes heat their honey to try to fool the authenticity tests, feed Manūka’s unique chemical markers directly to the bees, or even shake the pollen from a live Manūka tree directly into their honey, according to Adrian Charlton, head of chemical profiling at the United Kingdom’s Food and Environment Research Agency, a joint governmental and commercial laboratory that ensures food quality and safety in the UK.
To try to foil the fakers, Kiwi researchers initially tested for a certain amount of a compound associated with the honey’s antibacterial properties: methylglyoxal. It’s derived from the carbohydrate dihydroxyacetone, which comes from the nectar of the Manūka flower. However, fraudsters can heat the honey or store it for a long time to artificially turn the available dihydroxyacetone into methylglyoxal. They could also make dihydroxyacetone in a lab, adding another layer to the honey security problem.
Charlton’s team and other industry and governmental regulators needed a surefire way to identify authentic Manūka honey. Finally, in 2014, a Japanese researcher named Yoji Kato identified a complex compound that isn’t easy to replicate. He called it leptosperin, and it’s now the standard measure for determining whether a honey labeled Manūka is the real thing.
Except that there’s a problem: Aussie Manūka contains leptosperin, too, according to Brooks. “The New Zealand Manūka product and the Australian Manūka products are equivalent,” he says.
Try telling that to a Kiwi. “The environment definitely changes things,” asserts Rawcliffe. He argues that discrepancies between the soil, light, and weather in Australia and New Zealand make a difference in the quality of the honey—just as they do with wine. “The wine out of Napa Valley is completely different from the wine out of New Zealand,” Rawcliffe says. He’s backed up, sort of, by a study in the New Zealand Journal of Botany that concluded local soils change how much nectar a Manūka plant produces—though its antibacterial properties remain the same.
But the trees at the center of the dispute actually grow in many countries, in all kinds of conditions. They’re so hardy and fast-growing that they have become an invasive species in some places, though there are more Manūka trees in Southern Australia and New Zealand than anywhere else, where indigenous Maori people used the tree to make fence posts, spears, roofing, and even scented toilet oil.
The Unique Manūka Factor Honey Association argues that this cultural and geographical heritage should give Kiwis exclusive rights to the word “Manūka.” They have lodged an application with the New Zealand Intellectual Property Office for a certification trademark, which would secure the name “Manūka Honey” internationally. They could then take honey producers who use the Manūka name without approval to court. (Roquefort, France used it on American William Faehndrich after he sold sheep’s milk blue-mold cheese from Italy and Hungary under the moniker “Roquefort Cheese.”)
No matter how the trademark dispute turns out, Brooks, a proud Australian, thinks there’s rich irony in New Zealand trying to claim ownership of the Manūka. “The odd thing is that New Zealand Manūka is actually an Australian plant that blew across the Tasman” Sea, he says. “We argue they’re trying to copyright an Australian plant.”
That’s a contention that the Kiwis, no doubt, will dispute.
Space exploration isn't all pretty pictures and floating around eating lettuce. Today, an unmanned Russian Progress 65 spacecraft was destroyed shortly after it launched from the Baikonur cosmodrome in Kazakhstan. The spacecraft was on an International Space Station resupply mission, stuffed with 2.5 tons of food, fuel, clothes, and other hardware. After successful blast off at 9:51 EST, ground crews lost contact with the ship just six minutes later. They stopped receiving telemetry, and radar stations weren't picking up any signs of the spacecraft where it was expected to be, either. Further investigation showed the craft and its cargo burning up in the atmosphere 190 kilometers above Siberia.
While this could be a setback for Russian spaceflight, it's not as much of a concern for either the Russian or US segments of the ISS. The ISS is by definition a multi-national enterprise, so losing a Russian cargo ship (or, you know, a couple) doesn't spell doom. ISS resupply missions have had struggles before: Over nine months in 2014 and 2015, an Orbital ATK Cygnus spacecraft, a SpaceX Dragon, and another Russian Progress mission all failed for various reasons. But the astronauts were able to carry on as normal because the space agencies involved have built in redundancies and failsafes. They're essentially hoarders.
Roscosmos is still investigating the incident, and it's not entirely clear why this Progress cargo ship failed. But early indicators—and recent history—point toward issues with the Soyuz rocket launching the cargo. Russia's 2015 failed supply mission was brought back to Earth by the same problem. The Soyuz has been a Russian spaceflight mainstay since the Soviet period, and for the moment, the Soyuz rockets are the only ones capable of bringing humans to the ISS.
Besides needing Soyuz in working order to bring relief crews, Progress spacecrafts perform key functions like reboosts and maneuvers of the ISS itself. That's why this one was carrying extra fuel: You can either use engines on the Progress spacecraft to shift the space station after it's docked, or use the fuel the cargo ship carried to power the engines on the Russian segment of the station. But according to NASA spokesperson Dan Huot, the ISS is all fueled up, and still docked with another Progress craft.
Another resupply mission scheduled for just next week: On December 9th, a Japanese HTV cargo ship is planned to deliver food, water, clothing, replacement parts, repair kits, and new experiments to the US segment of the ISS. Which doesn't mean that the astronauts in the ISS's Russian orbital segment are going hungry. "You do a variety of missions to keep those coffers full, to protect yourself from situations like this," says Huot. "The loss of this vehicle isn’t going to impact operations in any way." The ISS keeps a reserve of six month's worth of supplies at all times, so nobody is going to be chowing down on space flowers or growing potatoes in poop any time soon.
My recent post on tightropes reminded me of a great "hack." Here's the situation. Your car is stuck in the mud, so you grab a rope and tie it to the front of the car and then the other end to a very sturdy tree. Now for the trick—grab the rope in the middle of the length and pull perpendicular to the rope. Here is a diagram.

It's a cool and useful trick, but how does it work? In short, it's the same as standing on a tightrope. The forces at the point of contact have to add up to the zero vector if it's in equilibrium.
Let's take a closer look at the point that you would pull on the rope. At this point, there are essentially three forces.

With the contact point in equilibrium, these forces have to add to zero. The only component of force that is interesting is that perpendicular to the rope. Assuming the magnitude of the two tensions is the same, then I get the following expression.

If the distance from the car to the tree has a value of L, then pulling perpendicular a distance of x would give the following for sinθ:

Why am I calling the perpendicular distance "x"? I have no idea, but I'm sticking with it. Now if I substitute this expression for sinθ, I get the following relationship between tension in the rope and the force I pull with.

With the term in front of F as the "force multiplier" (I made that term up). How about an example with actual real numbers? Suppose I have a rope that is 4 meters long and I pull to the side with a force of 20 Newtons such that it is displaced 10 cm. Putting these values into the above expression, I get a tension force of 200 Newtons—or a force multiplier of 10! Not too bad, right?
What if I pull with a force of 20 Newtons but only displace the rope 0.1 cm? Ah ha! I caught you trying to cheat. Yes, if you put these values into the expression above, you would indeed get a huge force multiplier. However, you don't get to pick how far the rope deviates from the straight line. This deviation is actually a factor of the initial rope tension (and of the "springiness" of the rope). Either way, start with a rope at a high tension and then pull to the side to get an even higher tension.
Oh, you aren't getting something for nothing—that's not how physics works. This is essentially a simple machine. You pull with a small force over some distance and get a much larger force out, but that larger force would only move the car a little bit (small distance). If you need to keep the car moving, you would have to re-tie the rope to get the tension back up.
But does this really work? I'm not going to go and get my car stuck just to test this out (but you know, that's not a bad idea). Instead, I will do this on a small scale using some force sensors. I will take one force sensor and tie a string to it and a stationary object. Next, I will take a second force sensor and pull to the side of the string. The perpendicular displacement of the string will be measured with cart on track that measures position (this is pretty cool). Here is a picture.

Now I can collect the values of the two forces (the tension in the string and the side pulling force) along with the displacement distance. Here is a plot.
That's pretty cool. The tension force is indeed greater than the sideways force. I will assign a homework question that goes with this data (down below).
One of the things I have trouble thinking about is the initial tension in the rope. How does this effect the system? Honestly, I'm not too sure—so I'm just going to build a model to play with. My model will be in Python and you can play with it too.
Here is the plan. I'm going to replace the string with two springs. The two springs will have an unstretched length of a little under half the original rope length. This way the two springs will create a tension equivalent to the rope. Then when the middle point (between the two springs) is moved down, the two springs will stretch and increase the force.
Without too much detail (because you can look at the code), here is my two-spring model of a rope pull. Click the "play" button to run and the "pencil" to see (and change) the code.
Notice that the graph does indeed look similar to the actual data above. That's called winning.
Here are some questions for you to consider.
The North Island of New Zealand is chock full of volcanoes—and big volcanoes at that. No less than four major calderas sit in the Taupo Volcanic Zone (TVZ) that stretches from White Island in the north to Ruapehu in the south. One of the most violent volcanic eruptions in human history took place in ~186 AD from Lake Taupo. That rhyolitic (high silica) eruption produced an ash plume that may have towered 50 kilometers (164,000 feet!) over the caldera, what we call an "ultraplinian" eruption (and anything that is "ultra" has to be big). More recently, Tarawera in the Okataina caldera erupted in 1886 in one of the most explosive basaltic (low silica) eruptions on record that had ash plume that reached 10 kilometers (~32,000 feet) and buried a number of towns along with blasting a new valley out of the landscape. The North Island is definitely a place where volcanic unrest is taken seriously.
So, the somewhat surprising steam explosions that took place this week at Lake Rotorua have caught a lot of people's attention. On November 28, a large steam explosion occurred near Ohinemutu near the shores. Then, on December 30, the caldera had a second, smaller explosion. The first explosion sent water and volcanic gases 25-30 meters (80-100 feet) up in a geyser-like blast. The event was brief and over by morning, so very few people actually saw the explosion happen. This was the first hydrothermal explosion at Rotorua in 15 years and came as a surprise to GNS Science, the volcano monitoring agency of New Zealand. People near the explosion reported hearing low, rumbling noises prior to the blast, which likely were caused by the movement of hot water and steam subsurface.
The second explosion came on Wednesday (November 30) and this one was caught on video. In that event, you can see the lake surface begin to churn with heavy steam and dark material (likely sediment from the lake bottom). This blast looks much smaller, with water and debris only reaching a few meters (10 feet) over the lake surface.
Hydrothermal explosions like these are common in calderas. However, the trigger of these explosions is unclear. GNS Science has suggested that they could be related to the recent spate of earthquakes New Zealand has experienced since the M7.8 on November 13. This could make sense: Hydrothermal systems under volcanoes have been known to readjust after earthquakes due to movement on the faults that riddle the ground beneath the TVZ. Brad Scott from GNS Science suggested that the second blast might have also been related to recent weather, and that it's likely linked to what triggered the initial blast.
However, Scott has said that these new steam explosions do not suggest that the Rotorua caldera is heading towards any sort of volcanic activity; GNS Science has not raised the alert status for the volcanic system either. Steam explosions are driven by building up of steam in the subsurface hydrothermal system until the cap of rock above can't hold the pressure—like popping a champagne cork. These steam explosions, although relatively infrequent at Rotorua, do happen and no eruption has occurred near the lake in 25,000 years. Even the explosions that occurred during the 1980s-2001 were likely helped along by drilling during attempts to exploit the hydrothermal system at Rotorua.
Anyone who has been to Rotorua can attest to its volcanic nature (see above). There are geysers and mudpots on one side of town, including the impressive Pohutu geyser, buildings have been closed due to volcanic gases seeping into their basements, and many sewer grates steam from the gases and heat of the magma deep below the street. It is actually a remarkable location, as if you built a small city directly on top of the hydrothermal areas of Yellowstone Caldera in Wyoming. Although steam explosions like these two might seem dramatic, they are not signs of impending destruction at Rotorua, but rather just continuing evidence of the volcanic nature of the North Island of New Zealand.
In an epidsode of the dystopian near-future series, Black Mirror, a small, implantable device behind the ear grants the ability to remember, access, and replay every moment of your life in perfect detail, like a movie right before your eyes.
Theodore Berger, a biomedical engineer at the University of Southern California, can’t promise that level of perfect recall—perhaps for the better—but he is working on a memory prosthesis. The device, surgically implanted directly into the brain, mimics the function of a structure called the hippocampus by electrically stimulating the brain in a particular way to form memories—at least in rats and monkeys. And now, he’s testing one that could work in humans.
Berger’s device hinges on a theory about how the hippocampus transforms short-term memories, like where you deposited your keys, into long-term memories—so you can find them later. In his early experiments, he played a tone and then puffed air in a rabbit's face, causing it to blink. Eventually, just playing the tone would make the rabbit blink, just like Pavlov’s famous salivating dogs. Berger recorded the hippocampus’ activity with electrodes, and as the rabbits learned to associate the tone with the air puff, patterns in those signals changed in a predictable way.
“The hippocampus was being actively engaged by and modifying its firing pattern by the training,” says Gregory Clark, Berger’s former mentee and a professor of biomedical engineering at the University of Utah. Berger calls this firing pattern a space-time code: It’s defined by where the neurons are in the brain, as well as when they fire. “As the space-time code propagates into the different layers of the hippocampus, it’s gradually changed into a different space-time code,” Berger says. “And we don’t understand why, but when it comes out, that space-time code is what the rest of the brain can recognize and use as a long-term memory.”
The outgoing code represents the memory that the rest of the brain uses as a signal—for the rabbits to blink their eyes when they hear the tone. And Berger says he’s been able to mathematically model the general rule the hippocampus uses to convert short-term memories into long-term memories.
With the general rule in hand, he built rats an artificial hippocampus. To do that, he first had to teach rats to complete a memory task: He would present a rat with one of two levers to press, then distract it with a light. When the turned back to the task, it was trained to press the lever opposite the one it originally pressed, to demonstrate it remembered.
All the while, Berger and his team recorded the firing from the hippocampus, noting which space-time codes corresponded with the lever-pressing memory. They took the data from the incoming and outgoing firing patterns in the hippocampus and developed a mathematical model that could predict the outgoing space-time code corresponding to the incoming one. Later, when Berger gave the memory task rats a drug that blocks memory formation, he used his device to electrically stimulate the brain with the pattern of pulses—the outgoing space-time code—predicted by his model.
Then the rat would press the correct lever. “They recall the correct code as if they’ve created it themselves,” Berger says. “Now we’re putting the memory back into the brain.” Berger has also tried out the prosthesis in rhesus monkeys, in a part of the prefrontal cortex. This area is involved in executive functions like using memories to solve a novel problem. In that context, the implant improved the monkey’s memory, too.
But could a similar implant in a human really work? “All of these prosthetics interfacing with the brain have one fundamental challenge,” says Dustin Tyler, a professor of engineering at Case Western Reserve University. “There are billions of neurons in the brain and trillions of connections between them that make them all work together. Trying to find technology that will go into that mass of neurons and be able to connect with them on a reasonably high-resolution level is tricky.”
Even cochlear implants—which simulates a range of sound frequencies by stimulating the auditory nerve with a couple dozen electrodes—can’t mimic sound perfectly. Scientists are far from simulating entire memories, with all their sensory inputs, especially with an electrical code using only about 100 electrodes. But that didn’t stop a new startup called Kernel from syncing up with Berger, partially bankrolling his research and naming him their Chief Science Officer.
Kernel’s earliest goals are to bring Berger’s implant to the market as a medical device that can help the memory impaired—Berger is currently conducting a human trial with a version of the device, and says that so far, the patients in his human trial are performing well on memory tests. But ultimately, CEO Bryan Johnson wants Kernel to develop devices—implantable in a simple outpatient procedure—that enhance human intelligence in areas like attention, creativity, and focus.
That goal would venture into new waters for regulatory agencies: Are these medical devices or consumer devices, and who should regulate them? Under the Food and Drug Administration’s terms, an implant would count as a medical device if its intent is to diagnose or treat a medical condition or to affect the structure or function of the body. But a subdermal implant that merely suggests it could improve concentration or creativity may slip through the FDA’s regulatory grasp, like the dietary supplements of brain stimulators.
Johnson did not comment on which direction he’ll take Kernel’s yet-unmade devices: It will depend on the individual device, its applications, and potential side effects. Sure, all medical devices and drugs come with possible side effects. Now we wait to see if this one will be a benign annoyance, or the inspiration for a new, chilling episode of Black Mirror.
I'll be honest. I don't really watch Gotham, but it looks interesting. It chronicles the events in Batman's city before he became Batman. That's about all I know.
However, when I saw a recent commercial for an upcoming episode, I had to do something. I'm not sure what's going on here, but from my research this appears to be Selina Kyle and Bruce Wayne doing something with a tightrope. Here's the important shot:
From the rest of the scene, it seems that Selina is trying to avoid laser tripwires. Someone uses an arrow to fire a rope across the room into a wall, then Bruce holds the other end as Selina walks its length. But there's a problem with this: No one could hold that cable. Not Batman, and especially not Bruce Wayne.
This is all about forces and equilibrium. If Selina is standing at the middle of the cable, all of the forces on her must add up to the zero vector. Let me start with a force diagram showing the vector forces on a stationary Selina:

Some important things to consider about this diagram and the forces:
If I assume that the x-axis is horizontal and the y-axis is vertical, I can write the vector force equation as two component equations. Let me start with the x-forces. Only two forces act in the x-direction—the components of the two tension forces. Since I know the angle between these forces and the x-axis, I can write the following:

Notice that since that T1 pulls to the left, it has a negative x-component and T2 has a positive x-component. However, since the magnitude of T1 is equal to the magnitude of T2 this equation is pretty useless. It basically just says that 1 = 1, which we probably already knew.
What about the y-direction? Here is the sum of forces in just the y-direction:

In this case, both of the tension forces are in the positive y-direction. But since they have the same magnitude, T1 = T2 so I can just call these T. Now I get the following:

This gives a value for the magnitude of the tension. Remember, this is the force that Bruce must pull on the rope. I can give an approximate value to this tension force by estimating the mass of Selina (50 kg) and the bend angle in the rope (I'll say 10 degrees for now). Putting these values into the above equation, I get a tension force of 1,410 Newtons (317 pounds). Yes, that's a huge force. Oh sure, maybe Batman could pull that hard, but remember, this is Bruce Wayne as a boy. I don't think he could hold her up.
But wait, there's more! Clearly, we have other questions to consider. I'll just leave these homework questions for you.
On October 19, two European Space Agency spacecrafts arrived at Mars, right on schedule. But while one crash-landed on the red planet's surface (ESA scientists are still trying to figure out what happened to poor ol' Schiaparelli), the other safely inserted itself into orbit. And last week, the ExoMars orbiter sent home its first images.
An onboard camera called CaSSIS—Color and Stereo Surface Imaging System—snapped these pics. In the past weeks, it has blinked online for just a few hours at a time, taking experimental shots, like a beginner art student pointing her camera at nothing in particular. This is in advance of the orbiter's main job: sniffing out and cataloguing trace gases like methane, a possible indication of life. After ExoMars' other instruments identify a gas, it’s CaSSIS’s job to look around on the Martian surface to figure out what source might’ve dealt it.
CaSSIS powered up for the first time in space for a fully-configured testing phase and generally, things look pretty good. The scientists needed to know whether everything worked: how quickly the camera could capture images, how fast the telescope rotated, whether the images overlapped correctly so they could be stitched together. The camera was a lot more sensitive to light than they expected—which was a nice surprise, says Antoine Pommerol, a planetary scientist at the University of Bern in Switzerland. And CaSSIS has great, sharp focus, which you can see in the images. But sometimes, the scientists found, the camera's aim is off: a short lag means it might miss a particular feature on the surface that it’s trying to capture.
CaSSIS isn’t as high-res as some cameras on other Mars spacecraft (like NASA’s Mars Reconnaissance Orbiter, for instance), but it has other capabilities. For one, it comes equipped with four different color filters, which allow scientists to tease out the mineralogy of the surface, telling one iron-based mineral from another, or whether an area is rife with olivine or just has high clay content. And CaSSIS takes stereo images, which lets researchers assemble the photos to reconstruct particular areas in 3D. That’s useful for keeping track of Mars’s various slopes, which can slump because of ice condensing or subliming away.
Those capabilities will come in handy when the data-gathering portion of the mission begins in earnest in 2018. Then, CaSSIS will photograph specific, promising target sites suggested by scientists and the public. “It’ll be a firehose of data,” says Nicolas Thomas, the principal investigator on CaSSIS. Before that, though, the team has to make sure everything works just right, and that means test shots like the ones above, where they couldn’t really choose what they were imaging.
These are no planetary glamour shots. “We didn’t bother putting it in color, purely because it was boring,” says Thomas—the areas they photographed were so full of dust that they completely covered the mineralogy underneath. (Though, does anyone really ever tire of photos from other planets?) Scientifically, they're valuable because they tell Thomas and the rest of the CaSSIS team that the instrument is working. They can use the information to develop better calibration tools, populate a database of targets, and generally get ready for the real deal.
And this camera work is important, Thomas says, because it’s vital to have instruments monitoring the Red Planet—especially as the current ones age. “Mars is a lot more geologically active than we imagined 15 years ago,” he says. “Things change.” And science needs pics of those changes, or they (basically) didn’t happen.
Ariana Campellone grew up in East Greenwich, Rhode Island. It is a small community, affluent and charmingly New England. Heroin was very available there, and very good.
By age 15, Campellone was a daily user. She stopped going to school, stopped doing much of anything besides scoring drugs, doing drugs, stealing stuff, selling stuff, scoring more drugs, doing more drugs. "This was the beginning of the New England heroin epidemic," she says. "Everyone I knew was overdosing, dying, lives falling apart, people contracting diseases from sharing needles."
That experience was mirrored around the country. In 2014, overdoses from heroin or prescription opioids killed 30,000 people—four times as many than in 1999. Today, 3,900 new people start using prescription opioids for non-medical purposes every day. Almost 600 start taking heroin. The yearly health and social costs of the prescription opioid crisis in America? $55 billion.
Campellone kicked her habit at 19—with rehab, suboxone, and a lot of willpower—and moved out west, to the San Francisco Bay Area. She began working at a natural remedy shop in Berkeley. Her bosses and co-workers introduced her to a plethora of plant-based products, among them a tart-tasting leaf called kratom. It gives a slight, euphoric high. Like the feeling that remains when you spin around in circles, after the dizziness wears off. It was also a decent painkiller, so she'd take it when she was hurt, or on her menstrual cycle.
And, on two occasions, she used it to help with the withdrawal symptoms following heroin relapses. "Nothing really feels good when you're withdrawing from heroin, so no matter what you're taking, you're still in pain and it's pretty excruciating," says Campellone. But kratom helped some.
Campellone never needs a prescription to get kratom. Nor does she have to visit a dealer. She buys it from an herbal remedy store—about $20 for a 4 ounce packet, which lasts about a week. When she takes too much, she gets a stomach ache. And when she does not take it, she doesn't crave it like she craved heroin. Mostly she doesn't think about it; it just sits in her cabinet. So, she was surprised when, on August 30, the DEA announced that it was pursuing an emergency scheduling of mitragynine and 7-hydroxymitragynine, the active alkaloids in kratom. Campellone was one of perhaps 4 or 5 million Americans who were being told, for maybe the first time, that this leaf posed an "imminent danger to public safety."
Biologically, kratom acts enough like an opioid that DEA considers it a threat to public safety. The agency planned to use a regulatory mechanism called emergency scheduling to place it in the same restrictive category as heroin, LSD, and cannabis. This category, Schedule I, is reserved for what the DEA considers the most dangerous drugs—those with no redeeming medical value, and a high potential for abuse.
Kratom leaf
Before they finalized the scheduling, something surprising happened. An advocacy group called the American Kratom Association (yes, AKA) raised $400,000 from its impassioned membership—impressive for a nonprofit that typically raises $80,000 a year—to pay for lawyers and lobbyists, who got Congress on their side.
On September 30, representatives both conservative and liberal—from Orrin Hatch to Bernie Sanders—penned a letter to the DEA. “Given the long reported history of kratom use, coupled with the public’s sentiment that it is a safe alternative to prescription opioids, we believe using the regular review process would provide for a much-needed discussion among all stakeholders,” they wrote.
It worked. The DEA lifted the notice of emergency scheduling, and opened a public comment period until December 1. When was the last time the DEA backed off anything? "This is unusual," says Gantt Galloway, a Bay Area pharmacologist specializing in treatments for addictive drugs. Galloway could not recall another instance when the DEA responded to public outcry like this.
As of this writing, those comments number nearly 11,000. They are from: people who use kratom to relieve chronic pain or endometriosis or gout; people who use kratom to treat depression or wean off opioids or alcohol; people who said it saved their life. “It doesn't allow you to escape your problems,” says Susan Ash, founder of the AKA, who used kratom to treat pain and escape an addiction to prescription opioids. “It instead has you face them full on because it doesn't numb your brain at all, and it doesn't make you feel stoned like medical marijuana does. And yet it's effective on so many things, like pain and anxiety and depression.”
That promise is part of the problem. Scientists know practically nothing about kratom—how its compounds work in concert, what it can actually treat, how addictive it might be, what counts as a safe dose. And certainly not enough to back up all the life-changing claims extolled in public comments, and by the many kratom users we interviewed. In the absence of good science and the slightest hint of regulation, Ash and potentially millions of other users are winging it. And should the DEA follow through on its promise to schedule kratom, these people will become criminals overnight.
For Ash, that’s completely unacceptable. “I want the future to look like this is your next coffee,” she says. “I'd like it to be sold in Starbucks. I'm not even kidding.”
Kratom is not an opioid—actually, it is in the coffee family—but its active molecules bind to the same neuronal receptors as opioids like heroin, codeine, oxycodone, and morphine. Typically, those drugs give users a feeling of euphoria and dull their pain—that’s why David*, a former boarding school teacher, started using prescription opioids to treat his discomfort from ski injuries. He became addicted, and when his prescriptions ran out, he switched to heroin. "I became a high functioning user,” he says. "My addiction was never detected at my place of employment, although I do think my behavior became more erratic."
When David eventually committed himself to rehab, his doctors weaned him off heroin using suboxone, a combination of two drugs—buprenorphine, a partial opioid that quenches the body's chemical thirst, and naltrexone, which blocks any euphoric opioid feelings. But suboxone can give users symptoms of withdrawal, not to mention a dulled sense of reality. And users like David can still find ways to abuse it. "Dependence on that was different from heroin, and it became easier to take more suboxone to a higher high, or selling it to score heroin again," he says.
As of this writing, though, David has been clean for 18 months—success that he attributes to kratom. Since it binds to the same receptors as opioids, kratom users report similar euphoric and pain-killing effects, but they’re muted. After other 12 step recovering addicts introduced David to the plant, it helped him rebuild his life—he did eventually lose that boarding school teaching job—and deal with the physical pain that got him hooked on opioids to begin with.
Since it mirrors opioids in other ways, the concern is that kratom is also addictive. But again, the real science is sparse. David and several other users we spoke with said kratom is habit forming, to some degree, though one survey in Southeast Asia found that for people using it to kick an opioid addiction, the dependence is far less likely to disrupt their lives. "When I take kratom, that addictive part of me kicks in and it becomes habitual," says Jeffrey*, another former opioid addict. "It doesn’t throw my life out of control, but it bugs me when people say things like, 'it’s not more addictive than coffee.' I think that hinders us making inroads with the regulators.”
There is no doubt, however, that kratom is less harmful than opioids—even take-home synthetics like suboxone. When opioids kill, they do it through respiratory depression—they slow your breath until you stop breathing entirely. But kratom’s chemical composition doesn’t appear to produce the same effects. “The two main alkaloids in kratom, mitragynine and 7-hydroxy, appear to have a low ceiling for respiratory depression,” says pharmacologist Jack Henningfield of the Johns Hopkins School of Medicine, who with the consulting firm Pinney Associates has advised the AKA on kratom scheduling. “And that's why if you look hard, it's very difficult to find deaths attributable purely to kratom.”
Notice he said "purely." In its initial notice of emergency scheduling for kratom, the DEA did link the drug to 15 deaths between 2014 and 2016. But that accounting ignores the fact that all but one of those people had other substances in their systems. Folks using kratom to wean themselves off opioids may still be taking those opioids.
And some deaths could be attributed to contamination: Because kratom isn’t strictly regulated, bad actors can and do lace the plant with actual opioids, like the extremely powerful synthetic opioid fentanyl. “You can just imagine, ‘Oh you got pain? Well, we've got a special kratom product,’” Henningfield says. “Maybe it has fentanyl in it. That's scary.” Clearly, the plant needs some kind of regulation. The question is whether the DEA’s scheduling is the right kind.
The FDA could help prevent contamination-related deaths by strictly regulating kratom as a supplement, as opposed to the DEA scheduling it as a drug. "FDA has a lot of authority to actually help consumers know that what they're buying is what is labeled, and have at least some level of assurance," Henningfield says. "It's not close to the drug standard, but it's much better than something that's illicitly marketed."
But the FDA is actually also pivotal in advising the DEA on the scheduling of drugs. "The decision to permanently schedule any drug is not a DEA unilateral decision," says Steve Bell, a DEA spokesperson. Consider the regulatory pathway of suboxone. The FDA approved the drug in 2002, and the Department of Health and Human Services recommended that the DEA put it in Schedule III, which the DEA accepted. This puts the drug in the same category as Tylenol with codeine: It’s available for doctors to prescribe for narcotic addiction, but is still a controlled substance.
Schedule I, though, is an entirely different rodeo. If the DEA places kratom here, nobody can touch the stuff. Current users, should they continue to use, will be forced to even sketchier sources. And scientists will have a harder time learning how kratom works, and supporting, or refuting, the claims users make with hard data. (Consider marijuana, also a Schedule I drug. Science has a dearth of data on it because getting permits to study the drug is an exercise in bureaucratic insanity.)
All that research costs money. Which is kratom's catch-22: The DEA wants to schedule the drug because they think it might pose a danger to public health, but the only way to confirm (or refute) the DEA's worries is with more research—which will be next to impossible should the DEA follow through on its promise to schedule.
One of the few scientists studying kratom is the University of Florida’s Oliver Grundmann, who is finishing up an online survey of nearly 10,000 users. And the data (preliminary, though Grundmann plans to publish a paper in the coming months) reveals a different profile of kratom users than you’d expect from an “illicit” recreational drug.
“The age range is more geared toward an older population," says Grundmann, "which is more likely to experience work related injuries or acute or chronic pain from another medical condition." Over half of users are between the ages of 31 and 50. Eighty-two percent completed at least some college. Nearly 30 percent of respondents pull in a household income of over $75,000 a year. Not quite the party drug demographic. And the public comments on the DEA’s scheduling notice reflect that population. Many of those folks are using kratom to either wean themselves off prescription opioids or use the drug alone to treat pain.
Still, that's self-medication using a product that may be contaminated. "The industry needs to come together," says Susan Ash of the AKA. "There's no way the FDA is going to feel comfortable not seeing this as a scheduled controlled substance without a commitment from the industry that there will be proper measures put in place." Better labeling, for instance, would be a start.
Grundmann says he understands the DEA's motivation. "They do not want to have another drug out there that could potentially contribute to the already devastating opioid epidemic that some communities are experiencing,” he says. “But on the other side, we also need to consider that the 4 to 5 million estimated users of kratom may face a health crisis of their own if kratom becomes scheduled.”
Ariana Campellone takes her kratom with coconut milk and protein powder. Then, she mixes, diluting with water to take the lumps out of the mixture. By itself, the stuff tastes awful. Like oversteeped tea, or a mouthful of peat. She thinks the comparison to coffee is a bit overstated. "Coffee gives me a noticeable spike and high, and can feel when I'm coming down," she says.
The DEA’s public comment period closes tomorrow. The agency says it will consider those comments alongside the FDA's scientific and medical evaluation before proceeding to schedule. The FDA did not respond in time to comment on this story.
However, if the DEA follows through on its previous intent to schedule, Campellone says she'll still continue to use kratom. "Just like people have continued to use cannabis where it's not legal," she says. In practical terms, it means getting ahold of kratom would probably get more expensive and personally risky. Those costs, those risks—those hassles—might not be worth it to some kratom users. And then the not-so-small community of recovering opioid addicts lose something available, and possibly quite good.
*This name has been changed to protect anonymity.
Magnets aren't miracles, but neither are they a phenomenon that physicists completely understand. Particularly big magnets, like the sun. Until recently, the annals of research failed to completely explain how massive currents blooming on the sun's surface burst into solar flares, releasing incredible volumes of energy in short time frames.
Peter Sweet was vexed by this problem when, in 1956, the English physicist traveled to Stockholm for a meeting of the International Astronomical Union. He presented a partial solution: When two magnetic fields meet, a current sheet forms between them, and plasma (fiery blobs of energy) erupts at the seam. An American physicist named Eugene Parker saw Sweet's presentation, and worked out the math on his flight back to the states. For fifty years, their Sweet-Parker model has been crucial for explaining not just solar flares, but other large-scale magnetic activity, like Earth's aurora.
However, Sweet-Parker is too slow. Under that model, solar flares would take weeks to burst. "Imagine you have many persons in a room, but just one door to exit," says Luca Comisso, a heliophysicist—sun scientist—at Princeton University. "The rate at which they can leave is fixed, so it takes a long time for them all to leave." But solar flares discharge their energy in minutes. The problem is Sweet-Parker assumes magnetic fields remain stable when they meet. Like sophisticated guests at a society ball, the accumulated quanta of energy would exit the current sheet in orderly fashion.
Comisso says it's not that kind of party. Magnetic field behave more like fraternity ragers being busted by the cops: People crawling out windows, leapfrogging through doors, busting down walls to escape. He and some co-authors recently published an alternative theory, on the open physics exchange arXiv. "Current sheets are not stable in time, they evolve, get narrow, become more intense," says Comisso. This dynamic activity causes the huge, burning plasmas carried by the current sheets to intensify. "Plasmoids are like small blobs in this current sheet that grow until they break," he says. "At a certain point they become big enough to burst, and destroy their current sheet and you have an explosion of current energy."
Comisso and his co-authors built on 10 years of research by themselves and others on plasmoid instability to develop their mathematical solution. The theory calculates a given plasmoid's size, and the size it would need to be in order to destroy its current sheet. "We can characterize the properties of plasmoid instability, and identify which blob of plasmoids will become big first," he says. Developed more fully, their theory could become a the basis for things like early warning systems for the satellite-wrecking waves of energy emanating from bursted solar flares.
Nuclear physicists working on fusion energy might find the theory useful, as well. A tokamak is a type of fusion reactor that uses electromagnetic coils to control donut-shaped plasmas of energy. But heating the plasma to fusion-hot temperatures—about 10 times hotter than the center of the sun—is complicated. Because just like on the sun's surface, the current sheets between magnetic fields in the tokamak want to burst. This releases energy, lowering the temperature, making safe, stable fusion impossible. But, if scientists can predict when and where plasmoids will burst, they can use some external force, like radiofrequency waves, to keep the current sheet stable. And if they figure all that out? Well, talk about a miracle.
Early this morning the Senate confirmed Rep. Tom Price as the new secretary of Health and Human Services by a party-line vote of 52-47. Price, a six-term Republican legislator from Georgia who has been proposing alternatives to the Affordable Care Act since it was signed into law in 2010, will play a central role in the new administration’s plans to dismantle the legislation. And while he’s made it clear that scrapping the ACA is a top priority, as the most powerful man in health care he’ll have authority over way more than just insurance coverage.
As HHS secretary, Price—an orthopedic surgeon before being elected to the legislature in 2004—assumes command of the government’s largest social programs: Medicare and Medicaid. He’ll also have wide authority over agencies like the Food and Drug Administration, the Centers for Disease Control and Prevention, and the National Institutes of Health. Not to mention a hand on the purse strings: HHS is the largest single source of funding for medical research in the world. How exactly he will wield that power is yet to be determined, but policy analysts say a look at his voting record gives some good clues.
“It’s notable that the president-elect appointed a real conservative as opposed to someone more populist,” says Paul Ginsburg, director of public policy at the University of Southern California’s Schaeffer Center and a Brookings Institution senior fellow. “It breaks with the theme of some of the other appointments.” Over the years Price has described himself as a fierce opponent of government waste and an advocate for lower spending. He’s also voted against federal funding for abortion and family planning groups like Planned Parenthood, along with a bill that would have provided four weeks of parental leave for federal employees and a law that now requires the FDA to regulate tobacco as a drug. And he’s in favor of privatizing Medicare—those who qualify would be provided a voucher to be used as a subsidy for private insurance.
There are also clues in Price’s ACA replacement plan—the Empowering Patients First Act—which is the most detailed of all the Republican proposals (including Paul Ryan’s) to replace Obamacare, and the least generous, especially to the sick, old, and poor. It would leave in place the basic structure of the insurance exchanges but replace the existing income-based subsidy system with age-based tax credits, making the individual market more advantageous for the young and healthy. The plan also lets insurers charge sick people more if they lapse in coverage—up to 150 percent of the standard premium. It also would repeal the expansion of Medicaid, a program that provided more than 12 million low-income Americans with coverage, and replace it with nothing. While these wholesale cuts didn’t make it into the GOP’s comprehensive “Better Way” agenda that Ryan announced in June, many other ideas from Price’s plan did.
Ginsburg says the fact that Republicans have had such a difficult time coming together on an alternative plan is grounds for skepticism that it will truly provide similar coverage. “Repeal has come much more quickly from the lips of Republicans than the word replace,” he says. And he notes that the people who should worry most are the 22 million Americans who’ve received coverage under ACA. Based on the Republicans’ plan, they’re the ones most likely to to be left behind in the overhaul.
But others think Price’s experience will help to focus and unify efforts to reform Obamacare in his new position. “Deals are not a conservative or a liberal instinct, they’re a legislative instinct,” says Tevi Troy, CEO of the American Health Policy Institute and former deputy secretary of HHS. The big picture, he says, is that Obamacare mandates too big of a benefit package, which kept premiums high and thwarted enrollment, especially by young people. “Price wants to build on what works and find ways to drive down costs overall so you can incentivize people to purchase health care coverage on their own,” he says. “And he knows how to make compromises—he’s a very smart choice from that perspective.”
Historically speaking, however, Price’s willingness to compromise only goes as far as a complete and total redo of existing health care laws. In an interview with The Wall Street Journal over the summer, he said, “I wouldn’t draw any lines in the sand other than that the plan we’re on doesn’t work.”
And as HHS secretary, Price now has executive control over the vast regulatory apparatus that directs the national health care system. Some advocates worry he’ll be able to use this to chip away at Obamacare before legislators even move to a final vote. “Dr. Price has long advocated policies that until now have not gone into effect," says Cindy Pearson, executive director of the National Women’s Health Network, including, for example, the requirement that insurers have to cover every type of FDA-approved contraceptive. And because that requirement is a regulation, not a law, it could be undone without any legislative action—simply by not enforcing it. The same is true for federal guidelines that punish states’ efforts to not provide abortion services by denying Medicaid programs. "Now he has the executive power to actually do something," Pearson says. "And women will get hurt."
While groups that advocate for women’s health and LGBT rights are sounding the alarm bells on the Price nomination, Ginsburg says it’s important to remember that the Republican war on Obamacare started a long time ago. “Appointing Tom Price to be HHS secretary doesn’t really change much, it just makes the process better focused.”
Editor's Note 2/10/17 12:30 Eastern: This story has been updated with the results of Price's Senate confirmation vote.
This summer, Riva-Melissa Tez was searching online for research that might help her father. He’d gone into a coma after suffering a stroke, and she wondered what the latest recommendations said—whether playing music to him in his native language could keep him connected to this world, or if giving him Prozac could boost his chances of recovery as it had done for mice in a study last year. Doctors are so busy saving lives, she thought, that they couldn't possibly keep up with all the papers published every day.
Her concern is shared by doctors, who wonder what they could be missing in the 2.5 million scientific papers published every year. Popular sites like MedCalc and UptoDate are useful tools for doctors to consult diagnostic criteria and double check on treatment guidelines. But there’s plenty of room for improvement, and some believe artificial intelligence could be a solution to science overload: machine learning assistants to read incoming papers, distill their information, and highlight relevant findings.
Last month, a company named Iris launched a first version of that type of assistant. The machine can currently read the abstract of a paper, map out its key concepts, and find papers relevant to those concepts. It provides a quick way to get a sense of the scientific landscape for a given topic, something especially useful when you don’t know the exact keywords for the type of research you are looking for. The Allen Institute for Artificial Intelligence also recently launched a search engine, Semantic Scholar, that takes search beyond keywords.
“One of the problems is getting research out of the dusty digital drawers and into the hands of people who can implement it,” says Anita Schjøll Brede, the CEO of Iris. Her tool should make it easier to navigate the literature, especially for people doing interdisciplinary research, she says. In three years, the company plans to make a proactive version that remembers which papers you read last week and gives you new ones based on your project description. And in 10 years, she hopes the AI will be powerful enough to discover new concepts—based on its reading and understanding of the literature—all on its own.
Iris’s machine is discipline-agnostic. It doesn’t care if you ask to find research about cancer or composite material. But other groups are homing in on the problem in medicine. IBM is using its AI technology to take on the high-stakes field of cancer treatment with Watson for Oncology, an application trained by expert oncologists at Memorial Sloan Kettering Cancer Center. It draws from papers, patients data, and clinical trials to help generalized cancer doctors keep up with developments in the field.
IBM’s application doesn’t expand to other medical fields, and Iris’ machine currently just improves how literature is organized and accessed. For a typical doctor with a typical schedule, just finding the proper research is not enough: Someone has to read and understand that research. “This is a huge problem,” says Setareh Alipour, a medical resident in New York. “Scientific data is becoming so vast that even specialized doctors can't know everything that is being discovered about their field. And I'm talking about larger studies, not small and unreliable data.”
The idea that scientific literature should have a place in clinical practice—so-called evidence-based medicine—is a fairly recent departure from medicine’s tradition of practicing what you learn in medical school. Physicians’ knowledge doesn’t always age well: Only about half of patients in the US receive the recommended course of treatment. Any efforts to bridge the knowledge gap or just make it a bit easier to track new science would be welcomed by doctors. “I would love it if a machine could act as my reliable and smart memory,” says Alipour.
Tez’s father came out of the coma and is now recovering. But some of the papers she found online actually piqued the interest of on-call physicians, who printed them and put them on the notice board in the neurology ward. Following this experience, Tez, who is the co-founder of an AI-focused venture capital fund Permutation, has thought a lot about the future of medically-minded machines.
An AI physician’s assistant could, she imagines, plug in to a universally accessible electronic health record that keeps all your information—cross referencing your symptoms and medical history with the most up-to-date recommendations to guide treatment choice. It could also alert your doctor about new research that could be of interest “The problem with hospital research and applying AI is that people who work in AI don't understand hospitals,” says Tez. Just as shown by IBM’s partnering with those in the medical field, if there’s an AI solution to improve healthcare, it will likely come out of a collaboration between hospitals and technologists.

Deserts are living contradictions: seemingly empty but in fact packed with life, burning hot by day yet freezing cold by night, and arid save for that odd flash flood that tears through the land, gouging out great canyons. And nowhere are these canyons more dramatic—and dangerous—than in Arizona.
For its new series Planet Earth II, the BBC paid one such chasm a visit. Oh, and they brought along a 360-degree camera, which means by clicking and dragging the video above, you too can drop into the canyon. It’s much safer this way—trust me. Should a flash flood come through, if the water itself doesn’t kill you, the boulders it carries most certainly will.
(This is the fourth of six 360-degree videos the BBC is publishing as companions to Planet Earth II. Scroll down for more!)
Listen, I don’t have anything against piranhas. They’ve never bothered me none. But a whole lot of other creatures in the Amazon have every right to fear them—except for the arapaima. This beast grows to 10 feet long and is covered with armored scales, making it an apex predator of incredible proportions. Check out this week’s episode of Absurd Creatures to learn more!
Find every episode of Absurd Creatures here. And I’m happy to hear from you with suggestions on what to cover next. If it’s weird and we can find footage of it, it’s fair game. You can get me at matthew_simon@wired.com or on Twitter at @mrMattSimon.
You know you’ve struck marketing gold when a brand becomes a so-called “proprietary eponym.” Need to blow your nose? Grab a Kleenex. Track some sand from the beach onto your floor? Hoover it up.
In biology, Crispr is the proprietary eponym of the moment. The gene-editing technique is so inexpensive and easy to use that, in just four years, it’s become a ubiquitous tool in labs across the world. And soon, it could jump from bench-top workhorse to human therapeutic. In late October, a Chinese team deleted a gene out of a lung cancer patient’s lymphocytes and then injected the edited cells back into his bloodstream, and more cancer-related trials are planned next year in both the US and China.
But the jury’s still out on whether Crispr will be as transformative as a medical therapy as it has been as lab tool. Plenty of gene-editing techniques have been attempted as therapies, but few have made significant impacts—especially when it comes to diseases as complex as cancer. A better place to start testing gene therapies is with inherited blood disorders, like sickle cell anemia and beta thalassemia.
These diseases are a good comparison point because they’re relatively easy to treat. Both arise from mutations to a single gene, which in this case result in malfunctioning red blood cells that starve the body’s organs of oxygen. And while it’s tricky to edit cells in a body while they’re in a body, it’s much easier with blood diseases: You just take blood cells out, treat them, and put them back—better known as a bone-marrow transplant.
Researchers have thrown a number of gene-editing techniques at these diseases, hoping one might become the standard of care for the more than 100,000 people in the US who suffer from them. But if you ask experts in the field, the smart money’s on Crispr. “The Crispr field is moving at such a lightning-speed rate,” says Stuart Orkin, a hematologist-oncologist at Boston Children's Hospital. “Many of the issues that people raise as potential problems are being solved—and they’re being solved at a faster rate than other techniques.”
Early this month, researchers reported harnessing Crispr to edit bone marrow stem cells from humans with sickle cell. Then they grafted them into mice to see how long the edited cells survived. Stem cells in the bone marrow give rise to all cells in the blood, including red blood cells; so presumably editing them would mean the correct gene would be incorporated into the red blood cells they create.
After four months, edited cells remained in the mouse’s bone marrow, making up about 6 percent of the total population. That was a three-fold improvement on a similar study from Berkeley scientists, who less than a month earlier reported finding only 2 percent edited cells in the marrow of mice after the same amount of time elapsed.
Meanwhile, in late October, over on the East coast, a team from Yale and Carnegie Mellon revealed results of a new, alternative gene-editing technique—one that doesn’t require a transplant. They managed to find 7 percent of bone marrow cells to be edited after five months in mice with the human mutation for beta thalassemia, simply by injecting them with synthetic DNA-like polymers (usefully called PNAs) via IV.
At first glance, that might seem like a more viable gene therapy strategy. To begin with, the technique doesn’t involve cutting the genome, which can lead to errors. Instead, a nanoparticle ferries the PNA into cells along with a snippet of DNA to correct a mutation. The PNA binds to a matching section of DNA and appears as a “pothole” that needs fixing, says Peter Glazer, chair of Yale’s Department of Therapeutic Radiology. The cell’s repair machinery then uses that template DNA to replace the divot.
With Crispr, in comparison, an enzyme called Cas9 cuts a targeted sequence of DNA out of the genetic code, leaving the repair machinery to fill the gap using a template DNA segment that scientists supply. Since Cas9 is a fairly active enzyme, there are concerns it could make cuts elsewhere in the genome, as it persists in cells after editing the beta globulin gene. Further, in both the Stanford and Berkeley studies, often when a cut was made the DNA template wasn’t used to guide the patch. That incorrect fix might stop red blood cells from forming sickle shapes, but it could render them dysfunctional—effectively trading sickle cell for beta thalassemia.
But editing alone is not enough. It’s important that the correct cells are modified. Scientists raised concerns that the PNAs were not editing stem cells, but rather cells that are farther along the path to becoming full-fledged blood cells. That could mean any therapeutic effect would be temporary, and that a human version of this therapy might require regular IV treatments. With Crispr, since cells are being brought outside the body and treated in the lab, it’s easier to ensure that it’s the actual stem cells that are being edited. And if a Crispr team can get a higher fraction of edited stem cells to persist in bone marrow, a one-time treatment could permanently alleviate a blood disorder.
According to Matthew Porteus, the pediatrician who led the Stanford sickle cell study, most scientists agree that there should be at least 10 percent modified cells persisting in bone marrow to have a clinical benefit. And the improvement in his study following so soon after the Berkeley team’s proof-of-principle suggests that the bar could be cleared in short order. “Both of our groups have shown the blueprint,” says Porteus. “And it should be easy for the next groups to adopt our recipes.”
A huge advantage of the technique is what led to its mass adoption in the lab—the gene-editing systems are simple and easy to make. PNAs, on the other hand, involve complex chemistry reminiscent of zinc finger nucleases (ZFNs), which less than a decade ago were the gold standard in gene-editing. Zinc fingers are pairs of proteins that each target a sequence of three DNA bases to bind to specific parts of the genome and break off a segment of DNA. While there are ZFNs that are as effective as Crispr at editing genes, building a pair of zinc fingers takes months. “To make a really good pair of ZFNs takes a lot of time,” says Donald Kohn of UCLA’s Broad Stem Cell Research Center. “Any lab can make 20 Crisprs tomorrow.”
That disparity means that when a problem arises for Crispr to solve, many groups around the world can easily take a crack at it. Meanwhile, the Yale/Carnegie Mellon team is essentially the only one refining the PNA technique. But that doesn’t mean they should abandon their efforts. “From a patient perspective, we need to have alternative approaches that people are developing,” says Porteus. “Because in a few years, we might stumble upon a fatal flaw in the Crispr technology that we can't solve.”
But until we hit that deal breaker, a future where people suffering from genetic blood disorders will soon have their pesky mutations Crispr’d out of their DNA for good is coming into clearer view.
You don't even have to watch the whole movie to get the best line from Doctor Strange. Let me set this up (mostly spoiler free). Stephen Strange (Doctor Strange) ends up meeting with The Ancient One and she shows him some seriously awesome stuff. Here is the conversation they have.
Strange: How do I get from here to there?The Ancient One: How did you become a doctor?Strange: Study and practice—many years of it.
Oh, you thought this post was going to be about the physics of magic in the Marvel Universe? Wrong. It's about learning magic in the Marvel Universe. It appears that learning super hero magic is just like learning anything in real life—there are no short cuts.
Sometimes it's easy for faculty to forget the struggles that we had when we were undergraduates. It's easy to look at students and say, "Hey—these people just don't get it because these concepts really aren't that hard." The real answer is that they aren't complicated now and for us. But they are still complicated ideas. The big difference is that students have spent a few weeks on a topic, but I have looked at it for decades (literally true in many cases).
Let me give a few more examples.
Even learning about learning takes time. You can't just tell someone that students don't learn by telling them stuff. But go ahead and try it yourself: That's the only way you really understand it.
It's not what we can do about learning, it's what we can't do. We can't make a magic pill that makes people learn, you can't skip the hard work to get to real learning. In fact, it is the hard work that is the learning. Yes, it hurts and it's confusing, but that's the way it is.
There seems to be a common theme in education that tries to make learning fun. I think this is a little backwards. Instead, it should be that real learning is fun—but it still includes the struggle and the confusion. Just imagine this. You have a puzzle to put together, but it only has four pieces. Would that be much fun? People like puzzles that are challenging, and we should all embrace the challenge of learning.
Theoretical computer science can be as remote and abstract as pure mathematics, but new research often begins in response to concrete, real-world problems. Such is the case with the work of Cynthia Dwork.
Original story reprinted with permission from Quanta Magazine, an editorially independent division of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences
Over the course of a distinguished career, Dwork has crafted rigorous solutions to dilemmas that crop up at the messy interface between computing power and human activity. She is most famous for her invention in the early to mid-2000s of “differential privacy,” a set of techniques that safeguard the privacy of individuals in a large database. Differential privacy ensures, for example, that a person can contribute their genetic information to a medical database without fear that anyone analyzing the database will be able to figure out which genetic information is hers—or even whether she has participated in the database at all. And it achieves this security guarantee in a way that allows researchers to use the database to make new discoveries.
Dwork’s latest work has a similar flavor to it. In 2011 she became interested in the question of fairness in algorithm design. As she observes, algorithms increasingly control the kinds of experiences we have: They determine the advertisements we see online, the loans we qualify for, the colleges that students get into. Given this influence, it’s important that algorithms classify people in ways that are consistent with commonsense notions of fairness. We wouldn’t think it’s ethical for a bank to offer one set of lending terms to minority applicants and another to white applicants. But as recent work has shown—most notably in the book “Weapons of Math Destruction,” by the mathematician Cathy O’Neil—discrimination that we reject in normal life can creep into algorithms.
Privacy and ethics are two questions with their roots in philosophy. These days, they require a solution in computer science. Over the past five years, Dwork, who is currently at Microsoft Research but will be joining the faculty at Harvard University in January, has been working to create a new field of research on algorithmic fairness. Earlier this month she helped organize a workshop at Harvard that brought together computer scientists, law professors and philosophers.
Quanta Magazine spoke with Dwork about algorithmic fairness, her interest in working on problems with big social implications, and how a childhood experience with music shaped the way she thinks about algorithm design today. An edited and condensed version of the interview follows.
QUANTA MAGAZINE: When did it become obvious to you that computer science was where you wanted to spend your time thinking?
CYNTHIA DWORK: I always enjoyed all of my subjects, including science and math. I also really loved English and foreign languages and, well, just about everything. I think that I applied to the engineering school at Princeton a little on a lark. My recollection is that my mother said, you know, this might be a nice combination of interests for you, and I thought, she’s right.
It was a little bit of a lark, but on the other hand it seemed as good a place to start as any. It was only in my junior year of college when I first encountered automata theory that I realized that I might be headed not for a programming job in industry but instead toward a PhD. There was a definite exposure I had to certain material that I thought was beautiful. I just really enjoyed the theory.
You’re best known for your work on differential privacy. What drew you to your present work on “fairness” in algorithms?
I wanted to find another problem. I just wanted something else to think about, for variety. And I had enjoyed the sort of social mission of the privacy work — the idea that we were addressing or attempting to address a very real problem. So I wanted to find a new problem and I wanted one that would have some social implications.
So why fairness?
I could see that it was going to be a major concern in real life.
How so?
I think it was pretty clear that algorithms were going to be used in a way that could affect individuals’ options in life. We knew they were being used to determine what kind of advertisements to show people. We may not be used to thinking of ads as great determiners of our options in life. But what people get exposed to has an impact on them. I also expected that algorithms would be used for at least some kind of screening in college admissions, as well as in determining who would be given loans.
I didn’t foresee the extent to which they’d be used to screen candidates for jobs and other important roles. So these things—what kinds of credit options are available to you, what sort of job you might get, what sort of schools you might get into, what things are shown to you in your everyday life as you wander around on the internet—these aren’t trivial concerns.
Your 2012 paper that launched this line of your research hinges on the concept of “awareness.” Why is this important?
One of the examples in the paper is: Suppose you had a minority group in which the smart students were steered toward math and science, and a dominant group in which the smart students were steered toward finance. Now if someone wanted to write a quick-and-dirty classifier to find smart students, maybe they should just look for students who study finance because, after all, the majority is much bigger than the minority, and so the classifier will be pretty accurate overall. The problem is that not only is this unfair to the minority, but it also has reduced utility compared to a classifier that understands that if you’re a member of the minority and you study math, you should be viewed as similar to a member of the majority who studies finance. That gave rise to the title of the paper, “Fairness Through Awareness,” meaning cross-cultural awareness.
In that same paper you also draw a distinction between treating individuals fairly and treating groups fairly. You conclude that sometimes it’s not enough just to treat individuals fairly — there’s also a need to be aware of group differences and to make sure groups of people with similar characteristics are treated fairly.
What we do in the paper is, we start with individual fairness and we discuss what the connection is between individual fairness and group fairness, and we mathematically investigate the question of when individual fairness ensures group fairness and what you can do to ensure group fairness if individual fairness doesn’t do the trick.
What’s a situation where individual fairness wouldn’t be enough to ensure group fairness?
If you have two groups that have very different characteristics. Let’s suppose for example that you are looking at college admissions and you’re thinking about using test scores as your admission criterion. If you have two groups that have very different performance on standardized tests, then you won’t get group fairness if you have one threshold for the standardized-test score.
This is related to the idea of “fair affirmative action” you put forward?
In this particular case, our approach would boil down, in some sense, to what’s done in several states, like Texas, where the top students from each high school are guaranteed admission to any state university, including the flagship in Austin. By taking the top students from each different school, even though the schools are segregated, you’re getting the top performers from each group.
Something very similar goes into our approach to fair affirmative action. There’s an expert on distributive justice at Yale, John Roemer, and one of the proposals he has made is to stratify students according to the educational level of the mother and then in each stratum sort the students according to how many hours they spend each week on homework and to take the top students from each stratum.
Why wouldn’t it work to sort the entire population of students by the amount of time they spend on their homework?
Roemer made a really interesting observation that I found very moving, and that is: If you have a student from a very low-education background, they may not even realize it’s possible to spend a large number of hours studying per week. It’s never been modeled for them, it’s never been observed, nobody does it. It may not have even occurred to the student. That really strikes a chord with me.
What is it that you find so moving about that?
I had an interesting experience in high school. I’d started playing the piano at the age of about six, and I dutifully did my half-hour of practice a day. I was fine. But one time—I guess freshman year of high school—I passed by the auditorium and I heard somebody playing a Beethoven sonata. He was a sophomore, and I realized that you didn’t have to be on the concert-giving scale to play much, much better than I was playing. I actually started practicing about four hours a day after that. But it had not occurred to me that anything like this was possible until I saw that someone who was just another student could do it. I think probably this is why Roemer’s writing struck such a chord with me. I’d had this experience in my own very enriched life.
Your father, Bernard Dwork, was a mathematician and a longtime faculty member at Princeton, so in a sense you had an example to follow—as a scholar if not as a piano player. Did his work inspire yours in any way?
I don’t remember his work directly inspiring my interest in computer science. I think growing up in an academic household as opposed to a nonacademic household gave me a model for being deeply interested in my work and thinking about it all the time. Undoubtedly I absorbed some norms of behavior so that it seemed natural to exchange ideas with people and go to meetings and listen to lectures and read, but I don’t think it was mathematics per se.
Did that lesson about practice and the piano influence your approach to your research? Or, to put it another way, did you have experiences that taught you what it would take to be successful in computer science?
When I finished my course requirements in graduate school and I started to wonder how I could do research, it turned out that a very famous computer scientist, Jack Edmonds, was visiting the computer science department. I asked him, “How did your greatest results happen? Did they just come to you?” He looked at me, and stared at me, and yelled, “By the sweat of my brow!”
Is that how your best results have come to you?
It’s the only way.
You’ve said that “metrics” for guiding how an algorithm should treat different people are some of the most important things computer scientists need to develop. Could you explain what you mean by a metric and why it’s so crucial to ensuring fairness?
I think requiring that similar people be treated similarly is essential to my notion of fairness. It’s clearly not the entire story surrounding fairness—there are obviously cases in which people with differences have to be treated differently, and in general it’s much more complex. Nonetheless, there are clearly also cases in which people who should be viewed as similar ought to be treated similarly. What a metric means is that you have a way of stating a requirement about how similarly two different people—any two different people—can be treated, which is accomplished by limiting the amount by which their treatment can differ.
You mentioned previously that you consider this work on fairness a lot harder than your work on privacy, in large part because it’s so hard to come up with these metrics. What makes this so hard?
Imagine presenting the applications of two students to a college admissions officer. These students may be quite different from one another. Yet the degree to which they’d be desirable members of the student body could be quite similar. Somehow this similarity metric has to enable you to compare apples to oranges and come up with a meaningful response.
How does this challenge compare to your earlier work on differential privacy?
I think this is a much harder problem. If there were a magical way of finding the right metric—the right way of measuring differences between people—I’d think we had gotten somewhere. But I don’t think humans can agree on who should be treated similarly to whom. I certainly have no idea how to use machine learning and other statistical methods to get a good answer to it. I don’t see how to avoid dealing with the fact that you need different notions of similarity, even for the same people, but for different things. For example, discriminating in advertising for hair products makes perfect sense in a way that discriminating in advertising for financial products is completely illegal.
When you frame it like that, it seems like a monumental task. Maybe even impossible.
I view this as a “sunshine” situation; that is, the metric that’s being used should be made public and people should have the right to argue about it and influence how it evolves. I don’t think anything will be right initially. I think we can only do our best and—this is the point that the paper makes very strongly—advocate sunshine for the metric.
Original story reprinted with permission from Quanta Magazine, an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.
No one ever won a Nobel Prize for using lemons to power a light bulb or setting their hand on fire. Maybe someone should have, because experiments like those have introduced generations of kids to the wonders of science.
Laura Skinner celebrates the wide-eyed joy of childhood science in Experimental, blurring the line between science and magic with cool experiments like making fluorescent ice and creating a tornado in a bottle.
Wanna Feel Small? Step Into an Abandoned Cooling Tower
The Internet Lives in a Huge Hotel in Manhattan
Wasteland: The Mad Max Festival That Makes Burning Man Look Lame
Skinner is the first to admit she doesn't have a background in science (neither does her father, who won a Guggenheim grant to write poetry about CERN's particle accelerator). Her interest blossomed three years ago when a friend showed her how to use dish soap, water, and lighter fluid to set her hand on fire. Other middle-school science experiments soon followed. “I have a profound interest in scientific properties as a means of understanding the world,” she says.
She draws inspiration from websites and science fairs, choosing experiments designed for kids 8 to 18. She's done 18 so far, working her basement and backyard in Louisville, Kentucky, using stuff she's bought at the supermarket and hardware store.
The experiments take just minutes to execute but hours to perfect. Mirrors, long exposures, and other tricks help convey what's happening, as does patience. Getting a shot of her matchstick rocket launching 10 feet into the air required performing the experiment more than 150 times. “My failure rate is high,” she says.
The result is a fantastic blend of art and science. Kids, go ahead and try this at home.
Alan Turing was the mastermind whose role in cracking the Nazi Enigma code helped the Allies win World War II. He built a machine to do the calculations necessary to decipher enemy messages and today is hailed as the father of the com­puter and artificial intelligence. He's also widely believed to have been autistic.
Kevin Pelphrey (@KevinPelphrey) is Carbonell Family Professor and director of the Autism and Neurodevel­opmental Disorders Institute at George Washington University in Washington, DC.
Turing was not diagnosed in his lifetime, but his mathematical genius and social inelegance fit the profile for autism spectrum disorder (ASD). And his story illustrates how society benefits when it gives a voice to those who think different. Until he came along, no one perceived the need for a com­puter; they simply needed to crack the code. It took a different kind of mind to come up with that unexpected, profoundly consequential solution.
While Turing's renown has arguably never been higher, today we are failing to recognize the potential in millions of other talented minds all around us. Like Turing, many of them are also capable of exceptional technological expertise that can help to safeguard our nation.
The Centers for Disease Control and Prevention report that more than 70 million people worldwide—1 percent of the global population—are living with autism. In the US, an upward trend in diagnosis means that the number of adults with ASD is expected to top 3 million by 2020. And today, according to expert estimates, 70 to 90 percent of them are unemployed or underemployed.
The common prejudice is that people with ASD have limited skills and are difficult to work with. To the extent that's true, it's a measure of our failure as a society. Almost half of those diagnosed with ASD are of average or above-average intellectual ability. And we have clear evidence that job-focused training and support services, especially in the transition to adulthood, can make a huge difference, leading to higher levels of employment, more independence, and better quality of life.
But few are getting such help. Programs for adolescents and adults with ASD receive less than 1 percent of all autism-related funding in the US, public and private. (Most spend­ing is on research into the causes of the syndrome and on programs for children.) That we are not preparing these individuals for the future is more than just a personal tra­gedy; it's a monumental waste of human talent.
In what kinds of jobs could we match the interests and passions of people with ASD and our country's needs? Well, it just so happens that there is a massive labor shortage in the vital field of cybersecurity. Globally, the damage from cyber attacks by criminals, terrorists, and hostile states is projected to exceed $2 trillion by 2019. Yet the number of unfilled jobs in this area is growing and will likely reach 1 million worldwide next year.
How Autistic People Helped Shape the Modern World
Neurodiversity Rewires Conventional Thinking About Brains
At the same time, more than three-quarters of cognitively able individuals with autism have aptitudes and interests that make them well suited to cybersecurity careers. These include being very analytical and detail-oriented as well as honest and respectful of rules. And there are many other areas in which these talents could quite literally be employed.
A few innovative firms, including Microsoft, SAP, and Freddie Mac, already have pilot programs for hiring people with autism to fill sophisticated IT jobs and other positions. The Gates Foundation, the Milken Institute, and the Hilibrand Foundation have also funded valuable employ­ment and research programs.
But given the coming tsunami of adults with autism, a much broader effort will be required. We need a national strategy, coordinating the efforts of public agencies, companies, and organizations, to bring these valuable minds into the work­force. Such an initiative should focus first on providing meaningful job opportunities for adults who are cognitively able and eventually branch out to more of the autism spectrum.
This effort needn't start from scratch. Let's begin by convening those working on the issue in Los Angeles, New York, San Francisco, Seattle, and Washington, DC—areas where strong research and clinical programs are up and running and where tech industry jobs are readily available. By capitalizing on this existing network, we can seed job hubs around the country for adults with autism.
These hubs would create programs to cultivate expertise in cybersecurity and would teach workplace social skills and independent living skills. They'd also work with industry partners to develop a talent pipeline and help them under­stand how best to integrate autistic employees.
Half a century ago, Turing's extraordinary abilities helped us win a war and launched the technology that is still reshaping our world. Today we're facing a new threat, and we must once again band together. This is a tremendous opportunity—to use one social challenge to solve another—and a potentially transformative moment. Let's take full advantage of it.
If your pan-seared salmon didn't quite turn out right, you may be tempted to blame it on the type of salmon you bought—maybe it was farm-raised instead of wild—but none of that should matter if you understand the chemistry of how this colorful fish cooks. For another episode of Edible Science, Dan Souza, ultra chef-nerd and co-author of the new Cook's Science by America's Test Kitchen, shows us how brining and low temperatures can help enhance the flavor and retain the moisture of salmon, no matter what kind you buy.
You might think brine is reserved for poultry or pickling, but its basic mechanisms work just as well for fish. A simple brine of salt and water should be enough to permeate the cell walls of a salmon filet, kickstarting the process of osmosis. The meat's cells have a lower concentration of salt than the brine, so water rushes out of the cells as salt flows in. The additional salt eventually tips the scales so that water comes gushing back in to dilute it, and all that sloshing increases the amount of liquid and flavor inside the meat. The salmon becomes somewhat waterlogged—but that's the way you want it. It'll soon lose that water to the heat of the pan, leaving the meat just moist enough. Added perk: Both wild and farmed salmon aren't very dense and can absorb brine faster than other meats. As Souza demos above, 15 minutes is all you need for perfectly brined filets.
The main difference in farmed vs. wild salmon is fat, which means you can get delicious cuts out of either variety if you cook them each a little differently. Farmed varieties have nearly three times as much fat as wild, according to Souza. Wild filets also have significantly more collagen—the protein that gives meat its structure and holds its fibers together. Cook a wild filet next to a farmed filet and you might notice that the wild filet has a much firmer surface, which is the collagen in action. Brining can help prevent that wild filet from getting too tough, but so can cooking it at a slightly lower temperature. Souza recommends using a meat thermometer to get the center of the cut to just 120 degrees Fahrenheit, as he does with this crunchy, silky, standout rendition of the ubiquitous sesame-crusted salmon. Hungry for the full recipe? Follow along with the video or get the book.

The new BBC series Planet Earth II, like the Planet Earth that came before it, promises to take you deep into the natural world, to places that humans without multimillion-dollar budgets could never tread. Cold places, searing places, tippy-top-of-mountains places.
As a companion to the series, the BBC is releasing incredible 360-degree videos that immerse you in the action like never before. And the latest, embedded above, drops you in the middle of a Costa Rican rainforest to meet a giant snake, a less giant but still fascinating snake, and a lizard that can walk on water. NBD. Just click and drag to look around like Sir Attenborough himself.
(This is the third of six 360-degree videos that the BBC will be publishing. Scroll below to see more.)
The Ring of Fire is a belt of tectonic plates around the Pacific Ocean. It skirts along the coasts of North and South America, New Zealand, and Japan. And all along, it is gnashing and colliding, creating earthquakes small and large.
On Tuesday, it erupted with two particularly large ones. In New Zealand, a 5.6 tremor hit the country's North Island. Three hours earlier—and more than 5,000 miles away—a 6.9 magnitude quake hit off Japan's northeast shore—Fukushima prefecture, site of the 9.1 2011 Tōhoku megaquake. The two quakes probably aren't related. But the fact that both island nations lie along such earthquake prone regions really makes you wonder why neither saw these quakes coming.
Japan touts the most advanced earthquake warning system in the world. The government spent big bucks implementing a network (California’s en route to implementing a similar one) that detects precursor waves that happen when faults begin to slip. That means the warning system gives notice after the primary waves, but before the destructive seismic shaking—secondary waves. The Japanese Meteorological Agency has about a thousand hardware sensors spread across the country's four major islands.
The early warning system doesn't operate alone, though. Seismologists also use the so-called Omori law to calculate how long aftershocks will occur after a big earthquake. It's been five years, but Japan's Tuesday temblor is likely an aftershock to the destructive 2011 Tōhoku earthquake. The sequel occurred just 80 miles southwest of Tōhoku’s epicenter—enough to give geologists second thoughts about their interrelatedness. “It’s a response to the stress continuing to readjust to that earlier quake,” says Doug Givens, a geophysicist with the US Geological Society.
So the Omori curve helps geologists calculate whether any given activity their early warning system detects is preamble to a large quake, or just some benign seismic stress relief leftover as an aftershock. But even with the calculations and a state-of-the-art warning system, there was no way the JMA could have had longer term predictions for Tuesday's quake. At best, their alerts give people a minute to duck and cover before the ground wreaks havoc.
“Seismiologists just don’t have enough information about the processes that are going on in Earth,” says Peggy Hellweg, Operations Manager at UC Berkeley’s Seismology Lab. “We know the stress is building up, but we don’t know the details of each particular location, and when the stress is going to be too much for it. That’s the problem with earthquake prediction.”
And these systems can fail. “It sort of works, but pretty kludgily, and there are lots of false alarms,” says Robert Geller, a geoscience professor at the University of Tokyo. For starters, the sensors can simply miss the primary waves, and therefore issue no alert. Second, there’s always the possibility the alert might come too late. And, lastly, seismologists can miscalculate the level of shaking that’s likely to occur. Last year, a 2.8-magnitude offshore quake sent JMA’s networks into a frenzy. This was because an electrical fault in one of the sensors created a false spike, forecasting a small earthquake into a large one. “Early warning shouldn't be oversold as a panacea,” says Geller.
Longer term forecasting is probably impossible. “The physics of earthquakes is extremely complex, and it’s hidden from us,” Givens says. That said, geologists can sometimes use statistics to predict the recurrence rate along any given fault, but these are just odds—for example, Northern California's Hayward fault has a 23 to 28 percent chance of having a magnitude 6.5 quake or larger in the next 30 years. Odds are nice, but don't give seismologists nearly enough information to start marking their calendars up with dates for future quakes.
Oh, and just in case you were still wondering whether Japan and New Zealand's quakes were related, the answer is no. Western Japan skirts along the same plate that moved northern New Zealand, but there are still four other sheets converging in the area. So geologists have a pretty hard time knowing when an earthquake is going to be a foreshock or an aftershock to a bigger shake—precursors can only be identified in retrospect. Either way, megaquakes are some seriously dangerous geology, and they’re ready to rumble.
Today, a tiny office in the sprawling edifice of the National Institutes of Health released a strategic plan. The 58-page document, complete with bullet points and clip art, spells out a direction for behavioral and social science research—including psychology, economics, and sociology—for the next four years. And while it doesn’t directly shunt funding around, the plan is a bat signal for social scientists across the nation: It shows what the NIH is interested in and (likely) where grants will follow. And that could ultimately shape the direction of behavioral and social science itself.
The plan comes from the Office of Behavioral and Social Science Research, an arm of the NIH that directs social science efforts within each of the agency’s 27 institutes. The last time the office released a report was a decade ago. But “there’s been a fundamental shift in social science research,” says the office's director Bill Riley—in large part because of the advent of smartphones and sensors and the rich, deep data they’ve yielded about people. The new plan aims to take those changes into account.
Mostly, the goals are about making social science more useful: coming up with public health interventions informed by research, reducing the gap between finding an effective treatment for say, anxiety, and actually treating people that way. But it also includes a nod to the problems raised by proponents of replication in the past two years—you know, the researchers who suggest that the foundations of psychology and other sciences aren’t as firm as everyone thought. As a blueprint for the future of social science, the plan is a revealing look at how the NIH thinks about those issues.
For one, the plan calls for scientists to nail down and agree on terminology for different concepts so researchers aren’t just talking past each other. “Often, in behavioral science, people talk about different phenomena but really mean the same thing,” says Riley. Or the opposite happens: Chemists don’t squabble about what oxygen is, but if psychologists convene a conference on a fuzzier concept like “trust,” says Colin Camerer, an economist at Caltech, they'll spend the first two days disagreeing about what the word actually means.
That ambiguity gets tricky when researchers are trying to share and compare datasets, especially the massive ones scientists work with nowadays. (If you’re trying to compare variables in two datasets both named "resilience,” how do you know they’re really the same thing?) To fix these problems, the plan suggests, scientists should settle on rigorously defined terms. “We need to figure out what we mean when we say ‘depression,’ and how to define it—either by using the same measures, or by calibrating with the same framework,” Riley says.
Social scientists like Camerer are impressed that the NIH recognizes the potential of new sources of data, from Twitter to text messaging to more detailed brain scans. “It’s absolutely fantastic,” Camerer says. “The NIH is trying to lead, not follow.” And he says some of the NIH’s priorities in the plan, like defining terms, would do wonders for reproducibility. Focusing on bigger datasets would also help make research more robust, says Jonathan Schooler, a psychologist at UC Santa Barbara, since performing experiments on too-small groups of people can often lead to unrepeatable studies.
But Camerer isn’t as enthused about having every researcher use a single metric to measure something, even if it would make comparing work easier. “It’s a classic problem of standardization,” he says. “The danger is that you get stuck with one measure to use that isn’t that great," and then everyone ends up with mediocre data. Instead, having a list of three acceptable measures is better than just requiring one.
Other researchers are concerned that the plan doesn’t call out reproducibility issues front and center—instead, it folds those issues into a discussion about better managing data. “It’s disappointing, because replication is all I hear anyone talk about these days,” says Hal Pashler, a cognitive scientist at UC San Diego. He and Schooler think the NIH should more aggressively fund research into meta-science and encourage scientists to perform replications, or foster big multi-lab collaborations. And the plan makes no mention of issues like publication bias or preregistration—other key parts of the research process that impact a study's reproducibility.
But even if the NIH's plan comes up short, supporters of replication aren't too worried. Yes, the NIH could do more to incentivize redoing studies by offering up more funding for it. But thanks to reproducibility efforts in the past two years, other grant-making organizations are now much more eager to fund that work. And there's nothing like funding to shape the direction of scientific research.
Last month, in advance of its annual Stress in America report, the American Psychological Association released what will likely be counted among the most obvious research findings of 2016. The presidential election, concluded the APA, was a source of significant anxiety for the country. Regardless of party, over half of American adults surveyed felt very or somewhat stressed by the election. Gasps could be heard from across nowhere.
Because the eventual winner finished his campaign with the highest unfavorability ratings in modern history, chances are good that stress levels for a lot of Americans won’t be plummeting any time soon. The election, distinguished by a sharp rural-urban split, divided many families as effectively as it divided the country as a whole. Thanksgiving reunions promise to be the source of some tension and anxiety this year, which provides an excellent reason to discuss stress—and what it actually does to the human body.
Connor Narciso is a freelance writer and former combat medic with 3rd Special Forces Group.
The term “stress,” as it’s commonly used today, wasn’t actually coined until 1946, when Austrian-borne physician Hans Selye attempted to describe a pattern of maladaptive responses he had observed in lab rats. It seemed that in the course of various experiments, the rats tended to exhibit the same range of physical symptoms, regardless of which hormones or foreign tissues they had been injected with. The rodents, Selye believed, were reacting to the trauma of the experiments themselves.
Our understanding of stress, and of its physiological effects, has come a long way in the years since. We now know that when the brain perceives a threat, the hypothalamus sends signals to the pituitary and adrenal glands, activating the production of cortisol and epinephrine, known together as the “stress hormones.” The process is involuntary, governed by the autonomic nervous system, and highly individualized.
Stress exists to help us. The spikes in heart rate and blood pressure caused by stress hormones are still crucial to the “fight or flight” response, and for our early ancestors on the plains of Africa, a forceful response to stress could have meant the difference between life and death. But today we experience stress in disproportion to a variety of non-threatening stimuli—and as a result, stress hormones can accumulate and provoke superfluous reactions across the body. Hans Selye blamed numerous medical conditions on “errors in our adaptive response to stress."
Nausea and vomiting are two acute examples. It might seem counterintuitive, but the digestive tract—regulated by what is known as the enteric nervous system—contains more nerve cells than the entire spinal cord, and is often referred to as the “second brain.” In times of panic, stress hormones will push blood away from the gastrointestinal and genitourinary systems, sometimes causing an uproar from, among other things, the vast society of foreign microbes living in our gut. “It’s no time to feed or breed,” says Andy Morgan, a PTSD expert at the University of New Haven. The urge to throw up or pee your pants, he says, “is related to these systems evacuating while energy and resources are redirected to muscle groups and your brain under high sympathetic drive.”
Of greater concern is chronic stress, which research has linked to asthma attacks, heart disease, and other life-threatening illnesses. In the liver, for instance, cortisol and epinephrine stimulate the release of glucose, a source of instant energy for the brain and muscles. In diabetics though, the rise in blood sugar is unnecessary and unsafe.
So can stress be managed, or contained? Morgan, who spent 24 years as a forensic psychiatrist at Yale University, tried to answer that question by studying stress response and performance in Special Operations Forces. He found measurable differences in body chemistry between these elite soldiers and average recruits: Special Forces soldiers were able to stay calm during harsh training scenarios by releasing higher levels of natural stress suppressants. He credits their composure in part to stress inoculation, obtained through rigorous training pipelines—but the most resilient soldiers were already above average when they signed up.
Even if they aren't preternaturally anxiety-averse, soldiers can still be a good source for lessons on stress. War reporter Sebastian Junger has written extensively on the long term effects of stress on soldiers, and he points out that the percentage of veterans suffering from symptoms of PTSD exceeds the percentage of soldiers who actually see combat. Junger suspects the problem may be rooted in lost feelings of purpose and camaraderie, exacerbated by a cumbersome transition back to the coldly selfish and isolating reality of modern culture.
Not surprisingly, solutions are mainly tailored to the individual: one-on-one therapy, medication, exercise, even controlled breathing. Although there’s plenty of evidence to support the use of each technique, it may all leave you wondering why, with all of our advantages as an affluent nation, rates of mental illness and depression are still higher here than they are in lower income countries.
Modern society, Junger points out in his book Tribal, is afflicted with some of the highest rates of mental illness in human history, including anxiety. If Junger is correct, and our decline in mental health is attributable to society’s diminished capacity for shared sacrifice and collective living, then perhaps an assembly of friends and relatives is perfectly in order. Perhaps we should see Thanksgiving not as a cause of our stress, but as a solution.
Last week, a Royal New Zealand Air Force flight spotted a new pumice raft in the middle of the Pacific ocean to the west of Tonga. Pumice rafts are floating islands of pumice created during a submarine volcanic eruption and they can persist for months or longer. This raft was seen by aircraft and satellite in an area with no known volcanoes. However, from the looks of the raft, it might be a long way from home. The pumice is strung out in long streamers, suggesting it has been smeared and distorted by ocean currents and weather as the pumice floats along the ocean surface.
UPDATE: A number of people have asked a good question: how big is this raft? Based on the satellite images, it could be tens of kilometers long, but very narrow (hundreds to tens of meters?). It is a little tricky to get a confident size because of the resolution of the images.
This is, by no means, the first time an orphaned pumice raft has been spotted. Back in 2012, a pumice raft was seen by a research vessel in an area near the Kermadec Islands. With a little sleuthing using satellite images, Rob Simmon (Planet Labs) and I were able to trace the source of the eruption to a seamount called Havre (see below) that had no other known historical eruption.
Now, with the Havre eruption, we may have gotten lucky, with a pumice raft that could be backtracked through the satellite image archive to a volcanic plume that broke the surface above Havre. The ultimate source of this current pumice raft appears to be a little more elusive. The GeoNet folks in New Zealand have tried to use the same technique to find where this pile of pumice originated, but so far have come up empty.
The pumice raft (tan) and eruption plume (white in bottom center-right) from the 2012 eruption of Havre in Tonga/Kermadec arc. This is an example of a pumice raft that was eventually traced to its source.
I took a stab at it as well. The area where the pumice raft was spotted is bounded by volcanic arcs: Vanuatu to the north, Tonga to the east, Kermadec arc to the southeast. Ocean currents in the area would likely have pushed the pumice from the east to the west, so the source should be in the Tonga arc. I checked some potential suspects in the Tonga and Kermadec volcanoes—Havre, Home Reef, Monowai—but couldn't find any evidence for eruptive activity going back all the way to early October.
Mind you, this is based on when it was clear enough to see the ocean surface and for a decent slice of that month-and-a-half, cloud cover obscured the target volcanoes. So, they could have been the source and we might never see the surface manifestation of the eruption. Or, the pumice might have been from a hitherto unknown (or underappreciated) submarine volcano in the Tonga arc, which makes finding the source especially challenging with so much ocean to cover.
Ultimately, these pumice rafts disperse and wash up on distant shores, sometimes helping organisms colonize new territory. As a volcanologist, what do you do that this point? Well, you hope that someone can go scoop up some samples of the pumice spotted last week so you can analyze its composition. Then, that composition can be compared to known samples from some of these Tongan, Kermadec (and many Vanuatan?) volcanoes to possibly hope we can match the new pumice to a volcano. If that doesn't work, we might just have another rogue volcanic eruption with no known source, an event that isn't uncommon in the geologic record.
Sequels rarely live up to the original. And thank goodness for that. Yesterday, a 6.9 earthquake shook the coast of Japan almost exactly where a 9.1 quake hit nearly 6 years ago. Japan is fortified against quakes and tsunamis. But the 2011 quake was so powerful it generated 30 to 60-foot tsunamis, overtopping the island nation’s extensive sea walls and shore protections, killing over 15,000, leaving 228,000 homeless, and causing a meltdown at the Fukushima Daiichi nuclear plant.
Yesterday’s temblor was comparatively tame. Tsunamis rolled in at 4.6 feet. Nobody died. Only 15 people reported injuries—broken bones, at worst. And although the cooling system for spent fuel rods momentarily stopped at a nearby nuclear reactor (Fukushima Daini, not Daiichi), there was no meltdown.
Partly, that’s because this quake was so much weaker. Going straight numerically, 6.9 doesn’t seem like much less than 9.1. But earthquakes are measured logarithmically. “In terms of magnitude, a 6.9 is basically 1,000 times smaller than a 9.0,” says Paul Huang, a seismologist at NOAA’s Tsunami Warning Center in Palmer, AK. And only 1 to 2 percent of a quake’s energy gets transferred into the ocean, so that thousandfold difference becomes fractional at tsunami scales. Yesterday’s quake moved side to side—a so-called lateral slip—and so displaced less water than a vertical thrust quake like in 2011.
小名浜松の中地区の状況。サイレンの音しか聞こえない。近くの沿岸部の工場（日本化成）の夜勤担当の方が続々と逃げてきている。 pic.twitter.com/jM2sSFXa0i
— 小松 理虔 (@riken_komatsu) November 21, 2016

Yesterday’s quake wasn’t just further from the fault, it was closer to shore. Some bit of its energy actually went directly into shaking stuff on land, instead of getting transferred to the water.
This quake was also shallower than its predecessor, which, all things being equal, would mean more energy propagated into the water, not absorbed by earthen crust. “If deep, it has not as much energy, so less gets transferred to water and you get smaller waves,” says Huang. But all things are not equal. Remember, thousandfold difference in energy?
Just because the energy was less, and the tsunamis smaller, does not mean the Japanese government’s evacuation orders were for naught. “Remember, a tsunami is the whole ocean, from top to bottom, moving,” says Huang. Even a few feet of swell powered by the whole ocean is enough to sweep a body out to sea. And local residents are wise to stay wary for more. This weaker sequel has already generated many aftershocks, at least three of which were 5 magnitude or higher.
Wildlife poachers who stalk endangered animals in East and South Africa have long operated under the cover of night. But lately not even a moonless sky is safe cover for stalking impalas, elephants, and rhinos. Now, the power of increasingly inexpensive infrared cameras, artificial intelligence, and drones are being used to stop illegal poaching. Rangers are rounding up veteran poachers in the middle of the night, says Colby Loucks, World Wildlife Fund's senior director of wildlife crime technology, who ask, dumbfounded, "How are you finding me?'"
This spring, the World Wildlife Fund began deploying thermal sensing infrared technology from the imaging company FLIR to combat poaching in Kenya's Maasai Mara Conservancy park—and at another secret location that's home to rhinos, one of the most imperiled creatures on Earth. The technology, which detects a narrow sliver of the electro-magnetic spectrum of reflected or emitted heat, could become a critical tool in the fight to protect endangered species. Anything living appears as a white or grey blob on a screen or in a viewfinder, no light needed.
"We call it a superpower," says Travis Merrill, senior vice president of FLIR. The thermal imaging technology has existed for decades, but it was bulky and expensive—until it fell prey to Moore's law. Now, infrared sensors come as standard equipment on some smartphones. And in the field, FLIR can supply WWF with stationary cameras strategically deployed in poaching hotspots, powerful mobile units that are mounted to off-road vehicles, and even handheld rangefinders. The technology can detect a person through fog, haze, and smoke, and some cameras have a range of a full mile.
Installing solar panels for FLIR camera system in a National Park in central Kenya. As part of WWF's Wildlife Crime Technology project.
An elephant in the Maasai Mara, Kenya.
Dr. Asuka Takita, Veterinarian/Canine Unit Supervisor and ranger colleagues at the Mara Conservancy at Maasai Mara National Reserve. As part of WWF's Wildlife Crime Technology project.
Ranger anti-poaching unit testing the newly installed mobile FLIR camera system at the Mara Conservancy at Maasai Mara National Reserve Kenya.  As part of WWF's Wildlife Crime Technology project.
A herd of elephants (Loxodonta africana) in the Maasai Mara, Kenya.

Ranger anti-poaching unit testing the new mobile FLIR camera unit at the Mara Conservancy at Maasai Mara National Reserve Kenya.  As part of WWF's Wildlife Crime Technology project.


At Kenya's Maasai Mara Conservancy, the sensors are part of a high-stakes game of hide and seek. Rangers set up on a hill in their SUVs, blocking out their windows so no light from their monitors escapes. Watching the readouts from the thermal imagers, the SUV outposts radio the location of poachers to foot patrol units who can stealthily spring on their prey. Stationary thermal cameras distribute operations even more, with feeds that route back to headquarters where a trained AI algorithm alerts rangers to signs of human movement.
Without their lookouts, those rangers would have to secure hundreds of square miles of wildlife territory unaided. The thermal imaging cameras become a "force multiplier," says Loucks: Stationary thermal cameras mounted in a rhino habitat helped catch two poachers jumping a fence within the first weeks of use. And the technology may be as powerful as a deterrent as it is at finding criminals: That area hasn't seen a poacher in months.
The program is being tested out in Kenya, but initial results are positive, says Loucks. Since the program started in March, rangers have nabbed 26 poachers, and now the WWF and FLIR are trying out drones equipped with thermal imaging technology in Malawi and Zimbabwe. The poachers won't know what hit 'em.
November started out pretty normal for the Arctic. The sun had set for the season, temperatures were dropping, ice was growing rapidly. Winter was coming, right on schedule. And then, a few days ago, everything came screeching to a halt. Ice stopped forming. And then it actually started to melt, thanks to a sudden heat wave that blistered the region with temperatures 20 to 30 degrees Fahrenheit above average. For now, the mass of warm air doesn’t appear to be going anywhere.
That’s bad news for sea ice. Coverage in the Arctic was already at its lowest levels since researchers began using satellite data to measure it back in 1978. And as of November 19, Arctic sea ice was nearly 350,000 square miles below its extent in 2012, the last record-low year. The extreme weather has scientists scrambling to figure out what’s causing the historical temperatures, and more importantly, what their long-term impacts could be.
“It’s absurdly warm over the Arctic Ocean right now and the question is, where the heck is all that heat in the ocean coming from?,” says Mark Serreze, director of the National Snow and Ice Data Center in Boulder, CO. “No one has a real handle on that yet.”
There are a few likely explanations. At this time of year, without the sun’s rays, the ocean begins to lose its heat in the form of infrared radiation. On its way to outer space, the radiation has to pass through the atmosphere, and water vapor and carbon dioxide and other greenhouse gases trap and absorb some of that radiation, heating up in the process.
That’s all pretty normal. But this year, atmospheric circulation patterns are bringing more warmth to the Arctic than usual. Last month, an unusually high pressure system centered over Scandinavia brought in a flow of warm southerly air between Greenland and Norway. At the same time, in the Pacific, an abnormally low pressure system formed just east of Russia, along the Kamchatka Peninsula. That drew in warm heat from the mainland up toward Alaska and the Bering Sea. With their powers combined, they blasted the Arctic with a heavy, sweaty dose of hot air.
This wouldn’t be such a big deal on its own, but warmer and more humid air increases the greenhouse effect. It becomes more and more difficult for the ocean to transmit heat away from its surface, and more and more difficult for ice to form. Which is one explanation for why Arctic sea ice cover continues to run at record low levels this late into the year.
This is a mind-blowing figure. pic.twitter.com/znGjbd1iDu
— Andrew Thaler (@DrAndrewThaler) November 21, 2016

The effects are being felt far below the 66th parallel. States in the Upper Midwest experienced their warmest falls ever, with temperatures running about 15 degrees warmer than average through the second week of November. Minnesota experienced the longest growing season ever recorded: 220 days. And the Twin Cities set a record for the latest frost in history.
On his weather nerd cult blog the Updraft, Minnesota Public Radio chief meteorologist Paul Huttner said that the Arctic “was broken.” Normally, northwest winds blow down from the Arctic over snow-covered ground and iced-over lakes before reaching the US. But this year bare ground all the way up the Arctic circle allowed the sun to warm the upstream air mass more efficiently (no snow means no albedo effect). “The Arctic is North America’s refrigerator,” Huttner says. “If it stops getting as cold as it should, the effects are felt far and wide. I always say that the Arctic is no Las Vegas. Whatever happens in the Arctic, doesn’t stay in the Arctic.”
Which is why climate scientists are gathering data points to try to understand what this anomaly means for the future. It’s too soon to tell if the extreme temperatures are part of a pattern or just an outlier, Serreze says. But if there’s one thing history teaches us, it’s that the Arctic is not as resilient as it once was. Thick layers of old sea ice are the Arctic’s buffer against rare weather events—and that kind of ice has been rapidly disappearing. In the 1980s, multiyear ice made up 20 percent of sea ice cover; today, it’s only 3 percent. As those numbers decline, the Arctic becomes more vulnerable to wide temperature fluctuations.
“Had that same pattern set up in 1980, the sea ice could have taken the punch,” say Serreze. “Now it can’t. And what we’ve learned is that the response of the ice to these extreme events is changing, and with it so are the odds. It loads the dice.”
Dear Arctic, may the odds be ever in your favor.
I want to analyze a scene from Star Trek Beyond but don’t want to spoil the movie. Let me set things up in the most generic way possible. If you are very allergic to spoilers, maybe you should just move along to this nice post about radioactive bananas.
You have been warned.
Here is the scene: Some people have found an old starship at the top of a cliff. They want to get it flying and leave the planet. An engineer-types says, “We have to achieve terminal velocity in order for the stabilizers to provide lift. Are you sure this drop is high enough to do that?”
Of course they get the starship over the edge. What happens next? You’ll have to see the movie to find out.
Suppose I take a wad of paper and drop it from a height of 4 meters. What happens as it falls? At first, there is only one force acting on the object—gravitational force. I can represent this with the following diagram:

This gravitational force makes the paper speed up as it falls. However, once it is moving down, another force acts on the paper—air resistance. This air resistance force increases with the speed of the object such that at some point it might look like this:

Now with two forces on the paper, the net force is still down and the paper still accelerates—but with a lower value. Oh, let me point out that I just put down a value for the downward speed. But since this paper is still accelerating it will increase in speed until it gets to something like this:

At this point, the air resistance force is equal in magnitude to the weight such that the net force is zero. Without a net force, the object’s velocity will be constant. We call this constant velocity the terminal velocity since it is no longer increasing. But why did I use balled-up paper as an example? Because the weightis small enough that a small air resistance force becomes significant. If used a similarly sized rock, the air resistance could be about the same magnitude but the gravitational force would be much larger. This rock would still reach a terminal velocity, but it would take much longer.
But what does terminal velocity have to do with the stabilizers on a starship? I have no idea—it’s not real anyway.
The real question is, did the starship have enough room to reach terminal velocity? It’s a great question, but not a simple question. Find out how high I need to drop something to reach a particular speed is pretty easy—as long as I ignore the air resistance force. With the air resistance, the object will have a non-constant acceleration. This makes it a more complex calculation. The best way to find this distance to terminal velocity would be with a numerical calculation—you know, with python.
If you are waiting for me to do this calculation, keep waiting. I’m not going to do it. You can use it as a homework problem. I want to move on to something else. Besides—I don’t know the drag coefficient or the mass of this starship, but I might be able to approximate the size. Still, all of this can be your homework assignment.
There is a shot of the starship as it falls off  the cliff. I will use this to estimate the terminal velocity of the starship. I only need one thing to get started—the size of the starship. Since I don’t know the height of the cliff, I will have to use some other object to set the scale of the video. The only option is the starship.
But how big is the starship? (Notice how I avoid naming the starship just in case it’s a spoiler?) Really, my only evidence (that I could find) is this diagram from Popular Mechanics showing the Enterprise and this other starship. According to this post, the Enterprise has a length of 725.35 meters. Using this info, the falling starship should have a length of about 119 meters.
With this, I can just use video analysis to get the position of the starship during this motion. Here’s the data:

Well, that’s odd. That doesn’t even look like an accelerating starship. Instead that looks like it’s pretty much moving at a constant speed—so I guess it just starts off at terminal velocity with a value of 332 m/s (from the slope of the plot). OK, technically there might be a slight curve to that data but I assumed a constant velocity.
I guess I have to do it. I have to make a model that shows what a falling starship would look like if it started from rest and had an air resistance force. Here are my assumptions.
With that, I can make the following numerical calculation. This shows three falling ships. The one on the right moves at a constant velocity like the video. In the middle, the ship has a air resistance force and the one on the left is just free falling with a constant acceleration. Just click the “play” button to run the code and the “pencil” to view and edit the code.

You can see that at the bottom of the fall, the starship with air resistance only reaches a final speed of 128 m/s.
Yes, there are lots of great homework questions.
Drunk shoppers beware: Impulse buying online just got even easier. With Apple's new MacBook Pro launched last month, all you have to do is tap your finger to the Touch ID scanner located on the Touch Bar to buy—no more searching through your wallet for the right card, no more typing in three-digit security codes and expiration dates.
On the front end, the new method is faster and probably more secure than using stored credit card info online. On the back end, it gives merchants and banks a new framework to process your purchases. And if past research is any indication, Apple Pay, Samsung Pay, Venmo, and countless other reduced-friction digital payment technologies are probably going to change the way your brain processes purchases, too.
"You might assume from a rational point of view, there should be no difference in spending behavior based on how you're paying for the item, using Touch ID versus a credit card," says Sachin Banker, a consumer researcher at the University of Utah. But behavioral economists like him, who mix psychology and neuroscience methods with economics, know that the way you pay can make a big difference in what you buy and how much you're willing to spend. And while there isn't much data on digital transactions—less than a third of smartphone users in the US even make a phone-based payment each year—the way we use other payment systems can tell us a little about the future of digital spending behaviors.
Cash, for example, induces a psychological pain of payment, while credit cards are associated with rewards that go beyond airline miles and 2 percent cash back on groceries. Drazen Prelec, a neuroeconomist at the Massachusetts Institute of Technology's Sloan School of Management, first came up with the idea of the pain of paying in 1998. "There's something schizophrenic about credit cards," Prelec says. "On the one hand, people seem to feel better if they buy something with a credit card, but they feel much worse when they have to pay the bill. Credit cards really disconnect your mental accounting systems." Debit cards, however, can reconnect the act of buying something with paying for it. "And that's what people like," he says.
Apple Pay can be hooked up to either a credit or a debit card, so consumers' spending behaviors could be influenced by what method they use. But the impact of a digital payment technology goes beyond the account it's linked to. Tom Noyes, a former Citibank and Wells Fargo executive and digital payments wonk, says that the implications of Touch ID are potentially radical: It's not just a new way to pay, it's changing what a transaction is. "Instead of presenting a payment, you’re presenting your identity," he says.
Whether it’s pressing a finger or tapping a smartphone, digital payment will bring a tangible dimension to the experience, too, and maybe even an emotional one. How it feels to use a device—one that feels far more individualized than a plastic card, that is linked to daily routines and your physical fingerprint—may influence how people feel about the payment technology on the device. MIT recently launched a program that turned Prelec's campus ID into a free Boston public transit pass. "It's changed my behavior, I use [public transportation] much more," he says. "I think it's not just the cost savings, it feels good to use the ID."
Clearly, the banks in league with Apple think consumers will like paying with their devices so much that they'll do more of it. If customers set their bank-issued credit cards as their Apple Pay default, using them more frequently and incurring more debt, so much the better for the banks.
These new transaction technologies are clever and convenient, but they could thumb the scales in favor of the banks. Prelec's suggestion? Link them to a debit card. "In the end, [payment methods] are evaluated by how well they serve the user's long-run financial objectives and how they make you better—or worse—off in a much broader sense," he says. The drunk shopping? Well, that's on you.
It’s a good thing the coati doesn’t have much of an internal life, because if it did, it would probably be having a major identity crisis. This guy has the long, muscular snout of a pig, the tail of a burgling raccoon, and the tree-climbing dexterity of a monkey. Oh! And bonus animal: It can also bend its snout up to 60 degrees in any direction as it roots through the dirt for grubs, so it’s pretty elephantine, too. No matter what it looks like to you, I think we can all agree on one thing: The coati is universally cute.
Find every episode of Absurd Creatures here. And I’m happy to hear from you with suggestions on what to cover next. If it’s weird and we can find footage of it, it’s fair game. You can get me at matthew_simon@wired.com or on Twitter at @mrMattSimon.

Updates from South America:
Perú
Sabancaya has been restless for the last two years, with periods of heightened activity and a return to quiet. However, it looks like the Peruvian volcano has entered a new phase of activity since early November. The volcano has produced dozens of explosive eruptions since November 6, when the renewed activity began. This first explosion generated an M3.6 earthquake as well. Ash has reached 1.5-3.5 kilometers (4,900-11,400 feet) over the volcano and spread ash over 40 kilometers (25 miles) from the volcano on the people living across the area. The ash plumes (see below) have been some of the highest ever recorded at Sabancaya and video from the explosions show a vigorous plume of dark grey ash from the volcano.
Erupción del Volcán #Sabancaya esta mañana en Arequipa Perú, columna de cenizas 3.8km
Alerta Amarilla #Ingemet
Vía @carlos_linarez pic.twitter.com/kPrS0DmPwY
— Geól. Sergio Almazán (@chematierra) November 19, 2016

Interestingly, the number of earthquakes is down some from late September and early October, possibly betraying the time for the magma to rise from depth into the volcano to cause these explosions. Deformation of the volcano continues, which supports the idea that magma is still rising into the edifice and sulfur dioxide emissions remain high (almost 3,000 tonnes/day), so all signs still point to continued likelihood of explosive eruptions. This continued threat means that a state of emergency has been declared across 23 districts around Sabancaya due to this ash hazard for the next 60 days. This area is a tourist destination, so any prolonged unrest at Sabancaya could impact that industry. The volcano remains on Yellow alert status. You can see the changing activity at Sabancaya on the webcam pointed at the crater.
Sabancaya isn’t the only restless volcano in Peru right now, either. Ticsani has been experiencing earthquakes over the past few months that all suggest magma is moving into the volcano. The number of earthquakes has dropped some at Ticsani since earlier in the year, but harmonic tremor, a sure sign of magma movement, has increased over the past few weeks. However, deformation and degassing is low, so an eruption isn’t likely happening in the immediate future. The only known eruption of Ticsani was in ~1800 A.D.
Ubinás has also had an eventful 2016, with numerous explosions from Peru’s most active volcano. Over the past few months, the volcano has had a couple bouts of seismicity that quieted during much of October. However, since the start of November, there have been numerous earthquakes, tremor and some explosions that sent ash ~1.5 km (4,900 feet) over the volcano. Those explosions coincided with a spike in sulfur dioxide emissions, all supporting the conclusions that new magma is rising into the volcano. You can check out the IGP webcam or INGEMMET webcam to see what’s going on at the restless Andean volcano.
Chile
Further south, an explosive eruption on November 17 occurred at Nevados de Chillán that sent ash 1.2 kilometers (3,900 feet) over the volcano. This is one of a number of “ash puffs” that the volcano has produced over the last year, most of which were noticed thanks to the webcam pointed at the volcano. Nevados de Chillán remains at Yellow alert status.
Meanwhile, M3.6 earthquake shook Hudson in southern Chile. The SERNAGEOMIN thinks the earthquake was related to fluid movement within the volcano, although it could be from hydrothermal activity rather than magma. The last eruption from Hudson was in 2011 and the 1991 eruption was a VEI 5, one of the largest of the 20th century.
I worked for a number of years, like many people, in an office building with windows that did not open. For the first time in my life, a slight soreness tingled in my throat almost every day. Each time a denizen of that floor got a cold, it decimated at least a third of the floor’s employees. For the next week or two, a swath of cubicles would sit empty. I took to avoiding pressing the water cooler button with a bare hand.
For the sake of energy efficiency, more and more buildings are sealed off completely to the outside world, relying on mechanical ventilation for airflow. But little science has been done to explain how our architectural choices are changing the world of microbes that live inside these buildings—and human health. If I wanted to test whether it was really my office getting me sick (or figure out strategies to avoid it), I wouldn't have much to go on.
But that’s about to change: The National Academies of Sciences has spent the better part of the year gathering scientists, architects, and engineers to understand the indoor microbiome, which will culminate in a review paper released at the beginning of next year. The National Academies hopes the paper will serve as a guidepost for future research, by nailing down which unanswered questions about the indoor microbiome are most critical to society.
The stakes are high: Americans spend almost 90 percent of their time indoors, so almost all of our microbial exposure occurs inside buildings. That entire time, we’re being enveloped by millions of organisms we can’t see. That’s because a building, like a human gut or vagina, has a microbiome too—a community of microbes that live and thrive in it. Only about 20 percent of the microbes in any given occupied building come from the humans inside, according to Yale University professor and chemical engineer Jordan Peccia, who studies how microbes move inside rooms and through vents (he will help to write the National Academies study). “When you come into your home, or your office, you’re completely and continually bathed in those microbes,” Peccia says.
We don’t yet know exactly how our architecture and design choices are influencing them—we just know they absolutely are influencing them. We’re already unintentionally choosing to live with certain organisms and to keep others out just by deciding how a building will be heated and cooled, or how it will be occupied. “Those decisions affect the microbial ecology of a building,” he says. “Now we’re trying to build a framework so we can start to model buildings and say: This design will lead to this type of microbial ecology.”
Already a question that has drummed up a lot of attention from the group is the issue of building “tightness,” or how the sealed windows in my office might have been affecting my health.
Scientists already know that children who are more exposed to microbes from the outside world—especially from animals—have lower rates of immune problems and of diseases like asthma. Bavarian farm children who grew up in close contact with animals, for example, had drastically lower rates of asthma and allergies. And in Northern Canada, Inuit children's asthma-related health problems plummeted after ventilation systems were installed in their homes, where windows had always been sealed to retain heat.
Farmers Are Manipulating Microbiomes to Help Crops Grow
The Microbiome Is Gross, But It’s Here to Stay
Microbiome Startup uBiome Will Sequence Poop for the CDC
Peccia’s own studies have tried to answer the question of what kinds of outdoor microbes appear to be good for kids. He tracked children from the time they are in utero to see whether certain microbes in their house might contribute to a diagnosis of asthma in early childhood. But instead, he says, “we found no microorganism that seemed to cause asthma, or to protect them from asthma. But what had a strong protection was diversity. If they were exposed to a diverse array of fungi and microbes, they were less likely to get asthma.”
So what happens when buildings in our modern, hyperclean society get tightened even further?
Back in the 1970s, right after the first energy crisis, architects began sealing up buildings for the sake of energy efficiency—adding insulation, thickening walls, making windows less permeable. Around the same time, doctors began seeing patients with a mysterious constellation of symptoms—cough, chest pain, shortness of breath—that went away almost as soon as they left the buildings they worked in. Now, architects are well acquainted with that illness, which they call sick building syndrome. It’s become a cautionary tale of how not to design a building: With insufficient ventilation, any toxic or irritating fumes from 1970s formaldehyde-laden building materials would offgas and stay put, for inhabitants to breathe in.
Since then, new regulations have limited the noxious fumes in paint and flooring, but architecture is entering a new era of building “tightness” as cities try to take on climate change, says Robin Guenther, a principal architect at Perkins + Will who designs hospitals, and who is also involved in the National Academies study. “Our desire to save energy, and our desire to live sustainably, is in some instances driving us to more tightly sealed, mechanically ventilated buildings,” she says.
Not only are buildings become more sealed off, but Guenther is worried about a trend she is seeing in hospital design: Companies are beginning to advertise antimicrobial paints and flooring. In the world of hospitals, that might be a very enticing add-on: The potential for catching an infection is highest inside a hospital, and those infections are much more likely to be fatal.
At the same moment as the FDA recently banned antimicrobials like triclosan from hand soap, Guenther is seeing it sold as an additive in building supplies without any proof that they actually reduce infectious diseases. “Building products don’t have any disclosure requirements, or any oversight. Unsubstantiated product claims are rampant and becoming more rampant in the building industry,” Guenther says. Already, researchers behind a study of buildings where antimicrobials like triclosan are being used found antibiotic-resistant genes living in the microbes in the buildings’ dust. “Since antibacterials have been linked to more resistant bacteria, why would we put that in our hospitals?”
Americans today are living in a massive real-time microbial experiment. Two generations ago, people lived in much “looser” buildings, where indoor and outdoor air was continually exchanged. Plus, building materials used to be much more natural—now they’re predominantly synthetic, which means the dust we breathe is man-made. Beneficial indoor bacteria might eat those synthetic compounds, or they might not—and if they do, are they being altered by toxic effects? “Is the flame retardant in building materials having the same endocrine disrupting effects on them as they do on us? How are they adapting to this?”
Guenther hopes the National Academies study will start to prod at some of these questions, but for now, she says, “It’s a good a sci fi plot, isn’t it?” It’ll be a long time before I know if the sealed windows in my old office were to blame for the floor-wide sick days. But for now I’ll stick to not touching the water cooler.
At the Large Hadron Collider in Geneva, physicists shoot protons around a 17-mile track and smash them together at nearly the speed of light. It’s one of the most finely tuned scientific experiments in the world, but when trying to make sense of the quantum debris, physicists begin with a strikingly simple tool called a Feynman diagram that’s not that different from how a child would depict the situation.
Original story reprinted with permission from Quanta Magazine, an editorially independent division of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences
Feynman diagrams were devised by Richard Feynman in the 1940s. They feature lines representing elementary particles that converge at a vertex (which represents a collision) and then diverge from there to represent the pieces that emerge from the crash. Those lines either shoot off alone or converge again. The chain of collisions can be as long as a physicist dares to consider.
To that schematic physicists then add numbers, for the mass, momentum and direction of the particles involved. Then they begin a laborious accounting procedure—integrate these, add that, square this. The final result is a single number, called a Feynman probability, which quantifies the chance that the particle collision will play out as sketched.
“In some sense Feynman invented this diagram to encode complicated math as a bookkeeping device,” said Sergei Gukov, a theoretical physicist and mathematician at the California Institute of Technology.
Feynman diagrams have served physics well over the years, but they have limitations. One is strictly procedural. Physicists are pursuing increasingly high-energy particle collisions that require greater precision of measurement—and as the precision goes up, so does the intricacy of the Feynman diagrams that need to be calculated to generate a prediction.
The second limitation is of a more fundamental nature. Feynman diagrams are based on the assumption that the more potential collisions and sub-collisions physicists account for, the more accurate their numerical predictions will be. This process of calculation, known as perturbative expansion, works very well for particle collisions of electrons, where the weak and electromagnetic forces dominate. It works less well for high-energy collisions, like collisions between protons, where the strong nuclear force prevails. In these cases, accounting for a wider range of collisions—by drawing ever more elaborate Feynman diagrams—can actually lead physicists astray.
“We know for a fact that at some point it begins to diverge” from real-world physics, said Francis Brown, a mathematician at the University of Oxford. “What’s not known is how to estimate at what point one should stop calculating diagrams.”
Yet there is reason for optimism. Over the last decade physicists and mathematicians have been exploring a surprising correspondence that has the potential to breathe new life into the venerable Feynman diagram and generate far-reaching insights in both fields. It has to do with the strange fact that the values calculated from Feynman diagrams seem to exactly match some of the most important numbers that crop up in a branch of mathematics known as algebraic geometry. These values are called “periods of motives,” and there’s no obvious reason why the same numbers should appear in both settings. Indeed, it’s as strange as it would be if every time you measured a cup of rice, you observed that the number of grains was prime.
“There is a connection from nature to algebraic geometry and periods, and with hindsight, it’s not a coincidence,” said Dirk Kreimer, a physicist at Humboldt University in Berlin.
Now mathematicians and physicists are working together to unravel the coincidence. For mathematicians, physics has called to their attention a special class of numbers that they’d like to understand: Is there a hidden structure to these periods that occur in physics? What special properties might this class of numbers have? For physicists, the reward of that kind of mathematical understanding would be a new degree of foresight when it comes to anticipating how events will play out in the messy quantum world.
Today periods are one of the most abstract subjects of mathematics, but they started out as a more concrete concern. In the early 17th century scientists such as Galileo Galilei were interested in figuring out how to calculate the length of time a pendulum takes to complete a swing. They realized that the calculation boiled down to taking the integral—a kind of infinite sum—of a function that combined information about the pendulum’s length and angle of release. Around the same time, Johannes Kepler used similar calculations to establish the time that a planet takes to travel around the sun. They called these measurements “periods,” and established them as one of the most important measurements that can be made about motion.
Over the course of the 18th and 19th centuries, mathematicians became interested in studying periods generally—not just as they related to pendulums or planets, but as a class of numbers generated by integrating polynomial functions like x2 + 2x – 6 and 3x3 – 4x2 – 2x + 6. For more than a century, luminaries like Carl Friedrich Gauss and Leonhard Euler explored the universe of periods and found that it contained many features that pointed to some underlying order. In a sense, the field of algebraic geometry—which studies the geometric forms of polynomial equations—developed in the 20th century as a means for pursuing that hidden structure.
This effort advanced rapidly in the 1960s. By that time mathematicians had done what they often do: They translated relatively concrete objects like equations into more abstract ones, which they hoped would allow them to identify relationships that were not initially apparent.
A New Measurement Deepens the Puzzle of the Proton’s Size
Mathematicians Are Building a Unified Theory of Geometric Randomness
The Physicist Who Might Have Discovered a New Building Block of Matter
This process first involved looking at the geometric objects (known as algebraic varieties) defined by the solutions to classes of polynomial functions, rather than looking at the functions themselves. Next, mathematicians tried to understand the basic properties of those geometric objects. To do that they developed what are known as cohomology theories—ways of identifying structural aspects of the geometric objects that were the same regardless of the particular polynomial equation used to generate the objects.
By the 1960s, cohomology theories had proliferated to the point of distraction—singular cohomology, de Rham cohomology, étale cohomology and so on. Everyone, it seemed, had a different view of the most important features of algebraic varieties.
It was in this cluttered landscape that the pioneering mathematician Alexander Grothendieck, who died in 2014, realized that all cohomology theories were different versions of the same thing.
“What Grothendieck observed is that, in the case of an algebraic variety, no matter how you compute these different cohomology theories, you always somehow find the same answer,” Brown said.
That same answer—the unique thing at the center of all these cohomology theories—was what Grothendieck called a “motive.” “In music it means a recurring theme. For Grothendieck a motive was something which is coming again and again in different forms, but it’s really the same,” said Pierre Cartier, a mathematician at the Institute of Advanced Scientific Studies outside Paris and a former colleague of Grothendieck’s.
Motives are in a sense the fundamental building blocks of polynomial equations, in the same way that prime factors are the elemental pieces of larger numbers. Motives also have their own data associated with them. Just as you can break matter into elements and specify characteristics of each element — its atomic number and atomic weight and so forth — mathematicians ascribe essential measurements to a motive. The most important of these measurements are the motive’s periods. And if the period of a motive arising in one system of polynomial equations is the same as the period of a motive arising in a different system, you know the motives are the same.
“Once you know the periods, which are specific numbers, that’s almost the same as knowing the motive itself,” said Minhyong Kim, a mathematician at Oxford.
One direct way to see how the same period can show up in unexpected contexts is with pi, “the most famous example of getting a period,” Cartier said. Pi shows up in many guises in geometry: in the integral of the function that defines the one-dimensional circle, in the integral of the function that defines the two-dimensional circle, and in the integral of the function that defines the sphere. That this same value would recur in such seemingly different-looking integrals was likely mysterious to ancient thinkers. “The modern explanation is that the sphere and the solid circle have the same motive and therefore have to have essentially the same period,” Brown wrote in an email.
If curious minds long ago wanted to know why values like pi crop up in calculations on the circle and the sphere, today mathematicians and physicists would like to know why those values arise out of a different kind of geometric object: Feynman diagrams.
Feynman diagrams have a basic geometric aspect to them, formed as they are from line segments, rays and vertices. To see how they’re constructed, and why they’re useful in physics, imagine a simple experimental setup in which an electron and a positron collide to produce a muon and an antimuon. To calculate the probability of that result taking place, a physicist would need to know the mass and momentum of each of the incoming particles and also something about the path the particles followed. In quantum mechanics, the path a particle takes can be thought of as the average of all the possible paths it might take. Computing that path becomes a matter of taking an integral, known as a Feynman path integral, over the set of all paths.
Every route a particle collision could follow from beginning to end can be represented by a Feynman diagram, and each diagram has its own associated integral. (The diagram and its integral are one and the same.) To calculate the probability of a specific outcome from a specific set of starting conditions, you consider all possible diagrams that could describe what happens, take each integral, and add those integrals together. That number is the diagram’s amplitude. Physicists then square the magnitude of this number to get the probability.
This procedure is easy to execute for an electron and a positron going in and a muon and an antimuon coming out. But that’s boring physics. The experiments that physicists really care about involve Feynman diagrams with loops. Loops represent situations in which particles emit and then reabsorb additional particles. When an electron collides with a positron, there’s an infinite number of intermediate collisions that can take place before the final muon and antimuon pair emerges. In these intermediate collisions, new particles like photons are created and annihilated before they can be observed. The entering and exiting particles are the same as previously described, but the fact that those unobservable collisions happen can still have subtle effects on the outcome.
“It’s like Tinkertoys. Once you draw a diagram you can connect more lines according to the rules of the theory,” said Flip Tanedo, a physicist at the University of California, Riverside. “You can connect more sticks, more nodes, to make it more complicated.”
By considering loops, physicists increase the precision of their experiments. (Adding a loop is like calculating a value to a greater number of significant digits). But each time they add a loop, the number of Feynman diagrams that need to be considered—and the difficulty of the corresponding integrals—goes up dramatically. For example, a one-loop version of a simple system might require just one diagram. A two-loop version of the same system needs seven diagrams. Three loops demand 72 diagrams. Increase it to five loops, and the calculation requires around 12,000 integrals—a computational load that can literally take years to resolve.
Rather than chugging through so many tedious integrals, physicists would love to gain a sense of the final amplitude just by looking at the structure of a given Feynman diagram—just as mathematicians can associate periods with motives.
“This procedure is so complex and the integrals are so hard, so what we’d like to do is gain insight about the final answer, the final integral or period, just by staring at the graph,” Brown said.
Periods and amplitudes were presented together for the first time in 1994 by Kreimer and David Broadhurst, a physicist at the Open University in England, with a paper following in 1995. The work led mathematicians to speculate that all amplitudes were periods of mixed Tate motives—a special kind of motive named after John Tate, emeritus professor at Harvard University, in which all the periods are multiple values of one of the most influential constructions in number theory, the Riemann zeta function. In the situation with an electron-positron pair going in and a muon-antimuon pair coming out, the main part of the amplitude comes out as six times the Riemann zeta function evaluated at three.
If all amplitudes were multiple zeta values, it would give physicists a well-defined class of numbers to work with. But in 2012 Brown and his collaborator Oliver Schnetz proved that’s not the case. While all the amplitudes physicists come across today may be periods of mixed Tate motives, “there are monsters lurking out there that throw a spanner into the works,” Brown said. Those monsters are “certainly periods, but they’re not the nice and simple periods people had hoped for.”
What physicists and mathematicians do know is that there seems to be a connection between the number of loops in a Feynman diagram and a notion in mathematics called “weight.” Weight is a number related to the dimension of the space being integrated over: A period integral over a one-dimensional space can have a weight of 0, 1 or 2; a period integral over a two-dimensional space can have weight up to 4, and so on. Weight can also be used to sort periods into different types: All periods of weight 0 are conjectured to be algebraic numbers, which can be the solutions to polynomial equations (this has not been proved); the period of a pendulum always has a weight of 1; pi is a period of weight 2; and the weights of values of the Riemann zeta function are always twice the input (so the zeta function evaluated at 3 has a weight of 6).
This classification of periods by weights carries over to Feynman diagrams, where the number of loops in a diagram is somehow related to the weight of its amplitude. Diagrams with no loops have amplitudes of weight 0; the amplitudes of diagrams with one loop are all periods of mixed Tate motives and have, at most, a weight of 4. For graphs with additional loops, mathematicians suspect the relationship continues, even if they can’t see it yet.
“We go to higher loops and we see periods of a more general type,” Kreimer said. “There mathematicians get really interested because they don’t understand much about motives that are not mixed Tate motives.”
Mathematicians and physicists are currently going back and forth trying to establish the scope of the problem and craft solutions. Mathematicians suggest functions (and their integrals) to physicists that can be used to describe Feynman diagrams. Physicists produce configurations of particle collisions that outstrip the functions mathematicians have to offer. “It’s quite amazing to see how fast they’ve assimilated quite technical mathematical ideas,” Brown said. “We’ve run out of classical numbers and functions to give to physicists.”
Since the development of calculus in the 17th century, numbers arising in the physical world have informed mathematical progress. Such is the case today. The fact that the periods that come from physics are “somehow God-given and come from physical theories means they have a lot of structure and it’s structure a mathematician wouldn’t necessarily think of or try to invent,” said Brown.
Adds Kreimer, “It seems so that the periods which nature wants are a smaller set than the periods mathematics can define, but we cannot define very cleanly what this subset really is.”
Brown is looking to prove that there’s a kind of mathematical group—a Galois group—acting on the set of periods that come from Feynman diagrams. “The answer seems to be yes in every single case that’s ever been computed,” he said, but proof that the relationship holds categorically is still in the distance. “If it were true that there were a group acting on the numbers coming from physics, that means you’re finding a huge class of symmetries,” Brown said. “If that’s true, then the next step is to ask why there’s this big symmetry group and what possible physics meaning could it have.”
Among other things, it would deepen the already provocative relationship between fundamental geometric constructions from two very different contexts: motives, the objects that mathematicians devised 50 years ago to understand the solutions to polynomial equations, and Feynman diagrams, the schematic representation of how particle collisions play out. Every Feynman diagram has a motive attached to it, but what exactly the structure of a motive is saying about the structure of its related diagram remains anyone’s guess.
Original story reprinted with permission from Quanta Magazine, an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.
Talking about the weather is, for many people, boring. Or maybe you used to feel electric discussing things like warm fronts and lightning strikes, but lately your weather conversations lack, shall we say, thermal convection. But talking about the weather is just like other interpersonal activities: You can spice it up by looking at nice pictures.
The very best weather porn comes from geostationary satellites, and the very best geostationary satellite is launching today at 5:42pm ET. It is called GOES-R, and comes equipped with a 16 channel multispectral imager capable of delivering the hottest, high-resolution cloud-on-cloud action.
Since 1975, the US has kept a trio of weather satellites in geostationary orbit—22,3000 miles up. The cast gets rotated as technology improves, but one is always parked over the west side of the country, another over the east, and a third between the other two as backup. GOES-R will replace GOES-14, the current west side satellite, giving weather fetishists a fourfold improvement in spatial resolution (crisper clouds) and fivefold improvement in refresh rate (smoother storm footage).
Settle down, little buddies. GOES-R won't be shipping home imagery for several months. But, courtesy of the Japanese Meteorological Administration, you can get a sneak peep show. The agency's Himawari-8 weather satellite, launched last year, has an imager that's nearly identical to GOES-R's. The video below shows Himawari-8 footage of a typhoon off the coast of Taiwan.
Notice how the time lapse's tint changes between :03 seconds and :08 seconds? That's night time, captured by Himawari-8's 10 infrared bands (out of a total of 16). Really, the only difference between the two imagers will be during daytime imaging. "The JMA wanted a red, green, and a blue band for their visible light, but the National Weather Service doesn't have a requirement for green, so instead we have a band capable of detecting cirrus clouds," says Steve Goodman, GOES-R's senior scientist.
GOES-R will be able to do close-up rapid scans, bouncing between things like tropical storms and volcanic eruptions, every minute. Meanwhile, it can also stitch together images of the whole hemisphere. If working on rapid scans, the whole disk refresh rate is 10 minutes. With nothing else going on, you get the whole earth every five. Again, the Himawari-8 has some absolutely stellar whole hemisphere time lapses. Peruse away.
But GOES-R has some other equipment that the Himawari-8 does not. One: a lightning detector. If you want to know whether a cluster of thunderstorms is going to develop, check the cloud tops, where lightning flashes will register as momentary brightening. Storms with lots of lightning are unlikely to turn into hurricanes. But measuring the cloud-top light levels during the day is super difficult, because the sun's glare dulls everything. So the lightning imager measures microsecond-scale changes in light intensity, comparing image after image. “That gives us better accuracy, fewer false alarms, and better lead time with predicting severe storms,” says Goodman.
And because GOES-R is out in space, it can also act as an early warning system for radiation. High energy particles from solar storms can mess up GPS, utility grids, and other satellites. But GOES-R ain't scared of no danger. In fact, it stares directly into the sun, creating high resolution maps of corona holes, solar flares, and sunspots. That's so hot.
Click through the gallery to see this week’s helping of the best the universe has to offer. And if you need more when you’re done but can’t wait until the next one, here’s the entire collection.
Do you remember President-elect Trump holding forth on the campaign trail about “China beating us at our own game”? Well, it's true, as long as the game in question is editing human DNA using Crispr/Cas9. China is now using Crispr-edited cells in living, breathing human beings.
Last month, Chinese scientists at Sichuan University injected cancer-fighting, Crispr-modified white blood cells into a patient suffering from metastatic lung cancer. It was just the latest in a line of recent firsts for the People’s Republic of China, following on the heels of the first Crispr-edited monkeys in early 2014, and the first Crispr-edited human embryos last May. So there it is, Mr. President-elect: Are you going to let China win the race to edit humans?
Researchers and bioethicists worry that Trump's political posturing could lead to a dangerous loosening of safety standards for patients. Right now, using Crispr—or any other gene-editing technique—is totally legal in the US, and subject to the same rigorous regulatory framework as other gene therapy treatments. There are even a handful of clinical trials in progress which use gene-editing, and more, including some that will use Crispr, are planned for next year.
Where it gets sticky is when you start talking about heritable changes to the human genome—what's known as germline editing. Last December a broad coalition of leading biologists agreed to a moratorium on that until the discipline could learn more about the risks. It's non-legally binding and anyone could buck that agreement, the problem is finding funding to do so. So what the US gene-editing community really wants to know is if Trump is going to make it possible for prospective human gene hackers to apply for big time federal grants.
“There are two different and opposite things that are likely to happen,” says Hank Greely, a Stanford University lawyer and bioethicist. “The first has to do with Crispr and germline editing. Anything that looks like an embryo or sounds like an embryo will probably come under attack in the new administration.” That's more or less the situation researchers face now. Last year’s omnibus spending bill contains a ban on all federal research dollars involving genetic manipulation of embryos, including via Crispr.
Crispr Gene-Editing Upstart Editas Goes Public as Patent Battle Rages
Internet Outrage Is Shaping the Battle Over Crispr
Can You Tell These Real Crispr Projects From the Fake Ones?
That spending bill expires December 9, though Capitol Hill Republicans plan to continue current government funding through March 31 (a short-term patch is aimed at giving the Trump administration a say in 2017 funding priorities). But don’t be surprised if embryonic editing stays taboo. The right wing's history of opposing anything that seems like playing god goes all the way back to George W. Bush’s 2001 ban on federal funding for embryonic stem cell research.
At least one gene-editing pioneer sees that as short-sighted. "Germline editing is going to happen and to think otherwise is naive," says University of Utah's Dana Carroll. "And as to research on human embryos, whether or not it's happening in the US anytime soon, elsewhere in the world it's already started. If we want to know how to do it safely, research is going to have to provide those answers." That may be true, but it won't be happening on the government dollar, at least for now.
More likely is those Republican legislators will take another look at editing adult human cells—somatic cell therapies. This is the category of editing that the Chinese scientists just accomplished. The team at Sichuan University in Chengdu removed immune cells from a lung cancer patient and disabled their PD-1 gene, a brake pedal for the immune system which cancers exploit in order to proliferate. The researchers then inserted the re-engineered cells back into the patient as part of the first clinical trial to test Crispr’s safety in gene therapy applications.
In the US, two pieces of legislation currently in front of Congress could make it easier (and cheaper) for researchers to push similar treatments through the approval process. First is the Regrow Act, introduced in March, which would allow the FDA to bring drugs to the market for five years without Phase 3 trials (the phase where you figure out whether or not treatments actually work).
Then there’s the 21st Century Cures Act, which passed the House last year and is still waiting for a Senate vote. Actually a chimera of 19 separate bills, the proposed law would make substantial changes to the way the FDA approves drugs and devices, including streamlining of the clinical trial process. “Some provisions in there are aimed at making it easier for companies to get on the market. And while the main political thrust is stem cells, Crispr would certainly benefit as well,” says Greely.
Despite China’s head start, the international milestone still surprised some scientists—many expected the first human use of Crispr to come from a trial planned to begin next year at the University of Pennsylvania.
Whether or not you see that as a good thing depends on your politics, and what you have to gain from weaker oversight. The last few years has seen an increase in biotech lobbyists partnering with patient advocacy groups to make gene therapy and stem cell therapy treatments available to the public faster.
The Sichuan University trial received ethical approval from a hospital review board in July, after only six months of review. “To get the same thing approved in the US would take dramatically longer,” says Paul Knoepfler, a stem cell researcher at UC Davis. While study leader Lu You declined to comment for this article, others have noticed China’s reputation for moving quickly through the regulation process.
And Knoepfler says he can see how that would create a sense of urgency here in the US. “If the Trump administration buys into the idea of needing to be more competitive on gene editing, then all of a sudden there’s this pressure to allow things to move forward based on less data," he says. "Speaking as a scientist though, we don’t tend to think along nationalist terms. None of us want to be scooped, but if it happens, we don’t care what country that person is from.”
The FDA, for better and for worse, is a historically cautious gatekeeper, unconcerned with international spitting contests. Clinical trials cost millions, and last for years. But George Church, Harvard University geneticist and co-founder of Editas Medicine believes it’s a necessary step to ensure new technologies like Crispr-based gene therapies really work. Even when they hold you up from making history. (Editas had been an early pick to cross the CRISPR clinical trial finish line first, in their efforts to treat a rare genetic eye disease.) “The FDA is commonly viewed as a roadblock,” he says. “But if your treatment is safe and effective it will fly through the approval process. It has nothing to do with novelty and everything to do with safety and efficacy.”
Patients are looking for answers. Biotech is looking for big bucks. Both oppose regulation. And both are at odds with scientists who think the current frameworks is appropriately judicious. “There is a real philosophical difference of opinion in Washington about whether competent adults should be able to take big risks, and whether desperate people should be offered false hope,” says Greely. He’s concerned about politicians playing up the threat of international competition to drum up support for deregulation. “That will allow trials to go forward without good data behind them. And I hope not too many people die as a result,” he says. “Elections have consequences.”
Yes they do. The consequences of this most recent one will be made clear soon enough.
Every year, many of us gather around a Thanksgiving table and stuff our faces with food before ducking out of awkward conversations with distant relatives by blaming our post-feast food coma on "too much turkey." It's true that there is no slumber quite like that of a Thanksgiving nap, but it's time we faced what's really turning us into drooling zombies who overstay our welcome on some second cousin's couch. And guess what? It's not the turkey.
For starters, turkey may be loaded with tryptophan, the amino acid that's a precursor to the sleep-inducing serotonin, but so is just about any high-protein food. Cheese, nuts, and, yes, even Tofurkey all have way more tryptophan than turkey and many other meats. More importantly, tryptophan by itself doesn't really make you tired. Foods laden with this amino acid are also loaded with a bunch of other amino acids that block your brain from absorbing the tryptophan and turning it into the sleep-inducing serotonin. A psychiatrist named John Fernstrom looked into this back in 1972 and found that, "The main determinant of brain tryptophan and serotonin concentrations does not appear to be...tryptophan alone." Rather, it's the presence of good ol' delicious carbs that helps your body convert that tryptophan into serotonin. And let's be real here—Thanksgiving isn't really about the turkey. It's about the carbs.
When you mix tryptophan with generous helpings of mashed potatoes, bread, and pie, it floods your body with sugars. Suddenly, all those other amino acids that were blocking your brain from absorbing that tryptophan suddenly have a new job: helping your body break down all those sugars. Without anything to stop it, the brain starts converting that tryptophan into serotonin, which ushers in those warm, sleepy feels.
What really seals your fate in dreamland, however, is the fact that you probably just ate way too much food. Regardless of whether you even ate any turkey, eating large portions of anything will leave your body with a ton of food to digest. That takes up a lot of energy, so while your innards are doing their work, your brain is signaling to the rest of your body that it's time to take it easy and reserve energy.
This happens whether you want it to or not because the same part of your body that tells your heart to beat and your lungs to breathe also tells your body to digest. It's called your parasympathetic nervous system, and it automatically queues up tasks that are necessary for survival. In order to successfully take in and process all of those nutrients you've just scarfed, that system goes into hyperdrive. So while you might feel guilty dodging the dishes, at least you can say one part of you is working hard.
Besides, you've likely just endured hours of horrible traffic, jet lag, day drinking, endless cooking, and/or a series of tense and circular political discussions all in the name of gratitude. So go ahead—loosen that drawstring, kick off your shoes, and post up. You've earned it, ya big glutton.

It's Halloween, so what better time to look at some of the creepier names in the world of volcanoes? Ever since people stared up at erupting volcanoes and thought "Huh, I guess that thing might kill me," volcanoes have engendered a lot of fear and apprehension. So it's no wonder that a pile of them have horrific-sounding names. Now, this list is by no means complete—I created it by looking at the Global Volcanism Program's Holocene and Pleistocene volcano lists, so I likely missed a bunch of scary names in tongues I don't understand. But it's a good start, and if you have any suggestions, feel free to leave them in the comments.
Here they are: my ten best Halloween-themed volcanoes.
Jornada del Muerto, New Mexico: We'll start off with a volcano named "Route of the Dead Men" (mostly thanks to its remote, inhospitable location). Jornada del Muerto is a small shield volcano almost in the middle of New Mexico. The whole desert Southwest is pockmarked with these small, basaltic volcanoes, likely related to Basin and Range extension across that part of the continent. Although it likely hasn't erupted since 760,000 years ago, Jornada del Muerto is near a potential magma body located under Sorocco, so it could be a place of renewed activity sometime in the future.
Alligator Lake, Canada: Now, I suppose Alligator Lake isn't a particularly frightening name, unless you are afraid of alligators. However, did you notice that this Alligator Lake is in Canada? You know, that country that is more-or-less bereft of the large reptiles? Something must be especially frightening about this lake to get this name. Alligator Lake is a collection of cinder cones, shield volcanoes, and lava flows in the Yukon(!) that likely hasn't erupted since the last Ice Age. Canada is actually full of spooky volcano names, including Crow Lagoon, Dark Mountain, and Hoodoo Mountain.
Devil's Garden, Oregon: Look at enough volcanic terranes and you'll find a bevy of names related to ol' Scratch himself. Devil's Garden is another lava flow field that stretches to the east 0f Newberry Caldera in central Oregon. This area is also full of lava tube caves from these voluminous basalts that might be as young as 10,000 to 20,000 years old. Oregon also features another Devilish volcano in the Devils Hills chain on the southern slopes of South Sister, a linear array of rhyolite domes that erupted in the last few thousand years, along with the nearby and disturbing Three Fingered Jack.
Monte Vulture, Italy: Monte Vulture is a bit of an oddball. It is located to the east of the Appenines and has quite a violent history, although it might be nearing the end of its volcanic lifespan. The volcano features a caldera at its summit but no one can agree on exactly when and how the caldera was formed. Over 150 square kilometers around the volcano are blanketed by the volcanic ash and debris from its eruptions, the most recent of which occurred ~420,000 years ago.
Descabezado Grande, Chile: One of my favorite volcano names, Descabezado Grande, translates to "the big beheaded one." It is located in one of the most volcanically active areas in Chile, flanked to the south by Cerro Azul and Quizapu and to the east by the Calabozos caldera (which sent a dacitic lava flow almost 32 kilometers to reach the edge of Descabezado Grande). In 1932, Quizapu produced one of the largest explosive eruptions of the last few hundred years, and Descabezado Grande followed with a VEI 3 eruption of its own in 1933. A number of rhyolite flows and domes are found across the area as well.
Traitor's Head, Vanuatu: Traitor's Head is actually a peninsula on the island of Erromango, a string of three smaller volcanoes once part of another island that connected to Erromango after a series of eruptions. Nothing much has happened at Traitor's Head from what we know, but some submarine volcanism had been noted in the 1880s and 1950s off the northern coast of Erramango.
__Spokoiny, Russia: __Alright, so there is nothing specifically Halloweeny about this volcano, but its name did remind me of "spooky," which gets it somewhere. The nearest I can tell (using Google Translate), Spokoiny translates to "quietly" in Russian, which is a little odd considering it is a volcano. I suppose the name does make sense as it is one of the quieter volcanoes on the Kamchatka Peninsula, with no known eruptions over the last 5,000 years—unlike its very noisy neighbors like Shiveluch, Kliuchevskoi, and Kirimsky.
Devil's Desk, Alaska: I know I covered Devil-related names above, but I couldn't pass this one up. I mean, I suppose the devil does want hell to be fully furnished and when he/she gets down to business, and a desk would be handy while writing up those soul purchases. So, that's where we find Devil's Desk, an eroded remnant of a volcano that pokes through a glacier in Alaska. Heavy glaciation in Alaska means that although it is beat up, it could have erupted in the last 10,000 years, although most likely it hasn't been active for over 250,000 years. It is also in the same volcanic complex of Mount Denison, possibly the only potentially-active volcano named after a small, liberal arts college.
__Mount Terror, Antarctica: __Part of Ross Island, you'd think Mount Terror would be a little more, well, terrifying. It isn't even the most active volcano on Ross Island—that distinction belongs to nearby Erebus. It does feature TERROR POINT and TERROR SADDLE and TERROR GLACIER, which sounds pretty amazing, but even the name "Mount Terror" isn't from some frightening event or feature of the volcano. Instead, it was named in honor of the HMS Terror, which was lost exploring the other of Earth's poles. However, in a quirk of history, the Terror belong to the Vesuvius-class of bomb ships, so hey, volcanoes! Mount Terror likely hasn't erupted in over 800,000 years, but that doesn't stop it from having one of the best Halloween-related volcano names on Earth.
__Hell's Half Acre, Idaho: __We'll end the list with one of the best Halloween names of all: Hell's Half Acre. Now, much like Devil's Desk, you have to ask yourself why the devil would decide to purchase a measly half acre in Idaho, but who knows what the Lord of Darkness is thinking most of the year. Hell's Half Acre, which actually covers over 400 square kilometers (Hell's 98,842 Acres?) is yet another lava flow and shield volcano field that is part of the Snake River Plain, a lowland created by the Yellowstone hotspot track. Some of the lava flows from Hell's Half Acre can be traced 10 kilometers, making it one of the largest lava flow fields along the Snake River Plain. Most people don't think of Idaho as a place of active volcanoes, but Hell's Half Acre likely erupted only about 3,200 years ago, so native Americans living in the area would have seen the eruptions.
I'm not a huge fan of Halloween, but I am a fan of finding ways to squeeze physics into an event. Here are four common Halloween effects that you might have at a party—along with a quick explanation of the physics involved. I saved the best for last.
You pretty much have to use this at your party. I think it's an official Halloween party requirement. The basic idea is to take some dry ice and plop it in water. Boom—instant cool fog effect along with bubbling water.
But what is dry ice? It's just the solid form of carbon dioxide. However, unlike water ice, dry ice doesn't melt. Instead it sublimates. This means it goes straight from a solid to a gas. If you just place a piece of dry ice on a table, after a while it will have just turned into gas and mixed with the rest of the air. No puddle.
You might think that the fog you see is carbon dioxide. Nope. This fog is actually condensing water vapor from the air. When the dry ice turns into a gas, it is cold. This cold carbon dioxide gas cools off the water vapor in the air. Cool water vapor condenses into tiny droplets of water and these droplets reflect light. This white fog looks just like a cloud because it is essentially just like a cloud.
The condensing water vapor is still cooler than the surrounding air and more dense. Not only does the water vapor in the air form this fog, but the fog sinks to the surface of the table. It makes a great effect. Oh, and you don't even need dry ice. In the image above I actually used liquid nitrogen since our dry ice machine wasn't functioning. But still, it's the same idea.
Oh, and dry ice is mostly safe. Don't touch it with your bare hands because it is super cold at -75°C (that's colder than the temperature on Hoth). The other dangerous thing about dry ice is that it expands into a gas. If you put dry ice into a bottle with a closed top, it's probably going to explode. I probably shouldn't have told you that.
Sparks are just another cool visual effect that you can use for your Halloween party—or just for fun. How does it work? The whole thing starts with a high electric potential difference (in volts). Think of an electric potential difference (which we often just call potential for short) as a big hill. If you put a ball at the top of this hill, it can gain kinetic energy as it moves down the hill. The same is true for electric charges and electric potential. As an electron moves through a potential it also increase in kinetic energy.
Now just imagine that you have a free electron that is accelerating due to this electric potential difference. It can't keep speeding up forever—something is going to get in the way. That something is probably a molecule of nitrogen or oxygen (since that's what the air is made of). When this electron collides with air, the impact can free even more electrons. More electrons means more collisions and more free electrons. Now you have an electron avalanche (that's actually what it's called).
After these electrons are freed, you have both electrons and positive ions (of oxygen and nitrogen). When an electron meets back up with an ion, you get light. That's what we call a spark. You might think that this is pretty cool stuff—but wait! There's something even cooler. Where does that first free electron come from that starts this whole avalanche? The answer is space. The free electron is most likely produced by cosmic radiation that ionizes air. Without this free electron, there would be no spark (and maybe no Halloween).
Two notes: First, this idea of cosmic rays being responsible for sparks comes from the awesome introductory physics textbook Matter and Interactions. Great book. Second, if you create a high voltage source to make great sparks don't blame me if you shock yourself. Getting shocked is no fun.
How do you make a ghost? This is an old trick, but it's still great. The basic principle is that glass can both reflect and transmit light. Of course you already knew this. When you try to look outside of your house through a window at night, all you really see is your own reflection. This is because the light coming in from outside is so much dimmer than the reflected light—but light is still coming in.
So here's what you do. Take a piece of glass and place it at a 45 degree angle with respect to a viewer. Put the normal objects straight in front of the viewers so that they can be seen through the glass. Now place a "ghost" (but not a real ghost) in a location such that a reflection from this ghost makes it appear near a normal human. Clearly I am going need to include a diagram.
Hopefully it's clear that those white arrows show the path of light. Also, I replaced the audience with a camera—it's essentially the same thing. The camera (or our eyes) can't really tell where the light came from. We just trace it back to its apparent source which would be behind the glass. It's the same thing as a normal mirror except that you can also see the human through it.
Warning: awesome physics ahead. Now that you have been warned, let's get started.
When an electron in an atom is excited, it jumps up to a higher energy level. When this electron then goes back to the ground state it creates light. The frequency of this light is dependent on the size of the energy level jump. OK, but there are some special cases. The first is called fluorescence—yes, just like a fluorescent lightbulb. In this case, an excited electron doesn't go straight back to the ground state energy level: It takes more than one transition to fall down. In the fluorescent lightbulb, this happens in the powdered coating in the tube. The gas in the tube produces ultraviolet light that excites electrons in the powder. But the electrons take multiple transitions to get to the ground state and in the process produce light with lower frequency (visible light).
Stuff that glows in the dark is called phosphorescent. This is just like the fluorescent material except for one difference—one of the transitions to get back to ground state is a "forbidden" transition. This doesn't mean it can't happen, but just that it doesn't happen right away.
So here's what happens. You excite the electrons in the phosphorescent material and they jump to some higher energy level. Next, the electrons take more than one transition to get back to ground state—but one of these transitions takes a while. This means that after the light is removed from the material, it still continues to give off its own light for some time. It "glows in the dark."
The light that excites these electrons must be higher frequency than the light it gives off. In the above image, you can see a violet laser pointer will get the glow in the dark material excited. But what about a green or red laser? Nope, those won't work. The energy transition depends on the frequency of light and those lasers don't have a what it takes to get the stuff excited.
But really, you should try that blue laser with the glow-in-the-dark stuff. It's awesome.
You know bats—the flighty mammals that find their way around with sonar and eat bugs and sometimes revert to their human form and live in a castle on a hill. But bats have a little secret I’d like to share with you: They can be astonishingly fast. As in, as fast as a car on a highway. This isn’t a Halloween trick, because quite frankly I don’t got time for that. So check out this week’s episode of Absurd Creatures to learn more!
Find every episode of Absurd Creatures here. And I’m happy to hear from you with suggestions on what to cover next. If it’s weird and we can find footage of it, it’s fair game. You can get me at matthew_simon@wired.com or on Twitter at @mrMattSimon.
Last summer, as it sped through the Pluto system, the New Horizons spacecraft only had a few hours to pack its memory banks with as much data about the dwarf planetary system as possible. On October 25, the last few hundred bits of that data finally arrived in one of NASA's deep space radio dishes.
For posterity's sake, take a moment and remember that before the flyby—a mere 15 months ago—the dwarf planet was a pixellated blur. Planetary scientists had some ideas about Pluto's atmosphere, geology, and satellite system, well, pixellated works as an analogy for the clarity of those ideas. But now, hoo boy. New Horizons didn't just deliver a picture of Pluto's gigantic heart: The probe's flyby revealed the dwarf planet as one of the most dynamic and complex worlds in the solar system. What a time to be a planetary scientist.
New Horizons is equipped with seven different instruments—multi-spectral imagers, particle sniffers, dust collectors. Together, they collected 6.25 gigabytes of data. You could download (legally, of course) a movie that size in a few minutes. But New Horizons is 3 billion miles away. Bit by bit, the New Horizons ground team collected the flyby data over 469 days.
Alice Bowman, New Horizons' mission operations manager, was the point person for those transmissions. You might remember her as the person who received the "all's well" signal New Horizons sent on July 15, 2015 after it finished its historic fly by. "I would say July 15th was not the norm for us," she says. Instead of elated public check ins, Bowman's team was doing heavy logistical lifting for the priority scientific data.
How NASA Is Steering New Horizons Toward a Tiny Space Rock in the Kuiper Belt
Buckle Up, Space Fans: A New Batch of Pluto Science Is Here
New Horizons’ Sharpest Photos of Pluto, Now in Color
"God forbid anything happen to that spacecraft, we wanted to have the highest value data on the ground as soon as we could," says Bowman. But doing so isn't just a matter of drag and dropping folders from your flash drive onto your laptop. Every bit of data on New Horizons' drives is indexed according to when it was collected. And that goes back to Newtonian physics. New Horizons' engineers had to calculate exactly how many seconds it would take for the probe to reach Pluto. And then instruct the computer with things like, "At 299,791,044 seconds after New Horizons has left Earth, roll 32 degrees, pitch 15 degrees, and yaw 256 degrees, and activate the Ralph imager for .25 seconds."
Bowman and her team had to start planning each of these downlinks 8 weeks in advance. And the process wasn't just figuring out which jigsawed piece of data to retrieve. "Then we run the command through software simulators, hardware simulators, and have the science and mission operations teams review the results of those simulations to make sure the commands do what we want," she says.
Bowman and her team also had to jostle with other missions, like Voyager, Cassini, and Stereo, for antenna time on NASA's 70-meter Deep Space Network antennas. "If we were able to get that time, we would get the data down and run operations software to make sure we got everything we requested," she says. If not, her team had to send a realtime request back to New Horizons. Sound fun? Repeat this process for over 500 chunks of data.
"New Horizons was just raining data every week for a year and a half," says Alan Stern, the mission's principal investigator. The images showed vast glaciers, mountains made of water ice, plains of frozen nitrogen, atmospheric haze layers, cryogenic volcanoes, and geologic evidence that Pluto has been tectonically active for 4.5 billion years. Plus surprises—like Charon's 600-mile minimum equatorial canyon—from each of Pluto's five satellites.While Stern treats every byte of data like his own blood, a few downlinks hold special significance. First was that first, lovely, high resolution downlink from July 14, 2015. "After 26 years of working on this, it was just stunning to see what the world really looked like," he says. New Horizons took the second image towards the end of its fly by. "It's the true color image of Pluto's atmosphere, with a blue ring around it," he says. The only way to get that image was to be on the far side of the dwarf world, backlit by the sun. That one really nailed it for Stern: It was his equivalent of seeing the Apollo Earthrise picture.
Stern says his team has only turned about 80 percent of the New Horizons data into science. Completing the job might employ another generation of planetary scientists. Imagine: A 10-year-old kid inspired by last year's flyby could spend her post-doc solving Plutonian mysteries using New Horizons' data. "There are people who were born after Voyager who have earned a PhD and work on data from the 1980s," he says. NASA knows this. The agency recently sent out research proposals for more scientists to help the original New Horizons team analyze data.
And lest you think data analysis is the team's only chore, remember that they are still steering New Horizons towards its next target—a remote object in the Kuiper Belt known as 2014 MU69.
What's that? The last bit of Pluto data New Horizons sent home? "Some composition mapping data from the LEISA infrared mapping spectrometer aboard out Ralph instrument," says Stern. What does that mean? Wait and see. Or go get a degree in planetary science and find out for yourself.
It'll take a year for New Horizons to send back all the information it gathered on Pluto when it flew by in July.
In space, nobody can hear you scream. But you can holler with delight here on Earth, especially if you were at NASA's Jet Propulsion Laboratory last Thursday for its annual pumpkin carving contest. Although, calling it a “carving competition” seems off: It's more like a science fair on steroids.
Hate to break it to you, but that pumpkin you carved for Halloween this year is pretty lame compared to these insanely intricate jack-o-lanterns. And you probably had all night. Participants in JPL's contest only had an hour to build these crazy contraptions. In the time it took you to scrape out the pumpkin's guts, this team turned their gourds into a spinning, flickering amusement park carousel.
HBD JPL! The Southern California research depot was founded on October 31, 1936. Bedecked with a cone hat and surrounded by balloon-shaped squashes, this festive birthday pumpkin takes the cake.
The JPL teams are just like you and your nerdy friends (except capable of building spacecraft): They love geeky inside jokes. This pumpkin, what we call Saw VIII: Ninja Starshade, is getting its face split by a starlight-blocking spacecraft.
How many mechanical engineers does it take to screw in a light bulb? None, they’ll create their own. Thomas Edison would be proud. Bonus points: is that a pumpkin rave in there?
Hide your kids, hide your cows. Apparently these Martians prefer abducting livestock over humans. Phew, that’s a relief.
These NASA pumpkins are clearly next level. Let them be rocket-fueled inspiration, because you still have time before Monday to carve a masterpiece. Or, maybe just settle for something like this.
When scientists finished sequencing the human genome in 2003, many researchers focused their attention on decoding the long strings of As, Ts, Gs and Cs as the way to understanding the mysteries of human genetics. The genome, however, doesn’t appear in nature as a simple long line of letters. Unfurled, the genome stretches for nearly two meters, yet it folds itself in coils and loops to fit inside a nucleus less than 10 microns in diameter.
Original story reprinted with permission from Quanta Magazine, an editorially independent division of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences
In recent years, researchers have begun to understand just how important this 3-D genetic architecture really is. Just as the only accessible information in a book is what’s on the open page in front of you, the genome’s instructions can only be read by the cell when those instructions aren’t hidden inside deep folds. But researchers don’t understand how the cell folds DNA in such a way that the important bits can be read.
Earlier this year, two independent groups of researchers took a big step toward decoding the mysteries of DNA folding. Both groups used the powerful new gene editing tool known as Crispr to uncoil a tightly wound piece of DNA. Their work could help scientists identify some of the basic rules behind how and why the genome forms its 3-D structure. It also reveals that the presence of small DNA sequences can lead to massive changes in how the genome is organized.
The new research began as an attempt to understand a mystery of the X chromosome. Most male mammals have an X and a Y chromosome, while most females have two Xs. This presents a potential problem for a female’s cellular machinery. If both Xs remain active, twice the number of X chromosome genes will be switched on. This will lead to a host of developmental difficulties, often culminating in the death of the embryo soon after fertilization.
To avoid this scenario, one copy of the X chromosome switches itself off using a gene called Xist. The inactive X chromosome, known as the Barr body, is small. It coils itself up and hides nearly all of its genes from the cellular machinery that turns DNA into RNA and proteins.
“X inactivation is a critical process in female development,” said Brian Chadwick, a biologist at Florida State University. “The only difference between the two Xs is how they’re packaged.”
Chadwick has spent his entire career trying to understand how the body inactivates one copy of the X chromosome. Chadwick’s work on Barr bodies zeroed in on a DNA sequence called DXZ4 as being potentially key to the folding that switches off most of the genes on one copy of the X chromosome. All the mammals his team has looked at with an inactive X chromosome had these sequences.
But how was Chadwick to test whether DXZ4 really was the origami master of the X chromosome? A major clue appeared in 2014, in work that had begun over two decades before.
As a doctoral student in Mark Seyfred’s lab at Vanderbilt University in the early 1990s, Katherine Cullen wanted to understand a protein called prolactin, which enables female mammals to make milk. Cullen and Seyfred believed that exposure to estrogen sets off a cascade of events that ends in the creation of a giant loop of DNA. This loop connects the prolactin gene promoter, which acts as a switch to turn the gene on, with a prolactin enhancer, which serves as the metaphorical finger that flips the switch. Cullen’s task for her doctorate was to verify this.
She searched for this loop using a technique that had recently been developed by Seyfred called a proximity ligation assay. The first step is to treat the genome with formaldehyde, which creates cross-links between segments of DNA that are close to one another in the genome’s natural 3-D form. The process reveals which parts of the genome are touching even if those sequences are far away from one another on the linear genome. Cullen found that exposure to estrogen creates a loop that links the prolactin enhancer and the promoter. Her discovery earned her a 1993 publication in Science and sent her well on her way to her doctorate.
Cullen’s work offered some of the first direct evidence that the larger three-dimensional structure of the genome is related to its function. But her article didn’t receive much attention. “I wasn’t thinking about genome architecture at the time. The term wasn’t even a term back then,” Cullen said.
Things had changed a decade later, when she received a surprise call from Erez Lieberman Aiden, at the time a visiting fellow at Harvard University, who was looking for more information about the ligation assay she had used. Aiden had big ambitions for it. He didn’t want to just use the assay on one gene. Instead, he wanted to search through the whole genome, identifying not just one loop but potentially thousands of them.
Over the next few years, Aiden, who is now a computational biologist at Rice University and Baylor College of Medicine, built on work by Job Dekker, a biologist at the University of Massachusetts Medical School, to create the Hi-C system, which maps the probability that two pieces of the genome are touching each other.
“We bump into our next-door neighbor more than someone who lives in another country. It’s the same idea here,” Aiden said. “If we know who bumps into whom in an ordinary day of the genome, then we can figure out how close these areas are and consequently what the genome looks like in three dimensions.”
Aiden and colleagues published results of the initial Hi-C experiments in 2009. These results revealed genome architecture at 1-million-base-pair resolution—a pointillist outline that began to reveal the genome’s dazzling complexity. “The results were like a map of the world that only gave you the fuzzy outlines of the continents,” said Suhas Rao, a graduate student who works in Aiden’s lab. “You couldn’t really navigate with them, but it was a place to start.”
The Aiden lab spent the next few years refining Hi-C and, in 2014, published a paper in Cell that charted every loop and coil of DNA at 1,000-base-pair resolution. If the 2009 paper revealed the blurry outlines of North America, the new Hi-C exposed a street grid of Manhattan. The detail gave scientists some of their first clues about the rules by which the genome folds.
Of all the billions of contacts among DNA that Aiden’s Hi-C generated, one area of the genome stood out. In XX female cells, Rao, Aiden and colleagues found that while one X shared patterns of loops with the rest of the chromosomes, the inactive X looked very different. Instead of having multiple loops of around 200,000 base pairs, the inactive X had two massive “superdomains” characterized by multiple “superloops” of up to 77 million base pairs. What was anchoring the superloops? A DNA sequence called DXZ4—the same one that Chadwick had previously identified as key to the folding of the X chromosome. Chadwick read the paper and reached out to Aiden. The pair agreed to collaborate.
Understanding the relationship between the structure of a molecule and its function is a classic question in biochemistry. Scientists studying proteins mastered this field of inquiry beginning in the 1960s by changing one amino acid building block in a protein and measuring how it altered the protein’s ability to do its job. Chadwick and Aiden wanted to do something similar to understand the relationship between DNA sequences and genome architecture. Like many genetics labs, they turned to the genome editing tool Crispr, which can act as a set of biomolecular scissors.
To prove that DXZ4 really does influence genome folding, the team took human cells and used Crispr to snip out the DXZ4 section—a repetitive stretch of DNA that goes on for hundreds of thousands of nucleotides. They then used Hi-C to measure how the cut affected chromosome looping. When they removed DXZ4, “those gargantuan loops disappeared. The chromosome starts to look like a normal autosome,” Aiden said. “It showed that we could have fine control over how the genome folded.”
Independently, Dekker’s lab had likewise shown the key role of DXZ4 in the folding of the inactive X chromosome in mice. They also revealed that the Xist gene—the molecular switch that coils up the inactive X chromosome—helps to create the boundary between the two large superdomains on that chromosome. Both Dekker’s paper (published in Nature) and Aiden and Chadwick’s (published in the Proceedings of the National Academy of Sciences) have helped to untangle the Gordian knot of genome folding.
“It’s quite spectacular that the structure of an entire chromosome would rely on a small DNA sequence somewhere in the middle,” said Wouter de Laat, a biomedical geneticist at Utrecht University in the Netherlands.
These papers, de Laat said, are expanding our knowledge of the intimate relationship between how a genome folds and how it functions. Scientists have long suspected that abnormal genome folding may cause diseases, and several new studies have identified links between genome architecture and biological development. A 2016 study by Stefan Mundlos at the Max Planck Institute for Molecular Genetics in Berlin and his colleagues showed that a rearrangement of DNA in a noncoding region of the genome caused limb malformations during development by changing chromatin folding. Other researchers are using Crispr to investigate whether changes to genome architecture affects the ability of parasites like Trypanosoma, the cause of African sleeping sickness, to evade the immune system.
It’s becoming apparent that in the genome, as Dekker says, “nothing makes sense except in 3-D.”
Original story reprinted with permission from Quanta Magazine, an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.
This summer, 81,000 homes in Pittsburgh received a worrisome letter about their water. The local utility "has found elevated levels of lead in tap water samples in some homes," it said. Seventeen percent of samples had high levels of the metal, which can cause "serious health problems."
The situation was bad enough to attract the attention of Marc Edwards, the Virginia Tech professor who helped expose the water crisis in Flint, Michigan. "The levels in Pittsburgh are comparable to those reported in Flint," he said in an interview with local TV station WPXI.
This was surprising because until this year, Pittsburgh's lead levels had always been normal. So what happened?
First, a bit of background: In 2012, the city faced a dilemma. Though it had clean water, its century-old water system desperately needed repair. And its utility, Pittsburgh Water and Sewer Authority, was plagued by administrative problems. Residents complained of bad customer service and unfair fees. And after a series of poor financial decisions in the 2000s, PWSA was hundreds of millions of dollars in debt.
Pittsburgh isn't alone: Public utilities around the country are trying to make ends meet with dwindling public funding and increasingly outdated infrastructure. Many, like Pittsburgh, turn to private management companies to help out.
Pittsburgh's utility called in Veolia, a Paris-based company that consults with utilities, promising "customized, cost-effective solutions that reflect best practices, environmental protection and a better quality of life." Veolia consults or manages water, waste, and energy systems in 530 cities in North America, with recent contracts in New York City, New Orleans, and Washington, DC. Last year, the company, which operates in 68 countries, brought in about $27 billion in revenue.
Pittsburgh hired Veolia to manage day-to-day operations and provide an interim executive team, helping the utility run more efficiently and save precious public dollars. Under the terms of the contract, Veolia would keep roughly half of every dollar the utility saved under its guidance.
Under the leadership of Jim Good, a Veolia executive serving as interim director, PWSA began making sweeping changes—and they seemed to be working: Within a year, call waiting times for concerned customers dropped by 50 percent. Thanks to new fees for commercial buildings, new customers, and other assorted changes, the utility saved $2 million.
According to a 2013 article in the Pittsburgh Post-Gazette, Veolia changed PWSA's culture, too: Instead of traditional top-heavy management, Good checked in with employees over pizza and burgers every week. At a staff barbecue in 2012, "I told them that we were there to work with the employees as their partners," he later told the Post-Gazette. "I provided assurances that there wouldn't be any layoffs and that together we could achieve anything."
But by the end of 2015, the utility had laid off or fired 23 people—including the safety and water quality managers, and the heads of finance and engineering, according to documents obtained through a Right-to-Know request. The PWSA laboratory staff, which was responsible for testing water quality throughout the 100,000-customer system, was cut in half. Stanley States, a water quality director with 36 years of experience at the utility (employees referred to him as "Dr. Water") was transferred to an office-based job in the research department. Frustrated with the move, he retired.
Good maintains that not all staffing decisions were made by Veolia, which was in a consulting rather than management role when the layoffs occurred. Any suggested staffing changes had to be approved by the board, he said.
As the lab staff shrank, PWSA made major changes to its water treatment system. For decades, the city had been adding soda ash—a chemical similar to baking soda—to its water to prevent the pipes, many of which are lead, from corroding and leaching into the water. (Lack of corrosion controls caused lead to leach into the water in Flint.) In 2014, PWSA hastily replaced soda ash with another cheaper corrosion control treatment, caustic soda. Such a change typically requires a lengthy testing and authorization process with the state's Department of Environmental Protection, but the DEP was never informed of the change. Nearly two years later, as news spread about the disaster in Flint, the utility switched back to soda ash.
Pittsburgh Mayor Bill Peduto puts the blame for the treatment change squarely on Veolia, saying the company never informed the utility's board or the city. Veolia denies responsibility for the change, saying it "did not and would not prioritize cost savings ahead of effective corrosion control methods or water quality."
What is certain is that this spring, the state's DEP cited the utility for breaking state law and ordered immediate lead testing.
Tests this summer—the first since 2013—found that the city's lead levels had crept up and, for the first time on record, exceed federal standards. Seventeen percent of homes had levels above the Environmental Protection Agency's action level of 15 parts per billion.
Many suspect that the change in water treatment chemicals led to the jump in lead levels; the city is currently conducting an internal investigation into the matter.
Stanley States, the former water quality director, believes the staff cuts almost certainly played a role. Lead levels first crept up in 2013 because of a previous change in treatment chemicals, though they didn't exceed federal standards. But without a fully staffed lab, says States, the matter wasn't addressed. "They cut our laboratory in half," he said. "We would have been researching like crazy this lead corrosion problem to see how to correct it."
But Pittsburgh citizens' complaints about Pittsburgh's water goes beyond quality—it's also extraordinarily expensive. In 2013, a year after Veolia was hired, the water board approved a 20 percent rate increase over four years; by 2017, the average residential water bill will be $50 per month—triple the average Midwest cost, according to the Guardian.
Soon after, customers began complaining that their bills were coming erratically and appeared to charge for water residents hadn't used. One vacant property owner was charged for using 132,000 gallons of water in one month—that's about how much a family of four uses in a year. "You don't know if it's going to come in, whether it's late or not, how much it will be, a Pittsburgh retiree told Truthout. "Then you get it and there's a late charge."
In May of 2015, a group of Pittsburgh customers filed a class-action lawsuit against the utility, Veolia North America Water, and the accounting company keeping track of PWSA bills, alleging that new water meter readers installed in 2013 "catastrophically failed and customers have received grossly inaccurate and at times outrageously high bills"—including increases of nearly 600 percent. "PWSA is acutely aware that the billings are wrong but do not hesitate for a moment to issue 'shut off' notices and then arbitrarily turn off water service," read the complaint. PWSA and Veolia declined to respond to the allegations.
Last December, facing the class-action lawsuit, a state citation for changing corrosion controls, and mounting debt, Pittsburgh terminated its contract with Veolia. All told, PWSA had paid Veolia $11 million over the course of the contract.
Earlier this month, the utility announced it was suing the company. According to a press release, Veolia "grossly mismanaged PWSA's operations, abused its positions of special trust and confidence, and misled and deceived PWSA as part of its efforts to maximize profits for itself to the unfair detriment of PWSA and its customers."
Pittsburgh isn't the first municipality to sue Veolia this year. In April, Massachusetts officials sued Veolia, which was managing Plymouth's sewage treatment facility, for allowing 10 million gallons of untreated sewage to spill in and around the town's harbor last winter.
Two months later, Michigan Attorney General Bill Schuette charged Veolia with fraud and negligence for failing to discover Flint's enduring lead contamination problem after the city hired the company in 2015 to consult on water quality.
"Veolia stated that the water, quote, was safe," Schuette told NPR. "Veolia also callously and fraudulently dismissed medical and health concerns by stating that, quote, some people may be sensitive to any water."
In many cases, critics point to a pattern of Veolia saving utilities money through quick fixes—while ignoring bigger problems. In a phone interview, Kevin Acklin, the chief of staff for Pittsburgh's Mayor Bill Peduto, pointed out that Veolia's earnings are directly tied to the utility's short-term savings. "They had the incentive under the contract to not make capital investments in property, planning, and equipment—to basically not fix the pipes when needed, to pass off those costs to other agencies, including the city and private homes," he alleged. "Ultimately they were fiduciaries for the public authority, but they also served the business needs of a large multinational corporation."
Veolia denies responsibility in both Plymouth and Flint, saying the leak in Plymouth came from a pipe failure that was out of its control, and that the contract in Flint was limited to looking at another chemical called TTHM.
In the case of Pittsburgh, Veolia maintains that PWSA's board of directors retained control over the authority over the course of the three-year contract. "Veolia met its obligations and fulfilled the requirements of our contract in a fully transparent manner," wrote a Veolia North America spokeswoman in an email. "We stand behind the work performed on behalf of PWSA."
Yet Pittsburgh leaders can't help but notice that the city's utility is arguably even worse off than it was when it hired Veolia four years ago, with a depleted bank account—half of all earnings are directed to serving debt—and pipes that are still a century old. "The authority is in a pretty precarious financial situation right now, and I can't sit here and point to anything tangible to show the positive legacy of the contract we had with Veolia," says Acklin.
A former PWSA employee was more blunt about it. When asked how to advise utilities considering contracting with Veolia, he warned, "They will come in, rape your water company, and leave with money bags."

If we get our way and really put humans on Mars in the coming decades, they’re going to need power. NASA has had concrete plans to send people to the Red Planet since 2010—with target dates in the 2030s, while Elon Musk thinks SpaceX can make it to Mars faster. But no matter who gets there first, the power problem remains. Astronomer Frank Shu has a great idea that could work—a type of nuclear reactor that’s cheaper, safer, and more efficient than the ones currently in wide use.
But Shu, a former president of the American Astronomical Society, actually doesn’t care so much about Mars. He thinks his reactor could do wonders here on Earth—so he’s flipping the space technology script. Usually, scientists say things like, “If we develop a rocket to Mars, who knows what cool earthly spinoffs we’ll develop along the way. Stuff like Tang! You love Tang! Right?” But Shu’s plan does the opposite. He wants to develop technology that helps Earth—and then get Martian spinoffs. Like power systems for the space settlers you’re never going to see again!
The path to plopping new nuclear reactors—or any nuclear power source—on this fragile planet is politically and philosophically fraught, so they require big buy-ins from governments and funding agencies. “Even if you can convince people to do it, it’s probably a long-term thing,” says Shu. To manifest his vision, he needs significant, long-term investment—which is why Shu is promoting his reactors as a solution to Martian power problems. In sum, he says: “I want to build this on Earth, but I want NASA to pay for it.”
Bonus: “Development by NASA could bypass much of the red tape that now ties up the timely testing of novel prototype reactors,” says Shu.
Shu’s nuclear power device is called a “two-fluid molten salt reactor.” The full details are in the patent, but the basic idea is this: The first batch of molten salt is full of a thorium compound, which eventually decays into uranium as neutrons bombard the mixture. That uranium goes into the second batch of molten salt and circulates into the reactor’s graphite-filled core.
There, it encounters slowed-down neutrons, which kick off a fission chain reaction—that’s the energy-producing part. The first batch of salt then absorbs the heat from the reactions, cooling the system. (In typical nuclear reactors, water does the cooling.)
This system is self-regulating: If the reactions happen too fast and the reactor gets too hot, the salt naturally expands out of the core, which cools it off—think transferring hot coffee from a tiny cup to a cookie sheet (don’t ask questions). That makes the reactor pretty meltdown-proof.
That’s great for Mars, obviously—any energy supply on a newly-formed colony is going to have to be pretty foolproof. Not worth setting up a trillion-dollar settlement if your reactor gives everyone radiation poisoning (at least not before the sun does, anyway). Plus, the planet has plentiful thorium, and nuclear power doesn’t care if dust storms dot out the Sun for months at a time (solar panels, on the other hand, care very much). That’s why Shu hopes NASA will back the R&D for his reactors.
It’s also great for Earth. While Shu’s specific design is novel, the idea comes from the 1960s, when Oak Ridge National Laboratory made a molten salt reactor. The World Nuclear Association calls them “a promising technology today,” and China and India are sinking effort into their own designs. That hasn’t happened yet, though—which is where Shu’s plan comes in.
Any new technology must prove that it has the potential to scale safely, while outcompeting other established options. That takes time, and money—time and money that a Mars-tech development plan can provide.
Some technologies—like electricity-makers—make easy sense in Shu’s Earth-first philosophy. People and this planet want things like cleaner energy and clean water. Solar power and water purification, says MIT’s Olivier de Weck, are big markets with big companies behind them. “They’re not specifically working on space problems, but the technology is progressing,” he says. That technology can then transform into space-colony-ready systems.
And Mars may need Earth technologies just as much as Earth needs Mars technologies. Back in 2014, De Weck and his colleagues at MIT made a big crater among the go-to-Mars set when they called out a Dutch plan to send people to Mars, one-way. The so-called Mars One team claimed that “each stage of Mars One mission plan employs existing, validated and available technology.” But the technology they pegged as nearly go for launch simply wasn’t.
But when will we actually need systems that are space-colony-ready? Just how anticipatory is all this development, and how long is it likely to remain Earth-bound?
“The true answer is it’s always one generation away,” says de Weck.
“Like fusion,” I say.
“It’s kind of like fusion,” he says.
But the limits aren’t strictly technological. “If we really had to establish a Mars colony, we could do this within 10 to 15 years,” he says. It would be expensive, but not impossible.
In the meantime, the most prominent plans for Mars colonization are still sketchy. Elon Musk hopes his first ships will reach Mars around 2022, and last month, he revealed a nebulous version of his blueprints for his later colonization plans—run largely on solar, not nuclear, power—at a presentation.
“Elon’s plan is huge; it’s monolithic; it’s very ambitious,” says de Weck. But Musk basically waves his hands at the architectural and infrastructural details of the colony itself. “I’ve been asking—and others have been asking—to see the roadmap from the current capabilities to the far-out vision. I just don’t see the logical pathway,” he continues.
While Musk fills auditoriums, it may be people like Shu—with their terrestrial technologies and their economically supported stepping stones—who actually make Mars a livable planet instead of somewhere settlers stand around and stare at each other until they die.
Gravestones! It's cemetery season here in the States, so what better time to discuss how to be remembered forever? If you wander through any graveyard, you'll find grave markers made of all manner of the same thing: stone! Now, I'm sure many people don't give a second thought to what kind of rock they should use for their monument beyond which might be the most attractive. But they should. All rocks are not the same when it comes to how they handle the wear and tear of the hereafter.
Most gravestones made over the last few centuries are made of a few types of rock: marble, slate, and granite are the big three. Sometimes you run into darker stones made of gabbro, maybe a few sandstone markers, but especially in more recent monuments, marble and granite (and other plutonic rocks) rule the roost. Older graveyards tend to use rock that was available locally, so they can be variable. Around central Ohio, a lot of the old gravestones are made of readily available limestone. They're attractive—but are they the best choice if you want your marker to last as long as possible?
It turns out that making your gravestone (or any monument) from materials like marble is not a good idea for longevity. Rocks can break down two ways: physically and chemically. Physical weathering is the toll put on rocks by processes like frost/ice splitting, abrasion (from things hitting it), plant roots, decompression at the surface (remember, most rocks are formed deep under our feet at high pressure, so the surface is way out of the their ideal conditions) and more. Chemical weathering are reactions that occur when the rock interacts with water, air, and acids. The two types of weathering work together to make the tallest mountain into nothing more than a pile of sand given enough time.
Now, rocks are made of minerals and certain minerals are more susceptible to breaking down at the Earth's surface than others. If we wanted to rank common gravestone minerals in terms of how quickly they weather, it would look something like this (from most to least weatherable):
So, what is the first thing you notice? Calcite is terrible when it comes to withstanding the ravages of chemical weathering. This is why the old gravestones of the Midwest are barely legible because acid rain created by factory pollution has dissolved a lot of the calcite in the limestone and marble gravestones. Even more hardy minerals like plagioclase feldspar, found in everything from gabbro to granite, can be susceptible to breaking down into clays when they react with acidic water.
What rock types might withstand the ravages of chemical weathering? Granite is a good start, as is sandstone, because they are rich in more-stable minerals like quartz and orthoclase (a potassium-rich feldspar). However, physical weathering can hit them hard. Sandstone might be mostly quartz (depending on what kind you select), but sandstone is really just sand grains cemented together. Water can alter the cement or get into cracks between the grains, and when it freezes it can split! This is what happens in gravestones made of slate, where the prominent parting known as cleavage can allow water into the rock to split it apart. Who knew that water was such an enemy of rocks?
What are you going to do if you want your gravestone to last forever? Beyond putting it someplace out of reach of most weathering like the Atacama Desert or, I don't know, the Moon, you want to choose a rock that is made of a resistant mineral that is fused together and lacks cleavage (planes of weakness in the rock). That would get you into two places. First would be non-reactive metals, so yes, make your gravestone out of solid gold and it would last a long time (or as long as it takes for someone to steal it and melt it down). You could also be remembered as your refrigerator with a stainless steel marker as well, but they aren't called gravestones for nothing.
Second would be something made entirely of what we call "resistant" minerals that are resistant to chemical and physical weathering. There are a bunch of uncommon minerals like zircon, monazite and sphene that can take a beating and persist. That's why when you look at sand under a microscope, you might see a lot of these minerals — and why the oldest stuff on Earth is zircon (the ~4.4 billion year old zircon of the Jack Hills, themselves "gravestones" of rocks that came before them). However, making a gravestone out of these minerals might mean a very, very small marker.
Quartzite: the ideal gravestone material.
What more common minerals might work? Well, the two best might be garnet and quartz. Now, depending on your desire to stand out in a cemetery, trying to make an average size solid garnet or quartz marker would be hard. Typically these minerals don't form enormous blocks that can be carved into headstones. However, quartz is the primary constituent of quartzite (shocking, isn't it?). Quartzite (above) is a metamorphic rock made from heating up sandstone under pressure—it fuses all those quartz sand grains together into an interlocking network of quartz. All the weakness between the grains is removed and instead you get an almost solid block of quartz.
Quartzite would be highly resistant to chemical weathering because it's quartz. And because it lacks a lot of space for water to sneak in, very resistant to physical weathering as well. Make your tombstone out of quartzite and you're looking at a rock for the ages. Or at least until the sun envelops the planet (so better get that interplanetary probe prepped to launch your earthly remains into space).
In the late 1990s, Elizabeth Holmes was in middle school. Her scandal-beset company Theranos—which promised to use amazing advances in a hybrid scientific field of microfluidics to detect multiple conditions from a single drop of blood—didn’t exist.
But at the University of Washington, bioengineer Paul Yager was using microfluidics to develop paper-based assays that he hoped would detect pathogens with just a nasal swab. And like Holmes did later, he also saw the potential in making these tests directly accessible to patients. He was ahead of his time. Investment dollars and talented post-docs went instead to big labs working on big, traditional testing machinery. And now he worries that his life's work will suffer collateral damage from Theranos’ abuse of trust. Investors, he says, are already acting cagier towards him. He calls it, “the Theranos crater.”
The crater analogy is apt: Theranos blew up in the middle of the biotech world. Anybody looking to raise capital for their new diagnostic technology will likely have to answer tougher questions from more skeptical investors. And nobody working on point-of-care diagnostics can make a promise like Holmes’ 70-tests-from-one-drop rhetoric. But even without magic blood machines, point-of-care diagnostic investing is looking up. So while Theranos may have made it harder for some researchers to fund their ideas, the company also proved that the biotech market is ripe for point-of-care diagnostics.
John Waldeisen is the CEO and Co-founder of Diassess, a diagnostics start-up that raised an undisclosed but "significant" amount in its Series A last October—right around the time the Wall Street Journal exposed Theranos’ internal struggles to the world. He sees the (now) ex-deals with Walgreens and Safeway as a sign that things aren’t as bad as they seem. “These two huge giants clearly see the opportunity here,” he says. “And you have to believe that Theranos catalyzed that excitement. Now that they’re relinquishing their position, it’s anyone’s game.”
And that game is a long one. Diassess has been around for three years, making quick and easy DNA testing for chemical, forensic, agricultural, and industrial applications. Things like ID’ing oil field bacteria, or running genetic tests on a farmer’s corn crop right there in the row. Diassess has been trying to source as many diagnostic opportunities as possible, even as they continue to develop the real moneymakers: Rapid, cheap point-of-care tests for STIs like chlamydia and HPV.
Compared to Theranos, Diassess is pretty small potatoes. They’ve publicly disclosed having raised only $120,000 so far, not counting the Series A. But they have something that Theranos didn’t: rigorous oversight telling them their tech actually works. That’s because since 2012 they’ve received $2.5 million to develop their products through prestigious grants from the NIH and the NSF. As a condition of the grants, Diassess has been submitting data to the NIH three times a year for the last three years, as they prepare to head into FDA clinical trials. “Submitting yourself and your technology to that level of scrutiny is very useful,” says Waldeisen. “It’s helped us justify our successes to investors and provide firm grounding that the technology is very real.”
Diassess is putting the horse before the cart, but that is no guarantee that the cart will fill with money. According to the Journal’s reporting, Theranos raised the bulk of its money from venture capital firms with little biotech experience. The company was part of a bigger trend, says Andrew Lee, co-founder of StartX Med, Stanford’s medical and biotech incubator. “People have taken money from general tech investors who don’t have much biotech experience but want to play in the biotech landscape,” he says. This kind of reckless investment has Lee and others worried that biotech has been captured by Silicon Valley’s hype cycle. “Tech and software have been getting more and more saturated and so people want to do something more meaningful, deploy in the medical health space to see if they can make a difference. And it’s those people who are wary now that Theranos has gone the way it has.”
That means companies that really want to make a difference have to strike a balance between innovating and overpromising. In practical terms, at one end you have the slow, rigorous federal research grant process; and a fevered Series A funding round at the other. Andrew Ellington, a University of Texas biochemist developing DNA computing systems to diagnose diseases like Zika, SARS, MERS, and Ebola with pregnancy kits and other off-the-shelf products, says playing both ends of the spectrum requires nuanced strategies.
For example, Ellington has also earned NIH funding for his diagnostic research. And while he credits the agency with trying to push the technological edge despite massive budget cuts, he admits that the federal granting process often moves too slowly for real innovation. To make up for it, he has licensed his technologies out to a local company—Paratus Diagnostics—for commercialization. “I grew up in a system that rewards your ability to come up with great ideas over a 20-30 period," he says. "That's so different from being able to take a great idea from the lab to market in two to three years. So that disconnect between academia and the corporate world, I try to make it less stark, while still recognizing the cultural barriers."
Paul Yager, the University of Washington bioengineer who has been working on microfluidics since the 1990s, says he’s had no trouble getting federal money or hard data to show his technology works. It’s been a bit harder for him to find a commercial partner. General Electric showed interest a few years back, but then later got cold feet. Yager’s still trying to see out of the Theranos crater, but he doesn’t blame Silicon Valley. “People want to invest in a big way, make a splash, get their name on the wall,” he says. "But it would be nice to get people who grew up in software development to put things in their portfolio that might not make them a lot of money, and might actually make a difference."
That’s the thing about craters: Scorched earth leaves a lot of room to grow.
Climate predictions—kind of like romantic comedies—are full of will they/won't they suspense. Like this year's La Niña. In September, the National Weather Service cancelled its months-long lookout for the climate phenomenon—which, as a counterpoint to El Niño, is associated with cooler overall global temperatures. Then, last week, the agency reversed. Its Climate Prediction Center predicted a 70 percent chance of La Niña forming, and folded that prediction into its Winter Weather Outlook. If true, that means the next few months will be warm and dry in the southern half of the US; wet and cool in the north.
If. A La Niña requires months and months and months of persistently cool sea surface temperatures in the equatorial Pacific—and—colluding atmospheric conditions, like stronger than normal trade winds. Unlike the inevitable (and inevitably adorable) first encounter between protagonists in a romcom, there's no guarantee of a geothermal meet cute.
La Niña and El Niño are part of the same climate cycle. And like all things climate, they begin with the sun. Solar energy heats the ocean's surface, creating convection—wind. The Earth's rotation (via the Coriolis effect) makes those winds blow from east to west. Trade winds. They, with help from giant subsurface waves, push the warm surface water westward against the island clusters of Indonesia and Papua New Guinea. "There’s a slow buildup of warmer than average water under the surface in the western tropical Pacific," says Anthony Barnston, chief forecaster for the International Research Institute for Climate and Society at Columbia University. "If you build up enough it will spill over into eastern tropical Pacific." When the spillover happens, the normally cool eastern Pacific becomes unusually warm. The convection slows down, and the trade winds fade, or die. From there, global weather havoc—El Niño.
In all things, balance. La Niña is the yin in the tropical Pacific tajitu. Sometimes, as an El Niño drags on, giant subsurface waves begin to reflect off Indonesia and the other islands. The water there is tepid, drawn in to replace the warm stuff that went east. If the subsurface waves push enough cool water to overcome the balmy El Niño blob, you've got La Niña conditions. (Note: La Niñas don't just form after El Niños, but more on that in a bit.)
"But if the ocean cools off without the atmospheric component, you can't have a La Niña," says Barnston. That means the trade winds have to kick up a notch or so. "That correlates with things like shifts in tropical rainfall patterns, sea level pressure, and upper atmospheric winds." And those drive phenomena like hurricane formation and drought. For the past several months, a crucial area of the central tropical Pacific has been cold enough for La Niña, but the trade winds have been normal.
The people who keep track of La Niñas and El Niños work at NOAA's Climate Prediction Center. The crucial area they watch is a rectangle about the size of the US along the equator between the International Date Line and South America Pacific. It is called the Nino 3.4 region. When the area cools by more than 0.5˚C of the historical average for a three month period, the NOAA climatologists issue a La Niña watch. (They issue an El Niño watch when the same region is 0.5˚C degrees warmer than usual.) And then they watch some more.
"A month ago, a team of us looked at the models, and looked at the numbers, and when averaged together, it didn't seem like the La Niña would hold," says Tom DiLibert, a meteorologist at the Climate Prediction Center. Mostly, this was due to the fact that those nothing special trade winds I mentioned earlier. "Then September happened." The trade winds finally picked up. La Niña watch is back. In order to earn the official La Niña title, the Nino 3.4 region needs to stay 0.5˚C cooler for five consecutive three month periods.
But La Niñas don't always happen after El Niños. Sometimes they just happen. And even the fact that the world just experienced one of the strongest El Niño's on record is no guarantee of a La Niña. It took a full year for a La Niña to form after the super strong 1982-83 El Niño.
Nature, however, doesn't care about the words humans use to describe its atmospheric fluctuations. "If you look at weather patterns in the US, it pretty much conforms to what we'd expect from a weak La Niña," says Barnston. Warm and dry in the south, wet and cool in the north. "Forecasters are calling for effects from this event whether it gets labeled a La Niña or not," he says. Sheesh. Some people just can't wait for the plot to bear out.
On June 14, 2016, four researchers at the Jet Propulsion Laboratory were preparing to ship a waist-high, ape-like robot named RoboSimian off-site. They had built the bot to rescue people from dangerous situations that human rescuers can’t hack. The scientists swapped one lithium-ion battery for a fresh one, then left for lunch to let the new power supply charge.
Left alone in the lab, RoboSimian’s battery did what such batteries famously do: went boom. Plumes of smoke vented from the robot’s exposed torso, followed by a burst of flame. Fire filled the room, then stabilized at the size of a toxic campfire. Gather round the burning bionic monkey, everybody. (Don’t.)
Exploding lithium-ion batteries are not new news. Last year’s hottest Christmas present, the hoverboard, was a bit too hot. You can’t take an e-cigarette on a plane because it might combust in the cargo hold. And if you have a Samsung Galaxy Note 7…well…better luck in your next phone pick.
But the magnitude of RoboSimian itself—and that of other lithium-powered NASA projects—set its battery fire apart. “In general, a single lithium ion cell is dangerous, but it can’t cause a gigantic explosion,” says Jay Whitacre, a Carnegie Mellon professor of materials science and engineering who used to do battery science at the Jet Propulsion Laboratory. Cell phones typically have a single cell; RoboSimian had 96. If you’ve seen what a Samsung device can do to your hand, imagine what this robot could have done to the rest of you.
And because NASA builds lithium-loaded vehicles that also go to space—sometimes, someday taking people up there—this fire may feel like cause for concern. The huge sets of cells that live inside robots, spacecraft, and robotic spacecraft? “That’s a lot of energy that’s released very quickly, and it can be fatal,” says Whitacre. “The more you put in one place, the more you have to look at it.”
According to a presentation that Lynne Lee, the laboratory’s mishap program manager, made earlier this month to senior management, RoboSimian’s boom packed the power of a stick of dynamite. “If you notice where that fire came out, it was exactly where our researchers were standing,” Lee said, as she prepared to share lessons learned as the October Safety Message. “It could have been a very bad day.”
After the initial battery burst, an intern from the next lab over climbed through a window and sprayed RoboSimian with a CO2 fire extinguisher. But the fire persisted—he needed water to quench this combustion, despite NASA’s safety protocol, which called for a Class D extinguisher (no such extinguisher was around, anyway).
Another intern called the fire department. Firefighters, with the benefit of breathing masks, eventually rolled RoboSimian outside by a handle, like some kind of Mad Max Radio Flyer, and killed the fire with water.
So what actually happened here? The final report on why the fire erupted in the first place isn’t ready, says Brett Kennedy, head of the RoboSimian project. But they do have some details about The Incident.
Lithium-ion batteries have a positive side (anode) and a negative side (the cathode), separated by a liquid electrolyte, which is highly flammable. When the battery is charging, ions move from the positive side to the negative side. “When you charge a battery, you put a current through it,” says Whitacre. “And you do it until the battery hits its max voltage. When it hits its max voltage, you should stop that current.” If you don’t halt that flow, the battery can fail and, sometimes, explode.
Samsung’s Recalling Millions of Note 7 Phones Over Battery Fires
Why Hoverboards Keep Exploding
Tesla’s New Battery Will Make Lithium Ion the Next AA
Kennedy says the battery itself, as a whole, was not overcharged. “There was a monitoring system in place that continuously monitored the overall battery voltage and current,” he says. “Had either the voltage or current to the battery moved out of specification, the charging would have been shut down.”
But based on initial analysis, one cell of the battery was damaged and sent misleading information to the monitoring equipment. As a result, individual cells became overcharged—and kablooie.
While Whitacre couldn’t confirm or deny a specific hypothesis—his evidence coming only in the form of this non-forensic video—he did notice one thing: It all happened fast, not in the slow-burn way of many battery fires.
“Battery packs are made up of a number of smaller cells. It’s common for one of the cells to go a little haywire first,” he says. That cell damages its neighbors, and then they go nuts, and the mess cascades. “This one is a little bit different,” Whitacre continues. “It looks to me like almost everything went at the same time or like one of the cells got very, very hot very quickly.”
Lithium-ion batteries are “an essential part of power in NASA,” Lee said in her presentation. They’re on the Curiosity rover, the OSIRIS-REx craft that just launched itself to an asteroid, the Juno Jupiter mission, and the space station, as well as other current and future ventures.
Plus, adds Whitacre, they’re incredibly common in the aerospace sector generally and satellites in particular.
These batteries make good aerospace solutions because they pack wallops of energy relative to their size, hold a high amount of charge over their lifetime, and don’t lose that charge quickly when left alone. That’s exactly what you want in a space battery, which has to live long and prosper in the vast, empty off-Earth.
And so on systems that actually fly, NASA’s batteries undergo tons of oversight, from procurement to test after test after test. If a battery had inherent flaws, says Whitacre, engineers would know long before it went to space. “I’d be surprised if we ever saw this kind of thing occur in a flight project,” he says.
But if a battery cell or its management system happened to fail—or, as in RoboSimian’s case, failed to foresee a problem because of one cell’s faulty readings—a spacecraft may have inadequate shielding to contain the potentially resultant explosion. Shielding is heavy and every ounce counts when you’re trying to heft stuff to space.
RoboSimian is a non-flight technical project, and JPL is currently looking at how it can be used to “assemble orbital structures, like super big telescopes,” says Kennedy. If future ape-y robot ever went to space, it would go through the full zoo of tests. But because this particular robot wasn’t meant to fly, it—and all other ground-based NASA projects—was subject to less rigor. On top of that, some agency protocols are out-of-date, Lee said in her presentation, before stating that the agency needs to improve and update.
Because you know what they say: With great power comes great responsibility.
A basic pendulum is a mass at the end of a string that swings back and forth. It seems simple, and it appears in most introductory physics textbooks. But it's not a trivial problem to solve for the motion of this mass on a string.
Traditionally, the introductory view of the pendulum is to show that for small amplitudes the motion of the mass is like a simple harmonic motion (motion of a mass on a spring) with a period of oscillation that depends on the length of the string and the local gravitational field.

Here is an extra fun fact. A pendulum with a length of 1 meter has a period of about 2 seconds (so it takes about 1 second to swing across an arc). This means that there is a relationship between the gravitational field (g) and Pi. But really, it's fairly difficult to lead a student through the derivation of this expression for the period (at least it's difficult for an introductory physics student). It's still useful to look at pendulums in the physics lab because you can very easily measure both the period and the length and see if they do indeed fit the expression above.
The real problem is the nature of the tension force in the string. In order to model the motion of an object (like a mass on the end of a string), you need to find all the forces on that object. These forces fall into two types:
If you want to model the motion of an object with deterministic forces, it's fairly straightforward. Just use the following recipe. Break the motion into small time steps. During each time step:
But this doesn't work with the pendulum. The tension in the string of a pendulum is clearly a force of constraint. Sure, the direction of this tension force is in the same direction as the string but the magnitude changes to whatever value it needs to be to keep the mass at the same distance from the pivot point. This means that in order to make a numerical model for a pendulum, you need to use a trick.
There are three different ways you can model the motion of a pendulum. I have looked at these methods before, so let me just give a short review. Notice that the title of that post is "a third way." In that case, I was counting two different methods to get a differential equation—but now I'm calling those the same method.
If you assume the mass is confined to move in a circular path, then you can reduce this to a one dimensional problem with the angle of the pendulum as the only variable. The only force that changes this angular position is the angular component of the gravitational force. With θ being the angle of the string as measured from the vertical, I can get the following expression:

There is a simple solution to this differential equation by assuming a small amplitude of oscillation (and thus a small angle). In this case, sin(θ) is approximately equal to θ and you get the same expression that you have for simple harmonic motion.
The problem with the pendulum motion is that the tension is a constraint force. Well, what if we make it a deterministic force? If the string is replaced with a very stiff spring, it should be an easier problem.

This method can work fairly well. Here is a numerical model that displays the angular position for both method 1 and 2.
Just click the "play" button to run this. If you want to change some of the code (and you probably should), I have left comments to indicate which things you could change. Don't worry, you won't break anything. Just click the "pencil" icon to switch to the code mode to edit.
Really, you should play around with the values for mass, spring constant (k) and time step (dt) to see how well this model agrees with the differential equation. Hint, try looking at both models to see which one is better at conserving energy. Yes, you can consider that a homework assignment if you like.
I can use the usual numerical model method if I can find an expression for the tension during each time step. Let's take a look at the forces on the mass during a swing.

I already know the direction of this tension force—it has to be in the same direction as the string (because strings only pull). But what about the magnitude? Suppose this mass is at some angle θ and moving with a velocity magnitude of v. In that case, I can add up the forces in the direction of the string (I will call this the r direction).

With the net force in the r-direction, I know this must also be equal to the mass of the object multiplied by the acceleration in the r-direction. Since the object is moving in a circle with a radius of L and a speed of v, it will have a centripetal acceleration towards the center of the circle (in the direction of the tension).

Now I have an expression for both the magnitude and direction of the tension force (based on the angle and the velocity). With this, I can just add a line into my numerical calculation loop and determine the vector value for the tension force. After adding this to the gravitational force, I can use the momentum principle—that should work.
Here is this method as a numerical calculation. I have again included the solution for the differential equation (for comparison).
Again, click the play button to start this. Also, you should play around with the code.
Why does anyone need to use this third method for the motion of a pendulum? Really, it's all about introductory physics courses. Although the real solution to the pendulum motion is complicated, it's still a great experiment for lab. It's very easy for students to measure the period of oscillation of the pendulum and to change things like string length or amplitude.
With this third method, students can also create a numerical model for the motion using a method similar to the that for calculating the motion of a mass on a spring. Better yet, they can easily change the starting angle for the pendulum and see that the period does indeed depend on amplitude, especially with the angle gets large.
Now for some homework questions.
The US loves a good pumpkin: the Great Pumpkin from Charlie Brown, that Jack-o-lantern headed guy in The Legend of Sleepy Hollow, the pumpkin spice latte. The king of gourds is all over fall-related popular culture. And by the time October rolls around, they're all over supermarkets, farm stands, and front doorsteps, too.
To feed that national enthusiasm, every year American farmers grow a whopping billion pounds of pumpkin—gourds ranging from tiny Munchkins weighing less than a pound to heftier varieties like Grower's Giants, Monster Smashes, and Prizewinners that clock in at well over 100. On average, Americans consume (or decorate with) about 3 to 5 pounds of pumpkin each, so these days pumpkin farmers need a lot of space to grow a big enough crop.
According to the USDA Economic Research Service, pumpkin patches take up about 50,000 acres altogether, and most of that area is in just six states: Illinois, Ohio, Pennsylvania, New York, Michigan, and California. And while pumpkins may not be the first thing to come to mind when you're thinking about California crops, the golden state's pumpkin patches are actually the most productive in the country—at about 24,000 pounds per acre.
McGrath Brother's Great Pacific Pumpkins, a family-owned grower that distributes pumpkins to Southern California and Nevada, contributes about a million pounds to California's pumpkin total. You can see how they take their big orange gourds from seed to sprout to store-ready in the video above. It's a trickier process than you'd think, involving months of preparation, two types of irrigation, and boxes on boxes of imported bees.
It also turns out that pumpkin farmers have a similar problem to their customers: When the pumpkin's seasonal reign is over, nobody's quite sure what to do with the leftover gourds. But rather than wait for their pumpkins to deflate into a stinky mush on their doorstep or wait for an angsty teen to come by and smash them, the McGrath brothers have a better plan.
Their pumpkiny excess gets funneled to charitable organizations, and, more whimsically, to the Santa Barbara Zoo. According to Trent Barnhart, the zoo's animal nutritionist, the animals go through about three to four pickup trucks full of pumpkins yearly from about October through December, and especially on Thanksgiving, when the zoo has its annual Pumpkin Smash.
The keepers make sure that every animal—from fish to tortoises to bears to gorillas—gets a pumpkin as a food source, or as some form of pumpkin enrichment. (In layman's terms, that means they get to do whatever the heck they want with a pumpkin: roll it around, eat it, smash it, hang out inside it, it's all fair game.) "The keepers try to think outside the box," Barnhart says. "We can turn pumpkins into a feeder for a small carnivore like a meerkat, or put it in the water to interest a crocodilian or even a penguin."
It's a favorite activity for all the animals, but according to Barnhart, nobody loves it more than the elephants. "It’s definitely a treat compared to their regular food source," he says. Seasonal pumpkin treats: They're not just for Starbucks anymore.
It’s a sleepy summer Friday at Lawrence Berkeley Lab’s Advanced Light Source. The particle accelerator operates at a constant, gentle hum—quieter than you’d expect for a synchrotron that whirls electrons to just short of the speed of light. Most of the 40 experimental beam line stations lie empty.
But one X-ray beam is a hub of activity—an arts and crafts session, by the look of it. The researchers crowding the narrow galley huddle over scraps of papyrus paper, streaking them with metallic paint markers, pencils, and pens. They roll the samples up onto dowels, or crumple them up, or fasten them to each other in layers. The idea? Devise creative ways to hide the ink out of sight, and see if X-rays can uncover it.
It’s a space-age solution to an ancient problem. For more than a century, archaeologists have dismantled mummy coffins, also known as cartonnage, in a hunt for literary treasure. In ancient Egypt, undertakers entombed the departed middle-class in sheets of papyrus thrown out by local scribes, hiding the recycled wrapping with a layer of paint and plaster, or gesso. To uncover the text—everything from bills of sale to the rare castoff of Greek literature—collectors use invasive methods, including massaging intact coverings in a sink full of Palmolive suds.
The trouble is, it’s impossible to know if you’re searching for Sophocles or a shopping list before dissolving an artifact.
Mike Toth hopes to take the guesswork out of that hunt. A private imaging expert specializing in cultural heritage, he’s partnering with archaeologists, physicists, and engineers from Berkeley, Duke, UCL, and Stanford to develop imaging tools that can read the text buried in these objects without pulling them apart.
Reading those hidden layers of papyrus is like rummaging through an old, forgotten filing cabinet. “These contain the lives and challenges of ordinary people,” explains Joshua Sosin, a professor of classical studies at Duke—particularly the lives of women, who are largely left out of the historical record. “We have hate mail, the strange diary ramblings of a hypochondriac, contracts and bills of sale.” And the occasional relic: Christian scripture or a long-lost literary treasure.
Most often, an archaeologist with a lead on some intriguing ink won’t head straight to the particle accelerator. Toth jets around the world with equipment for multi-spectral imaging, which floods an artifact with light at a series of increasing wavelengths—purple to red to infrared—in a kind of slow-motion psychedelic light show. Each wavelength glances away differently depending on the material it encounters, yielding a series of images that define areas invisible to the eye. He's used the method to pick out mathematical proofs by Archimedes smeared over in the Middle Ages, and a fingerprint that clasped an early draft of the Gettysburg Address.
For mummy cartonnage, multi-spectral radiation is a good baseline. But things get complicated fast. Unlike the paper of the Gettysburg Address, the papyrus layers are haphazard, fused and interlaced with plaster into what Toth calls a “papyrus mâché.” Add to that the folds and wrinkles of age and layers of mold and grime, and you’ve soon got a puzzle worthy of a particle physicist.
That’s where Stanford physicist Uwe Bergmann comes in. He was studying photosynthesis in spinach, which involves detecting trace metals, when he stumbled upon an article about Toth’s work on Archimedes. The secret to revealing the hidden text, he reasoned, could lie in the composition of the ink, which could contain heavy elements like bromine or iron. Fire X-rays at them and they’ll emit unique fluorescent signatures of their own, indicating the presence of ink within the mess of the papyrus mâché. “If we can study these metals at very low concentrations,” Bergmann says, “why wouldn’t we use that same method to image and read the text?”
That's true of many of the inks used on papyrus as well—but not all of them. Just as you could reach for a number two pencil instead of a gel pen to scribble down a note, some ancients inks are carbon-based, and thus barely discernible from the papyrus.
It’s problem cases like those that brought Bergmann's team across the San Francisco Bay to the particle accelerator at Lawrence Berkeley. Ancient papyri have been scanned here before, but today scientists are working with test papyrus to figure out which techniques and energy levels work best. Typically, those levels are lower than you'd think—as low as 6,000 electron-volts, far less than your last dental X-ray. But the images produced at Berkeley hone in at 3-micron resolution—less than the diameter of a human red blood cell. With phase contrast imaging at that resolution, you can ideally see the faint outline of the text on the papyrus, and even the shallow impressions made as writing implements etched the fibers.
The researchers are currently focused on making their data freely available online. By pooling everything they learn from their techniques—multi-spectral imaging, X-ray phase contrast, fluorescence, and others—they can begin to account for the vast diversity of the cartonnage material. That could also help them downsize: could an accelerator, for example, eventually be swapped out for a handheld form of phase-contrast imaging? (It’s proven tricky to schlep ancient artifact five minutes uphill from Berkeley's campus for imaging, much less ship in an object in London. That’s part of the reason why it's simpler to work with test papyrus.)
Eventually, that might mean a surge of new discoveries in a field that has had relatively few new documents to study in decades. Nearly a century ago, massive excavations yielded what felt like a limitless supply of papyrus from the linings of human cartonnage and stuffings of crocodile mummies. Just down the hill from the accelerator, at UC Berkeley’s Tebtunis Center, acting curator Derin McLeod pulls out one of the prizes of that era: a lost play, Inachus, by Sophocles. For 80 years, scholars have painstakingly pieced its fragments together, often making discoveries on the basis of a single word or character.
For now, scholars like McLeod are satisfied learning from the papyrus extracted a century ago. “Apart from destroying a mummy, washing away is a reckless way to deal with something where the littlest thing can be really interesting," McLeod says. “I would dearly love more Sophocles. But that does seem a bit unfair.”
Even simply knowing whether text is buried in cartonnage or not would be a start. These days, academic scholars have sworn off invasive methods—only private collectors use them to search for potentially invaluable innards. “At the very least, we want to say there’s no text there and don’t even consider tearing this apart because you’re just going to destroy an object,” says Toth. Private owners of ancient artifacts will still be free to do what they want with them. But soon, the researchers hope, they may think twice before dissolving them in the sink.
You know the deal with the sun: Don't look right at it. Don't fly too close to it. Pretty basic stuff. Not that NASA heeds that advice. For 10 years now, two spacecraft have been orbiting our nearest star, staring into it to unravel its secrets.
The region between Earth and the sun, a distance of some 93 million miles, teems with solar flares and solar wind and charged particles. The two Solar Terrestrial Relations Observatory probes, dubbed Stereo A and Stereo B, follow orbits just ahead and behind the Earth to provide a stereoscopic view of it all. (Hence the acronym "Stereo." So punny, NASA.) "Until Stereo, all we had were flat images," says Eric Christian, an astrophysicist in the heliophysics division of NASA's Goddard Space Center. "So we couldn’t see things like solar flares, ribbons, prominences in 3-D."
Stereo B went dark about two years ago (we get why they didn't change the name to Mono, but it still feels like a missed opportunity), but NASA considers the mission a success. Stereo's dual-angle imaging capability helped confirm that solar wind is solar plasma drifting too far from home: As the pull of the sun's magnetic field weakens, the plasma acts more like a gas, streaming out to fill the space around it.
Coronal mass ejections are similar, but more forceful. "Coronal mass ejections are billions of tons of material leaving the sun at a million miles an hour. So if solar wind is a constant background ocean, coronal mass ejections are waves on top of that," says Alex Young, another astrophysicist in the heliophysics division at Goddard. "We have a much better understanding of their structure, how they travel, after being able to see them in detail with Stereo."
The goal with solar energy particles—charged particles accelerated to almost the speed of light by shock waves coming off a coronal mass ejection—was similar: figure out how these things move, and where. "The particles interact with the sun's magnetic fields as they travel along, they don’t have a straight path," Young says. Rather than flowing straight out in a targeted burst, the particles fan out from the sun latitudinally, like buckshot. "We were really surprised to observe the particles at both crafts," Young says. If the mission weren't broadcasting in stereo, scientists wouldn't have fully understood the particles' trajectory.
These insights are more than academic. Coronal mass ejections and solar energy particles are electromagnetic, and threaten any technology in their path. "When spacecraft are bombarded, they can get charged up, and it's like running sock feet across the carpet and touching a doorknob," Young says. "They will randomly discharge and knock out systems." Stereo plays a key role in a solar weather monitoring system that NASA and NOAA use to warn spacecraft and aircraft flying over the North Pole to the risk of solar flares or charged particles from an ejection.
Computers aren't the only things scrambled by solar weather. If solar energy particles sound a little like cosmic radiation to you, it's because they behave in similar ways—in space, and in the body. Like any radioactive particle, they wreak havoc on DNA, and the solar energy can be so intense that it causes radiation poisoning. Stereo's advance weather warnings are an important cue for astronauts on the International Space Station to shield themselves.
Not to say that solar weather is all about death and destruction. Billions of years ago, the sun was much dimmer, and emitted far less light. That's puzzled scientists: To get life going, you need energy, and it didn't seem like a weaker sun could provide enough to kickstart the process. "People have theorized about lightning, but people are beginning to think about the sun being more active then," Young says. And an active sun is one that's spitting out a lot of coronal mass ejections and charged particles. So it's possible that those energetic particles could have been bombarding Earth, supplying the energy to give priobiotic material a nudge in the right direction. Seems like staring into the sun might have been a good thing after all.
Slide:  1 / of  10.
Caption: 
Caption: In the Cybathlon, pilots with complete spinal cord injuries take part in a bike race with the help of functional electrical stimulation.ETH Zurich/Alessandro Della Bella
Slide:  2 / of  10.
Caption: 
Caption: In this team event, competitors use powered arm prosthesis to complete a series of tasks. Zurich/Alessandro Della Bella
Slide:  3 / of  10.
Caption: 
Caption: Team Avalanche competes in the powered wheelchair race.ETH Zürich/Alessandro Della Bella
Slide:  4 / of  10.
Caption: 
Caption: Team Mahidol competes in the computer interface race.ETH Zürich/Nicola Pitaro
Slide:  5 / of  10.
Caption: 
Caption: Team Imperial GBR competes in the powered arm prosthesis race.ETH Zürich/Nicola Pitaro
Slide:  6 / of  10.
Caption: 
Caption: Team OssurPowerKnee competes in the powered leg prosthesis race.ETH Zürich/Nicola Pitaro
Slide:  7 / of  10.
Caption: 
Caption: A participant with limited mobility can climb steps with the help of an exoskeleton.ETH Zurich/Alessandro Della Bella
Slide:  8 / of  10.
Caption: 
Caption: Team Meltin competes in the functional electrical stimulation bike race.ETH Zurich/Nicola Pitaro
Slide:  9 / of  10.
Caption: 
Caption: Team Varileg competes in teh powered exoskeleton race.ETH Zürich/Alessandro Della Bella
Slide:  10 / of  10.
Caption: 
Caption: A competitor in the powered leg prosthesis race.ETH Zürich/Alessandro Della Bella
In pop culture, cyborgs can fly, throw cars, and blow up buildings. Nobody did any of those things at the world’s first-ever cyborg Olympics—the Cybathlon in Zurich, Switzerland, held earlier this month—but the action was just as miraculous for a different reason. Using the latest bionic technology, disabled competitors paired up with prosthetics developers to accomplish tasks ranging from bread slicing to bike racing. Of the 59 teams, these three triumphed and scored top marks.
Many Small Steps
In 2012, NASA teamed up with roboticist Peter Neuhaus to build an exoskeleton for space exploration. Out of that project grew Mina v2, a robotic suit that moves paraplegic competitor Mark Daniel across the floor. By operating a joystick and a button on his crutches, Daniel can manipulate the six actuators positioned along his legs. Daniel won’t be traveling to Mars anytime soon, but he will be walking down ramps, over stones, up stairs, and across tilted pathways in the Cybathlon, bringing home silver in the exo contest.
Armed Force
When Claudia Breidbach noticed that no women were competing in the arm prosthetic event, she signed up. For years, the German skydiver has been jumping out of planes with a simple prosthesis. At the games, she used Touch Bionic’s i-Limb Quantum model (shown)—five indepen­dently articulated fingers controlled by muscle contractions in her remaining forearm—for decidedly more earthbound tasks: assembling a puzzle, slicing a loaf of bread, and buttoning a blazer. Challenging the status quo ended up paying off: Breidbach came in fourth place.
Virtuous Cycle
Vance Bergeron biked over 4,000 miles a year before he was hit by a car on the way to work. Now tetraplegic, he can’t move his legs, has only partial arm control, and has to actively remind himself to breathe. But in the years since his accident, he has brought together an international team of engineers to develop the Carbon TetraTrike, a tricycle that electrically stimulates his muscles at just the right frequency and intensity to get him back on the road—in time for the Cybathlon’s 750-meter race. The bike pilot clocked in results that put the team in the top ten.
In the summer of 1995, a blistering heat wave settled over Chicago for three days. It killed 739 people, making it one of the most unexpectedly lethal disasters in modern American history. No statistical models of the heat wave predicted such a high death toll. Researchers in the American Journal of Public Health reported that their analysis “failed to detect relationships between the weather and mortality that would explain what happened.”
Just as mysterious as the number of fatalities was the way they were distributed across the city. Several of the most deadly areas were entirely black and disproportionately poor, but so were three of the least deadly. Adjacent areas that looked alike—like Englewood and Auburn Gresham, two hyper-­segregated black South Side neighborhoods with high poverty and crime—suffered vastly different effects.
Scientists who study urban breakdowns like this usually focus on hard-line infrastructure: electrical grids, transit networks, communications systems, water lines, and the like. And to be sure, Chicago’s aging infrastructure was woefully equipped for extreme heat. The power grid failed, leaving tens of thousands without air conditioning. Roads buckled and drawbridges locked, leading to gridlock and long ambulance response times. But those failures blanketed the entire city; they didn’t explain the patchwork death toll.
As a young sociologist who grew up in Chicago, I wanted to figure out why the heat wave killed who it did, where it did. So I set out to examine those pairs of “neighboring neighborhoods” that should have fared similarly but didn’t.
Englewood and Auburn Gresham may have looked similar on paper. But when I got to know them at street level, they came to look like different worlds. Englewood had been hemorrhaging for decades: first the employers; next the banks, groceries, and restaurants; finally the people. Residents described the area as “bombed out” and “abandoned.” Empty lots, boarded-­up houses, and broken, uneven sidewalks discouraged people from going outside, especially older people. During the heat wave, the residents of Englewood tended to hunker down in the safety of their homes—which became brick ovens. Englewood’s death rate was among the highest in the city.
Auburn Gresham, on the other hand, never lost its core institutions or its people. Stores, restaurants, community organizations, and churches animated its streets, and people hung out on the sidewalks. Older people there belonged to block clubs; residents assured me they knew who they had to keep tabs on during the heat wave. Auburn Gresham has long been regarded as one of the worst neighborhoods in Chicago; but its death rate, three per 100,000, was among the lowest in the heat wave—far lower, in fact, than many of the wealthy white neighborhoods across town.
Throughout the city, the variable that best explained the pattern of mortality during the Chicago heat wave was what people in my discipline call social infrastructure. Places with active commercial corridors, a variety of public spaces, local institutions, decent sidewalks, and community organizations fared well in the disaster. More socially barren places did not. Turns out neighborhood conditions that isolate people from each other on a good day can, on a really bad day, become lethal.
This is important, because climate change virtually guarantees that, in the next century, major cities all over the world will endure longer, more frequent, and more intense heat waves—along with frankenstorms, hurricanes, blizzards, and rising seas. And it’s inevitable that cities will take steps to fortify themselves against this future. The first instinct of urban leaders is often to harden their cities through engineering and infrastructure, much of which is indeed pretty vital. But research keeps reinforcing the lessons of Englewood and Auburn Gresham. Just as the temperature of a heat wave, the height of a storm surge, or the thickness of a levee, it’s the strength of a neighborhood that determines who lives and who dies in a disaster. Building against climate change can either support vibrant neighborhood conditions or undermine them. We know how to do both.
On October 2012, Superstorm Sandy smashed into New York. With 30-foot waves and 14-foot surges, the storm killed 24 people on Staten Island alone, ripped into the Jersey shore, and swamped lower Manhattan, one of the most densely populated zones in the US and home to thousands of public housing units, massive hospitals, major underground transit hubs, and several of the world’s largest corporations and financial institutions. When a major electrical substation in the East Village took on 4 feet of water, it exploded and snuffed out power for about 250,000 people below midtown. The outage left some of the most impoverished and some of the most affluent people in the city alike stranded on high floors of apartment buildings without water, electricity, or elevator service for nearly a week.
Like the Chicago heat wave, Sandy turned up evidence for the importance of social infrastructure. A study conducted by the University of Chicago’s National Opinion Research Center and the Associated Press showed that residents of neighborhoods with low levels of social cohesion—as measured by how much people said they trusted their neighbors—reported longer recovery times. Much of the initial response to the storm, however, focused on hard infrastructure. Prominent climate scientists and engineers called for vast, colossally expensive seawalls around big cities and on coast lines.
Officials have started to embrace the idea that social infrastructure is as essential to resilience as the built stuff.
Even in pure engineering terms, sea gates and seawalls can impart a false sense of security: They can accelerate coastal erosion, and if they fail, they can fail catastrophically. They also erode the quality of neighborhoods; when an oceanfront area turns into a fortress, people lose their connections to the water, and street life dries up. Who wants to live behind an enormous seawall? (Plus, storm surge has to go somewhere. Who wants to live where the wall ends?)
Luckily, officials have started to embrace the idea that social infrastructure is as essential to resilience as the hard stuff. In 2013, I started serving—at the behest of the White House—as the research director for an international competition called Rebuild by Design. The competition’s purpose was to allocate around $1 billion for major projects that would make the areas affected by Sandy more resilient against climate change and serve as pilots for the rest of the country. And a major requirement of the competition was that the projects should improve social infrastructure.
The six winning plans were announced in 2014. The highest-profile project, by architect ­Bjarke Ingels and the BIG Team along with One Architecture, essentially swathes lower Manhattan in a fortress of storm protection disguised as a smorgasbord of public space. The portion of the design proposed for the Lower East Side—which is, for now, the only funded part of the project—lines the waterfront with lushly planted berms that give pedestrians easier access to a slew of amenities on the water’s edge. The berms, which are 18.5 feet at their peak, absorb storm surges when necessary, but their everyday function is just as important: serving as parklands and recreational areas for people who live in an especially gray and unpleasant part of an especially gray city.
People are realizing that when the floods come or the heat wave settles, neighbors are the true first responders.
Another winning design—far more low-key and far less expensive—will subtly transform the coastline of Staten Island. Being directly exposed to the Atlantic, Staten absorbed waves so large during Sandy that they tore through communities blocks from the ocean, where no one expected a deluge. Working from computer models of waves and tidal flow, the landscape design firm Scape proposed a necklace of submerged reefs and oyster beds to rim the island’s Atlantic coast—partially man-made, partially natural structures that will promote sedimentation and absorb a tremendous amount of wave energy. But not all of it. Scape’s plan makes a point of acknowledging the inescapable fact that water is coming: Part of the project even launches a new school curriculum to teach kids on the island how their fate is linked to the fate of the oceans. It also links people in the area to each other, with plans for the construction of several cultural and educational hubs along the shore.
Neither project is under construction yet; the plan for lower Manhattan has received $335 million dollars in federal funding, and the Staten Island project has received $60 million. Both could get steered off course. Late-­stage budget cuts could reduce the Lower East Side’s verdant berms to an ugly and imposing seawall, exactly the kind of project that Rebuild by Design was supposed to reject. But so far the plans have wide support from local and federal offices, and other cities around the world have taken notice. People are realizing that when the floods come or the heat wave settles, neighbors are the true first responders. Next up, we’ll be able to focus on an even more urgent problem: reducing our greenhouse gas emissions before there’s no way to adapt.
Eric Klinenberg (@EricKlinenberg) is a professor of sociology and director of the Institute for Public Knowledge at New York University. He is a coauthor (with Aziz Ansari) of Modern Romance: An Investigation.
This article appears in our special November issue, guest-edited by President Barack Obama. Subscribe now.
Men think they’ve got it rough finding love. Oh, bars are the wooorst place to meet women. And the drinks are sooo expensive. But in the animal kingdom, the males got it easy. The true burden lies with the female, who expends enormous energy producing eggs and, in the case of mammals, bearing and looking after the young. But what if you’re a hermaphrodite, like some species of marine flatworms? Who’s going to bear the maternal burden there?
Whoever loses the bout of penis fencing, that’s who. In coral reefs, certain species of flatworm do battle with their members.
It starts off innocently enough. Two often brilliantly colored flatworms approach each other and nuzzle a bit. But before long the calm departs, as each rears up and exposes its weapons: the two sharp white stylets that are its penises. Like human fencers, each flatworm will juke and stab, simultaneously trying to inject its partner with sperm anywhere on its body while doing its best to avoid getting inseminated itself. And this can go on for as long as an hour until the two retract their double penises, lower themselves, and go their separate ways. When the struggle is over, both can end up pockmarked with white stab wounds filled with sperm, and you can see pale streaks running along their bodies, branching rivers of semen on their way to fertilize the eggs.
Now, you might be asking why. Why evolve violent “traumatic insemination,” or more specifically and hilariously, “intradermal hypodermic insemination”? The problem is that the two flatworms have the same interest: Neither wants to be the female (I know that sounds sexist, but bear with me here). Developing those eggs is a tremendous energy suck, not to mention that the loser is deeply wounded on top of being knocked up. The winner gets to pass down its genes without taking the trouble of raising the young.
But here’s the weirdest part. Natural selection dictates that if the tapeworm’s going to get stabbed, it’s in its best interest to get stabbed a whole lot. The most accomplished fencers are the ones who will have the most reproductive success, and their genes are what other flatworms want to pass down to their offspring, who will in turn be more likely to become skillful combatants and fertilizers. It’s one of nature’s cruelest ironies: The flatworm doesn’t want to be stabbed with a penis and inseminated, but if it must, it may as well get stabbed with a penis and inseminated thoroughly.
Things get even weirder with another type of flatworm, this one a transparent, microscopic species. It, like our beautiful seafloor variety of flatworm, mates by injecting its partner with sperm. But it seems that the tiny flatworm can really feel the pangs of loneliness: If there aren’t any partners around, it uses its stylet to stab itself … in the head, a maneuver known as selfing. The stylet is at the tail, while the head is of course at the other end, so with a dexterous bend the flatworm can jab itself right in the noodle. The sperm then makes its way down the body to fertilize the eggs. So in a pinch, the flatworm can reproduce all on its own. The researchers who discovered the behavior cautiously referred to it as hypodermic insemination, not traumatic insemination (as in the aforementioned fencers), because they weren’t sure if the creature seriously injures itself with the stab to the head. Not even kidding here.
Now, flatworms aren’t the only creatures out there engaging in such shenanigans. Far from it. In case you needed another reason to fear/despise/be grossed out by bedbugs, they’re reproducing by traumatic insemination in our sheets. A male will puncture a female’s exoskeleton with his genitalia and pump his sperm into her body cavity—no trifling matter when bedbugs rely on their tough shells to protect them from the elements. Indeed, female bedbugs have evolved an immune response: proteins that erode the cell walls of bacteria, helping them ward off infection.
Such is the push and pull in the battle of the sexes. As one side evolves an attack, the other evolves a defense, nature creating problems and then solving them. The issue comes down to the meaning of life: reproduce at all costs. This can put the sexes in conflict with each other—or, in the case of the tapeworm, the single hermaphroditic sex in conflict with others of the single hermaphroditic sex—particularly when females need to maintain some measure of control over who they mate with to ensure they’re picking the best genes. And perhaps nowhere is this kind of sexual conflict more dramatic than among ducks, whose males are notoriously forceful with their mating. Females have evolved a vagina that corkscrews to try to keep out the male’s penis, which corkscrews in the opposite direction (and can grow up to fifteen inches long). Some duck vaginas even have pockets that branch off into dead ends, frustrating the male’s efforts.
The idea that animals can be choosy about their mates, and that such choosiness will drive the evolution of certain characteristics, was one of Charles Darwin’s more brilliant realizations. Known as sexual selection, it drew ridicule in Victorian England, a patriarchal society that found the notion of female choice laughable, to say the least, especially when it came to sex. A notable dissenter, though, was none other than Alfred Russel “So What If It’s Only One ‘L’” Wallace, the phenom naturalist who had simultaneously developed the theory of natural selection on his own. (Charles Darwin scrambled to publish On the Origin of Species after receiving a letter from Wallace, an acquaintance who would later become a good friend, pontificating on his ideas. But that was only after colleagues presented the ideas of both men to the Linnean Society of London.) Wallace didn’t think animals had the brainpower to make these choices, except when it came to the ladies of our own species. He wrote that “when women are economically and socially free to choose, numbers of the worst men among all classes who now readily obtain wives will be almost universally rejected,” thus improving the species. Emphasis his own.
Gotta love that feminist optimism, however wrong he may have been about sexual selection. (To be clear, Wallace was brilliant, so perhaps this isn’t the greatest way to introduce him, and for that I apologize. But we’re all wrong sometimes, and indeed being wrong is fine in science, for it invites others to discover the truth.) Females in the animal kingdom can in fact wield great power when it comes to sex.
So, sure, we human men may not always have the greatest ideas, but at least we’re not penis-fencing. It’s the little things that count, really.
From THE WASP THAT BRAINWASHED THE CATERPILLAR by Matt Simon, on sale October 25, 2016. Reprinted by permission from PENGUIN BOOKS, an imprint of Penguin Random House LLC. Copyright © 2016 by Matthew Simon
On the morning of September 1, just before a routine pre-flight ignition test, a SpaceX Falcon 9 rocket exploded. In an instant, the 277 foot-tall space vehicle and its $200 million satellite cargo disappeared into a ball of flames.
SpaceX has been fairly mum with details on what went wrong last month on Launch Complex 40 at Cape Canaveral. Which makes sense. But, considering it is SpaceX's second launch failure in 15 months, the explosion is a more tangible measure of the company's future than its highly-publicized (and hypothetical) plan to settle Mars. On Friday, the Wall Street Journal reported that the problem may have been operational—rather than a manufacturing or design flaw of the rocket itself. But that does not mean the case is that simple. Nothing involving rockets ever is.
The investigation itself is a collaborative effort between SpaceX, the FAA, NASA, the US Air Force, and industry experts. Together, they are looking at over 3,000 channels of engineering data, along with video, audio and imagery, the company said. Early rumors speculated that SpaceX was worried about potential sabotage by rival space firms, and were reviewing images of strange shadow on a building next to the launch site. But mostly, the investigation has focused on the second stage liquid oxygen tank.
Or more specifically, on the cryogenic helium system inside the liquid oxygen tank. Basically, this is the fuel that would have helped the Falcon 9's cargo—an Amos-6 communications satellite—maneuver from Low Earth Orbit into Geostationary Transfer Orbit. But even that level of detail masks a confounding number of possibilities.
To start, whether a design flaw, or some part of the pre-flight process, caused the explosion. “It could be good if it turns out to be an operational problem, because that is easily remedied, rather than a design or manufacturing problem,” said Scott Pace, director of the Space Policy Institute at George Washington University. “But you have to ask why did that operation failure happen. Was their lack of training or understanding of what was going on?” Pace said he’d like to know whether investigators from SpaceX and the Federal Aviation Administration, which oversees the accident probe, have proof that the fueling failure was what occurred, or did they eliminate other faults and the fueling operation what was remained? “Was it that people felt rushed?” Pace said. “Was there schedule pressure, were they doing something innovative. Was it something else?”
Officially, SpaceX isn’t saying much. A spokesman referred Wired to an earlier statement that “a preliminary review of the data and debris suggests that a large breach in the cryogenic helium system of the second stage liquid oxygen tank took place. At this time, the cause of the potential breach remains unknown.”
Other members of the investigation are playing just as coy. NASA officials in Washington referred questions to the FAA’s Office of Commercial Spaceflight. And the FAA spokesman for that office did not answer questions regarding the probe. Which means experts and amateurs in the space-interested public can only speculate.
The investigation itself might inevitably hit a wall of conjecture. “They are looking at some of the charred remains to see what part failed and was there a manufacturing problem,” says Marco Caceres, a space industry analyst at the Vienna, VA, based Teal Group. “Or was it just a one of those freak accidents? I’m not sure they are every going to know exactly.”
The timeline of the explosion was extremely short – from first signs of an anomaly to loss of data was about 93 milliseconds or less than 1/10th of a second. And though the investigators have access to thousands of datastreams from that short period, they would have had much more if the explosion had occurred when the rocket were launching, or in flight. Then, thousands of cameras would have been streaming info from all angles of the rocket, and additional sensors would be feeding into flight control computers.
For his contribution to the speculation, Caceres noted that a fueling failure could occur from a small piece of brittle metal that begins vibrating, breaks apart, lodges into a fuel line and causes combustion. SpaceX is testing this sort of malfunction at its McGregor, TX, facility.
Finding out what happened to this rocket is important. The Falcon 9 is SpaceX's workhorse, scheduled to carry the brunt of the 70 commercial satellite launches—a $10 billion backlog—waiting to go into orbit. Oh and also, the rocket is part of SpaceX's bid for a $2.6 billion NASA contract to send astronauts to the International Space Station.
Those ISS crew flights have already been delayed until 2018 at the earliest, three years past NASA’s original launch date, according to a NASA Inspector General’s report released the day of the explosion.
SpaceX has lost only two of its 29 launches. Until the investigation bears out, nobody will know if those failures follow any kind of pattern. In the meantime, Musk's company continues to sign up new customers. Should those customers be worried? Well, there's no simple answer.

Volcanoes have been a persistent feature on Earth since the planet condensed out of the primordial nebula of our solar system. The scale and style of that volcanism has changed dramatically over that 4.5 billion years—heck, after Thera bumped into proto-Earth to form the Moon, we probably had a planet-wide lava lake as the molten Earth coalesced and cooled from the collision. However, we lack much of a record of that tumultuous time beyond a few zircon found in younger sediments. Figuring out what exactly the volcanism might have been like that far back is a little bit of scientific storytelling.
If we look at the first few billion years of the planet, we can guess that we might have seen some very different kinds of volcanic eruptions. During the Archean Eon (~3.8 to 2.5 billion years ago), a type of lava that has been rarely seen since erupted in many places across the early Earth:komatiite, a type of magma that is hotter, more liquid, and denser than any lava that erupts today.
Basalt, which is common in volcanic eruptions across the globe, is the most mafic (that is, lowest silica and highest magnesium) lava erupting on modern Earth. It is usually 45 to 52 percent silica by weight and full of plagioclase feldspar, olivine, and pyroxene. When basalt erupts, it is typically over 1100ºC and has a relatively low viscosity so that gas can escape, leading to lava flows like what we see in Hawaii.
But early-Earth komatiites are even more mafic—actually, we're talking ultramafic (yes, that's a real geologic term). Komatiites typically are less than 45 percent silica by weight and are chock full of olivine and pyroxene, making them much more magnesium and iron-rich (and denser) than basalts. A typical komatiite is 18 percent magnesium by weight, roughly double that of your typical basalt. Those changes in composition means that komatiites are hot, erupting at temperatures between 1300-1600ºC. Some komatiite lavas even have chromite crystals, betraying how much chromium they have.
This composition, with abundant magnesium, iron, and chromium, indicates that komatiites are a product of melting the Earth's mantle. The composition of komatiite lava is pretty close to what we might expect if we were able to sample the mantle underneath our feet, so if you melt a good portion of it (maybe 50 to 60 percent!), you'd get a komatiite composition. Basalt is also derived from melting the mantle, but in that case, only 10 to 20 percent is typically melting thanks to fractional melting (the lowest temperature minerals melt first, leaving behind the more mafic minerals/elements).
There are lots of questions about komatiite lavas out there: How did they form and why don't we see them today? What is up with the strange spinifex texture (above) that we see in olivine and pyroxene in komatiites? What might a komatiite eruption have been like?
The most recent komatiite eruption was likely about 90 million years ago and those rocks are currently found on Gorgona Island off the coast of Colombia. These komatiites are likely from a mid-ocean ridge volcanism, so they might be the record of the last gasp of "hot interior Earth." You need to a high geothermal gradient (how hot it gets as you go down) to make komatiite lava because without it being hot, you'll never melt the mantle 50 to 60 percent (*unless you add water, but that's a whole other story). The Earth has lost a lot of heat to space and isn't as productive in terms of generating its own heat from radioactive decay of elements inside the mantle. The interior of the Earth might not be hot enough to produce many (if any) komatiites, and definitely not at the rate it was back when the Earth was only 1 or 2 billion years old.
As for what a komatiite eruption might have looked like, we don't have a lot of evidence. Komatiites found in the rock record indicate that they were mainly lava flows. The heat and composition of komatiites mean that they have a lower viscosity than basalt (possibly 100 times lower), so the lava flows would be exceptionally runny, so many these lava flows would have flowed faster and further than modern basalt eruptions (like Holuhraun in Iceland). However, they were also very hot, so when they did erupt, they probably cooled fast, so maybe they didn't end up traveling far unless they established a lava tube system?
Sinuous Rilles on the Aristarchus Plateau on the Moon. These features may have been formed by komatiite lavas.
Some geologists think that we can see the evidence of komatiite eruptions ... but we have to look at the Moon. Sinuous rilles (above) are winding valleys on the moon that might be a few meters to a few kilometers across and sometimes over 250 kilometers long. It has been suggested that these rilles are volcanic features carved by lava thermally eroding (melting) their way through the lunar crust, likely caused by komatiite lava flows. Maybe on early Earth, we would have seen these lava valleys cut by super-hot komatiite flows. There is even the possibility that komatiite-like lavas are erupting on Io or some of the volcanic features seen by Magellan on Venus may be the product of komatiite volcanism.
They might be a thing of the past, but back in the Archean, komatiites may have been very common. Some geologists postulate that the oceanic crust on early Earth may have actually been komatiite rather than basalt as it is today. All we really know is that the conditions of melting the mantle and the resulting volcanism were not the same back when the Earth was young ... and komatiites are a record of that very different planet.
Shrimp are supposed to be, well, shrimpy. They’re not supposed to pair up Bonnie and Clyde style, dress in silly costumes, and go marauding for starfish to flip over and devour. But the harlequin shrimp doesn’t give a damn about your rules. Check out this week’s episode of Absurd Creatures to learn more!
Find every episode of Absurd Creatures here. And I’m happy to hear from you with suggestions on what to cover next. If it’s weird and we can find footage of it, it’s fair game. You can get me at matthew_simon@wired.com or on Twitter at @mrMattSimon.
The Secretary of State is the frontal lobe of US foreign policy—managing the country’s diplomatic nervous system and its relationships with every other nation in the world. The vast majority of that work is slow and subtle: chipping away at a humanitarian crisis here, greasing the wheels of progress there. Occasionally a big one comes along, something that deals with the whole world, forcing the whole diplomatic brain to work to produce a universal agreement.
The Paris Climate Agreement was perhaps the biggest of all biggies. The UN treaty, drafted last December and set to go into full force this November, seeks to limit the most devastating effects of global warming through a combination of drastic emissions cuts and socio-structural adaptations. This Earth Day, John Kerry signed the treaty, the first time in history the US has officially begun thinking, and therefore acting, in concert with the rest of the world on climate change. In the video above, he discusses the implications with WIRED's deputy editor Adam Rogers.
Here’s what the US is in for: cutting between 26 and 28 percent of its greenhouse gas emissions (based on 2005 emissions levels) by 2025. This is going to require a massive restructuring of the country’s energy infrastructure. Nobody is quite sure exactly how it will look, but in broad strokes coal, oil, and natural gas have got to go. Meeting the Paris goals is also going to require industry-wide changes in agriculture, automotive, commercial air travel, marine shipping, construction, manufacturing, and pretty much every other way people make a living in this country.
President Obama’s Clean Power Plan is the keystone to these goals, as it effectively forces the energy sector to transition from coal to cleaner fuel sources. That plan, however, is currently in legal limbo. And even if it wins the challenges that have been brought forth by numerous Republican-led states and business groups, it (along with a suite of lesser regulations) probably still falls short of meeting the US’s 2025 emissions reduction goal. And that doesn’t even begin to address what might happen if Donald Trump—who believes climate change is a hoax perpetuated by the Chinese—wins the November presidential election.
Which is why diplomacy is so important. With the Paris Agreement in effect, the US is obligated to uphold its end of the bargain. Climate change is now a front-line global issue, affecting everything from trade to geopolitics. If the US reneges now, it loses the world’s trust—and possibly the world’s business. That should be enough to make any future president stop and think.
To feed the 9 billion humans who’ll be living on Earth in 35 years, we’re going to have to double the amount of food available. That would be a challenge even if those same humans weren’t changing the planet’s climate, making it less friendly to farming. But agriculture’s inefficiencies, misuse of fertilizer, and inappropriate crop choices are actually easy to fix. Feeding the world of tomorrow is technologically feasible with existing tools (and some creative thinking). It’ll just take some work.
Problem
Low yield
Farmers will need to produce more food on less land, especially in the developing world.
Solution
Money, seeds, and poop
Seeds bred or engineered for specific soil and climate types and to resist pests or diseases will be key, as will business solutions like One Acre Fund’s combination of fertilizer, finance, and training. You get a big hit just by raising worldwide yields for 16 crops. And then you can stop turning forests into farms.
Problem
Waste
For every 100 calories of food grown, people eat only about 35.
Solution
Sensors and apps
Instead of arbitrary sell-by dates, how about biochemical bacteria monitors so people don’t trash good food? Apps can pair extra food with those who need it. University cafeterias are ditching trays, leading to a 50 percent drop in waste. Oh, and hey: Eat less meat. That’ll let farms grow food for people instead of cows.
Problem
Extreme weather
Droughts and floods powered by climate change are hammering the most productive food-growing regions.
Solution
Insurance and genetics
In India, if rainfall drops below a level that will cause crops to fail, some farmers receive rolling insurance payouts (instead of going out of business waiting till season’s end). Smart seeds can also help; the Drought Tolerant Maize for Africa project has developed new strains to boost yield.
Problem
Data drought
Farmers need access to weather information.
Solution
Access
Monsanto paid $930 million for the data-driven ag company Climate Corporation because the future isn’t just seeds and chemicals. It’s also timely updates on weather, water, and pests. Radios and cell phones can deliver the latest forecasts—news that might help farmers decide, say, whether to plant a drought-adapted crop.
This article appears in our special November issue, guest-edited by President Barack Obama. Subscribe now.
Before Helen Quinn was a famous theoretical physicist, she thought about becoming a teacher. Now, in the second act of her career, she has come full circle, helping to craft the Next Generation Science Standards, which have been adopted by 17 states plus the District of Columbia. But her path to becoming both a world-class physicist and a leader of science education reform was one she almost didn’t take.
Original story reprinted with permission from Quanta Magazine, an editorially independent division of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences
Quinn, who is now 73, grew up in Australia, where she had to decide on an academic focus by her sophomore year in high school. Her father was an engineer, and family conversations often revolved around how things work. “The kind of problem solving that I recommend as useful for learning science was part of our family culture,” she said.
She recalled how a high school teacher encouraged her to become a mathematician, telling her, “Because you’re so lazy, you will never solve a problem the hard way. You always have to figure out a clever way.” But in the 1950s, she said, “the idea that a woman could be an engineer was nonexistent. I once walked into the engineering school at the University of Melbourne, and one guy said, ‘Look what’s got in here,’ and the other one says, ‘You think it’s real?’”
After Quinn transferred to Stanford University in 1962, her adviser encouraged her to consider graduate school, even though, as he explained, “graduate schools are usually reluctant to accept women because they get married and they don’t finish. But I don’t think we need to worry about that with you.” Which made her wonder: “Is he telling me I’m never going to get married?”
Helen Quinn in her Stanford Linear Accelerator Center office around 1977.
Quinn applied to graduate school, but she hedged her bets. “There were no women in the faculty at Stanford at that time in the physics department,” she said. “I didn’t see myself there.” She thought she would “apply for Ph.D. programs because good universities don’t offer master’s degrees in physics, but really I’d do a master’s degree and then go take education courses and be a high school teacher.”
Instead, she went on to make seminal contributions to our understanding of basic particle interactions. In the 1970s, she worked with Roberto Peccei on a proposed solution to the strong charge-parity (CP) problem. The puzzle has to do with why a kind of symmetry between matter and antimatter is broken in weak interactions, which drive nuclear decay, but not in strong interactions, which hold matter together. Peccei and Quinn’s solution, known as the Peccei-Quinn mechanism, implies a new kind of symmetry that predicts the existence of an “axion” field, and thus a hypothetical axion particle. Axions have been invoked in theories of supersymmetry and cosmic inflation, and have been proposed as a candidate for dark matter. Physicists are searching high and low for the elusive particle.
Her work on the strong CP problem and other contributions to particle physics have been recognized with prestigious awards including the Dirac Medal, the J.J. Sakurai Prize, the Klein Medal and the Compton Medal. Meanwhile her attention has shifted back to science education. Starting in the late 1980s she led the science education outreach effort at the Stanford Linear Accelerator Center (SLAC), and she later chaired the National Research Council’s Board on Science Education, which developed the framework that led to the Next Generation Science Standards. Quanta Magazine caught up with Quinn at last year’s International Teacher-Scientist Partnership Conference in San Francisco. An edited and condensed version of the conversation follows.
QUANTA MAGAZINE: What was it like entering the field of particle physics in the 1960s?
HELEN QUINN: It was a very exciting time. The thing we now call the Standard Model was just beginning to take shape, and SLAC had just been built at Stanford. In fact, the reason I became a particle physicist is probably because there were so many people around me who were so excited about the science. But I never at any point said, “I’m going to be a physicist. That’s what I want to do.” It just sort of grew on me as I learned more about it.
You did a year of student teaching.
I did my Ph.D. in four years, and it was an interesting piece of work that got noticed. During graduate school, I’d married. My husband was another physicist, and we took postdocs in Germany. Coming back, my husband was offered a faculty position at Tufts, and I said, “Well, if there’s any town in the country where there ought to be another job, it’s Boston because there are seven universities in the Boston area, or probably more.” But I didn’t get a job.
I thought, “OK, I’ll fall back and I’ll be a teacher,” and I took education courses at Tufts and did the student teaching.
Then what happened?
During that semester when I was doing the student teaching, I happened to run into one of my graduate school friends, Joel Primack, who was then a junior fellow at Harvard, and he said, “Why don’t you come talk to us at Harvard sometime?” At that moment, a piece of research came along which was really fundamental to the development of the Standard Model. Gerard ’t Hooft and Martinus Veltman [who shared the 1999 Nobel Prize in physics] provided a method for calculating the mathematics in gauge theories, which underlie the Standard Model. So I started working with my friend and one other junior faculty member at Harvard, Tom Appelquist, on applying that method to what we call one-loop calculation.
Before the Standard Model, there was a problem with weak interaction theory. You could do the first-order calculation, but the next order (the one-loop calculation) was infinite. So the theory was not well-defined and not stable. We did the first finite one-loop calculation of weak interactions using the new theory. At that point I realized this is drawing me in more than the teaching.
You didn’t like teaching?
I loved the teaching. I hated supervising study hall and the intellectual atmosphere of the high school. So it was not the teaching that put me off as much as it was the intellectual draw of something really exciting going on directly in my field, in my area of interest in physics, that basically was the beginning of the development of the Standard Model. It was an opportunity that I couldn’t turn down.
Later in your career, why did you become involved in trying to fix science education?
After I was elected to the National Academy of Sciences my background in education outreach work meant I was invited to join the Board on Science Education. The opportunity this provided to be involved with science education more broadly was attractive, but more than that it was a chance to learn some interesting things about teaching and learning. As a scientist, if you think you know something without having done any research on it, you probably don’t know. So I said, “Who does understand what’s effective in teaching science?”
There was a study called “Taking Science to School” for which I was part of a committee with people who research learning. I was able to learn how they studied the question: What is most effective in teaching science? That was the beginning of my education about research on learning.
The challenge for me was to understand what the other people in the room were arguing about. At the beginning of that study, I was the physicist, and these were education researchers. And they were having an argument, and I did not know what they were arguing about. I couldn’t discern the differences in their positions because I didn’t know the history.
Later, after the Common Core came along and 47 states adopted common standards in math and language arts, the Carnegie Corporation of New York came to the Board on Science Education and said, “We should be doing this for science, too.” If many states are doing common things in math and language arts, why not think about what they could do in common in science?
You were the chair of the Board on Science Education by that time. What areas of science education did you think needed to improve?
The general conclusion really is embodied in the “Framework for K-12 Science Education” we developed: You have to engage the students in doing things in order for the learning to become meaningful. Just memorizing the knowledge that other people have produced doesn’t really lead to transferable knowledge. The big issue is knowledge that you can apply.
The question is: How do you change learning so that the knowledge becomes much more integrated into the way a person approaches problems outside of school?
What was the biggest challenge for you in developing these standards?
The challenge, but also the fun, of doing it is to try and take a group of people, all of whom have expertise in different areas, and come up with a common view that’s based solidly enough on everyone’s expertise that other people will buy into it and carry it forward. And I think we succeeded with the Framework. Science teachers are generally enthusiastic about the picture we’re putting before them. When I talk to scientists, they’re generally enthusiastic about this way of describing science. So the synthesis works, but achieving it is a group effort. Chairing such a group and bringing it to consensus is a challenging but rewarding process.
And so in some sense, the common view that came out of the Framework became the Next Generation Science Standards.
The standards are based on the Framework, and it helps to read the Framework to understand the intent of them. Standards are, by their very nature, knowledge in pieces. A standard has to be something where you can say: Can the student do that or not?
Essentially, standards are the basis on which you build assessments, and they’re a set of guideposts for teachers and curriculum developers. So standards are in fact not the way to convey the bigger vision. They’re all the little bits and pieces students need to know or be able to do, and in and of themselves, they don’t make sense. Unless they’re built on a bigger vision and unless you have some idea of what that vision is, reading the standards is confusing.
So the Framework is the vision.
The Framework is the vision. The standards are a set of stakes in the ground. If students can do this in third grade, if students can do that in fifth grade, if students can do that in 12th grade, then they have learned sufficient science.
Helen Quinn giving her Dirac Medal lecture in 2000.
You describe the Next Generation Science Standards as three-dimensional science learning. What does that mean?
What I mean is that to learn science, you have to learn core ideas from the disciplines of science. [In physical science, these ideas include matter and its interactions, motion and stability, and energy.] But you also have to learn how those ideas were arrived at, what scientists do, the practices of science, and the practices of engineering, both in order to understand the nature of science and in order to engage in those practices to make the learning your own. That is a second dimension to science learning. And finally, the third dimension is that there are some big concepts which you need in order to know where you’re going and to know which kinds of questions to ask when you’re looking at a new problem. These are concepts such as the fact that explanations in science are about cause and effect mechanisms, or that, in order to decipher these mechanisms, it is useful to define and make a model for the system in which a phenomenon occurs. And those big concepts are very often not taught. Students are sort of expected to get them as a side effect of doing things over and over again.
And you call that third dimension “crosscutting.” Is that meant to imply that you’re cutting across different disciplines?
Right. These are the concepts which apply whether you’re doing physics, chemistry, biology, earth science or any other area of science. These will be useful lenses to look at a problem with.
Isn’t it harder to assess whether students have learned crosscutting concepts and the process of science?
Queensland and other states in Australia in fact do this. Some part of the state assessment is an external exam, but part of it is performance assessments in the classroom that are graded by the teachers. First of all, this approach trusts teachers as professionals, but secondly, it has a cross-check system. If there’s an imbalance between the external testing part and the teacher’s grading of the in-class part, then inspectors come and they watch. So there’s a whole structure developed around having the teachers be part of a professional system and monitoring that system.
Meet the New Math, Unlike the Old Math
Using Math to Repair a 650-Year-Old Masterpiece
The Oracle of Arithmetic Works Best Without Writing Down a Thing
In the US, we have adopted a system of drop-in-from-the-sky external testing where the teachers play no role in it. That’s actually a very inefficient model because the teachers know a lot more about the students than any drop-in test can discover. Assessments that drop in from the sky are designed to be cheap and to be scored by machine; it’s very limited. Mostly it just tests what has been memorized. And having our entire education system designed to have students be able to get high scores on those tests is counterproductive. It drives all the wrong behaviors into the classroom. So we need new types of testing tasks to test whether students have achieved these new three-dimensional standards and to drive the teaching and learning behaviors that we know are more productive.
Now that the standards are out there, what are you focusing on?
My term on the Board on Science Education is up, so I no longer have that particular platform to work from. I go where I’m invited to give talks, to sort of wave the flag and talk at the county level or the state level about what the standards are and why they were developed, and to help people understand how to implement them.
When you talk to teachers, what advice do you give them about making science more interesting for students?
There are two things: first, building learning around observable events or phenomena. And, second, getting students engaged with a question before you give them the answer. We all get much more interested in things if we have a question about it than if somebody is telling us something that we haven’t any reason to know we want to know.
What’s the endgame?
I want educated people. I want citizens who can look at a problem in their community and think like a scientist about the part of the problem that is science. I want high school and college graduates with capabilities that employers want, whether they come from well-educated families or not. I want them to be able to take on a problem and solve it because that’s what employers are looking for. They want you to be able to work on a team; to be given some information, interpret it and use it; to not have to be told: “This is what you do tomorrow.” And all of those things require something more than just being able to repeat back what you were told. So that’s where I’m going. I think it’s a huge equity issue.
Original story reprinted with permission from Quanta Magazine, an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.
Click through the gallery to see this week’s helping of the best the universe has to offer. And if you need more when you’re done but can’t wait until the next one, here’s the entire collection.
Although we’re in the midst of a critical blood shortage, fewer than 10 percent of eligible donors roll up their sleeves to give blood. But it’s a logistics problem as well as a supply problem: There is no central nationwide database to track the availability and cost of blood products, so getting a pint to a patient in need is akin to calling multiple airlines to compare flight schedules and prices.
Shelf Life For Blood Products
—————————–
5 days
Platelets
Up to 35 days
Whole blood
Up to 42 days
Red blood cells
365 days
Plasma
“It’s a massively fragmented patchwork,” says health care entrepreneur Christopher Godfrey. To address these inefficiencies, Godfrey founded Bloodbuy, a Dallas startup whose cloud-based platform allows hospitals and acute-care facilities to shop for blood at the lowest price and from the best available source. Blood banks enter data about their supplies, including expiration dates and prices, and hospitals log in to place orders. Everything is done via Bloodbuy, digitizing processes previously done by phone or (yes) fax.
After a successful pilot project with Texas Medical Center’s teaching hospitals in 2014, the startup launched nationwide and, to date, has facilitated transactions between 25 hospitals and nine independent blood banks. In one study, Brigham and Women’s Hospital in Boston reported savings in excess of $100,000 during the first 45 days of placing orders on the platform.
The ultimate goal is to create a forecasting model that can predict shortages and prevent states of emergency. As for the sting of donating blood, well, that’s up to another startup.
Jennifer Lopez—singer, dancer, actress, and producer—is one America's most successful entertainers. Crispr—repeated genetic sequences that, when combined with Cas-family proteins, are capable of editing DNA—is one of biology's most talked-about developments. Combined, they are ingredients for prime time procedural drama.
We hope. C.R.I.S.P.R. is a TV project her Nuyorican production company is developing for NBC—though the network hasn't officially greenlit a series. The premise: A CDC biologist and FBI sleuth team up to stop a diabolical gene-hacking genius. The twist: Diabolical gene-hacking genius is the CDC biologist's former boss. And obviously, a romantic subplot will blossom between the show's principal investigators.
Problem is, besides the nibbles of plot reported by the The Hollywood Reporter (Assassinate the president! Frame an unborn baby for murder!) nobody outside the production team knows what to expect.
Personally, I trust the genius behind On The 6 to produce a TV show about gene editing. But that doesn't mean I am willing to wait around for NBC to write the damn thing. So I did it for them.
Note: Nuyorican hasn't named the characters (let alone cast them), so (in homage to the Murder, Inc. remix of J.Lo's "I'm Real") my protagonists will be Dr. Lopez of the CDC and FBI Special Agent Rule. And the diabolical gene-hacking genius? Professor Affleck, of course.
C.R.I.S.P.R. Season 1
Episode 1: "Pilot"
Microbiologist Jamie Lopez walks into her CDC lab one morning to a man—Special Agent James Rule—hunched over her bench, staring through her microscope. The two bicker (he's not even wearing eye protection! Just a bandana tied at the forehead!) until he convinces her to peer into the eyepiece. She recognizes immediately what she's looking at: A hacked strand of the president's DNA. Lopez notices a suspicious sequence of A's, G's, C's, and T's, realizes it is a code, and uses a public database to decrypt the message: An assassination attempt at the State of the Union! Special Agent Rule arrives just in time to push the president out of harm's way.
Episode 2: "What to Expect When You're Gene Splicing"
Lopez visits Rule in the hospital. The bullet meant for the president grazed his arm. Rule insists he is fine, and gets released, but collapses as he and Lopez are walking to the hospital's parking garage. Before he gets carted back inside, she uses his bandana to stem the blood flow from his again-bleeding arm. Inspecting the bandana later in the lab, Lopez sees evidence of gene hacking—that bullet was infected with a super-flu. Luckily, Lopez got her post-doc working on genetically enhanced viruses. She reluctantly turns to a technique she'd sworn off—Crispr—in order to hack together an antidote just in time to save Rule's life.
Episode 3: "The Cell"
Episode opens with Lopez staring pensively at a microscope. The super-flu could only have come from a fellow disciple of the Crispr method. Knowledge in hand, she visits Agent Rule at the FBI headquarters. (Thanks to her gene-hacking talents, he is fully healed.) Upon arriving, she is dismayed to see that Rule shares an office with the beautiful and brilliant Special Agent Ashanti. Lopez tells them about the clue she found in Rule's blood sample. Taken aback, the two FBI agents show Lopez a new case they've just been assigned: a mysterious illness outbreak in New York City.
Episode 4: "On the Six"
Lopez, Rule, and Ashanti head to New York, where nearly a dozen passengers aboard the Bronx-bound 6 train have fallen ill in the past week. After some detective work, Rule finds a common thread: All are faculty, staff, or family members of faculty or staff at Fordham University—Lopez's alma mater.
Episode 5: "Gene-ie from the Block"
Ashanti stays behind in New York to track down leads, while Rule and Lopez get called away for a strange case of gene-hacking in Boston: A resurrected woolly mammoth is on the loose in Southie.
Guest starring Anthony Hopkins as the de-extinction obsessed Harvard genius Jorge Chapel.
Episode 6: "Waiting for Tonight, part I"
A freak snow storm traps Lopez and Rule on an Acela train back to New York. Their cautious flirting is interrupted by a call from Agent Ashanti—she followed a lead back to an incinerator room at Fordham, and found it filled with fans blowing air over petri dishes filled with purple goo. As the air passes over, it congeals into snowflakes, which ascend out the incinerator's smoke stack. Standing between train cars, Lopez samples some of the air outside. It is filled with moisture-accreting bacteria. Somehow, someone has used Crispr to hack the weather.
Episode 7: "Waiting for Tonight, part II"
The Crispr-caused snowstorm is threatening to shut down the entire East coast. Rule and Lopez escape from the train, and trudge through the snow to Rule's cousin's house in nearby New Haven. Rule fast-talks his cousin into lending the duo a snowmobile. They race back to the Bronx, and Lopez Crisprs up a warm-air burping bacteria to counteract the snowstorm.
Episode 8: "Humid in Manhattan"
Lopez's anti-snowstorm hack has created balmy, summer conditions in New York—even though it's November. She and Rule get in a heated argument in a bodega over who gets the last poppyseed bagel. The wise cracking bodega guy finally just sells them an everything bagel, with sarcastic advice to pick off all the seasonings except poppyseed. The food hack inspires Lopez, who suddenly realizes who must be behind all the recent gene-hackery: her former mentor, Professor Benedict Affleck.
Guest starring Lin-Manuel Miranda as the bodega shop guy.
Episode 9: "In Living Color"
Lopez takes Rule to her mentor's former Fordham lab to look for clues. The two are attacked by a pack of super-buff Crispr beagles.
Episode 10: "Gigli Apparatus"
A group of neo-Nazi terrorists use Crispr to gene hack a litter of blue-eyed, blonde-haired, super-strong babies. The babies (which resemble 20 year-olds, due to a super-growth gene hack) attack the National Lawn in Washington, DC. Rule, who is Catholic, has a personal crisis about shooting the Nazi babies—because they are technically only a few hours old. Lopez explains that biological aging does not conform to clock time. Just in time, Rule saves the president again.
Episode 11: "Anacondas"
It's New Years Eve, and Professor Affleck has sent Lopez a message: Watch the ball drop. She and Rule discover that Affleck is using the Times Square ball drop as a visual analogy for three-parent in vitro fertilization. He is threatening to unleash a gene hack that will infect New Yorkers with mitochondrial disease.
Episode 12: "This is Me Then"
In the season finale, Lopez is closing in on her fallen former mentor, but falls into a trap. Rule is living it up in Miami when he gets attacked in a club—by a gang of Lopez clones. Agent Ashanti's ex-husband shows up to try and reignite the old flame, and later shows up dead. Written in blood on his bedroom wall is a single word: Asilomar. Cut to credits.
Guest starring Jennifer Doudna as Miami club bartender.
For seven years, the Lunar Reconnaissance Orbiter has circled the moon, hovering just miles above its pock-marked surface. And every day, the craft's on-board camera snaps over 600 photographs of the moon's craters, dunes, and mountains, helping scientists understand lunar geology and topography. But that’s not the only reason to photograph the moon.
“It’s also just because [the images] are beautiful,” says Mark Robinson, the lead scientist running the Lunar Reconnaissance Orbiter Camera at Arizona State University's School of Earth and Space Exploration. “They show the grandeur of the moon, what landscapes look like on another world that’s only three days away.”
Of course, cameras aboard spacecraft like the Apollo and Clementine delivered gorgeous moon photos back to Earth decades ago. But in 2004, when President George W. Bush ordered NASA to return to the moon, no mission had photographed it in great detail from pole to pole. Robinson knew photography would be crucial for identifying landing sites, so he and a team pitched NASA on the Lunar Reconnaissance Orbiter Camera. By July 2009, it was firing away.
The spacecraft orbits the moon 12.7 times a day, providing plenty of photo ops. The system includes a wide-angle camera, small enough to fit in a backpack, that photographs in seven colors at a moderate resolution of 328 feet per pixel. Two much bigger narrow angle cameras, each over four feet long, together amount to a 500-megapixel camera. They see 4,000 shades of gray at a resolution as high as 1.6 feet per pixel—high enough to capture the shadow of the flag Neil Armstrong planted—with shutter speeds as fast as .34 milliseconds. (Timing is critical when you're barreling 3,600 miles per hour through space.)
No one's sitting aboard the spacecraft to snap the photos, obviously. Instead, the system has targeting software that predicts the spacecraft's flight path and schedules about 95 percent of its shots. Robinson's favorite automatically-targeted images are temporal pairs, in which the spacecraft rephotographs an area if the lighting is similar to an existing photograph. A whopping 70 percent of those twinned shots unveil new impact craters and other changes to the lunar surface.
The Lunar Reconnaissance Orbiter's Wide Angle Camera
The coolest images, though, are carefully planned out by Robinson's team. “It’s really fun to think, ‘OK, in a week, we’re flying over a really fantastic beautiful spot on the moon, say the Bruno Crater,’” Robinson says. “‘What would it look like if we flew the spacecraft over 60 degrees and got a view of it in these lighting conditions?’”
Robinson and his crew send bundled three-day command loads every day to NASA Goddard Space Flight Center, which uploads them to the spacecraft. Sometimes they schedule two staggered photographs of the same place to create a 3D stereo image. They can also tilt the spacecraft 60 or 70 degrees on its side for an oblique shot—like what you'd see out the window of a plane. "Those are much more easy to relate to on a human sense," Robinson says. "You get a much more immediate sense of the landscape."
The images come back to Earth through a Ka-band antenna in White Sands, New Mexico. And while Robinson’s day-to-day involves endless paperwork and meetings, he always makes time to process certain manually targeted images himself. He removes electronic noise from the raw files and sends them off for parallax distortion correction. When they come back, he tinkers with them in ISIS editing software to stretch the 12-bit images down to 8-bit tiffs. Then he prints them out, passes them around the office, and sometimes hangs them up in the hallway.
Mark Robinson serves as Principal Investigator for the LROC.
"I’ve been doing this seven and a quarter years, and it still knocks my socks off when the image comes up on the screen,” he says. “It’s really spectacular.” The camera's photographs have shown geological features like thrust faults that indicate the moon is shrinking, as well as volcanic craters that suggest the moon’s volcanic activity is about 1.4 billion years younger than previously thought. And of course, the incredibly detailed maps and images it has produced have also given astronauts a good idea of where to land when they finally return.
Now all that's left is to go back.
*Over 60 images from the LROC are on view in the exhibit *A New Moon Rises at the National Air and Space Museum in Washington D.C.
This story originally appeared on the Guardian and is part of the Climate Desk collaboration.
At first, Yury Scherbakov thought the cracks appearing in a wall he had installed in his two-room flat were caused by shoddy workmanship. But then other walls started cracking, and then the floor started to incline. “We sat on the couch and could feel it tilt,” says his wife, Nadezhda, as they carry furniture out of the flat.
Yury wasn’t a poor craftsman, and Nadezhda wasn’t crazy: One corner of their five-story building at 59 Talnakhskaya Street in the northern Russian city of Norilsk was sinking as the permafrost underneath it thawed and the foundation slowly disintegrated. In March 2015, local authorities posted notices in the stairwells that the building was condemned.
Cracking and collapsing structures are a growing problem in cities like Norilsk—a nickel-producing centre of 177,000 people located 180 miles above the Arctic Circle—as climate change thaws the perennially frozen soil and increases precipitation. Valery Tereshkov, deputy head of the emergencies ministry in the Krasnoyarsk region, wrote in an article this year that almost 60 percent of all buildings in Norilsk have been deformed as a result of climate change shrinking the permafrost zone. Local engineers said more than 100 residential buildings, or one-tenth of the housing fund, have been vacated here due to damage from thawing permafrost.
In most cases, these are slow-motion wrecks that can be patched up or prevented by engineering solutions. But if a foundation shifts suddenly it can put lives at risk: cement slabs broke a doctor’s legs when the front steps and overhanging roof of a Norilsk blood bank collapsed in June 2015. Building and maintenance costs will have to be ramped up to keep cities in Russia’s resource-rich north running.
Engineers and geologists are careful to note that “technogenic factors” like sewer and building heat and chemical pollution are also warming the permafrost in places like Norilsk, the most polluted city in Russia. But climate change is deepening the thaw and speeding up the destruction, at the very same time that Russia is establishing new military bases and oil-drilling infrastructure across the Arctic. Greenpeace has warned that permafrost thawing has caused thousands of oil and gas pipeline breaks.
“There were problems there before, but climate change exacerbates them,” says Ali Kerimov, an engineer at Foundation Research and Production in Norilsk. “We need to study each case separately to understand what awaits us with climate change.”
Global warming has been tied to more frequent forest fires and flooding across Russia, but its impact on permafrost, which covers two-thirds of the country’s territory, is also beginning to be felt. At least seven giant craters have been discovered in Siberia—reportedly caused by thawing permafrost allowing methane to explode out of the ground—and a 12-year-old boy in Salekhard died from anthrax in August after thawing released bacteria.
Arctic islands and the northern coastline—and scientific outposts there—are disappearing into the sea as permafrost thaws, sea ice melts and wave action increases. Valery Grebenets of Moscow State University’s department of cryolithology and glaciology teaches his students 13 “horror stories” about thawing permafrost, including buckling roads and railways, soil runoff killing fish and the release of toxic and radioactive pollutants contained by frozen dams.
Flying into Norilsk at the end of August, when the vegetation of the treeless tundra was already turning orange and spots of snow were on the ground from an early storm, it’s hard to picture this warming. Built by gulag prisoners starting in 1935, the city gets more than six weeks of polar night and up to 2 million tonnes of snow each winter, when the temperature can drop below -51 degrees C (-60F).
But average annual temperatures in the Arctic are rising faster than anywhere else—more than 2 degrees C since 1900, and a 2015 study found increases in soil temperatures across Russia’s permafrost regions over the last 50 years. Soil temperatures in Norilsk increased by almost 1 degree C between 1999 and 2013.
The term permafrost is somewhat a misnomer: While deeper soil remains frozen year-round, the “active layer” of soil extending several feet below the surface thaws each summer. It thaws unevenly, contorting and warping buildings. To avoid this, in the 1960s builders of apartment blocks in Norilsk began drilling holes up to 100 feet deep and pouring reinforced concrete piles that stuck into the permanently frozen soil below. The piles also lifted each building off the ground, allowing air circulation to cool the soil and preventing further thawing.
Engineers didn’t think the soil could start warming so much, however. Data from a Norilsk monitoring station showed the active layer has been thawing earlier and its thickness has increased from three feet to five feet. In addition, climate change has increased precipitation, adding more moisture to the soil that freezes and expands, gradually crumbling the concrete piles. More snow covers the ground and further warms the permafrost.
“In most cases the effect of climate change was not accounted for properly or at all, so the story is not about one building falling, even though there are examples of that, but about thousands of people living in buildings which have the potential to fall,” says Dmitry Streletskiy, an assistant professor of geography at George Washington University.
The problem also threatens Alaska, Canada and other northern territories, but only Russia has cities so far north. Forty percent of buildings in the coal mining city Vorkuta have been damaged, the emergencies ministry’s Tereshkov says. Salekhard, Nadym and Dudinka, the port on the Yenisei River through which Norilsk Nickel ships its products, have also seen deformations, among others. More than 100,000 people are living in buildings in “critical condition” across Russia’s far north, Streletskiy estimates.
At 59 Talnakhskaya Street, an 80-apartment building dating to the 1960s, the sinking corner became visible when a giant crack appeared on the side. Workers cemented it over and propped up the corner with logs, but the deformation continued.
Tatiana, a fire protection engineer who lives in the building with her son and husband, says she found out it was condemned from the TV news, although they had seen cracks and tears in the wallpaper.
“When I saw the television report, I thought they were talking about the building next door. You don’t think that you could be relocated,” she says. “We’ve lived in the building for 15 years, and nothing suggested this would happen.”
The city has been offering residents replacement homes elsewhere. Even the front doors have been removed from many vacated flats, leaving only the occasional ratty chair, empty vodka bottle or Iron Maiden poster. The slight tilt to the worst-hit stairwell creates the same disorienting sensation as the shifting floors of a carnival funhouse. But a handful of flats are still occupied; Tatiana is waiting for an appraisal so her family can receive compensation.
It’s a story that has repeated itself again and again in Norilsk; buildings have been partially or fully torn down, leaving only drooping foundations. Demolitions often have to be done by hand and cost 15 to 20 million roubles ($240,000 to $320,000) each, Kerimov says.
Norilsk city hall referred requests for commentary to the construction company NorilskStroiRekonstruktsiya, which says it has done work to strengthen the foundations of “almost all the buildings in Norilsk.” At least nine unsalvageable buildings have been torn down in the past decade, according to manager Vladislav Petrovsky.
If temperature monitoring or visible deformations tip maintenance workers off in time, structures can be saved. Thermosyphons were installed to cool the soil under the apartment block at 36 Nansen Street when temperature probes showed warming there, for instance.
But sometimes changes come too suddenly. A brick office building on Komsomolskaya street cracked like an egg one September morning in 2009 and stands empty to this day. A top corner of the building pitched forward 28 inches, sending jagged fissures up the middle of its facade and squashing windows.
Zoya Yanchenko, a botanist at the Institute of Arctic Agriculture and Environment, went into the building the next day to retrieve her equipment. “When we saw what had happened, it was terrifying,” she said. “It made my head spin, because the floor was at an angle. It wasn’t for the weak-nerved.”
“Happily there weren’t any human casualties in 2009 because it was 3 am and the building was empty,” Kerimov said. But things could have been very different had it been daytime.
Norilsk mayor Oleg Kurilov created a “permafrost council” of Kerimov and other experts in 2014 to try to preserve building foundations. Kerimov has been campaigning for stricter building codes to be drafted for the far north and has presented ideas to deputy prime minister Dmitry Rogozin. But it’s questionable whether the political will is there to address the challenge, since many local officials and residents like those at 59 Talnakhskaya have doubts about climate change.
“I think the problem is exaggerated. Our icebreakers won’t be out of work for the next 100 years,” says Alexei Novakov, director of the port in Dudinka, when asked about climate change, which he argues is part of a “natural cycle.” Although Grebenets warns that as permafrost retreats from the river bank, piers and other structures there could be compromised, Novakov says he didn’t “see any trend that piers have suddenly started to be destroyed”.
This skepticism goes all the way to the top: President Vladimir Putin has in the past voiced doubt that human activity is behind climate change and suggested warmer temperatures will benefit the country. Russian media rarely mentions the issue.
Adapting northern cities to climate change is also a difficult sell due to the price tag: Costs typically increase by 30 to 40 percent to build a structure able to withstand more volatile permafrost conditions, Kerimov says. Residents of 59 Talnakhskaya have already called for the city to spend more money on keeping up buildings and monitoring soil conditions—but recession and sanctions make funds hard to find.
“Many climate change problems are solved by investment, spending on engineering. Where will we get this investment? Will local budgets find this money?” asks Oleg Anisimov, head of the climatology department at the State Hydrological Institute in St Petersburg. “With the dollar at 70 roubles, the budget in the north won’t be enough.”
“The peasant won’t cross himself until the thunder crashes,” Kerimov says, using a Russian folk saying. “As long as there’s no catastrophe with human casualties, nobody will do anything.”

If you are afraid of heights, this is a super scary video. In case you are too afraid to watch it, this dude jumps off the top of a building that is listed at 129 feet and lands in water. But wait! Although that's crazy, the crazy part is that he jumps over two docks in order to hit the water (and not the wooden dock).
The physics question here is: How hard is it to jump over that second dock?
When you have an object whose motion is only determined by the gravitational force, that's called projectile motion. So, to be clear, that's the time right after the dude leaves the building until right before he hits the water. If this is true projectile motion, there would have to be negligible air resistance—which I will assume for now.
Actually, this is a great example of projectile motion since it appears that the guy launches horizontally off the building. Let me start with a diagram and some parameters that I will need to estimate.

Of course this isn't a very accurate diagram—you can tell because the jumper didn't actually scream "AHHHHHHH." But anyway, I can still analyze the motion. There is one key element to projectile motion—and it is this: You can treat the horizontal motion (x-direction) and the vertical motion (y-direction) as two separate one-dimensional kinematics problem. The only thing these two 1D motions share is time. The time it take the guy to move in the x-direction is the same time it takes him to move in the y-direction.
Let's look at this y-motion first. Since there is only the gravitational force pulling down, the dude will have a vertical acceleration of negative g (where g = 9.8 N/kg or 9.8 m/s2). If I call the water level the location where y = 0 meters, then he starts at a y-value of h with an initial y-velocity of 0 m/s (since he jumped horizontal and not up).
With this, I can use the following kinematic equation (for motion with a constant acceleration):

If you want to know where this equation comes from, I can recommend this excellent book on introductory physics. Or if you prefer a more hands-on approach, here is my incomplete online book for introductory physics using Python. But using this equation I can put in my values for the starting and ending y-position as well as the initial y-velocity and solve for the time.

This expression for time can be used in the x-motion. Since there are no horizontal forces on this dude, the x-acceleration is zero. This means there is just the following (and simpler) kinematic equation.

I will set the starting x-value to zero and the initial x-velocity is just the dude's launch velocity (the magnitude of initial velocity vector).

Substituting the expression for time, the horizontal distance traveled will be:

Let's take a moment to just check this equation.
OK. Now we can use this expression to look at the jumping guy. Oh, this is essentially the same experiment you did in your introductory physics lab. No, you didn't jump off a building like a crazy person. Instead, you probably had one of these ball launchers that shot a small metal ball horizontally off a table and onto the floor. Replace the ball with a crazy person and you get 1 million views on Youtube.
OK, what do we know? The video says this is in Newport Harbor—but I think it's Newport Beach harbor. Pretty sure this is the location from Google Maps.
The great thing about Google Maps is that I can use it to find the horizontal jump distance. I get a value of approximately 7.4 meters. If I assume the height is correct (at 129 feet or 39.3 meters), I can use these two values to calculate this crazy dude's launch speed.

A launch speed of around 2.6 m/s is like a slow jog or fast walk (it's a jalk)—but definitely seems like a reasonable starting speed. The guy easily could have taken a running start to get a faster speed, but he didn't. Really, I'm wondering if he was trying to land in between the two docks. If that's the case, he was probably freaking out a little bit on the way down thinking that he might hit that second dock. Or maybe he was thinking of how many Youtube views he was going to get.
But there are still some questions. I will leave these for your homework assignment.
On Monday, at a launch center in the middle of the Gobi desert, two taikonauts boarded a spacecraft and rocketed into space. Yesterday their ship, Shenzou-11, docked with China’s experimental space lab, Tiangong-2. For the next 30 days—China's longest crewed space mission—they will conduct experiments, test equipment, practice repairs, try to grow plants, and keep track of how the space environment affects their bodies. Sound familiar, space fans?
It should. Tiangong-2 is like a baby International Space Station. Sure, it doesn't have the ISS's scale, technological sophistication, or multi-national backing. But it's the technical testing ground for the grown up space station China plans to launch in the next couple of years. Which will more permanent, and about the size of Mir, the Soviet Union's space station in the 80s and 90s. But mostly, Tiangong-2 an important part of China's long term plan to build a Moon base. And from there, it'll be hard to deny China a seat at the space superpower table.
Like everything China does, people consistently underestimate the nation's space program. Common snubs include: It's miles behind the curve; their gear is all Russian knockoffs; their launch schedules are hopelessly slapdash. Yeah, those have all been true at one point, but not an honest assessment of the program as it currently stand.
China did not launch its first satellite until the 1970s, and didn't really invest heavily in their space program until the early '90s (the Cultural Revolution was a bigger priority) but they've been gaining ground on the US and Europe ever since. Early on, the nation's program relied on Russia, both for components and training for their would-be taikonauts.
And the Shenzhou spacecraft do resemble Soviet (now Russian) Soyuz. But don't hate: "The Shenzhou is the same idea, but not a copy," says Jonathan McDowel, an astrophysicist at the Harvard-Smithsonian Center for Astrophysics. "In its present form, it's very much a Chinese vehicle." The Chinese spacecraft is bigger, more powerful, and its forward habitation module has solar panels that can provide power for a separate mission—even after the astronauts climb aboard Tiangong-2.
Slapdash? Anything but. "This is not a fly-by-night program," says Joan Johnson-Freese, a professor of national security affairs at the US Naval War College. "They're just taking a very different approach than the US did. We launched a lot. They only launch every three years or so, but take a very big step forward with each launch."
The Chinese announced their manned spaceflight program in 1992 as an incremental three step process: First, send someone on a non-fatal, roundtrip space journey, which they did in 2003. Like any trilogy, the second act is where things get exciting. (Don't @ us: you know *The Empire Strikes Back *and *The Two Towers *are where the drama's at.) Part two of China's program is what's happening now—launch some space labs and develop advanced spaceflight capabilities like orbital docking. Last is getting permanent structures out into orbit, like that space station we mentioned earlier. And sometime after that, the Moon.
China ramping up its space program has some people worried, and that's understandable. China's space program is run by the People's Liberation Army, and has always had a strong military bent. "It would not surprise me if during this month-long mission, the taikonauts were used to do observations of military interest amongst their scientific experiments," McDowell says.
It's not like US astronauts have never been agents of the military. But really, the US is unusual in that its military and civil space programs are fairly distinct. For those with reason to be concerned by such things, China's space program has a few concerning military projects—looking at you, spy satellites and anti-satellite missiles—but the very un-weaponized space station probably isn't one of them.
The notion that China is a burgeoning space superpower is harder to deny. "This is the pivot year in the Chinese space program," McDowell says. "They’ve got lots of hardware coming through the pipeline, and are now preparing to switch over to a new generation of rockets." A Long March 2F launched Monday's spacecraft, but China expects to start test flying the Long March 5 in early November.
Newer, bigger rockets will allow China to launch that bigger space station. The next generation, heavy lift Long March 5 rocket is powerful enough to get a craft to the Moon. According to McDowell, Chinese taikonauts are likely to reach that destination by the late 2020s. "China's human spaceflight program is ticking off everything America and Russia did in the space age," McDowell says.
And while China developing manned spaceflight prowess isn't a pressing security threat, it does stand to rebalance the global powers. "Having your own space station, flying somebody to the moon, that's what big countries do," says John Pike, a prominent military analyst and director of GlobalSecurity.org. "It unambiguously demonstrates that China has stood up and wants to be taken seriously as a rising power."
Crewed spaceflight is basically a prestige move. It doesn't have the direct economic benefits of something like GPS (or China's version, BeiDou). The probable reason China wants people in space—and why some people get huffy about China's space station or Moon ambitions—is because it gives them a shot at unseating NASA as Earth's premier space power player. "We’ve taken careful aim and shot ourselves in the foot," says Johnson-Freese. "There’s a perception that the US is floundering and underfunded, and European astronaut wannabes are learning Chinese."
To be fair, China is still about 20 years behind the US in terms of spacecraft automation, sophistication, and reliability. According to McDowell, at the 'where no one has gone before' limits of the field, the US, Europe and perhaps Japan are still the real power players. But as China continues to advance at gathering speeds, it sure seems like another space race might be in order.
I was a graduate student when I taught my first class, a physics lab. There's nothing unusual in this; university physics departments often hand labs over to graduate students. It's a win-win, really. Departments need teachers, and grad students need experience.
Of course, I didn't really know what to do, but no worries. I could follow a manual describing the experiments. In time, though, my ideas about labs changed. It started after a presentation I saw at a conference. I don't recall the conference or where it was, but I remember the talk. It was about innovations in lab. One of the speakers discussed an "improvement" to the electric fields mapping lab.
This is a common lab during second semester physics. The basic idea is to explore the electric field around an electric charge or between two electrically charged plates. It's not easy to measure the electric field. Instead, you cheat and measure something simpler—conducting paper.
The power supply connects to two points on black conducting paper. You can make these connections in whatever shape you like—two points, or two straight lines, or any two-dimensional shape, really. Using a voltmeter, you can map out lines of equipotential and use that to calculate the electric field. That is the basic idea. As far as electricity-magnetism labs go, it's not too bad in that students can use this electric potential to create a plot of the electric field.
But wait! Isn't this lab super tedious (rather than just plain tedious)? That's where that conference talk comes in. One physicist came up with a modification: He'd have students use a probe to press various points on the conductive paper. The apparatus would automatically record the voltage as well as the x and y-coordinates. Boom. Instant data without the tedious recordings. Better, right?
It was at this point that I realized the student was essentially eliminated from the lab. Granted, the student probably was never really was involved, but this made it was obvious. What started as an investigation into the relationship between electric fields and electric potential became an exercise in data collection.
But what is the goal of a physics lab? I doubt all physics faculty will agree (and that's OK), but this is what I think an introductory physics lab should do:
In other words, a physics labs should encourage students to figure things out, not just follow instructions or collect data for data's sake. Research backs this up. Students exposed to open-ended labs have better ideas about the nature of science. Here is the paper:
Open-ended versus guided laboratory activities:Impact on students’ beliefs about experimental physics. Bethany R. Wilcox and H. J. Lewandowski, Phys. Rev. Phys. Educ. Res. 12, 020132 – Published 3 October 2016
How do you make a lab more open-ended? Here are some suggestions:
In the end, giving up control of the lab can be scary because you can't be sure what happens. But isn't that just like science—and life?
If the climate keeps warming the way it has, Greenland may finally live up to its name (which was probably bestowed on it by some colorblind viking). The island's glacier-crusted surface is melting, and a lot of this is from balmier atmospheric temperatures. But as the saying goes, that's just the tip of the iceberg. The oceans are becoming more tepid as well, and that warmer water is causing the glaciers to thaw from below.
Scientists have good measurements of how much ice melts due to warmer air. And now, thanks in part to torpedo-like probes, they are getting better data on the ice being lapped away by sea water. Those submarines are part of NASA’s Oceans Melting Greenland campaign—OMG, for short. And that's a fairly accurate acronym, because Oh-My-Goodness those glaciers are melting fast.
“Glaciers acquire mass through snowfall but melt from sun radiation or contact with warm ocean water," says Michele Koppes, a glacial geomorphologist at the University of British Columbia. Air-induced melting is pretty straightforward. But water makes things a bit more complicated. In Greenland, the melting starts deep. Ocean currents converge off Greenland's continental shelf. You'd think the warmer water would be near the surface, because it is less dense. But that's because you didn't think about salt. Greenland's warm currents come from the Atlantic Ocean, which is super salty, and therefore denser than the chillier Arctic water.
Greenland's glacier-gouged coastline provides the deep, warm water a path to the inland ice. Ancient ice sheets carved subsurface fjords and canyons, many of which reach down to the same level as the Atlantic-Arctic currents at the continental shelf. Problem is, “the seafloor around Greenland's coast isn't very well known," says Josh Willis, a climate scientist at NASA’s Jet Propulsion Laboratory and the project lead for OMG. "The location and depths of these underwater fjords and canyons have just been poorly mapped out."
Chillin' with the Bots
Willis and his crew have spent the past five weeks flying over Greenland's coastline, dropping torpedo-shaped probes into the underwater fjords. These units are called (deep breath) AXCTDS, or Airborne Expendable Conductivity, Temperature and Depth Sensors (exhale).
The probes work in teams. One goes deep, measuring saltiness and temperature—essentially, where that warm, deep sea current is. Because it descends at a steady rate, Willis can track its depth by counting how long it's been in the water. The other stays at the surface, transmitting the deeper probe's information back to the plane. In the end, the probes will tell the team where ice-ocean interaction is most likely to occur, and how much of the ice sheet is at risk.
Before OMG launched, marine glacial retreat patterns in Greenland had really only been observed by satellites and concentrated fishing surveys. The ship measurements, though, weren't widespread enough for the research to truly count. And satellite signals mostly bounce off the ocean's surface.
Mission OMG aims to change this. The program spans five years and will look for ocean-caused changes to Greenland's ice sheet. This spring, the team measured glacier height with aircraft radar, comparing past and future data to ascertain which glaciers are vanishing the fastest. The subsurface torpedo work took place this fall, when Arctic sea ice was at its minimum. It was the first time underwater probes had collected data on Greenland's continental shelf depth, salinity and temperature.
Ultimately, the group wants to know how much of Greenland's melting is because of air temperature, and how much is caused by water. Koppes, who has worked with the OMG team, believes air temperature and ocean water will play a 50/50 role in glacial melting.
OMG will need time to analyze the data and confirm, but so far they've encountered some surprises. “The amount of warm water was bigger than expected, and we saw it in more places than expected,” continues Willis. “Almost everywhere along the shelf where the water was deep enough, we found Atlantic water interacting with the glaciers.”
And the current isn't the only deep interaction making the glaciers melt. The Greenland ice sheet is a mile thick, so even when the temperatures at the summit are beyond blustery in the winter (we’re talking -25 °F), the sheet sheathes the cold weather from the bottom of the ice. And where the bottom of the ice makes contact with the bedrock, it's met with warm temperatures from geothermal heat. Altogether, this thaws out the bottom of the glacier.
And the stakes are high. The deep current warming turns Greenland's 27,000 miles of coastline—a distance greater than the Earth's circumference at the equator—into a melt factory. The island's interior is three times the size of Texas, and holds enough frozen water to raise global sea levels by 20 feet. More than enough to drown the Maldives, Venice, and New Orleans. But hey, maybe those people can resettle in Greenland's thawed out fjords.
Photo taken from Greenland's northwestern coastline in September 2015 during Phase 2 of the TerraSond/Cape Race Bathymetry survey.
A few years ago Eric Schadt met a woman who had cancer. It was an aggressive form of colon cancer that had come on quickly and metastasized to her liver. She was a young war widow from Mississippi, the mother of two girls she was raising alone, and she had only the health care that her husband’s death benefits afforded her—an overburdened oncologist at a military hospital, the lowest rung on the health care ladder. The polar opposite of cutting-edge medicine. To walk into such a facility with stage 4 metastatic disease is to walk back in time to the world of the unmapped human genome, when “colon cancer” was understood to have a single cause instead of millions of causes resulting in unique variations, when treatment was the same bag of poison, whether you were in Ocean Springs, Mississippi, or Timbuktu. A time without big data, machine learning, or hope.
Schadt had just started the Icahn Institute for Genomics and Multiscale Biology at Mount Sinai Hospital, and when he heard about the woman in Mississippi, he said, simply, “That’s exactly the kind of patient we take.” By that he meant patients for whom the current standard of care would fail, for whom the future of medicine—one in which supercomputers sift through masses of genetic data for patterns that could lead to new treatments and cures—could not arrive fast enough.
Schadt isn’t a cancer specialist or even a medical doctor. He’s a mathematician and a specialist in molecular and computational biology, and he had never had a single patient in his life. Yet through his new lab at Sinai, Schadt would generate a terabyte of data on this woman’s cancer, thousands of times what she could have expected in a conventional medical setting, in the hope of finding new ways to combat it. Toward the end, Schadt would sit at her bedside, distraught. They had become close, and the scientist who had never had patients before was seeing the implications of scientific ambition and failure. She died last year.
Seated at his desk at Mount Sinai, Schadt is direct and disarming. At 51, he wears a short-sleeved polo shirt and shorts everywhere he goes, even to black-tie galas or in New York winters, which gives him the unassailable air of a true eccentric, or a high-school football coach. For any medical researcher, it’s easier to be bullish when you’re publishing papers or developing drugs, layers removed from the human impact of your work. But living the effect of your work and watching someone slowly die in front of you, well, “that’s a deeper humbling than I’d ever experienced before,” Schadt says today.
“We’re on this exponential growth curve, where your mind naturally projects all the way into the future, and you think: We’re going to figure this out,” he says. “In the end, we will know what all these cells are doing, what all these perturbations do. The humbling part is that as we are on this growth curve, we are continually struck by the increasing complexity that is revealed.”
For a decade we’ve been talking about the potential of gene sequencing and personalized medicine, how advances in computer processing power combined with an increasingly intimate understanding of our individual genomes has put us on the threshold of an age of miracles. With enough data, the theory goes, there’s not a disease that isn’t druggable. But as Schadt has learned, it’s not enough to plumb the depths of an individual’s DNA. It requires a universe of data—exabytes worth—to detect patterns in a population, apply machine learning, find the network of mutations responsible for disease, and do something about it. The bigger these data sets become, the more accurate and powerful the models and the predictors become.
You must convince the medical centers and genetic companies that collect our data to not hoard it for their own profit.
The problem is getting these exabytes of genetic data. Turns out you can’t just walk up to people, millions of them, and say, “Your data, please.” You must first persuade them that you’ll only do good things with it and won’t let it fall into the wrong hands. (We do like our privacy.) You must then convince the medical centers and genetic companies that collect this data that, rather than hoard it for their own profit, they should share it so the entire research community can attain the economies of scale—the critical mass of data, individual sets eventually numbering in the millions—that Schadt and many others believe is necessary to understand the causes of diseases and engineer new treatments and cures.
Right now, that volume of information is simply not available. But companies ranging from tech behemoths to biomedical startups are racing to solve these issues of scale. And Schadt wants in.
If human biological complexity can be likened to an animated movie, then a hundred years ago we had about one pixel’s worth of understanding of that complexity. With a single pixel, you have no idea what the story is. But with more pixels, hundreds or thousands—or say, 1 percent of the whole in pixels—patterns and themes begin to emerge. The beginning of a narrative.
This was the thinking that compelled Schadt to set up the Icahn Institute in 2011 after a decade of developing drugs for Merck. (At one point, half of Merck’s metabolic drugs, which treat ailments like heart disease, diabetes, and obesity, were derived from Schadt’s research.) In the face of widely held assumptions based on the single-gene model of disease and drug development, he came to believe that genes worked not alone but in vast networks to enable disease to penetrate our natural defenses, and we could understand these networks only through deep bioinformatic spelunking. To explore his complexity model, Schadt arrived at Mount Sinai with $150 million of financier–philanthropist Carl Icahn’s money and built a supercomputer named Minerva in the basement to analyze the thousands of genomes collected at Mount Sinai each year. He hired other quants, including Jeffrey Hammerbacher, who had created Facebook’s first-ever data team. According to an esteemed oncologist at the medical school, “All of a sudden you had all these math nerds running around, people who looked like they should be programming videogames.”
“We need 100 Mount Sinais to achieve the scale required to recognize the patterns in patient data that guide you to diagnoses and treatments.”
It didn’t take long for Schadt to realize that he was going to need a bigger boat. In 2014 the Icahn Institute started a joint venture with Sage Bionetworks to try to cure rare childhood diseases—cystic fibrosis, sickle cell anemia, Tay-Sachs—170 in all. They called it the Resilience Project, and researchers set out to find individuals in the population who carried the DNA variants for those diseases but somehow, through some inoculating buffer, didn’t have the disease. In their search for these “resilient individuals,” Schadt and his team amassed a pool of genetic data from 600,000 people, then the largest such genetic study ever conducted, with data assembled from a dozen sources (23andMe, the Beijing Genomics Institute, and the Broad Institute of MIT and Harvard, most notably). But in searching the 600,000 genomes, the researchers found potentially resilient individuals for only eight of the 170 diseases they were targeting. The study size was too small. By calculating the frequency of the disease-causing mutations in the population, Schadt and his team came to believe that the number of subjects they’d need to be useful wasn’t 600,000—it was more on the order of 10 million. For all the computational power behind the Resilience Project and what seemed like a wealth of data, Schadt still lacked the quantity and quality of patient information required to crack the genetic code behind resilience.
“We need 100 Mount Sinais to achieve the scale required to recognize the patterns in patient data that guide you to diagnoses and treatments,” Schadt says. “In the five years that I’ve been here, I’ve realized that’s just not going to happen within the medical centers. They’re too isolated from each other, too competitive, and they’re not woven together into a coherent framework that enables the kind of advancements we’re seeing in nearly all other industries.” Since the major medical centers hold an effective monopoly over their patients’ data and have little economic incentive to collaborate with one another in critical research areas, Schadt says, “the disruption is gonna happen outside the medical establishment.”
So that’s what Schadt is aiming to build by establishing his own genetic data company, Sema4. The New York–based venture will focus on acquiring and expanding companies that specialize in genetic testing—–think cancer-carrier screenings and noninvasive prenatal tests—in order to collect and share millions of individual data sets. On Sema4’s searchable platform, doctors will have instant access to a world of genomes to help diagnose their patients. Pharmaceutical companies will pay to use the system to find patient populations for clinical trials. And scientists, their current analytic arsenals amplified through ever more powerful computers and machine-learning algorithms, will finally possess enough genetic data to fuel ambitious research.
Though a handful of tech giants are venturing into the life sciences (see “Big Bets on Biodata,” below) and the National Institutes of Health is asking for a million volunteers to create its own massive biobank, Schadt believes that Sema4 and other startups like it—Craig Venter’s Human Longevity and Patrick Soon-Shiong’s Nant-Health chief among them—are the most committed to achieving the optimal scale of genetic data. While these companies will compete with one another to collect ever greater stores of high–quality biodata, Sema4 will stand out by making its genetic library accessible and free of charge to academic medical centers and nonprofit researchers around the world. Should any of Sema4’s competitors need to harvest information from a subset of Schadt’s data populations, he says, they could simply pay to access the Sema4 search platform. Or Sema4 and other companies could join forces to assemble large data sets for ambitious endeavors like the Resilience Project—only bigger.

How four tech heavyweights are going all-in on life science.
—Gregory Barber

Alphabet
Using machine learning for their Baseline study, Alphabet’s Verily Life Sciences team will pore over genomic, clinical, and imaging data from thousands of healthy volunteers in the hope of better understanding what makes them healthy—knowledge that might help keep people from getting sick in the first place.

IBM
In the 1970s, the World Health Organization used IBM hardware to hunt down the last vestiges of smallpox. Today IBM is partnering with hospitals to funnel health data into Watson, its Jeopardy!-winning AI system. The goal is to predict disease, personalize treatment, and even power virtual medical assistants to sift through records and research.

Apple
Using Apple’s ResearchKit, scientists can recruit clinical study subjects en masse and collect real-time health data from participants’ iPhones. Last spring the company added CareKit, which lets Apple users share health data directly with their personal doctors.

Microsoft
The company is developing tiny sensors to be worn on the skin that can transmit biometric data to remote health monitors (and, potentially, large-scale data aggregators). Microsoft also just announced its plan to use machine learning and biological data to “solve” cancer.

Still, Schadt argues, the problem of scale can’t be solved by companies simply pooling their data. “It’s about getting the data from the patients themselves.” Based on his experience at Mount Sinai, he’s seen a leap in recent years in the number of people who are coming around to his belief that there is more upside than down to having a physician know their genetic predisposition to certain conditions. He says that when he got to Mount Sinai in 2011, the hospital was screening a few thousand genetic samples a year. This year, they could screen up to 150,000, most of them collected from patients in the New York region, and at Sema4, Schadt says, “we intend to scale that up to 500,000 to a million samples a year.”
That growth will occur by buying and expanding existing genetic testing companies all over the country, most of which are now independent from each other but under Sema4 will combine to create a massive network of genetic information governed by a uniform standard of security and consent. Schadt acknowledges that it’s no simple task to ask a person to give up their biodata to an anonymous corporation. Even though billions of public- and private-sector dollars have been spent to modernize and secure existing data networks, breaches and leaks remain a fact of life. At Sema4, patients will be told, in detail, how their data will be encrypted, anonymized, and scrubbed of identifying information (except for an encryption key). Even in the event of a breach, the chance of someone being identified and exposed is exceedingly low.
There is also the issue of informed consent—the patients’ understanding and approval of the whats, hows, whys, and how longs of whatever they’re asked to endure—which impacts both the quality and the quantity of the data being collected. “There are companies today that claim access to millions of patient records,” Schadt explains. “But from the standpoint of what we intend to do, the data is meaningless. It’s often inaccurate, incomplete, and not easily linked across systems. Plus, that data doesn’t typically include access to DNA or to the genomic data generated on their DNA.” To take the example of the Resilience Project, it wasn’t simply that the universe of data was too small—it was also that the 600,000 genomes were governed under a hash of various consenting arrangements. If something vital was discovered, hundreds of thousands of participants could not be recontacted or tracked, making the data useless from a practical research standpoint.
Today, most consent forms are designed to be as quick and uninformative as possible, but rather than make it easier for researchers to get high-quality data, this approach actually makes it harder. Studies have shown that the more informed the consent, the better the information, since patients are more willing to participate in follow-up exams and interviews when they appreciate the purpose of the research. (This also allows scientists to track health and wellness over time.) At Sema4, Schadt is adopting a multistage informational process—which includes a mandatory, must-pass quiz—so it will be clear that patients understand the full scope of what they’re consenting to. This will require more of a patient’s time, but Schadt is betting that as more patients understand, more of them will consent to sharing their genetic information.
With this digital infrastructure in place, Schadt envisions a future in which more and more patients share not only their genomes but also medical and lifestyle information collected by monitoring devices like glucometers, blood-pressure trackers, and inhalers. The hope is that, ultimately, these increasingly sophisticated, increasingly patient-friendly tests will be so comprehensive that a patient’s microbiome can be regularly sequenced, their RNA frequently examined, and their blood cells constantly monitored for signs of trouble.
The virtual monopoly that medical centers like Mount Sinai now exercise over patient data will be smashed, and researchers will finally have the masses of genetic data that the medical breakthroughs of the future require. “Can we do better for human well-being if information is more broadly accessible, where you’re leveraging the mindshare of the entire planet to evolve the models of disease?” Schadt asks. “Absolutely.” This is medicine as math, not guesswork, and every disease—even stage 4 cancer—might one day be druggable.
This exclusive online extra accompanies our special November issue, guest-edited by President Barack Obama. Subscribe now.
On Wednesday morning, if all goes well, the European Space Agency’s Schiaparelli probe will alight on rusty Martian dirt. It’s been zipping through space for seven months now, and once it triggers its parachute, pops off its protective coverings, and lands, it’ll kick off a six-year mission to test Mars for signs of ancient (or current!) life.
Watch the livestream of the landing here; it starts at 11:40 am Eastern.
The European probe itself will be short-lived. For only a few Martian days, Schiaparelli will gather wind speed, humidity, temperature and other atmospheric data before its batteries die out—it’s really more of a test for the landing equipment ESA scientists have designed. But the spacecraft it hitched a ride on, the Trace Gas Orbiter, will orbit Mars until 2022, sniffing the methane, acetylene, and other trace gases in its atmosphere to see if they were produced by life or just chemistry.
But whoa there, Mars is the hottest destination this side of the Kuiper belt. NASA’s Curiosity is still ticking along on the Martian surface, and the agency is gunning to launch a super-slick improved rover in 2020. China, India, and the UAE are all working on their own forays to the Red Planet. And Schiaparelli is really more of an overture for the ESA’s next mission, a rover decked out with a drill and more heavy-duty scientific gear that’s also slated to launch in 2020. Also, Elon Musk. Does humanity need another science sniffing droid on the Red Planet?
Well, yeah. For one, “there’s no way to pack every analysis tool you want on every launch,” says Kevin Lewis, a planetary scientist at Johns Hopkins who works on the Curiosity mission. Each mission provides a different, valuable peek at the way things are on Mars—and looking at it from various angles helps scientists nail down what’s actually going on.
And, like Earth, Mars is complex. You wouldn’t be able to choose just one place to put a rover on Earth to get a sense of its sheer diversity. “If you sent one to Baltimore,” Lewis says, “it would teach you nothing about the Sahara desert or the Greenland ice sheet.” So scientists pick promising landing sites after years of deliberation and input from other researchers. Schiaparelli will touch down on a flat area called the Meridiani Planum, above a promising vein of hematite, a mineral that only forms around liquid water.
For all of the designs space agencies and ambitious entrepreneurs have on Mars, it’s still a whole planet’s worth of unknowns, far away and hard to reach. To start figuring it out, scientists are going to need all the data they can get.
Last week, astronomers announced the discovery of DeeDee, a possible dwarf planet. That name—dwarf planet—means it is like Pluto: Massive enough to assume a spherical shape due to its own gravitational force, but not quite big enough to control the region of space it inhabits. And it too circles the sun, but from much, much farther away than Pluto. A single orbit takes 1,100 years, making DeeDee the second-most distant dwarf astronomers have ever discovered.
The Internet's scientific diaspora got excited for DeeDee. New worlds, even tiny ones, are special. But eventually, they won't seem so. Scientifically, DeeDee is mainly important as a data point—an addition to a growing catalog of similar objects. And—like a census—as the catalog grows, the individuals listed therein will become less interesting. Which might sound sad but is actually a sign that astronomy is succeeding. Dwarf planets were only created as a class a decade ago, and it's only a matter of time before you don't care that somebody found a new one.
When University of Michigan astronomer David Gerdes began the research that would eventually yield this big rock that might be a small planet, his goal was (and still is) larger. He wanted to use data from a dark-energy survey to find “trans-Neptunian objects”—anything orbiting beyond Neptune that is neither a planet proper nor a comet. He started combing through observations from a Chile-based instrument called the Dark Energy Camera.
The camera, as you might guess, is meant to study dark energy. But, says Gerdes, “fundamentally, what we’re doing is making a big, detailed map.” And in that map, Gerdes’s team looked for points of light that moved from night to night. This suggests they are small objects orbiting the Sun, rather than huge, bright objects moving incredibly fast through some distant part of the universe.
In an initial search of just one percent of the survey’s sky area, they found five new trans-Neptunian objects. And with that proof of concept, they decided to expand, searching a couple thousand square degrees of sky. (If you extend your arm all the way, the tip of your pinkie covers approximately one square degree of sky.) That larger patch contained a few hundred candidates. One of which stood out: 2014 UZ22, affectionately called DeeDee for “distant dwarf.”
Gerdes and his team spotted DeeDee when it was more than 90 astronomical units away—90 times the average distance from Earth to the Sun. To show up from that far away, it had to either be small and very shiny, or big and less reflective. Given those parameters, DeeDee is somewhere between 350 kilometers (very shiny) and 1,200 kilometers across (pretty dull). New, still-in-process data from the ALMA telescope in Chile, which can detect infrared light, should help pin down the dwarf's size and shininess.
That’s all fantastic. But what’s most fantastic: Dwarf planets like DeeDee are becoming more and more discoverable, in general.
Scientists didn't demote Pluto to dwarf planet out of spite. They were matching it to its context. When more powerful telescopes showed them more of the outer solar system, they realized Pluto was one of many icy, rocky bodies lurking far from the Sun. In 2004, astronomers discovered Sedna, about 40 percent as wide as Pluto.
A year later, they found Eris, an object bigger than Pluto. The name—Greek goddess of strife and discord—was appropriate. Instead of turning Eris into the 10th planet, astronomers at the contentious 2006 International Astronomical Union conference created a new category of thing: the dwarf planet. Pluto and Eris both became that thing.
Today, the International Astronomical Union recognizes five dwarf planets—Pluto, Eris, Ceres, Haumea, and Makemake. Mike Brown, the self-described “Pluto-killer,” claims six more objects are “nearly certainly” dwarf planets. His site lists almost 1,000 more, with dwarf planet statuses ranging from “highly likely” to “possibly." So while finding a new potential dwarf like DeeDee is laudable, its addition to the catalog is now just that: an addition to the catalog.
This move from curiosity to category is not a thing to be mourned, which Gerdes would agree with (after all, he found the one while searching for the many). A lone object could be an outlier. But with a bunch, scientists can study the population; conclusions become generalizable. It’s why a government takes a census instead of publishing 350 million individual biographies. It’s why a medical trial doesn’t just recruit one poor participant. In transitioning to something that can be measured in aggregate, dwarf planets join pretty much every other astronomical object ever.
How many stars can you name? How many galaxies? “[The] saying has been ‘In astronomy, one is a pet rock, 10 a solid statistical sample,’” says astronomer William Keel.
Just last week, scientists announced that the universe contains 10 times as many galaxies as they previously thought—up from around 200 billion to 2 trillion. To do that, they didn’t actually have to discover billions of new galaxies: They looked deeply into the sky and extrapolated. Scientists know enough about galaxies, and know of enough galaxies, to deal in math.
Astronomical objects—from space rocks to star systems—are most notable as individuals when scientists weren’t expecting them and have to scramble to explain. That scramble usually means finding more examples, reaching “solid statistical sample” status, and then doing statistical science.
Alone, DeeDee is a shiny thing far, far away. Combined with other dwarfs and trans-Neptunian objects, it can help reconstruct the recipe from which the solar system was baked. DeeDee, Pluto, Haumea, Makemake, Ceres, and all the future dwarf planets that will get only number-names are the solar system’s leftover ingredients. They and their smaller companions are the dusting of sugar and flour left on the counter after the dough has accreted into cookies.
“[They] are kind of the primordial globs of stuff that formed the rest of the planets,” says Gerdes, “and so by studying them and how they’re distributed and what their sizes and compositions are, and the dynamics of their orbits, we can learn about that primordial solar nebula out of which we and the other planets coalesced.”
Still, the surprises aren’t done. Scientists will inevitably find dwarfs and subdwarfs that will make them go, “Huh.” And they'll have a meeting, and that meeting will have a bunch of arguments, and eventually they will agree to create new subclasses to explain and contain these new, weird little worlds.
DeeDee, Gerdes says, is delightful in its own right. But it’s also tautological proof: Because they found DeeDee, they can find more stuff like DeeDee, more Makemakes, more Plutos. And those objects—all the spilled flour and sugar—might someday reveal the solar system’s secrets.
What do you get when you mix a hippo and a rabbit? A magical, totally chill creature called the capybara, which happens to be the world’s largest rodent. Oh and it has webbed feet. Why? Check out this week’s episode of Absurd Creatures to find out!
Find every episode of Absurd Creatures here. And I’m happy to hear from you with suggestions on what to cover next. If it’s weird and we can find footage of it, it’s fair game. You can get me at matthew_simon@wired.com or on Twitter at @mrMattSimon.
Mark Zuckerberg and Priscilla Chan's announcement in September that they will pour $3 billion into research, mainly at elite universities in California, with expressed interest to "cure all disease" within a century, was an endearing move from new money billionaires who have pledged to devote their phenomenal wealth to supporting biomedical research.
Jim Kozubek is the author of Modern Prometheus: Editing the Human Genome with Crispr-Cas9.
Sean Parker, another Facebook cofounder, in April promised $250 million, and Oracle cofounder Larry Ellison promised $200 million, to cancer centers. Eli Broad and Ted Stanley have contributed more than $1.4 billion in private wealth to fund the nonprofit Broad Institute research center and its associated Stanley Center for Psychiatric Research. (I worked at Brigham and Women's Hospital, which is affiliated with the Broad, for three years.)
But despite even the best intentions, the injection of private money into science is creating power alliances and disrupting the longstanding public research-funding model.
If there is a modern koan, it is the unquestioned belief that more data and money can solve most of our problems. A year ago, I was at the National Academy of Sciences listening to a talk by Eric Lander, director of the Broad Institute. He described a large study on schizophrenia involving more than 100,000 patients, which found that the strongest single genetic variant could increase a person’s risk of developing schizophrenia from 1 percent in the general population to 1.25 percent—hardly useful. We know that genetic variants that predict psychiatric disorders number into the thousands, each adding small effects, and they are beguilingly straddled over the entire genome. We know that small epigenetic changes are also associated with psychiatric disorders, and that these can change throughout a lifetime, and are highly dynamic. The recent claims that we would "cure all disease" sounded a lot like the White House's "cancer moonshot," which proposed to "end cancer as we know it." Still rates of cancer incidence continue to rise, because cancer and schizophrenia and so many other human diseases are very intractable, for reasons that include their diverse origins.
Robust public funding of science in the US began in the 1940s. The spoils of publicly funded research were quickly claimed by private interests. In 1980, the Bayh-Dole Act was passed to permit universities and small businesses to claim patent rights to insights gleaned using federal funds, galvanizing the public-private partnership and giving rise to tech transfer, whereby academics could land patents with government funds and license to business. Most people (including me) would argue that patents are in the blueprint of the American spirit and enable competition and innovation. At issue is whether we should be publicly funding research institutions, when the game of modern science has been made so lopsided by billionaires. For instance, the Broad Institute has an executive pay structure and quasi-corporate governance, which is designed to compete with other academic hubs.
In fact, the Broad has been involved in a high-profile patent interference battle with the University of California and Emmanuelle Charpentier over the rights to a new genetic modification tool named Crispr-Cas9. The Broad already licensed its patents to Editas Medicine and in July made David Liu, a cofounder of Editas, a core member of the Broad, a highly paid position, thereby strengthening ties with its industry partner. At the same time, STAT News reported that Editas has paid more than $15 million so far to pay the Broad’s legal fees associated with patent claims. The Broad this month also licensed one of its patents to the GMO agriculturalist Monsanto Corp. The rationale for paying for lawyers becomes clear as time passes; the Broad's income from that patent will likely exceed its legal expenses.
I understood the pitch of the competition on a day last year when I was hunched over my laptop, earning around a post-doc salary, when I locked into gaze with Bill Gates, a spry investor in Editas and an owner of science, tumbling out of a conference room at the Broad. To me, it epitomized the broader structural tension in science, in which publicly funded academic institutions have ties to billionaires yet maintain divergent pay scales for their workers. At the same time, investors find ways to leverage infrastructure built and paid for by the public.
Sean Parker's institution funds science with the nifty caveat to claim the right to patents that derive from work that it funds. The Parker Foundation coordinates with scientific actors involved in the cancer moonshot, so far including scientists at the University of Pennsylvania. Now consider that the biotech giant Novartis, which licensed a CAR T-cell cancer technology from Penn, last year paid out $12.3 million to Juno Therapeutics to resolve a three-year patent battle for the rights to commercialize it. Cases like these show how taxpayers fund basic research (via grants from the National Institutes of Health), while private investment merely makes select institutions more top-heavy, enabling a more cut-throat climate. Salaries for directors at The Jackson Laboratory, The Salk Institute for Biological Studies and Cold Spring Harbor Laboratory, or the Broad Institute, can approach $1 million; even university settings such as University of Wisconsin-Madison's Morgridge Institute for Research now establish "core members" of upper management. Those are often scientific founders of corporations with deep ties to the investment community. These changes mean that publicly funded science in part goes to subsidize scientists in their quest to start their own businesses.
Early-career researchers are largely taught to survive on poverty-level wages. Science, we are told, is a noble pursuit in the spirit of Francis Bacon, who exalted the "scientific priesthood.” suggesting their public importance. "If these scientific priests can reach the center of the maze," Bacon wrote, "they will find the 'summary laws of nature' and can use them to grasp immense power for the benefit of humankind." In the words of Walter James Miller, for the Baconian scientist, "work is public and offered for the general benefit of humanity," while the Faustian scientist works “in dark secrecy, ostensibly for public good but largely for personal power...and concealing all responsibility for his action." The Faustian scientist relates to the corporate element, not evil, responsible to private, competitive interests. And so, while science is publicly funded, in the Baconian spirit of the public good, it is increasingly under control of Faustian interests. As often as taxpayers are asked to pay for basic research in STEM, scientists surround themselves with lawyers and venture capital partners. Lawyers like to ask cui bono? Who benefits?
Taxpayers, and importantly, our national funding agencies, ought to consider "institutional health" rather than the needs of individual investigators. Some federally funded institutions are exploiting the tax base to protect the wealth of their investors and partners, often spending millions on grueling patent battles. Why should taxpayers front the money for basic research only to watch scientists clobber one another? The NIH and the National Science Foundation must evaluate the financial health of institutions and their industry partners before funding science, since many of these institutions these days operate in the public benefit, but protect and shield private partners. Journals too, notably Cell, need to take into account "institutional conflicts of interests," and institutions must be asked to more fairly disburse their intramural funds. It's my sense that, with increased private backing of researchers at academic institutions, the public funding model may be upset to a degree that there could be a populist blowback to these high-profile clashes. It doesn't make a difference to the public who wins—and that matters.
A spaceship is preparing to land on Mars when the crew notices that one of the thrusters isn’t firing. There is, as they say, a problem. But there’s no use telling Houston—by the time a distress message reaches home more than 30 million miles away, either the astronauts on board will be space dust or humanity will have become an interplanetary species.
That’s the premise of National Geographic’s new series, Mars, which mixes documentary and speculation to tell the parallel stories of two groups: the fictional future explorers who will make that first journey, and the pioneers of today—scientists, astronauts, and strategists—who are blazing the trail. In the premier episode, for example, that white-knuckle landing scene is spliced with a look at Elon Musk’s SpaceX as engineers test a real retropropulsion landing system.
Every piece of tech in the show was designed to accurately reflect the current scientific vision of how we’ll get to Mars—and to avoid the gaffes that have undermined recent films and invited the wrath of astrophysicist/space ombudsman Neil deGrasse Tyson. As executive producer Ron Howard puts it, “It’s not sci-fi!” (Indeed, President Obama has outlined a vision to send humans into Mars’ orbit by the mid-2030s.) Here’s how Mars envisions our red future.

The six astronauts in Mars travel to their new home in a rocket called the Daedalus, and their ship is based on science that’s more than simply plausible—it’s coming, and fast. “This is technology that will probably be tested in the next five years,” executive producer Justin Wilkes says. The spacecraft is heavily inspired by SpaceX, but it also borrows design elements from NASA, Boeing, and even the Russian space program. “Other films say ‘Let’s make it look cool,’” production designer Sophie Becher says. “We asked, ‘How’s this going to function? Where are they going to use the bathroom?’”
Slide:  1 / of  7.
Caption: 
Caption: The view from the top of the mid-deck ladder that leads to the main corridor of the Daedalus.National Geographic Channels/Robert Viglasky
Slide:  2 / of  7.
Caption: 
Caption: The main corridor.National Geographic Channels/Robert Viglasky
Slide:  3 / of  7.
Caption: 
Caption: The crew quarters (note the stacked bunks) and dining room share a space on the mid-deck of the Daedalus.National Geographic Channels/Robert Viglasky
Slide:  4 / of  7.
Caption: 
Caption: The flight deck.National Geographic Channels/Robert Viglasky
Slide:  5 / of  7.
Caption: 
Caption: The main control console on the flight deck. Plenty of screens—but also plenty of buttons.National Geographic Channels/Robert Viglasky
Slide:  6 / of  7.
Caption: 
Caption: A satellite view of the ship's landing zone on Mars, as well as the nearby location where the crew will establish their base.National Geographic Channels/Robert Viglasky
Slide:  7 / of  7.
Caption: 
Caption: The interior of the rover that will bring the crew from the Daedalus to the base location.National Geographic Channels/Robert Viglasky
“Daedalus doesn’t have wings, but aerodynamically it’s almost like a space shuttle,” show adviser and spacesystems engineer Robert Braun says.
While it’s not shown in the series, Daedalus launches from low Earth orbit.
In the show, Daedalus lands on the planet directly rather than from an orbital docking station, using a protective aeroshell to absorb the friction of reentry and help the craft decelerate without, y’know, burning up. Supersonic retropropulsion further slows and stabilizes the ship. In the final seconds, legs deploy for greater stability.
Every item is labeled, barcoded, and stored in a payload racking system based on actual ISS storage protocol.
The onboard displays feature real data modeled on actual calcula­tions. And don’t expect Minority Report holograms. “Astronauts want buttons,” Wilkes says. “You need redundancy.”
Braun says he answered design questions with real engineering: “How big does the environmental control and life supportsystem need to be for x number of astronauts for y number of days? How much recycling of water and oxygen can these systems handle before they have reliability issues?”
Astronaut and show adviser Mae Jemison flagged the ship bunks’ original open-air design: “You guys are looking at me while I’m sleeping?” Jemison says. “It would drive me crazy.” So the beds have privacy screens.
Emerging director Everardo Gout (Days of Grace) shot the Mars colony in Budapest and Morocco, where the topography is so similar to the Red Planet’s that NASA has tested rovers there. Producers picked a specific location on Mars to replicate: the foothills of Olympus Mons, the planet’s tallest mountain, where underground lava tubes provide shelter and protection from cosmic radiation. (Scientists are studying Mars-like isolation in the lava tubes of Mauna Loa volcano in Hawaii.) The first Mars settlers would construct a bare-bones underground habitat in the tubes; over time, future missions would deliver additional materials, and the colony would expand, module by module. Once the original six welcome more inhabitants, this is how they would live.
Slide:  1 / of  6.
Caption: 
Caption: The largest of Olympus Town's domes contains a common room that doubles as rec room and cafeteria.National Geographic Channels/Robert Viglasky
Slide:  2 / of  6.
Caption: 
Caption: A laboratory in Olympus Town.National Geographic Channels/Robert Viglasky
Slide:  3 / of  6.
Caption: 
Caption: When you erect a colony in a subterranean lava tube on Mars, covering the ductwork and wiring isn't a high-priority decorating job.National Geographic Channels/Robert Viglasky
Slide:  4 / of  6.
Caption: 
Caption: The main airlock.National Geographic Channels/Robert Viglasky
Slide:  5 / of  6.
Caption: 
Caption: A hydroponic greenhouse facility in Olympus Town will use water extracted from Mars' atmosphere to cultivate food.National Geographic Channels/Robert Viglasky
Slide:  6 / of  6.
Caption: 
Caption: The first Martian crops in progress.National Geographic Channels/Robert Viglasky
The nearest Ikea is millions of miles away, so settlers will rely on lightweight origami-style furniture and structures. “Everything’s modular: inflatable beds, inflatable furniture, fold-up furniture,” Becher says.
Subterranean lava tubes may offer the greatest radiation protection, so the show’s fictional settlers will go underground. “It’s like Homo sapiens have returned to our roots as cave dwellers,” ­Wilkes says. “Here we are on a new planet, and we’re huddling in a cave around a pro­verbial fire.”
Building on uneven ground in unpredictable conditions without bulldozers and cranes, settlers will have to improvise. The dwelling design is inspired by Buckminster Fuller’s geodesic domes: lightweight, inflatable modular structures that can be connected by flexible concertina-­style corridors.
After consulting with Mae Jemison, who took a brightly hued Swatch watch and some colorful earrings into space, Becher added color to the living area. “No one wants to live in a place that’s completely alien,” Becher says. To make Mars more cozy—and less Star Trek—she spruced up Olympus Town with warm tones and family mementos.

Mae Jemison knows what it’s like to do brave work in dire conditions: She was a Peace Corps medical officer in Liberia and Sierra Leone. She’s also a former astronaut who became the first African American woman in space in 1992, aboard the Endeavour. Today she runs the 100 Year Starship project to support long-term interest in space exploration, and she was an adviser for Mars. It’s a good fit: She has some (very) strong opinions about how Hollywood gets space wrong.
What type of astronaut would take such a huge risk to go so very far away?
The world has changed because of going to the moon. People think it’s just the astronauts going up into space, but it’s the technology: Magnetic resonance imaging, miniaturization, GPS—we couldn’t have Pokémon Go without it! It’s about the mission and what we’re going to gain from it. These are pioneering days.
Why did you start the 100 Year Starship program?
Our tagline is “Space isn’t just for billionaires and astronauts.” It’s a place for everyone to participate. But we’re in this time period where our fantasyand our virtual reality havein some ways superseded what we do in reality. Our reality doesn’t seem as thrilling. So how do we include more people and make it more thrilling?
How did you advise the producers and the writers for Mars?
I wanted to help support the drama and the suspense with plausible operational and physiological activities: What would happen, logistically, in a particular circumstance? So you aren’t saying “Oh, come on now!”
What do most movies get wrong about astronauts?
When actors play astronauts, they often take them off the deep end. Astronauts are driven, but they’re not crazy. They’re passionate but prac­tical, energetic but measured, decisive but willing tocompromise.
What else drives you crazy?
When I go to the movies, I can suspend disbelief, as long as it’s not egregious. But would people shout when things go to hell? No. You train so much on so many contingencies, you know how to do things. Think about it: If you’re all screaming on top of each other, you’re not going to be able to work it through. If you can’t hear, that’s a surefire way to get dead.
What else?
Interstellar did incredible work around relativistic physics, but they couldn’t have given a damn about biology. On Earth, you can’t grow grain and foodstuffs—but you’re driving through lush countryside with trees? You can’t figure out what else to eat?
And?
When you resort to stuff that physically could not happen. Not like warp drive, but more that somebody didn’t take the time to think this through—like putting a hole in the glove in The Martian. Or my ship is all busted up, so my first reaction is to beat on all the control panels and the switches? What the hell? If I’m already about to die, I’d hit myself in the face before I’d beat on the panels!

This article appears in our special November issue, guest-edited by President Barack Obama. Subscribe now.
Daedalus and Olympus town artwork: courtesy of Framestore; all inset photographs: National Geographic Channels/Robert Vigalsky; illustration: Stanley chow
Everyone knows MacGyver. He's the guy who gets out of sticky situations by cobbling stuff together. Here he is in the reboot, maybe four floors up, with a sudden need to jump from a window. Solution? Use a fire extinguisher and body bag to create an impromptu cushion. Could that really work?
First, a disclosure. I'm the technical consultant for MacGyver, which means I check if MacGyver's hacks are legit. I don't say whether someone should try it, and I definitely recommend against this body bag jump. I only make sure it isn't impossible.
Jumping from a four story window (say, 40 feet or 12 meters) wouldn't kill you, though the landing probably would. Anyway, let's start with the free fall. When MacGyver leaves the window, a gravitational force pulls him down (I'll ignore air resistance for now) at a constant acceleration of 9.8 m/s2.
How fast would he be moving just before hitting the ground? Since I know how far MacGyver falls but not how fast he falls, it's best to use the following kinematic equation. It's not a difficult equation to derive, but you probably want me to handle it.

A change in height of 12 meters and a starting velocity of 0 m/s yields a final speed (right before crashing) of 15.3 m/s (34 mph). That might not seem very fast, but imagine running twice as fast as the fastest you can run and crashing into a wall. That wouldn't feel too good.
When you hit the ground, you stop. Immediately. Going from some velocity greater than zero to a velocity of zero means there is an acceleration. (You might think, "that sounds like deceleration to me." But in physics, acceleration refers to any change in velocity.) It is this acceleration that you must be wary of—high acceleration can kill you. Just check out this g-force tolerance data of the maximum acceleration for different time intervals. For very short periods, humans can withstand an acceleration of up to 30 G's—but you don't really want to. An acceleration of maybe 15 G's would be better (oh, 1 G = 9.8 m/s2).
A human can easily go from very high velocities to stopping without injury—just think about a car stopping after getting off the interstate. It all comes down to how fast the change in velocity occurs. For instance, stopping a car is a much greater change in velocity than jumping from a building. But stopping a car might take several seconds. Stopping a fall by hitting the ground takes a fraction of a second. That small time interval produces huge acceleration.
One way to think about the acceleration is not with time, but distance. If you fall to the ground, both the ground and your body compress—not much, and your body much more than the ground. This makes the stopping time very short. If you jump into a giant air bag, the air bag will compress over a larger distance producing a much longer stopping time and a smaller acceleration. If I want to calculate this acceleration based on stopping distance, I could use the same formula that I used above to calculate the velocity of jumping from the window.
So. Back to MacGyver'. He needs to jump from of a window. Now, he could land on his feet and use his legs to increase the stopping distance. That's what the Winter Soldier does after jumping from a bridge in Captain America: Civil War. But MacGyver isn't pumped up on serum like the Winter Soldier. He'll need another way of increasing the stopping distance.
He grabs a body bag. Of course, an empty body bag doesn't provide much cushion. To fix this, he fires a fire extinguisher into the bag, filling it. Foam would work, but an ordinary carbon dioxide fire extinguisher is fine. The key is to fill the bag enough to make it expand, but not so much that it can't collapse a bit on impact. You don't want a super-stiff body bag. That's no better than hitting the ground.
As you can see, MacGyver waits until just before landing to fill the bag. Why not fill it when he leaps? Well, that added time might allow the gas (or foam) to leak out. Waiting until just before impact ensures the bag remains inflated. Also, it looks way cooler.
The bag compresses upon impact, decreasing the stopping acceleration. It also provides an evenly distributed stopping force so no part of MacGyver's body experiences a force great enough to injure him.
Physics says this would work. The inflated body bag provides a short stopping distance of just 10 to 20 centimeters, but that's enough. As a real-life example, take a look at Professor Splash. He jumps from 35 feet into a pool just 12 inches deep. He even survives. This is pretty close to the parameters for MacGyver. This jump seems at least plausible, if not advisable. You might survive, you would not feel great afterward.
When Rosemary and Peter Grant first set foot on Daphne Major, a tiny island in the Galápagos archipelago, in 1973, they had no idea it would become a second home. The husband and wife team, now emeritus biology professors at Princeton University, were looking for a pristine environment in which to study evolution. They hoped that the various species of finches on the island would provide the perfect means for uncovering the factors that drive the formation of new species.
Original story reprinted with permission from Quanta Magazine, an editorially independent division of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences
The diminutive island wasn’t a particularly hospitable place for the Grants to spend their winters. At less than one-hundredth the size of Manhattan, Daphne resembles the tip of a volcano rising from the sea. Visitors must leap off the boat onto the edge of a steep ring of land that surrounds a central crater. The island’s vegetation is sparse. Herbs, cactus bushes and low trees provide food for finches—small, medium and large ground finches, as well as cactus finches—and other birds. The Grants brought with them all the food and water they would need and cooked meals in a shallow cave sheltered by a tarp from the baking sun. They camped on Daphne’s one tiny flat spot, barely larger than a picnic table.
Though lacking in creature comforts, Daphne proved to be a fruitful choice. The Galápagos’ extreme climate—swinging between periods of severe drought and bountiful rain—furnished ample natural selection. Rainfall varied from a meter of rain in 1983 to none in 1985. A severe drought in 1977 killed off many of Daphne’s finches, setting the stage for the Grants’ first major discovery. During the dry spell, large seeds became more plentiful than small ones. Birds with bigger beaks were more successful at cracking the large seeds. As a result, large finches and their offspring triumphed during the drought, triggering a lasting increase in the birds’ average size. The Grants had observed evolution in action.
That striking finding launched a prolific career for the pair. They visited Daphne for several months each year from 1973 to 2012, sometimes bringing their daughters. Over the course of their four-decade tenure, the couple tagged roughly 20,000 birds spanning at least eight generations. (The longest-lived bird on the Grants’ watch survived a whopping 17 years.) They tracked almost every mating and its offspring, creating large, multigenerational pedigrees for different finch species. They took blood samples and recorded the finches’ songs, which allowed them to track genetics and other factors long after the birds themselves died. They have confirmed some of Darwin’s most basic predictions and have earned a variety of prestigious science awards, including the Kyoto Prize in 2009.
Daphne Major is less than half a square kilometer in size.
Now nearly 80, the couple have slowed their visits to the Galápagos. These days, they are most excited about applying genomic tools to the data they collected. They are collaborating with other scientists to find the genetic variants that drove the changes in beak size and shape that they tracked over the past 40 years. Quanta Magazine spoke with the Grants about their time on Daphne; an edited and condensed version of the conversation follows.
QUANTA MAGAZINE: Why did you decide to go to the Galápagos? What drew you to study finches specifically?
ROSEMARY GRANT: I had more of a genetics background and Peter more of an ecological background. But we were both interested in the same process—how and why species form. We both wanted to choose a population that was variable in a natural environment.
The Galápagos had several things that were very important. The islands are young, and there are lots of populations of finches that occur together and separately on the different islands. The islands were in close to pristine condition, having never been inhabited by humans. We knew that any changes would be natural changes and not the result of human interference.
The climate is extremely dynamic. The archipelago lies astride the equator and is subject to the El Niño–Southern Oscillation phenomenon. There are years with a terrific amount of rainfall, which is very good for finches. But it can also get years of drought, when many birds die. We now know that up to 80 to 90 percent of birds on the small islands die in times of drought. Those extremes would give us the opportunity to measure the climate variations that occurred and the evolutionary responses to those changes.
PETER GRANT: We had three main questions in mind. First, how are new species formed? That’s the Darwinian question of the origin of species. Second, do species compete for food? If they do, what effect does that have on the structure of animal communities? That was a hot topic in the early 1980s. There was very little experimental evidence at the time, so there was plenty of scope for taking a position one way or another. Third, why do some populations exhibit large variation in morphological traits like body size and beak size?
https://www.youtube.com/watch?time_continue=1&v=YytNWiYLv1M
What was it like stepping on the island for the first time?
PG: It’s difficult to convey the thrill of arriving in an exotic location you have thought so much about for a long time, scrambling up the cliff, excited that you have finally arrived, and seeing the boat leave and knowing that you are on an uninhabited island. That first landing is unforgettable.
Your first major discovery came after a severe drought in 1977. What happened?
PG: A student of mine was on the island working, regretting the fact that birds were dying. We got a letter from him about the dismal field season. But we thought this could be of crucial importance for understanding why birds are the shape and size they are. That was the first glimmer.
We went back to the island at the end of 1977 with our two daughters. As a family we scoured the island for dead and live birds. We discovered it was largely the small-beaked birds that had died. The medium ground finches with large beaks had a survival advantage over those with small beaks because they were able to take advantage of large seeds. When we looked at the offspring of survivors, we found that they were large like their parents. There had been an evolutionary change in beak size. This was a clear demonstration of evolution by natural selection.
Was this the first time anyone had observed evolution in real time?
Peter Grant on Daphne Major in 1995.
PG: In a natural environment, yes. Scientists had previously demonstrated evolution of insecticide resistance and resistance to bacterial infections. But for continuously varying ecologically important traits, this was the first demonstration of evolution in a natural environment.
RG: That’s why it was so important for us to use a pristine environment. We knew it hadn’t been influenced by humans at all.
In 1981, you spotted an unusual-looking finch, which you dubbed Big Bird. What was so special about him?
RG: When Big Bird arrived on Daphne, we caught him and took a blood sample. It showed that he was with high probability an introgressed bird—a hybrid medium ground finch and cactus finch that had backcrossed [bred with] one of the parent species.
Big Bird bred with two medium ground finches, and those offspring started a lineage. Daphne had another serious drought from 2003 to 2005, and all the birds from Big Bird’s lineage died except for a brother and sister. When the rains came again, the brother and sister mated with each other and produced 26 offspring. All but nine survived to breed—a son bred with his mother, a daughter with her father, and the rest of the offspring with each other—producing a terrifically inbred lineage.
Why is that so significant? Was Big Bird the beginning of a new finch species?
RG: In all respects, this lineage was behaving like a different species. The lineage was much bigger than its nearest relative, the medium ground finch. These birds all sang a different song that had never been heard on Daphne, the song of the original colonist. They bred in one part of the island and held territories that were continuous with each other’s but overlapped those of other species. The other species completely ignored the Big Birds, and the Big Birds ignored them.
Big Bird arrived on Daphne Major in 1981. In time his lineage would form a new species.
The original colonist had a genetic marker that we were able to trace all the way down through the generations. The brother and sister that survived the drought had two copies of that marker. From then on, all the birds in the lineage carried that marker.
Were you surprised by the Big Bird lineage?
RG: We had often argued that if birds that had genes from other species flew to another island with different ecological conditions, then natural selection would shape them into a new species. We never thought we’d see it happen, but we did.
What does the Big Bird story tell us about interbreeding? That it can possibly stimulate the development of new species?
PG: Several years ago, people thought that when populations interbred, exchanging genes would not lead to anything other than a fusing of two populations. It’s almost a destructive force, undoing the generation of a new species. But in the Big Bird story, interbreeding can actually generate something new. We see the same thing in the butterfly literature. Some populations of butterflies are the product of interbreeding of two others.
RG: By putting two genomes together, you can get a new genetic combination. Then the process of natural selection can act on the new population and take it on a new trajectory. Some will fail. Some will produce offspring that are extremely variable. Some of those individuals will be in a new or a changed environment. This is where they could have some advantage.
Rosemary Grant on Daphne Major in 1994.
We know now that certain genes came from Neanderthals to modern humans, which gave us some immune advantages. We saw the same sort of thing in finches.
During your tenure on Daphne, you witnessed a new group of finches colonizing the island. Why was that so interesting?
PG: With the heavy rains of the 1982 El Niño, five large ground finches from another island decided to stay and breed on Daphne. They built up numbers very slowly and had little influence on the other finch species. But when the drought started in 2003, their numbers were high enough to have a material influence on the food supply.
The large ground finch competed with the resident medium ground finch for the diminishing supply of large and hard seeds. As a result, average beak size in medium ground finches decreased, and the difference between the two species increased. Darwin called this the principle of character divergence—traits like beak size diverge as a result of natural selection. It occurs when two species, previously separated, come together and compete for food. It allows species to coexist, as opposed to one species becoming extinct as a result of competition. Ours was the first conclusive and comprehensive demonstration of the process, the cause and the role of natural selection.
What are the biggest changes you’ve seen over the past 40 years in our understanding of evolution?
PG: From our studies and others, I think the general concept of the rate of evolution has changed. It’s a much more rapid process than it was thought to be. When we started, most people would have been skeptical that you could get evolutionary change in one generation—producing a bird with a more pointed beak, for example. The idea that the effects of natural selection are so minute that you can’t measure them has been thrown out.
Peter and Rosemary Grant at Princeton University.
How has our understanding of speciation—the development of new species—changed?
RG: The [traditional] model of speciation was almost a three-step process. First, there was colonization of a new area. The new area has different ecological conditions, so the species changes as a result of natural selection. Then it goes to another area. Colonization, change and dispersal occur until the two species come in contact again. Then you can get things like character displacement.
Our work has shown that this model of speciation does hold. But in addition, we have shown there are other routes to speciation, such as gene flow from one species to another. We see this in the Big Bird lineage but also in cichlid fishes and butterflies. There are multiple routes to speciation.
What impact has genomics had on the field?
PG: Our understanding of evolution in general and speciation in particular is undergoing a large transformation as a result of genomics. That’s a major difference from when we started. Now we have a genetic underpinning of the processes of evolution that we previously had to infer from morphology [the physical form of organisms].
RG: The really big breakthrough was whole-genome sequencing. We are collaborating with Swedish geneticists, who are sequencing finch genomes. That’s become very exciting.
For the big selection event of 2003 to 2005, we have blood taken from birds before the drought and from the survivors. We’ve shown that one gene, HMGA2, was extremely important. The gene comes in two forms. One is associated with large birds and one with small birds. We could show that the large-bird version of HMGA2 was at a selective disadvantage, and the small-bird version was at an advantage.
PG: There was a major shift in the frequency of these two variants—the variant associated with small size increased. Until this discovery we had plenty of reasons for thinking that evolution had taken place but no genetic evidence of a change in gene frequencies. This was the clincher. That’s why it was so exciting to us.
RG: Sequencing genomes can reveal so much more if you have the actual knowledge of the population in the wild. Putting that together has become enormously rewarding. We’re lucky that we can do this. We always kept our blood samples and song recordings and were able to go back. I hope that in the future, there will be greater appreciation for putting together genomic work with fieldwork.
What new questions are you most excited to explore?
PG: The Big Bird story. We want a genetic underpinning for Big Bird like we have for the selection in 2005. We’re waiting for the data.
You didn’t originally plan to keep going back to Daphne for as long as you did.
PG: No one who does long-term studies expects at the beginning to go back for a long time. We were lucky to have rewards at the beginning.
Do you plan to go back to Daphne?
RG: We stopped intensive work after 40 years, but we do plan to go back.
PG: The oldest person died at 122 years old. That means we have 40 more years.
Original story reprinted with permission from Quanta Magazine, an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.
At their core, data tell stories. They reveal patterns, show changes over time, and confirm or challenge our theories. And in cities across the country, mayors, police chiefs, and other local leaders are turning to data to help them understand and address gun violence, one of the most persistent crises they face.
Ted Alcorn (@tedalcorn) is Director of Innovation atEverytown for Gun Safety, the nation's largest gun violence research and advocacy organization, which recently issued a comprehensive report entitled Strategies for Reducing Gun Violence in American Cities.
Innovative, data-driven programs are showing encouraging results. To keep high school students on the right track, the city of Chicago scaled up a school-based program called Becoming a Man for seventh through tenth graders living in neighborhoods with high rates of violence. The students reflect on their life goals, observe how their automatic responses inside school and outside school differ, and learn to slow down and react more thoughtfully to these sometimes divergent social environments. An adaptive behavior on the street, like fighting back to develop a reputation of toughness that could deter future victimization, will be maladaptive in other social situations. To test the impact of the program, the University of Chicago Crime Lab built a rigorous evaluation into its rollout. After two years, they were able to show that participants were 50 percent less likely to be arrested for a violent crime than students in a control group, and those students graduated at a rate 19 percent higher than those who did not participate. This close analysis of the program affords new insight into what makes the program work, and how to enhance it and apply it in other settings.
While the Becoming a Man study required significant coordination and planning, sometimes measures as simple as counting can produce remarkable findings. Law enforcement officials have long noted that substantially more illegal guns are recovered from Chicago streets than other large US cities—almost as many as in New York City and Los Angeles combined. And when the Chicago mayor's office analyzed the sources of those recovered firearms, with help from the University of Chicago Crime Lab, it found that many had been first sold by just a small number of gun dealers in the suburbs of the city. One gun dealer in Lyons, Illinois, alone accounted for 659 guns recovered between 2009 and 2013.
When this data came to the attention of the mayor of Lyons, he decided to do something about it. Working with the gun dealer and local law enforcement, he developed a local ordinance for responsible gun sales that requires local shops to comply with several safety measures, including background checks for employees and regular inspections, similar to the Responsible Firearm Retailer Partnership that Mayors Against Illegal Guns (a project of Everytown) developed with Wal-Mart. These types of measures could serve as models far beyond the borders of Lyons.
Other communities offer their own examples of how data can provide insights to improve public safety. In Lafayette Parish, Louisiana, an analysis of crime data last year showed that car burglaries were a leading source of reported gun thefts in the city—a trend that cities have been noticing nationwide. To better keep guns out of dangerous hands, a local criminal justice agency responded by designing a public information campaign that encourages car owners to lock their cars to protect guns and other valuables from theft, and it's drawn the attention of both law enforcement and the public to this often-ignored source of guns used in crimes.
America’s Got a Gun Addiction. These Numbers Prove It
An Intriguing Link Between Police Shootings and Black Voter Registration
What an AR-15 Can Do to the Human Body
In Milwaukee, Wisconsin, city and law enforcement leaders have convened regularly for more than a decade as part of the Milwaukee Homicide Review Commission, which studies each of the city's shootings and sifts them for patterns that can be turned into prevention strategies. In 2006, the commission noted that 10 of the city's killings in the first six months of the year—about one-tenth of all murders in the city at the time—had followed a dispute at one of the city's bars. Acting on this information, the city passed a new rule requiring bars to install security cameras after three crime-related police service calls, and homicides at or near bars dropped significantly in the years that followed.
Programs like these will not end gun violence on their own. Cities face an uphill battle while a loophole in our federal gun laws continues to enable criminals to easily buy guns from unlicensed sellers—including strangers they meet at gun shows and online—without a background check. But even with this challenging backdrop, communities large and small are making strides that are saving lives, and they must continue to do so. In September, people involved in each of the examples above participated in the Data for Good Exchange, a conference that brings together innovators from cities across the country to discuss the novel uses of data driving a number of public interest programs.
As officials in Chicago, Lyons, Milwaukee and Lafayette Parish know, we must refuse to accept our urban gun violence crisis as unsolvable. The data show us that it isn't.
This story originally appeared on Mother Jones and is part of the Climate Desk collaboration.
Rivers in eastern North Carolina, still swollen from Hurricane Matthew's downpours, are flooding a region that teems with hog and poultry farms. As many as 5 million chickens and turkeys had already died as of Wednesday, Reuters reports. The North Carolina Department of Environmental Quality has so far not released an estimate of hog deaths, but they could be steep.
That's because North Carolina is home to one of the globe's highest concentrations of pork production. Clustered mainly in five counties in the state's southeast region, 2,000 large-scale hog operations churn out about 10 million hogs annually, more than any other state except Iowa. And it's not just animal corpses that are likely to stream out of inundated farms. Together with the state's chicken houses, North Carolina's hog barns generate 10 billion gallons of fecal waste annually, "enough to fill more than 15,000 Olympic-size swimming pools," reports Environmental Working Group, much of it stored in open cesspools known as "lagoons."
Hog manure is loaded with pathogenic bacteria, including antibiotic-resistant ones, antibiotic residues, and plenty of nitrate, which fouls drinking water and also feeds dead-zone-causing algae blooms. University of North Carolina researcher Steve Wing has spearheaded a rising tide of research documenting how the state's hog facilities harm nearby residents, who are disproportionately low-income African Americans.
What happens when storm floods meet vast confined hog-rearing facilities and their lagoons? The Waterkeeper Alliance's Rick Dove has been taking extraordinary aerial photos like the one above. Typical hog confinements, like the white buildings on the right in that photo, hold about 2,000 hogs each. According to the Environmental Working Group, there are 586,092 hogs in Wayne County and 229 manure lagoons.
Waterkeeper Alliance's Dove told me that in his recent airplane forays over eastern North Carolina, "Some of those lagoons were so submerged that we didn't even know they were there when we photographed them."
In many cases, Dove said, he didn't realize until he and his team got back on the ground and compared their aerial photos with Google Earth images. As an example, he pointed to the image below, taken of a hog operation in Seven Springs, Wayne County.
The Google Earth image of the same site shows no fewer than three lagoons that are submerged in the above photo.
Here's another one of Dove's photos, taken October 10, capturing an obviously flooded lagoon in Wayne County.
Another one, taken October 12, shows just how close some Wayne County hog operations are to the Neuse River.
The next two, captured on October 10 and 11, respectively, show scenes from Duplin County, where a staggering 2.3 million hogs are raised each year, more than any other US county. The state has not released information on the extent of hog deaths in flooded facilities, but these images paint a grim picture.
In recent years, North Carolina's eastern counties have seen hundreds of industrial-scale chicken houses appear, adding yet another source of concentrated manure. They, too, are prone to flooding, as this photo shows.
Back in 1999, Hurricane Floyd wrought similar havoc in North Carolina hog country, washing untold amounts of raw manure and hog corpses into watersheds and creating a 350-square-mile dead zone in coastal estuaries. Here's how Jeff Tietz described it in a seminal 2006 Rolling Stone piece "Boss Hog":
Hurricane Floyd washed 120,000,000 gallons of unsheltered hog waste into the Tar, Neuse, Roanoke, Pamlico, New and Cape Fear rivers. Many of the pig-shit lagoons of eastern North Carolina were several feet underwater. Satellite photographs show a dark brown tide closing over the region's waterways, converging on the Albemarle-Pamlico Sound and feeding itself out to sea in a long, well-defined channel. Very little freshwater marine life remained behind. Tens of thousands of drowned pigs were strewn across the land. Beaches located miles from Smithfield lagoons were slathered in feces. A picture taken at the time shows a shark eating a dead pig three miles off the North Carolina coast.
It's still too early to tell whether the damage from Matthew will reach or surpass that scale as rivers continue to flood. A North Carolina Department of Environmental Quality spokesperson told Reuters that many hog lagoons have been inundated and are leaching into waterways. Dove flew similar photography runs after Floyd in '99, and says that from his observation, some places have been harder hit by Matthew than by Floyd, and others have gotten off easier. And rivers are still cresting, causing new floods as storm waters make their way east through North Carolina's hog counties, Dove said. "It will be days before we know the extent of the damage," he added.
Click through the gallery to see this week’s helping of the best the universe has to offer. And if you need more when you’re done but can’t wait until the next one, here’s the entire collection.
When Nathan Copeland got into a car accident in 2004, he suffered a spinal cord injury that left him paralyzed in both arms and both legs. Eventually, Copeland got a prosthetic—but one that is very different from most anyone else’s out there. Copeland is the first person in the world to use a system created by DARPA and the National Science Foundation, which allows him to “experience” the sensation of touch via a special robotic prosthesis. He has a brain implant that lets him control and feel the system with his mind. Pretty amazing stuff.
Oh, he’s also one of the few Americans who has personally met the President of the United States.
'I confess I’m a science geek. I’m a nerd. I won’t make any apologies for it.'
President Barack Obama
Yesterday in Pittsburgh, during the White House Frontiers Conference, Barack Obama went on a tour of the most cutting-edge US technologies. With just a few months left in office, Obama is seeking to cement his legacy as a whole-hearted supporter of science—something that has been a clear differentiator between camps in this crazy election year. Science and technology, Obama seemingly hopes to underline, leads to progress—and, yes, American success.
But more than just being a trumpeter of this message, watching Obama nerd out on science projects himself proves how much of one he is. "I confess I’m a science geek," Obama announced at the conference. “I’m a nerd. I won’t make any apologies for it." And this much was clear as he spoke with a handful of Pittsburgh scientists and academics who let him tinker with their machines and ask about their research.
The first stop on the tour was to shake Copeland's hand. The President chatted quietly, almost conspiratorially, with Copeland, and with University of Pittsburgh assistant professors Robert Gaunt and Jennifer Collinger, who explained to him the science of how the robotic arm worked. Obama held the fingers on the arm, which was mounted to a metal post by Copeland’s side, and moved them one by one. Then he shook the robotic hand. “Do you want to blow it up?” the President asked Copeland. “Let’s blow it up!” The two fist-bumped and mimicked exploding fingers. “Boo-yah!” Obama said.
Then, rather suddenly, he turned to the gathered crowd: “Does everyone fully grasp what’s going on here?” Obama explained not only was Copeland moving the arm himself, using his own brain, whenever he moved the hand it also sent signals to Copeland. “You can imagine what this means over time as this gets miniaturized and more sophisticated,” Obama said. “Somebody who may currently have paralysis but now has, essentially, a set of robot limbs? Nathan’s going to be in a position where there’s all the kids of stuff he’s going to be able to do, and do it without having to manipulate something mechanically—but simply generated by what he’s thinking.”
“Is it painful?” a member of the press called out.
“No, never painful,” Copeland answered. “Look at him!” Obama chimed in. “He’s pretty chill.”
“Tiring?” a reporter pressed. As Copeland said next to no effort was needed, Obama joked, “If you moved your arm up and down all day, you’d get tired of it too.”
Obama then met with a NASA astronaut and Boeing representative, who taught him how to operate a spacecraft flight and docking simulator. The video game-like contraption—complete with dual screens, various knobs and levers, and a sloping hood above Obama’s seat—is the training setup that NASA’s own astronauts are using to prepare for future missions to the International Space Station.
“Uh, let me try to get comfortable,” Obama said, approaching the intimidating-looking machine. “Let me take my jacket off.” He shed his coat and sat in front of the controls, rocking the chair back and forth like a kid testing out the seat of an arcade game. The experts coached him on how to use the simulator—left, right, left. The representative from Boeing representative told Obama what speed he should aim for, but told him not to go so fast that he crashed into the ISS.
'Your ride is here, baby!' the President said as he docked the spacecraft into the ISS.
“I don’t want to crash!” cried Obama. “This is really expensive stuff… OK, let’s drive.”
A few minutes later: “I’m so tense!” Obama said, struggling to follow the commands and not let the spacecraft drift. The scene made for a pretty good case for anyone who wants to defend their childhood love of video games. And finally, after several moments: “Your ride is here, baby!” the President said as he docked the spacecraft into the ISS. “This is like the Uber shuttle. Just call, they’ll be there in five minutes.”
The press crowd, trailing Obama, hurried over to an autonomous flying machine demo from Carnegie Mellon used for inspecting bridges, imaging, and mapping. Standing in front of one of the screens that apparently sensed motion, Obama flapped his arms for a bit, checking to see if his movements would register.
So, President Obama’s Got a Workout Playlist. Let’s Rank Its Songs
Barack Obama Talks AI, Robo-Cars, and the Future of the World
How to Watch President Obama’s Essential Sci-Fi TV and Films
Several minutes away, one last demonstration awaited Obama: a SpaceX Dragon capsule that has been successfully tested by NASA and meant to keep astronauts safe during human spaceflight. “You almost want to get in and take off, don’t you?” Obama asked. He wondered out loud what it'd be like to bring the whole family along for a trip, and how his kids Malia and Sasha might react to being in the backseat.
And when a SpaceX representative said the company could one day visit Mars, Obama said, “That’s our goal.” Pushing the frontiers of human achievement, at least to this US President, means one day leaving this world entirely. Presidents: they're kooky science lovers, just like us! Apart from the cabal of Secret Service keeping crowds back at all times. Oh, and they have access to cooler toys, too.
Last week, Tanzania planted its first ever genetically modified crop—a drought-resistant white corn hybrid. Government researchers will spend the next two to three years monitoring the plants for safety and effectiveness at growing in perilously dry conditions. It's a notable milestone, given the nation's longstanding lack of enthusiasm towards biotechnology. But as much as Tanzania’s turnaround is unique to its particular politics, history and culture, it’s also part of a quiet regulatory reversal in Africa. Other countries facing climate change-fueled food insecurity are beginning to bet on biotech.
Until last year, Tanzania was a very difficult place to even think about owning a genetically modified crop product, let alone growing one. Under a “strict liability” law adopted in 2009, anyone involved with importing, moving, storing or using GM products could be sued if someone else claimed the product caused them harm or loss. And that broad definition went beyond personal, it included environmental damage. Effectively, it was a regulatory blockade.
“Tanzania has been a nightmare, with that strict liability clause,” says microbiologist Jennifer Thompson, who is on the board of the African Agricultural Technology Foundation. “Until last year we had never bothered to apply for field trials there because we knew it was such a lost cause.” AATF manages the Water Efficient Maize for Africa (WEMA) project, which developed the GM maize (another word for corn) hybrid for Tanzania.
The repeal's timing was no coincidence. In the last 18 months, unusually high temperatures and a brutal El Niño have punished many parts of Africa with drought. Ethiopia, 400 miles to the North of Tanzania is currently experiencing its worst water shortage in 30 years. South Africa just emerged from its worst drought since 1904. According to the World Health Organization, at least 30 million people in Southern and Eastern Africa will be affected by the water shortages this year.
It is in this context that nations like Tanzania are rethinking their GM food crops positions. Maize is the main food source for one out of every four Africans, and droughts hit it hard. While WEMA has also been developing and distributing non-GM drought-resistant hybrids, so far they have proved to be less efficient than the engineered version. At present only South Africa, Egypt, Burkina Faso and Sudan grow GM crops commercially, but that is likely to change in the next few years.
In January and March of this year (respectively), Malawi approved confined field trials for insect-resistant cowpea and a genetically modified banana being evaluated for resistance against the Bunchy Top Virus that decimated banana crops in the region last year. Uganda also approved field trials of a cooking banana variety engineered with Banana Bacterial Wilt resistance in March. Kenya granted a conditional approval for Bt maize performance trials in February.
“It’s really exciting, because until the crop is in the ground this is all just talk,” says Pam Ronald, a plant geneticist at UC Davis whose own work with flood-resistant rice resulted in a variety now being grown by 5 million farmers in India and Bangladesh. “Farming everywhere in the world is empirical. But you can’t see how useful something is until it’s actually in a field somewhere. And that takes leadership that is going to make decisions based on science and the needs of farmers rather than an abstract ideology imported in from developed countries.”
Philbert Nyinondi planting maize seeds for the first GMO field trial in Tanzania.
She's talking about the EU, and its hard line stance against GM crops. That imported ideology gets promoted by opposition groups backed by European dollars; The Tanzania Alliance for Biodiversity, the country’s loudest opponent of GMOs is comprised of 19 partner organizations, 11 with roots in Europe. Economics play a role, too. Trade laws allow EU countries to ban cultivation of GMO crops within their borders (would you want to grow something other people won’t eat?).
Also in less overt ways. When talented Tanzanians leave their homes to access higher education abroad, they leave a void in homegrown biotechnology. As of 2015, Tanzania’s top academic institution had fewer than 20 staff with backgrounds in the agricultural sciences and only one staff member in the Department of Molecular Biology and Biotechnology (according to its website). In that research vacuum, multinational corporations come in as Plan B.
The Alliance for Food Sovereignty in Africa (a partner organization of the Tanzanian Alliance for Biodiversity) is opposed to the GM trials. "There are many other ways that Tanzania can produce its own food,” wrote Million Belay, an organizer for the Alliance. Data seems to prove otherwise: According to the FAO, 32 percent of Tanzanians are currently undernourished. And in a country where 80 percent of the population are subsistence farmers, that implies that millions of people are not able to grow enough food to feed themselves.
Philbert Nyinondi understands why so many Tanzanians might be distrustful of GM crops. As his country’s coordinator for the Open Forum on Agricultural Biotechnology, he has been traveling Tanzania for the last few years (no easy feat—it’s twice as big as California!) talking to farmers and organizing workshops with local leaders and policy-makers about bringing the benefits of biotechnology to their farm fields. “With a controversial topic like GM, one will not simply trust a text message or a statement heard on the radio, especially when it goes against people he or she has been working with over the years who are against the technology,” he says. "We have the strongest base of GM opponents in the East Africa region. Unless you physically reach out to communities to present a case, you cannot push past challenges like the low levels of scientific understanding among the general public.”
Which is why he believes this new maize is so important. Yes, Monsanto donated the drought-tolerant genetic traits to the project. But with a royalty-free licensing agreement in place, the drought-resistant corn, like all WEMA maize hybrids, was developed specifically to suit local conditions and will be made available to smallholder farmers through local seed companies at an affordable price—pending successful trials. That's as close to a homegrown GM crop as anything else that’s ready in Africa right now. And it’s this convergence of local GM solutions coming online at a time when climate change impacts are really starting to be felt on a daily basis that has tilted the balance of power away from the luxury of caution and toward the urgency of feeding not 9 billion people by 2050, but millions of people now.
And it's also important to not trivialize the weight of history here; if you’d spent hundreds of years having white people showing up in your country telling you what gods to believe in, what clothes to wear, and yeah, what crops to plant (not to mention slavery, genocide, and warmongering), you’d be wary too.
Hats off to Elon Musk. He gave us Paypal, Solar City, and Tesla Motors. If only some of his other, more ambitious ideas warranted the same praise. Take his latest plan, to shoot people off to Mars. Though details remain a bit confused, the key takeaway is tickets to Mars would sell for the modicum price of $200,000 apiece by 2024.
Of course, Musk's plan assumes someone is willing to front $10 billion or more to pay for all that gee-whiz rocketry and infrastructure he described at the International Astronautical Congress. (It also assumes $10 billion is enough, but more on that later.) When SpaceX debuted, Musk claimed his rockets would be 10 times cheaper, 10 times more reliable, and provide 10 times the flight rate of existing rockets—at least a 1,000-fold improvement that never came true. Musk's ambitions seem to rely on that old Silicon Valley magical thinking, of an exponential growth curve predicting cheaper access to space. But he offers neither sufficient technology improvements nor evidence of demand to add up to a $200,000 trip to Mars. Musk is coming from a Moore's Law world of computers and cars. Mars is not a Moore's Law world.
John Pike, director of GlobalSecurity.org, is an expert in space, defense, and intelligence policy, and is frequently called upon to testify in front of congress on these issues.
Concerning technology, two types of problems exist: engineering problems that can be solved and physics problems that cannot be solved, only accepted and worked around. Solutions to engineering problems generally have a key performance parameter that embodies the essence of the solution. Take Moore's Law. Around 1965, Intel co-founder Gordon Moore observed that overall processing power for computers—the number of transistors on an equal-cost CPU—would double every two years or so. Moore's Law was born, with a pretty amazing S-curve with persistent exponential growth that is responsible for the technological vastness of the future.
A Moore's-like growth curve requires an infinitesimal number of intermediate steps of improvement. Each year's CPU, airplane, or automobile is slightly better than last year's. As economies of scale lower costs, the market expands.
In contrast to computers and cars, technologies with which Musk is familiar, rockets cannot be systematically improved. Specific impulse—the number of pounds of thrust produced per pound of propellant—is the key parameter capable of producing significant cost reductions in access to space. Technological solutions to improving specific impulse include building lighter rockets or finding better fuels. And rocket scientists optimized both of those when Eisenhower was president. That leaves the physics problem: Mass versus gravity. The only way to work around it is through economies of scale, driving down operational costs through an increased launch tempo.
The problem with economy of scale is it relies on demand. SpaceX's current launch tempo owes a lot to commercial satellite launches. Information is space's biggest market. Naively, one might have hoped that the growth in satellite communications would have increased demand, and thus launch tempo, driving down prices. But the capacity increase was, ironically, eaten up by Moore's Law—which allows satellites to transmit more information. Communications satellites have not significantly increased the demand for mass to orbit.
Crewed spaceflight, in order to incur demand without cost, must go from the Wright brothers to the Concorde with no intermediate steps. But putting people into the equation makes the continuous improvements harder to meet. There are a handful of "islands of stability"—discrete objectives for piloted missions—100 km hop for tourists, low Earth orbit, the Moon, and Mars. Similarly, there was an X-Prize for a 100-kilometer altitude flight, but none for 200 km. But the increments between those are huge, in terms of cost. No one remembers the first astronaut to go halfway to the Moon, because nobody cares what's between the two. There was nothing between Neil Armstrong's small step for a man and his giant leap for mankind. The very nature of space makes incremental steps moot.
One of the fundamental problems with a grand visionary projects such as shooting people to Mars is they do nothing to solve the underlying problem of physics, laws of thermodynamics, and the most grand, visionary aspect of all: How to pay for them. Musk ignores the fact that NASA and others have outlined similar roadmaps to Mars for more than 50 years. He waves away the risks and technical limits of current technology to make it happen reliably, cheaply and safely, as if Moore's law is easily applied. He shies away from discussing the infrastructure and work required to make it happen, letting others spell it out.
Moore's Law is a product of Silicon Valley, as is the tendency to misapply—with overreaching drama—it to various capital-P Problems. The September, 2013, issue of Time featured a cover story raising the tantalizing question "Can Google Solve Death?" And yet people are still turning up dead. Mark Zuckerberg and his wife, Priscilla Chan, announced a $3 billion effort "to rid world of major diseases by end of century." Contrast that with the National Institutes of Health's annual budget of more than $30 billion (about 2.5 trillion through 2099), with no such promise of ending ailments for all. Musk estimates that it will cost $10 billion to reach Mars. Every time NASA has pondered manned missions to the planet, the price has been several times the $150 billion (more or less) spent on the Apollo program to the moon and back. Not every problem has convenient engineering solutions.
Vision without funding is hallucination. Mars is not a how problem, it is a why problem. I grow weary of pretty pictures of rockets. Musk has done the easy part of sketching the obvious destination. The hard part is why—why pay for it? And that has been on hold for decades. Musk's rocket blueprints put us no closer today than we were half a century ago.
The pattern showed up in old telescope data: Weird variations in the light patterns of about 230 stars. The astronomers—a pair of Canadians—published their analysis, along with what they believed was the culprit: Aliens.
SETI researchers quickly countered that the patterns were probably just artifacts from analyzing the data, and the Breakthrough Listen project published a response pointing out several flaws.
Caveats aside, the Breakthrough Listen rebuke also assigned the finding a number: 1. According to the Rio scale—used by SETI researchers to assess the likelihood that a suspected alien signal actually came from ETs—that means the finding is "insignificant." That's one above 0 (“no importance"), and nine below a perfect 10 (“extraordinary”). Not quite a scientific tool, the scale's main purpose is to inform the public. Which is important for SETI, a field constantly guarding its scientific cred—while talking about aliens. And the scale isn't perfect, but SETI scientists are now working on revamping it and using it in earnest.
The scale originated (naturally) with an internet hoax. In 1998, a British man claimed he had detected a signal emanating from the star system EQ Pegasi and sent a tip to the BBC, who broke the story. “The media jumped on it right away,” says Seth Shostak, a senior astronomer at the SETI Institute. The SETI community tried to quash the story, and it was eventually debunked, but scientists wanted to head off future hoaxes. So, at a 2000 conference in Rio de Janeiro, astronomers Jill Tarter and Ivan Almar presented a paper laying out their scheme for the scale.
Essentially, the (so named) Rio scale takes into account the following: What was the observation? (An intriguing radio signal? Flashing laser beams? An actual, physical encounter?); How far away did it originate?; How often did it occur? Those factors, lumped together, are multiplied by the report's credibility—did it come from a credentialed university group, or some internet rando?
Ready to calculate? The International Academy of Astronautics has a handy online calculator!
Scientists can go back and grade past signals on the scale, like the famed 1977 Wow! signal, which gets anywhere from a 1 to a 3. But that variable range exposes a problem with the Rio scale. Astronomers complain that there’s no standardization to using the scale, no repository where the ratings of past signals are kept, and no standard announcement process (that people follow). It’s mostly used on an ad hoc basis, and some astronomers don’t even know it exists.
And that's all in addition to a few major flaws. First, the Rio scale is hard to use on the fly. It asks for a lot more information than is typically available in a lot of cases. “By the time you have all the information, the story’s already gone,” Shostak says. There goes the usefulness to the public. Plus, it assumes that you’re dealing with aliens in the first place, which just isn’t true most of the time. And deciding what sources are credible can get subjective.
But scientists still use the scale. During an advisory board meeting for the Breakthrough Listen project this year, the board recommended that astronomers make a concerted effort to use the scale and standardize their responses to it. “It’s even more pertinent in 2016 given the way news is reported now, with social media and shorter news cycles online,” says Steve Croft, a radio astronomer at the project.
Plus, it’s good for controlling expectations, says Eric Korpela, the head of the SETI@home project at UC Berkeley—it’s hard for a possible signal to even get a 2. “People tend to be disappointed when we don’t find anything,” he says. “The scale gives them some realism.”
But the Rio scale is just one answer to a bigger problem of SETI stories getting away from scientists in the news. Bad press has shaped the science of looking for extraterrestrial life—in one memorable instance, by Congress pulling the plug on a NASA project in 1993 after a Congressman accused it of wasting taxpayer money and called it a "great Martian chase." (The field has largely been funded by private donors ever since.)
So when reports of alien signals pop up in the news, SETI scientists tread a delicate line: they have to respond with extreme skepticism because once things get overblown, it makes the work of everyone else in the field look a little less legit. No matter how much they believe the truth is out there.
The odds are stacked against Haiti. Geologically, it's wedged between tectonic plates, where earthquakes happen. Meteorologically, it's in the center of hurricane alley, where massive storms roil. And historically, the country is forever fighting a colonial legacy that left it largely incapable of recovering from natural disasters. Like endemic cholera, caused by the United Nations' botched response to 2010's earthquake and exacerbated by Hurricane Matthew flooding the country's southwestern peninsula.
The hurricane may have put cholera in the news again, but really, the disease never went away. In the six years since cholera seeped from a UN camp's faulty plumbing, it has infected at least 800,000 Haitians and killed nearly 10,000. "There's no doubt that the main route of transmission is contaminated drinking water that hasn't been filtered or heated," says Art Reingold, an epidemiologist at the School of Public Health at UC Berkeley. Its symptoms are diarrhea and dehydration, sometimes serious enough to be fatal. But thanks to the work of Haiti's Ministry of Health, the disease peaked in 2011 at 6,766 cases a week. Since then, the number of cases has dropped by 90 percent, and the fatality rate fell slightly, from 1.04 percent to 0.075 percent.
So that's good news right? But get this: In 2016, the country reported 771 cases every week, with 28,559 in the last ten months. That was before Matthew hit, knocking back the Ministry's progress and bringing the perfect conditions—flooding, mostly— for a cholera epidemic to spread anew. Since the storm, health workers have diagnosed more than 200 people, and 13 have died. "We're seeing a resurgence of an outbreak," says Patrick Dupont, program director for Haiti at the Real Medicine Foundation, a humanitarian support group that works in disaster-stricken areas. "It wasn't completely cured or eliminated in Haiti at all."
Not for lack of trying. Since 2010, Haiti's Ministry of Health has invested in safe water infrastructure, and partnered with NGOs to administer oral vaccines. They established protocols for putting cholera treatment facilities next to, but separate from, general care hospitals. "If a hospital practicing general care identified a cholera patient, he or she was referred to a center, so they could isolated, treated, and doctors could control dissemination," Dupont says.
But those cholera treatment facilities were often just plywood structures or tents. You can imagine how well those survived Hurricane Matthew. Only five of the original 12 remain, according to Sean Casey, the International Medical Corps' emergency response team leader in Haiti. Along with general care facilities, these remaining centers have seen an influx of people since Hurricane Matthew, and healthcare workers are no longer able to isolate cholera-infected patients. When kept in the same area as everyone else, the chance of transmission goes up.
"New outbreaks are happening where cholera treatment facilities can't function the way they're supposed to," says Casey, who flew to Port-au-Prince from the Dominican Republic by helicopter. Now in Le Cayes, the hub of response operations after Hurricane Matthew, he's still trying to understand how bad the outbreak is, because the affected areas are only now becoming accessible. Compared to what the weekly numbers were prior to the storm, the resurgence doesn't seem like much. But the low numbers are probably because the country's health agency and its NGO allies don't have all the data.
Though the direct impacts from the 2010 earthquake claimed more lives than those from Hurricane Matthew, the cholera complications will likely be similar: An outbreak, compounded by bad infrastructure, overworked health services, and extreme poverty.
For now, rescue teams are distributing water purification tablets and working to keep the disease from spreading further. (The World Health Organization is sending a million doses of preventative cholera vaccine). But even if aid workers and local health officials get this outbreak under control again, the odds against Haiti won't have changed.