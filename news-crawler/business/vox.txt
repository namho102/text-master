
When the people of Greece go to the polls on Sunday to decide on their economic future, they're going to face a really difficult choice. They're being asked to decide whether to accept European demands for further austerity. If they reject those demands, they're likely to be forced out of the euro altogether.
We're torn on how Greeks should vote, because all of their options are bad. Either option is likely to lead to more economic pain, and there's a lot of uncertainty about the long-term results of either decision.
But we thought it would be interesting to write what we felt were the strongest arguments on each side. Matt Yglesias wrote his strongest case for a "yes" vote, while Tim Lee wrote the case for voting "no." But neither one of us is sure that we picked the right side.
The best case for a "yes" vote on the Greek referendum is simple: Germany and other major European states will want to make a Greece that votes "yes" look like a success. They'll want to grind a Greece that votes "no" into the dust. And they'll have the power to do.
The truth is that no matter what Greece does, Greece is still going to be a relatively small, relatively poor country with little leverage against either its larger, richer, and more powerful European partners or the financial markets. What those partners want Greece to do is to commit to staying on the euro, commit to running modest but meaningful primary budget surpluses, and commit to pursuing a menu of "structural" reforms of its economy.
But if Greece doesn't do that, then what those partners will want to do is make an example out of Greece to ensure no other Eurozone member ever dares to consider following their lead.
The European powers-that-be have strong incentives to make a "Grexit" as painful as possible. If Greece experiences rapid recovery post-eurozone, that will make the Eurozone project look misguided and call the continued membership of Portugal, Spain, and other states into doubt. That would have negative consequences for the citizens of those countries, while also making politicians in Europe's most powerful countries look ridiculous.
It's true that Greece would be better off today if it had never joined the Eurozone. But as Greek Finance Minister Yanis Varoufakis himself argued back in 2012, "while almost everyone would prefer Greece to have been outside the eurozone, the actual cost of severing Greece will prove equal to that of dismantling the eurozone itself painfully, slowly, catastrophically." Varoufakis' argument at the time was that Greece should therefore default without leaving the Eurozone. This is a perfectly fine idea for Greece, except that Greece's European partners have made it clear that they won't stand for it. If Greece defaults, the European Central Bank will stop providing the Greek banking system with the euros it needs to operate. In that case, the Bank of Greece will need to provide them with some other currency and Grexit will be a reality.
But the terms of the departure will be messy and difficult for Greek citizens. They will receive no leniency in the treatment of euro-denominated debts that they owe to foreigners, and little cooperation in setting up clearing systems for international financial transfers. Rightly or wrongly, Greece will be treated as a pariah that chose to isolate itself from the continent's financial and monetary systems.
If Greece votes "yes" the path ahead is by no means easy but it is easier.
It starts with the fall from office of the current Syriza-led government, whose high-stakes gamble that it could extract better terms from Europe has utterly failed. It will probably be replaced by a new version of the old mainstream coalition that preceded it. That new coalition, by reaffirming its commitment to groveling and doing what Europe wants, can begin to rebuild a little of the good will that Greece has lost during the Syriza months. That won't lead to major concessions in the short-term, but it could lead to more leniency in the months and years that come.
None of Greece's current options look very attractive, and not much about the situation in which Greece finds itself is totally fair. But the best thing Greece can do for itself is to stop worrying about things that are out of its control, and recognize that going along to get along is more likely to work than any of the alternatives.
The best argument for Greeks to vote "no" on Sunday is simple: the euro is a disaster. And voting no is the quickest way for the Greeks to get out of it.
The euro is a kind of macroeconomic straitjacket. Central banks are supposed to print more money when the economy is in a recession, and print less money when the economy is booming. But the European Central Bank is responsible for the health of 19 different economies, and at any particular point in time they will have wildly different needs.
Right now, Greece is suffering from 25 percent unemployment, while Germany is enjoying 5 percent unemployment. Greece needs more monetary stimulus; in Germany, more stimulus would only create inflation. There's no way for the ECB to craft a monetary policy that will serve both countries well.
This isn't a problem that's going to go away. Europe will have more economic downturns in the coming decades. And each time this happens, the economic straitjacket of the euro will make it harder for some of Europe's economies to recover as quickly as they could. And as one of the poorest and most isolated of the European economies, Greece is among the most vulnerable.
European elites were aware of this problem when they created the euro, and they had a plan for solving it, under the slogan "ever closer union." The idea was to gradually make Europe more like the United States. In the US, we also have a single central bank setting monetary policy for 50 state economies. The difference is that America has a much more integrated economy. Much of the tax collection and government spending in the United States happens at the federal level. People regularly move from one state to another in search of work. The huge economic disparities we see between Germany and Greece today don't tend to exist among American states.
The problem is that this kind of integrated economic system ultimately requires an integrated political system. Americans see themselves as Americans first and Floridians or Oregonians second. People in wealthy Connecticut don't get too outraged that their tax dollars are subsidizing people in West Virginia.
That's not how things work in Europe. Germans and Austrians have no interest in paying for welfare benefits for people in Greece and Spain. For that matter, people in Greece and Spain don't particularly want to give up sovereignty to the European Parliament. A European superstate isn't going to happen any time soon.
Matt is right that European elites have an incentive to make a Greek exit as painful as possible for Greece. But Europe can only inflict so much pain on the Greeks as they exit the euro club. Greece is still a sovereign nation, and there are many countries it can trade with outside the European block. Moreover, Europe will have both geostrategic and humanitarian incentives not to push Europe too far.
But the larger point here is that the worst effects of a euro exit would be be over fairly quickly — probably within a year or two. After that, the Greek economy could enjoy significant upsides. With its own currency, it would have a lot more leverage to renegotiate its debt burden. And with its own central bank, Greece would be able to pursue a monetary policy that's more appropriate for the highly depressed state of the Greek economy.
Leaving the euro is hardly a panacea. There's a risk that leaving the euro would produce a severe and protracted panic that's even worse for ordinary Greeks than the endless 25 percent unemployment they're suffering from now. Greece will have to pay higher interest rates for decades after leaving the Eurozone, and it will have to work hard to convince foreigners to take its currency seriously. But in the long run, Greece's future outside the Eurozone is likely to be better than its future inside of it.
Back in 2011, before the most recent reorganization of Greek debt, German Chancellor Angela Merkel told her personal assistant that Greece's debts would still be unsustainable under the terms of the new arrangement unless it received more generous assistance from Germany and other wealthier European countries.
That's according to this National Security Agency intercept of her communications, revealed to the world by Wikileaks:

NSA Merkel phone tap: chancellor saw Greek debt as unsustainable in 2011 even with another haircut #Wikileaks #Greece pic.twitter.com/78B9cuiRDJ


This is one of these things that's going to be treated as a bombshell by some, and as "everyone already knew this" by others. Understanding why some will scream and others roll their eyes helps explain some important aspects of the situation.
Greece's debts really are unsustainable. This is just basically not a debatable point. The reason it's not genuinely shocking to hear that Merkel privately admitted this is that nobody really disputes it. Greece's creditors know that they aren't going to be paid back. But they want the debt to stay on the books anyway.
Why?
Well because as long as the debt is on the books, Greece needs to keep asking for permission to roll the debt over and failure to pay debts can be used as a political trigger for forcing Greece out of the Eurozone. The debt, in other words, isn't about money. It's about political control. If the debt is formally forgiven then not only do Greece's creditors need to write down some money, but they need to let Greece go on its merry way. If the debt is merely subjected to repeated rounds of extend and pretend then Greece's creditors get to keep making various demands about structural reform.
It's not, in other words, that Europe wants Greece to reform in order to get its money back. It's that Europe wants Greece to remain formally on the hook for its debts as a tool to get Greece to reform.
That's what "everyone knows" about the situation, and it's what "everyone" knew last week, last month, and last year. European Union bureaucrats will tell you, the Greek government is well-aware, and it's all-in-all not exactly a big secret.
But this is kind of like how "everyone" knew that the link between Saddam Hussein and 9/11 was about altering US risk-tolerance rather than about direct operational ties. Nobody told the American voting public! In fact, they were told just the opposite to keep the whole project viable.
By the same token, the stories that are being told to the population not just of Greece but also of Finland, Germany, Austria, the Netherlands, etc. are not that Greece's debt is a symbolic and legal token of political control whose purpose is to allow Greece to be governed by experts at the European Central Bank rather than elected officials in Athens. They are being told that Greece's debt represents real monetary value that is owed to Northern Europe's taxpayers, and that whether or not they get their money back is a huge point of contention.
The flipside of this is that Greek politicians have been engaged in their own version of this same misleading dance. They tend to present their requests for debt forgiveness in terms of a technical analysis of what is sustainable and realistic, the way a bankrupt company might negotiate with its creditors.
But a bankruptcy agreement is legally enforceable. For Europe, the existence of the debt and Greece's period need to refinance, is the enforcement mechanism. If Europe and Greece make a deal that makes the debt go away, then there's nothing to hold Greece to the rest of the deal. So when Greek negotiators demand debt reduction they're really asking for weaker enforceability not a financial adjustment.
Macy's joined Univision and NBC in dropping ties with Donald Trump following widely-criticized comments about Mexicans during his presidential campaign launch. Following the announcement, Trump called for a boycott of the chain:
Those who believe in tight border security, stopping illegal immigration & SMART trade deals w/other countries should boycott @Macys.

Macy's statement honed in on the matter of celebrating diversity -- a business-related matter as much as a moral one for one the largest national employers. "Macy's is a company that stands for diversity and inclusion. We have no tolerance for discrimination in any form. We welcome all customers," they wrote.

The consumer brand said it will "discontinue" the "business relationship" with Trump -- in the same manner the company might discontinue a poorly-selling casserole dish.
Here's Macy's full statement to CNN on why it's cutting ties with Donald Trump pic.twitter.com/rE9cPLPa2n

The statement continued: "We are disappointed and distressed by recent remarks about immigrants from Mexico. We do not believe the disparaging characterizations portray an accurate picture of the many Mexicans, Mexican Americans and Latinos who have made so many valuable contributions to the success of our nation. In light of statements made by Donald Trump, which are inconsistent with Macy's values, we have decided to discontinue our business relationship with Mr. Trump and will phase-out the Trump menswear collection, which has been sold at Macy's since 2004."
Trump, hours after Macy's statement was released, claimed he was the breaker-upper, and not the other way around. Trump has been releasing statements on letterhead as images in Instagram:
My recent statement re: @macys -- We must have strong borders & stop illegal immigration now! #MakeAmericaGreatAgain
A photo posted by Donald J. Trump (@realdonaldtrump) on Jul 1, 2015 at 8:21am PDT

The relationship's end reflects the continued backlash against Trump, and no less from a retailer best known for its love of group events, from selling everyone the same pair of reasonable, trendy shoes to hosting, sponsoring, and otherwise enjoying large parades with balloons the size of cars.
Perhaps sales were down, and this was Macy's way of cleaning out the shop? As of last glance, much of Trump's collection is on sale on Macy's website.
Stanley Fischer, vice chairman of the US Federal Reserve, former chief economist of the World Bank and head of the Bank of Israel, isn't a person whose name will pop up on the top news feed of most Americans. But his straightforward speech on the history of monetary policy deserves your attention, especially if you want insight into how policymakers address crises in, say, Greece or Puerto Rico.
Here's the one sentence that will catch you up on the state of monetary policy in 2015:
In other words, monetary policy isn't a one-size-fits-all approach --  exactly what happened in the case of Greece's currency. Timothy Lee explains:
If Greece wasn't in the euro, it could have boosted its economy by printing more of its currency, the drachma. This would have lowered the value of the drachma in international markets, making Greek exports more competitive. It would also lower domestic interest rates, encouraging domestic investment and making it easier for Greek debtors to service their debts.
But Greece shares its monetary policy with the rest of Europe. And the German-dominated European Central Bank has given Europe a monetary policy that's about right for Germany, but so tight that it has thrust Greece into a depression.
Fischer believe that, at least on the international stage, nuance matters a great deal, and points to the IMF as an example of how policy has evolved. This last part about not putting horses before carts is key for countries like Greece.
...The ambitions of developing countries to modernize their monetary policy frameworks have to proceed in parallel with further efforts to develop the market institutions necessary to conduct monetary policy in a conventional way.
Don't take this to mean that Fischer doesn't support more traditional tools, such as pegging currencies to a fixed value (which he mentions in his speech). There are factors which apply to one country, but may not apply to another.



Barack Obama took to the op-ed pages of the Huffington Post to propose a new plan that he claims will extend overtime pay to 5 million new Americans, by making workers earning under $50,400 per year eligible for overtime wages.
The White House first expressed its intent to fix overtime pay in March 2014. Currently, only salaried workers making under $23,660 per year — or $455 per week — are eligible to be paid overtime (meaning that they earn one and half times their normal hourly rate when they work over 40 hours in a week). Obama's plan is to increase the threshold under which employees are eligible for overtime compensation, thus making sure that more American workers get paid extra when they work overtime.
Since 2014, several policymakers released suggestions about where the threshold should be set.
The following graphic, released by the Economic Policy Institute last December, breaks down some of the popular proposals:

Economic Policy Institute
Although none of the suggestions match Obama's current number exactly, they provide a rough estimate of how many Americans will benefit from the proposed change. In terms of the actual threshold amount, Obama's current plan most closely matches the figure based on inflation-adjustment of the threshold in 1975.
Salaried workers indicate employees who are paid a set salary, rather than a rate based on the amount of work they do. According to the Bureau of Labor Statistics, America had over 106 million full-time salaried workers in 2014, over 55 percent of whom were male.
Before Obama's proposal becomes law, it will likely have to make its way through a review process and consideration by the Department of Labor. Congressional Republicans have already expressed disapproval of changing overtime regulations.
Greece's long-simmering economic crisis has finally boiled over into a full-fledged political and financial meltdown — banks are closed, Greek citizens' ability to withdraw cash from ATMs is limited, a default on Greece's debts to its fellow European countries looks overwhelmingly likely, and the odds of the country being forced to leave Europe's single currency look very strong.
Yet for all the drama, Greece itself is a rather small and economically marginal country. Consequently, a lot of the commentary about the Greek crisis sheds less light on the actual situation in Greece than it does on the political opinions of the writer. If you actually want to understand Greece, though, these are the key facts you need to know.

Before you blame anyone in particular for the disaster unfolding in Greece, it’s important to understand that the underlying concept of the Eurozone is badly flawed. Foreign observers as ideologically varied as Milton Friedman and Paul Krugman have said all along that joining a group of quite distinct European countries into a single currency would end in tears.
Foreign certainty that the Eurozone was a bad idea was so widespread that back in 2009 before everything collapsed, the European Union produced a mocking paper titled: "The Euro: It can’t happen. It’s a bad idea. It won’t last. US economists on the EMU, 1989 – 2002."
The Americans were badly wrong about one of these things — the mere fact that European Monetary Union is a bad idea didn’t stop the EU from doing it, and it hasn’t quite collapsed yet even though it’s caused a lot of suffering.
The basic problem, however, is quite simple. When a given country's economy falters, one of the easiest ways for it to adjust is for its currency to decline in value relative to other countries' currencies. This reduces the country’s citizens’ real purchasing power — there’s no getting around the bad news — but has the upside of boosting the country’s exports and tourism. In other words, it lets the country respond to an economic crisis by putting people to work making things.
A country that lacks this flexibility is much more likely to absorb economic pain by entering a prolonged period of mass unemployment. Which is what's happening to Greece now.
World Bank data, Google Finance chart
To understand both Greeks’ emotional commitment to the Eurozone and Europe’s stingy attitude toward Greece, it’s important to realize that Greece experienced a wild boom in the early years of European monetary union.
Before the euro, different countries’ governments paid wildly different interest rates because lenders knew there was a risk of currency devaluation. Greece, in particular, was saddled with high interest rates since its economic policies were held in low esteem and it was widely believed the country would need to resort to devaluations.
When the euro came into place, those worries vanished — and, wrongly, were not replaced with worries about Greece paying off its debts — which lead to plunging interest rates for Greek bonds. This let both the Greek government and the Greek private sector go on an unsustainable borrowing binge that created extremely rapid debt-fueled growth. In retrospect, both the borrowers and the lenders should have known better but it is what it is.
Massachusetts has been richer than Kentucky for as long as Kentucky has existed and that shows no sign of changing. California, too, is richer than Idaho. Since the United States of America has a system of taxes and spending that transfers money from rich people to poor people, it also transfers money from rich states to poor states. We could record this history of transfers as a large debt that Kentucky owes to Massachusetts that someday needs to be repaid.
But we don't. And the government of Massachusetts doesn’t waste its time lecturing the government of Kentucky about the need for Massachusetts-style structural reforms to revive its dysfunctional economy.
The United States is not unique in this regard. London and the Southeast subsidize northern England. Northern Italy subsidizes southern Italy. Alberta and Ontario subsidize Atlantic Canada. The former West Germany subsidizes the former East Germany. The reason is that once high-value industries are established in particular places, it is very difficult for other regions to fully catch up — New York, London, Frankfurt, Milan, and Toronto all serve as draws for talent from throughout the country and absent ongoing transfer payments back to poorer regions you would see a path of endless divergence.
To function smoothly, the Eurozone would need to have some of these cross-subsidies. Taxpayers in Germany and the Netherlands would have to commit to subsidizing Greece and Portugal on a constant, ongoing basis without fussing the Greeks and the Portuguese about it too much. That German and Dutch voters aren’t excited about this idea is perfectly understandable. That they think it’s reasonable for a currency union to work despite these kinds of transfers is less understandable.

The roots of the current crisis lie in the botched handling of the previous Greek debt default crisis. Irish economist Karl Whelan has written an excellent overview of this for those who’d like to delve in deeper, but in broad strokes:
The current crisis is what happens when people stop trying to kick the can down the road. The Greek government is demanding that it be able to choose for itself what Greek public policy looks like, and Greece’s European partners are demanding that Greece live up to its commitments if it wants their money.
In its successful 2015 electoral campaign, Syriza told the Greek electorate what it wanted to hear: that there was a path out of the nightmare of austerity and external political control into which Greece had fallen that didn’t involve leaving the Eurozone.
This simply wasn’t true.
For it to be true, European governments would need to have been willing to write Greece blank checks worth billions of dollars. This isn’t by any means a crazy idea — again, Kentucky gets large, blank checks from Massachusetts because that’s how things work — but it was obviously a non-starter in the Eurozone. The only way to free itself from European shackles has long been for Greece to quit the Eurozone. One suspects that at least some of the movers and shakers in Syriza knew this to be the case, but it was a bad electoral message the party didn't want to send.
Syriza is not Greece's traditional left-wing party; it's a different, further-left party that rose to power by displacing the traditional Greek social democrats. Each European country has its own political parties and party system. But, broadly speaking, European parties fall into a few big "families" that have similar ideologies and also meaningful cross-national institutional ties.
In present-day Europe, Greece is the only country whose coalition government is led by a far-left party. Indeed, far-left parties have never led a coalition in any other European country. And in a bunch of European countries — including Germany, France, and Spain — the far-left party and the center-left party are not on good terms.
Consequently, there is a fairly broad sentiment in Europe, including among left-wing parties, that Syriza’s fall from power is something that ought to be welcomed.
"#Greece has refused to take the tough steps that the other crisis-ridden countries have taken". Really? pic.twitter.com/5dO7za2Wmt

You hear a lot about "austerity" in the context of the Greek situation. This is in part because Greek fiscal policy has been very austere over the past several years, with the government cutting spending more drastically than any other in Europe. But mostly you hear a lot about austerity because austerity was a very real issue in British and American politics during many of the relevant years, and if you read article on the internet in English you find yourself exposed to the preoccupations of Americans and British people.
In Greece’s case, however, austerity is largely a red herring.
In the US or the UK, austerity was a choice: financial markets were happy to keep lending the two countries more and more money to cushion their recessions.
But the Greek government didn't have a choice: it couldn’t run a bigger budget deficit. Nobody would lend them the money! Greece’s European partners have demanded a lot of austerity from the Greek government in exchange for their money, but absent that money Greek fiscal policy would have to be even more austere.
Often, when people criticize the austerity measures in Greece, what they are saying is that Germany and France should have given Greece more money. And maybe they should have! But they didn't, and in the absence of such subsidies, running a more stimulative economic policy wasn't an option for Greece.
The other thing you hear a lot about with regard to Greece is "structural reform," which Greece’s creditors want the country to undertake.
It’s easy to see from the broad economic aggregates that Greece really would benefit from some kind of reform. Even at its pre-crisis peak, Greek GDP per capita was much lower than the GDP per capita in Germany or the Netherlands. And Greek labor productivity per hour worked was dismal by European standards.
The Greek tax collection infrastructure was legendarily ineffective, and the Greek civil service is shot-through with patronage. If Greece managed to achieve the level of governance professionalism and economic performance of the average European country, then Greece’s ability to repay loans would be greatly enhanced.
But here’s the problem: if Greece managed to achieve the level of governance professionalism and economic performance of the average European country, then this would also be great news for Greek citizens. If there were lots of ideas that would be clearly effective and politically viable, Greek's elected governments would be doing them on their own.
External pressure and expertise can help with this at the margins, but only at the margins. Greek elites are well-aware of what foreign elites think they should do and "a bunch of experts from Germany and Finland really think we should do this" is not really the kind of argument that breaks political logjams. Meanwhile, the foreign governments pressing Greece for reform are also political actors. Consequently, outsider demands tend to focus disproportionately on things that are salient in their own domestic politics rather than on game-changing solutions to Greece’s problems.

Greece is an outlier in Europe. But it’s not unique. Lurking behind it are the relatively poor and relatively indebted economies of Portugal and Spain, and arguably even Italy. When Greece stiffs its external creditors and threatens to leave the Eurozone, that makes creditors wonder whether Portugal and Spain and Italy might someday do the same.
Consequently, it is broadly in Europe’s interest for whatever Greece does to end up being as messy and painful as possible. Europe needs the message to Portugal to be, "Wow, that was a disaster, let’s avoid that by any means possible" not "Well, that was uncomfortable but it worked out fine in the end."
The Greek situation is fascinating, and of course, it’s crucially important to Greek people. But unlike some earlier iterations of European debt drama, it is very unlikely to impact you personally.
After months (if not years) of highly public wrangling, a Greek default and departure from the Eurozone is completely predictable. Any financial institution that was even slightly paying attention was aware of this possibility, and while the news certainly moves markets there is no reason to think it will spark any kind of panic.
The big exception here is if you are planning a vacation to Greece. If that’s the case, the precedent of Argentina (which has been in a somewhat similar situation) suggests that it is probably in your interest to bring a fairly large quantity of paper money (both dollars and euros) into the country since physical currency is likely to be in high demand and the banking system is crippled. Greek individuals will face legal difficulties in turning their money into foreign currency, so opportunities will likely arise to pay for things in paper dollars at a steep discount compared to the official exchange rate.
If you are considering this vacation, definitely take it.
The truth is that increased tourism is one of Greece’s best chances for recovery. The country desperately needs foreign buyers and more economic activity, and in the short-term, purchases by tourists attracted by cheap vacations in Greece is one of the best chances for making that happen. Buy stuff to take home. Mail care packages of olives to your friends.
The government of Greece has decided to hold a yes/no referendum on a final proposal from the European governments to whom it owes money with Greece's prime minister arguing that Greek citizens should vote "no." It's not entirely clear what the implications of a no vote would mean, but it seems likely to lead to Greece's exit from the Eurozone and an uncertain future for both Greece and the single currency.


It's going to take 10 bullet points:
Because these are negotiations and the two sides both claim the other is misrepresenting what's been happening, it is difficult to tell exactly what's been going on. But by and large, both Greece and its creditors seem to be mostly haggling over the exact size of the primary surplus that Greece is going to be required to run.
Greece is, in essence, asking for flexibility to run a less austere policy, and some of its creditors are reluctant to let the country do it.
On this level, the whole thing is really pretty simple. Back in 2010, Greece was in the position of supplicant, asking richer and more creditworthy European countries for money.
But Greece also had a fair amount of leverage. A disorderly default might have spread financial chaos to countries like Portugal, Ireland, Spain, and maybe even Italy. Under the circumstances, other eurozone countries had strong self-interested reasons to help Greece out.
In the intervening five years, a lot of work has been done to insulate other European countries and the European banking system from the risks involved in a Greek default. Greece is asking for more generous terms, but it has less objective leverage.
Indeed, while back in 2010 other debt-burdened European states really wanted Germany and others to bail out Greece by 2015, their calculus has now changed. If a far-left party sweeping into office and demanding more money works out in Greece, then that imperils the establishment political parties in Spain and elsewhere. So even if Germany were feeling generous, it would face pressure to be stingy.
Yes and no.
As Tony Yates of the University of Birmingham points out, it's very misleading to say that Germany has been demanding austerity from Greece. If Greece defaults on its debt, it will be locked out of international credit markets and forced to run a very austere budget policy. Any financial assistance at all entails a reduction in the level of austerity relative to what would be the case if Greece did not get help. The deal is: "if you want to avoid super-strong-austerity by taking more money from us, carry out reform."
In that sense, the problem has nothing to do with German aversion to austerity and everything to do with Greece's failure to put forward a reform program that seems compelling to Greece's creditors.
On the other hand, the German government really is obsessed with austerity. German's aversion to public sector investment is hurting its own economy and making life more difficult for all of its trading partners.
Eurozone inflation rate.
Trading Economics
Concurrently, the eurozone's overall inflation rate has been incredibly low for the past several years. This tight money has made it more difficult for countries like Greece to restructure their economies and has hurt growth in almost every European nation, Greece included.
In other words, a German government that was more open to the case for stimulative policies would be good overall for Greece (and for Germany), but wouldn't resolve this particular standoff.
To many outsider observers, it seems like Grexit — a Greek departure from the eurozone — isn't really an outcome people should be working so hard to avoid.

Doesn't Greece need to leave the Euro for the same reason everyone needed to leave the gold standard in the 1930s?



I get it: transitioning off the Euro would be very very painful. But not transitioning off also looks very very painful!


To see why this is considered so unappealing, you have to understand that the euro is a political project. To many European policymakers, the slogan of "ever closer union" has been an enormous success at pulling the continent out of the destructive cycle of wars that characterized the first half of the 20th century. To Greek citizens, participation in the European project signifies the country's emergence from decades of civil war and military dictatorship.
Whether these considerations are really as compelling as European leaders seem to believe is up for debate, but the calculation they are making is not strictly based on dollars and cents.
Nobody knows for sure. On paper, it seems as if the absence of an agreement should lead to two big consequences. One is that the Greek government runs out of euros with which to meet its various spending commitments. The other is that the European Central Bank retaliates against Greece by no longer providing short-term financing to Greek banks.
Both circumstances would tend to push the Greek government toward issuing some kind of new, non-euro currency.
They could call them "new drachmas" to make the change seem purposeful and deliberate. Or they could call them IOUs or promissory notes to make it seem temporary. Either way, one of the new currency units would be worth much less than a euro, and the country would de facto be out of the eurozone.
Most likely, the Greek government would also want to impose capital controls — regulations limiting people's ability to take euros out of Greece.
Alternatively, you could imagine a more cooperate scenario — similar to what happened in Cyprus — where they imposed capital controls first, creating a situation in which Cyprus uses money that's called euros, but a euro inside Cyprus or a Cypriot bank can't actually be exchanged for a regular euro or taken outside the country.
Wolfgang Münchau at the Financial Times had perhaps the best account of the lost opportunity for a meaningful breakthrough. Greece has been hobbled for decades by extremely weak public institutions and extensive corruption in its public sector. Syriza, as a party that has never before held office and substantially stands outside the system, was in a sense ideally positioned to deliver on a much stronger reform agenda than any of the mainstream parties.
In a reasonable proposal, Münchau writes, Syriza would have offered much bolder reforms in exchange for meaningful budgetary flexibility:
Step back a little and the solution is not hard to see: less austerity, more public sector reforms, and some clever debt restructuring. That was the overwhelming conclusion of a recent conference by some of the world’s leading experts on this issue, as reported by Richard Portes and co-authors from the London Business School in a recent article.
We are not talking about reforms of the ideological variety, on hiring and firing for example, or on ending collective bargaining, but socially useful reforms such as credible tax collection, a modern public administration or a working legal system.
Without a modernisation of Greek public-sector infrastructure, there is no way that Greece and large parts of northern Europe can coexist in a monetary union. It would be a recipe for a never-ending, structural slump.
Instead, the continent appears to mostly be stuck between a Greece that wants some face-saving concessions on austerity and European leaders who want to save face by drawing a tough line.
Adam Posen is president of the Peterson Institute for International Economics and, like every international economist right now, he's glued to the drama in Greece. There is, he says, a simple solution to the crisis: the Northern European countries should write a check and end it. But they won't, and in a conversation on Monday, he told me why. The interview has been lightly edited for length and clarity.
Ezra Klein: Imagine I haven’t been following this at all. What’s the simplest explanation for why the world is so concerned about Greece today?
Adam Posen: The simplest explanation is that for the euro to remain together, and therefore to remain a stable currency, you have to believe the membership pays their debts. Right now, the Greeks are not going to pay back what they owe the rest of Europe. Right now, there literally aren’t enough euros in the Greek financial system, public and private, to pay back what they owe.
So Greece will have to issue IOUs to their creditors and their businesses. And that will mean you have a currency in Greece that is not the euro. It will be a kind of scrip. And so the Greek people have been pulling their money out of the Greek financial system because they don’t believe this scrip will be worth as much as the euro.
The way we deal with this kind of problem in the US is we have fiscal transfers. Mississippi and Alabama never really pay back what they owe California and New York, and that's okay. So you can see the crisis in Greece two ways: you can believe it’s a failure because the Greeks are reneging on their debts or because Germany is not treating Greece like the US treats Mississippi, as a state they have to look after.
EK: Why is this happening right now though? What's changed from, say, six months ago?
AP: What has changed since a year ago is a breakdown in trust and a change in politics. The economic fundamentals really haven’t changed. But you have this new government in Greece that is taking a harder line with its creditors. They’re saying, basically, we can’t pay all this back, you need to be more realistic. And the European leadership has reacted to this first by saying, sorry, that deal is not on the table, and second, by saying, we basically just don’t trust you. You’ll tell us one thing and then go do something else.
So that’s the key: the economics didn’t change. It was a change in the Greek government, and then a change in the relationship between that government and the rest of Europe.
EK: One thing that makes this hard to follow from the US is it's not entirely clear which outcome to be rooting for. Greece can stay in the euro and try to endure grinding depression for years and years or they can leave the euro and endure a financial crisis. Which outcome is better?
AP: It’s easy to say what people should want to happen in Greece. It’s just impossible to get there. The Northern Europeans should write a check and make this go away. They should accept the fact that Greece is not going to pay most of its debts. They also need to accept that these debts are partly their fault. These loans were made by Northern European financial institutions, and the Northern Europeans should suffer for making stupid loans, too.
But that won’t happen. Northern European governments like Germany, Finland, Austria, the Netherlands, and Sweden don’t want their banks to lose money and they don’t want to tell their voters that they’re handing money to the Greeks.
EK: You often hear about how the Greek government is barely able to collect taxes. How big a contributor is that to this crisis?
AP: There is no question that the Greek system has done a terrible job of collecting taxes, and especially collecting taxes on the richest people. For instance, shipping is constitutionally protected from being taxed, and that’s where many of Greece’s great fortunes are. Taxation on real estate is also poorly collected. But in terms of Greece racking up all its debt, that isn’t the fundamental issue. The fundamental issue was the surge in capital from Northern Europe to Greece during the early and mid-2000s. Even if the Greeks hadn’t been able to collect much tax revenue they couldn’t have gotten into so much debt if people weren’t giving them all these loans.
EK: What do you think the financial consequences of Greece leaving the eurozone would be?
AP: I think the short-term consequences are going to be much smaller than people fear, with the huge, horrible exception of the Greek people themselves. It will be awful for them. But pretty much all the Greek debt is now in government hands. The total amount of debt, which is about $200 billion euros, is real money, but it’s really just about 1-2 percent of total euro area GDP. And every bank and every investor has known this has been coming for months.
But that’s the short term. The long-term is the IMF will be out billions of dollars which they need to pay back to their poorer members. The euro will be seen as less safe a currency than it once was and that will permanently raise interest rates in many European countries. It will permanently reduce the appetite for euro assets. And it will mean that the so-called periphery countries in Europe — notably Portugal — will be looked at with suspicion going forward. And that will make it harder for them to get investment and funding.
EK: What about the political side of it? Do you think this raises the possibility of dangerous political backlash in Europe?
AP: Absolutely. Branko Milanovic had a nice essay about how bad the politics of Europe could get in the aftermath of this. It’s a bit extreme but it’s a good point. Basically what you’ve had is the undermining of European solidarity. There is this level of distrust and resentment. The Greek people feel the Northern Europeans are trying to get blood from a stone and the Germans feel they’re being exploited.
On Monday, the Supreme Court opted not to review a 2014 ruling on copyright law that held Google's Android operating system infringed copyrights relating to Oracle's Java platform. This is a disaster for the software industry.
Here's the problem: the digital economy depends on gadgets and software being able to communicate seamlessly. Last year's decision by the Federal Circuit Court of Appeals opened the possibility that efforts to make software work together better could trigger copyright liability. The result could be more compatibility problems and less innovation.
Google modeled its Android smartphone platform on the Java programming language, which was created by a company called Sun Microsytems. Google didn't get Sun's permission to do this, and Oracle (which acquired Sun a few years ago) sued for copyright infringement.
But Google argued that it had acted within the law. It had only copied those characteristics of the Java system necessary to allow Android to run Java software. Google believed that was legal because copyright law doesn't protect functional characteristics, which the law defines as an "idea, procedure, process, system, method of operation, concept, principle, or discovery."
Google's defenders point to a landmark 1995 ruling, in which an appeals court held that the software company Borland had not infringed copyright when it created a spreadsheet program whose menus were organized in the same way as the menus in the more popular spreadsheet Lotus 1-2-3.
The court held that the order of Lotus 1-2-3 menu items was an uncopyrightable "method of operation." And it concluded that giving Lotus exclusive ownership over its menu structure would harm the public:
Under Lotus's theory, if a user uses several different programs, he or she must learn how to perform the same operation in a different way for each program used. For example, if the user wanted the computer to print material, then the user would have to learn not just one method of operating the computer such that it prints, but many different methods. We find this absurd.
Google only copied those characteristics of the Java system necessary to allow Android to run Java software
Google believed that its own copying was directly analogous to what Borland had done. There were thousands of programmers with expertise in writing Java programs. By designing its platform to respond to the same set of programming commands as Oracle's Java system, Google allowed Java programmers to become Android programmers with minimal training — just as Borland's decision to copy Lotus's menu structure avoided unnecessary training for seasoned Lotus 1-2-3 users.
But the Federal Circuit Court of Appeals didn't buy Google's argument. It held that the technical specifications Google had copied — including the names of functions (such as "max" for the maximum function), as well as what type of data these functions accept and return (like the fact that "max" takes two integers and returns an integer) — was eligible for copyright protection.
Programmers call this kind of technical specification an application-programming interface, or API. And a brief drafted by the Electronic Frontier Foundation — and signed by some of the nation's leading computer scientists — argues that the lack of copyright protection for APIs has been essential for the development of the digital economy. A second brief by the group Public Knowledge reaches the same conclusion.
That's because software is all about interoperability. The internet's power comes from the fact that billions of computers can all communicate with one another. And that compatibility is made possible in large part because programmers have had the freedom to do what Google and Borland did: build new software based on de facto industry standards that might originally have been developed by incumbent software companies.
One such industry standard is the Unix operating system, which was developed by AT&T in the late 1960s. Unix became an industry standard, and over the years many people have created "Unix-like" operating systems. One of those Unix clones, called Linux, now provides the foundation for everything from Android phones to powerful web servers.  Apple's Mac OS X and iOS operating system also make heavy use of Unix standards.
The internet's power comes from the fact that billions of computers can all communicate with one another
If copyright law had prohibited this kind of copying, people might have been forced to develop mutually incompatible operating system standards. Programmers and systems administrators would have had to waste time learning about a variety of different systems. We'd all be worse off as a result.
A similar type of copying can be essential to keeping older devices working, as the EFF brief explains:
Jeremiah Flerchinger is an electrical engineer with over ten years of service in the Department of Defense, after previous experience with a machine-tool company. When the National Aeronautics and Space Administration (NASA) sought to repurpose old manufacturing robots for a new project, they asked Flerchinger’s company to manufacture and program updated memory chips to store the robots’ new instructions. Configuring firmware to put on the chips required using obsolete software that wouldn’t run on modern computers. Flerchinger reimplemented the software’s API, creating modern software that could fulfill the same functions and work alongside old machines that had the same API hard-coded into their electronics.
As software is increasingly incorporated into a wide variety of products — industrial equipment, automobiles, and even children's toys — restricting this kind of reverse-engineering will have huge costs.
Disclosure: My brother is an executive at Google.
Milton Friedman might be best known today for his free-market political views. But some of his most important contributions to economics were in monetary policy. He explained the high inflation rates of the 1970s, and he was also an early and influential advocate of the system of floating exchange rates that we have today.
So European policymakers would have done well to pay attention in 1997 when Friedman predicted that the euro would be a disaster. Eighteen years later, with Greece on the verge of a financial meltdown, his analysis looks prophetic:
Europe’s common market exemplifies a situation that is unfavorable to a common currency. It is composed of separate nations, whose residents speak different languages, have different customs, and have far greater loyalty and attachment to their own country than to the common market or to the idea of "Europe." Despite being a free trade area, goods move less freely than in the United States, and so does capital.
The European Commission based in Brussels, indeed, spends a small fraction of the total spent by governments in the member countries. They, not the European Union’s bureaucracies, are the important political entities. Moreover, regulation of industrial and employment practices is more extensive than in the United States, and differs far more from country to country than from American state to American state. As a result, wages and prices in Europe are more rigid, and labor less mobile. In those circumstances, flexible exchange rates provide an extremely useful adjustment mechanism.
What Friedman means here is that if Greece still had the drachma, it could deal with its financial difficulties by devaluing the currency. A cheaper drachma would make Greek goods more attractive to foreigners, boosting exports and creating jobs. And a bit of inflation in Greece would help ease the country's debt burden — not an ideal outcome, but better than the yearslong depression the country has suffered since the 2008 financial crisis.
It's much harder for an unemployed man in Greece to move to get a job in Germany than it is for somebody who loses his job in Pennsylvania to find work in Texas. So Greece's unemployment rate has stayed disastrously high, even as other eurozone nations have enjoyed a robust recovery.
Friedman concluded that the euro experiment would backfire:
The drive for the Euro has been motivated by politics not economics. The aim has been to link Germany and France so closely as to make a future European war impossible, and to set the stage for a federal United States of Europe. I believe that adoption of the Euro would have the opposite effect. It would exacerbate political tensions by converting divergent shocks that could have been readily accommodated by exchange rate changes into divisive political issues. Political unity can pave the way for monetary unity. Monetary unity imposed under unfavorable conditions will prove a barrier to the achievement of political unity.

If you want to understand why Greece and the rest of Europe are at such loggerheads, you could do worse than check out this chart I made by running a digital paintbrush over World Bank data on Greek GDP per capita.
World Bank data / Google finance
The magenta line is more or less how things look to Greek people. Since 2008 or so, under the watchful eye of European Union elites (the central bank, the European Commission, the International Monetary Fund, the government of Germany, etc.), the Greek economy has completely collapsed. And the Greek population has been thrown into a state of dire immiseration.
The yellow line reflects more how things look to European officialdom. Greece is about on track for where you would expect it to be if you extrapolated forward from the pre-euro era. The prosperity of seven years ago was a bubble, driven by imprudent lending and dodgy government finances. Meanwhile, though Greece is a lot poorer than it was it's not actually a poor country in the global sense. As a supplicant looking for charity, Greece is a lot less compelling than India or Guatemala or any number of sub-Saharan African countries.
A new purported debunking of Thomas Piketty's Capital in the 21st Century is out, from Robert D. Arnott, William J. Bernstein, and Lillian J. Wu, and it purports to show that, historically, rich families do not stay rich over time. Reason's Ron Bailey and the Economist's Buttonwood columnist are both very impressed.
But while I would say they raise some good points about charitable giving and the splitting of inheritances across multiple children, their core methodology is badly flawed. As Buttonwood writes, "the authors point out that the rapid turnover of the Forbes 400 suggests that inherited wealth is unstable. Three-quarters of the families in the original list no longer appear on it."
It's important to understand that the Forbes 400 list is a journalistic undertaking, not a peer-reviewed study of wealth. And it turns out to be a very shaky foundation on which to build academic research.
As Piketty told me when I asked him about the Forbes list, "the methodology is biased simply because it's much easier to spot large entrepreneurial wealth than large inherited wealth."
Say someone asked you to figure out how rich Steve Ballmer is. I would start by Googling "Microsoft largest shareholders" which would quickly reveal that according to Microsoft's public corporate documents Ballmer owns 333,254,734 shares of Microsoft stock. At the company's current share price of $45.63, that gives him about $15.2 billion worth of Microsoft stock.
Of course that's going to be an underestimate because he also owns other stuff. The LA Clippers are worth about $2 billion, for example, and we know he owns that because it was a big story when he bought the team. With a little more work, we can probably confirm a few billion more dollars.
But what if some third-generation rich guy had $15 billion in index funds? How would we find that out? That wouldn't show up on corporate paperwork. And our hypothetical rich guy wouldn't actually be very interesting. He wouldn't be the CEO of any famous companies or sit on the board or do newsworthy things. He'd just be kind of quietly super-rich.
The other big issue with this study is how it deals (or, rather, doesn't deal) with the changing policy environment over time.
It used to be that the United States had a pretty hefty estate tax. Piketty thinks that was a good idea and that today's environment of much-lower estate taxes will lead to dynastic wealth.
The authors purport to show that in the past we did not see a huge dynastic wealth problem. And this is exactly what Piketty thinks! He thinks that in the past we had public policies designed to prevent the emergence of dynastic wealth, and that we should worry about a future in which those policies have been removed.
Piketty might be wrong about the future, but simply pointing to a past in which the policy environment was different can't prove it.
The Chinese stock market is in the news. And even though you probably haven't been day-trading Chinese stocks, it's a fascinating situation with potentially grave implications for the world's second-largest economy. This looks to a lot of people — especially smug foreigners — like a Chinese version of the stock market mania the United States experienced in the 1990s. A bubble, in other words, that's in the midst of popping. But financial markets are inherently unpredictable, so you should be wary of anyone who sounds too sure they know what's going on.
Bloomberg
Bloomberg
Bloomberg
Bloomberg
So what's happening? Well, one should always be cautious about being sure you know what's happening in financial markets.
But broadly speaking, this looks a lot like a Chinese version of the 1990s stock market boom and ensuring mania in the United States. For a long time, even through China's miraculous multi-decade span of economic growth, Chinese households have been very cautious investors — either holding money in bank accounts or else parking in tangible real estate. Chinese people don't have a lot of experience with stock exchanges, and confidence in the markets was shaken by some so-called "fat finger" trading errors in 2013. But as the Chinese government began to take tentative steps to open up stock markets to foreign investors while simultaneously trying to discourage fevered real estate speculation, retail investors starting pouring in.
As retail investors poured in, Chinese stock prices went up. As Chinese stock prices went up, more people decided they wanted to get in on the action. It looked a lot like a bubble to most foreign observers. But there was also a belief that the Chinese government would keep trying to pile on stimulus to avert a market crash, and there's always the hope that you can trade your investment to a greater fool regardless of the underlying fundamentals.
On the other hand, I should say that when I went to China in 2008 I heard from a lot of smart foreign observers that the country was in the midst of an unsustainable stimulus-driven boom that would surely crash someday soon. Now it's seven years later, and all the smart foreign observers say China is in the midst of an unsustainable stimulus-driven boom that's in the midst of collapsing. And since no country goes forever without an economic contraction, surely China really will see its long boom come to an end and the economy fall into recession one of these days. Maybe even tomorrow!
But it's dangerous to be too confident you know what's going on. Nobody really predicted the boom that's unfolded over the past six months, so nobody really knows what the future holds.
Harvard University's Joint Center for Housing Studies is out with a big new survey on the state of housing in America in 2015.
It's full of interesting facts, but this one chart is the best illustration I've seen of an issue that doesn't quite get as much attention as it should — the fact that in some key metropolitan areas, affordable housing has become a problem for the middle class:
Joint Center for Housing
Here's why that matters. Suffering from housing "cost burden" is defined in this report (and the affordable housing community writ large) as spending over 30 percent of your income on housing.
By that standard, it's obviously true that many low-income households struggle to afford housing. And it's also sad. But in an important sense this isn't really a problem that has anything to do with housing specifically.
If you only earn $15,000 a year, then 30 percent of your annual income is just a really low number. It's hard to afford anything at all when you're poor, and the solution needs to involve either giving poor people subsidies or else enhancing their overall incomes.
But if you're making $55,000 a year, you're not poor. In fact, your average income is slightly above average for the United States. If non-poor people can't afford something as basic as housing, then that's really a specific issue about housing.
And what this shows is that while middle-class housing affordability isn't a huge problem in most of the country, it's a very big challenge in the 10 highest-cost metropolitan areas. These are places — places like the Bay Area and Greater New York City — where people who aren't poor still struggle to afford a decent place to live.
Those are the places where anti-development regulations have created a systematic undersupply of market-rate housing, costing billions in economic damage to the economy as a whole.
The average young person today spends a lot less time watching television than her parents or grandparents. And that time has been declining quickly in recent years, as shown in this chart posted by Rich Greenfield:

In the first quarter of 2015, the average adult under 25 watched 16 percent less television than the same demographic watched a year earlier. For people between 25 and 34, television dropped by 9.2 percent in a year. And that comes after several years of smaller declines in the hours spent watching TV.
So television is dying. But it's important to distinguish between "dying" and dead. Young people watch less TV than they did a few years ago, but they still watch a lot of TV. In 2015, the 93 hours per month of television the average 18- to 25-year-old watched is still more than the 23 hours they spent playing console video games, 31 hours spent browsing the web on a PC, and 52 hours using apps or the web on a smartphone. Watching traditional television is still the most popular way young people — and everyone else — consumes electronic media.
But if these trends continue, that won't be true for long.
Someday soon, you might be able to attend an NHL or NBA game in Las Vegas — and bet on the outcome from the comfort of your stadium seat.
After years as one of the country's largest metro areas without a pro team, Las Vegas is building a new arena and is viewed as the favorite to get the NHL's upcoming expansion team. But whether it's the NHL or another league that makes the jump, the move to Vegas would be part of a clear trend: gambling is become more and more acceptable in American culture.
"there's an enormous revenue source to tap into"
Leagues are already promoting forms of pseudo-gambling that encourage viewership, such as fantasy sports and NCAA brackets. On-site gambling could be the next step. "The leagues recognize that there's an enormous revenue source to tap into if they can figure out a way to allow on-site betting," says Dennis Coates, a professor of economics at the University of Maryland who studies sports business. "I think it can be done, and eventually it will be done."
If Coates and other experts are right, it's very likely that on-site betting will happen first in Las Vegas — and that the NHL's possible move to that city could be the first stage of a much bigger shift in American sports.

The 1919 Black Sox Scandal scared sports leagues away from Vegas for decades. (Underwood & Underwood)
Leagues have historically avoided Las Vegas for two main reasons. Until recently, it wasn't a particularly large metro area by population. Now, however, it ranks 30th — and is bigger than 12 areas (including Salt Lake City, Raleigh, and Buffalo) that do have pro teams.
The other factor, though, has been the simple fact that Nevada law allows gambling on sports.
The worry is that the proximity of gambling would lead to match fixing, in which people with a stake in the outcome pay players to lose on purpose — like in 1919, when eight players on the Chicago White Sox were allegedly paid to lose the World Series. This episode led Major League Baseball to take the strongest stance against gambling of all the major sports: Pete Rose, for instance, was banned from baseball for life for betting on games while he was the manager of the Cincinnati Reds.
(Getty Images/Ken Levine)
There's also some reason to believe that Las Vegas in particular presents temptations. The closest thing the city has ever had to a pro team is UNLV's Running Rebels, who won the 1990 NCAA basketball championship and lost in the final the next year. But shortly afterward, the team was investigated for point shaving (intentionally scoring or allowing certain numbers of points, depending on bettors' point spread). The NCAA never uncovered any evidence, but for many, the rumors tarnished the team's legacy.
In 1992, lobbying by leaders of all major leagues led Congress to pass a law that prohibited gambling on sports anywhere that it hadn't already been legalized — banning it virtually everywhere besides Nevada. They argued that such a law was necessary to ensure the legitimacy of their sports.

(John Greim/LightRocket via Getty Images)
"Times have changed," NBA commissioner Adam Silver wrote in a landmark New York Times op-ed last year. "Congress should adopt a federal framework that allows states to authorize betting on professional sports."
In his argument, Silver cited several key cultural trends: the proliferation of legal casinos and lotteries across the country, the ease of gambling on sports in other countries like Britain (where you can bet on games on your phone), and the huge amount of money (estimated to be somewhere between $80 and $380 billion annually) that's illegally wagered with offshore bookmaking operations by American sports fans.
"times have changed," wrote NBA commissioner adam silver
But Silver left out a few trends, too. "It's not just the offshore, illegal sort of gambling," Dennis Coates says. "It's things like FanDuel.com." The "daily fantasy sports" site, not technically considered gambling, allows users to effectively bet on individual players' statistics in each game, and took in some $57 million in net revenues in 2014 — the same year the NBA bought a stake in the company.
Silver and the leaders of other leagues know that both illegal betting and the surging fantasy sports industry help them by giving lots of people reasons to watch games. But they likely want more — a piece of the gambling pie for themselves. "I'm sure that somewhere in their minds, they're thinking, 'Since we're providing the basis for the gambling, we ought to be able to generate some payment,'" says Robert Baade, a sports business professor at Lake Forest College.

In Britain, you can place bets at soccer stadiums. (Nigel Roddis/Getty Images)
The leagues could pursue two different strategies in this area. One would be to push for the legalization of sports gambling nationwide, as Silver has done. The other, easier route would be to put a team in Vegas. "As teams move around and leagues expand, Las Vegas keeps entering the conversation," Baade says.
Though the NHL seems like to expand to Las Vegas, there are very good reasons to wonder whether the desert city has enough hockey fans to support a team. At other times, it's seemed more likely that the NBA would move there first.
For either league, though, Baade thinks on-site gambling would eventually be part of the plan: "In the competition between stadiums and watching games at home, television quality continues to improve, and stadiums need to keep up," he says. This competition has led to things like T-shirt guns, mascot races, and the kiss cam. "I have a hunch that in the future, they're going to offer some sort of in-seat gambling opportunities," he says.

A rendering of the Las Vegas Arena. (AEG)
This would presumably give fans the ability to bet on teams, but might even involve fantasy-esque betting on individual players and other sorts of creative wagering. If the current popularity of fantasy sports is any guide, it's easy to imagine this boosting attendance and interest in the game. And if ongoing efforts to overturn the 1992 congressional ban on sports betting are successful, we could eventually see this sort of in-stadium — and perhaps even online — gambling experience across the country.
But just because gambling has ceased to be a cultural taboo doesn't mean that the risk of match fixing has miraculously disappeared. In 2007, for instance, NBA referee Tim Donaghy was sent to prison after selling inside information to professional gamblers — and perhaps affecting the outcome of games.
Adam Silver, the NBA commissioner, says he supports legalizing gambling because it'll make this sort of illegal activity — which often leads to unusual betting patterns —  easier to track and prevent. But the hard truth is that the more money that flows into gambling, the greater the temptation for players, coaches, or referees to fix games.
"It's a dicey proposition," Baade says. "But teams and leagues see gambling as a potentially significant revenue stream, and they're not going to ignore it."
Correction: This article previously referred to FanDuel's net revenues as profits, not taking into account customer acquisition and other operating costs.
Society constantly tells working mothers to feel bad about the fact that they're spending less time with their kids to bring in additional income. In polls, only 21 percent of US adults told pollsters they think the trend toward mothers of young kids having paid jobs is good. But new research shows that a working mother isn't just a necessary evil, it's a positive good.
A new working paper from Kathleen McGinn, Elizabeth Long Lingo, and Mayra Ruiz Castro at Harvard Business School finds that having a mother with a job does make a difference to kids when they grow up, and that it's largely change for the better.
The researchers find statistically significant differences in outcomes for both boys and girls, though the outcomes are different.
In other words, the adult children of mothers who held jobs when they were little kids are likely to grow up as adults who are somewhat less gender-conforming. Their daughters "lean in" more in the labor market, and their sons "lean in" more at home.
The statistical findings are based on a large cross-national data sample provided by the International Social Survey Programme, supplemented with specific country-level data from a variety of sources. In the end, the researchers were able to aggregate data from more than two dozen countries on a range of continents.
They then applied statistical controls for basic demographic variables such as age, education, marital status, and  the presence of other children in the house.
The study posits two separate channels through which maternal work influences children's adult outcomes:
To support the first hypothesis, researchers show that "adult children of employed mothers have significantly more egalitarian gender attitudes" than adult children of full-time homemakers. This, they think, helps explain why the sons of such mothers do more household work, and partially explains why the daughters of such mothers have more success.
At the same time, the relationship between mothers' employment and daughters' odds of holding supervisory jobs "remains strongly significant when gender attitudes are included in the regression." This leads them to speculate that in addition to shaping gender roles, working moms directly transit "a set of skills that enable greater participation in the workforce and in leadership positions."
Efforts to study the impact of parenting choices on children's life outcomes tend to founder on the fact that the vast majority of children are close genetic relatives of their mothers.
The daughters of blue-eyed mothers are significantly more likely to grow up to have blue eyes because blue-eyed mothers pass down genes for blue eyes. By the same token, it is possible that gender attitudes and workplace skills are partially heritable traits, and that accounts for the correlation between maternal behaviors and children's outcomes. To explore the authors' hypothesis in more detail and make them more fully convincing would require studies specifically focusing on adopted children or on the labor market outcomes of identical vs. non-identical twins.
The genetic issue is a good reason to doubt the conclusion of the study, but not a good reason to doubt the basic conclusion that working moms shouldn't feel guilty.
But if you believe strongly in traditional gender roles, this study doesn't actually provide much reason to change your mind. The conclusion that working mothers help raise patriarchy-subverting children is great news if you want to subvert the patriarchy. But if you don't, it's not great news at all. If your goal in life is to raise kids who conform to traditional gender roles, all this study is saying is that you, personally, should try to conform to traditional gender roles.
It looks like the Export-Import Bank is really going to close its doors, at least for a while.
The 80-year-old institution got a reprieve in the fall, when Republicans quietly agreed to extend its charter to June 30. But June 30 is fast approaching, and there's virtually no chance that Congress will vote to save the bank before then. Politico sums up the state of play:
House leaders, who are divided on the issue, are waiting to see if the Senate can pass a reauthorization bill first.
But the lack of available floor time in the Senate — combined with scant pieces of must-pass legislation awaiting action this month — means the political football will almost certainly be punted until July after the bank’s charter expires, according to top Senate Republicans and Democrats following the matter. That means bank supporters are sure to try to revive the bank later this summer, an effort that will cause a major rift within the GOP.
One reason the Senate isn't likely to scramble to reauthorize the Export-Import Bank? Majority Leader Mitch McConnell has come out against it. It's a bit hard to get scarce Senate floor time when the guy who controls the floor doesn't want you to exist.
This is a huge win for the Tea Party and reform conservative wings of the GOP — they triumphed, at least temporarily, over a massive lobbying campaign from the business wing of the Republican Party.
Conventional wisdom remains that if the bank comes up for a vote, it will likely win. But there's no real chance of the bank getting that vote on its own. The question in July is whether reauthorization of the Export-Import Bank can be quietly attached as a rider to some bigger, must-pass bill, like transportation-funding legislation.
The big picture here is that given the difficulty Obama's trade deal has had and given the potential closure of the Ex-Im Bank, it doesn't look like the major business lobbies have nearly as much sway on Capitol Hill as they used to.

Pete is a 30-something software engineer who has been unemployed for years. He keeps himself busy writing a blog where he tells people how he scrapes by on basically no money: biking everywhere, never buying coffee, never eating out, making his own home repairs. He ekes out a bit of extra income making furniture for friends, but it's nothing near a viable business. Poor guy.
Mr. Money Mustache is a 30-something software engineer who has been retired for years. He writes a wildly popular blog where he tells people how to retire early and live on basically no money: bike everywhere, make your own coffee, stop eating out, figure out how to fix a toilet. He has elevated frugality into a status competition — and he is winning it. His followers call themselves Mustachians. He has been interviewed by every media outlet you can think of (including Vox). ABC News says he is "living the dream." His motto? "Financial freedom through badassery." Helluva guy.
As you've probably already guessed, Pete is Mr. Money Mustache. But the difference between the two ways of looking at his life isn't just a trick. There's economic research showing that when the long-term unemployed retire, they become happier — even though nothing about their situation has changed.
I found myself thinking a lot about Mr. Money Mustache and the unemployment/retirement difference after reading Derek Thompson's exploration of a post-work world.
Thompson is trying to imagine a world in which automation and outsourcing have replaced tens of millions of jobs — and no new jobs have risen in their place. He is trying to imagine a world in which there is plenty of prosperity, but not much work. He considers all the usual alternatives — hobbies, a guaranteed basic income, the wonderful promise of leisure — but finds them wanting:
When I think about the role that work plays in people’s self-esteem—particularly in America—the prospect of a no-work future seems hopeless. There is no universal basic income that can prevent the civic ruin of a country built on a handful of workers permanently subsidizing the idleness of tens of millions of people.
He notes that for all the complaints people make of their work, unemployment is typically experienced as a psychic and social trauma:
Time-use surveys show that jobless prime-age people dedicate some of the time once spent working to cleaning and childcare. But men in particular devote most of their free time to leisure, the lion’s share of which is spent watching television, browsing the Internet, and sleeping. Retired seniors watch about 50 hours of television a week, according to Nielsen. That means they spend a majority of their lives either sleeping or sitting on the sofa looking at a flatscreen. The unemployed theoretically have the most time to socialize, and yet studies have shown that they feel the most social isolation; it is surprisingly hard to replace the camaraderie of the water cooler.
Most people want to work, and are miserable when they cannot. The ills of unemployment go well beyond the loss of income; people who lose their job are more likely to suffer from mental and physical ailments. "There is a loss of status, a general malaise and demoralization, which appears somatically or psychologically or both," says Ralph Catalano, a public-health professor at UC Berkeley. Research has shown that it is harder to recover from a long bout of joblessness than from losing a loved one or suffering a life-altering injury.
Which brings me back to Mr. Money Mustache. How much of the trauma of unemployment comes from the weight of society's disapproval, the shame that comes when a friend of a friend asks, "And what do you do?"
One of the hardest things about imagining a post-work world is imagining the social value put on non-work. But you can see hints of how transformative it is even now. In Timothy Ferriss's runaway bestseller The 4-Hour Workweek, he frames his advice as a manual for joining the New Rich. What separates the New Rich from the Old Rich? Mainly that the new rich barely do any work, and they don't much care about money. "Gold is getting old," Ferriss writes. "The New Rich (NR) are those who abandon the deferred-life plan and create luxury lifestyles in the present using the currency of the New Rich: time and mobility."
In other words, rather than working hard now to enjoy a lavish retirement in the future, the New Rich figure out how to retire now and work hard never.
If all this seems a bit soaked in economic privilege, well, of course it is. The New Rich, in Ferriss's book, outsource much of their work to call centers in India. The extreme early retirement movement that Mr. Money Mustache leads works best for people who have a high-paying job in their 20s and so can sock away hefty savings quickly and then live off the interest.
But that's actually not the most interesting kind of privilege being employed here. What these efforts suggest is that people who begin with social status can figure out ways to carry that social status into a post-work lifestyle. Saying "I'm unemployed" is very different than saying "I retired at 32, and it's amazing." The question is, can someone who doesn't start with much social status — Ferriss is a Princeton graduate, Mr. Money Mustache an ex-software engineer — manage the same trick?
This is one of the questions that will decide whether a post-work world becomes a dystopia. Does whatever replaces work get branded more like unemployment or more like extreme retirement? What happens when you tell someone you just met on Tinder that you don't have a full-time job, but you really love hiking?
I am not worried that a post-work world can't be a good world. I am just worried that it won't be — that guilt-free early retirement will be a luxury reserved for people who can get good jobs, and denied to people who can't. But there is, in this, some optimism to be found looking backward. As Thompson writes:
As late as the mid-19th century, though, the modern concept of "unemployment" didn’t exist in the United States. Most people lived on farms, and while paid work came and went, home industry—canning, sewing, carpentry—was a constant. Even in the worst economic panics, people typically found productive things to do. The despondency and helplessness of unemployment were discovered, to the bafflement and dismay of cultural critics, only after factory work became dominant and cities swelled.
Over the weekend, Taylor Swift took on the biggest company in the world — and won — in a battle that ultimately reveals how weak the position of Spotify and other streaming music companies really is as they are squeezed between superstar performers and giant platform companies.
The background is Swift's longstanding opposition to free streaming music services paired with Apple's desire to launch a streaming service of its own. Apple's entry into this market, creatively named Apple Music, doesn't have a ton of features that differentiate it from existing competitors such as Spotify. But it does have two big advantages. One is that it will be included on every iPhone, complete with a three-month trial period. The other is that since, unlike Spotify, it doesn't have an unpaid, ad-supported tier, it doesn't violate the terms of Swift's war on free streaming music.
The combination of default presence on phones and Taylor Swift albums don't add up to a particularly innovative, imaginative, or exciting Spotify killer. But you could imagine it working. Except there was one big problem.
Rather than winning Swift over with the lack of a free tier, the specific policies around Apple Music alienated her, and she said 1989 wouldn't be available on Apple Music.
"I’m sure you are aware that Apple Music will be offering a free 3 month trial to anyone who signs up for the service," she blogged on her Tumblr page. "I’m not sure you know that Apple Music will not be paying writers, producers, or artists for those three months. I find it to be shocking, disappointing, and completely unlike this historically progressive and generous company."
Swift claimed not to be acting personally on her own behalf, but rather to be speaking for "the new artist or band that has just released their first single and will not be paid for its success ... the young songwriter who just got his or her first cut."
Over the weekend, this looked like just another spat between a huge music star and the larger forces shaping the industry. But then a remarkable thing happened. Late Sunday night, Eddy Cue, Apple's senior vice president for internet services, tweeted that Swift was right and Apple would change its policy. Apple Music listeners will get a three-month trial period, but royalties will be paid based on listens by non-paying customers.

Apple will always make sure that artist are paid #iTunes #AppleMusic



#AppleMusic will pay artist for streaming, even during customer’s free trial period



#AppleMusic will pay artist for streaming, even during customer’s free trial period


Swift pronounced herself pleased.

I am elated and relieved. Thank you for your words of support today. They listened to us.


Nominally, what happened here is Taylor Swift took on Apple and Apple surrendered. But the real loser is Spotify and other pure-play music streaming services.
The basic issue is that any deal a streaming service can make with artists, Apple can make a better one. If artists want to be on a free service that maximizes audience size, Apple can do that. If artists want to be on a pay-only service that maximizes short-term revenue, Apple can do that. If artists want it to be that songs only play if you're holding your phone in your left hand, Apple can do that too.
What Apple needs out of streaming music is:
Put those two together, and Apple has a reason for iPhone users to become slightly more loyal iPhone users and for iPhone users to become slightly more likely to extend their participation in the Apple ecosystem to ownership of a Mac, iPad, or Watch.
By contrast, for Spotify and Rdio to survive as independent companies, they have to find a way to actually make a profit at some point. That's hard. And when you're competing with a company that doesn't really have this need, you have a very serious problem.
As I wrote on Thursday, leaders in the eurozone and elsewhere around the world are no longer terrified that Greece defaulting on its debts would lead to a massive financial crisis. That's one of the main reasons Greece's creditors are so comfortable taking a tough line on the Greek government, which, in turn, is one reason a deal is so hard to achieve.
Larry Summers — the economist and former senior policymaker in the Clinton and Obama administrations —  says this complacency is dangerous in a scary new op-ed in the Washington Post. He concedes that "there are good reasons to think enough foam has been placed on the runway to prevent financial contagion." But he reminds us that "this was asserted with respect to LTCM, subprime and the fall of Lehman." And, indeed, the lead-up to Lehman's collapse featured things like articles explaining why Lehman Brothers was no Bear Stearns.
The op-ed is paywalled, but suffice it to say that Summers is really amping up the panic level. Some choice lines:
So who's right? I have to say that Summers is probably wrong here. People have had years to recognize that Greece might end up defaulting on its debts, and the very extended negotiating process since January means there's truly no chance of a surprise.
But probably may not be good enough here. How hard do you want to work to avoid a 40 percent chance of financial crisis? 20 percent? 10 percent? 5 percent?
Something a bit strange is happening in the American economy. After years of depressed demand for workers, employers are suddenly reporting that they have lots of job openings. But hiring, while it's picking up, remains relatively sluggish. New data confirms that, indeed, companies are getting slower to fill vacancies. Right now, open positions are staying open for longer than ever recorded in the 15-year history of the data:
DHI-DFH
A ton. The data on job openings doesn't go very far back, but it suggests that employers have about as many open positions to fill as they did before the dot-com boom unraveled.
BLS data
But the data on actual hiring looks very different:
BLS data
Consequently, the ratio of hires to openings is all out of whack and continuing to get weirder:
BLS data
The most popular explanation for this trend among business executives is that the American economy is suffering from a lack of skills on the part of workers. Academic economists often refer to this as "skills mismatch," suggesting that many Americans may have skills for jobs — travel agent, roofer, bank teller, anthropology professor, daily newspaper beat reporter — that there isn't much demand for these days, even as employers are looking to hire yoga instructors, chemical manufacturing workers, app developers, math tutors, and viral content creators.
Proponents of this theory, however, suffer a bit from "boy who cried wolf" syndrome.
There were people insisting (with not much evidence) three or four years ago that skills mismatch was holding back the economy, but in fact job creation has strengthened over time without any skills revolution. Part of the issue is that it is always true there is some mismatch between the skills people currently have and the skills employers would like people to have, so the mere fact that some mismatch exists doesn't really explain much.
That said, at the end of the story, a wolf really does show up. By the same token, survey data of small-business owners conducted by the National Federation of Independent Business really does show a recent rise in the number of small-business owners who cite "labor quality" as a big problem for their business:
National Federation of Independent Businesses
In other words, just because the skills mismatch hypothesis was false in 2011 doesn't mean we should dismiss it in 2015. Economic conditions have changed.
The traditional counter to the skills mismatch story has been to say that if the economy is really suffering from widespread shortages of qualified workers, then that ought to manifest itself in the form of higher pay for those who are qualified. A world of skills mismatch is a world in which businesses should be aggressively poaching workers and even preemptively raising salaries to ensure loyalty. But wage gains have been distinctly muted for years.
Catherine Rampell quotes Steven Davis of the University of Chicago offering a different theory. Perhaps the shortage of appropriately skilled workers leads companies to settle "for workers who have less of [or] lower-quality versions of the desired skills" which could actually hold wages down.
Tyler Cowen endorses this analysis, but it seems to only bring the problem around full circle. If employers are hiring underskilled workers at a discount rate, then why are jobs open for so long? A shortfall of skills could explain either stagnant wages (workers don't have what it takes to earn more) or sluggish job filling (nobody can do the job), but it's difficult to explain why they would both happen simultaneously. Markets are supposed to be able to adjust to imbalances between supply and demand with prices. The question is why they've gotten less efficient at that.
The biggest problem with the skills mismatch theory may be that the same small-business data that says the mismatch is real also says that it's not, by historical standards, especially large:
National Federation of Independent Businesses
This leads me to one theory that I haven't seen discussed among economists, but that pops out from my practical experience participating in a few recent hiring processes — it's too easy to apply for a job these days.
What's changed over the past 15 years is that the internet has dramatically decreased the cost of identifying an open job listing and sending in an application. But digital technology has done essentially nothing to make it easier to evaluate candidates. The stack of résumés you need to read through in order to start scheduling interviews has just gotten longer. Rationally, of course, one could respond to this by randomly tossing out 50 percent of the résumés sight unseen. But in the real world, nobody does this. The easier you make it to apply for jobs, the slower the hiring process becomes.
Tragically, I haven't found much research that directly addresses this hypothesis.
But Peter Kuhn of UC Santa Barbara has found that internet adoption has lowered the average quality of job applications that employers receive, while Constantin Mang of the Ifo Institute in Munich finds that internet adoptions improved the ultimate quality of job matches that applicants and employers make.
A story in which the average quality of the application is going down (this could also explain why employers perceive a skills shortage even as the data says the workforce has never been better-educated) but the average quality of the match is going up is consistent with a big increase in the volume of applications followed by employers carefully going through them all to find the best candidate.
The only problem is that doing the work takes time.
"Adjusted for inflation, would you rather make $50,000 in today’s world or $100,000 in 1980’s?"
The question comes from Wonkblog's Matt O'Brien, who is arguing that raw measures of income growth miss "smartphones and social networks, Netflix and HD TVs, apps and whatever other technology you prefer to waste time on." The truth, he writes, is "your middle-class salary is better than you might think."
The technical issues here get into some mind-numbingly complex questions around how economists measures prices, productivity, and quality adjustments. But some thoughts on the larger question he poses:
1) I definitely wouldn't want to be gay in 1980, even if I were making $500,000. Routine racism and sexism were more rampant, too (the dreaded "identity politics" has done a lot of good over the past three decades). This isn't stuff we even attempt to capture in income or productivity statistics. But being able to hold hands with the person you love, or be respected in a meeting, matters a lot in life.
2) Am I a single 20-something in this analogy? Or am I a 40-year-old with three kids? Child care, health insurance, and higher education were much cheaper in 1980. How you value them against smartphones probably depends on whether you have kids, or whether you're sick (and if you're sick, with what — treatments for heart disease are much better today than they were in 1980!).
3) I checked my email probably 200 times a day until making some serious resolutions and installing some blocking software. One way to interpret my old state of email mania is that I derive incredible value from checking my email. Another way to interpret it — a way I think is truer — is that I was addicted to checking email in a way that was providing substantial negative value to my life. I definitely use Twitter, but would I truly be less happy in a world where Twitter didn't exist and I read more of the New Yorker? I'm skeptical.
4) That said, I don't think economists have even begun to figure out how to value technological change, and I'm not sure it's possible to do. If you tracked my household purchasing, you would think I cared about my dining room chairs about as much as I cared about six months of internet access. I do not.
5) Air quality is a lot better today than it was in 1980.
6) Human beings are pretty bad judges of what will and won't make them happy. The happiness literature is pretty clear on this point: all kinds of stuff that we think will make us much happier — like buying a big house — quickly fade into our baseline. All kinds of things we think will make us much less happy — like losing a limb — we end up adjusting to. One of the main exceptions? Commuting times.
7) One thing we do know, though, is that human beings are very loss-averse. So the idea of losing the things I have today in order to live in 1980 is unbearable. But I also don't think I am a happier, more satisfied person today than I would be if I'd been born 15 years earlier. My guess is this question tells us more about how human beings value what they already have than whether people really should prefer one period to the other.
8) Similarly, we know that people are very bothered by relative inequality. It's one thing to go without a smartphone in an age where everyone has smartphones. It's another to go without a smartphone in an age where no one does. The 1980 society is more equal than the 2015 society and, in this counterfactual, you are much higher up the income ladder in the 1980 society than you are in the 2015 society. That kind of thing really does make a difference.
9) A related question that is interesting to think about, though obviously has some of the same problems, is how far back you would be willing to go if money were no object. Given the recency of antibiotics and statins, for instance, I wouldn't be willing to live in 1900 no matter how rich the Lord of Counterfactuals made me.
The latest round of Greece/eurozone crisis — touched off by Syriza winning the Greek election in January — is reaching a close. Other European Union member states are no longer scared of Greece defaulting, so the efforts of Greek Prime Minister Alexis Tsipras and Finance Minister Yanis Varoufakis to secure a better deal for Greece are failing.
This tweet, capturing and translating three Greek newspaper front pages, tells the story:

Headlines #Greece "Last Chance for Deal"  "Knife at our Throat"  "SOS Greece" pic.twitter.com/qhwwmj8Ng7


At the end of the month, Greece needs to give the International Monetary Fund €1.6 billion that it owes as part of the terms of the bailout deal reached way back in 2010. If Greece does not repay the loan, the European Central Bank says it will stop supporting Greece's banking sector. That means the Greek economy will collapse unless the Greek government either manages to make it illegal for Greeks to take their euros abroad (which would de facto be the end of euro membership) or else starts issuing its own currency (which would de jure be the end of euro membership).
To get the money it needs, Greece needs the cooperation of other European Union governments.
That, in essence, is what Greece and its partners have been negotiating over for the past several months: how large a budget surplus Greece will be required to run, and what kind of "structural reforms" Greece will be required to undertake.
It's worth saying that to a large extent the negotiations keep breaking down because of a lack of trust. Other European governments do not fundamentally believe Syriza intends to reform the Greek economy and Greek state in a constructive way. Greece's government does not believe its foreign creditors have Greece's best interests at heart.
But the core sticking points seem to be twofold:
Years ago, back when the Greek debt crisis and attendant political machinations in the Eurozone first hit the headlines, the media was full of people screaming at you to pay attention to arcane fiscal disputes in far-off European capitals. And they were right. At the time, there was a serious risk of financial contagion from Greece to other European countries that could have lead to the collapse of the Eurozone and all kinds of wild consequences for global banking, the world economy, and other big, important things.
Now Greece's debt woes are back in the headlines, and if you want to get caught up, we've got you covered. But if you don't want to get caught up, that's okay! There's a big difference between this round of Greek drama and the previous one. This time it's really not that important. You don't have to pay attention.
The crisis in Greece is very important for the nation of Greece. If you are Greek, if you live in Greece, if you have family in Greece, etc., this is very important.
Basically, if Greece cannot work out a new deal with the people to whom it owes money (primarily the European Central Bank, the International Monetary Fund, and various richer European nations), then Greek people are going to experience some (more) terrible economic pain.
Their country may leave the Eurozone, or the country may continue to formally use the euro but with Greek people unable to take their euros out of the country or exchange them for foreign money. Either way, the best-case scenario would be a healthy bout of inflation complete with lost savings and reduced incomes for pensioners and public employees followed by a reduction in the unemployment rate. The worst-case scenario would be the rapid breakdown of Greek politics and the further rise of the neofascist Golden Dawn political party.
Long story short — Greek people should pay attention to the Greece news.
Note that list of people to whom Greece owes money. Those are governments and government-backed institutions, not banks and individual investors.
That's not an accident, it's a consequence of the resolution of the last Greek crisis.
When that crisis happened, lots of Greek debt was owned by foreign banks. And lots of those banks also owned the debt of other European countries — notably Ireland, Portugal, and Spain — which had been hit by devastating recessions. This led to two big ways that Greece's crisis could become everyone's crisis:
In other words, a Greek default could have led to runs on both foreign banks and whole foreign countries, as panicky investors started selling things. And then behind the four PIGS (Portugal, Ireland, Greece, and Spain) lay Italy, a massively indebted country whose economy is also far too large for the rest of Europe to be able to avoid a bailout. People feared a worst-case scenario of cascading national defaults and the chaotic, unplanned collapse of the Eurozone. If that happened, the US economy, which was still fragile following the 2008 recession, could've fallen back into crisis.
But in the end, Greek politicians and German politicians worked out a bailout deal. Then the European Central Bank assured everyone that no country would be forced into default as long as it was playing by the austerity-minded rules of Eurozone elites. There was no contagion.
Greece is in crisis today because the deal the previous crop of Greek politicians worked out forced a steep fall in Greek living standards. The Greek government had to pursue a very austere fiscal policy, enact a series of unpopular changes to labor law, and, by staying in the Eurozone, was unable to use currency depreciation as a way of spurring job creation. As a result, Greece's unemployment rate has hovered at more than 20 percent for years.
Naturally, Greek voters were angry about this. So they turned to an opposition political party — in this case the far-left Syriza — to lead them out of the abyss. And since January, Syriza has been asking for a better deal.
But Syriza has a problem. The old risk that a Greek meltdown would burn the entire Eurozone has gone away. Greece's debt is in the hands of European governments, which are using that debt as a means of political control to force Greece to change its policies, not as an investment. And the European Central Bank is fully backing Portuguese, Spanish, Irish, and Italian debt, since all four of those countries are sticking with the program. If Greece defaults, nothing terrible happens to the rest of Europe. Syriza is playing high-stakes poker, but it has no cards, and everyone else at the table knows it.
This naturally raises the question of why the drama keeps happening at all. Why don't Greece's partners call the bluff and walk away from the table?
The reason is that the Eurozone is more of a political project than an economic one, and it's one that most of Europe's politicians believe in. If Greece were to leave the Eurozone, that would be a blow to the prestige of the project. Non-Greek politicians (and the voters they are accountable to) are not willing to pay a large price to avoid this outcome, but they are willing to pay something. Consequently, though Syriza isn't going to get anything close to what it promised Greece's voters, it really can get some kind of more generous deal.
This has left Europe in an endless cycle of negotiations that break up, only to return, only to break up again. If a deal is reached, it will be at the last minute, and it won't drastically alter the status quo. If a deal isn't reached, we won't know until the last minute, and it won't have big consequences for the rest of the rest of the world.
So if you're Greek, you really should be paying attention to this news. And if you're just interested in high-stakes economic stories, it's a fascinating, important story. But if you find all this mind-numbingly dull, well, this isn't 2010. It's okay to just read some stories about Donald Trump.
Yesterday, a California regulator ruled that one of Uber's drivers is legally an employee, not an independent contractor. Warren Meyer, a small business owner behind the Coyote Blog, speculates on the various ways this could affect the ride-sharing company:

A few thoughts about this:
Treasury Secretary Jack Lew confirmed late Wednesday that the Bureau of Printing and Engraving is preparing a plan to put a woman on the $10 bill. The woman, who has not yet been selected (here are some good ideas), will apparently appear alongside Alexander Hamilton on the bill.
Rather than resort to this odd arrangement, a better idea would be to take Andrew Jackson off the $20, as Jillian Keenan has argued. Many presidents oversaw mistreatment of American Indians, but Jackson's policies in this regard were especially egregious. He was also a proponent of slavery, and his crank monetary policies — including an opposition to paper money — make him almost uniquely unsuited for a role on currency.
Hamilton had his flaws and the case for putting a woman on American currency is strong, but Jackson is far and away the best candidate for removal.
A California regulator has dealt a serious blow to Uber, ruling that an Uber driver is legally an employee of the company. California Labor Commissioner Julie Su rejected Uber's argument that drivers are independent contractors.
If the ruling is upheld by the courts, it would have big implications for Uber and other companies that have emulated Uber's business model. Employees enjoy a number of legal rights that are not available to independent contractors. Classifying Uber drivers as employees could entitle them to minimum wage and overtime pay, compensation for expenses incurred on the job, workers' compensation and unemployment benefits, and more.
But transforming Uber drivers — and others who work in the so-called "sharing economy" — into full-blown employees might also create some problems. Uber drivers are free to set their own hours, working as many or as few hours as they like in any particular week. Classifying workers as employees could force Uber to place limits on when and how much drivers work, which could be bad for everyone.



When you hire a plumber, it will probably be as an independent contractor rather than an employee. (Ambient Images/UIG via Getty Images)

The law in California (and other states) draws a fundamental distinction between employees and independent contractors. Employees have a direct, long-lasting relationship with their employers, and as a consequence they are eligible for a number of benefits and legal protections.
Independent contractors, on the other hand, are service providers with an arms-length relationship to their customers. For example, if you hire a plumber or electrician to do work on your house, that person might be classified as an independent contractor. It wouldn't make sense for the law to treat everyone who pays for outside help on their house as an employer.
Whether a worker is an employee or an independent contractor is an issue that's decided by regulators and the courts. Employers can't opt out of the legal requirements of labor law merely by getting employees to agree to call themselves independent contractors.

Lyft has also faced controversy for classifying its drivers as independent contractors. (Justin Sullivan/Getty Images)
Uber has been pushing the boundaries of the independent contractor classification. There are a number of ways that Uber drivers seem a lot like conventional employees. Uber drivers must undergo a lengthy application and background checking process before they can begin work. Many drivers treat Uber as a full-time job, working 40 or more hours per week for months at a time.
Uber sets a wide variety of rules governing how drivers should provide services to Uber passengers. Drivers' fees are fixed by Uber, and Uber sometimes provides drivers with bonuses, minimum earning guarantees, and other forms of compensation that don't come directly from customers.
On the other hand, there were a few characteristics that — in Uber's view — distinguished its drivers from conventional employees. Normally, employers set their employees' schedules, requiring them to work a minimum number of hours and often dictating when and where to report for work. By contrast, Uber drivers set their own schedules. They can work as much or as little as they want, and they decide which parts of town to work in.
Employees generally use equipment supplied by their employers, while independent contractors usually supply their own tools. Uber cited the fact that drivers supplied their own vehicles as evidence that they were independent contractors. Uber argued that it merely provided a kind of online marketplace — like an eBay for transportation services — connecting independent ride providers with customers who wanted to purchase their services.
But the California Labor Commissioner rejected Uber's arguments. Su ruled that regardless of what Uber chooses to call its workers, they still meet California's definition of employees.
"Defendants [e.g. Uber] hold themselves out as nothing more than a neutral technological platform, designed simply to enable drivers and passengers to transact the business of transportation," the California regulators wrote.
Regardless of what Uber chooses to call its workers, they still meet California's definition of employees
"The reality, however, is that Defendants are involved in every aspect of the operation. Drivers cannot use Defendants' application unless they pass Defendants' background and DMV checks. Defendants control the tools the drivers use. Defendants monitor the Transportation Drivers' approval ratings and terminate their access to the application if the rating falls below a specific level."
The Labor Commissioner concluded that the plaintiff, a San Francisco Uber driver named Barbara Berwick, was an Uber employee.
The reason this question matters so much is that a lot of legal obligations hinge on whether a worker is classified as an employee.
Employees are entitled to earn a minimum wage, and to overtime if they work long hours
Berwick's complaint focused on one particular labor law requirement: employers must reimburse employees for expenses incurred on the job. She drove 6,468 miles as an Uber driver, which at standard IRS reimbursement rates corresponds to $3,622 in vehicle maintenance costs. She also incurred $256 in tolls. The Labor Commissioner ordered Uber to pay this amount to Berwick.
And according to Rebecca Smith of the National Employment Law Project, classifying Uber drivers as employees could trigger a number of other requirements. Employees are entitled to earn a minimum wage, and to overtime if they work long hours. Employees have collective bargaining rights. Employees can also be eligible for workers' compensation and unemployment benefits.
If this week's ruling is upheld by the courts, it will create opportunities for other drivers to file complaints about Uber's labor practices, forcing Uber to provide its employees with more employment benefits and protections.


FedEx has also faced controversy for allegedly misclassifying its delivery people as independent contractors. (STAN HONDA/AFP/Getty Images)

Berwick isn't the only Uber driver seeking to be classified as an employee. And Uber isn't the only company facing this kind of legal challenge.
Uber is facing a separate class-action lawsuit from Uber drivers who want employee status. This week's ruling will provide a helpful precedent for the plaintiffs in that case, but its outcome is uncertain. Uber's main competitor, Lyft, is facing similar suit.
Other companies have also faced litigation over charges that they misclassified their employees. This week, FedEx agreed to pay $228 million to settle charges it had improperly classified its delivery drivers in California as independent contractors.
The fundamental question here is how closely regulators and the courts should scrutinize a company's unilateral declaration that its workers are independent contractors rather than employees. Uber's defenders argue that the flexibility of independent contractor status is important for startups that are trying to create new types of businesses.
Wage and hour regulations are one area where applying conventional labor law could prove counterproductive. Unlike a conventional employer, Uber doesn't tell employees when or how much they have to work. Employees are free to work as few or as many hours as they want, and they're free to work at times of peak demand, or at times that are most convenient to their schedules.
If Uber was subjected to minimum wage and overtime laws, this would likely lead to new restrictions on when and how much workers can drive. Workers might be prohibited from working more than 40 hours per week, to avoid triggering overtime pay requirements. And Uber might limit how many drivers log in during low-demand period to guarantee that workers earn at least the minimum rate during those hours.
Ian Adams, an analyst at the free-market R Street Institute, argues that the best solution would be to create a new legal category for people who work for on-demand services like Uber and Lyft. This category would provide workers with some benefits of employees — such as expense reimbursements and worker's compensation — but wouldn't provide other benefits such as sick leave and unemployment benefits.
Obviously, a ruling that reduces Uber's flexibility and forces it to provide more generous benefits to its drivers isn't great for the company. But there's reason to be skeptical of fears that treating drivers as employees will doom the business model of Uber or "sharing economy" companies more generally.
Uber is a big enough company that it can easily afford to comply with California's labor regulations. And while those regulations may increase Uber's costs somewhat, Uber should be able to pass on those costs to consumers — especially because competitors will likely be forced to bear the same costs. Where the ruling could hurt Uber is by reducing its ability to experiment with different scheduling and compensation models.
A key point here is that while the ruling would force Uber to pay its employees more for things like expense reimbursement, this won't necessarily have a big effect on drivers' take-home compensation. Right now, drivers deduct their expenses from their gross pay. If Uber has to start reimbursing drivers for their expenses, the company should be able to reduce drivers' base compensation by a corresponding amount, leaving drivers' net pay little changed.
Many of the costs of the ruling could fall on parties other than Uber. One is the drivers themselves. Obviously, many drivers will benefit from the protections afforded by labor law. But others might be harmed. For example, Uber might limit drivers' freedom to choose when and how much to work to ensure that they do not run afoul of minimum wage, overtime, and other rules tied to workers' schedules.
The ruling could also harm would-be Uber competitors, especially if it is emulated in other states. Uber is a big enough company that it can easily absorb the costs of complying with labor laws in 50 states. Smaller companies trying to pursue an Uber-like business model might find the administrative burden too much. Ironically, then, the ruling against Uber could provide Uber with a modest barrier against new competitors in the long run.
And ultimately, the costs of the ruling may be passed on to consumers in the form of higher fares.
Correction: I originally referred to "the California Labor Commission," but there's no such body. The ruling came from California Labor Commissioner Julie Su. Also, I changed the headline to say "an Uber driver," rather than "Uber drivers," is an employee.

Here's a cool map put together by Broadview Networks using data from Hoover's to show the biggest company, ranked by revenue, from each US state:
Broadview
One big thing you see here is that defining "largest" in terms of revenue makes a significant difference. The most valuable company in Washington state is Microsoft, because selling software at massive scale is insanely profitable. And Amazon has a market value that's more than triple Costco's, because investors (apparently) believe that someday Amazon will abandon its zero-profit business strategy and emerge as some kind of monopolistic titan. But Costco's actual sales exceed either of those high-tech companies.
You see the same thing again in California, which is represented by a big oil company rather than by Apple or Google. Chevron is less lucrative than those Silicon Valley giants because the costs involved in its industry are enormous. But Chevron sells more dollars' worth of stuff.
Suddenly this month, news reports are full of tales of an egg crisis, with headlines like "Egg Shortage Impacts New Hampshire Restaurants" and "Egg Shortage Takes Tippin's French Silk Pie" in Kansas, and dire tales of the affliction crimping Austin's supply of breakfast tacos. You can even read about "7 Protein-Packed Breakfasts to Help You Survive the Egg Shortage." What makes this even more distressing than last spring's lime shortage is the link to a deadly outbreak of avian flu, which raises the specter of eventual transmission to humans and true catastrophe.
But even for all the terrified headlines, actual data proving a shortage is really difficult to come by. Supermarket egg prices were on the high side, but not historically high, at the Bureau of Labor Statistics' latest count, and the New York Times reported that wholesale egg prices have been falling since June 9. In part, the conflicting reports simply reflect the inherent uncertainties involved in collection and dissemination of price data. But they also reveal a national — and, to an extent, global — egg industry that is considerably more complicated than you might think. The eggs you see on your supermarket shelf are just a small slice of the overall industry, and the price quoted there has less to do with the laying habits of chickens than with the wily sales tactics of the retail industry.

The underlying issue is an outbreak of avian influenza, first detected in December 2014, which has pushed up egg prices ever since. Recent detections are actually reasonably well-contained in the Midwest, and in some ways look less alarming this spring than they did over the winter. But the sheer quantity of chickens in Iowa — home to about 30 million of the 47 million total birds afflicted — means the economic implications have become more severe recently.

That disruption in the egg supply should lead to higher prices seems reasonable enough, but the complete disappearance of eggs from some restaurant menus is a little more puzzling. One important issue here is that around a third of the eggs in the United States do not reach end users in shell form. Instead, they are cracked, separated, mixed, and pasteurized to create a variety of "egg products," mostly bagged liquid eggs.
These liquid eggs are then passed forward to restaurants and food manufacturers that use them as ingredients in creating packaged food products.
A surge in the price of wholesale breaker egg prices impacts the industrial and restaurant sectors differently.
This has to do with the complexities of supermarket pricing strategy. Large stores typically regard weakly branded staple foods — things like eggs — more as a way to get people in the door than as a way to make money, per se. They are willing to accept razor-thin and at times negative profit margins on these frequently purchased staples in order to ensure a steady flow of foot traffic to other, potentially more lucrative aisles.
That means that at times of supply crunch, many supermarkets would prefer to avoid massive price increases if they can. Since egg wholesalers have no such compunction, this means that when the market is disrupted, making bulk purchases of eggs at big grocery stores can start to look attractive to small restaurants. This undercuts the supermarket's goal of increasing foot traffic. A policy limiting the number of cartons of eggs a customer can buy at one time makes it all work, but can also create an unreasonable sense of alarm in consumers. It's not exactly that the world is running out of eggs, it's just that supermarkets are trying to offer a bargain to regular households without offering a bargain to business buyers.
Different restaurants have different suppliers and different contractual arrangements, so the specific impact of the avian flu on any given business can vary widely. Richard Webner of the San Antonio Express News found one breakfast entrepreneur who is reaping a windfall:
Eggs are an ingredient in almost every dish at Magnolia Pancake Haus, co-owner Robert Fleming said. He buys about 22,000 to 25,000 cases a year, containing 15 dozen eggs each. But he’s avoided the turmoil in the egg industry thanks to a contract he has with an egg producer.
Fleming decided in 2013 to start getting his eggs by contract to avoid the ups and downs that have buffeted the industry in recent years. Earlier this year, when prices were lower, he was paying about 12 percent more than market cost. Now, he’s paying about 30 percent to 40 percent below.
An economics textbook might tell you that Fleming should take advantage of his cheap egg situation by simply reselling eggs to other Texas businesses, smoothing prices throughout the region. In the real world, however, transaction costs and uncertainty tend to inhibit this kind of adjustment. Consequently, the practical impact of the bird flu on the price structure of any given business can vary wildly.
USDA
According to the June 15 issue of the US Department of Agriculture's Egg Market Report, the egg situation appears to be stabilizing just as the media frenzy about eggs is heating up. The reason? People have started buying fewer eggs. "Retail demand is mostly light," they report, as supermarkets have gotten less worried about running out of eggs that are a challenge to make money off of. "Breaking stock supplies are moderate to heavy for a usually light demand," as the impact of restaurant de-egging begins to work its way back up the chain.
Meanwhile, the USDA recently approved a Dutch plan to begin exporting egg products to the United States, the first time since 2002 that non-Canadian eggs will be allowed into the United States. With demand tempered by higher prices and new supplies from Europe coming online, it's likely that the June egg crisis will be forgotten as swiftly as it arose.
So far, that's only a concern if you're a chicken farmer, but things could get worse — and, yes, this is a lot more alarming than a temporary egg shortage.
Apple's decision to create a new streaming service called Apple Music is a recognition of just how much the music business has changed over the past decade. A decade ago, it was widely assumed that people would build collections of digital music just as they previously built collections of records and CDs. Apple was at the forefront of that change, with Steve Jobs convincing record labels to sell their songs for just 99 cents.
But we now know that this whole way of thinking about the music business was wrong. Customers don't want to buy music, and they don't want to build music collections. Smartphones allow something much better: services that allow unlimited streaming of millions of songs. These services are rendering traditional music ownership obsolete.
A decade ago, the iPod and iTunes seemed like the wave of the future. But it's now clear that they were just an awkward transitional stage between the physical formats of the 20th century and the streaming media services that will dominate in the future.
As recently as 2012, analysts were predicting that paid music downloads would continue growing — albeit slowly — for the foreseeable future. But that's not how things have worked out. In 2014, revenues from music streaming services surged, but paid song downloads in the US actually fell by 12 percent. Globally, downloads  declined by 8 percent in 2014.
Digital downloads appear to be on the same trajectory as CDs, only with a 15-year lag. As this chart from CNN shows, sales of CDs peaked around the turn of the century and have been steadily declining since then. Paid digital downloads soared in the decade after the iTunes Music Store was introduced in 2003, but they've now leveled off:
US music sales in various formats.
Tal Yellin / CNN Money, based on data from the Recording Industry Association of America
A key thing to note about this chart is that despite all the hype about digital downloads, they've never come close to offsetting declining CD sales. People just spend a lot less money buying music than they used to.
There are two big ways the rise of the smartphone is leading to the death of music ownership.
One is the popularity of music streaming services. In the pre-smartphone era, music streaming services weren't that useful because you could only use them when you were near your computer. So people bought iPods and filled them with music so they could listen to it on the go.
Globally, downloads declined by 8 percent in 2014
But today's streaming services work on smartphones that can access the internet wherever they go. There's little reason for users to have their own copies of the music they love. They can just call up songs they want to listen to on demand.
Another trend that's been bad for music ownership is the growing number of users who don't own a PC. People used to keep their music on their PCs and transfer it from there to their iPods. When people bought a new PC, they'd transfer the music library from the old computer to the new one.
That's not very practical on a smartphone, which doesn't have the sophisticated file-management tools of a conventional PC. When people buy a new smartphone, they expect to be able to just throw the old one away.
People can sign up for cloud-based storage services from Google, Amazon, and other companies to synchronize their music from one device to another. But managing these services is a bit of a hassle, especially if you have to do it entirely on a smartphone. And if you're going to rely on an online service to manage your music, why not just use a service like Spotify or Pandora that already has every song you could possibly want to listen to?
Like most technology trends, the shift from owning music to streaming it has been led by young people. A 2011 survey found that almost half of people between the ages of 16 and 24 used streaming services, compared with less than a quarter of 55- to 64-year-olds:
EMI Insight Data, 2011
The ubiquity of streaming services means that today's teenagers have no reason to get into the habit of buying music. "I haven't seen someone use iTunes in a really long time," one college student told CNN in 2012. So as the Spotify generation comes of age, the fraction of consumers buying digital downloads will continue to shrink.
Another sign that the shift toward music streaming is permanent: some countries are way ahead of the United States.
IFPI
Overall, downloads still accounted for a slight majority — 52 percent — of digital revenues. But in some countries, streaming has become the dominant revenue source for music labels. In Sweden and South Korea, streaming accounts for more than 90 percent of industry revenues.
It's probably not a coincidence that streaming is most popular in South Korea and the Scandinavian countries of Sweden, Norway, and Finland. These countries have long been among the world's leaders in the speed and availability of high-speed internet access. And streaming services depend more on ubiquitous and high-quality internet service than downloads do.
This suggests that as other countries, including the United States, improve the quality and availability of their internet access, we'll see a similar shift away from music purchases in favor of streaming.
Raising the minimum wage is a popular cause in America, with around 70 percent of the public saying a move to about $10 an hour would be right. A higher wage floor, not surprisingly, is somewhat less popular with American small-business owners, according to a recent survey conducted by Vistage in cooperation with the Wall Street Journal.
Overall, small-business owners are split about 50-50 on the subject of a higher federal minimum, with a very slight majority in the poll saying they are opposed:

However, if you restrict your attention to the owners of the smallest businesses, with less than $4 million in revenue, you see majority support for a wage hike:

Business owners at least claim this is not a matter of direct self-interest, with the vast majority of small-business owners reporting that they do not employ any minimum-wage workers:

Research indicates that wealthy people in general are much more skeptical of minimum wage increases than the population at large, so small-business owners' views may reflect general affluence rather than any specific concern about their workforce.

Consolidating operations at a single New York–area airport has a pretty compelling business logic. At Newark, United can offer connections to dozens of additional destinations, including smaller East Coast cities and major international centers.
At JFK, United was limited to offering point-to-point service. That placed them in head-to-head competition with smaller carriers like JetBlue as well as with Delta's much larger raft of potential JFK connections. By shifting to Newark, United can build on its existing strength.
Delta, by the same token, will benefit from the ability to add even more flights to its existing JFK hub.
Beyond efficiency considerations, however, the slot swap is also part of a trend whereby airlines are doing less direct competition with one another. This is probably necessary, since the airline industry was comically unprofitable for years, but rebuilding profitability by eliminating competition is a bad trend for consumers.
In this case, for example, part of what's happening is that even though Newark and JFK serve the same metropolitan area, they are still in different places. For residents of northern New Jersey, Newark Airport is much more convenient. Conversely, residents of Long Island find it much easier to get to JFK. By streamlining operations so that United's operations are consolidated in one airport and Delta's in another, both airlines gain a modicum of additional pricing power over suburbanites who have difficulty getting to an airport on the opposite side of New York City.
I have no doubt that Chris Mims's Wall Street Journal article making the case against the Mac will attract clicks from throngs of angry Apple fans. But however brilliant the piece might be as an exercise in trolling, Mims's arguments for Apple to cancel its most venerable product line don't really hold water.
The Mac is a popular, profitable, and prestigious product. It's usually a bad idea for a company to cancel a product like that, and this case is no exception.


Larry Page, CEO of Google, a company with more than three successful products. (Justin Sullivan/Getty Images)

"The world’s best tech companies can be the best at two things at once, maybe three," Mims writes. He then chooses the worst possible example to illustrate his point: "Google Inc. is search, Android and ad platforms, plus a long tail of commitments that sometimes feel like someone’s pet project."
Those "pet projects" include the world's most popular video-sharing service, the world's most popular web browser, and an extremely popular email service. They also include Google Docs, Google Maps, and Google Calendar. Google Maps isn't as profitable as Google's search engine, but it would be insane for Google to shut it down because it's only Google's fifth most successful product and Larry Page needs to focus more on the top three.
If Apple didn't have a PC business, it probably wouldn't make sense for the company to try to create one from scratch. But the Mac is highly profitable, and it should continue generating profits for the foreseeable future with minimal oversight from Apple CEO Tim Cook.
It's a mistake to conclude that the Mac platform is unimportant
Indeed, while Apple hasn't killed off the Mac, it has taken Mims's advice to a limited extent: the pace of Mac innovation slowed noticeably around 2007, when Apple introduced the iPhone. That's because Apple pulled many of its best engineers off of Mac projects to work on iPhone-related ones instead.
So there's no reason to think that continuing to sell Macs is particularly distracting. A company might only be able to focus on a few products at a time, but it can easily have others that are running on autopilot.


(Justin Sullivan/Getty Images)

Mims dismissively describes Macs as "a last-century technology." Because mobile OSes are newer and there's more activity around them right now, a lot of people have made the mistake of thinking this means desktop and laptop computers are obsolete products. But that's a misunderstanding of what's going on.
The best way to see this is to observe that most of the world's internet servers run on Unix-based operating systems such as Linux. Unix dates back to the early 1970s, and in some ways it seems horribly antiquated. Yet that doesn't mean people are going to start hosting websites on iPads soon. Rather, Linux works well for certain specialized tasks like running a web server, and it will continue to be used for that task for the foreseeable future.
The same point applies to Macs. They're extremely well-suited to certain kinds of computing tasks — creating a spreadsheet, editing an image or video, writing a computer program, playing a complex computer game, and so forth — that you can't easily do with an iPhone or iPad. There's no reason to think iPhones or iPads are going to become good ways to perform these relatively more complex tasks anytime soon. So people are going to continue to want to buy PCs (from Apple and other companies) for the foreseeable future.
Moreover, if Apple didn't have Macs in its lineup, the company would be more tempted to add PC-like features to the iPad in an effort to appeal to more demanding users. That would be bad for iPad users, who value the product's simplicity and don't really need the capabilities of a full-blown PC.
Apple sells a lot fewer Macs than it does iPhones, but it's a mistake to conclude from that that the Mac platform is unimportant. That's because Mac users are disproportionately important to Apple's broader business strategy.
Apple loves to create products that work seamlessly together
The most obvious example of this is that people use Macs to create iPhone apps. Controlling the Mac platform makes it easier for Apple to ensure that the process of developing iPhone apps is as good as possible, which will mean more iPhone apps get made.
Apple loves to create products that work seamlessly together. A recent innovation called Handoff, for example, allows users to continue a task such as a phone call from an iPhone to a Mac or vice versa. This kind of cross-platform innovation is a lot easier to do when a company owns both platforms.
Monday afternoon, Apple posted a job listing looking to hire editors for its new Apple News product — and it seems to give us a few big hints about how the company envisions the service. Most of all, it seems to be betting that despite Facebook's proven success at attracting and delivering massive audiences for news content, there's still room in the marketplace for a less algorithmically driven approach to distributing journalism.
The listing says that successful editors "will have great instincts for breaking news" — which Facebook's approach is weak on — "but be equally able to recognize original, compelling stories unlikely to be identified by algorithms." That sounds like they want to recapture some of the spirit of the traditional newspaper front page — a product that was less about a determination of what readers were likely to read than about what readers ought to be reading.
Similarly, it says that one of the editors' roles will be "ensuring that important breaking news stories are surfaced quickly, and enterprise journalism is rewarded with high visibility." This refers to stories that are usually costly to produce (in time, if not also money), and include a great deal of original reporting.
Publications do these stories because they make a big impact. But in the dog-eat-dog world of the social web, you can often gain just as much traffic — or even more — by pulling out a few key passages of someone else's enterprise work and slapping a great headline on it.
Most journalists hate this aggregation dynamic, and Apple seems to be promising to put resources behind the opposite strategy — a human editorial team that will ensure enterprise stories get the attention they deserve.
Zigging while Facebook zags is a smart strategy for Apple. Trying to compete in the algorithmic news game seems like a fool's errand, since Facebook's algorithms are already really good. Adopting an approach that caters to the sensibilities of the people who work in journalism offers the possibility that Apple will secure a competitive advantage through closer relationships with news publishers.
That said, ultimately the curatorial approach will only work if audiences embrace it. And here, there's reason for doubt.
The original curatorial ethos of journalism, after all, arose not because anyone was asking for it but out of logistical necessity. Only so much stuff fits on the front page of a newspaper, so someone has to decide what goes there. Trying to pick based on editorial judgment is almost certainly a better idea than picking at random, so that's what newspapers did. Similarly, a magazine cover oriented around a single large image looks better than a crowded mess, so someone needs to pick a cover story.
But if it had actually been possible back in the day to algorithmically determine what choice of cover story was most likely to get subscribers to engage with newsstand readers to buy it, isn't that what editors would have picked? In particular, wouldn't they have "picked" multiple different covers based on knowledge of audience demographics in order to best target the cover to the potential reader? Magazine issues appearing at an airport shop might have had a different cover image than issues at a shop in a New York City subway station. Older subscribers might have been targeted with a different cover story than younger ones.
None of this was possible, of course, but on the internet it more or less is. And it increasingly seems to be the dominant mode of content distribution for the sensible reason that offering people stories they are likely to want to read generates a lot of reading.
President Obama suffered one of the most stinging defeats of his presidency last week, as members of his own party in the House of Representatives overwhelmingly rejected a trade package he had championed. Supporters of Obama's trade agenda are now looking for a way to revive the package, but the odds of success look grim.
Last week's vote was over Trade Adjustment Assistance (TAA), a set of programs that help workers who lose their jobs due to foreign competition. It's part of a package that also includes Trade Promotion Authority, which guarantees a prompt up-or-down vote on trade deals negotiated by the president. Obama argues he needs TPA (also known as "fast track") in order to conclude negotiation of the Trans-Pacific Partnership (TPP), a controversial trade deal involving about a dozen Pacific Rim nations. But opponents of the TPP oppose fast track for the same reason, and last week they scored a major victory when opposition from House Democrats derailed the trade legislation.


Republican leaders in Congress support the legislation, and they may bring it up for another vote this week. However, the New York Times reports that "there were few indications Monday that large numbers of Democrats were ready to reverse themselves and send the trade legislation to the president’s desk."
Here are five reasons Obama's trade legislation — and with it, his broader trade agenda — is failing.
The problem facing President Obama and Republican leaders in Congress is that any package that can pass the Senate won't be able to pass the House, and vice versa.
In the Senate, Democrats refused to vote for any legislation that didn't include Trade Adjustment Assistance. So Republican leaders agreed to include TAA in the trade package in order to win their vote.
But in the more polarized House, this was a nonstarter: most House Republicans opposed it because it included TAA, while most Democrats opposed it because they didn't like the rest of the bill.
The House allows legislation to pass with a simple majority, but the Senate has a de facto rule requiring the support of 60 out of 100 senators to pass legislation. Without this supermajority requirement, things would have been a lot simpler, because the Republican majority would have been able to pass the legislation with minimal help from Democrats.
TPA enjoys a slim majority in the House and likely would get a majority in the Senate as well (49 Republicans voted for the Senate bill, so they'd only need to win one Democrat to get a majority of 50). However, under Senate rules, legislation needs 60 votes to pass. So the legislation needed at least 11 Democrats to vote for the bill. But the compromises required to get those 11 Democrats on board created a package that most House Republicans didn't like.
So the filibuster created a Catch-22 for supporters of trade legislation: anything they did to get Senate Democrats on board would turn off House Republicans, and vice versa. So even though majorities in both the House and Senate likely support TPA, the legislation can't become law.
Last Friday's vote in the House of Representatives represented a triumph for liberal groups, especially the labor movement, which has campaigned aggressively to defeat TPA as a way to derail the TPP. These groups didn't just kill legislation they thought was bad, they did it in the face of concerted lobbying by a Democratic president.
An important development was AFL-CIO head Richard Trumka's April announcement that he would freeze donations to members of Congress pending the vote on fast track. That got the attention of Democrats, many of whom rely on labor money to run their campaigns. The pressure worked, and rank-and-file Democrats in the House rebuffed President Obama's pleas to support his trade package.
House Republicans didn't actually need Democrats to pass the Senate trade package. They're in the majority, and House rules allow legislation to pass with a simple majority vote.
But Republicans in the House are under a lot of pressure not to vote for Trade Adjustment Assistance, which conservatives regard as wasteful government spending. And because TAA was in the Senate bill, the whole package can't pass unless the House passes it as well.
The Club for Growth, which funds primary challenges against Republicans who are judged insufficiently conservative, declared the vote on TAA a "key vote." That was an implicit threat to mount primary challenges against any Republican who voted yes. And the threat worked — House Republicans overwhelmingly voted against TAA, just like Democrats did, even though most Republicans would like Obama to have fast track.
Obama is seeking Trade Promotion Authority to help him pass the Trans-Pacific Partnership, which he is currently negotiated with countries such as Chile, Japan, and Vietnam.
A lot of opposition to fast track comes from old-fashioned protectionists, but support for the Trans-Pacific Partnership has also been eroded by concern over provisions that have little to do with trade. These include investor-state dispute settlement — which critics say makes it too easy for private corporations to challenge regulations they don't like — and measures designed to restrict generic drugs and boost the profits of big drug companies.
These issues weren't necessarily the top priority for congressional Democrats who voted against the treaty — a lot of them sounded protectionist themes about the loss of American jobs. But concerns over the cronyism helped turn liberal intellectuals like Paul Krugman against the treaty. That's important because it means the treaty lacked much of the trans-ideological elite support that previous trade deals have enjoyed.
The secrecy of the TPP negotiating process between the United States and other nations has given critics of the treaty a bit of an unfair advantage. If they make exaggerated claims about the treaty, defenders can't easily set the record straight. Moreover, the very concept of negotiating a treaty that affects everything from copyright law to investment disputes, and keeping it secret until negotiations are over, rubs a lot of people the wrong way. (It will become public before Congress votes on it, but only after it's too late to make changes.)
Supporters of the TPP get exasperated by this. They argue that it would be impossible to negotiate a trade deal if every step in the process were public. And they're not wrong.
But as trade deals have gotten more complex and more controversial, the secrecy looks less like a necessary expedient and more like a conspiracy against the public. If these deals are going to affect so many aspects of people's lives, shouldn't there be an opportunity for public input before the final draft is completed?
Twitter is in trouble again, leading to the resignation of CEO Dick Costolo and an uncertain future with company founder and current Square CEO Jack Dorsey serving as "interim" CEO. Since media types love Twitter, even if Wall Street doesn't, the web is suddenly full of schemes to save the company. Except most of these proposals seem to take for granted that the core problem with Twitter is that shareholders are sad its stock price hasn't gone up since the company's IPO.
But while this is certainly a problem of some sort, it's not a very serious one. Twitter is, after all, mostly owned by very rich people. If you want to know what multimillionaires think Twitter ought to do in order to make them even richer multimillionaires, you should probably listen to Chris Sacca, who is very rich and owns tons of Twitter stock. Alternatively, Twitter could just try to bluff Apple and Google and maybe Facebook or Microsoft into some kind of bidding war to buy the company.
But the actually sad thing about Twitter flailing isn't that it might make some rich people slightly less rich; it's that a service from which tens of millions of people around the world derive enormous value might collapse, vanish, or be ruined.
Here's how to do what matters — save Twitter the service, not Twitter the wealth-maximization vehicle.
This is really the most important one. The big problem with Twitter, allegedly, is that it's a lot less popular than Facebook. And so it is.
That said, Twitter has about 300 million monthly active users. By contrast, 114.4 million people watched the last Super Bowl. Toyota sells about 10 million cars per year. There are 250 million people living in Indonesia. But professional football is not a failure, Toyota is the world's largest car company, and Indonesia is not a small country.
This is the most important point to remember amid all the Twitter worrying: Twitter is extremely popular, it's extremely valuable to its heaviest users, and it's a service that's legitimately changed the world.
If every product that couldn't meet the "as popular as Facebook" test spent its days wallowing in misery, flailing around in search of growth, then the entire business world would be in a constant state of chaos and upheaval. Twitter needs to do what grownup companies do — focus on what it's good at and get better and better at executing on it.
Yes that's totally insane. Advertising is how modern internet companies make money.
And yet advertising on Twitter is a fundamentally dumb idea. In part, that's because so much of Twitter is free advertising — half of what you see on the service is celebrities, media personalities, politicians, small businesses, and national brands tweeting out little nuggets of this or that to promote themselves.
This idea of self-promotion without advertising is at the core of what makes Twitter great. On Twitter, the way you deliver your message to people isn't to pay a centralized distributor or targeting algorithm. It's to craft a Twitter feed that is entertaining and relevant to the people you're trying to reach. When one of my favorite bands announced their next album in June, they didn't need an ad to get me to preorder it.

People of Tomorrow, here it is! "Cascades", the pounding heart of our new album, 'Pagans in Vegas' https://t.co/JTXpEk3k4F


I found it on Twitter because not only do I love Metric, I also love their Twitter account, with its jokes and cool photos and all the rest.
How much money? I'm not sure exactly. But the basic idea would be to combine a free tier, suitable to the needs of the majority of Twitter users, with one or more paid tiers for accounts that want to be able to amass large quantities of followers.
Most people, in other words, would be able to use Twitter for free and follow all their favorite celebrities, sports stars, writers, etc. But a celebrity, sports star, writer, corporate brand, or small business that wanted to use Twitter as a publicity and promotional vehicle would need to pay. Maybe the free tier would be limited to 100 followers, and then you could have a cheap tier for power users and small businesses and an expensive tier for folks who wanted access to six- or seven-figure follower counts.
If you wanted to square this business model with the current vogue for free, ad-supported services, you would say it's a free service (that's the tier most people use) that's financially supported by charging brands money for access to the platform so they can conduct native advertising campaigns.
But call it whatever you want. The point is that you can make Twitter free for readers, and not-free for people looking to reach readers.
Saving Twitter by radically changing it would be beside the point. Accepting that it shouldn't change too much would help stabilize the problem by reducing the need for R&D expenditures. But without chasing the fantasy of dramatic transformation, the company should work on iteratively improving its core product:
Twitter is a widely popular service that has fundamentally transformed the way people communicate and the way news and culture is experienced. It also happens to be pretty great. But like everything else in life, it could benefit from hard work and continued improvement. The great risk is that unrealistic Wall Street expectations, investor greed, executive panic, and a curious lack of self-confidence will destroy something truly useful and leave nothing of note behind.
This past week was a bad one for both Twitter and Reddit. Reddit became embroiled in controversy after it banned a particularly vicious subreddit called Fat People Hate. On Thursday, Twitter CEO Dick Costolo resigned after years of huge losses.
Behind the problems of these two very different sites is a common struggle: most internet users don't particularly understand or like Twitter or Reddit. The average user finds both sites confusing and intimidating. Some — particularly women — find them downright hostile.
Twitter and Reddit retained a do-it-yourself ethos of the early internet that gives users powerful sharing tools, but leaves it up to them to decide what to do with those tools. This ethos made them great, attracted power users, and helped them scale — but only up to a point. It's also become a big part of the reason the sites have struggled to appeal to the average internet user.
If you walk by the desks of software developers here at Vox — or at virtually any other company — there's a good chance you'll see them using a Unix command-line interface that dates back to the 1970s. Geeks continue to use the Unix command line because —once you know how to use it — it's a powerful way to perform complex computing tasks.
Most users don't want to sift through large volumes of information
But most users don't need the power, complexity, or hassles of using a Unix command line, which is why it never caught on with ordinary users. Until recently, most people used Windows PCs or Macs with a more user-friendly graphical user interface. More recently, people have been shifting toward even simpler computing technologies: smartphones and tablets. These mobile platforms provide fewer capabilities than a conventional PC — it's hard to write a blog post or manage a complex spreadsheet on an iPhone — but they're also easy to learn and demand little of users.
The older, more complex computing platforms didn't die. Programmers still use Unix-based operating systems. Many white-collar professionals still use PCs. But for the average person, the complexity of a PC is more trouble than it's worth. So smartphones are becoming the most popular category of computer.
A similar principle applies to social media technologies: the most popular services tend to be the ones that demand the least from their users. And Twitter demands a lot more of users than Facebook does.
To make Twitter manageable, you have to carefully curate the list of people you follow to avoid being overwhelmed. The rules for Twitter conversations — for example, the fact that starting a tweet with someone's username will hide it from anyone not already following that user — are not intuitive to someone dropping by the site for the first, or even the 10th, time. And many users find it intimidating to write tweets that anyone in the world could read.
Twitter helps users sift through a lot of information efficiently, which makes it invaluable for a media professional like me. But most people don't want to sift through large volumes of information. They just want to look at pictures of their friends' weddings, vacations, and babies with a minimum of hassle. And Facebook makes this really easy.
Everything I've said about Twitter also applies to Reddit. For people who have mastered the site's complex rules, it's a fabulous place to find and share interesting content. But Reddit has a lot of arcane bylaws and an insular culture that's not always welcoming to newcomers. So while it has millions of users, it's not anywhere near as big as Facebook, nor is it growing as quickly as Instagram or Tumblr.
Facebook is like a suburban shopping mall — it's a tightly controlled environment that tries to guarantee customers will never have a bad experience. Photos containing nudity are forbidden, for example, and users are required to use their real names. And because most Facebook interaction happens in private, there are few opportunities for strangers to harass one another.
Twitter is more like a busy urban street. Users shout, and almost anyone can hear them. The service is designed to foster open-ended conversations among strangers, and some people have taken this as an invitation to harass others on the service.
Reddit, meanwhile, is an urban street that happens to contain an open-air drug market and a red-light district.
Reddit and Twitter are designed to foster open-ended conversations among strangers
In recent months, both sites have devoted more resources to fighting this kind of abuse. But ridding the sites of abuse won't be easy, because the versatility of the tools Twitter and Reddit provide to their users means they are more prone to being used for malicious purposes as well as valuable ones.
Regardless, the prevalence of online harassment represents another demand that these sites effectively place on their users. For certain users — especially women — spending time on Twitter or Reddit means you're more likely to have your day ruined by threats or crude insults. Which makes them less appealing than other sites that are designed to discourage this kind of abuse.
Twitter is under immense pressure to expand its audience so it can generate the kind of revenues and profits Facebook does. But there are good reasons to think this won't work — and that trying to make it work might destroy the site in the process.
Microsoft's struggles to adapt to the mobile revolution provide an instructive analogy. For years, Microsoft has been struggling to produce a version of its Windows operating system that works well on tablets. The result has often been products that occupy an awkward middle ground — neither as powerful as full-scale Windows PC nor as user-friendly as an iPad. It's hard to reduce the complexity of a Windows PC without simultaneously eliminating features that make it useful. After several flops, Microsoft has finally achieved modest success with the Surface Pro 3, but Windows-based tablets are still a lot less popular than iPads and Android tablets.
A similar point applies to social networks. Twitter's complexity isn't just a problem the company needs to eliminate, it's an essential part of what makes the site useful right now. Twitter facilitates a type of rich, open conversation that's much harder to have on a more restrictive platform like Facebook or Instagram. It's why its most committed users are so incredibly committed, and why they create so much valuable, free content for the service.
While more complex products tend to be less popular in relative terms, they can still be huge markets in absolute terms. Microsoft is a hugely profitable company because it can continue selling its products to businesses that need the power of a full-scale PC. Similarly, the rapid growth of Facebook and Instagram doesn't mean that Twitter or Reddit is doomed; there will continue to be tens or even hundreds of millions of people who want to use these sites.
Twitter's problem is that it hasn't found a way to monetize its relatively small but highly engaged and influential audience. Microsoft makes a lot of money from every Windows license it sells, so it doesn't matter that people buy fewer PCs than mobile devices. But advertisers don't seem willing to pay more to advertise to a Twitter user than a Facebook user. So Twitter's smaller audience has translated to a lot less money in the bank.
Twitter CEO Dick Costolo announced today that he will step down. His replacement, not yet announced, will face some difficult choices, since user growth is slowing and the company lost $578 million in 2014.
Here are four strategies Costolo's successor could pursue to turn Twitter around.
A lot of ordinary users find today's Twitter confusing and overwhelming. Under this strategy, Twitter would look for ways to make its wealth of information more accessible to casual users. For example, investor Chris Sacca has urged Twitter to build a series of channels that allow people to quickly find information about particular topics, like a sports team, TV show, or election. These channels would display tweets related to the topic that have been carefully curated by Twitter staffers.
Right now, Twitter displays tweets in strict reverse chronological order, but Sacca encourages Twitter to relax this assumption. Instead, when a user logs in, the platform should show a selection of the most interesting and insightful tweets that would have appeared on the user's timeline since the last check-in.
The counterargument here is that a more accessible version of Twitter already exists. It's called Facebook, and it's wildly popular. The danger is that aping Facebook might alienate existing users more quickly than it attracts new ones.
Another option, promoted by analyst Ben Thompson, would be to build lots of different apps that allow people to interact with the Twitter platform in different ways. Different apps could target different types of users, with some offering advanced features to power users, while others provide casual users with simplified ways to extract value from Twitter's firehose of information.
The best way to do this would be to encourage third parties to build Twitter apps. But that's tricky because Twitter has burned a lot of bridges with developers since 2012, when it effectively killed off many third-party Twitter apps.
This is one reason Thompson called for called for Costolo to step down back in April. Now that Costolo is out, Twitter's new CEO might have a better shot at convincing third-party developers to give Twitter's platform another shot.
One of Twitter's most valuable assets is an unrivaled view into what's happening at this very instant. That knowledge could prove very useful to Google, whose mission is to "organize the world's information." Earlier this year Google and Twitter signed a deal to make it easier for Google to index tweets in real time. But if Twitter were a Google subsidiary, the search giant might find even more ways to extract value from this data — without requiring significant changes to the primary Twitter app.
The big problem here is that Twitter is probably too expensive. Twitter is currently worth $23 billion, which is a lot of money even for a behemoth like Google. And Google may be able to accomplish many of the same goals at a small fraction of the price with the kind of strategic partnership the company signed earlier this year.
A final option, advocated by Vox's Matt Yglesias, is to simply accept that Twitter is never going to be a mass-market product on the scale of Facebook, and focus on serving the 300 million passionate users it has now as well as possible. This option would entail cutting back dramatically on research and marketing spending so that Twitter could earn a profit with limited revenue. The company might also focus more on selling premium ads targeted at its highly influential user base.
The problem with this option is that Wall Street would hate it. The company's current valuation of $23 billion is based on an assumption that the company will be dramatically larger. Admitting that this won't happen could precipitate a crisis and lead to pressure for the current leadership team to step down.
Rupert Murdoch is stepping down as CEO of 21st Century Fox, the media empire he has built over the past half-century. While most people today know Murdoch for his controversial politics, Murdoch's biggest impact was as a media innovator.
For decades, Murdoch was at the forefront of the media world's major trends. He was a pioneer in digital newspaper publishing, tabloid news, broadcasting, and cable and satellite television. In each of these media, he saw big opportunities and invested heavily (and in some cases waged bitter political fights) to build big and ultimately profitable business. Murdoch's repeated successes over more than four decades and on three continents makes him one of the most talented media executives of the 20th century.
Only in the past decade has Murdoch's business savvy begun to fail him. As the internet has become an increasingly important part of the media landscape, Murdoch has failed to come up with an effective strategy for capitalizing on it.


Print unions picketing the News International print plant at Wapping after Rupert Murdoch had set up a non-unionized plant, 1986. (Michael Ward/Getty Images)

In the United States, people mostly think of Rupert Murdoch as the man behind the Fox television empire. But he got his start in the newspaper business before he jumped into other media.
Murdoch is a native of Australia, and his career as a media mogul began in 1952, when his father died and left 21-year-old Rupert a chain of Australian newspapers. The younger Murdoch proved to be a savvy businessman, and steadily built up his news empire in Australia. He launched the Australian, a national newspaper for Australia, in 1964.
He then made a jump to the United Kingdom, buying News of the World in 1968, the Sun in 1969, and the Times in 1981. To cut costs, Murdoch consolidated these newspapers' printing operations and began to shift the papers to new digital publishing technologies.
These changes ran afoul of existing labor rules, known as "Spanish practices," which led to a war with the industry's unions, who saw the changes as a threat to their jobs. The conflicts turned violent — according to the Guardian, 1,262 people were arrested, and 410 police were injured during months of demonstrations. But Murdoch prevailed, gaining a more flexible workforce and a more efficient printing process.
According to the Guardian, "many in the newspaper business — including some who criticized Murdoch at the time — now concede" that Murdoch's triumph "probably helped prolong the life of the British press by a good few decades."


A cover of the Sun in 1998. (GERRY PENNY/AFP/Getty Images)

When Murdoch acquired the British newspaper the Sun, he soon inaugurated the "Page 3 girl," a photo of a topless woman that appeared inside the cover of almost every issue of the newspaper. Traditionalists were outraged, but the racy images helped make the Sun Britain's highest-circulation paper, a distinction it still holds today.
Other Murdoch properties have been equally willing to use racy content to boost circulation. The New York Post, which Murdoch acquired in 1976, has become famous for its sensationalistic headlines and focus on tawdry stories. The paper's most famous headline is probably "Headless body in topless bar," about a grisly 1983 incident in which a gunman forced a woman to decapitate the owner of the bar. (The author of that headline died on Tuesday.)
Murdoch's newspapers have also gotten a lot of mileage out of political controversies. For example, when Britain went to war against Argentina for control over the Falkland Islands in 1982, Murdoch's papers cheered on British Prime Minister Margaret Thatcher's aggressive posture in the conflict. Critics derided the Sun for its "xenophobic, bloody-minded, ruthless, often reckless, black-humoured and ultimately triumphalist" coverage. But the nationalistic coverage helped to boost the Sun's circulation.
Both traits — sexual titillation and jingoistic political coverage — are evident in one of Murdoch's most famous American ventures, Fox News. Fox News anchors like Bill O'Reilly and Sean Hannity play to the political prejudices of the network's conservative audiences with coverage that's often partisan and sensationalistic. At the same time, Fox News rarely misses an opportunity to broadcast images of scantily clad women.


Married with Children was one of Fox's first hits. (Fox Network/Getty Images)

It's hard to believe today, but there was an era when most Americans had only three options for television content: NBC, ABC, and CBS. This was partly because the primitive technologies of the 1960s and 1970s made running a television network really expensive. And a variety of FCC regulations made it difficult for smaller networks to gain traction. In the early 1980s, it had been decades since someone had successfully launched a new television network in the United States.
In 1985, Murdoch acquired a string of six television stations in major markets that formed the core of the Fox television network. While the network struggled in its first few years, it soon began to thrive with hits such as Married with Children, The Simpsons, Cops, and America's Most Wanted.
Fox consolidated its status as a major network in 1993 when it signed a $1.58 billion deal to carry National Football League games, including the 1997 Super Bowl. The lure of football and some further acquisitions helped Murdoch build Fox into a truly national network. In the early 2000s, Fox became the leading television network among viewers in the coveted 18-to-49 demographic.


Fox News has succeeded by featuring conservative pundits such as Bill O'Reilly. (Peter Kramer/NBC/NBC NewsWire via Getty Images)

While the Fox broadcast station was a big success in its own right, in some ways it was just the warmup act to his big American television success: a line of Fox-branded cable channels. Cable television wasn't exactly a new concept in the 1990s, but Murdoch was savvy enough to recognize that the medium offered huge growth opportunities at that time.
Murdoch launched the FX ("Fox Extended") network in 1994, as well as a network of Fox-branded sports channels. Murdoch's greatest impact came with Fox News. While it bore the tagline "fair and balanced," critics charged that it was anything but, with a conservative slant that permeated its coverage. Still, the channel became a huge hit, attracting a loyal audience of mostly conservative viewers that appreciated its lively, often bombastic coverage.
Murdoch was also an early innovator in satellite television. He acquired a majority stake in the British satellite TV company Sky in 1983. Murdoch merged Sky with British Satellite Broadcasting in 1990 and turned it into the dominant force in the British satellite television business, with 11 million subscribers.


Murdoch with Apple's Eddie Cue at the launch of the Daily in 2011. (Charles Eshelman/FilmMagic)

For three decades, Murdoch managed to anticipate and capitalize on shifting media technologies: digital printing, satellite television, and cable television. He built big, profitable companies for each medium. But he's never figured out how to do that for the internet.
His most ambitious effort was the Daily, an iPad app Murdoch launched in 2011. Murdoch spent tens of millions of dollars on the project, which had a staff of 170 people at its peak. But it was shuttered after less than two years in operation.
The Daily's basic problem was that it tried to reproduce the experience of a newspaper — in which consumers pay a subscription to access a bundle of daily content — at a time when internet news was becoming increasingly unbundled. Most people don't want to sit down and read the news cover to cover on an iPad app; they find news one article at a time using services like Facebook, Reddit, and Google News. The Daily walled itself off from the rest of the internet, and as a result, the rest of the internet mostly ignored it.


The "all in the family" succession strategy at work here is unusual for a company of Fox's size. The Murdoch family, through a trust, owns about a third of the total shares in 21st Century Fox, and the lack of any other large shareholding blocks means they largely have control of the enterprise. But their wealth is heavily tied up in the value of those shares, which in turn is driven by buying and selling on the broad stock market.
So even though nobody can stop Rupert from turning the company over to his sons, the Murdochs need to maintain the confidence of public markets to stay rich. In early trading, Fox shares were down modestly on the news.
Until relatively recently, the assets controlled by 21st Century Fox were part of a company called News Corp that evolved out of Rupert Murdoch's original business owning Australian newspapers. A few years back, Murdoch made the decision to split his conglomerate into two smaller conglomerates. One, the company now called News Corp, owns newspapers (including, most notably, the Wall Street Journal) and a book publishing house. The other, the company Murdoch is stepping down from as CEO, owns television networks and TV and film production studios.
This division makes business sense, but aligns imperfectly with the two faces Murdoch presents to the public.
He is, on the one hand, an entertainment entrepreneur. He is, on the other hand, a force in partisan politics, with properties like Fox News and the Sun that wield substantial influence on three continents. But even though in many ways Fox News is spiritually aligned with Murdoch's politically conservative tabloid papers, as a corporate matter it is lumped with the entertainment properties while the highbrow book publisher HarperCollins resides with the newspapers.
You’re probably not saving enough for your retirement. Check out this calculator and see. If you’re young, you need to be putting away about 15 percent. If you’re older and haven’t been doing that, then you need to be saving even more to catch up. Maybe 20 percent. Maybe 25. Seriously, check out the calculator.
When presented with these facts, many people react not with alarm but with outrage. Americans don’t save enough because by and large they seem to believe it’s not possible to save that much money. And for genuinely poor families, that may be true. But the problem of under-saving is much more widespread than that. Most of the people who have told me that it was impossible to save 15 to 25 percent of their income were relatively successful professionals who could expect to earn an above-average income over the course of their careers.
These people — the kind of people who are most likely to be reading this website — absolutely could and should be saving more.
In 2014, the average savings rate was 4.8 percent, far short of what the average American worker needs to enjoy a comfortable retirement.
Americans used to save a lot more:

A generation ago, the savings rate was between 7 and 10 percent. Two generations ago, Americans saved 10 to 13 percent of their income.
And while some of this might reflect a rising cost of living, especially for education and medical care, it's also a result of increased consumption. For example, the average American today has a house that's 50 percent larger than the average house three decades ago.

(David Cooper/Toronto Star)
America is a rich country, but our high incomes are not evenly distributed. In 2012, the richest 20 percent of households had incomes of at least $104,097. The poorest 20 percent made less than $20,600.
What this means is that unless you're at the very bottom of the economic ladder, it's easy to find examples of people living more frugally than you. A household that made 2012's median income, $51,017, could save 20 percent of their income if they lived like a family at the 40th income percentile, $39,765. Similarly, a household whose income was at the 60th percentile, $64,582 could save more than 20 percent of their income if they lived like a family making the median income.
That's not to say that it's easy to cut expenses. Money makes our lives easier, which is why we like spending it. Cutting expenses is a painful process. But the fact that millions of people do it proves that it's possible. And it's important to remember that you face a tradeoff between a better quality of life now and a better quality of life later. If you don't tighten your belt now, you might be forced to tighten it more dramatically when you reach retirement age.
When it comes to saving money, young workers have several advantages over older workers. One is rising incomes. Workers' incomes tend to grow fastest early in their careers as they gain experience and seniority. Later in their career, they're more likely to stay at the same (hopefully higher) income level.
This means that for many young workers, saving money may not require any actual belt-tightening. It just means not boosting their spending when they get raises. It means keeping a roommate for a few more years rather than getting your own place. It means keeping a one-bedroom apartment instead of looking for a place with two bedrooms. It means continuing to patronize cheap bars and restaurants rather than moving upscale.
You can expect every $1 you save at age 25 to grow to between $4 and $10 by age 65
Even better, if you develop more frugal habits today, that can reduce the amount of income — and, therefore, savings — you need when you reach your retirement age. If you never upgrade from a Honda to a BMW during your working years, then you don't have to worry about whether you'll be able to afford a BMW in your golden years. So saving aggressively early in your career has a double benefit: it increases the amount of cash you have in the bank, while simultaneously reducing the amount you'll feel like you need later.
Most importantly, thanks to the power of compounding interest, dollars you save early go a lot farther. If you follow sound investment principles, you can expect every $1 you save at age 25 to grow to between $4 and $10 (adjusted for inflation) by age 65. A dollar saved at 35 will grow three to five times by 65. So if saving an extra $1,000 this year is difficult, imagine how much worse off your 65-year-old self will be when you have to cut expenses by $5,000.

Your retired self will thank you for driving a car like this. (Justin Sullivan/Getty Images)
Often, when people try to cut costs, they do it by reducing small, optional expenses — like making coffee at home instead of buying it from a coffee shop. But while trimming those kinds of expenses never hurts, it's often more important to focus on expenses that people think of as the essentials — especially housing costs.
Obviously, everyone needs a place to live, so you're not going to be able to eliminate housing costs altogether. But there are a lot of things you can do to reduce them. You can get a smaller apartment or get a roommate. You could move farther out in the suburbs where you can get more housing for less money. And if your personal circumstances allow it, it's worth considering moving in with parents to save money.
Housing costs account for such a large fraction of many people's incomes — especially in big cities — that even modest reductions can free up a lot of cash.
Cars are another big-ticket item that may offer room for savings. Some people view a new, expensive car as a status symbol, but you can probably find a used car that will do the same job while saving you thousands of dollars.

If you don't mind the cold, Minneapolis is a great place to live. (Tom Dahlin/Getty Images)
If you live in a big metro area like New York or San Francisco, it might be a struggle to find affordable housing even if you get a tiny apartment or move far out into the suburbs. In that case, it's worth thinking hard about whether you really need to live in an expensive metropolitan area.
Housing costs are dramatically lower in other parts of the country. Philadelphia has many of the same amenities as other coastal cities but is dramatically cheaper than New York or Washington, DC. And the Midwest and the Sun Belt have cities that are cheaper still. As my colleague Matt Yglesias has pointed out, Minneapolis offers an appealing combination of high incomes and low housing costs. And if the cold weather doesn't suit you, Southern cities like Dallas and Atlanta are equally affordable.
Of course, some people have careers that require them to live in a particular, expensive city. And it might be difficult to earn a comparable salary in a lower-cost area. But many people could move to a much less expensive city without taking a big pay cut. If you're one of them, you could dramatically improve your standard of living.
Most working adults should be saving 10 to 20 percent of their income each year. An important exception is young people who are accepting a dramatically lower income in the short run to prepare them for more lucrative or prestigious careers later on.
Many people could move to a much less expensive city without taking a big pay cut
The most obvious example is people who are still in school. If you're waiting tables to cover the costs of getting a college degree, or if you're a graduate student with a $15,000-per-year stipend, it's going to be hard to save money for retirement. In this case, it's best to think of your education as a kind of savings in its own right — you're acquiring a valuable credential that will allow you to earn, and save, a lot more money in the future.
A similar point applies to people who are just starting out in a highly competitive career, like acting, writing, or fashion. Almost everyone in these industries starts out working a low-paying day job like bartending, waiting tables, or answering phones until they're able to get enough work to practice their passion full-time. Again, this is best thought of as a kind of investment: you're developing a skill that — you hope — will later allow you to earn a good living in a career you'll enjoy a lot more than bartending.
But it's important to be realistic. At age 25, it might be reasonable to live paycheck to paycheck as you focus all your energy on breaking into an acting career. But if you're still doing that at age 30, you need to start planning for the possibility that you're never going to get your big break. You need to either get a more lucrative job or cut expenses enough to save 10 to 15 percent of your bartending income.
Pressure from peers can be a major force driving higher spending. If you go out to eat with a group of friends and one of them wants to order a bottle of wine, it's awkward to be the one who objects to the added expense. But Megan McArdle has some good advice on dealing with this kind of situation:
Go to the mirror. Take a long, loving look at yourself. And then repeat after me: "I can’t afford it." That is what you say to friends who suggest going out when you don’t really make enough money to even stay in. It’s what you say to yourself when you’re feeling bad and want a splurge. There is nothing shameful about making very little money, so there’s no reason you shouldn’t tell your friends that you’re on a tight budget.
McArdle was writing about people who were having trouble finding work, but this is good advice for anyone who is trying to keep their spending down. If your friends are worth keeping, they should be more than happy to work with you to find activities that fit in your budget. More importantly, some of your friends might feel the same way, and be grateful to you for speaking up.
Everyone knows that "the rent is too damn high" in rich coastal cities like New York and San Francisco. And these days most people recognize that regulatory supply constraints — NIMBY activists and snob zoning rules — are a huge part of the problem.  But the finance blog Sober Look makes the point that over the past year a rental housing squeeze has descended on huge swaths of the country where the economic and legal framework is very different. This is going to be a huge financial challenge for lots of people, but it also presents a real business opportunity.
It looks like there's money to be made rehabbing or building homes in all kinds of unfashionable Midwestern markets.
St Louis Federal Reserve
St Louis Federal Reserve
St Louis Federal Reserve
St Louis Federal Reserve
The pessimistic view of this, offered by Nick Timiraos of the Wall Street Journal, is that "Last decade’s housing crisis could give way to a new one in which many families lack the incomes or savings needed to buy homes, creating a surge of renters and a shortage of affordable housing."
But while this dystopian scenario may arise in zoned-out coastal metropolises, there's no reason it should come to pass nationwide. For Michigan, Wisconsin, Ohio, and other low-vacancy areas that are far from built out, these trends simply mean there's a brand new small business opportunity on the horizon: building new houses or rehabbing old ones and operating them as rentals.
The National Federation of Independent Businesses is out with its latest survey of small-business owners, and it shows optimism on the rise and close to pre-recession levels. But the overall news is really better than that, because owners' optimism is tempered by one thing that's excellent news for everyone else — companies are getting ready to pay people more.
National Federation of Independent Businesses
We still haven't reached the levels seen during the mid-aughts, to say nothing of the halcyon days of the 1990s, but this indicator has been heading in the right direction for a long time and is at least getting close to normal levels.
National Federation of Independent Businesses
Bosses aren't handing out raises just to be nice — they're worried about recruiting and retaining the best possible staff. You can see that small-business owners pretty much always complain about taxes, but concern with sales versus concern with labor quality bounce up and down. When the economy is in bad shape, people worry about sales. When it gets better, they worry about labor quality. Right now, labor quality has moved past sales for the first time in years, and it seems potentially poised to open up a large gap for the first time since the Clinton administration.
That's a hassle for some businesses but a huge opportunity for their employees, who now have a real shot to secure raises.
A Monday article in the Wall Street Journal argues that the internet is on the verge of killing cable companies' widely hated practice of bundling a lot of cable channels together into expensive packages:
Pushback is building that could finally break the bundle. Pay-TV subscriptions have peaked in the U.S., and viewers have alternatives through Internet services such as Netflix, Hulu, and YouTube. Distributors like Verizon’s FiOS are trying to find ways to offer flexibility in pay-TV packages, drawing a lawsuit from ESPN in the process. And networks including HBO and CBS are now selling their content directly to consumers without requiring a subscription to a distributor’s big bundle.
The article goes on to complain about how big media companies "force" cable companies — and through them, consumers — to pay for channels they don't want, artificially inflating the cost of cable service.
The weird thing about this argument is that the company that has done the most to break the cable TV bundle — Netflix — is itself a giant bundle of content. Say you love House of Cards but aren't interested in the many other shows available through Netflix streaming. Netflix doesn't care. Either you subscribe to the whole Netflix bundle or you don't.
It's true that you can buy individual House of Cards episodes from other companies like Amazon or Google — but only at a huge markup. Individual episodes cost $1.99. If you expect to watch more than four episodes a month, it makes more sense to get a $7.99 Netflix bundle, which lets you watch not only an unlimited number of House of Cards episodes but a ton of other content as well.
This kind of bundling makes economic sense, because once a show has been created, the cost of distributing it to one additional person — what economists call marginal cost — is trivial. Removing channels from a bundle doesn't save content creators any money, so there's no reason to think it would save customers money either.
The most popular cable channels, like ESPN and AMC, cost a lot because a lot of people want to watch them. The media companies that own them then throw in other, much less popular channels in hopes of making them more popular. But if media companies sold the popular channels by themselves, they'd do it at a price that was almost as high as they charge for the bundles. In an à-la-carte world, different customers would pay different amounts, but on average customers would pay about the same for a lot less content.
It is true that the internet — and companies like Hulu, Netflix, and YouTube — is making the television market more competitive. But what's new about these services isn't that they do less bundling. Rather, it's that they're charging lower prices, and in the process resetting customers' expectations about how much television content should cost. But there's no reason to think this new competition will lead to a world where consumers no longer buy content in big bundles.
Yesterday, Iceland's prime minister, Sigmundur Gunnlaugsson, announced a plan that will essentially close the books on his country's approach to handling the financial crisis — an approach that deviated greatly from the preferences of global financial elites and succeeded quite well. Instead of embracing the orthodoxy of bank bailouts, austerity, and low inflation, Iceland did just the opposite. And even though its economy was hammered by the banking crisis perhaps harder than any other in the world, its labor didn't deteriorate all that much, and it had a great recovery.
How great? Well, compare the evolution of Iceland's unemployment rate with what happened in Ireland, the star pupil of the Very Serious People:

Or compare it with the United States:

How did Iceland pull it off?
For starters, rather than scrambling to mobilize public resources to make sure banks didn't default on their various obligations, Iceland let the banks go bust. Executives of the country's most important bank were prosecuted as criminals.
Trading Economics
Iceland was nonetheless hit by a very serious recession that caused its debt-to-GDP ratio to soar. But even after several years of steady increases, the government didn't panic. It prioritized recovery. And when recovery was underway and the ratio began to fall, the government let it fall gently.
Trading Economics
There's no free lunch in life, and no country recovers from a severe recession without some bad things happening. But while most developed countries have gone through years of grindingly high unemployment paired with super-low inflation, Iceland did the reverse. It let the value of its currency tumble, which naturally brought about higher prices.
But as a result, the country's export industries rapidly gained ground in international markets. Unemployment rose, but maxed out at a modest 7.6 percent before falling steadily to a very low level. In the US and Europe, the priority has been on low inflation to protect the asset values of the wealthy. Iceland prioritized jobs, and it worked.
In the context of bank defaults and a plunging currency, the government felt it was necessary to impose an additional measure — capital controls, regulations restricting Icelandic citizens' ability to take their money out of the country. This is a serious violation of free market orthodoxy. More importantly, it can be a major hassle to ordinary people's lives and an impediment to starting new businesses. In some countries, like Argentina, capital controls become a breeding ground of corruption and mischief.
That leads some to believe that no matter how well heterodox policies work economically, they're ultimately doomed to political failure.
Iceland shows that's not the case. Getting policy right is difficult, but it can be done. And the upside to doing the right thing — devaluing the currency massively, then imposing capital controls to contain the fallout, then ending the capital controls once the economy recovers — can be enormous. Iceland has had a rough time over the past seven or eight years, but so have a lot of other countries. Things are looking up there now because the country's leaders had the wisdom to reject elements of the self-satisfied conventional wisdom that have proven so harmful elsewhere.
Immigrants have long been disproportionately likely to found small businesses, but a new report on entrepreneurship in America shows that the foreign-born are becoming increasingly central to this aspect of the American economy:
Kaufmann Foundation
The turning points appear to have been the downturn in the house-building market and then the subsequent recession. While native-born Americans became slightly less likely to launch businesses during the tough economy (possibly due to difficulty securing credit), immigrants responded to a weak job market by turning to self-employment.
As a result, immigrants now account for 28.5 percent of all entrepreneurs in the United States — way up from 13.3 percent in 1996.
Immigrants are very disproportionately involved in high-flying Silicon Valley startups, but the typical immigrant entrepreneur is engaged in something more humble — more likely a taqueria or a dry-cleaning shop than the next Google. For hardworking, ambitious immigrants who may lack the language skills or formal educational credentials to secure good jobs in traditional workplace settings, starting a small business can be the best path to get ahead.
But policymakers looking to assist small businesses — and even companies looking to market services to them — rarely focus on the unique needs and circumstances of an immigrant community. With nearly a third of small firms owned by the foreign-born, it's time for that to change.
"If you think the Industrial Revolution was transformational, the app store is even bigger."
Those words actually appeared in a video aired at Apple's World Wide Developers Conference ongoing today in San Francisco. It was followed up by a lot of not-ridiculous observations about how apps are important in lots of industries and the app store makes a lot of money and blah blah blah reasonable assertions about how apps are a big deal.
And so they are.
But here's a good chart showing how central the industrial revolution was to the entire history of the global economy:
JP Morgan
Basically there is endless stagnation of living standards, and then there is the Industrial Revolution. It's the most important thing that has ever happened.
This particular bit of hubris doesn't actually derive from Apple, by the way. Rather, it comes from a McKinsey report that asserted that apps are part of a series of trends that are 3,000 times bigger than the Industrial Revolution. McKinsey's Richard Dobbs says, "The Industrial Revolution involved 10 million people. The changes we're seeing in emerging markets involve three billion people." This is an extraordinarily limited way of looking at the Industrial Revolution, which profoundly altered the course of world history and impacted the lives of everyone in the world today.

The basic news in this report — people getting jobs — is good. But it also contains new internal numbers that, in combination, spell a deeper and more fundamental kind of good news. That's that wage growth picked up and the size of the labor force expanded.
Wage growth, you see, is a bit of a mixed bag. On the one hand, it's good for people to earn more money. On the other hand, it can be a sign that the economy is running out of room to grow.
But given how long the US labor market has been depressed, one would hope that's not the case. The hope would be that higher wages would tempt people who've dropped out of the labor force to dive back in and start redoubling their efforts to find work. That would mean the economy has plenty of room for future growth. And that's what we appear to see in this June report.
Staffers at Gawker Media are organizing a union under the auspices of the Writer's Guild of America. This prompted a very bold member of the Vox team to observe to me that perhaps Vox should write an explainer on how one goes about forming a union. "Don't ask management how to form a union" is usually one good step.
The specific procedure actually differs depending on where you work. Government workers' unionization rights are governed by 50 different sets of state law. Airline workers are governed by a somewhat different process originally created for railroads. But for a basic private-sector worker who has nothing to do with airplanes, there is, in theory, a pretty clear process.
To delve deeper, the key thing to know is that labor-management relations in the United States are so bad, and American companies generally so averse to unionization, that there is a significant mismatch between how the process works on paper and how it works in practice.
The National Labor Relations Act basically says that if most of the workers in a given unit want to appoint a labor union to bargain on behalf of all of them collectively, they have a legal right to force management to recognize that union as their exclusive bargaining agent.
To make that happen at your workplace, you need to:
That's in theory. In reality, it could even happen! Maybe your bargaining unit is people who work at a factory in Tennessee building cars for a German company that is partially owned by the government of a German state and the German state in question has a newly elected Social Democratic government, and the union representing your German workers is pressing you to be neutral in the election.
A more typical union organizing effort, however, is a much uglier, litigation-riddled and politicized mess.
The practice actual American labor unions advise is to try to informally organize in a low-key way without tipping off management for as long as possible. You want to start with an internal organizing committee that is broadly representative of the workplace.  Then you want to try to build clear majority support for the union before you call for an election.
That's because once the election is underway, management has formidable tools at its disposal to tilt the campaign in their direction. Managers can't directly threaten to reduce employment if unionization is successful, but nearby Republican Party politicians can do it for them.
They're also not allowed to do favors for workers who wear anti-union shirts and pins to work while penalizing those who sport pro-union gear, but any normal person is going to have his suspicions.
Bosses can also hold meetings where they propagandize against the union, and generally take advantage of being the boss to shift the landscape in their favor.
There are also ample opportunities along the way to litigate.
For example, if your proposed unit is relatively small the bosses can argue that it's too small and the relevant bargaining group should be bigger, and you haven't hit the 30 percent threshold in that bigger group. Or if your proposed bargaining unit is really big, the bosses can go in the other direction and try to minimize the impact of unionization by making it smaller. Then they can litigate around the cards and around the election. Then, once the union is formed, the bosses can stall for years and years on actually signing a contract.
Overall, labor unions are extremely weak in the United States, especially in the private sector. As of 2014, 11.1 percent of American workers were in a union, down from 20.1 percent in 1983. But Gawker writers might have better luck in New York, a state that somewhat bucks the trend.
In the private sector, only 6.6 percent of workers are in a labor union. This means that even though the vast majority of Americans work in the private sector, overall labor union membership is almost perfectly balanced between the public sector's 7.2 million workers and the private sector's 7.4 million workers.
The rise and fall of US labor unions.
(Doug Henwood)
The private-sector unionization rate has been declining steadily since the early 1950s, which was partially offset for a time by a surge in public-sector unionization.
A partial exception to this, however, is in Gawker Media's home state of New York, where the overall union membership rate is a fairly high 24.2 percent and where the local political climate is dramatically more supportive of unionization than is the case nationally.
Apple has self-declared a revolution in technology with the Apple Watch, promising that the new fitness tracker will "help us all stay fit throughout the day," as Apple chief executive Tim Cook put it when the watch was first unveiled. The Apple Watch monitors and displays your heart rate, how much activity you've done, and how many calories you've burned. All of this information — and data from your other health apps — feeds into a new Apple platform called HealthKit, which acts like a dashboard of personal health information.The Apple Watch certainly makes analyzing data easier, and it may even be more precise than other wearable technologies. HealthKit data will also be made available to researchers for analysis through a new platform called ResearchKit.The tech company is promising this will amount to an Apple-shaped health revolution. "Apple Watch gives us the ability to motivate people to be more active  and more healthy," Cook declared last year. But the claims deserve some scrutiny: the evidence on existing wearables suggests that — as with all other silver-bullet solutions for health — we haven't yet figured out how to make behavior change stick. Scientists are also skeptical about how helpful ResearchKit will actually be in the sea of big data about health.
Natasha Dow Schüll, an MIT anthropologist who has been studying the science of self-tracking and behavior change for her forthcoming book Keeping Track, told Vox, "Even with the automated devices that just track you, like Jawbone and Fitbit, usually you still have to do something to keep using it — making sure to wear the thing, recharging it — and reports have shown there's a drop-off in use after about two months."
As this study of behavior change and wearables found, the "dirty secret" about these devices is that they "fail to drive long-term sustained engagement for a majority of users." After a few months, the novelty wears off, excitement wanes, and people are back to their old ways — if they ever changed them to begin with.
Those who use the devices religiously over the longer term tend to be health-focused already. Wearables are just another tool in their already well-stacked fitness arsenal.

Fitbit. (Photo courtesy of Mark Cacovic/Moment Mobil)
When modest changes are recorded as a result of tracking, Schüll added, it's difficult to untangle whether the devices are having an impact or whether it's just the fact that by collecting data, people are paying more attention to what they're doing with their bodies.
Consider a 2013 Pew survey that found that Americans with chronic conditions like diabetes are more likely to track their health indicators (diet, weight) and report that it helps them  maintain their health. But they didn't necessarily use gadgetry. Just the act of tracking — even in their heads — was helpful.
"Everyone agrees that the metrics are good and getting better, the algorithms for analyzing the behavior are better," Schüll summed up. "But the sticking point continues to be habit and behavior change, and how you do that."
Even so, a cottage industry has emerged of "habit pundits" or "behavior design" experts who mix motivational psychology with behavioral wisdom.
They're leading an effort to try to design technologies that respond to specific personality types in the hopes of inspiring lasting change. "Social butterflies will respond if they're in a community where they'll get pressure or kudos," Schüll said. "Others are introverts who find intrinsic satisfaction in looking at their data. People are struggling to come up with the way forward."
In time, these folks may be able to figure out how wearable tracking devices can improve the health of every user. And just because the devices that exist so far haven't been shown to be super helpful doesn't mean they don't have potential, said Schüll. Maybe the new Apple Watch, with its customizable interface and personalized designs, will be a step in the right direction. Maybe Apple will offer more effective prompts and nudges that could do  the trick. "But the technology is so new that we just don't know yet  what's going to happen with it."
For now, applying common sense is probably useful: for centuries, everyone — not just those who can afford the latest Apple gadgets — has had access to other, less sexy technologies (scales, measuring tapes)  that provide extremely accurate and predictive data about your  health (weight, the measure of your waist), and those haven't spurred  behavior change or reversed the trajectory of the obesity crisis in America.
ResearchKit may be more promising for researchers than the HealthKit will be for consumers. Essentially, ResearchKit includes disease-specific apps that allow patients to track their symptoms and opt to share that data with research partners such as the Dana-Farber Cancer  Institute, University of Oxford, and Stanford Medicine.
The open-source platform will also allow researchers to find potential participants for their studies and view the other health data generated by Apple users, such as details about diet and exercise habits,  blood pressure, and weight.
"It's part of a larger move toward greater democratization of  data," said Dr. Ashish Jha, a researcher and physician at Harvard, "and will allow researchers to much better understand what is  actually going on with patients during the 99.9 percent of their lives when  they are not interacting with the health-care system."
But Jha also questioned how easy it would be to access the data and what impact, if any, it will have on patient care. "One  big question is whether electronic health record systems, which tend to be closed, will  allow for providers and patients to link up the patient-generated data  with more formal clinical data in ways that will be useful for  patient care."Dr. Ben Goldacre, an author and physician-epidemiologist who has called for the more widespread use of such data to drive health care, noted that Apple's data set is just one of many available right now, and that we're not always great at harnessing the information deluge for health."Big data is very much in vogue right now. In medicine, this often  means: very large, very noisy datasets, riddled with biases, on  unrepresentative populations," he wrote in an email."Depending on the research question, that  can be useful, and fun, alongside smaller datasets of higher quality,  and it'll be interesting to see what Apple collect. But we should  remember that bigger isn't always automatically better."
Correction: A previous version of this story incorrectly stated when Apple would begin selling the watch.
Just as everyone's finished replacing their "high unemployment" talking points with "no wage growth" talking points, it looks like wage growth throughout the economy has finally picked up.
Here's the Bureau of Labor Statistics' latest chart on inflation-adjusted annual earnings growth, which you can see has accelerated a lot since last winter:
Bureau of Labor Statistics
Actual incomes are doing even better than this because a larger share of people are working and the average workweek has increased slightly.
Some of the increase is coming on the cost of living side (cheaper gasoline) rather than on bosses giving out nominal raises. But the higher pay is real. And one intriguing subplot in it is that wages are actually growing faster for "production and non-supervisory employees" than they are for "all employees." Which is to say that pay for rank-and-file workers is growing faster than pay for managers — a rare example of a trend toward greater economic equality.
On Wednesday, Apple's lead designer, Jony Ive, was promoted to Chief Design Officer. For some good analysis of the corporate politics behind the move and what it signals about Apple going forward, see Ben Thompson and Jon Gruber.
But it reminds me of one of my favorite Ive anecdotes, which comes from the New Yorker's lengthy profile of him. In it, Ive relays an argument he had with his late boss, Steve Jobs:
Jobs's taste for merciless criticism was notorious; Ive recalled that, years ago, after seeing colleagues crushed, he protested. Jobs replied, "Why would you be vague?," arguing that ambiguity was a form of selfishness: "You don't care about how they feel! You're being vain, you want them to like you." Ive was furious, but came to agree. "It's really demeaning to think that, in this deep desire to be liked, you've compromised giving clear, unambiguous feedback," he said.
You can take this insight too far, and if the stories about Jobs are any indication, he almost certainly did. But in trying to separate the tales of Jobs' brutality from his legendary effectiveness as a manager, this is probably a good place to start. Jobs was able to give his employees something many managers can't: clear feedback. And that's because he understood something that many managers don't: it's actually unpleasant to work for a manager who desperately wants to be liked:

Snapchat CEO Evan Spiegel warned of a tech valuation bubble (or maybe a general stock market bubble) at a Re/code conference earlier this week and got his remarks picked up at CNBC, the LA Times, and all over the business press.
It's extremely possible that valuations will go down in the future, but if you specifically look at what he said, you can see that we're actually in something like a bubble of bubble calls. Check out Jason Del Rey's writeup:
Spiegel said the investment bubble is being fueled by an "easy money policy" and low interest rates, which may not last a whole lot longer according to recent economic indicators. Those low interest rates are funneling investments toward stock markets, hedge funds and, yes, startups.
Lots of Silicon Valley types and venture capitalists have this concern about interest rates, and it makes some sense. But here's a crucial point: this isn't what a bubble is.
Low interest rates are not irrational exuberance. They're not mass hysteria. They're not hype. They're not a search for a greater fool. They're not overconfidence. They are very real. You can look them up on the internet. It is a genuine fact about the world that if you want a safe financial asset these days, you need to accept a very low nominal rate of return. That genuinely makes other asset classes — everything from houses to ordinary stock shares to zany digital media startups — look more appealing than they would be in a world of higher interest rates.
And that makes it eminently reasonable for the price of riskier asset classes to be higher than they would be in a world of higher interest rates.
To the extent that low interest rates push up the value of VC-backed technology startups, in other words, that's an example of asset prices being driven by the fundamentals. It's the opposite of a bubble.
Now, what I think Spiegel means is that these conditions won't last forever. Which is true. Financial conditions never stay the same forever. But "future valuations will change in response to changing objective conditions" is a totally different claim from "today's irrational mania will evaporate and prove to have been a mirage."
On Tuesday night, Vox Media — the parent company of Vox.com — announced it was purchasing Re/code, the technology site/conference juggernaut started by Walt Mossberg and Kara Swisher. Jim Bankoff, the CEO of Vox Media, sent a companywide note laying out the deal — how it will work, why it's happening, and what it means for both sides. His note was helpfully formatted as a Vox explainer, and with his permission, it appears, with light edits for clarity, here.
(For more on the Re/code deal, read this piece by Nilay Patel, editor of Vox's sister site The Verge, and marvel at his exceptionally tight GIF game; or watch Mossberg, Swisher and Bankoff announce the acquisition at the Code Conference in California.)
Re/code is probably the most respected and influential tech news media brand among business and C-suite audiences. It launched about 16 months ago and has grown steadily. Unlike The Verge, which is going after a broad and large consumer audience by being the most widely respected technology lifestyle media brand, Re/code's strength is with technology and business elites and leaders.
In addition to its digital presence, Re/code also runs the most successful and prestigious conference business in tech, featuring its flagship Code Conference, which began tonight. Re/code is led by Kara Swisher and Walt Mossberg, who started the successful AllThingsD business and have had long and impressive careers as journalists. They have a team of about 45 people who will shortly be Vox Media employees.
1) Vox Media is built around empowering the most talented digital voices — from our beginnings as a network of sports bloggers in SB Nation through our launch of The Verge and Polygon, acquisition of Curbed LLC, and launch of Vox.com, we've been all about building media brands through the combination of media hackers, platform and culture. The addition of Kara, Walt, and the rest of the Re/code team is a natural progression of our focus.
2) We are strengthening our leadership in tech coverage with the addition of Re/code. The Verge is already the preeminent digital tech/lifestyle media brand, with tremendous growth under Nilay's leadership, reaching a consumer audience of over 24.5 million unique visitors in April and generating 40 million video views each month. With the addition of Re/code, we will extend our leadership of comprehensive tech coverage online, with Re/code's unparalleled expertise in tech business news, to complement the broad consumer appeal of The Verge.
3) Conferences: Re/code is the undisputed leader in tech business conferences across substance, access, and quality. Vox Media will leverage Re/code's leadership in this space and explore ways to apply it to our other media brands.
4) Re/code will benefit from joining Vox Media, integrating Vox Media's various capabilities including marketing, communications, audience development, sales, and production. Their clients will become ours and will benefit from Vox Creative's solutions. Re/code will eventually migrate to Chorus and will be another shining example of the power of our platform.
If you've read this far, you've gathered that The Verge and Re/code have a very different focus. In fact, per Comscore, there is only a 4 percent audience overlap between the two properties.  The Verge is a big, consumer-focused media brand covering all aspects of tech culture, from science to entertainment to transportation and more.
Re/code's focus is on the business of tech from M&A to enterprise, executive movement and corporate strategy. The tech category is big and valuable, with some strong competition. Between The Verge and Re/code we are undisputed leaders, with the momentum to go much further together.
We are going to move the amazing review team on Re/code and have them join The Verge. Walt Mossberg, the most feared, followed, and admired product reviewer of the past few decades, will also contribute to The Verge review program. The program will report up through Dieter and Nilay and put The Verge far ahead of all other product review programs.
Walt and Kara both report to Lock and will be in charge of editorial for Re/code. Lia Kennett, Re/code's current COO, will report to Marty and run the conference business. The review program reports to Dieter and Nilay as exciting additions to The Verge team.
Not much day to day. We have a great events team led by Jen Leibow. Her group will continue to do what it does, organizing successful events for Vox Media and our advertisers. This is very different work than running the Re/code conference business which is what Lia will do. Over time, as often happens across many groups at Vox Media, we would not be surprised to see some radical collaboration, sharing of learnings from each other, or at the very least clinking glasses with new colleagues who share a deep appreciation for how much work goes into making an "in real life" production look effortless.
I've known Walt and Kara for the better part of two decades now. Their values as humans and professionals align with ours, but we'll all have to make an effort to welcome the Re/code team, make them feel at home, and also learn from them.
Well, if you are reading this, you are already distracted, but I believe if we are committed, we can keep it to a minimum. I am asking Marty Moe to help me coordinate the integration process, working with People, Culture, Revenue, Finance, and any other relevant teams. Part of Marty's role is to make sure we don't create distractions.  Our big initiatives, like video growth, audience development/data/growth, Unison, Anthem, etc., and our four priorities that we established at the beginning of the year don't change. There will be no changes to our product roadmap or our strategic initiatives.
Not for a while. No date set and no expectations. Unison, Anthem and other product work remain the priorities for the team. We also recognize that Curbed is first in line!
Not saying, but have faith that we take the company's financial resources seriously and that this is an agreement that works well for both Vox Media and Re/code.
I'm glad I asked. A lot of people had to work long hours, especially over the holiday weekend to get this done. Lauren Fisher, Brian Leung, Alexis Juneja, Steve Swad, Marty Moe, Trei Brundrett, Josh Albertson, Mike Burke, Fay Sliger, and Kevin Powers were all part of the core Vox Media team that helped to get this done. Of course, Kara, Walt, Lia, and others on the Re/code team have been great partners in the process. You learn a lot about people through a process like this, and we all got along tremendously well. Now several others will get involved to ensure a smooth transition.
Tweet it, high-five about it, ask me questions about it ... but then get back to whatever you were doing.
Yesterday, the federal government got five major banks to plead guilty to trying to rig foreign exchange markets. The government is making them pay billions of dollars in fines — more than $5 billion, in fact — but observers like Slate's Jordan Weissmann (or, for that matter, Vox's Matt Yglesias) agree that's pretty light. And Weissmann is mad about it.
"Is the Justice Department still too scared to pursue actual criminal penalties against a bank?" he asks. "So long as banks are allowed to pay for their crimes by simply writing a check, it's hard to think of these as anything other than ersatz convictions."
If you're trying to fix the way America regulates its banks by looking to the way it currently punishes its criminals, you're just asking one broken system to fix another.
CRIMINAL JUSTICE ISN'T JUST ABOUT TELLING BAD PEOPLE THEY'VE DONE BAD THINGS
You can't put a bank in prison. What the government could have done was ban the banks in question from a wide range of moneymaking activities, potentially killing them as viable businesses. Instead, prosecutors waited to bring charges until waivers from the SEC were secured to ensure that business would proceed as usual. That was a key decision and perhaps a mistaken one — is the economic benefit of letting the banks stay in all their major lines of business really worth the cost of lost discipline around misconduct? And if the government knew fines were the only way they were going to punish the banks, should they have made the fines bigger?
These are good questions. But simply dismissing criminal fines as an "ersatz" punishment is ridiculous. Banks like money (that's why they were cheating!), and punishing them by taking money away from them is a perfectly sensible idea.
If the federal government isn't willing to crack down harder on banks as institutions, Weissmann suggests it should make an example out of a few low-level bankers:
the Justice Department is still considering bringing charges against some of the individuals involved in the foreign exchange scheme. Even if the targets of its investigation turn out to just be relatively low-level traders, that would still demonstrate some determination to treat blatantly criminal activity as blatantly criminal activity.
To a criminal justice reporter, that sets off some alarm bells. Let's tweak some of the words a bit:
the Justice Department is still considering bringing charges against some of the individuals involved in the drug ring. Even if the targets of its investigation turn out to just be relatively low-level dealers, that would still demonstrate some determination to treat blatantly criminal activity as blatantly criminal activity.
In other words: the federal government has tried the "let's demonstrate that we disapprove of this criminal organization by cracking down on its low-level members" strategy. It hasn't worked.
It hasn't worked because the government simply expressing disapproval of something doesn't stop people from doing it. It hasn't worked because people at the top of a criminal organization don't necessarily feel vulnerable just because their entry-level employees are getting rounded up. And it hasn't worked because it's extremely easy to replace low-level employees — whether they're drug dealers or bankers. If the problem here is the banks' bottom line wasn't hit hard enough, that's one thing, but doling out severe punishments to rank-and-file employees is cheap moralism — not a real penalty to the organizations they work for.
Of course, a lot of Weissmann's complaint — which is pretty common among economic populists — is that prosecutions of bankers should feel more like prosecutions of other criminals, so that the government can send the signal that what they've been doing is wrong. That's exactly the sort of attitude criminal justice reformers are trying to get rid of.
The fight against mass incarceration isn't just that it targets the wrong people and should target other ones instead. It's a fight against the idea that criminal justice is just telling bad people they've done bad things. An actual drug cartel wouldn't be treated the same way as a group of bankers who called themselves a "cartel," and that's a problem with the criminal justice system, sure. But is the right answer really that bankers should be "punished like criminals," rather than the other way around?
Conventional wisdom in the United States is and has long been that the Great Recession at the close of the previous decade marked a structural break in important social and economic trends. Proponents of this view often like to portray themselves as a minority of embattled truth-tellers, but from New York Times columns to Treasury Secretary Tim Geithner dismissing stimulative policies as a "sugar high," the structural view has dominated both the media and the practical policy debate.
But a closer look at the trend data shows this is much less true than people thought. The real story of the past seven years is that the Great Recession was just really, really big. As the recovery continues, the shifts are melting away and revealing something far more boring: that things are going right back to normal.
This is a big one. As the recession made jobs scarce, many college graduates found themselves working the kind of low-paid retail jobs they had gone to school specifically in order to avoid. Trend pieces about newly minted bachelor's degree-holders plying their trades at coffee shops and clothing stores spread across the land. As far back as 2011, Kevin Carey pointed out that these anecdotes pop up during every recession, but the Great Recession lasted so long that the New York Federal Reserve even started releasing a formal index of the phenomenon.
And it was real enough — until the latest update, released this week, which showed that the trend is abating. This is still far from the best of times for new college grads (or anyone else), but things are clearly heading back to normal.
The bad years generated dozens of trend pieces about young people living at home with their parents, often metaphorically described as living in the basement. Data available in January suggested that this trend was reversing, and late-April census data confirms it — new households are being formed at the fastest pace since 2005, and demand for rental housing is surging.
Another recession-era trend staple was the observation that millennials weren't buying and driving cars at the same rate as earlier generations. While sharp observers like Brad Plumer thought this might have something to do with the weak labor market, overeager urbanists and trend-hungry journalists often spun it as a deep shift in American values. But guess what? Generation Y now owns more cars than Generation X, as an improving economy is giving more people the financial means to buy automobiles, a technology that remains both useful and expensive, just as it's been for the past seven or eight decades.
During the recovery years, employment growth has been stronger in traditionally low-paying, low-status service sector jobs than in middle-wage occupations like manufacturing. This reflects a long-term trend that's been taking place for decades, but mixed with very weak wages during the peak unemployment years led to a surge of worries about a "skills gap" or robots fundamentally altering the economy.
Yet recent months have seen stories about big wage hikes at T.J. Maxx, Walmart, and McDonald's, suggesting that the traditional story of supply and demand tells a better tale. With the unemployment rate falling, it's harder to retain workers at crummy retail jobs, so companies are raising wages.
In March 2009, the urban theorist Richard Florida predicted that the crash would transform the geography of the American economy in a permanent way. And, indeed, the crash did slow the pace of construction in Sunbelt boomtowns, scarring the economies of Phoenix and Las Vegas in a way that didn't happen in places like Boston or Seattle.
But there's been no change in the underlying forces driving suburban sprawl. The American population continues to move on net away from central cities and toward the suburbs. Part of the story is that most people — including most young people — say they prefer suburban living. And even the minority who do like living in central cities are faced with the problem that NIMBY barriers to building new houses in thriving cities like New York and San Francisco make it difficult for them to gain net population.
To say the recession is a passing phenomenon that the country is recovering from is sometimes taken as a full-pollyanna sign or a denial of one's right to complain about broad social problems in the United States. Do not make this mistake! Think back to 2007, before the recession started. America had a lot of problems back then, ranging from high child poverty to mass incarceration to a shockingly inefficient health-care system.
Just because things are heading "back to normal" doesn't mean you need to stop complaining about longstanding problems. But pretty much everything that made 2011 seem significantly different from 2007 now looks to be a consequence of the ups and downs of the business cycle.
Carl Icahn, the legendary investor, is out with a new "open letter" to Apple CEO Tim Cook with a message that should be unwelcome to Apple's management: the company needs to do even more dividends and (especially) share buybacks.
Icahn has been beating this drum for a while, and Cook has responded by launching Apple's first program to flush money out of the company and into the hands of shareholders and then repeatedly increasing its size. But Icahn thinks the program should be even bigger. His core argument is that while Apple's stock is currently very valuable, it actually reflects a fairly pessimistic market outlook.
They say that "the market continues to value Apple at a significantly discounted multiple of only 10.9x, compared to 17.4x for the S&P 500."
That means investors either think Apple will grow at a below-average rate in the future, that Apple will waste the cash it's already accumulated, or some combination of the two. Icahn's letter is full of rah-rah talk about how he loves Apple and how he thinks the Apple Watch and hypothetical Apple car and television products will be huge hits. But his bottom line is that rather than spending its enormous pile of cash on shoot-the-moon efforts to do those things, he wants to see Apple spend its enormous pile of cash on buying shares of Apple stock.
That will, naturally, push up the price of Apple stock, earning a nice profit for Icahn and other major Apple shareholders.
If you don't happen to be a major Apple shareholder, by contrast, it might be nice to see the company spend the money on something technologically and structurally ambitious. But management's current strategy of simply building up higher and higher piles of cash when they already have $194 billion on hand seems difficult to sustain. The impulse to think of this as offering flexibility and security is very understandable. But unless Cook wants to end up just handing this over to his shareholders (boring), he'd better think of a few ways to spend a couple tens of billions of dollars.
A few years ago, Paul Krugman heard an explanation for rising CEO pay that he's never forgotten. It came from a businessman Krugman doesn't name, and it revolved around, of all things, Monday Night Football:
His story went like this: when games started being televised, the financial rewards to winning teams shot up, and star players began being offered big salaries. And CEOs, who watch a lot of football, noticed — and started saying to themselves, "Why not me?" If salaries were set in any kind of competitive marketplace, that wouldn’t have mattered, but they aren’t — CEOs appoint the committees that decide how much they’re worth, and are restrained only by norms about what seems like too much. Football, so my conversation partner averred, started the breakdown of those norms, and we were off to the races.
By the way, the timing is about right.
The football thing is fun, but Krugman's real point has to do with one of the ways income data potentially misleads us:
[T]he eruption of top incomes that began around 40 years ago need not have solid causes — it could be a case of contagious norms-breaking. This might also explain why movements of top incomes are so different in different countries, with the most obvious determinant being whether you speak English; think of it as an epidemic of broken windows in the United States, which spreads to countries that are culturally close to America but not so much elsewhere.
If you look at a chart of CEO pay, you can identify a fairly precise moment when it began to skyrocket:
Economic Policy Institute
It's natural to look at this chart and ask what happened in the early 1990s that let CEO pay go so nuts. What Krugman is saying is that nothing happened in the early 1990s. It wasn't some new policy or disruptive technology. Rather, the conditions that made it possible for CEO pay to skyrocket might have been around for a long time before the 1990s, but CEO pay held steady because of social norms — because paying a CEO so much money just wasn't done.
To think about the difference here, consider that for much of the post–World War II era, paying your CEO a lot of money didn't make much sense because the government would simply tax it all away. Top marginal tax rates on income were above 90 percent:
VisualizingEconomics.com
President Ronald Reagan's tax cuts sent those top rates tumbling, and so a CEO who could negotiate a much bigger salary could also keep a much bigger salary. As Josh Bivens and Larry Mishel argue in an interesting paper on this topic, this gave CEOs more incentive to fight for higher pay. But it still took about a decade for CEO pay to really take off — and that was probably because, for much of that decade, social norms kept CEO pay down.
Eventually, though, some CEO who was a bit brasher than the rest, and had a more compliant board of directors, broke the norm. And once he broke the norm, every other CEO needed to keep up. At that level, after all, money isn't about putting food on the table; it's about showing what you're worth. If you're paid less than another CEO, it means you're worth less than the other CEO. People often think CEOs are greedy, and perhaps they are — but what they're greedy for is respect and status, not just money.
It reminds me, oddly enough, of the rise of the filibuster in the US Senate:
It would be natural to look at this chart and assume that the Senate rules changed at some point — that something happened to make filibusters dramatically easier. But there was no rule change that led the filibuster to explode starting in the 1990s. Rather, the filibuster was always there in a form that could be easily abused, but senators didn't abuse it.
Then, in the 1990s, the number of filibusters began to pick up, and once that happened it kept going up — the norm against filibusters was broken, and so there was no reason for anyone to exercise restraint. Nothing about the filibuster itself had actually changed, but everything about how members of the Senate perceived it had.
On Tuesday, Facebook announced Instant Articles, a new feature that dramatically speeds up the loading time for news articles by hosting them on Facebook's servers. Since then, I've seen a number of people I usually agree with, including Chris Mims and Mathew Ingram, make arguments against Facebook Instant Articles. But the more I think about it, the more I'm convinced that the controversy will look silly in a couple of years.
Fundamentally, Instant Articles are an effort to solve a technical problem — slow loading times for articles — with a technical solution — pre-loading articles so that they're available immediately. Media organizations have been relying on third parties to distribute their content more efficiently for years; the shift to Facebook-hosted articles isn't fundamentally different than earlier shifts to content-delivery networks like Akamai or video-hosting services like YouTube.
The benefits to users are immediate and obvious. The harms to journalism are speculative and for the most part they don't withstand close scrutiny. Here's why.
People spend an incredible amount of time on Facebook, and that gives the social media site a ton of influence over which news articles people read. I think critics are right to worry that Facebook could abuse this power.
Facebook referrals account for a huge share of web traffic. Here's some data from Shareaholic:
Shareaholic
By the end of 2014, Facebook was responsible for one-quarter of all traffic to the sites Shareaholic studied, dwarfing other sites like Pinterest and YouTube. This is consistent with our own experience at Vox: Facebook consistently drives dramatically more traffic to Vox.com than any other source.
This is made more alarming by the way Facebook's news feed works. To avoid overwhelming users with content, Facebook has an opaque algorithm that tries to predict which of their friends' posts users will be most interested and shows them first. In practice, that means that Facebook has a ton of discretion to decide how much traffic each site gets from Facebook.
Losing access to Facebook traffic would be a huge financial cost for most news sites, and that gives Facebook real power over the news industry. I'm told this was a major motivation for the first group of sites that signed up for Instant Articles — they were worried that if they didn't participate, Facebook would provide disproportionate traffic to their competitors.
But the key thing to notice here is that Facebook already had this power before Instant Articles came along. The power to play favorites comes from Facebook's ability to decide which articles to link to. Who hosts the content is irrelevant.

The big worry of Instant Article skeptics is that users will get used to the fast loading of Instant Articles, and that this will have two negative effects. First, as the experience of reading news on Facebook improves, more people will do it, further expanding Facebook's market share and — therefore — its power. And second, users will become more reluctant to click on links to outside articles and wait several seconds for the article to load.
This argument doesn't take the welfare of Facebook users seriously. The several-second delay between the time a user clicks on a link and the time she's able to read an article is a real problem. Reducing that delay will, in the aggregate, save billions of minutes of wasted time and frustration. News organizations should want that not only because it's good for their readers but also because it will cause readers to read more news articles.
It might also make Facebook more popular, but if it does so it will be because it's providing more value to its users. It would be pretty cynical to view that as a problem.


The New York Times is hugely dependent on this company to get articles to its readers. (Etienne Franchi/AFP/Getty Images)

A big part of the uproar over Instant Articles seems to come from the perception that this is an unprecedented change in the way news stories are distributed. But this is actually just the latest step in a long evolution.
Websites have always been dependent on internet service providers like Comcast and Verizon to get their articles to customers. Today, virtually all websites also rely on third-party content delivery networks to efficiently distribute their content. And a lot of media companies use video services like YouTube and, yes, Facebook video to deliver video for customers.
The big difference between Facebook Instant and earlier distribution platforms is that Facebook has a bit more control over how content is presented to readers. But it's not obvious why this matters. No one thinks it's a threat to journalisms when newspapers syndicate one another's articles. The value of a New York Times article is in its content, not the design of the webpage that surrounds it.
A fair number of critics see Instant Articles as threatening because it means Facebook is competing with news organizations. But there's a fundamental difference between creating content and distributing it. Facebook isn't becoming a news organization any more than AT&T, Akamai, or YouTube are news organizations. Instant Articles a content distribution system that — like those other services — helps news organizations get their work to users.


Cable companies pay a lot of money for content like this. (Al Messerschmidt/Getty Images)

To get a sense for how much leverage content producers can have in negotiations with distribution networks, it's worth looking to the cable industry, where media conglomerates periodically negotiate with cable companies to carry their television programming. You might expect cable companies to hold all the cards here, since cable companies control the pipes that actually deliver content to users
Yet surprisingly, media companies often get the upper hand in these negotiations. ESPN, for example, keeps raising its rates, and cable companies are forced to pay to avoid losing sports-loving customers. The value of the cable subscription comes from the quality of the programming the cable network offers. A cable subscription is worth a lot less without ESPN than with it.
The same point applies to Facebook. If Facebook stopped linking to New York Times articles, a lot of users would notice and object. Some of them would switch to another way of reading news. Others would just click on fewer links. It remains to be seen how much leverage news organizations will have, but they're far from powerless.
Several people, including the Wall Street Journal's Chris Mims, have analogized Facebook to Darth Vader in a famous scene from The Empire Strikes Back, in which Vader reneges on a deal he'd made with Lando Calrissian:

Facebook to publishers every day forever pic.twitter.com/HdqEzciDzz


The idea here is that once news sites join Instant Articles, they'll lose all of their leverage and Facebook will be able to impose more and more unfavorable terms on them.
But this ignores the fact that these deals are non-exclusive. The New York Times isn't shutting down its website, and the majority of its traffic and revenues will continue to be generated there. And so when the time comes for the Times to renegotiate its contract with Facebook, it will have more or less the same leverage it had the first time around: the option to leave the program and go back to just providing articles on its website.
Mathew Ingram, for example, points to the bad experience of companies like Zynga that built apps atop Facebook's platform, only to have Facebook shift directions and leave these partners in the lurch. The difference, though, was that Zynga's most successful games were designed primarily for Facebook; Facebook users accounted for 80 percent of Zynga's revenue. But the New York Times isn't replacing nytimes.com with a Facebook app. If Facebook abandons Instant Articles in the future, things will go back to the way they were last week, with no lasting damage to the Times or other Instant Article partners.
It's exceedingly rare for distribution networks to engage in the kind of censorship Mims alludes to here:

What happens the day a publisher decides to post an anti-Facebook piece to Facebook Instant


Here at Vox.com, we not only count Comcast among our investors, we also rely on Comcast to deliver our website to a large fraction of our audience. Yet these facts have had zero impact on my ability to write nasty articles like this when I thought it was appropriate.
This isn't just because there would be a huge public uproar and probably unwelcome scrutiny from regulators if Comcast tried to block articles it didn't like. It's also because large-scale electronic distribution networks just aren't set up for this kind of censorship.
The same point applies to Facebook. It would be monumentally stupid for Facebook to try to use its power over news publishers to try to censor anti-Facebook articles. This would not only fail to suppress criticism (after all, people can find the articles lots of other ways), but it would trigger the Streisand effect and create a huge PR headache for the company.
Of course, Facebook's policies bar users from sharing certain types of content, such as pornography and hate speech, from Instant. And it's possible that this could lead to self-censorship by publishers. But to repeat my first point, this would be a reflection of power Facebook already had due to its large user base. Instant Articles doesn't matter one way or the other.
Facebook has a problem, or thinks it does: reading news stories from Facebook's mobile app doesn't work very well. The company says the average news article takes eight seconds to launch — time in which a bored mobile user might give up and open another application altogether.
Facebook wants to change that. So today the company announced a new partnership with some of the nation's most prestigious publications, including the New York Times, National Geographic, and the Atlantic, where Facebook will actively host entire articles on behalf of news organizations.
Facebook's hope is that this will drastically improve article loading times, particularly on mobile devices. The company is also offering ways for publishers to improve the display of images and video.
But even as major news organizations participate in the partnership, journalists are worried that the deal will give Facebook too much power over the news business. Fusion's Felix Salmon, for example, wrote in March that if news organizations signed up with Facebook, they risked "losing most of the things which make [a] news brand memorable and unique."
The main thing users will notice — if they notice anything at all — is that articles from certain media organizations start loading more quickly than they did before.
In the past, when a Facebook user on a smartphone clicked on a link to a news story, it would open a separate browser window and begin downloading an entire webpage. In the new model, publishers upload copies of their articles to Facebook so they can be hosted on Facebook's servers. This allows Facebook to optimize how the articles are delivered to Facebook.
Facebook hasn't provided a lot of details on the technology behind the product, but what looks to be happening is Facebook is pre-loading the article's content so that it's already on the device when a user clicks a link. Right now, Instant Articles are only available for iOS, but an Android version is expected soon.
The resulting speed increase is dramatic:

Compare and contrast: Facebook instant articles vs Twitter link pic.twitter.com/IlNCg68fYw


But aside from this speed increase, users probably won't notice much difference. Facebook is touting several other features, such as the ability to zoom in on images and autoplay videos, but it's not clear how often publishers will take advantage of these features.


(Mario Tama/Getty Images)

Publishers have grown dependent on traffic from Facebook, and Facebook has a lot of discretion to decide which content is featured in its users' news feed. This fact gives Facebook a lot of leverage. Some publishers fear that if they don't participate, Facebook will point its firehose of traffic in the direction of more pliant competitors.
At the same time, the program offers some benefits for publishers as well. Faster loading times are good for publishers as much as they are for Facebook. And joining Instant Articles gives publishers access to Facebook's powerful advertising program. Facebook knows a lot about its users, and this data allows them to target ads at users who are most likely to be interested in them. That's good for advertisers, who are able to get a bigger impact from fewer ads.
Facebook-hosted articles can have Facebook-hosted ads next to them, and Facebook will give publishers 70 percent of the revenue generated with these Facebook ads. If Facebook's ad platform is good enough, publishers may find that 70 percent of the money from a Facebook ad is worth more than 100 percent of an ad they sell themselves.
Facebook made a few other concessions to coax publishers to get on board. First, publishers retain the right to place their own ads next to the content, and according to reports, they'll keep 100 percent of the revenues from these ads — at least for now. Facebook will also allow publishers to independently measure traffic to Instant Articles using third-party tools such as Google Analytics and Omniture.
Finally, publishers retain substantial control over the branding of Instant Articles. A New York Times article will have a prominent New York Times logo at the top, making clear to readers that they're reading a Times story, not a generic Facebook news story.


Facebook Chief Product Officer Chris Cox. (Ian Kennedy)

A number of journalists worry that the deal will give Facebook too much power over the news business. Here's how Felix Salmon put it in March:
It’s about losing control over exactly how your content is presented and delivered — about losing most of the things which make your news brand memorable and unique. At some point, it’s easy to foresee a world where talented individuals, rather than brands, make a good living by producing the kind of news content which "works really well" on Facebook. If Facebook becomes the new YouTube in that respect, and if Facebook continues to grow as a trusted news source in its own right, then the result could be an existential crisis for news organizations with old-fashioned things like editors and fact-checkers and clear ethical guidelines.
Skeptics believe that news organizations need the kind of control they get from running their own website. In their view, running their own websites fosters a stronger bond between readers and publishers and gives publishers more opportunity to innovate.
They also worry that the relatively favorable terms of Facebook's current deal with publishers won't last. They worry that Facebook could start taking a greater cut of ad revenue, limit news organizations' control over how their content is presented, and limit their access to data about their users' online activities.
As David Carr put it last year: "Many publishers are worried that what has been a listening tour could become a telling tour, in which Facebook dictates terms because it drives so much traffic."
Worst of all, they worry that Facebook will use the leverage provided by its huge audience to coerce the rest of the news industry into joining Facebook's platform. Now that nine prestigious publishers have agreed to join the platform, Facebook could direct more traffic to them and less traffic to the rest of the news industry. That would create tremendous pressure on those other publishers to join up.


Users come to Facebook for this kind of thing more than for news. (sabianmaggy)

It's too early to say, but I'm skeptical.
If you're worried about Facebook having too much power over the news business, then your beef is with user behavior in general, not Instant Articles in particular. The reason Facebook generates so much traffic for news organizations is because users spend a huge amount of time on the site.
And reading news is a small fraction of people's Facebook time. People mostly use Facebook to look at pictures of their grandchildren, share photos of their friends' weddings, and swap gossip about life in their hometowns. Facebook would continue to be a very popular website even if it had zero news content.
So it's not obvious how much publisher participation in Instant Articles increases Facebook's power. Facebook had a lot of power over the news industry last week, and it would have continued having that power even if no publishers had signed up for Facebook-hosted news.
And crucially, these content deals are non-exclusive. Facebook users on iPhones will see a special, Facebook-optimized version of New York Times articles. For everyone else, the Times website will work exactly the same way it did before. And that's unlikely to change, because while Facebook generates a lot of traffic, most of the news industry's traffic still comes from elsewhere on the web.
This means that news organizations retain a fair amount of leverage. If Facebook tried to drastically alter the terms of the deal, the news organizations can quit the program and take their content with them. They'd face some costs for this — slower load times and the loss of access to Facebook's lucrative ad platform — but that's just another way of saying they'd be back where they were before they signed up for the program.
The web is maturing. The early days of any new communications media tends to be a free-for-all, with a lot of small publishers or broadcasters experimenting with the new technologies and building up modest audiences.
But then there's usually a period of consolidation, when a few channels gain a disproportionate share of the traffic. In the 20th century, the television business became dominated by ABC, CBS, and NBC. Most cities became dominated by one or two newspapers. A few magazines like Time and Newsweek dominated the weekly news business.
These new platforms still give users a lot more control than the old ones
Something similar seems to be happening on the web. Facebook, Twitter, and YouTube are emerging as the ABC, CBS, and NBC of the 21st century — sites that attract vastly more traffic than most others.
But the web has two big things going for it. First, these new platforms still give users a lot more control than the old ones did. In 1970, everyone had to choose from the same 3 TV shows. Today, Facebook does a pretty good job of letting you pick what content you're interested in, and Twitter gives power users even more control over the content they choose.
Second, while a few sites are a lot more popular than the rest, there are still a lot of options out there. You can find news using Reddit or Digg or Pinterest or dozens of other sites. And while Facebook has a huge head start, barriers to entry are still pretty low. If Facebook stops serving its users well, someone else might take its place.
The derailment of an Amtrak train Tuesday night in Philadelphia has killed at least six people and injured dozens more.
We still don't know the cause of the accident. But we do know some basic facts about train safety that can help put it in context.
Train accidents are terrifying, and get lots of public attention when they occur. But the truth is that — just like plane travel — on a per-mile basis, riding on a train is much safer than in a car.
The most recent comparison study, conducted in 2013 by economist Ian Savage, compared fatality rates for several different forms of travel in the US.
The number of rail deaths from year to year ranges widely (because many can happen in large, sporadic accidents), but between 2000 and 2009, a person was about 17 times more likely to die while traveling in a car, compared to a train, for the same distance:

(Javier Zarracina/Vox)
Across the US, trains derail more often than you might think — last year, for instance, there were a total of 1,241 derailments. But the majority of them cause no injuries or deaths, and often only cause damage to the cargo they're carrying.
This is partly because just a slim minority of US trains carry passengers (most carry freight), and because most trains cars are designed to survive some level of impact. Additionally, most miles of track are in relatively rural, unpopulated places.
The Washington Post highlights a good analogy on this, which comes from George Bibel's book Train Wreck: The Forensics of Rail Disasters:
Most derailments are relatively benign, and can be compared to a person walking down the street, tripping, getting back up, and continuing on her or his way. Unless derailed cars crash into houses, strike passenger trains, or release hazardous material into a neighborhood, derailments do not normally affect civilians.
Bibel also notes that derailments have become dramatically less common over the years, with a huge dip in the annual rate in the 1980s:

(George Bibel)
There's been a similar dip in fatalities per passenger mile, Savage has found.
The decline was mainly caused by improvements in technology that were implemented after the freight industry was heavily deregulated in 1980, allowing companies to turn a profit, so they could invest more in track and new equipment.
Years ago, for instance, engineers were required to manually spot track signals and stop their trains to prevent collisions. Nowadays, automated systems do that, as well as monitor train speeds to ensure they don't exceed preset limits.

(Javier Zarracina/Vox)
Derailments can sometimes be caused by operator error or equipment malfunction — but more often, they're due to track problems. As Bibel notes in his book, "Broken, settled, spread, shifted, or overturned rails account for about 50% of the equipment related derailments."
We still don't know the cause of the Philadelphia derailment, but it's worth noting here that some of the decline in overall train derailments has been driven by huge investments freight companies have made into maintaining their tracks. As the Omaha World-Herald noted last year, the freight company BNSF spent $5 billion on it in 2014.
The same can't be said for Amtrak. The system has been underfunded for years, and federal legislation requires it to use the revenue it generates in the busy Northeast Corridor (where most of its riders are) to subsidize operations on the rest of its network, which lose money.
This has led to deteriorating track conditions in the Northeast (Amtrak trains ride on tracks owned by freight companies elsewhere), even as passenger numbers steadily climb. It's impossible to say for sure, but this may have played a role in Tuesday's derailment.
If a report by Gabriel Sherman of New York Magazine is accurate, the New York Times is about to sign a historic deal with Facebook that would allow Times news stories to be hosted directly on Facebook's website. The deal — and similar deals with other websites — could benefit users by sharply reducing the time it takes to load news stories. A lot of pundits see this as a danger to the independence of news organizations.
Felix Salmon, for example, has warned that hosting content on Facebook could dilute the brands — and ultimately undermine the journalistic standards — of prestigious media organizations like the New York Times.
"If Facebook continues to grow as a trusted news source in its own right," Salmon argues, "then the result could be an existential crisis for news organizations with old-fashioned things like editors and fact-checkers and clear ethical guidelines."
But this misunderstands something important about the media business. News organizations have always done two things: decide what content people should read, and produce the content itself. We're not used to thinking about these as separate functions because in traditional news organizations — especially newspapers and magazines — they were always packaged together.
But the internet is pulling them apart. And once you start to think about these as distinct functions, the apparent dangers of Facebook-hosted content no longer seem so threatening.


Internet news doesn't work like this. (Daniel R. Blume)

We can think of the New York Times website as really being two products. The homepage is a news aggregator that performs the same function as sites like Digg, Reddit, and Facebook: it suggests articles people might want to read.
Then there's the New York Times's core business: producing news articles. The success of these articles doesn't depend much on how users find them. A click from Facebook is worth about as much as a click from Twitter, Reddit, or the New York Times homepage.
Media organizations tend to overrate the importance of that first part of their businesses. This is especially true of newspaper editors, who have always viewed deciding what goes on A1 as a core part of their job. But the reality is that news organization homepages have been getting less and less important. Today users mostly find news with the help of news aggregators or social media sites, not by bookmarking a news organization's homepage.
So the trend Salmon is worried about — in which news organizations lose control over how readers find and consume their stories — has been underway for years. News organizations, even really big ones like the New York Times, already depend on third-party platforms for most of their traffic.
Indeed, I suspect most users will barely notice the shift from reading NYT-hosted content via Facebook links to reading NYT content hosted by Facebook. Users don't care which company owns the server that provided a particular bit of content or which ad network provided the ad that appears next to it. The only change most Facebook users are likely to notice is that New York Times articles load faster than they used to.


(Ethan Miller/Getty Images)

Of course, it's important for the terms of an agreement like this to be right. News organizations need to have final control over the content of articles, and they need to get enough revenue for the shift to Facebook to make financial sense. But given the significant consumer benefits of faster and more streamlined browsing, it should be possible to come up with terms that are good for Facebook, news organizations, and the reading public.
Salmon worries that as news organizations lose control over how their content is consumed, their brands will be devalued in the process. But recent experience points in the opposite direction: the strength of the Times brand means people are more likely to read, share, and link to Times articles over articles published by other news organizations.
And letting Facebook host news articles won't make Facebook a "trusted news source in its own right" any more than journalists tweeting makes Twitter a trusted news source. Users understand the difference between technology platforms (like Facebook, Twitter, and Reddit) and news organizations (like the New York Times, the Washington Post, and CNN).
This is more obvious in broadcast media than in print. People can get CNN content lots of different ways — cable networks, satellite TV services, or CNN's own website. But partnerships with cable and satellite companies aren't harming CNN's brand, because everyone understands that a cable channel is a different thing from a video distribution system. By the same token, the fact that people can get New York Times articles on Facebook's website isn't going to fool anyone into thinking Facebook has become a news organization.
Disclosure: Vox Media, the parent company of Vox.com, is involved in a collaboration with Facebook to develop video content.
Amy Chozick has a fascinating story about politicians struggling to find a vocabulary to describe families who are not poor but who feel their economic struggles are sufficiently severe that they no longer self-identify as middle-class. I don't have any advice to offer political wordsmiths, but the discussion is a good a reminder that household income is a pretty poor indication of a person's place in the American class structure.
This is too bad, because people like to talk about household income for a reason. It's great to have a summary statistic of people's economic situation, and household incomes invite easy comparison. We can tell which quintile you fall into. We can tell whether you are above average locally or nationally. We can even compare you to a German or Mexican household. It's great.
Except that it's terrible. Consider.
The median household income in the United States is about $52,000. So go ahead and picture a median-income household. What did you picture?
Did you picture a 25-year-old with a decent job who's maybe worried about student loans but is basically doing okay? Or did you picture a married pair of 45-year-olds who are both full-time workers stuck in kinda crappy jobs? Or did you picture a married couple with one full-time worker and one stay-at-home mom? Or a 65-year-old retiree whose $2.5 million stock portfolio yields him $52,000 a year in dividend income?
These people are all in very different situations. But household income says they are all the same. In fact, it says they are all typical households earning the US median household income.
Or consider two affluent dentists who earned the exact same (large) amount of money over decades of practice in Washington, DC. Both always maintained a high household savings rate, and both are now retired. For one dentist, that currently manifests itself in a Dupont Circle townhouse that's matched with a beach place on the Outer Banks and a ski cabin.
The other dentist sold his Dupont Circle townhouse and moved to a much cheaper place in Arizona. He doesn't own any vacation houses. Instead he's got a much larger stock portfolio, which helps pay for his country club membership and frequent travel to different places around the world.
These people are in essentially the same situation, and simply have different consumption tastes. One finds comfort in a stable routine — rotating among three great homes he owns and has set up exactly to his specification — while the other favors variety. But because the imputed rent (i.e., the rent that you would have had to pay to use the houses if you didn't own them) on the three houses doesn't count as income, household income will say they are in very different circumstances.
Last, consider three 22-year-olds.
One just graduated with a computer science degree from Stanford, where his parents covered his tuition, and has just taken a low-paid gig on Hillary Clinton's presidential campaign. The other just graduated with a debt-financed marketing degree from Schreiner University in Kerrville, Texas, and got a job with an electrical supply company. Last, you have a guy whose English isn't great because he was already 14 when he moved to the US and who works long hours at a CVS.
It's entirely possible that the first guy has the lowest income, and extremely likely that the second guy has the lowest net worth. But because of "human capital" — the value of fancy sheepskin, the value of computer skills, the value of social connections, etc. — it's the first guy who ranks highest in the class pecking order and the third guy who ranks third.
In any discussion of a broad social phenomenon, a little loss of precision is necessary. But the key things to keep in mind about household income and class are that you always need to supplement with life-cycle analysis and net worth — especially housing wealth, where otherwise similar people are often in very different situations.
Of course, sometimes ignoring life-cycle effects is appropriate. When you're talking about Affordable Care Act subsidies, the question of blunt ability to pay for insurance is very relevant. Consequently, the question of whether a 27-year-old earning $40,000 a year is "really" poorer than a 47-year-old earning $45,000 a year isn't the issue.
But if you're looking for an analysis of the structure of social class in the United States, you really need to know about where people are in life.
Brazil spent about $3 billion building 12 new or heavily refurbished stadiums for last year's World Cup. Officials promised these taxpayer-funded venues would continue to generate revenue for years, hosting concerts, pro soccer games, and other events.
But as Lourdes Garcia-Navarro at NPR reports, most stadiums are failing to generate much revenue at all. The most expensive one, in Brasilia, is most regularly used as a site for a municipal bus parking lot.

One big problem is that several of the stadiums — including Brasilia's 72,000-seat, $900 million venue — were built in cities where there are only minor league pro teams that don't draw large crowds. This was done so World Cup games could be spread across the entire country, instead of just the southeast, where most of the top pro teams play. It's as if we built gleaming new stadiums in Montana and Alaska for hosting a World Cup in the US.
In Brazil, this plan has left some pretty useless, expensive facilities scattered across the country, because these minor local teams don't sell enough tickets to make playing in the fancy (and expensive-to-maintain) stadiums worthwhile. The rainforest city of Manaus, for instance, is home to a $600 million stadium that was used for exactly four World Cup games. The pro team there currently plays in much smaller training centers, because it'd lose money if it tried to rent out the big stadium.
Many cities have been selling the stadiums to private companies that try to squeeze a bit of revenue out of them, but it's not easy. In Natal, the NPR story reports, a company bought the stadium, but has made little money renting it out for children's birthday parties and weddings, and the facility is now for sale once again.

Arena das Dunas, built in Natal for $130 million, is being used for parties and weddings. (Portal da Copa/ME)
What makes all this even more infuriating is that in many of these cities, hundreds of thousands of people were displaced from neighborhoods that were torn down to make way for these stadiums. And even though the World Cup was partly billed as a way to upgrade Brazil's overall infrastructure, several of the big projects — such as light-rail systems in São Paulo, Cuiaba, and Fortaleza — still aren't close to being finished.
Of course, the most insane part about all this is that for Brazil, the World Cup was just a prelude to an even bigger waste of public money on sports: the 2016 Summer Olympics in Rio de Janeiro. Though a stadium renovated for the World Cup will be reused for the games, the country will still spend a projected $13.2 billion on other facilities and infrastructure, a number that's likely to continue climbing as the games approach.
There are economists who study the potential economic impact of these events on the cities that host them, and their findings are unequivocal: they don't pay. As Victor Matheson, an economist at College of the Holy Cross, told my colleague Brad Plumer, "My basic takeaway for any city considering a bid for the Olympics is to run away like crazy."

Announcing the deal, Verizon said the acquisition "further drives its LTE wireless video and OTT (over-the-top video) strategy."
Un-jargoned, that means video that Verizon Wireless subscribers can access on their phones, and streaming video that cord-cutting Verizon wired Internet (via DSL or Fios) can watch without a cable television subscription.
Similarly, in a memo to staff, AOL CEO Tim Armstrong wrote that "Verizon will propel AOL and comes to the table with over 100 million mobile consumers, content deals with the likes of the NFL, and a meaningful strategy in mobile video."
On that account, this is basically a content acquisition. AOL's portfolio of media brands — which includes the Huffington Post and other things that don't have AOL logos slapped on them — produce videos that could be delivered to Verizon customers through Verizon's infrastructure, allowing Verizon to either charge a premium relative to competitors or extract extra value through ad sales.
Verizon making a content deal makes some sense. But the price paid here seems awfully high. As a professional content man myself, I don't want to devalue what content brings to the table. But the price offered here is more than the *combined* valuation of BuzzFeed and the New York Times, which sounds like a much more formidable content portfolio.
That said, one asset AOL brings to the table that no other media company has is its ridiculous legacy dial-up business. There is absolutely no point to buying dial-up internet from AOL, but a cohort of confused individuals do it anyway, and this brings in profits. Given the nonexistent growth potential in this business, nobody is going to buy AOL because of the subscriptions, but from a valuation point of view the revenue is real, which means you have to pay for it.
That explains some of the premium here, but it's still a bit fishy.
The answer to the riddle probably lies in something the press releases didn't really deal with: AOL's growing ad tech business, which lets advertisers automate ad buying and distribution.
If Verizon could integrate really good mobile ad targeting technology with its wireless infrastructure, it could conceivably gain a huge leg up on the competition. In effect, Verizon would derive more revenue from a Verizon subscriber than AT&T draws from an AT&T subscriber. That would let Verizon undercut rivals on price and create a flywheel where the growing size of Verizon's customer base increases the value of its ad platform, which makes it economical to drive further aggressive expansion of the mobile business.
There are a bunch of ways that could go wrong, but I could see talking myself into it.
If Verizon isn't that interested in AOL's content brands, that of course raises questions about their ultimate disposition. Kara Swisher reports for Re/Code that the German publishing company Axel Springer is in talks to buy the Huffington Post for $1 billion, and in an interview with Re/Code, AOL's Armstrong alluded to potential future sales of some elements of AOL's content business.
"We've spoken to partners about content and scaling," he said. "Obviously we've seen a lot of interest in the content brands we have. So over the course of the summer, stay tuned."
Elon Musk expects his employees to be so committed to their work that he once scolded a Tesla coworker for missing a company event to witness the birth of his child.

That's according to Ashlee Vance's forthcoming book, Elon Musk: Tesla, SpaceX, and the Quest for a Fantastic Future, which quotes the (anonymous) employee in question, who recalls that Musk emailed the following to him:
"That is no excuse. I am extremely disappointed. You need to figure out where your priorities are. We’re changing the world and changing history, and you either commit or you don’t."
At a time when more and more of corporate America seems focused on financial engineering and flushing cash out to shareholders, there is something genuinely admirable about Musk's determination to pursue game-changing innovations. On the other hand, taken to this extreme it becomes a real sickness.
As a new father, I find it rather astounding that Musk managed to write that without getting punched in the face. Even in pure cutthroat business terms, it's difficult to imagine that Tesla is going to be able to attract and retain engineering talent over the long run if this is genuinely the CEO's attitude toward his staff.
You can see more in Matt McFarland's roundup of astounding quotes from the book.
Update:  On Twitter Tuesday morning, Elon Musk took issue with this characterization of events:

Of 22 Quotes from http://t.co/VA2KQ03NNR, 2 need correcting: 1. I strongly support pregnancy leave 2. I've never called myself a samurai
And:

It is total BS & hurtful to claim that I told a guy to miss his child's birth just to attend a company meeting. I would never do that.
The British Conservative Party, led by David Cameron, swept to a surprisingly robust victory this week, securing an overall majority of parliamentary seats and a large advantage in total votes over the Labour Party at a time when polls indicated that neither was remotely likely.
For Americans who have followed British politics primarily through the lens of American Keynesians complaining that Cameron's austerity policies destroyed the British economy, the results may come as a bit of a shock. Is the UK economy actually doing great? Was Paul Krugman wrong about everything?
The truth is more complicated than that. Team Austerity didn't do as well as a superficial read of the returns would suggest — the UK economy is in some ways struggling, the austerity question itself was considerably more complicated than the US media debate about it suggested, and fundamentally the biggest issue in the UK economy has nothing at all to do with austerity or overspending.
To set the table, it's important to understand what actually happened in the 2015 election. Back in 2010, Cameron's Conservative Party scored 36 percent of the vote and 306 seats in Parliament. That made it by far the largest party, but left it short of a majority. Rather than lead a minority government that would have to try to cobble together majorities on a case-by-case basis, Cameron formed a coalition with the third-place Liberal Democrats — a centrist party that had won 23 percent of the vote and 57 seats.
<!--
window.pym || document.write( '<scr' + 'ipt src="http://apps.voxmedia.com/tools/javascripts/vendor/pym-cb3d02c4.js"></scr' + 'ipt>' );
// -->
<!--
var uk_elections_2010_vs_2015 = new pym.Parent( "uk_elections_2010_vs_2015", "http://apps.voxmedia.com/tools/charts-public/?labels=Conservatives%2CLabour%2CLiberal%20Democrats&datasets=36%2C29%2C23%7C37%2C31%2C8&title=UK%20elections%202010%20vs%202015&description=Lib%20Dem%20collapse%2C%20Tories%20don't%20surge&source=BBC&link=http%3A%2F%2Fnews.bbc.co.uk%2F2%2Fshared%2Felection2010%2Fresults%2F&type=bar&legend=2010%2C2015", { xdomain: ".*.voxmedia.com" } );
// -->
In 2015, the Conservatives won 37 percent of the vote, and the Liberal Democrats won 8 percent.
The total vote count of the austerity coalition, in other words, collapsed. And the popularity of Labour rose by a slightly larger amount than the popularity of the Conservatives.
The unpopularity of the austerity coalition is precisely what makes the defeat so crushing for Labour. People were not in love with the incumbent government, and the opposition had a clear chance to take over. But rather than win the votes of the disaffected, Labour watched opposition scatter — with votes heading to regional separatist parties, to the UK Independence Party, and to basically everywhere except the main opposition party.

UK vs. US GDP.
In 2010 through 2013, the overall UK economy really was performing quite poorly. These were hardly the best of times in the United States, but our economy was clearly growing. The UK, having crashed massively and then bounced back under Gordon Brown, witnessed a slowdown and a prolonged period during which total GDP remained below its pre-crisis level. But things began to pick up in the subsequent years.
Recent UK economic performance hasn't been stellar, but it's been totally fine — good enough for Cameron to hang on to those who supported him in 2010. But note that the UK continues to lag well behind the US in its recovery. Most research indicates that voters care more about rates of change than absolute levels, and Cameron's win seems to confirm that.
The coalition's controversial argument was that the British budget deficit needed to be reduced right away, rather than leaving the work of fiscal consolidation to come some time after economic recovery was underway.
This meant that the austerity mostly happened in the early years of Cameron's government. That's the centerpiece of Paul Krugman's explanation for the good years — they happened because austerity was largely over.
<picture class="c-picture" data-cid="site/picture_element-1500891955_6090_18879" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/AKu53tRkxxz6VwiNXkvzpC5jW8U=/0x0:960x640/320x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 320w, https://cdn.vox-cdn.com/thumbor/I8f7qeLMIptjt5RdmOzL1fcURcs=/0x0:960x640/520x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 520w, https://cdn.vox-cdn.com/thumbor/8RV-2E8a-kJLySblxsNGCGlMKR0=/0x0:960x640/720x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 720w, https://cdn.vox-cdn.com/thumbor/58x4Zna253eQVHMnareY_A1lOxw=/0x0:960x640/920x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 920w, https://cdn.vox-cdn.com/thumbor/phm3tFYBd63vg2vBgmwSeA876ik=/0x0:960x640/1120x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/dahZFa3slm_VQocjbtT9i9rp564=/0x0:960x640/1320x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/L_BORaH7EW02C-eGS99IqSgavGs=/0x0:960x640/1520x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/P-IAf0276q0G-vIhOc4mOVf_bz8=/0x0:960x640/1720x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/IKxyyx0JoALJkAeAvRQkL6R4LN0=/0x0:960x640/1920x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/lANaVlt7t4MmPgaECoFTG--ZBG0=/0x0:960x640/1200x0/filters:focal(0x0:960x640):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3680354/lms-july-14-gif.0.gif" alt="UK employment level">

</picture>
UK employment level. (UK government)
But while UK GDP growth went from bad to okay, UK employment growth has actually been extremely robust.
Not only has the unemployment rate fallen (as in the US), but the total number of people employed has soared as participation in the labor force has increased. A fair amount of this has to do with the coalition's policies, which have not simply been austere (i.e., focused on cutting the budget deficit) but are specifically focused on cutting social assistance spending and thereby encouraging people to go out and accept low-paid jobs.
The interesting macroeconomic achievement here is that the UK economy has been able to absorb all these additional workers despite mediocre growth.

In the UK, as in the United States, the central bank has attempted to boost the economy with rounds of quantitative easing.
Unlike in the United States, this expansionary stance has including willingness to run an inflation rate of more than 2 percent for a period of years. This had the effect of substantially driving down average real wages, which helped a bunch of new workers find jobs amid a slumping economy.
Regardless of what you think of David Cameron, it looks clear that the United Kingdom is not currently in a severe labor market recession. That means that on a forward-looking basis, there are no real grounds for an ongoing austerity debate.
The real debate concerns the past. Cameron and his coalition partner Nick Clegg say that had they not moved to swift fiscal consolidation in the past, the United Kingdom would have been at risk of a Greek-style financial market panic and total meltdown.
It is difficult, in practice, to see how this would have happened. A loss of investor confidence in the fiscal position of the government would have resulted in a falling value of the pound and an expansion/inflationary monetary environment. A falling pound and an expansionary/inflationary monetary environment are exactly what the UK got under austerity. On the other hand, the success of the Bank of England in achieving an expansionary monetary environment in the context of fiscal austerity suggests that fears of austerity crushing the economy were also somewhat misplaced.
Austerity was neither necessary to avoid a meltdown nor sufficient to wreck the labor market. It was simply a policy choice to emphasize small government, less spending, and more employment in the private service sector rather than a more expansive welfare state with more public sector employment.
The current economic challenge facing the UK, then, is not unemployment but low wages and low productivity. How to increase wages and productivity is, in general, a very deep and difficult economic policy question. But in the specific case of the United Kingdom, it's actually relatively simple.
You see, in the UK productivity is massively higher in greater London and the nearby Southeast than anywhere else in the country:

(Full Fact)
If more people moved from the low-productivity regions to London and the Southeast, productivity and wages would rise.
So why don't they? Well, as a recent Center for Economic Policy analysis explained, "In 2014, UK house prices per square metre were the second highest in the world (topped only by Monaco), with especially high valuations in London and the South East. New houses are about 40% smaller than in similarly densely populated European countries."
This is because it is very difficult to get permission to build new houses in these high-cost areas: "The UK's planning system is the main cause of the affordability crisis, especially in London and the South East."
If the UK revised its planning rules to allow for more construction in the most expensive areas, real wages would increase through three mechanisms:
This agenda of housing liberalization was not on the agenda of any major party in the 2015 election and appears very unlikely. But productivity has become the main problem in the UK economy, and housing reform is the key to unlocking it.


Payroll employment rises by 223,000 in April; jobless rate essentially unchanged (5.4%) http://t.co/1Y9cSWJUIB #JobsReport #BLSdata
Really the only unusual or exciting thing about this jobs report is how unusual it is for something so thoroughly expected and non-game-changing to happen. Adding a bit over 200,000 jobs a month is both what analysts thought would happen, and also a trajectory that is consistent with a continued slow decline in unemployment but no real labor market boom.
Dive deeper into the data, and the basic lack of surprises only continues. Labor force participation is up, but only very slightly. Hourly wages are up, but only very slightly.
There's nothing about this jobs report that is likely to change the Federal Reserve's mind about anything, and therefore no reason to expect financial markets to have any particular reaction. Those who think the Fed's current course is dangerously inflationary will keep thinking that. Those who (more correctly!) think the Fed's current course is unreasonably inflation-averse will keep thinking that, as well. Janet Yellen will keep thinking she's on the right track.

Monthly wage growth update: meh edition pic.twitter.com/o5zGiZe8Tw
Wage growth appears to have settled into a steady pattern that is somewhat better than what we saw at the depths of the recession, but far below what was considered normal before the recession. Partially offsetting this, overall consumer price inflation has been abnormally low for a couple of years now. There are also some compositional effects pulling average wages down as a large cohort of inexperienced 20-somethings have been entering the workforce.
Overall it is a little difficult to understand why some of the small upward bumps have been interpreted in some quarters as a sign of an imminent inflationary breakout. Even the strongest wage-growth months have been weak compared with 2006 or 2007, years that were not exactly halcyon days for the American worker.
Perhaps the clearest sign of how not-yet-completed America's recovery comes from looking at the level of full-time jobs, which is still well below where it was in 2007:
US has added 7.9 million full-time jobs since recession ended but there are still 750,000 fewer than when it began pic.twitter.com/YKTeuzeXK2
The population, needless to say, has grown in the intervening years, meaning that the failure to fully catch up in job growth makes it difficult for rank-and-file workers to gain bargaining leverage.
Activists have long promoted pay transparency as a means of combating the gender pay gap, with the theory being that women armed with objective information about the pay scale can do a better job of fighting for equal treatment. Now Myles Borins has created Talkpay, a new Twitter bot that can bring transparency to the scene.
How it works: you send a DM to the bot, and it tweets out anonymized information about your salary, industry, race, and gender.

Coming soon... send us a dm and we'll auto tweet your #talkpay


For example:

#talkpay female, 28, London, IT project manager, 6 years experience, Bachelors degree, £77k + performance bonus


Borens's inspiration comes from Lauren Voswinkel, whose #TweetPay hashtag and article touting pay transparency in Model View Culture got the transparency discussion rolling in technology circles.
That said, any opt-in program, whether anonymized or not, has some obvious limits.
A broader solution exists in Norway, where the government makes it possible to look up anyone's tax return online, thus ensuring full transparency of all salaries. Any person at any job can go look up any of their colleagues' pay or pay received by people doing comparable work at a competing firm.
So does it work? Well, Norway does have the smallest pay gap for experienced workers (Germany does better for 20-somethings) of any advanced economy.
The international gender pay gap.
(OECD)
So is that the miracle of pay transparency at work?
Unfortunately, it's a bit difficult to say for sure, since Norway's public policy varies dramatically from America's in a variety of ways. Norway has quotas mandating that women be represented on corporate boards and parental leave policies that are both generous and optimized to ensure men participate in child-rearing. It also has a higher share of its workforce in the public sector, and even in the US the public sector pay gap is smaller than in the private sector.
And even the Norwegians have stepped away from radical transparency somewhat. It used to be that the database was free and open, leading newspapers and other media organizations to create sites where you could browse salary data anonymously. Now you need to log in, and the system is two-way transparent, meaning you can see who's been creeping on your salary data.
Still, even in its current form Norwegian transparency is light-years ahead of any Twitter bot — creating a system that doesn't just change the conversation but that actually lets people rigorously research pay equity questions and find unambiguous proof when they're undervalued by their employer.
Here's a month's worth of interest rates on German 10-year bonds, from Bloomberg:
German bonds this year.
(Bloomberg)
This spike has the financial press (Reuters / Bloomberg / NYT / FastFT) into a tizzy and has created a situation in which a person trying to make money day-trading in European sovereign debt markets could easily have lost himself a bundle (pro tip: don't try to do this), with potentially huge implications for various hedge fund positions and other wheeling and dealing.
But is it economically significant? I am skeptical. Per Ralph Atkins's explainer for the Financial Times, it's very unclear to well-informed people why this is happening. And if you zoom the chart out, this dramatic week of bond yields looks rather less interesting.
Here's a six-month view:
Six months of German bonds.
Bloomberg
And here's a one-year view:
One year of German bonds.
Bloomberg
And a five-year view:
Five years of German bonds.
Bloomberg
Long story short, the interest rate paid by the German government on its debt is still freakishly low by historical standards. The fact that yields moved back to January 2015 levels so quickly is certainly interesting, but the current level the market is at is pretty dull. This would have to go quite a bit farther up to even reach what you would consider a normal level of interest for investors to charge a government to borrow money.
This post is part of a series on the past, present, and future of commuting in America.
Back in the 1920s, most American city-dwellers took public transportation to work every day.
There were 17,000 miles of streetcar lines across the country, running through virtually every major American city. That included cities we don't think of as hubs for mass transit today: Atlanta, Raleigh, and Los Angeles.
Nowadays, by contrast, just 5 percent or so of workers commute via public transit, and they're disproportionately clustered in a handful of dense cities like New York, Boston, and Chicago. Just a handful of cities still have extensive streetcar systems — and several others are now spending millions trying to build new, smaller ones.

Buffalo's extensive streetcar system in 1935. (International Railway Company)
So whatever happened to all those streetcars?
"There's this widespread conspiracy theory that the streetcars were bought up by a company National City Lines, which was effectively controlled by GM, so that they could be torn up and converted into bus lines," says Peter Norton, a historian at the University of Virginia and author of Fighting Traffic: The Dawn of the Motor Age in the American City.
But that's not actually the full story, he says. "By the time National City Lines was buying up these streetcar companies, they were already in bankruptcy."
Surprisingly, though, streetcars didn't solely go bankrupt because people chose cars over rail. The real reasons for the streetcar's demise are much less nefarious than a GM-driven conspiracy — they include gridlock and city rules that kept fares artificially low — but they're fascinating in their own right, and if you're a transit fan, they're even more frustrating.

Electrified streetcars in Grand Rapids, Michigan. (Grand Rapids Historical Society)
During the 1800s, animal-drawn streetcar lines were built in cities across the United States. Starting in the 1880s, they were replaced by electrified streetcars, which quickly became the dominant mode of transportation in many cities.
Running streetcars was a very profitable business. Cities expanded, and people who found themselves living too far from work to walk depended on them. (Some real-estate developers built nearby suburbs around streetcar lines.) Over time, the businessmen who ran the streetcars, called "traction magnates," consolidated ownership of multiple lines, establishing powerful, oftentimes corrupt monopolies in many cities.

In 1902, Atlanta had an extensive streetcar network. (Georgia Railway and Electric Company)
Eventually, many of them contracted with city governments for the explicit right to operate as a monopoly in that city. In exchange, they agreed to all sorts of conditions. "Eager to receive guarantees on their large up-front investments, streetcar operators agreed to contract provisions that held fares constant at five cents and mandated that rail line owners maintain the pavement around their tracks," writes Stephen Smith at Market Urbanism.
Until the start of World War I, these conditions weren't a huge problem. But soon afterward, they became excessively onerous — because even though these companies were making sacrifices to act as monopolies, they were no longer operating as them.

A Fresno streetcar stuck in traffic, in 1938. (Fresno Beehive)
The decline of the streetcar after World War I — when cars began to arrive on city streets — is often cast as a simple choice made by consumers. As a Smithsonian exhibition puts it, "Americans chose another alternative — the automobile. The car became the commuter option of choice for those who could afford it, and more people could do so."
But the reality is more complicated. "People weren't choosing to ride or not ride in some perfect universe — they were making it in a messy, real-world environment," Norton says.
The real problem was that once cars appeared on the road, they could drive on streetcar tracks — and the streetcars could no longer operate efficiently. "Once just 10 percent or so of people were driving, the tracks were so crowded that [the streetcars] weren't making their schedules," Norton says.
cars could drive on streetcar tracks — so they slowed them down dramatically
In some places, like Chicago, streetcars retained dedicated rights of way, and they survived. Pretty much anywhere else, they were doomed. "With 160,000 cars cramming onto Los Angeles streets in the 1920s, mass-transit riders complained of massive traffic jams and hourlong delays," writes Cecilia Rasmussen at the Los Angeles Times.
What's more, in many cities the streetcars' contracts required them to keep the pavement on the roads surrounding the tracks in good shape. This meant that the companies were effectively subsidizing automobile travel even as it cannibalized their business.
And paying for this maintenance got more and more difficult for one key reason: many contracts had permanently locked companies into a 5-cent fare, which wasn't indexed to inflation.

(City-data.com)
Especially after World War I, the value of 5 cents plummeted, but streetcars had to get approval from municipal commissions for any fare hikes — and the idea of the 5-cent fare had become ingrained as something of a birthright among many members of the public. "Nobody on these commissions would approve fare increases to cover costs, because that would get them in trouble with their constituents," Norton says.
The public had little sympathy for the traction magnates who'd entered into these contracts. Today, many progressives and urbanists are boosters of streetcars, but back then they were often seen as a bastion of corruption — especially because of their owners' history of violent strike-breaking.

Decommissioned streetcars awaiting destruction in Los Angeles, 1956. (Los Angeles Times photographic archive)
Because of these factors, some streetcar companies began going into bankruptcy as early as the 1920s, when they were still their cities' dominant mode of transportation. Huge costs and the falling value of fares forced them to cut back on service, steadily pushing people to the convenient, increasingly affordable automobile.
As they fought to stay alive during the Great Depression, many companies invested in buses, which were cheaper and more flexible. Initially they operated mainly as feeder systems to bring commuters to the end of lines, but as time went on, they began to replace some lines entirely.
That wasn't enough to save most of these companies, especially as city, state, and federal governments pumped more and more money into roads. "By the '50s, planners put a priority on bringing cars into cities with new urban highways," Norton says. "That really made streetcars truly impractical to get around on."

One of Detroit's final streetcars, shown as part of a special parade in 1956. (Dave's Electric Railroads —Stephen M. Scalzo collection)
By the 1950s, virtually all streetcar companies were in terrible shape. Some were taken over by new municipal bus companies, while a total of 46 transit networks were bought up by National City Lines — the holding company linked to GM, as well as oil and tire companies, that's at the center of all the conspiracy theories.
While it's true that National City continued ripping up lines and replacing them with buses — and that, long-term, GM benefited from the decline of mass transit — it's very hard to argue that National City killed the streetcar on its own. Streetcar systems went bankrupt and were dismantled in virtually every metro area in the United States, and National City was only involved in about 10 percent of cases.
It's also not exactly right to say the streetcar died because Americans chose the car. In an alternate world where government subsidized each mode equally, it's easy to imagine things playing out quite differently.
So what killed the streetcar? The simplest answer is that it couldn't compete with the car — on an extremely uneven playing field.
Last night at the Hoover Dam, the Freightliner company unveiled its Inspiration Truck: the first semi-autonomous truck to get a license to operate on public roads.
The Inspiration is now licensed to drive autonomously on highways in Nevada. It works a bit like a plane's autopilot system: a driver will get the rig on the highway, and can take control at any time once it's there. But the truck will be able to drive itself at high speeds, using cameras to make sure it stays within its lane and doesn't get too close to the vehicle in front of it.

This isn't a full-fledged autonomous truck, but it's a crucial first step toward one. And though this event isn't getting nearly as much attention as Google's debut of its self-driving car last year, there are good reasons to believe autonomous technology will transform the trucking industry much sooner than the private car.

The Inspiration Truck. (Freightliner)
There's one big reason why companies like Freightliner — as well as others in Japan and Europe — are investing in this sort of technology, and it's not good news for the 1.7 million people who drive long-distance trucks.
The trucking industry constantly struggles to find enough drivers, even when unemployment is high. And the cost of a machine operating a vehicle will be dramatically cheaper than the cost of a human.
The long-distance trucking industry carries about 68.5 percent of all goods shipped in this country, and on average, paying drivers accounts for 30 percent of its costs. One of the things that drive up the cost of drivers is the fact that long-haul trucking is a much more unpleasant lifestyle than driving a cab. Many drivers spend five or six days a week on the road, which is why trucking has such an extraordinarily high turnover rate: about 98 percent annually.
long-haul trucking has a 98 percent turnover rate annually
Obviously, machines won't care about these lifestyle difficulties. In fact, the Australian mining company Rio Tinto has already begun implementing autonomous trucks at its remote iron ore mines, partly because it's so expensive to get drivers to go live in those places.
Another factor is that unlike for taxis, limits on the number of hours a person can drive also drive up the cost of transport. A trucker can legally only drive for 11 out of every 24 hours, so shipping something cross-country requires delays for sleeping, or paying two drivers who trade off. That won't be the case with driverless trucks, which will also be able to more easily take advantage of traffic-free interstates at night.
Freightliner says its new technology isn't meant to eliminate drivers — it's mainly intended to cut down on driver fatigue, reducing the frequency of accidents. But if it doesn't develop the technology to fully replace drivers, another company will. Eliminating drivers will save trucking companies even more money than it will save companies like Uber — eventually reducing the cost of trucked goods.

(Freightliner)
Engineering a vehicle that can drive at a constant speed on a predictable highway is a much simpler problem than designing one that can drive on city streets, which are filled with traffic lights, pedestrians, and other sudden obstacles.
That's the reason Google began is self-driving car program with experiments on highways. And the vast majority of long-haul truck miles are logged on the interstate system, making it a convenient industry to begin implementing driverless technologies — including some that are already used.
Though Google's flashy car is getting the most press, you've probably already experienced semi-autonomous driving capabilities that have been rolled out in human-operated cars: things like adaptive cruise control (which can slow you down if there's a car in front of you) and systems that alert you if you begin drifting out of your lane.
Inspiration's new truck is a combination of these existing technologies, not a fully autonomous vehicle. (The government considers it a level 3 out of 4 on its automation scale, the same as Google's current cars.) But it's an incremental step toward a future truck that might be able to operate without a driver.

A truck convoy experiment in Sweden. (Scania)
Between 20 and 40 percent of the cost of shipping something by truck goes to fuel. A large amount of this fuel is burned as the engine fights air resistance, because trailers are so boxy and un-aerodynamic. One way of cutting down on it is driving trucks in tight packs, so one can draft behind another.

(Peloton)
It's not safe for human drivers to draft off each other in this way, because it doesn't allow for enough reaction time if the truck in front stops suddenly. But computers can do it. Recently, a few different companies have conducted experiments with a lead truck (driven by a human) and other trucks and cars that follow it (each with a human inside, but guided by computers).
Recent tests by a US company called Peloton showed that while traveling at 65 miles per hour 36 feet apart, two trucks packed together saved 7 percent on fuel. This was the average for just two trucks (the lead saved 4.5 percent, and the rear saved 10 percent), so it would increase as trains get longer.

These sorts of trains would also serve as a convenient bridge to eventually eliminating some drivers.
Initially, you could have drivers in each truck, like Freightliner is proposing. Later, before driverless trucks are ready for city streets, you could have a driver in just the lead truck, with others waiting to take them over after they exit the interstate. Eventually, you could do away with the humans altogether and save that 30 percent spent on pay.

(Scania)
The factors that block a broad rollout of self-driving trucks fall mainly into two categories.
One is safety. People are understandably concerned about the idea of computers driving cars around on the roads, and those worries are amplified for tractor-trailers that can weigh up to 80,000 pounds when fully loaded.
But experts actually predict that automated systems will make trucking safer by eliminating distracted driving and human error. And Google's driverless cars, at least, have now gone more than 700,000 miles without an accident.
safety concerns are amplified for tractor-trailers that can weigh up to 80,000 pounds
Obviously, their safety needs to be proven before these trucks are filling the interstates. But this may be a surmountable concern, especially since the technologies can be implemented incrementally. In a sense, a single driver leading two trucks linked digitally isn't all that different from the drivers that already pull two trailers linked physically, and these convoys may gradually get people used to the idea of autonomous trucks.
The other problem is legal. Right now, just a few states (including California, Nevada, and Florida, plus DC) have laws on the books regarding driverless cars, and their legal status as a whole is murky. For driverless trucking on interstates to be practical, all states would need to explicitly allow these vehicles on public roads.
Advocates are hopeful that national legislation will solve this problem. It's all very uncertain, but in 2012, Google's Sergey Brin predicted the Department of Transportation would begin regulating autonomous vehicles nationally as early as 2017.
And it seems likely that if self-driving cars were legalized, driverless trucks — which, though heavier, would mostly operate in a simpler, more controlled environment and would be exclusively owned and maintained by professional companies — would be allowed too.
Further reading:
This post is part of a series on the past, present, and future of commuting in America.
The technology that most profoundly changes US commuting might not be the self-driving car.
It could be the internet.
traffic engineers already see reduced congestion on fridays
Already, in many places, traffic engineers see notably reduced congestion on Fridays — a day when many offices let their workers telecommute from home. "I've spoken with people from the Maryland Department of Transportation, and they say there's no question," says Alan Pisarski, author of the Commuting in America report. "On Fridays, you really see a difference in traffic coming down from the suburbs to DC on I-270."
This shift is part of a broader trend: the steady fragmentation of what used to be a relatively uniform pattern of commuting. A few decades ago, the standard commute was for a full-time, 9-to-5 shift. People living in the suburbs mostly drove into the city in the morning and back in the evening.
But as more and more people work flexible hours, part-time jobs, or from home, the flood of commuters that used to fill highways during rush hour is becoming a stream that runs intermittently all day. Most suburban commuters, meanwhile, don't drive into the city — they drive to other suburbs.
Census data shows that the percentage of people who work from home every day is rising quickly, more than doubling since 1980. It's still only 4.33 percent of workers, but that's more than 5 million workers — and is more than the number of people who walk or bike to work combined:

About 45 percent of these workers are self-employed (with many working as freelancers or independent contractors), but a growing number of them are employed full-time in the private sector.
These employers aren't letting them stay home because they're suddenly feeling charitable, but rather because technology now allows them to easily ensure employees are actually working — and because doing so can save businesses a lot of money.
"The recession has also made companies more sensitive to operating costs," says Tim Lomax, a transportation researcher at Texas A&M. "If you can get someone to work from their home, where they don't need a parking space or an office, that reduces your cost of doing business."

(Mark Wilson/Getty Images)
What's more, the census only asks about your normal everyday commute, so its numbers don't include the many people who work from home occasionally, or those with other sorts of alternative schedules.
"More and more, people are working compressed schedules — say, with alternate Fridays off, or one or two days at home per week," Pisarski says. More people also work in fields that allow for varying schedules (like the health-care and service industries) than those that don't (like industry).
Meanwhile, the number of people working part-time has swelled since the start of the recession, rising by 2.1 million between 2005 and 2012. Increasing numbers of people, unable to find full-time work, are also combining multiple part-time jobs.
All these trends have broken up the old, predictable traffic patterns of yore. They're the reason for the reduced traffic on Maryland's I-270 (and many other highways around the country) on Fridays, and they mean that the twice-daily surge of commuters we used to see during rush hour is increasingly being spread out to other parts of the day:

(Commuting in America 2013)
Another dominant pattern being disrupted is geographic. "Our transportation system has basically been designed for radial service — getting people from the suburbs to the city center and back," says Pisarski. "But that's not what's going on now, and it'll be even less so in the future."
Though some people commute from suburb to city, most suburbanites actually commute to other suburb areas within the same metro area. A decent fraction of city dwellers, meanwhile, commute out to the suburbs for work.

(Commuting in America 2013)
This shift began as early as the 1980s. Though many early suburbs were initially designed primarily as residential areas, businesses have increasingly chosen to locate in them for a few different reasons, including lower real estate costs.
Additionally, the rise of households with multiple people working means that many families end up settling in compromise locations, halfway between a pair of distant jobs. This is why an increasing number of people (now about 27 percent of workers) cross county lines while commuting — and why several million people even end up commuting to other metro areas every day.

(Denver Post photo by Cyrus McCrimmon)
One final pattern being disrupted is the general uniformity of commuting across the country. It used to be that most US cities were pretty similar — in terms of the modes of transportation people chose, the geographical patterns of commuting that went on, rates of growth, and other variables.
But that's changing. "In some strong urban markets with particular lifestyles and cultures, or better transit — say, Boulder, Colorado, or San Francisco — we're seeing one set of trends," says Steve Polzin, a transportation researcher, "and in a place like Oklahoma City, we're not seeing them at all."

(Commuting in America 2013)
Polzin notes that between the 2000 and 2010 census counts, about a third of the counties nationwide had declining population, while another third grew explosively — accounting for 90 percent of the country's population growth.
For the planners trying to figure out the highways, transit, and other infrastructure projects we'll need in the future, this presents a big challenge. It means that even within the same region, one city might have a lack of jobs and lots of underused infrastructure, while another might have a shortage of infrastructure and plenty of jobs.
As Pisarski puts it, "It's harder and harder to talk about 'national trends' in commuting."
The Yahoo-owned analytics site Flurry has a lot of data on the types of mobile devices people are using to get online. And it shows a huge trend toward larger and larger smartphones:

Phones and computers used to be very different devices, and until recently everyone expected smartphones and tablets to be separate categories, as well. Steve Jobs used to say that no one would want to buy an enormous smartphone.
But he was wrong. In recent years, Android vendors started building larger and larger smartphones, and consumers bought them in droves. Then Apple's new, larger iPhone 6 and 6 Plus were huge hits. As this chart shows, the share of smartphones with screens larger than 5 inches grew from 3 percent in 2013 to 20 percent today. At the same time, smartphones smaller than 3.5 inches declined from 7 percent to 2 percent of the market.
It turns out lots of people want "phablets" that straddle the line between smartphones and tablets. It's just taken vendors a few years to realize it.
Most US carriers charge you if you want to check a bag, but not if you carry one on. As a result, people cram the overhead bins full of bags — a big reason it takes so long to board an airplane.
But the answer isn't letting people check as many bags as they want for free. Bag fees lower the base cost of tickets, giving people the option of packing lighter if they want to save money. They're also fair, given that fuel is a big part of the operating cost of airlines.
Instead, a better solution would be to charge passengers based on the weight of all the bags we carry aboard: our checked bags and our carry-ons.

(Chris Seward/Raleigh News & Observer/MCT via Getty Images)
Starting in 2008, largely in response to rising costs for fuel, most US airlines (excluding Southwest and JetBlue) began charging for checked bags. Perhaps in response to the backlash from passengers, however, most airlines still allowed people to bring carry-on bags for free (though Spirit Airlines charges for those, too). And for whatever reason, most will allow you to check bags right as you get on the plane for free, as well.
People respond to incentives, and this convoluted structure sets up some perverse ones. It means everyone has good reason to bring as many bags through security as possible, slowing down security lines. It's the reason there's a scramble for overhead-bin room during every relatively full flight. And it means that getting on and off the plane takes longer, because virtually every passenger is storing a bag in the overhead bins.
Engineers have devised a system for getting our bags into and out of the cargo holds of planes quickly, using codes, scanners, conveyor belts, vehicles, and people whose job is entirely focused on handling baggage. Yes, bags get lost sometimes. But the two-tiered charging structure means that instead of using this system, we're cramming a whole lot of luggage through a parallel system meant to put people on planes, causing all sorts of inefficiencies and delays.

(Robert Nickelsberg/Getty Images)
The underlying logic behind charging for checked bags, though, is sound. Though the cost of fuel has gone down in recent years, somewhere between 20 to 30 percent of the cost of your ticket still goes toward fuel costs. And the more weight you bring aboard, the more fuel gets burned during the flight.
Paying for that fuel makes sense — and not just for the ideal of fairness. It has real effects.
In recent years, airlines have cut down on weight as much as possible, eliminating drink carts for trays carried by flight attendants, for instance. "I’ve sat in on airline fuel committee monthly meetings to discuss how we could reduce the weight on each aircraft in a fleet by a single pound," Andrew Kemmetmueller, the CEO of a company that's worked to replace heavy pilot flight manuals with iPads, told the New York Times. "Just one pound makes a big difference when you're talking about a fleet of 700 aircraft."
passengers have no incentive to save on weight
Passengers, however, don't have to pay for the weight of their carry-on luggage — so they don't have the same incentive to pack less of it.
But when you bring a few extra pairs of shoes across the country and back so you can decide on your outfit at the last minute, or you lug extra books just in case you finish the one you're reading, you're marginally driving up fuel costs for everyone on the plane. When millions of passengers do this as a matter of routine, it burns more fuel and makes tickets more expensive.
The way to solve this is to decouple the cost of tickets from the cost of bags. If all your bags were weighed before each flight and you were charged accordingly, you'd have the option of flying cheaper by packing lighter, and the people who carry a ton of baggage have to pay the full cost of it.
WATCH: 'The better way to board an airplane'
When I first talked to my editor, Laura, about the Apple Watch a few weeks ago, she was skeptical. She's worn an old-fashioned watch for years and thought a computing device wouldn't look good on her wrist. And she didn't understand the point of having a computer strapped to her arm.
But she's changed her mind. On Friday, she told me she'd visited the Apple Store to try on a watch, and was persuaded to buy one. Her story illustrates a lot about how the gadget world is changing. Technology companies used to rely on tech-savvy early adopters to buy new gadgets that hadn't reached the mainstream. But gadgets like the Apple Watch have become so mainstream that early adopters just don't matter very much any more.
Laura's rationale for buying the watch was simple. She was already in the market for an iPod Nano and a Fitbit. She was specifically interested in this Fitibit case from Tory Burch that looks like a piece of jewelry. The iPod costs $150 and the Tory Burch case costs $175 (plus $100 for the Fitbit inside), so together they cost more than the $350 Apple Watch Sport. Plus she gets the functionality of both devices and a bunch of other features, too. She was particularly excited about the possibility of making phone calls with her wrist.
She also found the watch more attractive than she expected. She likes several of the bands Apple is offering, and she's expecting to see an even broader range of options once third parties get into the watch-band market. If Tory will make Fitbits, why not Apple Watch bands?
Laura gushed about personalized experience of buying the watch. "I loved making an appointment to see the watch," she told me. "I loved everything about it. It was a really great experience."
It's interesting that the factors that persuaded Laura to buy an Apple Watch have little to do with the questions technology pundits usually focus on. She doesn't care very much about the watch's technical specs or what apps will be available on it. She's not buying the watch because she's expecting smartwatches to become a new computing paradigm. She's buying it because it will look good on her wrist and and perform a handful of specific functions — playing music and tracking her exercise — that are useful to her.
The debate in tech punditry is whether smartwatches will become a big new computing platform the way PCs and smartphones did. But Laura's story suggests the Apple Watch could be a huge hit even if that doesn't happen. Even with zero third-party apps, the built-in capabilities of the Apple Watch would offer a compelling value proposition to millions of people.
Gadget makers used to rely on early adopters to buy first-generation products that weren't yet useful enough to appeal to mainstream users. But that is becoming less and less necessary. Computing hardware has become so cheap and powerful that new platforms like the Apple Watch can appeal to mainstream users from the outset. We saw this with the iPad, which seemed underwhelming to tech pundits like me but proved to be a huge hit with ordinary consumers who just wanted a simpler way to perform basic computing tasks like web browsing and watching videos.
The Apple Watch appears to be reaching the same kind of customers — people who care about whether a gadget is useful, of course, but don't care at all about being part of the next big thing.
When Floyd Mayweather and Manny Pacquiao fight this Saturday in Las Vegas at 11:30 pm ET, it'll be the biggest boxing match in decades.
After years of delays, backroom negotiations, and anticipation, the two biggest stars in boxing will face each other for the first time. In an era when boxing's prominence is fading, this is one of few matches in recent memory to pop up on the mainstream radar.
This means non-boxing fans might be hearing a lot about an idiosyncratic, oftentimes confusing sport. In boxing, after all, matches are negotiated by the athletes, to be broadcast for a huge fee, with a mysterious agglomeration of different championship titles at stake. These seven numbers will help you make sense of the fight — and the sport as a whole.

Manny Pacquiao celebrates are defeating Oscar De La Hoya in 2008. (JEWEL SAMAD/AFP/Getty Images)
This is how long it's been since Mayweather and Pacquiao were first tentatively scheduled to fight, in March 2010.
Back then, Mayweather was a dominant figure who'd recently defeated the legendary Oscar De La Hoya. He then retired, only to return to boxing with another resounding victory. Pacquiao was an undersized fighter who'd become a national hero in his native Philippines with a string of surprising upsets, including his own defeat of De La Hoya the year prior. The two boxers had become the sport's best-known figures, and their representatives reportedly came close to agreeing on the terms for a marquee fight.
there are no tournaments forcing top boxers to compete
But boxing isn't like other sports. There are no playoffs or tournaments forcing the best teams or players to compete. Instead, boxers negotiate all the terms of a fight, much like political candidates hashing out the mundane details of a televised debate. And negotiations for the 2010 fight fell apart over drug testing: Mayweather reportedly wanted blood drawn the day before the fight, and Pacquiao, who claimed to be afraid of needles, wanted only urine testing during the 30 days before the bout. Mayweather accused him of doping, and a defamation lawsuit ensued.
It took five more years — which included a pair of losses for Pacquiao — for the fight to finally happen. Now both boxers are in their late 30s, and many fans say they're well past their prime. Still, they're two of the best boxers in the world, and certainly the top two in their weight class (welterweight, which goes from 140 to 147 pounds).

Mayweather, holding lots of cash. (Ethan Miller/Getty Images)
This is the projected total earnings to be split between Mayweather and Pacquiao, easily an all-time record. It'll mostly come from pay-per-view revenues, ticket sales, and sponsorships.
Mayweather is reportedly guaranteed $120 million, while Pacquiao is only guaranteed $80 million. They'll both end up getting more than that (with the exact number based on pay-per-view sales), but regardless, Mayweather will take home most of it — and it doing so will remain the world's highest-paid athlete.
The difference is mostly due to the fact that Mayweather is the bigger draw (in boxing, this is called the "A-side"), as he typically brings in more money through pay-per-view. He's also undefeated throughout his career.
As a result, Pacquiao had more to gain by fighting Mayweather than vice versa, giving Mayweather more leverage during the negotiations. If the pair had fought back in 2010, the purse would have reportedly been split 50-50, but the two fighters are no longer on level ground. Mayweather is considered the favorite.

(Comcast)
This is the amount you'll need to pay to see this fight in HD on TV (it's $89.99 for standard definition). An estimated 3 million to 4 million homes are expected to pay to tune in.
Unlike most sports in the US, boxing's biggest matches aren't available on broadcast TV or even cable. Starting in the 1980s, fight organizers began selling TV rights to companies that sold the fights directly to subscribers for increasingly high prices.
"it hurts the sport because it narrows our audience"
In the short term, this arrangement makes sense for fighters, promoters, and TV networks (including HBO, which carries most of boxing's biggest fights today). They can make way more through pay-per-view than through selling the TV rights to networks that would broadcast the bouts for free, supported by commercials.
But in the long term, pay-per-view is cutting off new fans from boxing matches and is one of the biggest factors in the decline of the sport. Viewers can simply watch other sports for free — and they are.
"I can't tell you that pay-per-view helps the sport, because it doesn't. It hurts the sport because it narrows our audience, but it's a fact of life," then–HBO Sports president Ross Greenburg told Thomas Hauser for his 2008 book The Boxing Scene. "But if HBO stopped doing pay-per-view, the promoters would simply do it on their own."

MGM Grand Garden Arena, during a fight in March. (Alex Trautwig/Getty Images)
This is currently the average resale price for a ticket to the bout at the MGM Grand casino in Las Vegas — again, easily an all-time record.
Tickets originally went on sale for prices ranging from $1,500 to $10,000. But the resale market has been especially hot because very few tickets ever went on sale to the public. The venue seats nearly 17,000 people, but about 16,500 were directly given to sponsors, the fight promoters, casino high rollers, and the fighters themselves for friends and family. This left a tiny number of tickets for a large number of rich people who wanted to attend — and they sold out within 60 seconds.
The crazy prices, though, also reflect a huge amount of pent-up interest in this long-awaited fight. Tickets for the weigh-in — an event at which the two fighters are weighed, do some talking, and go back home — went for an average of $155.

Mayweather is led away to serve a three-month jail sentence in 2010. (David Becker/Getty Images)
It's impossible — and irresponsible — to talk about this fight without mentioning Mayweather's lengthy and appalling history of violence against women. He has been accused of assault seven different times, by five different women, as detailed in this harrowing piece by Louisa Thomas at Grantland.
Mayweather has pleaded guilty twice, serving brief jail sentences both times. In other instances, he's benefited from his accusers changing their stories before or during the trial, insisting that Mayweather was merely holding them back as they attacked him. In the most well-known instance, in 2010, Mayweather allegedly showed up at his ex-girlfriend's house at 5 am, punched her in the head, and tried to break her arm. When their 9- and 10-year-old children entered the room, he threatened to hit them if they left the house or called the police.
The fact is that Mayweather, the world's highest-paid athlete, has gotten relatively little punishment during his history as a serial abuser of women. Some are calling for people to boycott the fight over it, but this story still isn't getting nearly as much attention as it should be.

Mayweather and Pacquiao, with one of several belts on the line. (Ethan Miller/Getty Images)
This is the number of championships at stake in this fight: the welterweight titles as decided by the World Boxing Council, the World Boxing Organization, and the World Boxing Association.
The fact that three championship titles exist for the exact same weight class might be the most bizarre aspect of boxing. And there are actually more: in total, there are 111 belts for 17 weight classes, handed out by a mess of different organizations.
Over the years, these for-profit organizations (and many others) have proliferated, each creating their own rankings and championships. And as these groups gain credibility, fighters pay them fees to sanction fights.
over the years, sanctioning organizations have proliferated
To most boxing fans, this has ultimately rendered all of them meaningless (and, some say, has also helped kill the popularity of the sport). "Belts are a dime a dozen, meaningless straps churned out by meaningless sanctioning bodies in order to collect a portion of each paper champion's purse," Connor Ruebusch at SB Nation's Bad Left Hook writes.
But many fans pay more attention to a non-sanctioned idea: that of lineal championships, which can be earned only by beating the fighter who previously held the lineal championship. Because Mayweather beat "Sugar" Shane Mosley in 2010, he currently holds the lineal welterweight crown.
To Ruebusch, this crown gives this fight more importance than any number of belts. "The wearers of the crowns — there are eight currently in the sport — are the closest things boxing has left to true champions," he writes.

Mayweather hits Marcos Maidana during a May 2014 fight. (JOHN GURZINSKI/AFP/Getty Images)
This is how long the fight will probably last.
During each three-minute round, if one fighter knocks the other down and he can't get up before the referee counts to 10, the fight is over in a knockout. It can also end in a technical knockout (TKO), if the referee, doctor, or either fighter's corner calls the fight for safety reasons.
In all likelihood, though, it'll go the full 12 rounds, to be scored by a panel of three judges to determine the winner. The scoring system is extremely complicated, but in short, the judges will decide which boxer won each round, and the guy who won more rounds (according to the majority of the judges) is declared the victor. If all three judges split the rounds equally between both boxers, the fight is a draw.
WATCH: SB Nation's fight night preview show
Seven in 10 Americans are disengaged from their jobs, according to Gallup. That's more than two-thirds of us who are unfulfilled by our work, just dragging our sorry selves to and from the office every day.
One community has an attractive answer: just quit.
A burgeoning online community advocates early retirement. And they're not talking about people quitting in their 50s or early 60s. They mean retiring before age 40 — perhaps even in their 20s.
Over the past few months, I've interviewed seven people who have managed to leave the working world before age 40. That seems like a crazy idea to most people, but these extreme retirees insist it's something everyone should consider. What they all understand — and what they wish other people understood — is that achieving financial freedom isn't just about budgeting or clipping coupons; it's about reconsidering your core values.
The basic framework of early retirement is pretty simple: cut way down on your spending, then invest your savings. High savings rates can lead to surprisingly fast retirements. For example, if you save half your income, you'll be ready to retire in around 17 years.
And the best place to start on cutting costs isn't with coupons or thrift stores; it's with the big purchases. The lion's share of savings in early retirement come from what Jeremy Jacobson calls "the big three": housing, transportation, and food.
"While many of my coworkers were maybe leasing a new BMW SUV, I sold my car and started riding my bike. And when one of my coworkers was spending $50,000 remodeling his kitchen, we moved into a small apartment that was in a very walkable neighborhood," says Jacobson, who along with his wife, Winnie Tseng, blogs about the early retirement life at Go Curry Cracker. Likewise, he says, Tseng learned how to cook well enough that they started eating out far less.
The approach of cutting back on these three areas makes sense when you look at how American households spend their money. The average home in 2013 spent $51,100, according to the Labor Department, and together, shelter, transportation, and food accounted for nearly two-thirds of that. For most households, these are the places with the biggest opportunities for savings.
Once households have cut back on those huge expenses, the other part is making that saved money earn more money.
How do you know when you're ready to retire? Many of the retirees I spoke to rely on the "4 percent rule," a common rule of thumb that retirees can safely withdraw 4 percent of their savings each year without exhausting their principal. Jacobson and Tseng estimated they'd need $1.2 million saved up. The couple that blogs at Frugalwoods estimated they'd need $1.4 million. This gives each of those couples something like $50,000 to $60,000 to spend annually.
Mr. Money Mustache, the best-known early retirement blogger, has done the math and shown that assuming a 5 percent rate of return, if you save half your take-home income, you can retire in 17 years. If you save even 30 percent, it's 28 years — which might sound like a long time, but if you start at age 22, it means retiring at 50, far earlier than most people do. And this is far less than many extreme early retirees' savings rates. Several of the retirees I spoke with have managed to save 70 percent or more, allowing them to retire in less than 10 years.
Yes, those are all far more than your typical American's savings rate — currently at 5.8 percent of total income — but many Americans (particularly those with above-average incomes) could probably save a lot more than they think, as Vox's Tim Lee wrote earlier this year. The average home is 50 percent larger than it was 30 years ago, so many people could save a lot by downsizing. Transportation costs the average household more than $9,000 a year. Live somewhere near the right bus line or, even better, somewhere walkable, and you can slash that easily.
"If you think about it the person who’s cooking your lunch at a cafe or is serving your coffee ... somehow they’re living or getting by," says Justin McCurry, a 34-year-old former civil engineer who retired a year ago and blogs at Root of Good. "If you figure out how those folks are getting by and emulate that, but you're making middle-income or upper-income salaries, living one step down and saving that surplus left each month — I think that's how you have to do it if you’re in a higher-cost-of-living area."
It of course helps to have some investment savvy — some retirees I spoke with advocated picking a good index fund and avoiding big brokerage fees, for example. But really, aggressive saving is far more important than any investment wizardry, says one early retiree.
"Even if we put 100 percent of our savings into bonds, we still could have achieved it," says Paul Novell, 46, who retired from a career as an electrical engineer at 38 and lives with his wife, Nina Fussing, in an RV (currently they are in Bend, Oregon). Because you don't have a lot of years to work before you retire, he says, aiming for huge returns to create that nest egg is misguided — he considers investing far less important than cutting back on expenses.

How do you save 70 percent of your annual income? Dumpster diving helps. (Frugalwoods)
It's fairly easy to figure out how much you need to save to retire early. The trickier shift is making the lifestyle changes needed to save that kind of money.
It's a much bigger change than just cutting costs here and there. You need to stack a bunch of the savings choices on top of each other — moving to a cheaper neighborhood, cooking all your meals at home, biking to work, buying clothing only rarely, cutting out expensive coffees, not indulging your kids. And when you're done, you'll have a new lifestyle, one that's unorthodox in a consumerist society.
And as people living unconventional lives have done for decades, early retirees seek out kindred spirits online.
"Some of the closest friends we've made are online through the early retirement space because they're the most like-minded," says Mrs. Frugalwoods (the couple requested not to use their real names). "That's a real source of satisfaction and enjoyment for me, and I love being able to reach people and talk to them about the joys frugality can bring you."
Many extreme savers simply love cutting costs, self-sufficiency, and tinkering with a budget. The Frugalwoods couple fits this bill. They do a lot of services for themselves — a concept they call "radical insourcing."
"Earlier this year Mrs. Frugalwoods for the first time allowed me to cut her hair," says Mr. Frugalwoods. "A few YouTube videos and a bottle of wine, and we got it done." (His wife reports she was pleased with the results.)
Their YouTube-fueled self-sufficiency covers not just haircuts but bike repair and pet grooming. Not only that, but the couple rarely buys clothing, dumpster dives occasionally, and spends $0 on entertainment ("Paying for entertainment is like admitting defeat," they have written on their blog). They estimate that they spent around $13,700 last year on non-housing-related expenses. By contrast, the average US household spent more than double that: $34,000.
The majority of people who responded to my request for interviews (I sought out early retirees on Twitter and Reddit) are either current or retired engineers. There is, of course, some logic to this — engineers tend to have higher-than-average salaries — and there could be some self-selection at work in my sample, as well (maybe engineers simply hang out on Reddit a lot). But the retirees themselves believe something else is at work: the need to tweak and fiddle, taking pleasure in the improvements that come from making minor adjustments to their finances.
Novell and Fussing are going on hikes these days instead of going to the office. (Wheeling It)
"I was born as the stereotypical engineer kid, which means I was always interested in optimizing everything. Money was just one of those things," Pete, a.k.a. Mr. Money Mustache, told me earlier this year.
Mr. Frugalwoods, who works as a software engineer, uses his job as an example.
"A lot of what we're doing is all about having a long-term goal and spending our money around the pursuit of that goal and optimizing the crap out of everything else," says Mr. Frugalwoods. "At work I spend a lot of time trying to cut 100 milliseconds off of a webpage load, and that same kind of analytical optimizing mindset plays into this."
Perhaps the most important thing you need for early retirement is an ability to break out of conventional societal programming — the persistent notion that a person has to work for four or five decades and retire at 65 or later to live a productive, fulfilling, "normal" life.
Every single early retiree I spoke with stressed that more people could live like them, but many of us simply never consider the possibility of busting out of our normal ways of life.
"There are probably seven billion different right ways to live. Some people love what they do. Some people would be terrified of an unstructured environment. So there's not a right answer for everybody," says McCurry. "[But] you talk to people sometimes and you know they're not happy with what they're doing with their lives, but at the same time they're not open to the idea of something else."
Jacobson is a prime example of how a person's point of view can shift — in his first few years out of college, he worked hard at paying down student debt but also bought a new car and a house that came with a 40-minute commute. Deciding to try for financial independence meant breaking the keeping-up-with-the-joneses cycle of bigger houses and new cars he fell into by default in his early 20s.
What all of this this means is that early retirement isn't for everyone. While working less and enjoying life more might sound great to most people, it means giving up some things that might genuinely bring you joy — if fancy dinners out on the town and a large house truly bring you more joy than the idea of retiring early, then it makes a lot less sense to retire at 40.
Sometimes the shifts can go beyond even lifestyle changes. Starting a new financial lifestyle can open up an entirely new outlook on your own identity, as Mrs. Frugalwoods knows well.
She's one of the most visible women in the early retirement community — she does the majority of the blogging at Frugalwoods. The process of becoming mindful about her spending, she says, changed how she views her own femininity.
"It's really been a personal journey for me to not worry as much about what people think about me and really gaining confidence and really setting that societal concern and fear about appearance," she says.
She has stopped buying clothing — she says she hasn't bought a new article in 16 months — and no longer wears makeup. What resulted, she says, is a "fantastic transformation," as she has shrugged off the double standards society places on women: now she has a new perspective on what it means to be successful (and, more to the point, how little it has to do with appearance). In the process of being less focused on money, she became less focused on how she looks ... and more aware of who she is.
"Honestly it wasn't so much about being frugal as about being true to myself," she says. "I found ways to just be more confident and happy with what I have and have less of a focus on my appearance, and it has made me into a much more confident person. I'm a better writer [and] employee, and it's made me happier."
Maybe a lot more of us could retire well before 65. But there are certain factors that give certain people a big head start over the rest of us.
One is working in a high-paying industry — and early, says Novell.
"The good-paying job when you're young is critical. If not, the math just never works out," says Novell.
Likewise, having no student debt helps — Novell and Fussing, as well as the Frugalwoods couple, acknowledge that this eased their path to financial independence.
There's another, less obvious factor in many early retirees' success: a lifetime of privilege. The Frugalwoods couple is outspoken on this topic. In one February post, Mrs. Frugalwoods wrote about how having well-educated, middle-class parents set up her and her husband to get educated themselves, take good-paying jobs, and start on the path to early retirement in the first place.
Personal responsibility is a major theme in many financial independence blogs and forums — if people simply take control of their money and their lives, the thinking goes, they can much more easily have an early retirement than they realize. That may be true, she wrote, but she added that "the game is rigged" in their favor and against many others.
The most common term for what these people have done — leaving the working world and pursuing their own interests decades before the rest of us do — is "early retirement," but this phrase is itself the source of heated debate in the community. Plenty of others prefer the term "financial independence," as retirement implies a lifetime of relaxation and nonproductivity. In fact, many early "retirees" end up working again — just not taking traditional jobs they need to do for an income.
"Being freed from having to work to pay the bills, many [early retirees] plan to retire from professional life in the sense of no longer working in that career," as Jacob Lund Fisker writes at Early Retirement Extreme, one of the most popular early retirement blogs.
The goal of early retirement (or financial independence, if that's your phrase of choice) is to be able to have enough money to never have to work again. But that doesn't mean early retirees won't work if they feel like it. The Frugalwoods couple's plan to retire to a farm in Vermont and be as self-sufficient as possible. McCurry, meanwhile, says he might consult on friends' startups, in exchange for equity.
So while it's easy to ask if early retirement wouldn't be just a little boring, Fisker simply lists all the other things you could be doing than sitting in an office.
"[Early retirement] usually means taking up some other activity that is more meaningful to them [than work] but which would be hard to make a living from such as raising children, saving the world, rock climbing, making art, open source programming, writing, etc.," he writes. "It doesn't mean doing nothing."
You might not have noticed, but many of the websites you visit have a big security flaw. Anything you upload or download can be intercepted by anyone who's listening in on your internet connection. And in today's wireless world, that can be a lot of people: your nosy neighbor, the guy sitting next to you at the coffee shop, or a foreign intelligence agency.
Luckily, technologists have come up with a solution to this problem. In fact, they invented the solution in 1995. It's an encryption technology called SSL. Unfortunately, the people who run websites have been dragging their feet on using it.
In the early years, there were good reasons for this. Encryption requires extra computing power, and servers in the 1990s didn't have much to spare. So the technology was only used by sites that really needed it — primarily banks and e-commerce companies accepting credit card payments.
The lack of SSL will be treated as a security flaw
But today's servers are a lot faster. Google estimates that using SSL encryption only increases the load on its servers by about 1 percent. So a lack of computing power isn't a good excuse for not using SSL. A lot more websites use the technology today than did a decade ago. Yet there are still a lot of websites that don't use it.
This is why a new announcement from Mozilla is such a big deal. The nonprofit company behind the popular Firefox web browser has decided that the lack of SSL will be treated as a security flaw.
Mozilla is planning to back this determination up with some concrete actions — in the future, non-SSL websites won't have access to security-sensitive features such as your camera.
But the move is also significant from a rhetorical point of view. Until now, SSL has generally been seen as an optional feature — something that's nice to have but not essential if you're not running a bank or e-commerce site. Mozilla is hoping to change the conversation, describing sites that don't support SSL as defective.
This shift in terminology could help IT guys convince their bosses that this is an issue worth taking seriously. It's one thing to say, "Hey, boss, I'd like to spend the next couple of weeks adding a new feature to our site that will make it more secure." It's another thing to say, "Hey boss, major browsers think our site is broken. Can I take a couple of weeks to fix it?" The change in vocabulary could shift SSL from being seen as a nice-to-have to a must-have.
(Full disclosure: our boss at Vox Media agreed with our engineers about the need for SSL prior to the Mozilla decision, and we're working on a solution now.)
And there's good reason to think this will work. Google, the company behind the industry-leading Chrome browser, is a big SSL supporter. Google is considering taking a similar step with Chrome, and has already started downgrading non-SSL sites in search results.
Ultimately, this is good news for users everywhere. SSL doesn't just protect users from snooping, it also safeguards the integrity of websites, preventing intermediaries from hijacking pages for their own purposes. And with luck, we could soon live in a world where almost every website uses the technology.
Americans like to talk about themselves, so when we talk about Bitcoin we usually focus on ways the technology can make life better for American consumers. But an in-depth piece in the New York Times illustrates why the currency could have a brighter future overseas. Nathaniel Popper describes a day he spent hanging out with an Argentine Bitcoin trader:
That afternoon, a plump 48-year-old musician was one of several customers to drop by the rented room. A German customer had paid the musician in Bitcoin for some freelance compositions, and the musician needed to turn them into dollars. Castiglione joked about the corruption of Argentine politics as he peeled off five $100 bills, which he was trading for a little more than 1.5 Bitcoins, and gave them to his client. The musician did not hand over anything in return; before showing up, he had transferred the Bitcoins — in essence, digital tokens that exist only as entries in a digital ledger — from his Bitcoin address to Castiglione’s. Had the German client instead sent euros to a bank in Argentina, the musician would have been required to fill out a form to receive payment and, as a result of the country’s currency controls, sacrificed roughly 30 percent of his earnings to change his euros into pesos.
The United States has a pretty good financial system; the dollar generally holds its value from one year to the next, people are generally free to exchange their dollars for foreign currencies at market exchange rates, and we don't worry about governments or banks suddenly confiscating our wealth.
But some other countries have much worse financial systems. Argentina in particular has suffered from a series of financial crises that have made Argentines wary of the country's banking system. As the Times explains, the government has tried to fight inflation by enforcing an unrealistic exchange rate, which in practice operates as a huge tax on foreign transactions.
As a result, Bitcoin looks a lot more attractive to people in Argentina. The Argentine government can't impose its arbitrary rules on the Bitcoin network, which operates all over the world. And Bitcoin's volatility seems less alarming in a country where double-digit inflation is a common occurrence.
As Bitcoin takes root around the world, it will provide an effective floor on how terrible a country's financial system can get. In the past, when a country suffered from a bout of hyperinflation — as Argentina did in the 1980s — there wasn't much locals could do about it. Back then, it wasn't practical to use the American or German financial systems for everyday purchases in Argentina, and there was a limit to the number of dollars or Deutsche marks people could smuggle into the country.
Bitcoin will provide a floor on how terrible a country's financial system can get
But it's easy for Argentines to use the Bitcoin network — all you need is an internet connection. So if the Argentine financial system gets more dysfunctional, Bitcoin will become more popular.
And this is one reason Bitcoin is here to stay. Even if it never poses a serious threat to financial networks in rich countries, there will always be some countries around the world with dysfunctional financial systems. People in these countries will want unregulated ways to send money overseas, and they'll want ways to shelter their wealth from inflation and the kleptocratic tendencies of their governments. These users will generate demand for bitcoins for the foreseeable future.
In the 1980s, Gary Reback was an attorney representing Sun Microsystems, which was then a young startup making computer workstations. In a 2002 article for Forbes, Reback told the story of the time a group of IBM lawyers in blue suits visited Sun demanding patent licensing fees.
The IBM lawyers arrived with a list of seven patents they claimed Sun had infringed. Reback writes that his colleagues "took to the whiteboard with markers, methodically illustrating, dissecting, and demolishing IBM's claims." They patiently explained that most of the patents were probably invalid, and that Sun didn't infringe the others.
Reback tells what happened next:
An awkward silence ensued. The blue suits did not even confer among themselves. They just sat there, stonelike. Finally, the chief suit responded. "OK," he said, "maybe you don't infringe these seven patents. But we have 10,000 U.S. patents. Do you really want us to go back to Armonk [IBM headquarters in New York] and find seven patents you do infringe? Or do you want to make this easy and just pay us $20 million?"
After a modest bit of negotiation, Sun cut IBM a check, and the blue suits went to the next company on their hit list.
This story came to mind as I was thinking about the PATENT Act, a patent reform proposal that was unveiled by a bipartisan group of Senators on Wednesday. The PATENT Act is focused on dealing with patent trolls: fly-by-night companies that get rich by exploiting flaws in the way the courts handle patent lawsuits. If trolls are the primary problem with the patent system, then the PATENT Act will go a long way toward fixing it.
But trolls aren't the primary problem with the patent system. They're just the problem Congress is willing to fix. The primary problem with the patent system is, well, the patent system. The system makes it too easy to get broad, vague patents, and the litigation process is tilted too far toward plaintiffs. But because so many big companies make so much money off of this system, few in Congress are willing to consider broader reforms.
IBM's visit to Sun is ancient history, of course. But the problem of large companies exploiting the patent system hasn't gone away. If anything, it's gotten worse as the courts made it easier to get broad, vague patents in the 1990s and early 2000s.
A modern example is Microsoft, which has more than 40,000 patents and reportedly earns billions of dollars per year in patent licensing revenues from companies selling Android phones. That's not because Google was caught copying Microsoft's Windows Phone software (which has never been very popular with consumers). Rather, it's because low standards for patents — especially in software — have allowed Microsoft to amass a huge number of patents on routine characteristics of mobile operating systems. Microsoft's patent arsenal has become so huge that it's effectively impossible to create a mobile operating system without infringing some of them. And so Microsoft can demand that smaller, more innovative companies pay them off.
The patent system is acting as an innovation tax
The proliferation of software patents has triggered an arms race. Google, for example, spent $12.5 billion for Motorola, largely for access to its large patent portfolio. A consortium of technology companies including Microsoft and Apple spent another $4.5 billion on patents from the defunct technology company Nortel. Their vast patent libraries help protect them from each other — but they could also help them crush potential future competitors.
The billions of dollars technology companies are spending patents and patent lawyers are billions they can't spend hiring engineers to make their products better. In effect, the patent system is acting as an innovation tax, transferring wealth from companies that are creating successful technologies today to companies that acquired a lot of patents a decade ago.


Rep Bob Goodlatte (R-VA), the lead sponsor of the 2013 Innovation Act, dropped a proposal to nix low-quality patents after heavy lobbying by big software companies. ( Bill O'Leary/the Washington Post via Getty Images)

When people started thinking about the next round of patent reform in 2013, many of them wanted to craft legislation that did more than address the patent troll problem. For example, in a 2013 reform proposal, President Obama not only sought to curb abusive litigation tactics favored by trolls, but he also proposed to expand a patent office program for reviewing and getting rid of low-quality software patents.
Getting rid of the worst software patents would have helped to de-escalate the technology industry's wasteful patent arms race. And early versions of the Innovation Act, the patent reform bill that eventually passed the House of Representatives in 2013, included a version of Obama's proposal. But this language was dropped from the final bill after intense lobbying from big software companies like Microsoft and IBM.
The PATENT Act, which a bipartisan group of senators unveiled today, is even more careful to avoid provisions that would alarm patent holders that are not trolls. For example, two university presidents recently pointed out in a Wall Street Journal op-ed that some provisions of the Innovation Act could have negative impacts on universities who try to enforce their patents. So Senate negotiators modified those provisions to keep them narrowly focused on companies that behave in unsavory, troll-like ways, such as using shell companies and filing lawsuits that are not "objectively reasonable."
To some extent this is natural: negotiations in Congress often lead to compromise legislation that's less ambitious than early drafts. But what's striking here is how completely Congress has backed away from using concerns over trolls as a way to address larger problems with the patent system. The PATENT Act might keep the nation's most egregious patent trolls up at night. But no one else who owns patents — even broad, frivolous patents — is going to lose sleep.
And the legislation might not even stop trolls. The legislation focuses on particular tactics that are favored by trolls, like indiscriminately sending out vague, threatening letters to thousands of businesses. But none of these tactics is essential to the troll business model. What makes trolling possible is the existence of broad patents that many companies infringe by accident. The PATENT Act would do nothing to eliminate these patents, which means it may only produce a new breed of trolls that use different tactics to enforce the same bad patents.


Justice Clarence Thomas's 2014 opinion in Alice v. CLS Bank will probably prove more important to fixing the patent system than anything Congress does. (Chip Somodevilla/Getty Images)

Congress has been loath to make any changes that could harm the interests of large patent holders, but the Supreme Court has not been so careful. Over the last decade, the high court has handed down a series of opinions that have very slowly corrected the law's pro-patent tilt.
The most important decision might have been last year's Alice v. CLS Bank ruling, which addressed the patentability of software for the first time. Lower courts are still working out the exact implications of that decision, but the ruling led to the destruction of a dozen software patents within three months. It's likely to destroy hundreds more in the future.
And there's every reason to think the courts are just getting started. The pro-patent laws that produced today's patent litigation crisis were developed by the courts over a 25-year period, from about 1980 to 2005. Since 2005, the Supreme Court has been working to restore balance to the patent system, but it could take another decade or more for them to complete their work.
But relying on the courts alone won't be enough. For example, the Alice decision may have created legal grounds for invalidating thousands of low-quality software patents issued in the 1990s and 2000s. But the courts haven't provided an efficient process for actually getting rid of those patents. Only Congress can do that — and there's no sign that it's going to.
In last year's NFL draft, the Buffalo Bills traded up from the eighth pick to the fourth to take receiver Sammy Watkins. To do so, they gave up their first pick this year, 19th overall.
Watkins has had a solid start to his career. But the receiver the Bills could've taken if they'd stayed put — Odell Beckham Jr. — was named Offensive Rookie of the Year and already looks to be a generational talent.
teams should never trade up — and should trade down whenever they get an offer
It's always easy to pick apart draft decisions in retrospect. But this mistake was utterly predictable — and it remains a mistake whether Watkins ends up a better player than Beckham or not.
A series of papers by economists Cade Massey and Richard Thaler has shown that at any given position, historically, the odds of the top player picked (Watkins) being better than the third player picked (Beckham) is just 55 percent or so.
"It's basically a coin flip," Massey, who serves as a draft consultant with several NFL teams, told me last year, "but teams are paying a great deal for the right to call which side of the coin."
Because teams just aren't that good at evaluating a player's chance of success, Massey and Thaler's analysis says in the current trade market, teams are better off trading down whenever they get an offer — that is, trading one high pick for multiple lower ones, in order to diversify risk. But many teams, like the Bills, become overconfident in their evaluation of one particular player and do the opposite: they package several slightly lower picks for the right to take one player very early.

Watch: The history of the NFL draft, explained in 2 minutes
In their first paper, Massey and Thaler studied 1,078 draft pick trades made between 1990 and 2008. This let them determine the value teams got in return when they traded away each pick in the first five rounds of the draft:


(Massey and Thaler 2012)
The most important thing about this graph: the curve is very, very sharp in the first round. That means teams think the very top picks are extremely valuable: the value of the 10th pick is only about half that of the first pick.
Now, it's worth pointing out that for years, most teams followed something called "the Chart," which assigned values to each pick in the draft for trade purposes. Since 2008, many teams have smartly stopped treating the Chart as gospel, and the curve has become slightly less steep.
But Massey says it still hasn't flattened out to anything near where it should be, in terms of the actual value derived from the players picked. He and Thaler calculated this value based on the odds that the first player picked at any given position will perform better — in terms of the number of games he starts in his first five seasons — than the second player drafted at that position.
teams just aren't very good at figuring out who's the best player at any position
Lots of teams, like the Bills, will trade up when they identify a player they prefer at a needed position: they need a wide receiver, and a few highly rated ones are available, but they trade up because they're certain Sammy Watkins is the best. But the data says that teams just aren't very good at figuring out when this is true.
On average, the chance that first player will start more games than the second one picked at his position: 52 percent. Compared with the third player, it's still only 55 percent, and compared with the fourth, it's just 56 percent.
These numbers suggest that moving up eight picks (the average distance between the first and second players at the same position) should cost a small amount, since you're only increasing the odds of a getting a more productive player by 4 percent or so. But as the steep curve shows, teams pay a ton to move up, especially at the top of the draft.


Philip Rivers: just part of the valuable package the Giants gave up to take Eli Manning. (Christian Petersen/Getty Images)
Given that some teams, like the Bills, are irrationally willing to pay a lot to trade up, smart teams can reap huge benefits by trading down. Even staying put and drafting from your original spot, the researchers' analysis shows, isn't the best strategy.
For each pick in the first round, Massey and Thaler calculated all of the different two-pick packages a team could've gotten by trading down, based on the historical data (a team with the first pick, for instance, could get the second and 181st picks, or the 14th and 15th picks, or any combination of picks in between that provide the same sum value).
staying put and drafting at your original position is not the best strategy either
Then they calculated what teams have gotten out of these picks, on average, in terms of the number of starts a player picked at that spot has historically provided in his first five years, and the number of Pro Bowls he's voted to. (They included Pro Bowls to counter the criticism that their analysis ignores the unique impact of superstar players only available in the first few picks.)
Again, the data was unequivocal. On average, trading down and getting two players gave a team five more starts per season and slightly more total Pro Bowls.
You could chalk this up to the simple fact that more players start more games, but it's more than that. Even if you imagined that the team trading down could only keep the better one of the two players it drafted, it'd still get slightly more total starts and the same number of Pro Bowls. The truth is that teams are imperfect talent evaluators, so having two later picks is better than a single early one. It's just risk diversification at work.
The most straightforward piece of proof for all this is the fact that trading down correlates with more wins on the field.
Massey and Thaler came to this conclusion by looking at the number of wins a team had in any given season between 1997 and 2008, and the total value of all picks they'd made in the previous four years (the amount of time, on average, for which a rookie is under contract).
They found that one standard deviation in pick value translated to 1.5 more wins per season on the field. Sure, it's a small sample size, and there's a lot of chance and other factors built into the system, such as a coach's strategy. But trading down correlates with a significant amount of victories, given that there are only 16 games in a season.

Baltimore Ravens GM Ozzie Newsome knows how to draft. (Rob Tringali/SportsChrome/Getty Images)
If all teams took note of these findings and corrected their behavior, the principles would no longer apply. Teams would be much less interested in trading up, so the lucrative market for trading down would evaporate.
Why hasn't this happened? One answer is a widely known psychological bias called the overconfidence effect. As people are given more information, the accuracy of their analysis often hits a ceiling, but their confidence in it continues to increase.
This tendency has been demonstrated in all sorts of areas, from bettors picking horses to psychologists making diagnoses. It's not hard to imagine that NFL general managers — who are given scouting reports on players that cover everything from their body fat percentage to their home life — fall victim to the same sort of overconfidence.
"[teams] fall in love with players, get more and more confident in their analysis"
"In my experience, teams always say they're on board with [trading down] in January," Massey said. "Then when April rolls around, and they've been preparing for the draft for a long time, they fall in love with players, get more and more confident in their analysis, and fall back into the same patterns."
There's also the fact that the sports world as a whole tends to glamorize superstars — leading many to disproportionately attribute a 53-player roster's success to one or two highly drafted players. For a struggling GM, it might seem easier to trade up and land a guaranteed superstar than to patiently fill a roster with competent players.
The problem, though, is that there are no guaranteed superstars — and Thaler and Massey have found that, given a long enough time frame, no teams are any better at accurately evaluating prospects than others. Sure, a GM might hit a hot streak over the course of a few drafts, but long term they estimate that 95 to 100 percent of the difference in teams' odds of striking gold with any one pick is driven by chance.
So the key isn't drafting better — it's just drafting more.
As Massey noted, there are a few teams out there following his philosophy. In a recent interview, Eric DeCosta — assistant GM of the perennially successful Baltimore Ravens — dropped a hint about the identity of one of them:
We look at the draft as, in some respects, a luck-driven process. The more picks you have, the more chances you have to get a good player. When we look at teams that draft well, it’s not necessarily that they’re drafting better than anybody else. It seems to be that they have more picks. There’s definitely a correlation between the amount of picks and drafting good players.
Today, Facebook is one of the biggest and most famous sites on the internet. But that wasn't true 11 years ago, when a young Mark Zuckerberg made one of his first TV appearances to promote his new site, which was then just a few months old.

11 years ago today, someone named Mark Zuckerberg appeared on CNBC to discuss a social network that had 100K users. https://t.co/qP6y4qocfB


One of the surprising things about Zuckerberg's quote is that even he didn't seem to realize — or perhaps wasn't ready to admit — how big Facebook could get.
"When we first launched, we were hoping for 400 or 500 people," he said. "Now we're at 100,000 people. We're hoping to have many more universities by fall, hopefully over 100 or 200. From there, we're going to launch a bunch of side applications, which should keep people coming back to the site and maybe make something cool."
At this early stage in Facebook's development, Zuckerberg was entirely focused on the college market. He gave no hint that the site could eventually grow to more than a billion users, the vast majority of whom are not college students.
For years, the NFL's tax-exempt status has been the subject of scrutiny and ridicule. To many people, the fact that a league headed by a commissioner making $44 million a year was categorized as a nonprofit was absurd.
On Tuesday, Richard Rubin at Bloomberg reports,  the NFL has finally decided to shed its tax-exempt status. As a result, it will pay an estimated $10 million or so per year in taxes.
But it's important to put this number in the proper context: the league's teams pull in about $9.5 billion per year, which they pay taxes on. And since 2000, US taxpayers have spent an estimated $3.9 billion on stadiums for these teams. The central league offices basically work as a distribution system, taking in just enough TV money to cover salaries and giving the rest out to teams.
The NFL's decision to give up its tax-exempt status isn't some noble recognition of the tax burden it's unfairly been shirking. It's a calculated move to pay a relatively small fee to avoid scrutiny and preempt possible Congressional action.

Pete Rozelle cut a deal with Congress for perpetual tax exemption in 1966. (Nate Fine/NFL)
In 1942, the NFL — which was financially struggling, with many of its players off to fight in World War II — successfully filed for tax-exempt status from the IRS. The individual teams (which took in most of the income) still had to pay taxes. But the league itself, based in New York, became categorized as a trade association, which made it exempt.
As the league became more profitable, this categorization grew increasingly important. Though the vast majority of profits continued to go to the teams, a bit did go to the league itself, and its tax-exempt categorization saved it some money.
The tax status was important enough that in 1966, when the NFL was about to merge with the American Football League (which would become the AFC), then–Commissioner Pete Rozelle lobbied Congress to make sure it'd stay that way. In exchange for putting a team in New Orleans, he got support from a pair of Louisiana lawmakers to put language into an unrelated bill that explicitly categorized football leagues as tax-exempt. (The bill also granted the new league antitrust protection.)
As a result, here's how the section 501(c)6 of the tax code still reads today (bold emphasis is mine):
IRC 501(c)(6) provides for exemption of business leagues, chambers of commerce, real estate boards, boards of trade, and professional football leagues (whether or not administering a pension fund for football players), which are not organized for profit and no part of the net earnings of which inures to the benefit of any private shareholder or individual.

(Otto Greule Jr./Getty Images)
This was a good deal for the league and saved it millions in taxes over the years. But recently it's attracted a lot of scrutiny, especially as the NFL's image has suffered and people have become more aware of the billions of dollars municipalities have spent on stadiums.
In 2013, Oklahoma Senator Tom Coburn introduced a bill that would have stripped the NFL of its tax-exempt status. It didn't succeed, but it's been followed by similar efforts in the House. And other lawmakers have used the tax-exempt status as a point of leverage in investigating the NFL's mishandling of concussions, among other issues.
Apparently, NFL Commissioner Roger Goodell and team owners decided the tax-exempt status was no longer worth it. In a Tuesday letter to Congress, Goodell called the issue a "distraction" and said that in March, the 32 team owners had voted to shed the league's tax-exempt status.
This will cost them a bit of money: about $10 million or so per year. But at the same time, total revenues for all teams have risen to nearly $10 billion (because all but one of those teams are privately held, they don't have to publish their operating expenses and income). The teams pay a great deal in taxes, but the new taxes to be paid by the league offices are negligible.
In exchange, the NFL will get a few big benefits. For one, lawmakers can no longer hold the league's tax-exempt status over it during hearings about unrelated issues. And it preempts a possible future move by Congress to strip the league of this status, which would have looked much worse to the public.
But more important, filing as a taxable, privately held entity will mean that the NFL no longer has to disclose its income — or the oft-criticized salary of its commissioner, Goodell. As Andrew Brandt, an ESPN business analyst, told Bloomberg, "It seems like Congress has been making a big deal out of it. Without this status there’s no requirement to disclose, which helps in the PR battle."
Apple had a fantastic quarter, selling 61 million iPhones between January and March of this year. But one huge weak spot was the iPad. Not only were iPad sales for the most recent quarter lower than they had been a year earlier, but those sales, in turn, were lower than the sales in the first three months of the 2013 calendar year.
<!--
window.pym || document.write( '<scr' + 'ipt src="http://apps.voxmedia.com/tools/javascripts/vendor/pym-cb3d02c4.js"></scr' + 'ipt>' );
// -->
<!--
var Quarterly_iPad_Sales_in_millions = new pym.Parent( "Quarterly_iPad_Sales_in_millions", "http://apps.voxmedia.com/tools/charts-public/?labels=Q3%202010%2CQ4%202010%2CQ1%202011%2CQ2%202011%2CQ3%202011%2CQ4%202011%2CQ1%202012%2CQ2%202012%2CQ3%202012%2CQ4%202012%2CQ1%202013%2CQ2%202013%2CQ3%202013%2CQ4%202013%2CQ1%202014%2CQ2%202014%2CQ3%202014%2CQ4%202014%2CQ1%202015%2CQ2%202015&datasets=3.3%2C4.2%2C7.3%2C4.7%2C9.2%2C11.1%2C15.4%2C11.8%2C17%2C14%2C22.9%2C19.5%2C14.6%2C14.1%2C26%2C16.3%2C13.3%2C12.3%2C21.4%2C12.6&title=Quarterly%20iPad%20Sales%2C%20in%20millions&description=null&source=Apple&link=null&type=bar&legend=", { xdomain: ".*.voxmedia.com" } );
// -->
As you can see, the latest results are part of a broader trend. After four years of growth, iPad sales peaked in the 2013 holiday season (Apple's fiscal year starts in October, so the company calls this Q1 2014), and have been declining ever since.
Why is this happening? I suspect two factors are contributing to the iPad's decline. First, people who already have iPads just don't have that much reason to upgrade. People don't take their iPads around the house as much as they do their iPhones, so there's less risk of damaging them. And the iPad hasn't shown big leaps in performance in recent years, so people who already have an iPad see little reason to buy a new one.
The iPad may also be hurt by the trend toward larger iPhones. There's not a huge difference between the 5.5-inch display on an iPhone 6 Plus and the 7.9-inch display on an iPad Mini. So someone who in the past might have bought both an iPhone and an iPad might now be satisfied to just buy an iPhone.
When you visit your bank, you probably see a green lock icon in your browser that looks like this:

That icon means you're using Secure Sockets Layer (SSL), a technology that encrypts communications between users and websites. SSL has been around for 20 years, and it's been widely used for financial transactions since the 1990s. But back then, the technology was too slow to be practical to use on every website.
But as the technology has improved and computers have gotten faster, that's been changing. Sites like Facebook and Twitter began using SSL in the last few years, and media organizations like the New York Times are currently working to adopt it. Advocates hope that SSL will become ubiquitous in the next few years.
People usually think of SSL as a way to protect people's privacy. When you browse a website that's not protected by SSL over a wifi network, the information you upload and download can be intercepted by other people near you. SSL prevents this by scrambling the data before it's sent across the network.
A blog post from security researchers at Google points out another huge benefit of using SSL across the web: it helps fight cyberattacks. The post analyzes last month's attack against the programming site Github, which was hosting material that had been censored by the Chinese government. The attackers had inserted malicious software into webpages from the Chinese search engine Baidu. This software caused Baidu users' computers to begin flooding Github with traffic, temporarily knocking the site offline.
As far as we can tell, Baidu wasn't responsible for these attacks. Rather, the attackers — widely believed to be connected to the Chinese government, though there's no proof of this so far — appear to have carried out this attack by modifying Baidu pages as they traveled across the Chinese internet.
This kind of attack is a lot more difficult to carry out against a site that uses SSL. Webpages protected with SSL aren't just hard to intercept, they're also hard to modify, which means users won't be exposed to the risks of third parties tampering with the websites they visit.
Google has started to apply significant pressure on website owners to upgrade to SSL. Last year, the company announced it would start penalizing websites that don't adopt it by docking their search results. The penalty is small for now, but Google says it may increase it in the coming years. That creates an added incentive for webmasters to get on board, improving security for both their users and the web as a whole.
There's a growing problem with patent trolls, the companies that create no products of their own but earn money threatening other companies with patent lawsuits. The problem has become so widespread that even low-tech companies like restaurants and grocery stores have begun lobbying Congress to do something about it.
Now Congress could be on the verge of taking action. On Friday, a Senate aide close to the negotiations told me that a bipartisan group of senators is "very close" to introducing legislation with broad support in the Senate.
Supporters of the legislation have good reason to be optimistic, as the coalition supporting the legislation is broader and more unified than in the past. But given Congress's penchant for gridlock, it's far from a sure thing.
Patent trolls take advantage of the fact that patent litigation is so expensive that it's often rational for defendants to pay even if they haven't done anything wrong. Patent reform legislation is expected to change how patent litigation works in ways that make the tactics used by trolls less profitable.
One example is known as fee-shifting. By making trolls pay when they lose a patent lawsuit, this change would discourage frivolous lawsuits.
Patent trolls take advantage of the fact that patent litigation is so expensive
Another proposal would delay discovery — the expensive process in which each side must produce documents relevant to the lawsuit — until later in the process. This will give defendants a chance to get a lawsuit thrown out before racking up huge legal bills.
A third reform would require patent holders to be specific about how a patent is being infringed — both when they send threatening letters to potential targets and when they file lawsuits.
Finally, trolls sometimes use a divide-and-conquer strategy in which they target users of a product — who often lack the resources to fight back — rather than its manufacturer. Patent reform legislation may give manufacturers the option to step into their customers' shoes and fight a lawsuit on customers' behalf.


Sen. John Cornyn (R-TX), left, and Sen. Patrick Leahy (D-VT) are influential advocates of patent reform legislation. (Bill Clark/CQ Roll Call)

In the polarized environment of Washington, it's rare to find an issue that can unite Republicans and Democrats. But patent law — a complex and technical subject that has never been seen as a subject for partisan politics — is one issue on which bipartisan consensus seems within reach.
That potential for bipartisan consensus was visible in 2013. The House of Representatives passed the Innovation Act, written by Rep. Bob Goodlatte (R-VA), the chairman of the House Judiciary Committee, in December 2013. It received the support of 130 Democrats as well as 195 Republicans.
But then Senate Majority Leader Harry Reid (D-NV), an ally of trial lawyers who opposed the legislation, blocked it. They were concerned with "fee-shifting" rules that would make it easier for a winning defendant to recover legal costs from a troll. Trial lawyers are concerned that including this language in a patent reform bill could set a precedent for applying similar rules to other types of litigation.
Reform advocates are trying again this year. Substantively, the new legislation is expected to be similar to the legislation the House passed in 2013. But this year, the legislation may have a better chance of getting through the Senate.
Thanks to the 2014 election, Reid is no longer the majority leader, and his successor, Kentucky Republican Mitch McConnell, has no love for trial lawyers. Patent reformers also have a powerful ally in Sen. Chuck Schumer (D-NY), who will take over for Reid as Democratic leader in 2017 and has been pushing for strong patent legislation. Schumer has been working with his fellow Democrat, Patrick Leahy (VT), and two senior Republicans — Majority Whip John Cornyn (TX) and Judiciary Committee Chairman Chuck Grassley (IA) on the Senate bill.
Schumer and Leahy supported the inclusion of some kind of fee-shifting language in the patent bill last year, and are expected to do so again this year. That leaves ample room for a compromise that should please most Republicans and many Democrats. And with Reid no longer in control of the Senate calendar, it will be harder for trial lawyers to scuttle a bill this year.


Microsoft lobbied against a proposal to eliminate low-quality software patents in 2013. Now that idea has been shelved, and Microsoft is expected to support patent reform legislation. (Joe Raedle/Getty Images)

In 2013, the patent reform debate was divided into three camps. On one side were pharmaceutical companies, patent lawyers, and other defenders of the status quo. They opposed the whole patent reform effort. On the other side was a coalition of technology companies — led by Google — and brick-and-mortar businesses that were lobbying for reform. Standing in the middle was a group of large software companies, most notably Microsoft.
Reformers are anxious to avoid reopening an old wound
Large, patent-rich software companies like Microsoft and IBM didn't object to going after patent trolls, but they lobbied against measures to nix low-quality software patents. Technology companies with fewer patents — and other industries frequently targeted by patent trolls —  lobbied for it. Ultimately, Microsoft and IBM won; the proposal was ultimately left out of the patent legislation that passed the House.
This year, reformers are anxious to avoid reopening this old wound. So they're planning to focus on procedural changes designed to hobble patent trolls, and leave out efforts to weed out bad patents.
Earlier this year, patent reformers launched a new umbrella group called United for Patent Reform that brings together a broad coalition of patent reform supporters. The members range from Facebook and Oracle to General Motors and even the Culver's fast-food chain.
And while language to eliminate low-quality patents won't be part of this year's patent reform bill, supporters have gotten an important consolation prize: a 2014 Supreme Court ruling has called into question the legality of the most dubious software patents. So the standards for patent quality are going up without Congress lifting a finger.


With Republicans in control of the Senate, Sen. Harry Ried (D-NV) won't be able to block patent reform legislation as he reportedly did last year. (Win McNamee/Getty Images)

While patent reform has broad support, there are also some powerful interest groups on the other side. Two longtime opponents of patent reform are the pharmaceutical industry and patent attorneys. Both groups have prospered from current laws, and have little interest seeing the playing field tilted more toward defendants.
A more surprising source of opposition to patent reform is universities. Since the 1980s, universities have developed "technology transfer" offices that patent inventions by university researchers and then demand that companies in the private sector pay licensing fees. In a piece for the Wall Street Journal earlier this month, two university presidents warned that patent reform legislation could "change the U.S. patent system in ways that would diminish the benefits of university research." My reporting suggests that university groups are actively lobbying against legislation like the bill the House passed in 2013.
In 2013, the House of Representatives passed a patent reform bill before the Senate even had time to start working on one. This year, advocates plan to take a different approach, pushing the House and Senate versions of the legislation through in parallel. That will reduce the chances of the House putting a lot of time into legislation that never gets a serious hearing in the Senate.
Last week, disagreement flared up over a House proposal to regulate demand letters
On paper, patent reform has an excellent chance of passing in 2015. The lopsided vote for the 2013 legislation suggests broad bipartisan support in the House. And in the Senate, legislation is supported by some of the most powerful legislators on both sides of the aisle.
But a lot could go wrong. Last week, disagreement flared up over a House proposal to regulate the vague demand letters trolls send to businesses in search of a quick payoff. Many patent reform groups opposed the bill, arguing that it falls far short of what's needed. Patent reform advocates will need to iron out this kind of disagreement in order to shepherd a bill through Congress.
The legislation could also be derailed due to outside forces. Last week, for example, Senate business ground to a halt due to a disagreement over abortion funding within a popular bill to combat human trafficking. While this fight was going on, other priorities — like patent reform — were put on hold.
The human trafficking dispute has been resolved, so patent reform may be able to move forward. But there remain a lot of tricky issue to be resolved, and even if patent reformers do everything right, the legislation may or may not make it through the legislative process before the clock runs out.
The first Apple Watches have begun shipping, and the folks at the gadget repair site iFixIt got their hands on one. So of course they immediately tore it apart, permanently damaging the device in the process.
The teardown gave us the first glimpse at the hardware that makes the Apple Watch tick. The largest component in the Apple Watch is the battery, which iFixIt found will be fairly easy to replace. But that's not true of other Apple Watch components.
The S1 computing chip that powers the Watch is permanently soldered in place, which could make it difficult for Apple to offer upgrades to early adopters of the more expensive Apple Watch models.
Here's what the internals of the Apple Watch look like once you lay them all out side by side:

Comcast has abandoned its $45 billion bid for Time Warner Cable, a deal that would have made the nation's largest cable giant even bigger. "Today, we move on," Comcast chair and CEO Brian L. Roberts said in a short statement. "Of course, we would have liked to bring our great products to new cities, but we structured this deal so that if the government didn't agree, we could walk away."
The failure of the deal represents a major blow to the firm, which has lobbied hard for the last year to get the deal approved by federal regulators.
A central issue in the debate over the merger is whether Comcast poses a threat to the growth of new, internet-based video services that compete with Comcast's old-fashioned cable television service. Critics have pointed out that Comcast has a history of making business decisions that hobble streaming services like Netflix.
According to media reports, regulators at the Department of Justice and the Federal Communications Commission found these arguments persuasive enough that they were planning to try to stop the deal. The failure of the deal is the latest sign of a more hostile regulatory climate for large telecommunications mergers.
Comcast and Time Warner Cable are the largest and second-largest cable companies, respectively, in the United States. Comcast has more than 20 million subscribers in both the television and internet markets. Time Warner Cable had more than 10 million of each. Combining them would have produced by far the largest cable company in the world.
Comcast's 2009 proposal to acquire NBC sailed through the regulatory process
Comcast's argument for approving the deal was simple: because Comcast and Time Warner Cable operate in different markets, the transaction would not reduce customers' options for cable or internet service. Therefore, the cable giants said, the deal couldn't reduce competition or harm consumers.
Comcast also promised an array of goodies for the public if the merger was approved. Comcast runs a program called Internet Essentials that provides low-cost internet access to 1.8 million low-income Americans; Comcast promised to expand the program to low-income customers in Time Warner's areas of service. Comcast also promised to increase programming diversity, such as the addition of four new minority-owned networks to the Comcast channel lineup.
This was a game plan that had worked for Comcast before. Comcast's 2009 proposal to acquire NBC sailed through the regulatory process after the company sweetened the pot with a number of concessions that won the support of influential interest groups.
While it's true that Comcast and Time Warner Cable don't compete with each other in the consumer market, critics pointed out that this wasn't the only market in which these cable giants operate. Comcast and Time Warner Cable have to buy content from major content providers, and they negotiate interconnection agreements with other internet companies.
And in these kinds of negotiations, size matters. Content companies like Disney and Viacom can play one cable company off another, but the larger a cable provider is, the harder this is. As the largest cable company and the owner of NBC Universal, Comcast already has a lot of power in the market for paid video content. Adding Time Warner's 10 million subscribers would give Comcast even more power.
The same point applies online, as we saw in last year's dispute between Comcast and Netflix. Comcast refused to upgrade connections that carry Netflix video content, leading to declining streaming quality. As a result, Netflix was forced to pay a toll for access to Comcast's customers. Only a company with a large number of cable subscribers would be able to take this kind of hard line.
Even if regulators have concerns about a deal, that won't necessarily lead to it being blocked. Often, officials can attach conditions to a merger to prevent particular competitive harms while allowing the overall deal to go forward. That's exactly what the feds did during Comcast's merger with NBC Universal, which was approved in 2011.
But critics say this approach didn't work very well. For example, that merger gave Comcast a stake in the internet streaming service Hulu. Regulators worried that Comcast might view Hulu's online streaming service as a competitive threat to its own cable TV service. So as a condition of that merger, federal regulators made Comcast promise not to influence how Hulu was managed.
The regulatory climate has become increasingly hostile toward big telecommunications mergers
Yet the Wall Street Journal reports that in 2013, Comcast helped persuade Disney and Fox not to sell their video service, Hulu, to a Comcast rival — DirecTV and AT&T were both considered potential buyers, according to the Journal. Comcast reportedly promised Disney and Fox that it would help make Hulu "the nationwide streaming video platform for the cable TV industry." That promise helped persuade Disney and Fox that the service could succeed as an independent operation.
"Whether Comcast technically violated the condition or not, the story illustrates both the power of Comcast already and the inability of conditions to adequately address that power," wrote merger critic Harold Feld in a Thursday blog post. According to the Wall Street Journal, "Hulu’s aborted sale process is among the issues that have captured the interest" of government regulators considering Comcast's latest merger.
For more than a decade, federal regulators routinely approved mergers that made the nation's telecommunications companies larger and larger. The eight companies created by the 1984 breakup of AT&T have consolidated into three large companies — AT&T, Verizon, and CenturyLink. Comcast and Time Warner are themselves the product of a series of cable mergers during the 2000s, and as we've already mentioned, regulators waved through Comcast's acquisition of NBC Universal in 2011.
But since then, the regulatory climate has become increasingly hostile toward big telecommunications mergers. In 2011, AT&T Mobility, the nation's second-largest wireless provider abandoned its effort to acquire T-Mobile, the fourth largest, after it encountered opposition from regulators.
Meanwhile, cable companies in general and Comcast and Time Warner Cable in particular have become less popular. Last year Comcast and Time Warner Cable were ranked the two least popular broadband and TV providers in a consumer survey. One reason might be the many media stories about Comcast's terrible customer service.
Growing public hostility toward Comcast probably contributed to the grassroots lobbying campaign for stronger network neutrality regulations, which the FCC approved in February. And those same political forces have made it easier for officials at the FCC and the Justice Department to take a hard line in their review of Comcast's merger.
Those same political headwinds will likely make it more difficult for other mergers to get approval. Charter's proposal to acquire another cable company, Bright House Networks, was contingent on approval of the Comcast deal, so that deal will fall apart if Comcast throws in the towel. And other big telecom companies thinking about merging will think twice given the growing skepticism of federal regulators.
Graduating high school seniors in Oklahoma last year had to meet the strictest financial literacy education requirements in the country. They had to demonstrate their understanding in 14 different areas of personal finance — everything from household budgeting and basic investing to the consequences of gambling and bankruptcy.
It's an ambitious set of standards that many adults couldn't meet. But it might not work.
Oklahoma is ahead of the curve in a post-recession national craze for financial literacy education. The Consumer Financial Protection Bureau would like to see similar graduation requirements in all 50 states. On an international test of personal finance skills last year, students in the US fared worse than their peers in Poland, Australia, or Shanghai, and scored about average for students in developed countries.

Oklahoma's 14 financial literacy standards.
Meanwhile, colleges, not satisfied with high school efforts, are starting financial literacy requirements of their own. And as student debt skyrockets, regulation-averse groups and members of Congress have suggested better consumer education is the solution, or at least part of it.
People who know more about money are more likely to be saving for retirement, more likely to have an emergency fund, and less likely to make only the minimum payment or miss payments on their credit cards.
But does knowing more about money simply accompany having more of it in the first place? Is it really possible to teach someone to be rich?

Understanding the use of a checking and savings account is one area where many high school seniors fall short. Barry Chin/The Boston Globe via Getty Images

Three basic questions are often used to test financial knowledge:
Just 27 percent of young adults in a nationally representative study, the National Longitudinal Survey of Youth, answered all three questions correctly. (If you're  part of the 73 percent, the answers are "more than $102," "less than today," and "false.") Even when controlling for other factors, men were more likely to respond correctly than women, and attending college or even just graduating from high school also made correct answers more likely.
A biannual survey of high school seniors from the Jump$tart Coalition for Personal Financial Literacy found they knew less about personal finance in 2008 than in any year since at least 1997. But even in 1997, the results weren't particularly strong: The average score on the test, which asked them about taxation, salaries, credit card interest, and other concepts, was never a passing grade.

If students don't remember linear equations 10 years after high school, they might not remember personal finance courses either. Universal Images Group via Getty Images
Just 17 states require personal finance courses for students, and only six test students on what they've learned. But those classes don't seem to make much difference anyway: students who took a semester-long class in personal finance fared below average on the Jump$tart survey.
There is no evidence that the classes actually made students worse at managing money, the group wrote in its report. But it certainly didn't make them any better.
Academic research backs up that conclusion. A 2008 study from two Harvard Business School professors studied the relationship between education and saving and investing behavior. They found state-required financial literacy education had no effect on graduates' saving behavior later in life.
The money spent on financial literacy education, they concluded, produced little in return.
Other research has come to the same conclusion — sometimes to the evident frustration of the economists conducting it. "What evidence is there that financial education actually increases financial literacy?" three researchers wrote for the National Bureau of Economic Research in 2012. "The evidence is more limited and not as encouraging as one might expect."
The latest idea: give people information about financial literacy when they need it, rather than decades in advance. Offer loan counseling when they're taking out loans, or advice on planning for retirement when they're enrolling in a 401(k) plan.
That's the advice offered by a broad analysis 168 studies of the effects of financial education. But that approach comes with problems of its own, including the difficulty of getting unbiased information in front of people who are shopping for financial products.

Teaching financial literacy might be more like teaching nutrition. Brendan Smialowski/AFP via Getty Images
The biggest question, though, might be what financial literacy is supposed to accomplish in the first place.
It's easier to get people to take one action — get a vaccine, open a savings account — than it is to get them to change their behavior for years or decades. And even successful public health campaigns change behavior for 5 percent to 10 percent of people at best, the Brookings Institution pointed out in its own report on financial literacy education.
Perhaps that's why a growing number of colleges are setting up financial education programs not through academic advisors or financial aid officers, but at campus health centers.
Ohio State University, for one, now offers "financial coaching" alongside nutrition coaching at its student wellness center. It's an acknowledgment that teaching money habits to college students is something like teaching good eating and exercising habits: much easier in theory than in practice, and not something that can happen in a traditional classroom.
Comcast intends to abandon its plan to acquire Time Warner Cable after it was met with skepticism from regulators, according to Bloomberg. The firms are the largest and second-largest cable companies in the United States, respectively; the merged firm would have been vastly larger than its rivals, with about 30 million subscribers.
The failure of the merger would be good news for consumers, as the combined company would have an outsize and likely detrimental impact on competition in both the internet and video markets.
At first blush, it might seem like the transaction shouldn't have much effect on consumers. The service areas of traditional cable companies don't overlap, so combining Comcast and Time Warner Cable won't reduce the number of options customers have for cable or internet service.
But cable companies don't only operate in the consumer market. They also negotiate with network owners and content providers on the "back end" of their networks. And here, size has a huge — and problematic — impact on the competitiveness of the market.
A good example of this is Comcast's dispute last year with Netflix. Netflix says Comcast strong-armed it into paying unfair tolls to deliver content to Comcast's own customers. Comcast says it was just an ordinary commercial dispute.
The dispute put the FCC in an awkward position, because it's hard to draw a clear line between legitimate business practices and monopolistic ones. The FCC probably doesn't want to get bogged down with policing the terms of each of the hundreds of peering agreements made between cable companies and ISPs. Yet Netflix, as well as ISPs such as Level 3 and Cogent, have raised some legitimate concerns about Comcast's business practices; ignoring them entirely isn't a good option, either.
THE MERGER would MAKE COMCAST EVEN BIGGER, GIVING IT EVEN MORE LEVERAGE IN NEGOTIATIONS WITH NETFLIX AND OTHERS
This is a problem created by Comcast's vast size. Small ISPs don't have the leverage to make the kinds of demands Comcast (and Verizon, another massive ISP) have made of companies such as Netflix. In a more decentralized broadband market, the FCC could leave these kinds of peering negotiations to the free market. But as the broadband market gets more concentrated, the danger of broadband companies abusing their power becomes correspondingly larger. The Federal Communications Commission recognized this dynamic earlier this year when it made interconnection part of its new network neutrality regulations.
The merger would have made Comcast even bigger, giving it even more leverage in negotiations with Netflix and others. That would increase the need for regulatory oversight to ensure Comcast doesn't abuse its market power.
And the same point applies to the cable television market. Comcast negotiates with big content companies like Fox and Disney for access to their content. Right now, some of these media conglomerates have a pretty strong bargaining position. That allows market forces to keep cable companies in check.
Adding Time Warner Cable's heft to Comcast's would have produced a cable behemoth whose business practices would require closer watch from regulators. It's hard to predict exactly what kinds of problems might crop up from such a combination. But allowing one of America's least competitive industries to become even more concentrated would likely have made things worse, not better.
When Google announced a new cellphone service called Project Fi on Wednesday, I was pretty excited. The service aims to reduce the cost of wireless connectivity by helping customers rely more heavily on cheap wifi networks rather than expensive cellular ones.
But reading and thinking more about the service has tempered my enthusiasm somewhat. I still think these services will exert some pressure on incumbent wireless cellphone carriers to cut prices. But so long as Google is reselling those companies' services, there's a limit to how much savings it can offer.
The big question is how much Google can help customers shift off of cellular networks in favor of free wifi networks. The experience of Republic Wireless, a startup that pioneered Google's wifi-first model, suggests that it's not as easy as it looks.
Ars Technica's Ron Amadeo compiled this chart showing how the service stacks up against competitors:


(Ars Technica)

Amadeo notes that this chart has some caveats, as different carriers' plans aren't perfectly comparable. But there are two broad trends evident from it.
First, Project Fi will be most appealing to customers at the low end of the market. If you want a bare-bones plan that uses less than 1 GB of data from cellular networks, Project Fi is a more affordable option than any of the alternatives you see here.
On the other hand, for customers who need large amounts of cellular data Google's offering isn't a particularly good deal. Other providers offer cheaper packages at the 3 GB and 5 GB levels.
And if you know how Project Fi works, this makes perfect sense. Google doesn't own its own cellphone towers; instead, it's reselling capacity provided by Sprint and T-Mobile. The people running those companies aren't stupid, so they're not going to sell Google capacity at a price low enough for Google to undercut their own offerings.


Wifi routers are cheap and easy to set up. (Squallwc)

Google can't offer customers lower rates for cellular data, but it might still be able to save its customers money by helping them shift more of their traffic from expensive cellular networks to affordable wifi ones.
Wifi networks are more affordable than cellular ones for two reasons. First, setting up a cellular tower is a complex and expensive undertaking, while installing wifi equipment is so simple and cheap that most of us have one in our homes. Second, cellular companies have paid billions of dollars to the federal government for exclusive wireless frequencies, while wifi uses freely available shared spectrum.
If Google can help customers use wifi more and cellular service less, it can save customers money. There are two basic ways Project Fi tries to do this. One is to make it easier for people to use the wifi networks they already have. Virtually all modern smartphones have built-in wifi chips, but switching from wifi to cellular networks — or vice versa — can be a hassle.
Following in the footsteps of a startup called Republic Wireless, Google Fi offers a phone service that can automatically switch between wifi and cellular networks without dropping calls. That allows users to make calls from their home wifi connection without worrying about losing the call if they go out of range.
The second way Google helps people use wifi more is by helping users find other wifi networks to log into. Google has a "network quality database" to help it identify wifi access points that are freely available. And it uses a privacy technology called VPN to prevent the owners of these networks from eavesdropping on a customer's communications.
While Google hasn't announced any plans in this direction, it would make sense for it to take steps to expand the number of available wifi connections. Google will have detailed data about where its customers consume the most cellular data. It could pay households and businesses in these high-demand areas to provide wifi service to Project Fi customers, reducing those customers' dependence on expensive cellular service.
The technology behind Project Fi could also work in concert with cable companies like Comcast that have enabled public wifi hotspots in their customers' homes. Right now, these networks are hard to find and not always easy to join. But Google could work with Comcast to make sure the process is automatic, while paying Comcast for the bandwidth used.


(Don Emmert/AFP/Getty Images)

While it hasn't gotten as much attention as Google's announcement, news this week from Republic Wireless suggests that it may be difficult to use wifi to dramatically reduce cellular data use.
Republic's original business model in 2012 was to couple wifi-first technology with unlimited cellular data service for shockingly low prices — starting at $19 per month. Republic hoped that customers would offload so much of their traffic to wifi networks that it could make a profit.
Evidently, that plan didn't work out, and over time the company has raised its prices. Today, you can get unlimited data over slow 3G networks for $25 per month or unlimited 4G data for $40 per month. That's still a pretty good deal, but not nearly as good as the original pricing scheme.
This week, the day before Google unveiled its wireless service, Republic announced yet another change to its pricing structure. While Republic didn't announce specific prices, it signaled that it would be shifting to the same model Google is using — a flat rate for   unlimited talk and text, plus metered pricing for data.
This suggests that after three years of trying, Republic couldn't figure out a way to use wifi offloading to radically reduce customers' cellular data use. If they had, then that original pricing model should have worked.
Of course, Google has some advantages Republic doesn't, including a strong brand name, a ton of capital, and a vast database of open wifi connections. It may figure out ways to improve on Republic's approach.
But the wifi-first model will likely always still depend on cellular networks for backup. And those networks cost billions of dollars to build and maintain. So while Project Fi will probably help cellular customers save some money, people are going to continue spending significant sums for cellular service for the foreseeable future.
Disclosure: My brother is an executive at Google.
Coke fans called it "Black Tuesday."
On April 23, 1985 — 30 years ago today — the carbonated disaster called New Coke made its debut. Coca-Cola's idea was to make Coke appeal to a younger generation by replacing its signature soda with a sweeter version. It quickly became a national disgrace.
The experiment only lasted a few months before Coke reversed course — on July 10, 1985, it announced it would bring back "Coca-Cola Classic," selling it alongside New Coke. But even though New Coke has gone down as one of the most infamous mistakes in marketing history, most people don't know the real reasons it failed.
New Coke didn't only fail because it tasted too sweet — it failed because the marketing campaigns, business structures, and company culture at Coke doomed it from the beginning.

In 1985, one consumer showed her love of old Coke and distaste for the new formula. (Toronto Star/Getty Images)
The problems with New Coke did have a lot to do with taste — because Coca-Cola didn't know how to measure what the ideal taste was.
As Coca-Cola itself recalls, desperate times called for desperate measures. The company was in the midst of the "cola wars" against Pepsi, and for 15 years it had been losing market share to the slightly sweeter soda. That caused a radical response: New Coke.
But Coca-Cola didn't rashly change its signature formula. The company claims to have performed more than 200,000 taste tests before introducing New Coke. In those tests, customers preferred the sweeter formula to the classic one, and that gave CEO Roberto Goizueta the ammunition to make the switch. The problem was that a taste test didn't measure how people drank Coke in real life.
Malcolm Gladwell proposed a compelling explanation in Blink: the taste tests conducted by Coke and by Pepsi didn't represent how consumers actually drank soda. The working theory is that consumers enjoyed the sweeter taste of Pepsi and New Coke in small doses, but in larger quantities (like a two-liter bottle or full can), the extra sweetness was more polarizing.

A vintage Pepsi glass, stealing Coke's vigor. (Shutterstock)
The cola wars had, in theory, begun as soon as Coca-Cola found a formidable competitor. It had that in Pepsi, starting with the Pepsi Challenge ad campaign in 1975, which asked consumers to perform a taste test between Pepsi and Coke. It only intensified as the upstart brand gained market share. When New Coke launched, it showed that Coke was sacrificing a key front in the war — and the media leapt on it.
According to Thomas Oliver's The Real Coke, The Real Story, the marketing salvos fired by Pepsi were paired with a sophisticated PR strategy. In addition to ads trumpeting Pepsi's victorious battle in the cola wars, the soda maker primed reporters to barrage Coke with challenging questions. Before the press conference announcing New Coke, Pepsi called more than 200 reporters with suggested lines of attack.
Though there was genuine consumer distaste for the New Coke formula — Coke's consumer hotline reportedly lit up with thousands of complaints — the media aided the backlash by leaping on stories about frustrated Coke consumers.
Gay Mullins, founder of an organization called Old Cola Drinkers of America, reportedly spent $30,000 to help convince Coke to bring back the original cola, and he earned much more than that in media attention. When he called Coke un-American and complained, "They have taken away my freedom of choice," it made for a better quote than one that might be offered by a satisfied New Coke consumer.
In 1985, Pepsi symbolized youth and Baby Boomers. Coke represented tradition, in part because of its marketing efforts over the previous 50 years. As noted in The Real Coke, The Real Story, Coca-Cola symbolized the real America.
Coke was the one true "daddy juice"
To pick one example featured in The Real Coke, The Real Story, Rocky Mountain News columnist John Coit called Pepsi "sugar-plum fairy gag juice" while Coke was (the apparently preferable) "daddy juice." When Coit received a case of New Coke, he blasted it as "a lousy imitation of Pepsi."
Some commentators even believed that the Coca-Cola company, the venerable Atlanta institution, had betrayed the South by copying Pepsi. Though Pepsi was founded in North Carolina, by the 1980s it was headquartered in Purchase, New York. The Real Coke, The Real Story notes that Southern bottlers and consumers more vociferously objected to the New Coke taste.
In the mid-'80s, Bill Cosby was at a peak in popular culture, and he was both a Coke pitchman and an investor. But Coke didn't know what to do with him.
Before New Coke, Cosby said how awful Pepsi and sweet drinks were:

After New Coke, his taste suddenly changed:

It reflected the general confusion in Coke marketing — the company had spent the early '80s mocking Pepsi's sweeter taste, priming the public to react negatively when Coke changed its recipe.

This McDonald's in Germany makes it seem like Coke is a constant. But that's not always the case. (Ulstein Bild/Getty Images)
New Coke was a massive risk, so why didn't it create a separate "New Coke" from the beginning to run alongside the classic version? It didn't have a choice — Coke needed to retain market share for a single drink.
Fountain sales made up a formidable two-thirds of Coke's market, and the presence of Coke in McDonald's and other fountain machines wasn't a foregone conclusion.
Many of the contracts depended on Coke being the top-ranked cola. And if market share for Coca-Cola fell, the company might lose even more ground to Pepsi. If Coke had planned to run New Coke and original Coke side by side, it would have risked splitting its market share and alienating valuable fountain clients.
Later, when Coke reversed course and briefly produced New Coke and Coke at the same time, that's exactly what happened — the company lost market share and prestige to Pepsi by splitting its own market.

A Coca-Cola bottling plant in 1950. (Welgos/Stringer/Getty Images)
When Coke changed course, it couldn't do so unilaterally. A large network of independent bottlers had influence over the company, and they helped drag New Coke down. Without the bottlers' support, Coke would lose a key channel for its product, since these franchisees bottled and distributed Coke around the country and world. Though consumer response might have doomed New Coke even without the objection of bottlers, the network of diverse business interests made it almost impossible for Coke to drastically change its formula without a wide consensus.
Constance Hays's The Real Thing: Truth and Power at the Coca-Cola Company describes the problem: bottlers at Coke were partners with Coke in Atlanta, and their business was dependent on "Big Coke" (these bottlers were more influential and independent in the '80s than they are today). As a result, Coke had to keep them happy.
"We did not know what we were selling"
When New Coke started to get negative feedback, bottlers were very angry (some had only learned about the change on the radio). Bottlers received angry customer complaints directly, and a couple of months after New Coke debuted, a group of bottlers traveled to Atlanta to register their complaints. The Coca-Cola Bottlers Association also jumped on board and told Coke to bring back the classic formula.
CEO Goizueta couldn't hold on to such a drastic change in the face of bottlers' protests. That led to the July 10, 1985, announcement that Coca-Cola Classic would return.
Some conspiracy theorists believe New Coke was introduced simply to revive the classic formula's fortunes. But it's more likely that Coke simply didn't realize all the ways it could fail, and what a revision to the classic formula would sacrifice.
As one executive said in The Real Thing, "We did not know what we were selling. We are not selling a soft drink. We are selling a little tiny piece of people's lives." It turned out that piece was a lot harder to take away than Coke originally thought, for more reasons than it ever could have predicted.
Project Fi keeps costs down by relying heavily on the wifi networks most of us have in our homes and offices. Wifi networks are cheap because they operate on frequencies that are freely available for anyone to use. By contrast, cellular companies had to pay billions of dollars to the federal government for the exclusive frequencies they need to build cellular networks.
But wifi networks have a big downside: because of power restrictions, they have limited range. So if you want to ensure you have connectivity everywhere you go, you need access to cellular networks, too.
The strategy of stitching together wifi and cellular networks was pioneered by Republic Wireless, a startup that entered the market in 2011. Today, the company offers unlimited talk, text, and data on a high-speed 4G network for $40 per month — much cheaper than conventional wireless networks.
Republic recently announced a shift away from unlimited plans. Beginning in June, the company's customers will be charged based on how much data they use. Google is taking this same approach. On its plan, customers will pay $20 per month, plus another $10 for each gigabyte of data they consume. Both services automatically rebate customers for unused data.
That could translate into serious savings for most cellphone users. For example, I currently use about 2 GB of data per month and pay about $100 per month for my AT&T service. Under Google's plan, I'd pay around $40 per month. And if Google only charges for cellular connectivity, not wifi, (which seems likely, though its website isn't entirely clear), the savings could be even larger, since Google's phones are designed to use free wifi networks more and cellular networks less than conventional cellphones.
Republic Wireless's service only works with Android-based Motorola phones that Republic has customized to support seamless switching between wifi and cellular networks. Similarly, Project Fi will initially only work with the Google's Nexus 6 smartphone, though presumably other phones will be added in the future.
Google isn't planning to build its own cellphone towers. Instead, the search giant is reselling cellular bandwidth provided by Sprint and T-Mobile. Yet Google's business model is likely to exert significant downward pressure on incumbent wireless providers.
By enabling users to seamlessly shift between wifi and cellular networks, Project Fi (and before them, Republic Wireless) could turn cellular service into more of a commodity. Right now, wireless providers sell phones that use cellular networks the majority of the time and charge them $50 to $100 per month for the privilege. Having spent billions of dollars on wireless spectrum and cellular towers, incumbent wireless providers have had little reason to encourage people to use wifi more and cellular networks less.
But Google has little to lose and a lot to gain by pushing down the cost of wireless service. Not only could it build a profitable business, but cheaper wireless service could also encourage people to use their smartphones — and Google products like Android and YouTube — more.
So if Project Fi catches on, it could force wireless providers to cut their prices and improve support for switching between wifi and cellular networks — something that's awkward on cellphones today. The resulting cost-savings should benefit everyone who owns a cellphone.
Disclosure: My brother is an executive at Google.
Did you know that law enforcement can track your cellphone with a fake cell tower? It's true — and devices that do this, known as stingrays, are at the center of a growing scandal.
The FBI has done everything it could to keep the existence and use of stingrays a secret. Local law enforcement agencies are forced to sign nondisclosure agreements before they can use the devices. The FBI claims that revealing details about how the gadgets work would tip off criminals and terrorists, rendering them less effective.
But in recent months, civil liberties groups have steadily chipped away at the secrecy of these devices. We've learned that they're used by dozens — and probably hundreds — of law enforcement agencies across the country, and that at least one agency has used them thousands of times.
Critics say the way these devices have been used violates the US Constitution, by tracking people's locations without judicial oversight. And the secrecy surrounding the devices also appears to be hampering efforts to prosecute violent criminals, as prosecutors have dropped key evidence rather than discuss how it was obtained.
The extreme secrecy surrounding these devices is out of step with the American tradition of open and accountable government. Americans have a right to know that law enforcement spying has proper judicial oversight. And this kind of oversight is impossible if even basic information about the technology is kept under wraps.


A stingray surveillance device.

When you turn on your cellphone, it scans the surrounding area to find the cellular tower with the best connection. It then communicates with this tower to send and receive phone calls and other data.
A device called a cell-site simulator, popularly known as a "stingray," lets law enforcement spy on people by pretending to be a cellphone tower. This device, not much larger than a toaster, fools nearby mobile devices into connecting to it instead of to a real cellphone tower. That gives law enforcement information about the identity and precise location of nearby mobile devices. Police departments say they never use the devices to intercept the contents of people's calls or messages, though it's hard to verify that without knowing more about how they work.
By turning everyone's cellphone into a tracking device, stingrays allow cops to track suspects from the back of a van hundreds of feet away — without any help from the target's cellular provider. Unsurprisingly, the devices have proliferated to police departments across the country.
And while we don't know the full extent of Stingray use, there's evidence that they're used heavily by law enforcement agencies. The ACLU has compiled a map of states where law enforcement is known to be using the devices — there are almost certainly other places where their use has yet to be uncovered:


(American Civil Liberties Union)

How often are the devices used? Most police departments won't say. But police in Baltimore recently admitted that they've used the device 4,300 times. And we don't know how many of these uses occurred with court approval — we'll discuss the legal issues more below.
We know that many law enforcement agencies use this technology, but we don't know how many agencies use the devices or how often they do so. That's because an elaborate scheme has mostly kept the devices out of the public eye until recently.
The FBI thinks that releasing even seemingly minor information can cause harm
Because stingrays emit radio waves, they must be approved by the Federal Communications Commission before they can be used. Harris Corporation, the leading manufacturer of the devices, asked the FCC to require state and local law enforcement agencies to get approval from the FBI before they can use the devices. And the FBI, in turn, requires law enforcement agencies to sign nondisclosure agreements in order to get access.
The FBI declined to comment for this story, but a spokesman sent me a copy of a 2014 affidavit from an FBI official explaining why the agency requires that information about the devices be kept secret. The FBI says that giving the public details about how stingray technology works or how it's used could provide criminals and terrorists with information that allows them to "develop defensive technology, modify their behaviors, and otherwise take countermeasures designed to thwart the use of this technology."
The FBI thinks that releasing even seemingly minor information can cause harm, since the bad guys can piece together different bits of information to learn how stingrays work and how they can be evaded.
Earlier this month, the New York Civil Liberties Union obtained a copy of the nondisclosure agreement the FBI asked the sheriff's office in Erie County, New York, to sign in order to use cell-site simulators. The agreement bars recipients from telling anyone about the devices, and specifically prohibits Erie County law enforcement from disclosing information about stingray technology in court.
The FBI's gag order appears to be undermining efforts to prosecute violent criminals. This week, for example, the St. Louis Post-Dispatch reported that the St. Louis city police chose to drop the prosecution of three men charged in a violent robbery spree shortly before a government witness would have had to testify about the use of stingray devices in the case. Prosecutors say the timing was a coincidence.
Judges are getting fed up with the secrecy surrounding stingrays
In a Baltimore case last year, prosecutors chose to drop evidence about the location of a suspect's phone after an angry judge insisted that police explain how they had located it. In Florida, prosecutors offered a defendant a generous plea deal to avoid having to comply with a judge's order to show a stingray device to the defendants' lawyers.
If the FBI continues insisting on keeping the devices secret, this problem is only going to get worse. In the past, defense attorneys didn't know that stingrays existed, so they didn't ask questions about them. But now defense lawyers not only know the devices exist, they also know that pressing for information about them can force prosecutors to drop the case. So expect law enforcement to face a lot more awkward questions about this in the coming months.
Meanwhile, there are signs that judges are getting fed up with the secrecy surrounding stingrays. When a Baltimore police officer said he was barred from discussing the stingray in court due to a nondisclosure agreement, Baltimore Judge Barry Williams retorted, "You don't have a nondisclosure agreement with the court," and threatened to hold the cop in contempt if he didn't answer the question.


(Michael Dorausch)

Adam Bates, an analyst at the Cato Institute (where I was a staff writer from 2003 to 2005), says that law enforcement use of stingrays raises two different constitutional issues.
One has to do with the Fourth Amendment. While the law isn't totally clear, a 2012 Supreme Court ruling suggested that tracking a suspect's location without a warrant may run afoul of the Fourth Amendment's rule against warrantless surveillance. For example, Bates notes that documents in Erie County showed that police "had deployed the device 47 times and had only gotten one court order." Future court cases will likely clarify when the police must seek judicial approval before tracking suspects.
A related problem, Bates says, is that when police use a stingray, they capture information about every cellphone in a large area. That means that in the process of spying on a single criminal suspect, they may also capture information about the location of dozens of totally innocent people, as well — making judicial oversight all the more necessary.
Also, it wouldn't be difficult for stingray-type devices to intercept not only a suspect's location and identity, but also the contents of his communications. Bates says law enforcement agencies have consistently denied that they do this. But given the potential for abuse, he argues that more oversight is needed to verify that these devices are not being used for illegal wiretapping.
And Bates says the FBI's gag order raises additional constitutional issues. "We have a long history of not allowing that kind of secret evidence," Bates says. The Constitution guarantees defendants the right to see evidence used against them and interrogate opposing witnesses. So even if warrantless stingray surveillance is legal, barring prosecutors and police officers from discussing it in court might still violate the Constitution.
The FBI claims it needs to keep information about stingrays under wraps to prevent the bad guys from learning how to evade surveillance. That argument might have made sense a decade ago when the use of this technology was unknown, but it doesn't make much sense today.
This isn't how we handle other police surveillance techniques. For example, law enforcement has long had the power to wiretap people's telephones. Information about specific wiretapping operations — whose phone lines are being tapped, and when — are kept secret for obvious reasons. But the existence of wiretapping capabilities is not a secret.
There's no way to put the stingray genie back in the bottle
Nevertheless, criminals regularly make incriminating statements over tapped phone lines. That's partly because criminals can be careless, and partly because it's hard to know which information might turn out to be incriminating. There's no reason to think that providing more information about how stingrays work would destroy the devices' utility to law enforcement.
We don't know if warrantless cellphone tracking is legal or not. Law enforcement agencies have insisted that the Fourth Amendment doesn't apply in this type of situation, and the courts have yet to squarely address the situation. Prosecuting people using secret evidence certainly seems constitutionally problematic.
In any event, there's no way to put the stingray genie back in the bottle. At this point, smart criminals are going to assume that the police have the ability to track their cell phones. If the FBI continues to insist on secrecy, it's only going to hamper the efforts of prosecutors, who will be put at a disadvantage by their inability to explain how they got incriminating evidence.
The office communications app Slack is less than two years old, but the company behind it recently raised an incredible $160 million dollars in a deal that valued the company at $2.8 billion. In an interview with the New York Times's Farhad Manjoo, Slack CEO Stewart Butterfield argued that this might be the best time in world history to raise money for a startup:
I’ve been in this industry for 20 years. This is the best time to raise money ever. It might be the best time for any kind of business in any industry to raise money for all of history, like since the time of the ancient Egyptians. It’s certainly the best time for late-stage start-ups to raise money from venture capitalists since this dynamic has been around.
Why do investors have a seemingly insatiable appetite for technology companies like Slack? In trying to answer this question, I think a lot of people focus too much on characteristics of the technology sector itself. Silicon Valley companies are pioneering a lot of important innovations right now, but the same thing was true 10, 20, 30, and 40 years ago.
Rather, I think the increasingly favorable environment for fundraising in Silicon Valley is a reflection of broader macroeconomic trends. Inflation-adjusted interest rates have been declining for decades, a sign that businesses are finding it more and more difficult to invest available capital in things like factories or research and development in ways that will produce high returns.
Silicon Valley is one of the few remaining bright spots. The worse the returns on other investments get, the more willing investors become to take big risks in pursuit of higher returns.
It's certainly possible that this will prove to be a bubble that pops in the next few years. But it's also possible that this is just the new normal. If interest rates stay low, any industry that shows a potential for rapid growth could be flooded with cash from investors desperate for higher returns.
A lot of people have credited a John Oliver segment for catalyzing a successful grassroots effort to get the Federal Communications Commission to institute strong network neutrality rules back in February. In yesterday's show, Oliver tried to get the same results with another tech policy issue: patent trolls and the broad software patents they use to shake down the American economy.
In this clip, which aired on Sunday night, Oliver highlights the story of an organization that provides employment services to people with disabilities getting threatened by a notorious patent troll that claims to own the concept of scanning a document to an email address. The same litigious company has threatened hundreds of other organization, seeking thousands of dollars in licensing fees just for using their office scanners. This kind of litigation has cost the US economy billions of dollars.
As Oliver notes, legislation to rein in patent trolls failed in the Senate last year because of lobbying from trial lawyers. But advocates of patent reform hope to be more successful this year.
They're tall. They're totally absurd. And they're everywhere.
Over the past few decades, as cellphone networks have grown, thousands of antenna towers designed to look vaguely like trees have been built across the United States. Although these towers are intended to camouflage a tower's aesthetic impact on the landscape, they typically do the opposite: most look like what an alien from a treeless planet might create if told to imagine a tree.
Still, there are some good reasons why it's really hard to build a tower that actually looks like a tree — whether it's the classic "monopine" or a palm tower.

A "pine" in Colorado.  (Brian Brainerd/the Denver Post via Getty Images)
There's a history of clumsily trying to conceal infrastructure that goes way further back than cellphone towers. In the 1950s and '60s, for instance, Canadian electric utilities built hundreds of entirely fake houses throughout Toronto to conceal substations.
In the 1980s, soon after cellphone companies started building antennas in the United States, they sought to hide them, as well, often in response to aesthetic complaints from local residents — as detailed in historian Bernard Mergen's excellent chapter in Analyzing Art and Aesthetics.
Initially, most concealed antennas were simply hidden on church steeples or water towers, but in 1992, a company called Larson Camouflage — which had previously made fake habitats for Disney World and museums — built a "pine" tower in Denver. The world was changed forever.
Soon afterward, companies in South Carolina and South Africa began building similar "trees." In the US, the Telecommunications Act of 1996 restricted municipalities' ability to block tower construction, so as demand for cell service spread, it meant that towers would inevitably be built in historic districts and other areas where locals might object.

A "tree" in Cambridge, Massachusetts. (Darren McCollester/Getty Images)
Still, municipalities have often tried to block construction, leading companies to offer "trees" instead of towers as a compromise. Some localities even require new towers be camouflaged as part of their zoning requirements.
There's no good data on how many of these "trees" now exist, but in 2013, Mergen estimated there were between 1,000 and 2,000 nationwide. The company Stealth Concealment says it builds about 350 new "trees" per year. They're most often built in suburbs, where residents have the time and urge to war with companies over new towers, and there's enough incentive for carriers to invest in "trees."
There are actually good reasons why these towers seldom actually look like real trees.
One is height. Towers are built to hold antennas higher than surrounding structures to ensure good reception, so they have to be taller than what's nearby. This is why you often see surreally tall "pines" or "palms" towering over normal trees.

(Travel Aficionado)
Another is cost. These "trees" are normal cellphone towers, which are then sent to companies like Larson or Stealth Concealment for plastic, fiberglass, or acrylic "bark," "branches," and "needles" to be added. This process is customized and expensive: it can add $100,000 or so to the baseline $150,000 cost of a tower.
As Ryan McCarthy of Larson told Bernard Mergen, "A pine tree that has 200 branches will be more appealing than one of the same height that has 100. However, the customer will not only incur the cost of 100 extra branches, but the extra wind load from the branches will also require that the pole be designed more stoutly."

(Russ Allison Loar)
This is also why you so seldom see towers designed as deciduous trees, even in areas where they're much more common than pines — their branching structure makes them more complex and more expensive to build. Pines, palms, and cacti are much easier to approximate in plastic and fiberglass.
In terms of blending in, the most successful towers are probably "saguaros," which can plausibly be built in deserts where there are no trees that they have to tower over — and don't have expensive branches or needles that need to be attached.

(Folsom Natural)
You can check out dozens of other examples of cellphone towers disguised as trees — but also as flagpoles, bell towers, and church crosses — here.
The one-year-old corporate messaging company Slack has raised $160 million in a deal that values the startup at $2.8 billion. As always happens when a young company raises a lot of money, people are describing this as evidence of a tech bubble — an unsustainable increase in the value of technology stocks.
People have been saying there's a technology bubble for the past decade, and so far they haven't been proven right. But pointing to Slack's $2.8 billion valuation as evidence of a bubble is particularly unconvincing.
Back in the 1990s, there were a lot of tech startups with no revenue and no real plans for earning revenues. That was a bubble, and those companies failed when the bubble popped.
More recently, there have been companies — like Twitter and Facebook in their early days — with no revenue but a totally plausible plan for generating revenue by showing people ads. People shouldn't have been surprised when these companies started making a lot of money, and yet they were.
But Slack isn't in either of these categories. It has one of the most straightforward possible business plans: charge businesses a monthly fee on a per-user basis. Slack's prices start at $6.67 per user per month, so if it has 200,000 paying users, as the New York Times reports, then the product should generate at least $16 million in revenues this year.
Obviously, $16 million in annual revenues isn't enough to justify a $2.8 billion valuation. But the opportunities to grow that number are obvious. First, 200,000 people is a tiny fraction of America's — to say nothing of the world's — workforce. There's opportunity to have 2 or even 20 million paying users over the next decade, which would translate to more than a billion dollars in annual revenue.
Second, there's a lot of room to upsell. That $6.67-per-month fee is a low price for business software. The company's pricing page signals that it expects it will be able to charge 10 times as much for an "enterprise" version of Slack that integrates with companies' existing IT systems.
So imagine that a few years from now, Slack has 10 million paying users (about 6 percent of the US workforce) and generates an average of $10 per month of revenue from each. Suppose also that the company has a 50 percent profit margin (that's high for most companies, but it doesn't cost very much to run an online service). At a price-to-earnings ratio of 15 — typical for a mature technology stock — this company would be worth $9 billion. So if you think Slack can maintain its current momentum for a few more years, $2.8 billion is a bargain. And Slack could easily attract more than 10 million users and generate more than $10 per user.
People are still in the habit of thinking of the internet as a bleeding-edge technology with an unproven ability to support profitable businesses. But it's long past that point. The internet has become a central part of hundreds of millions of people's personal and professional lives. People should stop being surprised when a company that makes millions of internet users more productive is valued at billions of dollars.
A Japanese bullet train just broke the all-time speed record for rail vehicles — with JR Central, the company that owns the train, saying it traveled at 366 miles per hour.
The feat, accomplished on Thursday on a test track in Yamanashi prefecture, was reported by Jun Hongo  of the Wall Street Journal. The previous record, set by a French train in 2007, was 357 mph.
The Japanese train is able to travel so fast partly because it hovers over the tracks, with powerful magnets lifting it and cutting down on friction. Here's a clip of the same train being tested earlier this year:

Company officials say the train can go even faster, and predict it could hit 372 mph during another test next week. It should eventually be used for a new line that will connect Tokyo and Nagoya, with trains routinely traveling as fast as 313 mph, cutting the travel time to 40 minutes.
By comparison, the fastest currently operating train in the US is Amtrak's Acela, which runs at 150 mph for very brief segments of track in Massachusetts and Rhode Island. However, the majority of the Northeast line runs at 110 mph or slower, and most other parts of Amtrak's network run at decidedly lower speeds.
There are lots of proposals for high-speed lines in the Northeast and elsewhere, but very few have gotten off the ground. California's high-speed rail network, now under construction, will have peak speeds of 200 miles per hour, but its San Francisco–to–Los Angeles segment isn't scheduled to open until 2029.

The European Union's competition commissioner filed a "statement of objections" on Wednesday that brings Google a step closer to facing legal sanctions under European law. The European Commission's specific allegation is a relatively narrow one — that the search giant has broken the law by giving Google Shopping a more favorable position in search results than other comparison shopping services — but the underlying policy issue is much broader. Following the logic of the EU complaint would require a massive transformation of Google's search product.
The key point is that Google doesn't just give prime real estate to Google Shopping results. It unapologetically does it for products like Google Images, Google Maps, and Google News — all of which regularly show up in special boxes near the top of Google search results.
Consequently, if you take the logic of the EC's complaint seriously, then EU regulators aren't going nearly far enough. If it's illegal to elevate Google Shopping over other search results, it should also be illegal to give special treatment to Google's other specialized search products for maps, news, or images.
And indeed, that's exactly what Google's more ambitious critics are pushing for. If they win, it could lead to a dramatic transformation of Google's search product — one that may not be in the interests of customers.


(Georges Gobet/AFP/GettyImages)

The European Commission complains that "Google systematically positions and prominently displays its comparison shopping service in its general search results pages, irrespective of its merits," and that it has done so since 2008.
The argument echoes charges that American and European regulators made against Microsoft in previous decades. During the 1990s and 2000s, the software giant repeatedly got in trouble for bundling products like Internet Explorer and Windows Media Player with its dominant operating system.
Critics said this gave Microsoft an unfair advantage in these markets, harming rivals such as Netscape and RealNetworks. Now, Google's dominance of the search market is subjecting it to the same kind of regulatory scrutiny Microsoft started getting two decades ago.
So why has the EC focused on shopping, while mostly ignoring the preferential placement given to other Google products? Mark Patterson, a legal scholar at Fordham University, believes European regulators probably focused on shopping because they "have what they think is a smoking gun" — though Patterson says we don't yet know what that is. For example, if the EC had evidence that Google chose to promote its own shopping products despite internal data showing customers preferred results from third parties, that could be a basis for legal action.
Another likely reason for the focus on shopping: a European shopping site, Foundem, has been a leading advocate for EU officials to take action against Google. Foundem's crusade against Google started nine years ago, when Foundem discovered that its pages had been deleted from Google. Foundem has long since been restored to Google's index, but Foundem has been seeking action by EU regulators ever since.


Google CEO Larry Page. (The Washington Post/Getty)
Whatever the motives for the specific focus on shopping, it's clear that the general principle has much wider implications.
If you search for "White House memorabilia," you get a result like this:

Notice the big "Shop for white house memorabilia on Google" box at the top of the results. If you click on the link, it will take you to Google Shopping, where you can browse a selection of White House memorabilia.
But that's hardly an isolated example. Search for "White House photos," and you get results that look like this:

Search for "White House directions," and you get results like this:

Google's search engine hasn't always worked this way. Google called this approach of blending results from different types of specialized search engines into a single page of results "universal search" when it was introduced in 2007.
Google says universal search is good for customers because it helps provide the most relevant search results. But critics say universal search gives Google's specialized search products an unfair and illegal advantage.
Foundem isn't just unhappy with Google's treatment of shopping results. Foundem views the whole concept of universal search as anticompetitive. In a 2010 white paper, Foundem noted that Google Maps displaced MapQuest as the leading online mapping service not long after Google Maps began appearing in search results in May 2007:

Frank Pasquale, a legal scholar at the University of Maryland, agrees with Foundem's critique. "You don't want to create a situation where the dominant interface by which people are trying to find mapping technology is going to squeeze out all of the oxygen for potential rivals," Pasquale says.
Even if the EU wins in court, it could be difficult to come up with an appropriate remedy
Pasquale would like to see regulators force Google to provide a level playing field for a wide variety of specialized search projects, including shopping and maps. In his vision, Google might be required to show results from Google competitors as often as it showed results from Google's own products. He argues that this kind of mandate would nurture the growth of small startups, leading to more innovation in the long run.
But others are more skeptical. Randal Picker, an antitrust expert at the University of Chicago, agrees that it seems arbitrary to single out Google's treatment of shopping while ignoring the treatment of other specialized search products. But he seemed less enthusiastic about what the EU was doing than Pasquale.
One big problem, Picker says, is that even if the EU wins in court, it could be difficult to come up with an appropriate remedy. For example, a few years ago the EU forced Microsoft to add a "browser ballot" to Windows, allowing users to decide which browser to use. But when a technical glitch prevented the ballot from appearing in 2011, no one noticed for more than a year. Similarly, when EU regulators forced Microsoft to distribute a copy of Windows without Windows Media Player installed, it only sold a few thousand copies, compared with tens of millions of copies for the mainstream version. The EU's remedies against Microsoft were toothless, and they'll have to think hard about how to avoid this kind of mistake with Google.
Another problem is more fundamental: getting regulators involved in designing search results could hamper innovation. Google's practice of including results from its other products in search results pages might be bad for competitors, but it's undeniably convenient for many users.
In theory, it should be possible to require Google to display competitors' results in place of Google's own results. But in practice, the increased bureaucracy could deter Google from making beneficial improvements to its search results page altogether.
Disclosure: My brother is an executive at Google.
The new Apple Watch comes in a variety of materials and price points, including a gold Edition case that retails for a minimum of $10,000. Apple also makes a variety of bands, including a stainless steel link bracelet that led many to anticipate that there would be a solid gold link bracelet to go with the gold case and reach an ultra-high price point. Yet when Apple unveiled its product lineup early this month, there was no gold link bracelet to be found.
And yet here's a photo posted to Instagram by Karl Lagerfeld's assistant that appears to show the designer wearing a solid gold link bracelet (via MacRumors):

1st apple watch specially made for KarL !! Amazing !!! Thanks #apple !!!!!! @karllagerfeld
A photo posted by Sebastien Jondeau (@bentoub) on Apr 15, 2015 at 9:55am PDT
One possibility is that this is a prototype model that Apple sketched out but decided that they couldn't produce at sufficient scale to bring to market. Or maybe it represents something they're working on but are planning to release when the market for smartwatches is more established and the company has a better sense of whether bands will be re-usable on future iterations of the watch.
But here's one hilarious angle John Gruber noted — Lagerfeld hasn't bothered to set up his five-figure watch: "the screen that's shown here is the setup screen for pairing with your iPhone. You point your iPhone's camera at your watch on this screen and it figures out which way it's oriented, and boom, they're paired."
That's a powerful reminder that the market for consumer electronics and the market for high-end jewelry are quite different in some fundamental ways.
"Design is not just what it looks like and feels like," Steve Jobs famously said,  "design is how it works."
Job's dictum is a very nice idea, but pretty clearly hasn't been true of the luxury watch market for the past thirty years or so. Mechanical watches are not as good at keeping accurate time as cheaper quartz alternatives, and high-end materials like gold have no utilitarian virtues as watch components. The design of a solid gold watch really is about looking like you're wearing a bunch of gold on your wrist, and nothing to do with how anything works. Under the circumstances, a watch that actually doesn't work — like Lagerfeld's not-yet-setup Apple Watch Edition — is about as good as any other.
Japan has just overtaken China as the largest foreign government buyer of US government debt, which hopefully can mark a time to finally retire dumb talking points about China somehow owning the United States or possessing vast leverage over our foreign policy through its debt purchases.

Japan overtakes China as the biggest foreign holder of US Treasurys: http://t.co/H7lTdx05Sz & http://t.co/K83ucrorNl pic.twitter.com/NVbV7iZzMs
Everyone from Richard "What if they dumped all their bonds at once" Shelby to Hillary Clinton has made some version of this argument over the years, and it's never made very much sense. Enough misleading political rhetoric about this was getting tossed around that somehow voters ended up telling pollsters most US debt was owned by China, which has never been anywhere close to true.
The simple truth is that all that Chinese debt-buying in the aughts was a way of subsidizing Chinese export industries — it was a central element to the "currency manipulation" American officials often complained about.
Chinese factories were selling lots of manufactured goods to consumers in the United States. Ordinarily, this would have pushed up the value of China's currency, the yuan, relative to the US dollar. That, in turn, would have made Chinese goods more expensive in the US and hampered the growth of Chinese exports. The Chinese government decided it didn't want to let that happen, so it needed to cycle export earnings back into something else priced in dollars.
China chose to buy lots of federal debt — and also lots of Fannie Mae and Freddie Mac debt that was guaranteed by the federal government — because it's very safe and also very easy to buy in large quantities.
Whatever its origins, the China bond surge is clearly over as China has moved on to a new era of slower growth and somewhat different political thinking about its desired path of development. In its place has come a rush of Japanese money. This money is coming from the Government Pension Investment Fund, which is kind of like Japan's equivalent of our Social Security Trust Fund.
The difference is that America's Social Security Trust Fund invests (or "invests") exclusively in US government debt, which makes it functionally equivalent to an accounting device rather than a proper trust fund.
Japan's GPIF, however, moved away from that model a few years back in favor of acting more like a real sovereign wealth fund, of the sort you see in Norway and the Gulf states. Over the past 12 months, that's generated a lot of stories about GPIF buying foreign stocks. But before it dove all the way into the stock market, it tested the waters with the relatively safe move of buying US Treasury bonds.
The point of all this is that Japan's population is declining, which means Japan's retirees can't necessarily count on the next generation of Japanese people to produce enough income to support them all. Japan needs to look outside its borders to more demographically vibrant countries to find the investment opportunities it needs.
All this points to the awkward truth about America's national debt — the federal government has no need to borrow money. If you want to buy a house, you probably need to borrow some cash to afford it. Lots of businesses face the same problem. So do towns, states, school districts, and other public agencies all around the country. But the US government makes US dollars out of thin air and thus can never be in a position where it needs to borrow some US dollars from someone else.
The reason the government finances deficits by selling bonds rather than printing dollars is because other people like to buy the bonds.
For some, like the Chinese government, buying a bunch of US government bonds is the most convenient way to gain exposure to the overall value of the US dollar. For others, like the Japanese government, buying a bunch of US government bonds is a safe and predictable store of value in a world where some countries are facing severe demographic or geopolitical risks. Many bond buyers, of course, are private individuals or companies who also have these motives.
The point, however, is that nobody can "threaten" the United States by refusing to buy our federal government's debt. The debt is there because people want to buy it. If nobody wanted it, there would be a logistical challenge in switching from debt finance to money finance — either Congress or the Federal Reserve would have to promulgate a new policy — but economically speaking, life would go on as before.
A new report from Gallup and the World Bank reveals another dimension in which America is a world leader in inequality — access to bank accounts.
According to the report, "In Canada, France, Germany, Japan, and the United Kingdom there is no significant difference in account penetration between adults in the poorest 40 percent of households and those in the richest 60 percent." But in the United States, there's an 11 percentage point gap, leaving lower-income American households much more likely to be unbanked than comparable households in other developed countries.

(Findex Gallup/World Bank)
This would just be a wacky trivia fact, except lack of access to bank accounts is one of these ways in which it's expensive to be poor. People who don't have bank accounts find themselves stuck getting paid via high-fee prepaid debit cars, having difficulty establishing a credit rating, and paying high fees at check cashing joints.
Eliminating these inequities in access to basic financial services is one key argument in favor of Postal Banking — using the US Postal Service to provide basic utility-like services for small dollar accounts.
It was a moment big broadband providers have been anticipating for weeks. The official publication of the Federal Communications Commission's network neutrality rules on Monday gave a green light for challenging those rules in court. This week, industry groups representing almost every type of internet service provider have filed lawsuits arguing that the FCC's new regulations are illegal. If these lawsuits succeed, they could strip the FCC of legal authority to establish strong net neutrality protections.
The groups won't be required to spell out their legal arguments until later in the legal process. But this week I talked to two industry insiders — including Michael Powell, who represents the cable industry as the head of the National Cable and Telecommunications Association — to get a preview of the industry's arguments.
The lawsuits will include a direct attack on the legal foundations of the FCC order: the decision to regulate internet access like a public utility. That was an essential precondition for enacting tough network neutrality rules. And industry groups say it goes beyond the authority Congress provided to the FCC.
But the telecom industry may have a difficult time convincing the courts on this issue. A landmark 2005 Supreme Court decision stressed that the FCC has considerable flexibility to decide how to regulate internet access. Network neutrality supporters say that ruling gives the FCC clear legal authority for the rules the agency established in February. Either way, this is a fight that's going to continue for years to come.


President Bill Clinton and House Speaker Newt Gingrich in 1998. The 1996 Telecommunications Act was passed in 1996 by the Republican House and signed by Clinton. (PAUL J. RICHARDS/AFP/Getty Images)

To understand the current legal fight, you have to go back to the last time Congress updated telecommunications law, in 1996. Online services had just begun to be a mainstream phenomenon, and the Republican majority in Congress faced a dilemma. On the one hand, too much regulation could hamper the evolution of these services. Yet total deregulation could allow incumbent telephone monopolies to strangle these services in their cradle.
So Congress established two sets of rules. Online services like AOL were defined as "information services" and were exempted from most regulations. But the telephone connections most people used to reach services like AOL were defined as "telecommunications services" and were subject to strict regulations.
Ever since then, telecom debates have focused on how to apply those 1996 categories to new types of internet service. And this is a hard question, because modern ISPs often play both roles: they provide the physical connection needed to get online (like old-fashioned telephone monopolies) and digital services that add value to that basic transmission capacity (like AOL in the 1990s).
After cable companies started offering internet access, a deregulation-minded Republican majority decided in 2002 to put cable internet access in the lightly regulated information-service category. (Michael Powell, now the top lobbyist for the cable industry, was head of the FCC at the time.)
That decision led to a lawsuit that went all the way to Supreme Court. In 2005, the Supreme Court ruled that the law was ambiguous. There were good arguments for either classification, so the court decided to defer to the FCC on the best approach.
Now the FCC wants to reverse its own 13-year-old decision. A 2014 court ruling limited the agency's ability to impose strong network neutrality regulations while treating broadband as an information service. Switching categories could provide the legal basis for stricter regulations.
Today, old-school ISPs are nearly extinct
Industry groups such as the National Cable and Telecommunications Association, which represents big cable companies, argue that the law doesn't allow the FCC to do this. They say ISPs have always been treated as lightly regulated information services, and that the law doesn't allow the FCC to subject internet access to utility-style regulation.
Liberals like Harold Feld of Public Knowledge say this is nonsense. They say that until 2005, DSL service was subject to utility-style regulation. Indeed, they say that in the late 1990s, it wasn't even controversial to subject the internet access provided by phone companies to the same strict regulations as conventional phone service.


Broadband providers want to be in the same legal category as dial-up online services like AOL. (Julie Thurston Photography/Moment Mobile/Getty)

So who's right? These apparently contradictory positions reflect a subtle change in the meaning of the term "ISP" that occurred around the turn of the century. Remember, to get on the internet in the 1990s, you needed to get a physical phone line and service from a dial-up provider such as AOL or Earthlink. The term "ISP" only referred to internet service, not the physical cable that connected you to the network. And it's true that standalone ISPs in this older sense of the term were never subject to utility-style regulations.
Today, however, those old-school ISPs are nearly extinct. We use the term ISP to refer to companies that provide both a physical connection and the ability to send and receive information over the internet. And it's true that the courts have never clearly ruled on whether this new type of ISP can be subject to utility-style regulations.


Antonin Scalia is one of the Supreme Court's most conservative members, but liberals loved his 2005 dissent on broadband regulation. (NICHOLAS KAMM/AFP/Getty Images)

There's always some uncertainty about how the courts will rule, but the industry's argument here seems like a long shot. A prominent theme in the Supreme Court's 2005 ruling — and other court rulings on telecommunications regulation — is that the FCC is entitled to significant latitude in deciding how best to apply an ambiguous law to a fast-changing industry. It's also notable that the three dissenting justices in that 2005 ruling — including two who are still on the court, Justices Antonin Scalia and Ruth Bader Ginsburg — believed the law required internet service from cable companies to be regulated as public utilities. So it won't be easy to convince the courts that the law actually prohibits such regulations.
The industry's argument seems to rely on resurrecting a sharp distinction between the physical network connection (provided by phone companies in the dial-up era) and the services provided by old-school ISPs. Industry groups can't deny that the first type of service can be regulated as a telecommunications service, but they want to convince the court that regulating the second type of service goes too far. But the Supreme Court's 2005 decision didn't seem to focus too much on this distinction. It treated internet service as an integrated whole, and ruled that the commission had a fair amount of latitude to decide how to regulate the bundle of services ISPs provided.
Supporters of the FCC's ruling also point out that the internet has evolved in a way that strengthens the agency's argument. In 2002, many customers relied on ISPs to provide online services such as email and personal websites — in addition to raw access to the internet. Many ISPs still offer email accounts, of course, but people are more likely to use web-based email service from third parties such as Google, Yahoo, and Microsoft. This makes it more difficult to characterize the internet access provided by companies such as Time Warner Cable or Verizon as an online service in its own right rather than a way to reach online services provided by third parties such as Facebook or Netflix.
WATCH: 'Ezra Klein on the new net neutrality developments from late February'

Tax Day doesn't have to suck — at least not this much.
The IRS knows what you make. It knows if you typically take the standard deduction. For a lot of Americans, the IRS could just fill out their taxes for them. It would save billions of dollars in tax preparation fees and hundreds of millions of hours spent filling out tax forms.
This isn't some wild idea: it was piloted in California, where citizens loved it — 97 percent of those who used it said they would do so again. It's how taxes work in Denmark, Sweden, and Spain. "No other industrialized country asks its citizens to jump through as many hoops to calculate their taxes as ours," writes Farhad Manjoo at the New York Times.
Politicians ranging from President Obama to Ronald Reagan have supported this tax change — but there are some very rich companies and some very powerful activists standing in its way.

A visual explanation of how the IRS could do your taxes for you, and why you should let it.
Intuit, the maker of TurboTax, is a particularly powerful opponent. Such a system "minimizes the taxpayers' voice and control over the tax process by reducing their role in filing their taxes and getting their own money back," David Williams, the company's chief tax officer, told the Times.
But that excuse doesn't hold much water. Under these automatic systems, no one has to let the IRS fill out their taxes for them. They can continue to do it by hand or by TurboTax, or hire an accountant. Intuit knows, however, that many fewer Americans would do their own taxes under this scenario, and that would be a big hit to Intuit's bottom line.
Some anti-tax conservatives also hate the idea of the IRS filling out sample returns. Grover Norquist, president of Americans for Tax Reform, warns, "Conservatives, in particular, should see this ploy for what it clearly is: a money-grab by the government." The easier and more efficient the tax system is, the more money it will raise, and the less public anger there will be for anti-tax conservatives to harness.
For much more on this subject, ProPublica's investigation of Intuit's lobbying against automatic tax filing is the best look at why a policy with so much bipartisan support can't seem to pass Congress, and the Sunlight Foundation has even more lobbying numbers here. Wonks will want to spend some time with economist Austan Goolsbee's white paper on how automatic filing could work in practice. And you can read Intuit's case against California's Ready Return system here.

People love the story of Dan Price, the CEO of Gravity Payments in Seattle, who cut his $1 million annual salary to $70,000 and raised the salaries of his lowest-paid employees up to a $70,000 floor. Price says he was inspired to make the move after reading that more money leads to more happiness, but only up to the point of $70,000 a year or so.
The original New York Times report quotes Price saying, "Is anyone else freaking out right now. I'm kind of freaking out," right after making the announcement. It's a wonderful story, and Price deserves the plaudits he's receiving.
Unfortunately, the big questions raised by the story have a couple of not-so-feel-good answers. But Price is getting something important right: a more equal world is going to be a happier world.
The most natural question is to wonder what would happen if more CEOs acted this way. After all, though $1 million is a lot of money, it's far from the top of the executive compensation sweepstakes in America. But as Danielle Kurtzleben pointed out last year, it turns out that the executive compensation packages of really big companies' CEOs don't actually go that far when stretched across huge enterprises.
Walmart chief Douglas McMillan, for example, pulled in $25 million in 2014. That's a ton of money. But Walmart has about a million hourly employees, meaning that a drastic pay cut for McMillan would only finance a very modest bonus for the entire team. If McMillan cut his salary to $70,000, for instance, he would only be able to give each of his employees a raise of not quite $25.
Walmart is, obviously, an extreme case. But the huge divergence in what Price can achieve with a pay cut and what the much-better-paid McMillan can achieve with a pay cut goes to show that the math of this kind of enterprise is heavily dependent on the size of the company. For smallish companies, what the boss pays himself really is the key to what he has left to pay his workers. Big companies have much more complicated pay structures. Compressing the salary distribution up and down the line at Walmart could certainly raise pay for rank-and-file associates considerably, but it would mean forcing not just one boss but hundreds of highly paid subordinates to take pay cuts.
Even worse, Price's reading of the happiness literature is likely mistaken. He appears to have been relying on a paper by Daniel Kahneman and Angus Deaton. But subsequent analysis by Betsey Stevenson and Justin Wolfers disputes this, and finds that the reason you see rich people trying to amass even more money is that there is no satiation point. So $70,000 is better than $25,000, but $7 million is even better.
Here's a chart summarizing their findings:

Across countries, life satisfaction increases with the log of household income. In other words, it's true that if you're already pretty affluent, a little money won't make you much more content. But that doesn't mean money is useless — it just means you need a lot more.
That point about how much money you need to become happier cuts both ways, though. What it says is that the well-being Price would lose by dropping from $1,000,000 a year to $980,000 a year is smaller than the well-being gained by a rank-and-file employee going from $50,000 a year to $70,000 a year. Which is to say that redistributing income from the haves to the have-nots makes the world a happier place.
In a corporate setting, that means a small raise to low-paid workers will accomplish more than a medium raise to workers who are already well-paid. In a political setting, it means that taxing the rich to finance tax credits or health insurance for the poor and the working class will make for a happier country.
Digital cameras and solar panels have more in common than you might realize. At their core, both convert light into electric current — it's just that a camera does so to measure light's intensity, and a solar panel does it to create usable power.
A group of Columbia University engineers recently took advantage of this similarity to create something pretty cool: a camera that powers itself.
The camera, which is made from off-the-shelf parts and will be presented next week at the International Conference on Computational Photography, doesn't take especially sharp pictures. Instead, it's intended as a proof of concept:
<picture class="c-picture" data-cid="site/picture_element-1500887605_7063_148640" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/_xWttf9iYdmp0R9kuvQsD0VO8Hc=/0x0:800x616/320x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 320w, https://cdn.vox-cdn.com/thumbor/r1oSNRhpiru8z-lh_7gEZrw-4IM=/0x0:800x616/520x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 520w, https://cdn.vox-cdn.com/thumbor/me3ra2YbXZ_s5OuwiXmp9cP0M0A=/0x0:800x616/720x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 720w, https://cdn.vox-cdn.com/thumbor/VHJPbMDBoLPSVfGFVPy2gJ5gdIQ=/0x0:800x616/920x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 920w, https://cdn.vox-cdn.com/thumbor/34xx_NB4IdjsEG_TeXlh1mr5N2g=/0x0:800x616/1120x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/1MrUeRP7f6ixBet2P6Ks6QSxx94=/0x0:800x616/1320x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/ytZwXXaM4t0hw68-jCNhfC6Q5FI=/0x0:800x616/1520x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/Wc6j2hsIBj8_hwkAwObnxoGr2II=/0x0:800x616/1720x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/nmMZVscT--iS2JT_SyQI8ztAUPA=/0x0:800x616/1920x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/-Evx9DWE9WkAlXL0yImsuWxh1NI=/0x0:800x616/1200x0/filters:focal(0x0:800x616):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3605142/camera.0.gif" alt="camera gif">

</picture>
A short video made from photos taken by the self-powered camera. (Computer Vision Laboratory, Columbia Engineering)
What makes the camera special is its image sensor. Normally, this component senses the intensity of the light hitting the lens with millions of photodiodes — semiconductors that convert light into electric current, which gets encoded as digital data.
But in this camera, the photodiodes cycle back and forth between the image-taking mode and an energy-harvesting mode, in which the current instead charges the battery. This means that if the camera is in a bright area, it can continuously take a photo every second, indefinitely, without ever needing an external charge. The scientists claim it's the first camera that's fully self-powered.
Eventually, this sort of technology could be used in what's called the "Internet of Things": the growing network of ubiquitous wifi-connected devices like smart thermostats, locks, and light bulbs.
A cheap, small camera that can be left on indefinitely could have all sorts of uses. It could perhaps be part of an array of face-recognizing security cameras, for instance, or a series of cameras that sense when someone's in the room to adjust the heating or lighting accordingly.
Read more: Everything's connected — how tiny computers could change the way we live
The button began its life as an April Fools' joke, but nearly two weeks later the community surrounding the Reddit social experiment is still going strong. On Friday morning, the community reached a new milestone, as users started earning coveted yellow flair.
The previous sentence probably didn't make much sense to you. To explain it, we have to start at the beginning. I promise it'll be interesting.
The button is a feature that the popular social media site Reddit introduced on April 1, 2015. It has its own subreddit at /r/thebutton.
The button looks like this:
<picture class="c-picture" data-cid="site/picture_element-1500881432_3886_25486" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/VZq-kHrxR_nN7kaIyUAP5s6x2Ho=/0x0:570x168/320x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 320w, https://cdn.vox-cdn.com/thumbor/itR7HVANcHzZ_ovI75DMG1nRtdg=/0x0:570x168/520x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 520w, https://cdn.vox-cdn.com/thumbor/n2FE0kaetnDcNW2pDUhZRJfBeVw=/0x0:570x168/720x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 720w, https://cdn.vox-cdn.com/thumbor/Wq0UGalwK5Qm-CLznVEOjGs04vA=/0x0:570x168/920x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 920w, https://cdn.vox-cdn.com/thumbor/OE8Q1yVcxs3MwQuIk8yBbinI6No=/0x0:570x168/1120x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/0ppuxUM0D1le99qt6P9uHEMpePU=/0x0:570x168/1320x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/33UwqDB1jRnAiG96h7mKsfFGUiU=/0x0:570x168/1520x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/dKs6VTDcdCx3hppPU2nB4-nHcCA=/0x0:570x168/1720x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/7k-deXtokEKG8NCaY8rbgEgZ3LI=/0x0:570x168/1920x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/AoGcnr6n9hKb1jy8PrdCajhL4Dw=/0x0:570x168/1200x0/filters:focal(0x0:570x168):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591892/button.0.gif">

</picture>
The actual button is on the left. At the right is a counter, which starts at 60 seconds and counts down to zero. Every time a redditor pushes the button, the counter resets to 60 seconds and begins counting down again.
Only people who had Reddit accounts before April 1 are allowed to push the button. And each user only gets to push the button once.
No one (outside of Reddit staff) knows, because it's never happened. As I'm writing this on Tuesday afternoon, it's been pressed by more than 730,000 people. Because of the combined efforts of these people, the timer has never gotten below 27 seconds.
The button is powered by two of the most powerful forces in human societies: status competition and boredom.
When users post messages on the /r/thebutton subreddit, a colored badge (called "flair" in Reddit-land) shows whether the user has pressed the button and if so, what time the counter showed at the time that user pressed it. If you've never pressed the button, you get a gray "non-presser" badge that looks like this:

People who have pressed the button get a flair that looks like this:

The color indicates how much time was left when you pressed the button — this user pushed the button at 31 seconds and has a coveted yellow badge as a result. If you were impatient and pressed the button with more than 52 seconds left, you get lame purple flair. People who pressed between 42 and 51 seconds get blue flair; 32 to 41 seconds gets green. You can only press the button once, so once you get a badge you're stuck with it for life.
These colored badges have created a virtual status hierarchy. Within the /r/thebutton community, lower numbers are more prestigious. Only a few people have had the patience and good luck to snag coveted yellow flair indicating a timer below 31 seconds. There are also believed to be orange and red flair for when the timer gets below 21 and 11 seconds, respectively, but no one has actually gotten this flair yet.
As I write this, there are a bunch of Reddit users wasting time on /r/thebutton in hopes of joining this elite group.
You can see statistics about how many /r/thebutton posters have achieved each level here. Tens of thousands of lazy people have earned purple flair for times over 52 seconds. Thousands have earned blue or green flair for times between 32 and 51 seconds.
Only a few hundred posters have earned yellow flair, including 38 who pushed the button at 29 seconds, 9 who pushed it at 28 seconds, and just 3 who pushed at 27 seconds. (The actual number of button-pressers is higher for most of these categories, since only those who post a message on the site are counted.)
It's basically a place where people can brag about their low numbers and look down on people unfortunate enough to have higher ones. This being Reddit, people post silly pictures to illustrate how they're feeling about the competition. For example, when the first yellow flair started to show up, someone with a yellow badge posted this GIF under the title "How I feel right now":
<picture class="c-picture" data-cid="site/picture_element-1500881432_5147_25490" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/fGnsjlSCM8p1RuRB6CkLA5CjBOY=/0x0:400x223/320x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 320w, https://cdn.vox-cdn.com/thumbor/_B0ZsjxFsw7uPgOqKaGwSefyYK8=/0x0:400x223/520x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 520w, https://cdn.vox-cdn.com/thumbor/nH8OOjtkXGumzb64A3nh9QpgitA=/0x0:400x223/720x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 720w, https://cdn.vox-cdn.com/thumbor/zSx2-O4YkNLJBNpFXnYHt_eVRKo=/0x0:400x223/920x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 920w, https://cdn.vox-cdn.com/thumbor/2id8mDDikmIaDWI9SPcKY1TOhL4=/0x0:400x223/1120x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/HEUerqRrcTTgnHX9MZws6ggGba8=/0x0:400x223/1320x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/hMBEAQhJmrQ-deQ-mFt8VXtCrYo=/0x0:400x223/1520x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/MpL6QpZ4cTzpPbFh1EQq595T1K4=/0x0:400x223/1720x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/lnWXXAQCSQTKALkEL4Jzwh2V81Y=/0x0:400x223/1920x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/hRk7M_sr6JdHreLfmprcJ-Ysgwo=/0x0:400x223/1200x0/filters:focal(0x0:400x223):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591926/PF09Fnb.0.gif">

</picture>
People also post GIFs like this one to express the frustration of having another user press the button right before they were going to:
<picture class="c-picture" data-cid="site/picture_element-1500881432_8823_25492" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/EsKR3YD6fuSvdVvoi34UVXJ-P_s=/0x0:300x209/320x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 320w, https://cdn.vox-cdn.com/thumbor/gZ5d00hXOVVDTISUAJdVQHOa3tY=/0x0:300x209/520x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 520w, https://cdn.vox-cdn.com/thumbor/VtjR5yM0gXoWIkQHIs0PxgPU9hw=/0x0:300x209/720x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 720w, https://cdn.vox-cdn.com/thumbor/8ZYFCpdKYUJQqwvFA6mnjyJsI5E=/0x0:300x209/920x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 920w, https://cdn.vox-cdn.com/thumbor/fv3_rt6EYNcgsC62cj7GfAP9VYg=/0x0:300x209/1120x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/MrMuWaCOgaikeVjJGJzUeQJOxc8=/0x0:300x209/1320x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/_VotwQXeVbXX5pZHDKafEwMWJ10=/0x0:300x209/1520x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/4pOwkEaTChs1ZHH8XZUdh9sj9hs=/0x0:300x209/1720x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/nctuVt_BmD3557ZUynGHnuivMpg=/0x0:300x209/1920x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/QZATBEr_tABHVcOTgrYTuqMOycQ=/0x0:300x209/1200x0/filters:focal(0x0:300x209):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3591934/oJG3B.0.gif">

</picture>
I thought you'd never ask. I pushed the button on Saturday morning at a time of 31 seconds, earning me some coveted yellow flair:

When I originally posted this story on Friday afternoon, I hadn't pushed the button yet, because getting yellow flair was too difficult. I captured about an hour of button press data around lunchtime on Friday (you can create your own chart here), and it looked like this:

You can see the problem: when the timer got into the 40s, someone almost always got greedy and pushed the button. The lower the timer got, the greater the temptation became to push it. As a result, the button only occasionally made it into green territory (32 to 41) and never fell into yellow territory below 31.
But my patience was rewarded. When I looked again around 8 am Eastern Time on Saturday, there were fewer people on the page, and so yellows were more common, allowing me to snag one.
If you want to get yellow (or even better, orange or red) flair, the key is to do it between 5 and 8 am Eastern Time (2 to 5 am Pacific). That seems to be the time when the fewest people are paying attention, so your odds of getting a low number are at their highest.
As the experiment went on and interest in the button flagged, the timer's value got lower and people set new records. Someone first earned blue flair for a 51-second time on April 3, and green flair started showing up on April 4. People only started getting yellow flair on Friday.
But this week a surge of media interest has caused more people to visit the site. This chart, created by Reddit user Dendrimer14, shows the average rate of button presses between April 3 and April 14:

This shows that in the last couple of days, media attention has driven more people to the site, which has caused the button to be pushed more frequently. As a result, there have been no new records set since Sunday morning's record of 27 seconds.
This can't last forever, though. Sooner or later, interest will dwindle to the point where people can earn orange and then red flair, and then finally the timer might run out altogether. Estimates on how long this will take range from a few more days to many months.
Cabel Sasser, co-founder of the Mac and iOS software company Panic, made an interesting discovery this afternoon — the rarest Apple product of all:

The rarest shipping Apple product, model A1622. It has MagSafe, USB-C, and is used to demonstrate the Apple Watch. pic.twitter.com/EJ4plbvxCF
It carries the same Federal Communications Commission ID as the iPad Mini 2, meaning that it's based on the same internals but has been modified in a number of ways, according to paperwork filed with the FCC:

The German government should go spend a bunch of money on something. Ideally a critically useful infrastructure project, given the country's large apparent needs on that front — but failing that, even a pretty blah project would be good. Or if Germany can't think of anything worth spending money on, it should enact a large cut in its national sales tax. How to pay for it? Easy.
Don't. Because the weirdest story in the economics world just keeps getting weirder.

German 10-year bond yield to go negative, says Citi. Targets -0.05%, vs current record low 0.15%.
Right now on the European continent there are several countries, including Germany and Finland, that have sold bonds that pay negative interest rates. In other words, you give the Finnish government 1,000 euros today and several years later they give you back fewer than 1,000 euros.
This is an extraordinary event, the impact of which has been somewhat blunted by the fact that for years now some government bonds have traded at negative real rates.
That means the rate of interest charged is less than the projected rate of inflation, giving governments the opportunity to essentially borrow for free. That's an unusual situation, but it's always been clearly something that might happen every so often. What's playing out right now where some governments are selling bonds at negative nominal rates — and a much larger group including Netherlands, Sweden, Denmark, Switzerland, and Austria have seen bonds trade at negative rates in the secondary market — is considerably weirder.
Indeed, the interest rate situation in Europe is so strange that until quite recently, it was thought to be entirely impossible. There was a lot of economic theory built around the problem of the Zero Lower Bound — the impossibility of sustained negative interest rates. Some economists wanted to eliminate paper money to eliminate the lower bound problem. Paul Krugman wrote a lot of columns about it. One of them said, "The zero lower bound isn't a theory, it's a fact, and it's a fact that we've been facing for five years now."
Well, think about it. A bond with a negative interest rate is a guaranteed money-loser. Why would you buy one if you can just hold cash instead?
The traditional view has always been that no one would. People thought the interest rate on bonds couldn't fall below zero because at that point people will just hold on to their money.
Well, back in January the Eurozone's central bank launched a program of quantitative easing — in other words, printing money and using it to buy government bonds. This was supposed to reduce interest rates, and it's working.
But here's the catch. The Eurozone has one central bank — the European Central Bank — but there's no consolidated Eurozone debt, no "eurobonds."
So when the ECB goes out and buys bonds, it needs to buy the bonds of its member states — a little Belgium, a dollop of Portugal, a smattering of Finland, a dose of Italy, etc. But one consequence of the Eurozone crisis of 2010–2011 is that people think the Eurozone might break up. If the Eurozone does break up, you're going to be way better off owning the debt of a rich and stable country like Germany than the debt of a country like Spain that's much poorer and facing an uncertain political situation. So whatever the interest rate on Spanish bonds, the rate on German bonds is sure to be lower.
In other words, if the ECB takes steps to make Spanish interest rates really low, then the interest rate on more creditworthy Eurozone countries has to go below zero.
That is the real mystery. The mechanics of pushing interest rates down are easy to see. But why not just hold cash in your bank account? It's not entirely clear what's happening, but here are three major motivations that market insiders say are in play:
The main practical short-term takeaway is that Germany (and other smaller creditworthy European nations) is hurting both itself and the world economy by declining to run a larger budget deficit. As Ben Bernanke explained in a recent blog post, Germany's huge trade surplus is a problem for the global economy because it means Germans aren't buying enough stuff to create job opportunities for non-Germans.
When German politicians hear their surplus criticized, they typically become defensive and say it's absurd to blame them for manufacturing great products that the world wants to buy. But the issue isn't what Germany sells to the world, it's how little Germany buys.
What's more, fixing the problem requires absolutely zero sacrifice on Germany's part. What the world needs from Berlin is for Germany to buy itself a bunch of nice shiny new transportation and energy infrastructure, or else for Germany to give itself a huge tax cut. Not only would shiny new projects and lower taxes be fun, but the message of the negative interest rates story is that by borrowing more money today Germany will improve its long-term fiscal situation.
For the USA, the main implication is that back in 2009 and 2010 the Federal Reserve made a mistake. All the objective economic metrics at the time said the "right" interest rate to curb unemployment would be negative. But negative interest rates are impossible! The Fed tried a few tricks to get around that problem, and also told Congress to try fiscal stimulus as a workaround.
The implication of the European experience, however, is that the Fed could have generated negative interest rates through a mix of Quantitative Easing and negative interest rates.
Wednesday saw the first round of reviews for Apple's first major new product in five years: the Apple Watch. Technology writers for the Verge, the New York Times, the Wall Street Journal, and a few of other media organizations have spent the last week testing the new device (Vox's got lost in the mail, we think), and it turns out there's a lot of consensus on the Apple Watch.
Most found the device more useful than they expected. But the watch didn't get the awed reactions you often see greeting a new Apple product. Instead, reviewers complained the watch was slow, complex, and occasionally a bit creepy — and that its third-party apps were sort of useless. Many found the experience of having a watch that buzzed with every email and like on Instagram overwhelming.
And yet, pretty much everyone could see how the Apple Watch is going to be awesome — even if it isn't awesome quite yet.


Farhad Manjoo. (Internaz)

Apple is famous for its simple and elegant user interfaces, but there was almost universal agreement that the Apple Watch has a steep learning curve. "The Watch is not suited for tech novices," wrote Farhad Manjoo of the New York Times.
The user interface on the Apple Watch has several novel elements. There's a crown wheel on the side of the watch that works something like the scroll wheel on an old-fashioned iPod. The watch also has a new type of gesture called a "force touch" that can call up some watch functions. And it can communicate with the user via subtle vibrations, with different vibration patterns representing different types of notifications — such as a new text message or email.
With one exception, reviewers said it took them several days to figure out these new rules. And even then, some found the experience overwhelming. The Apple Watch has "too many features that are too hard to find," according to the Wall Street Journal's Joanna Stern. CNet's Scott Stein agreed that the Apple Watch has "so many features that I felt a little lost at times."
One recurrent complaint is that, as Bloomberg's Josh Topolsky puts it, "the notification scheme is a little maddening at first. Apple sends a push notification every time you get a corporate e-mail, personal e-mail, direct message on Twitter, message on Facebook, and for interactions in countless other services." He eventually got the situation under control by disabling notifications for some services and creating a VIP list of email addresses worthy of immediate notifications.


The Apple Watch charges using a cable attached to the back. (The Verge)

Apple says its watch will run for 18 hours in a charge, and most reviewers found that to be roughly correct. The watch will generally run for a full day with moderate use, but it'll be close to drained by the time you go to bed. "The battery lives up to its all-day billing, but sometimes just barely," the Wall Street Journal's Gregory Fowler wrote. Users will definitely need to charge the battery at night.
Unsurprisingly, battery life depended a lot on what users did with it. The watch's fitness tracking app seems to be a power hog, and relying on the watch for turn-by-turn directions can also drain the battery. If heavy use does drain the battery prematurely, you can activate a power-saving mode where all functions are disabled except telling you what time it is.
"This is not luxury"
Apple products have always been among the most stylish in the technology industry, but with the Watch Apple the company is competing in a whole new league. Will the watch succeed as a luxury item? Reviewers were skeptical.
Nilay Patel of the Verge (Vox Media's technology site) asked Julia Rubin of Racked (Vox Media's fashion site) to weigh in on the watch. "This is not luxury," she said. "It feels very much like two separate objects that were not designed in tandem. It feels like you have a computer sitting atop a band, which is not the point of a watch."
With that said, most reviewers agree that the Apple Watch is the most attractive smartwatch yet devised. "I’ve worn my fair share of smartwatches and none are as good-looking as Apple Watch," wrote Recode's Lauren Goode. The Wall Street Journal's Stern wrote that "even when the watch face is off, the black sapphire-crystal screen looks elegant."


Lifestyle_20Images.0.html
The Apple Watch competes with dedicated fitness trackers like the Fitbit. (Fitbit)

The Apple Watch comes with two basic apps. "Activity" prods you to be more active throughout the day, while Workout is — well, you get the idea.
This is a crowded market; not only do other smartwatches have fitness features, but there are a ton of dedicated devices like the Fitbit that help people keep track of their personal fitness. While the watch isn't a game changer, reviewers generally found the watch to be a reasonable replacement for these other products. "If you get an Apple Watch, you likely won’t need a Fitbit, too," Goode wrote.
However, there are some notable rough edges. One "feature" nags the user to move around more after an hour of sitting, which reviewers found more annoying than helpful. And while the device does a good job of tracking certain types of workouts — especially those that get the user's heart rate up — it's not as good at tracking others, like yoga.
Probably the strangest feature Apple touted at the watch's unveiling was a suite of apps that allow users to send one another personal messages. These can take three forms: small sketches, brief animations, and recordings of the user's heartbeat.
<picture class="c-picture" data-cid="site/picture_element-1500895427_7728_85106" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/lJ23xtd_Op0ZhKokbztUOxHm5aE=/0x0:212x256/320x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 320w, https://cdn.vox-cdn.com/thumbor/VeCS8y8Jk45yOf_gziTyRRNKzOg=/0x0:212x256/520x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 520w, https://cdn.vox-cdn.com/thumbor/S0Aok2jIpTmEBS9BhxI5rb6EAbY=/0x0:212x256/720x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 720w, https://cdn.vox-cdn.com/thumbor/4uQFQosLnnngEOrQuFv0luMaMRk=/0x0:212x256/920x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 920w, https://cdn.vox-cdn.com/thumbor/JsHNZBsCyxZXoBtAHNMJP8rIWPg=/0x0:212x256/1120x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/YCSs73aW9wStnShkG9Zr21MFdwI=/0x0:212x256/1320x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/OIb4otkgo3WuL2xWVrxAuh2cFuI=/0x0:212x256/1520x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/Jog5zz-UXhB7OGDDLMg1ZO-CZSk=/0x0:212x256/1720x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/XE3oCQoxkLtB9Zk_Cybn3N226O0=/0x0:212x256/1920x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/ltEE148r0wRDja5TaEbB4X8FJQM=/0x0:212x256/1200x0/filters:focal(0x0:212x256):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3587306/creepyemoticon-8f000b7a.0.gif">

</picture>
Reviewers found these communication methods to be exactly as pointless as they sound. Topolsky found the heartbeat feature "weirdly intimate," and described the animations as "neutered, animated GIFs from the late '90s internet."
Multiple reviewers mentioned that friends or family found animations like the one at right creepy. And they found the watch's screen too small to draw sketches that were interesting.
Apple has been beating the bushes to convince companies like Twitter and Uber to build apps for the Apple Watch. Dozens of them have done so. Unfortunately, those third-party apps are "mostly useless right now," as the New York Times's Manjoo put it.
Part of the problem is inevitable growing pains. Developers at these companies have only had a few months to build these apps, so some of them are bound to be crude and lack important functionality.
However, there may also be deeper problem. "Loading an app requires the Watch to pull a tremendous amount of data from the phone, and there’s nothing fast about it," the Verge's Patel wrote. "The Uber app takes so long to figure out where you are that you’re better off walking home before someone notices you staring at your $700 Watch and makes a move."


(Justin Sullivan /Getty)

Indeed, Patel found the watch slow to use across the board. "There's virtually nothing I can’t do faster or better with access to a laptop or a phone except perhaps check the time," Patel wrote.
Fowler also had a speed-related complaint: "The maps app, surely the answer to wandering pedestrians’ dreams, is so slow it makes me want to pull out my paper Rand McNally."
The most important question about the Apple Watch is whether it's actually useful. A lot of people wonder why they'd ever want a tiny computer strapped to their wrists. And on this front, reviewers were consistently positive.
"It took three days — three long, often confusing and frustrating days — for me to fall for the Apple Watch," Manjoo wrote. "But once I fell, I fell hard."
"it’s not essential"
While critics fear that smartwatches will worsen the scourge of people ignoring their real-world companions in favor of the digital world, Manjoo found that the watch did just the opposite. It allowed him to quickly and discreetly get important messages: "My wife told me that I seemed to be getting lost in my phone less than in the past. She found that a blessing."
Different reviewers found different features useful. Some were enthusiastic about the watch's Apple Pay capabilities. Others were delighted by the ability to stream music directly from the watch to Bluetooth headphones, allowing runners to leave their iPhones at home.
Not all reviewers were ready to buy one, however. "The Apple Watch is cool, it’s beautiful, it’s powerful, and it’s easy to use," Bloomberg's Topolsky wrote. "But it’s not essential. Not yet."
WATCH: 'It's finally here- Reviewing the Apple Watch'
The first wave of Apple Watch reviews are out — my favorites are Nilay Patel's at the Verge and Farhad Manjoo's at the New York Times — and they are generally not stellar. Business Insider's Nicholas Carlson sums them up as brutal. I have not been favored with a review watch, so I'm not in a position to support or contradict anything the reviewers write. But reading them I'm reminded that reviewing a product is different from forecasting the prospects of a new line of products.
It sounds like the Apple Watch that's being released this spring is pretty meh — intriguing in some ways, but underpowered and inessential — but also that "the Apple Watch" as an ongoing category is positioned for success as future versions fix the flaws of today's model.


Of course, any company's dream review is, "This thing is amazing, you should go get it." But if you don't achieve that dream, there are three basic ways you can fall short:
The Apple Watch reviews definitely aren't making the first claim — Josh Topolsky says Apple "has succeeded in making the world's best smartwatch" and Patel calls it "the first smartwatch that might legitimately become a mainstream product, even as competitors flood the market." And I don't think they are making the second claim. Nobody is saying they had the watch on for a week and never thought to glance at it. It definitely has some value.
So what's the problem? Patel puts the basic criticism very clearly.
It's slow:
Let’s just get this out of the way: the Apple Watch, as I reviewed it for the past week and a half, is kind of slow. There’s no getting around it, no way to talk about all of its interface ideas and obvious potential and hints of genius without noting that sometimes it stutters loading notifications. Sometimes pulling location information and data from your iPhone over Bluetooth and Wi-Fi takes a long time. Sometimes apps take forever to load, and sometimes third-party apps never really load at all. Sometimes it’s just unresponsive for a few seconds while it thinks and then it comes back.
That's not great. And since almost every person on planet Earth has been getting along fine without a smartwatch, it stands to reason that relatively few people are going to want to shell out $349 to $10,000 to buy a slow and unresponsive one.
That said, anytime a company rolls out a brand new category of consumer electronics and the big complaint is that it's too slow, I think you are making a fundamentally bullish call. Apple's stock tanked 0.6 percent this morning when the reviews came off embargo (a small percentage, but over $4 billion in market capitalization) before rebounding slightly, and I think the rebounders have it right. After all, the one thing we can be really sure of in the digital realm is that computer manufacturers will be able to manufacture faster computers tomorrow than they can make today.
In software development, people talk about the idea of a minimum viable product: something that's good enough to be usable, so that future improvements can be informed by actual use.
Apple has taken to doing a hardware version of this with its new product categories. I was one of the people who rushed out to buy the first iPhone as soon as it was available, and boy was it slow. The original MacBook Air was so comically underpowered I'm a little shocked anyone ever bought it. And the new thinner MacBook with high-resolution display is, again, really slow.
Most people — the vast, overwhelming majority of people — probably won't want to buy the Apple Watch. But again, this is the one area where we can be sure of improvement. Stuff that "sometimes" takes a long time on this watch will do so more rarely on the next one. Things that take "forever" to load on this watch will load faster on the next one.
People forget that technology products typically start this way. The iPhone was introduced in 2007, and across its first 12 months of availability, Apple sold about 5.3 million iPhones. By the third quarter of 2009, the company sold 5.2 million iPhones in a single quarter. In the first quarter of 2012, it sold 37 million. In the first quarter of 2015, it sold 74.5 million.
The original iPhone, in other words, wasn't a very compelling value proposition. It was expensive and slow. But it was also the best smartphone in the world, and over time the number of people who wanted to buy the best smartphone in the world kept growing as the underlying technology improved.
For the Apple Watch to be a hit, it needs to clear two similar bars. None of today's reviews seem to dispute the idea that Apple has, in fact, made the best smartwatch around. Nor do they really seem to dispute that it could be cool to carry around a computer on your wrist. That leaves Apple in a fundamentally strong position to sell millions and millions of watches over the years.
New York City is currently in the process of constructing a $4.5 billion Second Avenue subway line. The project is important: it will deliver  much-needed relief to the overcrowded Lexington Avenue subway line in a city that is utterly dependent on mass transit to move people around.
But is the multibillion-dollar subway line actually necessary? There's a strong case for adding a second subway line to the Upper East Side, but Yonah Freemark points out that in terms of pure congestion relief one could accomplish almost as much by adopting a different form of international best practice — open gangway railcars, a technology that's been standard on foreign systems for over a decade yet is virtually unknown in the United States.
Open gangway on the Toronto Rocket
American metro trains are composed of separate cars that don't directly connect to one another. Consequently, passengers cannot safely move from one car to another without first exiting at a station. By contrast, in an open gangway system the cars are linked in a way that allows riders to safely step from one car to the next.
This has two main benefits from the standpoint of system capacity:
In New York right now, about 9 percent of the length of Lexington Avenue trains is the space between the cars where nobody can ride. The increase in capacity due to improving the rolling stock is almost equal to the 14 percent reduction in crowding promised by the Second Avenue subway. Obviously, building an additional subway line has some advantages beyond congestion — it'll be much more convenient for people who live on Second Avenue or points east — but elsewhere around the country there are many lines that could use more capacity but don't have the population density to support an entirely new parallel tunnel.
Of course, simply replacing all the cars in a major metro system would itself be very expensive. Indeed, it would be downright wasteful. But every so often, every city needs to order some new cars. This leads to a slow but steady replacement of older equipment with newer vehicles. And in 75 percent of non-US systems, there are now at least some open gangway trains plying the rails.
They are in brand new systems in China and very old systems in Germany. They are everywhere. Because the overall replacement process is slow, it's easy to miss how widespread open gangways have become as a procurement priority. But it's fair to say that they have become the standard in new mass transit railcars.
Meanwhile, in the United States, they are used in Honolulu and ... nowhere else. And no cities have plans to introduce them.
Freemark runs through various technical objections to the use of open gangway cars in the United States and finds them wanting. If this were a single example, it would be tempting to give American transit operators the benefit of the doubt and assume they must have some good reason for rejecting this technology. But the truth is that it's just a small part of a wider and troubling trend of mass transit isolationism.
Everyone knows European cities have, in general, superior mass transit to American ones.
But American agencies are remarkably resistant to the idea that they should try to adopt some best operational practices from abroad. Amtrak has passengers board trains in a bizarre manner, America builds brand new mixed-traffic streetcars that are universally rejected abroad, and America rarely uses proof-of-payment fare-collection systems.
It's understandable that the United States, which is very large, tends to be somewhat insular across a wide range of topics. But when it comes to mass transit when we are so clearly not the world leader in usage or performance, cutting ourselves off from the rest of the world is a costly error.
Here's some great news: the number of job openings just hit its highest mark since January 2001. As of February, there were 5.9 million job openings in the US economy, the Labor Department reported Tuesday.
That new opportunity is good news for the jobless: the number of unemployed people per job opening is at its lowest point since late 2007, with less than 1.8 unemployed people per job opening.
Federal Reserve Bank of St. Louis
But there's also some not-so-great news in Tuesday's release: while job openings are heating up, hiring isn't speeding up quite as fast.
Federal Reserve Bank of St. Louis
This continues a trend that my colleague Matt Yglesias pointed out last fall. So what's going on? It might be that there's a skill mismatch — that the workers who are available just aren't qualified for the work employers are offering. And that's probably true in some higher-skill industries.
But a lot of it is probably also hesitancy from employers. Clearly they are open to hiring (hence all the job postings), but they're taking their time doing it  — and not raising wages much in an attempt to lure in workers. One possibility is that employers, who still have a huge number of unemployed and underemployed Americans out there to pick from, are still waiting for perfect candidates to come along. This has been a problem throughout the recovery.
Last Friday's jobs report was also something of a disappointment, showing that hiring slowed way down in March. One disappointing jobs report doesn't necessarily spell doom ... but what this data does make clear is that there's plenty of room for more hiring, and it's not happening.
The concept of in-flight wifi is amazing. The idea that you can connect to the internet while flying through the air at hundreds of miles per hour is incredible.
In practice, though, it's pretty disappointing: the wifi access currently offered aboard most planes is terribly slow and fairly expensive.
you're splitting a tiny amount of bandwidth with dozens of people
Gogo, the provider used by most US airlines, charges steep prices for a very slow service that you can't use to stream video. There's one basic reason it's so slow: when you use it, you're splitting a tiny amount of bandwidth, beamed up from towers on the ground, with dozens of other users on your plane.
But the good news is that a few airlines — JetBlue and Southwest — offer faster satellite-based alternative services, and Gogo is currently implementing its own, to be rolled out across several airlines over the next couple of years. These services won't equal the speed of networks on the ground, but they just might be worth paying for.

More than 1,500 planes run on Gogo's ATG (Air-to-Ground) system, which relies on a signal that's sent up from ground towers and received by an antenna on the bottom of the plane. (Gogo)
The Gogo-based wifi offered by most US airlines (including American, Delta, United, US Airways, and others) runs on what's called an Air-to-Ground (ATG) system. More than 1,500 planes use it, and Paul Thompson at Jalopnik has a great rundown of it here.
Gogo's ATG service sends up a signal from a network of 200 or so towers stationed in North America. As your plane passes over these towers, an antenna affixed to the bottom of it picks up a signal they send out, and other equipment converts it to a wifi network that covers the cabin.

An ATG antenna. (Matthew Lammers)
The problem is that the data signal's bandwidth — and thus the total amount of data that can be transmitted — is fixed, and quite small. The top speed is 3.1 megabits per second (Mbps), which by modern standards is extremely slow: it's about a tenth as fast as what you get with a phone on Verizon or AT&T's 4G networks. On about 500 planes, upgraded antennas allow Gogo to run a slightly faster service, called ATG4, but it still only has a top speed of 9.8 Mbps.
What makes both these services even slower is that this tiny bandwidth is getting divided among dozens or more users. It's as if you're sharing a single cellphone with a hundred or so people.
As Allison McCann at BuzzFeed has pointed out, the shared signal also gives Gogo incentive to charge more money: if everyone's on it, the network will become borderline unusable, so one solution is setting the price high enough so that only a minority of passengers will buy it. Though standard Gogo prices are $16 for a full day and $5 for an hour, the company has experimented with surge pricing, charging $10 per hour on Virgin flights from New York to San Francisco, which see a disproportionate number of passengers buy the service.

(Allison Joyce/Getty Images)
Right now, the easiest way to get a faster in-flight wifi connection is to fly Southwest or JetBlue, which use services other than Gogo.
Southwest's wifi is provided by a company called Row 44. Instead of towers, the signal is sent up from a handful of base stations to a network of geostationary satellites (the same kind used for satellite TV services). These satellites send a signal over the Ku frequency band to a much larger, more complex antenna on top of the plane.
these airlines use satellites instead of ground towers
Row 44's service isn't nearly as fast as what you'd get on the ground, but it's better than Gogo's. Row 44 doesn't advertise specific numbers, but it's estimated to have download speeds between 1 and 5 Mbps per user. It's also cheaper: Southwest charges a flat fee of $8 per day.
Some JetBlue flights, meanwhile, offer wifi provided by a company called ViaSat. It's also satellite-based, and works a lot like Southwest's — except the satellites broadcast on a newer, different frequency (called the Ka band), which can carry more data, making the network much faster as a whole.

JetBlue's planes receive a signal sent out by satellites over the Ka frequency band. (Digi-Key)
ViaSat advertises speeds as high as 12 Mbps per user, and passenger reviews have confirmed it's quite fast. JetBlue has signed up sponsors to keep costs down, and offers the service for free, although you have to pay $9 per hour if you want to stream video or download large files. United also offers ViaSat's service on a handful of flights.
There is, however, a downside to satellite-based networks: latency. When you send a request to load a webpage, that signal has to travel 22,000 miles or so up to a satellite, and then the actual data has to travel the same distance down. That means there's a detectable delay (about 800 milliseconds or so to make the round trip), even though the page loads faster as whole.

But the real reason most airlines haven't yet adopted these faster satellite-based systems is that it costs more to install the antennas and other infrastructure needed on planes — and because many are locked in long-term contracts with Gogo, which was one of the first companies to market a few years ago.

Gogo's new GTO system will use both satellites and ground antennas. (Gogo)
The good news here is that Gogo is currently rolling out a few different networks that should dramatically speed things up on other airlines.
Gogo already operates a Ku band satellite-based system on a handful of international Delta flights, and plans to expand it over the coming year. It advertises maximum speeds of 30 Mbps per plane, which wouldn't match JetBlue's ViaSat service but would be a big step up from what's currently offered. Eventually, Gogo plans to install dual Ku band antennas on many planes, which will boost speeds further.
Gogo's hybrid system will use both satellites and ground towers
Even better, though, will be Gogo's Ground-to-Orbit (GTO) network, which the company says it plans to roll out over the next few years on US domestic flights. It'll be a hybrid system: the data downloaded by your computer will come from a satellite network, but the data uploaded will be sent down to the ground-based network.
Reserving the plane's satellite antenna solely for downloads will boost speeds. And because requests your computer sends out won't have to go all the way up to space and back (they'll get sent directly down to towers on Earth), it'll cut down on latency.
Gogo claims this GTO will allow for up to 60 or 70 Mbps of download bandwidth. That might be a bit of an exaggeration, but Engadget tested a mock-up version of GTO and experienced download speeds of 40 Mbps.

Of course, this would get split among dozens of users throughout the aircraft, so it still won't feel nearly as fast as your wifi network at home. But it'd definitely be a big improvement on what's currently out there.
Rand Paul is expected to make monetary policy and the malignant influence of the Federal Reserve a major theme of his 2016 campaign for president. These hard-money views, popularized by Paul's father in the last two presidential campaigns, are also popular in the Bitcoin community. Many Bitcoin fans see the decentralized virtual currency as an alternative to the dollar.
So it's not surprising that Rand Paul is accepting bitcoins on his campaign website. Supporters can also pay by credit card and PayPal.
The transactions are being handled by BitPay, a startup that has signed up more than 100,000 merchants to accept Bitcoin payments. And this means Paul may not be holding onto any of the bitcoins supporters donate; BitPay offers the option to immediately convert payments into dollars, which are deposited into a conventional bank account.
Paul is capping Bitcoin donations at $100. Supporters who want to give more than that amount have to pay using more traditional means such as credit cards.
Most laptops today have a built-in camera above the display. And most of those have a small light next to them that is supposed to turn on to alert the user when the camera is active. But a couple of years ago, researchers discovered that this doesn't always work; hackers can activate the camera on certain MacBook models (and probably some other laptops) without enabling the light and tipping off the user.
Ever since writing that story, I've had a precautionary Post-it Note over my laptop's camera. Newly minted presidential candidate Rand Paul is using concerns over laptop camera privacy to promote his campaign:

Paul's campaign has dubbed this the "NSA Spy Cam Blocker," urging supporters to "stop hackers and the NSA with this simple camera blocker."
I don't think there's been any proof that the NSA spies on people using webcams, but this isn't a crazy concern. We've known since 2013 that the FBI had technology to remotely activate targets' webcams and stream images back to the authorities.
Private-sector creeps have also jumped on the camera-hacking bandwagon in recent years. There's a whole underground community of men who trade tips and software for hacking into young women's laptops to capture naked pictures of them.
So Paul's webcam protector is a savvy bit of marketing. It provides a useful service (though a small Post-it Note will do the same job for a lot less money) and underscores an important theme of his campaign, while its prominent position above supporters' laptop screens will constantly remind them of his candidacy.
Starbucks has announced that it will offer hefty tuition reimbursements to its employees. The program will cover the full cost of an online degree with Arizona State University for employees working 20 hours per week or more, the Wall Street Journal reports. This expands a program announced last June, when the company only offered to partially cover the first two years of tuition, then the final two years fully. Altogether, the company says it could spend up to $250 million on the program by 2025, expecting to benefit 25,000 workers.
That's a nice perk for Starbucks employees, there are two big reasons why this is great business for the corporation as well. One is the tax benefits that come from compensating employees with tuition money rather than salary. In addition, the program benefits employers by attracting the kind of high-quality employees who are likely to be drawn to a tuition benefit.
starbucks' new program isn't about altruism; educational reimbursement can be great for employers
Starbucks is far from the first company to offer a tuition benefit — in fact, the company had, before this program, offered around $1,000 per worker in educational reimbursement. But now they will be spending an unusually large amount on it.
"It's very generous. Most large organizations will provide tuition reimbursement up to $5,250" — the line at which the IRS starts taxing the benefits for both the employee and employer, says Bruce Elliott, manager of compensation and benefits at the Society for Human Resource Management.
Around 54 percent of all companies offer some form of educational reimbursement, according to one SHRM survey.
In addition, many companies that offer reimbursement tend to only offer the assistance for programs that will specifically boost their performance at work, as the Wall Street Journal reports. Starbucks, meanwhile, will allow employees to choose their programs, which could potentially help them leave the company in the future.
The Starbucks offer is extended to both part- and full-time employees — anyone who works 20 hours or more per week, and it has no strings attached. Employees who take the company up on the offer are not under any obligation to stay at the company after that.
However, Starbucks' new program isn't about altruism. Research shows educational reimbursement can have big benefits for employers. One reason is taxes. The first $5,250 in tuition benefits accrue to workers tax-free, making tuition payments a way to get more bang for your compensation buck.
But another issue is that different employees will value a tuition benefit differently, and tuition assistance might disproportionately appeal to higher-quality workers. In a 2002 NBER working paper, Wharton School of Business Professor Peter Cappelli studied Census data and found that employees who use tuition assistance are more productive than their peers.
In addition, those extra abilities are not readily visible to most other employers who are competing for talent; the very act of offering tuition assistance draws in people with those higher abilities. An employer doesn't have to go looking for them.
That's not the only way tuition assistance can sort great employees into a firm. It may also have to do with a worker's "discount rate" — that is, how much the employee values a dollar today versus that dollar's payoff in a few years, as University of Minnesota professor Colleen Flaherty-Manchester wrote in a 2012 paper. The sorts of employees who take advantage of tuition assistance are more willing to hold out for that eventual payoff, she writes.
This benefits a company through employee retention — the workers who take advantage of the degree programs have an added incentive to stick around. This is great for firms, as it can be very expensive to replace an employee: a 2012 assessment from the left-leaning Center for American Progress found that replacement on average costs around 21 percent of a worker's annual salary, though some estimates have ranged above 100 percent.
"this is really a way to develop their quote-unquote 'farm team' for future roles within the organization"
And the savings will likely come not only from retention but from hiring; expanding the pool of educated Starbucks employees means expanding the pool of promotable Starbucks employees.
"If you think about it, it's much cheaper to hire from within than it is to hire externally, especially at the management level," Elliott says. "This is a way really to develop their quote-unquote 'farm team' for future roles within the organization."
The only downside, he adds, is the potential cost to Starbucks. It's hard to know right now how many workers will take the company up on its offer, but the pool of potential ASU students is large. As CNN reported last year, around 70 percent of the company's 135,000 store employees don't have undergraduate degrees.
New data from the Bureau of Labor Statistics lets us see the average pay for every major occupational group and also the distribution of pay at each level for these groups. It's pretty cool:

There are no huge shockers here, but a couple of interesting things. One is that even though "sales and related" positions is a pretty low-paying field, the top 10 percent of salespeople get paid like the top 10 percent of a considerably more upscale profession. My guess is that if the data got more granular and showed you the top 1 percent of salespeople, you'd see that pattern continue. That's what commissions will get you.
The flip side of that is computer and mathematical occupations, which are way up by the top but seem to have a relatively low-paid top 10 percent. Anyone who reports on the business world at all has heard about the "war for talent" that's allegedly happening in Silicon Valley, but you don't really see superstar salaries getting paid in this field. That's possibly because it's all going into stock options instead of wages, but maybe higher cash payouts are something companies waging this war should consider.
Neighborhood walkability has been a huge asset for commercial landlords during the recovery from the 2008 recession. Moody's and Real Capital Analytics have a cool dataset that lets you break down commercial real estate prices by WalkScore.
You can see that whether it's in suburbs or in central business districts, prices have rebounded from the recession much more strongly in walkable areas than in car-dependent ones:

(Moody's)
This may have to do with consumer tastes, but it probably also has to do with the mix of businesses that walkable versus car-oriented places can support. The steady rise of Amazon and other e-commerce outlets has been hard on the kind of retail businesses that are optimized for large parking lots. Bars, restaurants, and homey shops that don't compete directly with Amazon work better in walkable areas.
Whatever the cause, one natural consequence of disproportionately rising prices in walkable areas ought to be the construction of new walkable neighborhoods. The problem is that modern parking regulations often make it impossible for new neighborhoods to have the walking characteristics of older ones.
When Google first announced its plans to offer 1-gigabit-per-second broadband service back in 2010, it seemed ridiculously fast. At the time, many households had broadband speeds that were 100 times slower, and only a handful of cities had residential internet service anywhere close to 1 gigabit.
Today, Google offers gigabit in Kansas City, Austin, and Provo, Utah, and it's gearing up to offer service in several additional metro areas in the next couple of years. At the same time, incumbent cable and telephone companies have become a lot more interested in offering high-speed broadband service.
The latest example is Comcast, which announced Thursday that it would be offering 2 Gbps service in the Atlanta metropolitan area. It's probably not a coincidence that Atlanta is one of the metropolitan areas Google has selected for future expansion of its own broadband service.
AT&T has also gotten religion on gigabit broadband service in the last couple of years. The company introduced gigabit service in Austin (a Google Fiber city) in 2013, and announced last year that it would eventually expand the service to 21 cities.
Time Warner Cable has yet to join the gigabit club, but it is also in the process of dramatically increasing broadband speeds. Last year the nation's second-largest cable provider announced that it would increase its top speed tier by a factor of six, from 50 Mbps to 300 Mbps. Lower speed tiers will also see dramatic improvements. The upgrades began in New York City and Los Angeles in November, and are expected to expand to additional cities in 2015 and 2016.
The great thing about this from Google's perspective is that by directly supplying gigabit service in a handful of metropolitan areas, Google can prod incumbent broadband providers to offer faster service in areas where Google isn't directly operating. It would raise too many awkward questions if AT&T and Comcast only upgraded to gigabit speeds in Google Fiber cities. Both Comcast and AT&T have promised to offer gigabit speeds in cities where Google isn't competing. That's good for Google because faster internet connections will make all of Google's online services work better.
Disclosure: My brother is an executive at Google. Also, Comcast Ventures is an investor in Vox Media, the parent company of Vox.com.
Update: Based on a helpful tip, I added a paragraph about Time Warner Cable's recent speed increases.
WATCH: 'Ezra Klein recaps February's big net neutrality developments'


This chart from the Bureau of Labor Statistics shows the 10 largest occupational groups in the United States, plotted against their mean annual pay — nurses are up there making $70,000 a year, and all the rest are way lower:

(Bureau of Labor Statistics)
As you can see, there are basically two outliers here. Retail sales personnel are way more common than any other kind of job, and registered nurses are far better-paid than any other commonly practiced occupation. And for people and communities thinking about the future, this is likely to be a pretty robust result. Nursing jobs aren't going to be outsourced to Asia, tomorrow's older population will need more nurses, and technological advances will likely let nurses and other mid-skill medical professionals shoulder more of the load of overall health-care provision.
Hospitals are the factories of the modern economy, and nurses are the modern-day equivalent of the well-paid middle-class factory worker. It's a difficult job that requires commitment, discipline, and hard work, but it's not a winner-take-all superstar economy, and there are lots of positions available.
You don't want to read too much into a single monthly jobs report, but there's no denying that the latest news from the Bureau of Labor Statistics was disappointing. Employers added a meager 126,000 jobs, and the previous two months' worth of reports got downward revisions. It's not time to panic yet, but one lesson from the weak month ought to be that talk of an early interest-rate hike from the Federal Reserve is misguided and that the palpable desire of some stakeholders to raise rates at the first sign of bad news is itself a source of trouble.

Looks like construction was a culprit in weak payrolls number. -1k jobs, after averaging +35k in previous two months.


The construction sector took a notable turn for the worse, as developers apparently slowed their interest in new projects.

. @charlescwcooke more TK but manufacturing slowing due to strong dollar, wages stuck so no spending so no hiring, energy sector cuts


Meanwhile, the surging value of the dollar relative to other major world currencies weighed on the manufacturing sector.
No one month is a sure thing. But the conjunction of a domestic construction slowdown with a currency-induced manufacturing slowdown is a telltale sign of tight monetary conditions. And until the Fed clarifies its messaging around the relationship between economic recovery and higher interest rates, we are going to be stuck on this see-saw where every multi-month run of good news is swiftly followed by a fallback.
Elite thirst for a rate hike essentially guarantees that any decent economic run will lead to an immediate runup in the price of the dollar and plentiful concern about medium-term interest rates. Those, in turn, will lead to a joint slowdown in manufacturing and construction. That will pull the recovery back down to earth, and push the timing of the first Fed rate hike out further.
To achieve liftoff, the Fed needs to say that it wants liftoff.
And that after a multi-year run of inflation below its 2 percent target rate, it is prepared to keep interest rates low until there is clear and compelling evidence of an inflation problem. That will let investors know that good news is simply good news, and there's no need for every two steps forward to be followed by one step back.
McDonald's announced Wednesday it was raising the wages for tens of thousands of McDonald's workers nationwide. But the company didn't just announce the feel-good news that it's giving workers higher pay, not to mention paid leave — it also pointed out that its high-profile wage hike will only affect workers at the 10 percent of its stores that are company-owned.
The company emphasized in its press release that the other 90 percent of stores wouldn't be affected, as Vox reported yesterday: "The more than 3,100 McDonald's franchisees operate their individual businesses and make their own decisions on pay and benefits for their employees."
McDonald's isn't just being open about its business model here; it's making a point that it sees itself as separate from its franchisees. And that makes sense when you understand the legal battle heating up this week at the National Labor Relations Board.
The very nature of the company's relationship to its workers is in question in that case, and it could have massive implications for franchises nationwide.
One of the big points of franchising is to create a mutually beneficial relationship: the franchisee benefits from the parent company's brand and well-known products while also getting to make his or her own business decisions. And franchisers, meanwhile, can get more rapid growth and more revenues, without dealing with day-to-day minutiae of managing all these smaller outlets. Meanwhile, both sides give up some measure of control — a franchisee follows franchiser rules about what it serves, for example, while the franchiser gives the franchisee some independence in hiring, firing, and scheduling.
But the NLRB is trying to decide right now whether McDonald's is more than just a distant parent company to its franchisees. The question is whether McDonald's is a "joint employer," along with its franchisees.
NLRB hearings began this week that could help determine the answer to this question. In December, the board issued complaints against the company, alleging (among other things) that it retaliated against workers who protested in favor of higher wages. In naming McDonald's as a joint employer, the NLRB's general counsel, Richard Griffin, is essentially arguing that if McDonald's has enough control over its restaurants, it should have to also share in the liability of labor law violations. Griffin has also argued for a broader definition of what it means to be a "joint employer."
Because of its rules governing day-to-day operations at its restaurants, from the use of scheduling software to bag folding, some have argued the company is just as much an employer to its workers as franchisees are.
And if a franchiser is not a joint employer, under current law, that means it also plays no part in other issues that can happen at the franchisee level — like negotiating with unions or, say, setting the pay of workers.
As it stands now, the decision to boost pay could put franchisees in a bind, the New York Times writes. On the one hand, the franchisees could feel the pressure to raise their own wages. But one anonymous franchisee told the Times that "business in his restaurants had been 'horrible' and that he did not see how he could increase his employees’ pay."
This question of who is a joint employer isn't just about franchisers and franchisees. The question of the increasingly "fissured workplace" has become a central one in the US labor market. David Weil, now the administrator of the Wage and Hour Division at the Department of Labor, argued in a 2014 book that as businesses have distanced themselves from workers through means like subcontractors and temp agencies, shrugging off their roles as direct employers, it has led to lower wages, worse benefits, and growing inequality.
In addition to the McDonald's cases, the NLRB has yet to rule on another high-stakes case involving waste management firm Browning Ferris. The question in this case is whether Browning Ferris is a joint employer and therefore has to negotiate with unionized workers at a subcontractor. In this and the McDonald's case, the broader question of what it means to be an employer is at stake. And as attorney Michael Lotito told me in December, this could have "cataclysmic" effects on the nearly 9 million US workers who work in franchises, not to mention the relationship between contractors and subcontractors and even between businesses and their suppliers.
"It has a way of upsetting these business relationships and employers thinking they were separate suddenly finding they are combined," he said. "That has just enormous implications for business relationships."

McDonald's announced Wednesday that it would raise its entry-level wages at company-owned stores and allow workers with one year or more of tenure to earn paid time off, in a move that the company estimates will affect 90,000 workers at the roughly 1,500, or 10 percent, of its US stores that are company-owned. The move will raise average wages at McDonald's stores from $9.01 per hour now to $9.90 in July and to more than $10 in 2016, the Wall Street Journal reports.
The move comes as a slew of other massive, low-wage service-industry employers, most of them in retail, also announce their plans to raise wages. These companies' decisions to raise wages may be important signs that the job market is finally picking up steam and that employers have to compete for workers by offering higher pay. Higher wages have been a missing piece of the economic recovery until recently.
Higher wages can also be a good business decision, as it can mean lower turnover and higher productivity.
McDonald's has been one of the chief targets of minimum wage activists in recent years. While McDonald's wages will be nowhere near the $15 per hour many of those activists want, the move could boost the company's image. And the company's image arguably needs a boost. CEO Don Thompson quit in January amid plummeting earnings, as fast-casual restaurants continue to eat into the company's customer base. The image problems extend into labor relations, as well. Just this week, National Labor Relations Board hearings started in which McDonald's is accused of retaliating against workers who organized for higher wages.
That hearing raises the question of whether McDonald's is a "joint employer" along with its franchisees and therefore is liable for its franchisees' actions. The wall between the parent company and franchises is intact in this decision to raise wages — the 90 percent of McDonald's stores that are operated by franchisees (and not the company itself) won't be affected by this decision.
When Ellen Pao launched her high-profile lawsuit against the venture capital firm of Kleiner Perkins Caufield & Byers, she became a hero to feminists who believe Silicon Valley has a pervasive problem with workplace sexism. But while Pao provided some vivid examples of sexist attitudes by some of her male Kleiner Perkins coworkers, a jury found that she hadn't proved that these attitudes were the reason she wasn't promoted as quickly as some of her male colleagues.
While Pao's case might be over, the broader debate about gender discrimination in Silicon Valley will continue. Women at Facebook and Twitter have alleged that they missed out on opportunities because of gender discrimination.
Pao's loss in court showed that women can face an uphill battle in proving their claims in court. Many legal experts agree that proving to a jury that an atmosphere of sexism affected particular hiring and firing decisions is difficult. Meanwhile, there are fears that these sorts of cases will lead companies, fearing lawsuits, to hire fewer women.
But even when companies "win" these lawsuits, they still lose in the court of public opinion. A jury might have ruled that Pao didn't prove her case, but the lawsuit still persuaded a lot of people that Kleiner Perkins has a dysfunctional company culture, which could harm its reputation for years to come.
So smart managers should be thinking about ways to change their company culture so women never become frustrated enough to file these lawsuits in the first place. One way to do this is with data. By collecting detailed data on their hiring and promotion practices and analyzing it carefully, these companies can better understand where they're falling short on gender equality.
Sometimes proving discrimination is easy. Pao's case is often compared to the 1982 case of Price Waterhouse v. Hopkins. Ann Hopkins, a Price Waterhouse employee, was denied partnership despite stellar performance. When she asked for feedback, her employer gave her memorable advice: "Walk more femininely, talk more femininely, dress more femininely, wear makeup and jewelry, have my hair styled," as she later described it.
The firm admitted to giving her this advice, and with that evidence on her side, Hopkins later won the case.
That kind of smoking gun, as it were, is missing from many gender discrimination cases. One of the most common takeaways people have drawn from the Pao case is that subtle sexism is too hard to prove in courtrooms. That's true, but several of the incidents in the Pao case were anything but subtle.
One of Pao's coworkers, Trae Vassallo, testified that a male partner came to her hotel room on a business trip in a bathrobe and with a glass of wine one evening. Pao said that her mentor, John Doerr, said she had a "woman chip on her shoulder." Women at the firm weren't invited on a ski trip that all of the men went on, nor were they invited to a company dinner because, as one man commented, "women kill the buzz."
But Pao wasn't able to prove that those instances directly and substantially connected to her lack of promotion.
"Just the fact that defendants engage in some bias doesn’t establish that it was the cause of plaintiff’s lack of advancement," says Deborah Rhode, director of the Center on the Legal Profession at Stanford's law school. "It's not at the level of intent. No one at Kleiner Perkins said, 'We don't want women at the partnership level.'"
That said, there were also incidents in Pao's case where reasonable people could disagree about whether sexism was involved, as New York Magazine's Annie Lowrey has written. Women were asked to take notes at meetings, and Pao was criticized for having "sharp elbows," which may have been an inadvertent commentary on the distastefulness of a woman having an aggressive personality.
It's not that the law won't allow juries to award damages because of that subtler sexism, explains one expert.
"If a plaintiff can show that she lost out on a promotion because of implicit bias, she is entitled to prevail under the formal law. The problem is that it's hard to prove, and judges and jurors are typically looking for more overt proof," says Samuel Bagenstos, a professor at the University of Michigan law school.
Not only is sexism hard to prove in court, it's also hard to recognize and stop in the workplace. Especially in a male-dominated workplace, it can be easy to perpetuate subtler forms of sexism without even trying. Asking women to take notes may seem innocuous to some men, but it perpetuates ideas of women as filling peripheral, secretarial roles. Interrupting women is another example of this sort of inadvertent sexism, as Sheryl Sandberg has written.
None of this is to say that Pao should have won — Kleiner Perkins made a strong case that Pao was denied a promotion because of performance reviews, and jurors have cited those reviews as playing a key role in their decisions.
But there is a case to be made that low-grade, chronic sexism can worm its way into performance reviews, and that it may have in the Pao case.
"There was a fair amount of evidence to suggest that her personality was not a good fit for the firm. But I think you have to ask yourself what about the firm's culture made it a poor fit? And was she judged by a different standard from her male colleagues? And that's where I think her evidence was strong," says Rhode. "John Doerr famously said that she had a female chip on her shoulder, but I think it was the firm's responsibility to ask how it got there. And what about the culture was unwelcoming to women?"
As the Pao case shows, proving that sort of thing to judges and juries can be difficult. But more important, if a firm — or an entire industry — is truly committed to eliminating sexism, it doesn't want to go before a jury or pay out multimillion-dollar settlements. Undertaking the kind of introspection that Rhode describes will likely be the key. And there's one easy way to spot a lot of it: statistics.
"One thing you could do, which I am fairly in favor of, is look at, be really aggressive in looking at numbers," says Bagenstos. "You see if there are bottlenecks in the process where the demographics get skewed in one way or another, and those are the places where you say, 'Aha. It looks like something funky is going on here.'"
Bagenstos adds that judges and legislators tend to have an instinctive "quota-phobia," refusing to put affirmative-action policies into practice. Even absent hard quotas, however, companies should be looking hard at a wide range of metrics to see where they can do better (and if not, why not).
Some tech companies are already partway there, reporting their gender breakdowns publicly. Google acknowledges that it's a heavily male, mostly white company: "We’re not where we want to be when it comes to diversity."
But it's not just about hires — it's about pay grades and promotions. Companies should be looking at their numbers to determine whether the women they hire on are rising through the ranks as quickly as the men. And if women are falling behind on a companywide basis, it may be time to ask why that's happening. If enough women's ideas aren't being put into practice, it could be that those women are being silenced in meetings. Much sexism may be subjective, but numbers are an easy and concrete way to start rooting it out.
Google in fact is a model case of this — when the company found that women weren't promoted to better jobs as often as men, they discovered that the women weren't good at self-promotion. When the company started encouraging women to nominate themselves for promotion, the women started moving up the ladder.
To be clear, focusing on the data at Kleiner Perkins may not have gotten Ellen Pao a promotion. And data is only a first step at trying to eliminate sexism. But what data can do is prevent bad patterns from developing. And if enough women are around (particularly in positions of power), it becomes impossible to go on a ski trip without bringing them along.
If you're over 30, you probably have fond memories of "Pac-Man," "Donkey Kong," and "Space Invaders." You might have fond memories of "Pong," too. What if you could play all four games simultaneously?
A new game called Pacapong lets you do just that. Sort of:
<picture class="c-picture" data-cid="site/picture_element-1500895457_7143_25746" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/UqgI3saPBB2-G59ghETqkM9NC0Y=/0x0:960x540/320x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 320w, https://cdn.vox-cdn.com/thumbor/kknYkpzcJM-yRjxYgzdT-8BPt00=/0x0:960x540/520x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 520w, https://cdn.vox-cdn.com/thumbor/_hej7_0A7Sv7O_t1GnADxUBdBnM=/0x0:960x540/720x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 720w, https://cdn.vox-cdn.com/thumbor/CClhUI0zpSHv7zuyuo034cFVtoE=/0x0:960x540/920x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 920w, https://cdn.vox-cdn.com/thumbor/l15HU4oyshxr4EB-sjUWw3D2-mk=/0x0:960x540/1120x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/eZkjYSC6gJKCvtaxkXIC2RrfaMM=/0x0:960x540/1320x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/fjHE5ADCM3Q98lLfOsg4YU7xJYI=/0x0:960x540/1520x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/imL-2PB5d4qbMVMPOmPWPEBwtRs=/0x0:960x540/1720x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/mjLa6rH59_aZhPRrkPLdoGlhbvM=/0x0:960x540/1920x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/eP2bHHG8XfvCyi7hzfMvBldQjUU=/0x0:960x540/1200x0/filters:focal(0x0:960x540):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562884/sHNCKX.0.gif">

</picture>

(King Penguin)
You use Pong paddles to fire Pac-Man into the map, picking up points along the way. If your Pac-Man picks up a space invader, it triggers an alien attack on your opponent. And every once in a while, Donkey Kong shows up and throws some barrels around the screen:
<picture class="c-picture" data-cid="site/picture_element-1500895457_4117_25748" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/Ya-GFoQxRS7QnYyfYr1FrRxRBAY=/0x0:636x357/320x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 320w, https://cdn.vox-cdn.com/thumbor/8IMYs0SfDXMQhTRFARM_VearyaA=/0x0:636x357/520x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 520w, https://cdn.vox-cdn.com/thumbor/-ZdRjuv3yR0nFFqi-pEqJhd3BAg=/0x0:636x357/720x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 720w, https://cdn.vox-cdn.com/thumbor/UrHiifAeE7IvT3qlC7OCDKagSJg=/0x0:636x357/920x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 920w, https://cdn.vox-cdn.com/thumbor/5iISlEFbwBQAiVXxidhFEt2faqE=/0x0:636x357/1120x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/pcU6WHzwf6iQzxVE_O3QXLnqBVk=/0x0:636x357/1320x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/gFKRxXXGeCOFOU5TNTGNxS2PvrA=/0x0:636x357/1520x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/DkCbZvVg2IUX-yc3dPUudQb6MpM=/0x0:636x357/1720x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/Y-bHBQdn7lsZsqQgodlBpqjBCB8=/0x0:636x357/1920x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/0OmNBIrlXLknwazI8huzp6JIzx8=/0x0:636x357/1200x0/filters:focal(0x0:636x357):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3562890/vknaxxfky1cr0x8cjy8a.0.gif">

</picture>

(Kotaku)
The game, created by a group called King Penguin, is an application for Mac or PC. Any time you download software like this, there's a risk it will contain malware, so caveat downloader.
Ford has been enjoying a decent run of business lately thanks to the enormous popularity of its F-150 trucks plus some smaller sedans. But one sign that the company still exists in a somewhat fallen state is that its Lincoln luxury sub-brand is still a minnow compared to the major German and Japanese luxury marques.
The company is hoping to change that with the latest edition of the Lincoln Continental, announced yesterday in concept version in New York.
But there's an interesting twist. Ford's plans for reviving a once-iconic American brand are all about China — where chaffeurs are cheaper to hire and Lincoln doesn't have a tarnished reputation.

(The Verge)
The new Continental has a classic external style and a not-super-impressive V6 engine. But the interior and especially the back seat really stand out. It features a mini desk with a built-in touchscreen that offers seat controls, an entertainment system, and some not-yet-specified communications functions. A person sitting in the back can control the front passenger seat to make more room for himself, and the right rear seat features a footrest that can expand at the expense of the front passenger.
Which is to say that this is a car whose target market is people who are driven around by a chauffeur.
Such people exist in the United States, of course, but it's rare. For one thing, few people can afford it. But beyond that, America has a car culture and even prosperous people often want to put their luxury money behind a car that's fun to drive rather than a car that's optimized for backseat sitting. BMW markets itself as the Ultimate Driving Machine, not the Ultimate Riding Around Machine.
In China, the situation is a bit different. Wages are lower, so it's much cheaper to hire a  driver there than it is in the United States. And because the whole country was so poor so recently, few Chinese people have the kind of multi-generational commitment to driving that's common in the US. Over there, the thinking goes, the kind of person interested in paying a premium price for a premium car really is interested in sitting in the back seat.
China is already the world's largest market for cars overall. In the luxury segment, it's number two behind the United States. Even with Chinese economic growth slowing down, it's a fair bet that the growth in the Chinese luxury market will be enormous as it matures.
At the unveiling event, Lincoln President Kumar Galhotra reportedly told journalists that even though luxury cars are only 9 to 10 percent of all cars on the road they represent almost one-third of all profits.
The less polite version of the case for the China-first strategy is offered by Robert Wright of the Financial Times who says "Lincoln has built much of its strategy around appealing to Chinese consumers who have not been put off the brand by the decades when it focused on poor-quality vehicles popular mainly with US car services."
The focus is on China, in other words, because the Lincoln brand is tarnished in the United States.
Here in the company's home market, perception of the Lincoln brand is heavily influenced by the now-defunct Town Car — a very large but not especially high-quality vehicle optimized for fleet sales. Not so much a true luxury item for the chauffeur set as a moderately classy ride to the airport. One question for Lincoln is whether this chauffeur luxury market genuinely exists. By the numbers, after all, the #1 luxury brand in China is BMW — just like in the United States.
That suggests that as the Continental shifts from concept car to production model, actual driving quality will still be the key to its success. If Lincoln hopes to truly compete with the top luxury brands — rather than recreating the Town Car under a new name — they need to make a car people want to drive, not just be driven around in.
Amazon has a new product that seems so simple, it's hard to believe it's a product at all:

It's called the Amazon Dash Button. It's a small plastic device with a button and a light. When you press the button, it sends a message to Amazon to order a refill of some product, like a new bottle of Tide laundry detergent or a new order of Gillette razor blades. And that's all it does.
Dash Buttons have adhesive backs, and the idea is you'd stick them near the place where you store each product. So you'd put the Tide button on your washing machine, the Cascade soap button on your dishwasher, the Folgers coffee button on your coffee machine, and the Gillette razor button inside your medicine cabinet. That way, as soon as you notice you're running low, you can push the button to order more, saving you the minute or two it would take to browse Amazon's website to find that same product.
I don't know if the Dash Button is going to be a big hit. But regardless, it's a good example of how the plummeting cost of computer chips can change how people interact with computers.
Amazon's website doesn't have a lot of technical details, but the Dash Button appears to be a tiny, battery-operated computer with a built-in wifi chip, capable of connecting to the internet, just like your laptop, iPad, and Kindle can.
Two decades ago it would have been crazy to build a product like this. A PC capable of connecting to the internet cost $1,000 to $2,000. Because most families could only afford to own one or two PCs, they were designed to be all-purpose machines with a wide variety of applications.
By the end of the last decade, costs had fallen to the point where you could build an internet-connected computer for $100 to $200. Now, a typical family could afford to buy 10 or 20 of these devices instead of just one or two. So we started to see more single-purpose computing devices: Kindles for reading, iPod Touches for listening to music, wifi baby monitors for keeping track of sleeping infants, and so forth.
Yet these devices were still expensive enough that it only made sense to buy one if it provided a lot of value. People aren't going to spend $200 on a device they only use a few times a year.
But prices have continued to fall. We're now getting close to the point where you can build an internet-connected computer for $10 or $20. Suddenly, applications that seemed frivolous at $1,000 or $100 look sensible. It would be silly to spend $100 or $1,000 for a light bulb that you can turn off with your smartphone, but if it only costs $10, it might be worth it.
And this is also cheap enough to open up a lot of new business-model options. You might not be willing to pay $10 or 20 for a button that automatically orders Tide detergent, but I bet Tide would be happy to buy it for you!
And there's every reason to expect these costs to keep falling. If current trends continue, internet-connected computers will only cost $1 or $2 by the 2030s. At that price, no application will be too frivolous. Expect the average family to have dozens, and probably hundreds, of simple connected devices.
And in this sense, the Dash Button is the future of computing. People will still have PCs and smartphones, of course. But the vast majority of the computing devices they own will be single-purpose devices that cost just a few dollars.
Amazon has made it almost effortless to purchase a book, an iPad, or thousands of other physical products. You find the product you want online and order with one click, and it shows up at your door a few days later.
Now Amazon is trying to do the same thing for personal services like plumbing, lawn mowing, and music lessons. Amazon Home Services, which has been under development for the past year but officially launches today, promises to let people order personal services in much the same way that they've always ordered physical goods, complete with customer reviews and a money-back guarantee.
But it won't be easy to make ordering services online as effortless as ordering physical goods. While iPads come in a few well-defined models, every plumbing job is different. A lot of companies have tried to sell services online, and so far none of them has figured out how to make the process as easy as ordering a book online.


(David Ryder/Getty Images)

In the past, when you needed to hire someone to trim your trees or change your oil, you'd pull out the Yellow Pages and make a call. The internet has changed this process in some respects — you're more likely to use Google or Craigslist rather than the phone book — but the customer is still forced to do a lot of the work himself. Customers need to check a provider's references, verify that they're properly licensed and insured, and negotiate a fair price. For many customers, it's a stressful and intimidating experience.
A number of technology companies have been trying to make this process easier. Angie's List started out as a Yelp-style review site for services, but in recent years it's increasingly acted as a middleman, matching customers with service providers directly. Amazon competitor eBay launched a service called eBayHire in 2013, though it seems to have abandoned the product since then.
There are also newer startups, including TaskRabbit and Thumbtack, that help customers order services online.
Amazon brings two big assets to this already crowded market. One is its brand. As the nation's largest online retailer, Amazon has earned the trust of millions of American consumers. In a market where customers are nervous about getting subpar services, the Amazon brand could help put skeptical customers at ease.
Second, Amazon has a lot of experience partnering with third-party providers. While Amazon's original business model was to sell products it owned from its own warehouse, much of the company's recent growth has been from listing products from third-party providers on its site. So Amazon knows how to recruit third-party providers, vet them for quality, field customer complaints, and make the entire process seamless for users.
According to TechCrunch, Amazon is working with some of these smaller service startups, such as TaskRabbit, to help deliver services to customers.


(MyLoupe/UIG via Getty Images)

There are a lot of successful startups that sell physical products like shoes and sunglasses. But the services market seems to be a tougher nut to crack.
A big reason for this is standardization. When you sell physical products, you often have to keep track of a lot of different variations — a single line of shoes, for example, can come in many colors and sizes — but they're still well-defined and standardized. So when you order shoes online, you can tell exactly what you're getting.
But services are performed by individual human beings, which makes them inherently difficult to standardize. The fact that a plumbing company did a good job on my neighbor's toilet last week doesn't guarantee that it will do a good job on mine this week, since it might not send out the same guy.
"They’re shoehorning local services into the same way they treat other products," Thumbtack CEO Marco Zappacosta told Forbes. "What about building a deck? Your deck is going to be different than my deck and your backyard is going to be different than my backyard."
A lot of services have this character: it's impossible to say exactly what a professional can do and how much the service will cost without a personalized evaluation. And that runs against the grain of Amazon's business model, which is all about using technology to streamline the purchasing process.
Still, there are probably some services that can be standardized. For example, Amazon's move into services began with a pilot program that was focused on installation of products customers had bought. If you bought a flat-screen TV, Amazon would offer to connect customers with a professional who would mount it on the wall. That's a simple enough service that it probably is possible to offer uniform pricing. The big question is whether this is the norm or a rare exception.
The Census Department published new population figures for 2014 this week. KQED says that "The Bay Area Is Getting Way More Crowded," and made this map to show the trend; the reddest areas are the places where population is growing fastest.

KQED isn't wrong. The population of the Bay Area grew 1.3 percent last year, which is a lot better than the 0.7 percent average annual growth rate the Bay Area has seen since 2000.
But it's also important to keep a sense of perspective: 1.3 percent is not a very impressive growth rate. The population of the Houston metropolitan area grew by 2.4 percent between 2013 and 2014. The Dallas metro area grew by 1.8 percent during the same period. Greater Atlanta grew by 1.5 percent.
And these southern cities have been growing faster than the San Francisco Bay Area for more than a decade. Between 2000 and 2010, the Bay Area grew by about 5 percent. Houston, Dallas, and Atlanta all increased their populations by more than 20 percent.
The crazy thing about this is that while Atlanta, Dallas, and Houston all have perfectly healthy economies (Houston especially has benefited from an oil boom for much of the last decade), none of them compare Silicon Valley's.
Google, Apple, Facebook, and other internet giants are growing fast, and they're desperate to hire more engineers. The Bay Area should be comfortably topping the population-growth charts among large metropolitan areas. And the rising wealth of the region's technology elite should be boosting demand for schoolteachers, doctors, chefs, barbers, landscapers, nannies, and others in service jobs. That, in turn, should trigger a massive building boom, creating jobs for construction workers. Hundreds of thousands — perhaps millions — of people outside of high-tech should be benefiting from the boom.
But that hasn't really happened. Strict building regulations have made it impossible to significantly increase the Bay Area's housing stock. So rising tech industry wealth is mostly translating into higher housing costs. Middle-class people outside the tech sector are finding it harder to pay the rent and impossible to buy a house.
This isn't inevitable. San Francisco's population density is about half of Brooklyn's, and the rest of the Bay Area is a lot more sparsely populated than San Francisco. The region could be growing a lot faster than 1.3 percent per year if local officials — in San Francisco and especially in Silicon Valley's myriad low-density residential towns — wanted to. But so far they haven't chosen to do so.
Today, the Bureau of Economic Analysis released some moderately disappointing news about the economy, saying we enjoyed a 2.2 percent growth rate in the fourth quarter of last year. That's an okay number, but it's a slowdown from where we were in the third quarter and adds up to an overall very "meh" 2014.
But the White House Council of Economic Advisers takes a more optimistic view of the trend, and their case has some merit.
CEA chair Jason Furman is touting this chart:

(Council of Economic Advisors)
As you can see, by this measure the economy is speeding up rather than slowing down. But is it a good measure?
GDP is something you've probably heard of, while the chart's number — real private final domestic purchases — is awfully obscure. But it's arguably a better indicator of where things are going. Private final domestic purchases means you basically remove three things from the GDP number:
The idea is that these three factors can show a ton of moment-to-moment instability. They matter in the long run, but in the short run they arguably mostly add noise to the picture. When you strip them out, you see an economy that is still not doing amazingly well, but is definitely on an upward trend.
One of the biggest energy stories of the last decade has been the vast oil boom in the United States. But how long can it last?
When oil prices were soaring during the mid-2000s, energy companies found it highly profitable to use fracking, horizontal drilling, and other techniques to extract oil from shale formations in places like Texas and North Dakota. The result: a glut of oil and a major crash in global oil prices back in 2014.
What's surprising, though, is that US oil output has kept growing even though oil prices have fallen by half since last summer. On March 25, the US Energy Information Administration announced that US crude production rose yet again to 9.42 million barrels per day — the highest level since 1973:

(Energy Information Administration)
This is pretty astonishing. After all, it costs more to frack oil from shale rock in North Dakota than it does to pump out oil from conventional fields, like those in Saudi Arabia or Kuwait. So, when prices were dropping last year, many onlookers figured it would wipe out the US oil industry. (Some Saudi officials were reportedly hoping this would be the case.) Yet America's oil production has stayed remarkably resilient.
US oil drillers have certainly been affected by the recent crash. The price of West Texas Intermediate fell from $95 per barrel in July 2014 to less than $50 per barrel today. The result? It's less profitable for many companies to keep pumping for oil in difficult shale formations the way they used to.
To some extent, you see this in the data. The number of active drilling rigs has been declining steadily since the crash. On March 20, according to data from Baker Hughes, there were 825 active oil drilling rigs in the United States. That's plummeted from 1,473 rigs a year ago. Here's a chart from Business Insider:

(Chart: Business Insider, Data: Baker Hughes)
But that hasn't translated to a decrease in US oil production yet. Why is that? As the Energy Information Administration explains, when oil companies start idling their drilling rigs, they generally start with the older, least-efficient rigs first. That's then offset by output from the remaining rigs, which are in the most productive, oil-rich regions.
What's more, as Ed Crooks recently reported in the Financial Times, US oil companies are finding ways to pump oil more efficiently. They're putting pressure on suppliers to cut costs. They're adopting new techniques and technologies like "pad drilling," which allows them to drill multiple wells in tight clusters with fewer rigs. Add it all up, and oil output per rig has risen 29 percent in North Dakota's Bakken region and 30 percent in West Texas's Permian Basin.

An oil pump-jack is viewed on March 26, 2015, in the oil town of Gonzales, Texas. (Spencer Platt/Getty Images)
That dynamic can't last forever, though. Most of the oil wells drilled in the shale regions of North Dakota and Texas tend to produce a lot of crude very early on and then start declining sharply within a few years. (Output from a typical well in the Bakken declines by 65 percent after the first year.)
So over time, oil producers will need to keep drilling new wells to maintain production. But it's costly to drill a new well, and low oil prices make this a less-attractive proposition at the margins. Companies like EOG Resources and Hess have already announced cuts to capital spending this year.
The EIA, for its part, recently noted that this crunch has already started to hit certain shale regions, albeit unevenly. Crude oil production in the Permian Basin in West Texas is expected to rise through April 2015. But production in other shale regions, like the Bakken in North Dakota or Eagle Ford in East Texas, is expected to decline slightly:

(Energy Information Administration)
Indeed, while the recent growth in oil production has been impressive, last week's gain was actually the smallest since January. And the International Energy Agency expects US oil production to plateau sometime in the middle of this year, at least if prices stay around $60 per barrel. (If, say, the ongoing conflict in Yemen causes a surge in global oil prices, that would presumably give a boost to US drillers.)
That said, there's a big difference between a plateau in oil production and a massive drop-off. Officials at OPEC, the massive oil cartel that includes Saudi Arabia, have been predicting a decline in US oil production this year. (They've also been hoping for a drop-off, since it would cause oil prices to rise and augment their budgets.)
So far, US oil producers have been defying expectations. Whether they can continue to do that will go a long way toward determining how oil prices unfold in the near future.
The big news in politics today is that Senate Minority Leader Harry Reid (D-NV) is retiring from Congress at the end of the current term, and has endorsed Sen. Chuck Schumer (D-NY) to succeed him as Democratic leader in 2017. One group that's surely celebrating this announcement is advocates of patent reform.
In 2013, the House of Representatives passed the Innovation Act, which would make it easier for companies to defend themselves in patent lawsuits. The legislation was designed to combat the problem of patent trolls — companies that make their money by threatening patent lawsuits rather than by making useful products. The idea enjoyed the support of Sen. Patrick Leahy (D-VT) and several senior Republicans in the Senate.
But last May, Leahy announced that he was shelving his patent reform bill, and insiders told me he did this at Reid's request. Reid has a close relationships with trial lawyers' groups, who opposed the bill. Plaintiffs' lawyers were concerned that the bill's "loser pays" provision — which allows winning defendants in patent cases to collect legal fees from plaintiffs — could later be expanded to apply to non-patent cases.
By contrast, Schumer is an advocate of patent reform and was one of Leahy's key allies in the patent fight. That makes sense given his constituency; New York is home to both Wall Street and a lot of technology startups, and both groups are frequent targets of patent trolls.
On a lot of issues, it doesn't really matter who the party leaders are because their caucuses already have strong opinions. Harry Reid was personally pro-life, but he's been forced to reflect the views of his overwhelmingly pro-choice caucus. But patent issues aren't like that. There are Democrats on both sides of the issue, and a number of senators who don't have a strong opinion on the issue one way or the other. So who leads the Democrats can have a big impact.
Of course, if Republicans pass a strong patent reform bill this year — which they might — then this could be a non-issue by the time Reid's successor takes over in 2017. But given how slowly the legislative process moves, there's a good chance this will still be a live debate if and when Schumer takes charge.
Three of America's four largest airlines — American, United, and Delta — have teamed up with the labor unions representing their workers to form a coalition called Americans for Fair Skies, which is demanding US government action against three major airlines based in the Persian Gulf that are cheating on existing international agreements. Bill Shuster, the Republican chair of the House Transportation Committee, says the complaint has merit, and the Obama administration has agreed to review the matter.
The key complaint from the American airlines is that their three state-owned Gulf competitors — Emirates, Etihad, and Qatar — receive government subsidies that violate the terms of the existing Open Skies agreements between the US, the United Arab Emirates, and Qatar.
But the real stakes are less about legal details than about whom US transportation policy should favor: American aviation workers or American travelers. A crackdown on Gulf airlines could mean more jobs and higher pay for US-based aviation workers. But it could also mean higher prices and less choice for American international fliers, especially those bound for Asia.
Since 2001, the US has had an agreement with the government of the United Arab Emirates giving UAE-based airlines (specifically Emirates and Etihad) access to American airports, and vice versa. We have a similar agreement with Qatar, home to Qatar Airways. One stipulation of these agreements is that governments on both sides pledge not to subsidize their airlines.
The goal of these Open Skies deals is to create a free, open, and undistorted market in international air travel with traffic between the US and Doha (or Abu Dhabi or Dubai), won by whichever airline does the best job of providing a compelling deal for passengers.
Delta, America, and United have alleged for some time that Emirates, Etihad, and Qatar are all breaking this agreement. In March, they made their complaint formal and detailed to Robert Wright of the Financial Times and US government officials their specific concerns based on what's known about Gulf airline finances:
Against Emirates
Against Etihad
Against Qatar
The Gulf airlines counter that equity investments are not subsidies, that cheap labor and cheap airport fees simply reflect a pro-business policy environment, and that discount loans are the equivalent of the airline industry bailout Congress approved in the wake of 9/11's disruption to the industry — financial assistance that arguably violated the terms of the Open Skies deal.
The Economist's Gulliver blog makes a game effort to adjudicate the claim, but the basic reality is that there is no agreed-upon legal standard the US airlines' complaint needs to make. This is not a case that falls under World Trade Organization jurisdiction. It's simply up to the American political process. If the US government wants to cancel the Open Skies agreement it can, and if it doesn't want to it doesn't have to.
The political decision American officials need to reach is whom US aviation policy should benefit: US-based airlines or international air travelers. The stakes in the dispute are high because over the past 10 to 15 years the Gulf-based airlines have grown enormously.

(Chart by Eshna Basu, data from IATA)
The real issue is not so much direct transportation between the US and the Gulf airlines' hubs, but rather the massive business all three airlines do in connecting Western travelers to Asia and vice versa.
In other words, will a traveler from DC to Shanghai switch planes in California or in the UAE?
Regardless of why the Gulf airlines have been so successful, their success has been a boon to long-haul air passengers and a disaster for competing airlines. This is true whether their market share has been gained through savvy marketing decisions or through under-the-table subsidies.
Cheaper long-haul flights to Asia primarily benefit more affluent people, whereas the US-based airline industry's workforce is solidly middle-class. So one can see this as a case for a crackdown. On the other hand, the growth of Gulf airlines has been excellent news for America's airplane manufacturing industry and for US tourism, so the ultimate distributive consequences of a crackdown are by no means clear.
The logic of Gulf airlines' side of the case could be taken even further. The current Open Skies deal gives the Gulf carriers the right to fly from an American city to Doha or Dubai, but not to Boston or Baltimore. Foreign-owned carriers flying domestic routes inside the United States is called cabotage, and it's generally not allowed in order to protect the American airline industry.
But with limited competition keeping airfares high despite falling oil costs, it might be beneficial to take some of that protection away. After successive waves of bankruptcies and mergers, America's domestic airlines have become very cautious about expansion in a way that restrains competition and keeps fares high. The Gulf airlines, whether subsidized or not, have a spirit of gung-ho expansion that suggests they'd like to fly just about anywhere they're allowed.
Right now, it isn't on the political agenda to take advantage of the Gulf's eagerness to increase routes in order to boost competition on US domestic routes, but it could be. For now, though, all the momentum seems to be on the other side.
WATCH: 'The better way to board an airplane'
Today, everyone takes it for granted that you can type text into a computer and edit it on the screen. But this wasn't always such a commonplace activity. Indeed, it used to seem downright miraculous, as this 1982 passage by James Fallows in the Atlantic shows:
When I sit down to write a letter or start the first draft of an article, I simply type on the keyboard and the words appear on the screen. For six months, I found it awkward to compose first drafts on the computer. Now I can hardly do it any other way. It is faster to type this way than with a normal typewriter, because you don't need to stop at the end of the line for a carriage return (the computer automatically "wraps" the words onto the next line when you reach the right-hand margin), and you never come to the end of the page, because the material on the screen keeps sliding up to make room for each new line. It is also more satisfying to the soul, because each maimed and misconceived passage can be made to vanish instantly, by the word or by the paragraph, leaving a pristine green field on which to make the next attempt.
Computers have improved so much over the past three decades that it's hard to even describe the difference. The computer Fallows owned in 1982 had 48 kilobytes of memory. That was enough to store a few pages of text, but it would be too little to hold many modern webpages or even a single high-resolution photo. I'm typing this on a MacBook Air with eight gigabytes of memory — more than 100,000 times more.
And the comically underpowered computers people bought in 1982 were expensive. Fallows spent about $4,000 for his, which would be more than $10,000 in today's dollars. In contrast, my MacBook Air cost me about $1,200.
(Hat tip to Kevin Roose)
Apple cofounder Steve Wozniak is the latest technology luminary to predict that computers will eventually take over the world and relegate humanity to a subservient role.
"Like people including Stephen Hawking and Elon Musk have predicted, I agree that the future is scary and very bad for people," Wozniak said in an interview with Australian Financial Review. "If we build these devices to take care of everything for us, eventually they'll think faster than us and they'll get rid of the slow humans to run companies more efficiently."
This argument is superficially plausible: humans are the smartest species on earth, and we also dominate all other species. So if you built machines that are smarter than humans, they'd be able to dominate us just as easily.
But if you think about who has power within human societies, the theory that intelligence leads to power seems more dubious.
If this theory were true, societies would be run by their scientists, philosophers, or chess prodigies. Instead, America — like most societies around the world — has been run by men like Ronald Reagan, Bill Clinton, and George W. Bush. These men became powerful not because they were unusually bright, but because they were well-connected, charismatic, and knew how to offer the right combination of carrots and sticks to get others to do their bidding.
It's true that brilliant scientists have played an important role in creating powerful technologies such as the atomic bomb. And it's conceivable that a super-intelligent computer would conceive of similar breakthroughs. But building new technologies and putting them into practice usually requires a lot of cash and manpower, which only powerful institutions like governments and large corporations can muster. The scientists who designed the atomic bomb needed Franklin Roosevelt to fund it.
The same point applies to intelligent computers. Any plausible plan for taking over the world would require the cooperation of thousands of people. There's no reason to think a computer would be any more effective at enlisting their assistance for an evil plot than a human scientist would be. Indeed, given that persuasion often depends on longstanding friendships, in-group loyalties, and charisma, a disembodied, friendless computer program would be at a huge disadvantage.
Correction: In the caption I misidentified Steve Wozniak as Apple's CEO rather than its cofounder.

Kraft is probably best known for its mac and cheese and Heinz is definitely best known for its ketchup, but both companies are portfolios of brands. The companies released a handy infographic to summarize everything the new company controls:

While Warren Buffett has traditionally taken a "buy and don't change much" approach to acquisitions, the hallmark of 3G's management of Heinz has been firing lots of workers. There were the August 2013 layoffs, the April 2014 buyouts, the November 2014 layoffs, etc.
One suspects part of the value Buffett bought to the table in the Heinz purchase is that his folksy persona helped obscure the extent to which foreign investors were taking over an iconic American brand to sack its employees. Finding redundant back-office staff to lay off is generally a priority in any merger, and putting the Heinz management team in charge is a good sign that there is ruthlessness to come.
The more optimistic take on the merger is that this combines Kraft's products with Heinz's platforms. The background here is that the current version of Kraft is the result of a corporate split, in which a giant food conglomerate became two companies. One of those companies, Mondolez, controls an international portfolio of snack brands. New Kraft, by contrast, is very focused on supermarket products targeting the US market — Velveeta, Jell-O, Oscar Mayer, etc.
Heinz has a narrow range of products, but it is very global. The new company says it wants to fuel "global expansion" by "combining Kraft's brands with Heinz's international platform." In other words, they think they can use Heinz's distribution network to place Kraft products in foreign supermarkets, where its various wares may have more growth potential than in the mature American market.
Google has hired Morgan Stanley CFO Ruth Porat to be its new CFO. Neil Irwin notes that this is part of a broader trend of talent shifting from Wall Street to Silicon Valley.
In Irwin's view, this is a positive trend. Obviously, Wall Street performs an important function in channeling investments to companies that need them. But Irwin argues this is still a "back-office function," like legal services or human resources, that doesn't directly create wealth for consumers. On this view, an overgrown finance sector acts as a drag on the economy, so talent shifting to Silicon Valley is a positive sign.
A contrary view, expressed by Tim Fernholz, is that big Silicon Valley firms are simply becoming more like big Wall Street firms. Fernholz suggests that instead of creating innovative new products and services themselves, technology firms are increasingly acquiring technology companies that would have succeeded anyway and then claiming credit — and a bunch of profits — when they do.
There's some merit in both perspectives. But I think it's a mistake to draw a sharp distinction between innovation on the one hand and Wall Street–style financial engineering on the other. It's absolutely true that a lot of what Wall Street does — like, say, buying a company, loading it up with debt, and then reselling it — doesn't create value for society.
But most high-tech dealmaking isn't like that. There are a lot of ambitious startups in Silicon Valley that have a kernel of a good idea but lack the resources — both financial and otherwise — to turn that idea into a successful product. Like Wall Street banks, big Silicon Valley companies bring cash to the table. But unlike banks or conglomerates, technology giants also bring other things, like technical infrastructure, ownership of complementary products, and a brand that helps push little-known technologies into the mainstream.
Two examples help make the point. One is Android, which Google acquired in 2005. You could say Google "merely" bought Android and then managed it well as it grew into the world's most popular mobile OS. Yet it's hard to imagine almost any other company doing this so successfully. Google brought a lot to the table, from apps like Google Maps and Chrome to a corporate culture and reputation for innovation that made it easy to hire and retain the best programmers.
The same point applies to Siri. It was an innovative technology before Apple acquired it in 2010, but it wasn't obvious how it could succeed as a stand-alone product. Making Siri part of iOS not only put it in the hands of a lot more customers, but also made it a lot more useful, since it could be deeply integrated with other features of Apple's mobile OS.
Of course, a finance person like Porat isn't the most important ingredient in this kind of deal: the key decisions — which companies to buy and what do with them — need to be made by people with more technical expertise. I'd be worried if Silicon Valley companies started to hire Wall Street bankers to be their CEOs.
But people like Porat can expand a company's capacity to make deals like this. Lawyers aren't the key to building a successful technology company, but a successful tech firm is going to need smart lawyers to write contracts. Similarly, they need people to make sure companies have the capacity in place to make acquisitions quickly and efficiently.
Disclosure: My brother is an executive at Google.
After I wrote about my week as a Lyft driver back in December, the most common feedback I got was that I should have written about Lyft's (and Uber's) problems with insurance. Traditionally, the car insurance market has been divided between commercial insurance policies for people who use their cars to earn a living, like taxi and limousine drivers, and personal insurance for everyone else. But ride-sharing drivers too often fall into a legal gray area: their personal insurance won't cover accidents that happen while drivers are on the clock, but full commercial insurance was too expensive for part-time drivers to afford.
Uber and Lyft have stepped in with their own insurance policies that cover drivers most of the time they're working for the ride-sharing companies. However, there have still been gaps in coverage that can leave drivers exposed. Drivers have sometimes been caught in the middle of disputes between Uber and insurance companies about who should cover which accidents.
The new framework is designed to eliminate these gaps by establishing a clear set of rules for which accidents can be covered by personal insurance policies and which ones must be covered by either Uber or drivers.
The framework may also provide a boost for a new breed of supplemental policies being offered by a growing number of insurance companies. In January, both USAA and Farmers Insurance announced a limited ride-sharing plan that covers a driver between the time "driver mode" is enabled and the time the driver accepts a hail (at which point full coverage from Uber or Lyft kick in). GEICO began offering a ride-sharing plan in Maryland last month. The cost of the coverage is fairly modest — USAA plans to charge just $6 to $8 per month. The Farmers ride-sharing option is expected to boost drivers' premiums by about 25 percent.
Update: I've updated this post to reflect Uber's confirmation of the deal first reported in Insurance Journal.
Plaintiffs aren't required to spell out their arguments in much detail at this phase of litigation, so each lawsuit is just three pages long. But the documents still provide a hint of the kinds of arguments opponents will raise. It looks like the telecom companies will raise every major legal argument that has been raised against the FCC proposal in recent months:
Supporters of network neutrality dismissed the lawsuit as groundless. "The cable and telecom lobby have to deal with the fact that Title II is the right law for services like broadband Internet access," said Matt Wood of Free Press in an email statement. He called Title II of the Communications Act a "rock-solid basis for the Open Internet rules adopted last month."
Monday's filing is the first step in a long legal process. After Verizon sued to stop the last round of network neutrality regulations in 2011, it took more than two years for the issue to be settled by a federal appeals court. So we should expect litigation over this issue to hang over the FCC for the remainder of the Obama administration. But the FCC will have the authority to enforce the rules unless and until the courts order it to stop.
Wifi usually works so well that most people never give it much thought. You set up a wifi device in your house, and — as if by magic — every device in the house is connected to the internet.
But the technology has real limitations. Wifi chips can communicate only on certain frequencies, and as the technology has gotten more popular, those frequencies have gotten more and more crowded. Sometimes this causes download speeds to slow to a crawl.
New legislation from Sens. Marco Rubio (R-FL) and Cory Booker (D-NJ) aims to address this problem by expanding the number of frequencies wifi chips can use to communicate. However, the new frequencies have been slated for use in advanced car-to-car communication technology that could help prevent car crashes in the future. The big question is whether it's possible for these technologies to coexist.


Sen. Marco Rubio (R-FL) (MANDEL NGAN/AFP/Getty Images)

When you use the mobile service offered by companies like Verizon or T-Mobile, your communications are sent using frequencies that are set aside for the exclusive use of that company. These frequencies don't come cheap. For example, the FCC just wrapped up a big spectrum auction that generated $45 billion in revenues for the federal government.
Wifi is different. It uses frequencies that have been designated for unlicensed use, meaning that anyone can use them for any purpose, so long as they follow certain "rules of the road." This is why many wifi networks don't require a subscription — the spectrum needed to run them is open to the public.
But the federal government has only provided a limited number of "channels" for wifi communication. In sparsely inhabited areas, this isn't a problem, as there's plenty of spectrum to go around. But in dense urban areas, competition for capacity can be fierce. For example, right now there are 17 different wifi networks within range of my laptop. Two or three of them are mine; the rest belong to my neighbors.
the federal government has only provided a limited number of "channels" for wifi
The effect is similar to what happens at a crowded party: the more people (or mobile devices) there are trying to be heard, the harder it is for any single "speaker" to get a message across, especially from across the room.
At parties, there's nothing to be done but stand closer together and shout louder. But with wireless networks, there is an alternative: allocate more frequencies for use by wifi chips. That's what Booker and Rubio's legislation would do.
Currently, wifi networks in the United States (and much of the world) use two different frequency bands. Most older wifi chips communicate at frequencies between 2.4 and 2.5 GHz. Newer chips can also broadcast at frequencies between 5.1 GHz and 5.825 GHz (though not all of the frequencies in this latter range are available yet — the FCC has been working for years to open more of these frequencies for wifi uses).
Booker and Rubio's legislation would encourage the FCC to widen that second band further, opening frequencies between 5.825 GHz and 5.95 GHz for use by wifi networks.


(Justin Sullivan/Getty Images)

The problem with this proposal is that these frequencies have already been designated for car-to-car communications. The technology is still under development, but the idea is that increasingly smart vehicles will be able to share information that helps them avoid crashes.
Rubio and Booker's bill has received a chilly reception from the Intelligent Transportation Society of America, a coalition of government agencies and for-profit companies that are working on these technologies. The US Department of Transportation, which is developing standards for the technology, is also skeptical. These groups worry that interference from wifi chips will hamper vehicle-to-vehicle communications, making the latter technology less useful.
But advocates for the legislation say this problem can be solved with technology. Newer wireless chips have the ability to listen in on a particular frequency and check whether it's in use. If a wifi chip detects that there are nearby cars using the 5.9 GHz frequency band, it could transmit on another frequency instead.
Rubio and Booker want to require the FCC to study the feasibility of this approach and develop a plan for opening frequencies near 5.9 GHz up to wifi-style unlicensed uses. However, this plan would only go forward if the FCC determines that it can be done without interfering with others already using the frequency, including the nascent vehicle-to-vehicle technology.
"Spectrum is a valuable yet limited resource that must be utilized effectively and efficiently," Rubio said in a statement last month. "By requiring the FCC to conduct testing that would provide more spectrum to the public, we are ultimately putting the resource to better use."


(John Moore/Getty Images)

Expanding the spectrum available for wifi will be especially important if — as some experts anticipate — people increasingly use wifi as a substitute for conventional cellular service. A startup called Republic Wireless has pioneered a technique that allows cell phones to seamlessly switch between wifi and cellular networks, reducing demand for scarce cellular bandwidth. Google is rumored to be developing a wireless service of its own that would employ a similar business model.
If this model goes mainstream, the use of wifi networks could grow at an even faster pace in the next few years. Rubio and Booker's legislation would help to expand the capacity of these networks.
"Access to wireless spectrum opens the door for innovation and transformative new technologies," Booker said last month. "It can help bridge the digital divide that leaves too many low-income communities removed from the evolving technology landscape."
Rubio and Booker introduced their legislation in the Senate last month, and a bipartisan group of legislators introduced companion legislation in the House of Representatives at the same time.
The legislation enjoys support from public interest groups such as the American Library Association and Public Knowledge, and the idea of expanding wifi is popular with technology companies such as Google and Microsoft. But the bill hasn't yet been taken up by either house of Congress.
For many taxpayers, the annual refund check from the IRS is one of the year's biggest paydays. But thousands of taxpayers will get a nasty shock this year when the IRS tells them their refund has already been collected by someone else. In the best-case scenario, it will take these unlucky taxpayers months to convince the IRS to send them the refund they're entitled to.
This is not a new problem — I wrote about it last year, in fact. In the 2013 filing season, according to the Government Accountability Office, the IRS blocked $24.2 billion in fraudulent refund requests, while the agency paid out at least $5.8 billion (and possibly a lot more) in refunds that later proved fraudulent.
This year the refund-theft discussion has focused specifically on TurboTax, the nation's most popular tax-prep software. Two former employees of Intuit, the company behind the program, have charged that their bosses turned a blind eye to rampant use of TurboTax for refund theft.
Intuit denies it's done anything wrong. The company says stolen tax refunds are an industry-wide problem, and that Intuit has done more than any of its rivals to help the IRS combat the problem.
Here are the two big things you need to know about the story:


(Barry Chin/the Boston Globe via Getty Images)

There are two basic ways criminals can use TurboTax to steal tax refunds. One takes advantage of the fact that our tax system doesn't have any reliable way of verifying people's identities.
When it comes to tax returns, the IRS takes a "send money first, ask questions later" approach. The IRS might not discover that a return was fraudulent for weeks or even months — long after the refund check is out the door.
Fraudsters can use TurboTax to exploit this flaw. They just need to get their hands on basic identifying information, such as a victim's Social Security number, address, and date of birth. And thanks to a string of major data breaches, this kind of information is available to a lot of criminals.
Another way to steal tax refunds is by obtaining a victim's TurboTax username and password. In most cases, this is possible because people use the same passwords on multiple sites. Criminals find lists of usernames and passwords elsewhere on the internet, and then try those same credentials with TurboTax. If it works, they can hijack the user's account — using identifying information entered in previous years to submit a new, fraudulent return and direct the refund to an account controlled by the thief.
A key point here is that neither of these attacks is Intuit's fault — at least directly. If a criminal has a user's Social Security number and other identifying information, he can submit a fraudulent return using any number of tax-filing methods, including TurboTax competitors such as H&R Block and TaxAct. Similarly, TurboTax is far from the only website criminals have tried to break into by guessing users' passwords.
Intuit says it's reluctant to do more because this is a problem the industry as a whole needs to solve
But it is fair to fault TurboTax if — as two whistleblowing employees have alleged — TurboTax refused to take obvious precautions against these kinds of attacks.
"We found literally millions of accounts that were 100 percent used only for fraud," former Intuit programmer Robert Lee told journalist Brian Krebs. "But management explicitly forbade us from either flagging the accounts as fraudulent or turning off those accounts."
Intuit also dragged its feet on adding features that would make it harder to take over the accounts of legitimate customers. For instance, two-factor authentication is a technology that improves security by requiring the user to enter a numeric code sent to his or her cellphone in addition to a password. A lot of websites have offered this feature for years, but Intuit just made it widely available earlier this year.
"When you give your most sensitive data and that of your family to a company, that company should offer you more security than you can get at Facebook or 'World of Warcraft,'" Lee told Krebs.


(Julie Thurston Photography/Getty Images )

Intuit says it has voluntarily taken measures to combat fraud. The company says it's reluctant to do more because this is a problem the tax-preparation industry as a whole needs to solve. If Intuit is the only company to crack down on refund theft, the company fears the crooks will simply switch to other filing methods.
This argument might be self-serving, but it's also true. Private services can take steps to discourage fraud at the margins, but only Congress can overhaul the rules and make fraud harder system-wide.
One way the IRS could crack down on fraudulent returns would be to check that the wage information on a return matches the information submitted by employers on W-2 forms. The problem is that the IRS doesn't get this information in time to verify it before sending out refund checks.
Current law doesn't require an employer to submit this information to the IRS until two months after it's provided to employees. And small employers aren't required to submit the data electronically. Meanwhile, the law requires the IRS to send taxpayers their refunds promptly. So often, by the time the IRS discovers someone submitted a return with fraudulent W-2 data, the refund has already gone out the door.
Nina Olson, the IRS's official public advocate, has been calling for this system to be overhauled for years. But the IRS on its own can't require employers to file earlier, nor can it require all employers to file electronically. Only Congress can do that.
A more ambitious approach would be to establish a standard system for taxpayers to identify themselves. For example, when consumers request a copy of their credit report from the government-sponsored AnnualCreditReport.com, the site asks them a series of questions about the names of old employers, streets they used to live on, and so forth, to verify their identity. A similar approach could work for the IRS.
The IRS could ask taxpayers to supply a mobile phone number or email address. That would allow the agency to send taxpayers automated notices when a return is received the next year, allowing the taxpayer to notify the agency if a return is fraudulent.
There are a lot of options. The problem is that the body that's ultimately responsible for shaping the tax system — Congress — hasn't taken the problem seriously for many years.




(Denise Taylor/Getty )
It's important to note that the recent allegations against TurboTax do not necessarily mean your tax refund is in greater danger if you sign up for TurboTax. If a fraudster gets your Social Security number and other data and uses it to impersonate you, it's going to be a huge headache no matter what tax prep software you use. Crooks using H&R Block can steal refunds from legitimate TurboTax customers, and vice versa. Avoiding TurboTax doesn't make you any safer from this kind of attack.
What about having your username and password stolen? That's a risk with any online service, but there are a couple of things you can do to minimize the danger.
One is to enable two-factor authentication. As I mentioned before, TurboTax dragged its feet on offering this security feature. But it finally started doing so this year. This feature will ensure the bad guys can't access your account even if they figure out your password.
Second, choose a good, long password for TurboTax that isn't used on any other website. If you're worried about forgetting your password, don't be afraid to just write it down and save it with your tax documents. Anyone who steals your previous year's tax return will be able to impersonate you with or without your TurboTax password.
In March I asked Intuit to comment on the refund theft controversy. Here's what the company said:
As the challenge from cybercriminals evolves, we need to continually strengthen our efforts by helping the IRS detect fraud, while also protecting legitimate taxpayers from unnecessary burden and delay to their filings and refunds. And that is what we are doing. There are many different opinions about which security measures are most appropriate for a given threat level. We believe we offered appropriate features to address the threat level at the time and continue to evolve our security measures in response to the changing environment.
WATCH: 'Tax Day doesn't have to suck'
<!--
OO.ready(function() { OO.Player.create('ooyalaplayer', 'poZDF5bDqkrR_LWWfdjlDIlpkohK8qYF'); });
// -->
Target is joining the long line of retailers that are upping their wages, with reports that the store will soon be setting its minimum pay at $9 per hour. The Gap raised its wages early last year, and Walmart and T.J. Maxx have followed suit this year.
The nationwide wage hike seems to represent a change in Target's thinking. Earlier this month, the company's CFO, John Mulligan, said it was "not reasonable" for the store to think about its wages in terms of one national hourly rate, as Reuters reported.
"Fixating on some single number to us, on an average number is unimportant. It’s about being competitive locally at a store level within a marketplace," he said. He also noted that Target already paid more than $9 per hour in places where wages were high, like New York and North Dakota.
So why is Target changing its tune? The decisions of Walmart and T.J. Maxx to set their own national minimums may have forced the company's hand.
But Mulligan's broader point was absolutely right, and it applies not only to Target but also to how we think about minimum wage laws nationwide. It doesn't make sense to set a uniform minimum wage across the country, and then hope state and local governments raise them as needed. It would make more sense to have a federal system in which the local minimum wage in each area is more connected to local economic conditions.
If you've ever moved from one major city to another for a new job, you've probably experienced how different the cost of living can be in different places. The $50,000 you were making in Memphis might sound small compared with your new $70,000 salary in New York ... until you see rents in the Big Apple.
The same principle applies at the bottom of the wage scale: earning $7.25 per hour is a lot more doable in rural Idaho, for example, than in a higher-cost place like Dallas, Texas, where the minimum wage is also at the federal minimum.
It's true that many places have independently raised their own wages. San Francisco, which famously has a high cost of living, is slowly ratcheting its minimum wage up to $15 per hour. Indeed, at a time when many people agree the federal minimum is too low ($7.25 per hour, or around $15,100 annually for a full-time worker), 29 states and the District of Columbia have minimum wages above the federal minimum. And as MIT's Living Wage Project has found, the federal minimum wage simply isn't enough to live on for most American families.
But just hoping cities and states raise their minimums on their own isn't a great policy. Minimum-wage laws can get tied up in prolonged political fights in state legislatures, meaning minimum wages end up reflecting state and local politics, not state and local economies, as University of Massachusetts-Amherst economist Arindrajit Dube wrote in a 2014 paper.
As economist Jared Bernstein wrote last year, Dube's way is a better way: Dube proposed that state and local minimum wages be based at half the local median wage, a level he says is consistent with the US minimum wages of the 1960s and 1970s, as well as with standards in advanced economies.
He also advocates that lawmakers take local costs of living into account when setting those minimum wages, as the median wage and cost of living aren't perfectly correlated around the country. And finally, he advocates indexing wages to inflation, thus taking care of the problem of having to revisit the issue constantly.
Using Dube's calculations, every state would have a minimum wage above the current federal level of $7.25 per hour.
Mississippi is the state that would have the lowest minimum wage — $7.97 per hour — under Dube's proposal. Adjust for regional prices, and it's even higher, at $8.42.
Businesses and the government, of course, have different rationales for setting their minimum wages: firms want to attract talent, while the government wants to make sure people are making enough to live on. But to achieve either requires some semblance of flexibility, and the federal government's nationwide, rarely changing minimum wage simply doesn't have that.
It's become a cliché for an executive at a large company to promise to run it like a startup. Yet in his influential 2011 book The Lean Startup, startup founder and business guru Eric Ries argued that businesses of any size and age — and perhaps even nonprofit organizations and governments — can still learn a lot from management methods pioneered in Silicon Valley.
On Monday, Ries began work on his next book project. Fittingly, he started it off with a Kickstarter campaign. The campaign achieved its $135,000 fundraising goal on Tuesday, and by Thursday morning Ries had more than $170,000 in pledges.
"I'm a believer that this is the future of publishing," Ries told me on Monday shortly after the campaign began. For Ries, the Kickstarter campaign isn't just about raising money; it's also a way to solicit feedback from his future readers. Pledgers will be able to participate in a closed online community for aspiring entrepreneurs. Ries wants to learn what they want from the book and — more important — gather examples of real-world business successes and failures that he can incorporate into the book.
Ries' big idea is that the key to success for a startup — or any organization trying to innovate — is to learn quickly and act on the knowledge gained. While that might sound obvious, doing it often requires people to do many things that are counterintuitive.
Normal companies — and normal employees — measure their productivity by how many units of output they produce each day. A chef might measure his productivity by the number of meals he prepares, while a programmer might measure the number of lines of code she's written.
This notion of productivity assumes whatever is produced can be sold at a profit. This is a reasonable assumption for an established business in a mature industry.
But by definition, startups are trying to pioneer new product categories in situations of extreme uncertainty. There's a big risk that once the product is done, no one will buy it. And in that case, it doesn't matter how "productive" the company was in the months before the product was released, because no one is going to benefit from all that hard work.


Zappos CEO Tony Hsieh in 2010. (Ethan Miller/Getty Images)

Ries argues that startups should think about productivity differently: as the ability to quickly receive and respond to feedback from customers. Good startups boost productivity by minimizing the amount of time they waste building products customers won't want.
A key strategy here is to create a "minimum viable product." An MVP is a real product, not just a prototype. But the goal is to get the product out the door as quickly as possible, even if it's still missing key features and may only appeal to a narrow subset of the target audience.
Sometimes an MVP can be amazingly bare-bones. For example, the popular online shoe retailer Zappos started out by just walking into retail stores, taking pictures of shoes, and then listing those shoes for sale on their website. If a customer ordered a pair, they'd go back to the same store, buy them at full price, and ship them to the customer.
Obviously, this wasn't a viable long-term business model. But starting this way allowed Zappos to learn a lot about the market before spending a single dollar on inventory or warehouses. It avoided the risk of wasting millions of dollars building infrastructure for an online store customers wouldn't use.
This approach seems counterintuitive to many people, who worry that a low-quality MVP might turn off customers and tarnish a company's brand. But having customers who are frustrated with your product's limitations is a lot better than not having customers at all. And if you're building a new type of product, having no customers is a real risk.
Many companies are organized by function. A company might have a sales department, an engineering department, a design department, and so forth. While this method of organization has intuitive appeal, Ries argues that it's deadly for innovation.
Having customers who are frustrated with your product's limitations is a lot better than not having customers at all
Remember, the key to innovation is to learn what customers want as quickly as possible, and then to act on that knowledge. At any given point in time, different companies will have different ideas about how to make the product better. For example, the sales team's frequent contact with customers might give them insight into what features customers would like, while only people on the engineering team know which feature ideas are technically feasible.
If these two groups are segregated into different departments, learning will happen slowly. The engineering department will spend hundreds of hours building a new feature before the sales team tells them it's not what customers were asking for. The sales team might spend weeks touting a new feature to customers before learning the engineering team can't actually deliver it.
Ries notes that this idea — that cross-functional teams are more efficient than specialized ones — flies in the face of most peoples' intuition. When people are thrown into teams containing a mix of different job skills, they often feel they're being less productive, because they're forced to spend a lot more time talking to people with different job skills.
Individual workers might feel these interruptions reduce productivity. But these conversations tend to increase the productivity of the organization as a whole. That's because one part of the company is less likely to waste time working on things that don't actually serve the needs of other parts — or, ultimately, of customers. The programmer will overhear the sales guy in the next cubicle promising a customer features that are impossible. The sales guy will be able to give the programmer earlier feedback about what customers are looking for.
A large company wanting to follow these strategies faces an uphill climb
One of the big themes of The Lean Startup is that any company — large or small, old or new — can innovate like a startup. In theory, the strategies he advises — including building minimal viable products and organizing around small, cross-functional teams — can be practiced by a company of any size.
Still, a large company wanting to follow these strategies faces an uphill climb. Organizing a company by function is such an intuitive idea that most wind up doing it. The larger and older a company is, the harder it will be to change how business is done.
And while an MVP is a great way for a startup to test out a new product, the potential pitfalls are bigger for established companies. Customers expect a new product from a well-known brand to meet a certain quality threshold, and when a product fails to deliver, they judge it harshly. Big companies are naturally cautious because they have a lot to lose.
Ries isn't blind to these challenges, of course. In his first book, he offers some advice on how to deal with them. The goal of his new book project — which aims to produce one book designed for his Kickstarter supporters and then a second book for a broader audience — is to develop more practical advice for putting the principles of his first book into action in a variety of settings.
And he's hoping to have a lot of help to do that. Over the next year, he'll be encouraging members of his online community to put his ideas into practice and report back on the results. Hopefully, he'll learn a lot, and then share that with the rest of us.
The traditional way the Fed has managed the economy is by manipulating short-term interest rates. Lower interest rates encourage borrowing and make it easier for businesses to invest and grow. But since the 2008 financial crisis, the Fed has been keeping short-term rates near zero.
But with the economy recovering, the Fed is widely expected to raise interest rates for the first time in more than six years. The only question is when this will happen.
In its January meeting, the Fed signaled that interest rate hikes were not imminent. "The Committee judges that it can be patient in beginning to normalize the stance of monetary policy," the central bank said in its typical bureaucratic prose.
In today's statement, the committee said something more specific: "The Committee judges that an increase in the target range for the federal funds rate remains unlikely at the April FOMC meeting." That stuff about being "patient" is gone. And the statement that the Fed won't raise rates in April sure sounds like a hint that it will raise them in the meeting after that — in June.
But in a press conference following the statement's release, Fed Chair Janet Yellen encouraged people not to read too much into the change. "Just because we removed the word 'patient' doesn't mean we're going to be impatient," she said.
Another part of the latest Fed statement also suggests the Fed could wait longer. Today's statement says the Fed won't raise rates until it "has seen further improvement in the labor market and is reasonably confident that inflation will move back to its 2 percent objective over the medium term."
The stock market has reacted positively to the news, with the S&P 500 up about 1 percent for the day. Ordinarily, news that interest rate hikes are coming would trigger a fall in stock prices. The fact that markets rose instead may reflect relief that the Fed didn't send a stronger signal that higher rates were coming.
Late last week, we reported that the average Wall Street bonus totaled nearly $173,000 in 2014. Altogether, New York City's nearly 170,000 securities industry employees took home $28.5 billion in bonuses, according to the New York Office of the State Comptroller.
Shortly after the release, the left-leaning Institute for Policy Studies released a report showing that those bonuses equaled roughly double what all full-time federal minimum-wage workers earned last year. And that's just one of the jaw-dropping comparisons you can draw to the Wall Street bonus pool.

The $28.5 billion is more than double not only the minimum-wage earnings figure, but also annual Facebook revenues. It's nearly 18 times what the New York Times earned in revenue in 2014. It's more than 80 times what American Sniper — 2014's top-grossing movie — has pulled in at the domestic box office to date.
And keep in mind that while the average bonus was nearly $173,000, some highly paid workers have been known to take home millions of dollars in annual bonuses. So it wouldn't take too many to try to buy the New York Yankees (according to Forbes' valuation of the team). And if enough generous Wall Streeters got together, they could help the federal government double its spending on Head Start.
One more fact to keep in mind: this $28.5 billion is on top of the regular salaries Wall Street workers earn. As of 2013, New York City securities industry workers earned $355,500 on average (including bonuses), according to the New York Comptroller's office.
WATCH: 'CHART - How the rich stole the recovery'


In recent years, lots and lots of pundits — including me — have speculated about how self-driving cars will change American cities. But almost all the talk has been just that — speculation. Because we can't collect data on the social effects of a technology that isn't available yet.
But a recent study does the next best thing: it starts with detailed data about today's traffic patterns, and then uses a computer simulation to predict what would happen if drivers switched to taking rides in self-driving taxis. The research, by University of Texas at Austin professor Kara Kockelman and the University of Utah's Daniel Fagnant, provides unprecedented insight into how self-driving vehicles will change the urban landscape.
The researchers found that a company running a hypothetical fleet of self-driving taxis can make big profits charging $1 per mile, a fraction of what American taxis cost today. Each new self-driving taxi added to the fleet eliminates the need for about 10 privately owned cars. And thanks in part to the possibility of on-the-fly carpooling, the system can gracefully handle the demand spikes that occur during rush hour.
Self-driving technology is going to dramatically change how people get to work, to school, and around town. It's going to make a car-free lifestyle a lot more attractive to a lot of people, make taxis affordable to a lot of people who can't afford them today, and help ease both traffic jams and parking shortages.


Car-sharing services like ZipCar are already reducing private car ownership. (Spencer Platt/Getty Images)

Traffic planners collect detailed data about metropolitan traffic patterns to help them understand how changes to roads will affect traffic patterns. Kockelman and Fagnant realized they could use data from the Austin area (where UT is located) to build a precise simulation of how a self-driving taxi network would perform in the real world.
They started with existing traffic patterns and then created a computer model in which a small fraction of car commuters (1.3 percent in their main simulation) ditched their cars and relied on self-driving taxis to get around instead. Fagnant wrote a computer program that simulated the movement of each self-driving vehicle over the course of a 24-hour day.
In one 24-hour period, a fleet of 1,700 virtual self-driving vehicles completed 56,324 rides, which works out to a bit more than 30 rides per vehicle. Given that the typical privately owned car completes around three trips per day, this means each taxi does as much work as 10 private vehicles.
This finding is consistent with the experience of car-sharing services like Zipcar. One study found that each vehicle added to a car-sharing network corresponded to subscribers owning 9 to 13 fewer cars. This is a big social benefit, especially in cities that suffer from parking shortages.


Self-driving taxis are going to be a lot cheaper than these guys. (Justin Sullivan/Getty Images)

In the United States, the driver's labor is the single largest expense for today's taxi services. But self-driving taxis work 24 hours a day, seven days a week, for free. So taxi companies will be able to slash their fares.
How much cheaper could taxi service get? Fagnant and Kockelman assume self-driving taxis will cost around $70,000 — less than they cost now but a plausible guess for what they'll cost a decade from now. They also assume their virtual taxi company will charge $1 per mile, which is less than a third of the $3.65 per mile that conventional taxis cost in Austin. Despite these low fares, their simulated taxi service is highly profitable, earning a 13.9 percent annual return on investment.
There are several reasons to think fares will fall even lower than $1 per mile in the long run. Competition among self-driving taxi services should push prices — and therefore profits — down. Also, Fagnant and Kockelman assume self-driving taxis will have the same operating costs — about 50 cents per mile — as conventional vehicles. If self-driving taxis make super-efficient electric vehicles practical — as some people have predicted — then savings on energy should translate into lower fares. It's also likely that progress in sensor technology will eventually bring the cost of self-driving taxis below $70,000.
But even $1 per mile is cheap enough to make self-driving taxis a practical commuting option for many people, especially in urban areas. I live about two miles from Vox Media headquarters in downtown DC, so commuting by self-driving taxi would be a no-brainer for me — the $2 cab fare would be only slightly more than the $1.75 I currently pay to ride the bus to work, and it would be a lot more convenient.


(Scott Olson/Getty Images)

When I wrote a few months ago that self-driving taxis will mean the end of mass car ownership, the most common objection I heard regarded rush hour. Sure, people said, you can take taxis everywhere the rest of the time. But during the morning commute, everyone is going to work at the same time, so there's not much room for car-sharing.
But the data tells a different story. Fagnant tells me a single self-driving taxi was able to complete several trips during each rush hour period.
"You don't have a uniform peak where everybody leaves their house at 7:30 and arrives to work at 8," he says. "You have some people who leave earlier, some who leave later, some who do reverse commuting."
According to Fagnant, an autonomous taxi might pick up someone in an outer-ring suburb and take him to his job in an inner-ring suburb. Then it could pick up someone in the inner-ring suburb and take her to her job downtown. It could then pick up someone who lives downtown and take him on a reverse commute out to the suburbs, before turning around to take another customer into downtown. It's true that some taxis will have to travel empty out to the suburbs to get the next passenger, which isn't efficient. But this doesn't have to happen as much as many people think.

(Weimer Pursell / Galerie Bilderwelt/Getty Images)
The self-driving taxi network in the simulation was able to organize just-in-time carpooling arrangements, matching passengers who happened to be traveling in the same direction. This is similar to the UberPool and Lyft Line carpooling services that exist today.
Carpooling was still relatively rare, with about 4.5 percent of trips involving shared rides. However, this was still significant because it was concentrated during morning and evening rush hour, when cars and space on the roads were scarce.
And surprisingly, passengers who agreed to the carpooling option didn't see their average trip time go up. Carpooling does slightly increase the average distance each passenger travels, since sometimes one passenger has to go out of his way so another can be dropped off. But this increased travel time was offset by the fact that carpooling reduced the amount of time people spent waiting for a taxi to arrive. This effect was most dramatic at rush hour, when carpooling slashed the average time passengers spent waiting for a car from nine minutes to four and a half minutes.


(Justin Sullivan/Getty Images)

Due largely to computational limitations, the study focused on scenarios in which only a small percentage of trips in the Austin area — about 1.3 percent — are taken in self-driving taxis. But Fagnant and Kockelman also did some simulations with higher (but still single-digit) market share for self-driving taxis, and found that the economics of self-driving taxis improve as the size of the network grows.
If a network has more cars and passengers, it becomes easier for the system to find pairs of passengers who are a good fit for carpooling. The data reflects this. As the market share of self-driving taxis increased from 1.3 percent to about 6.5 percent, the fraction of carpooling trips rose from 4.5 percent to 5.9 percent.
With more taxis on the road — including many taxis whose passengers are willing to carpool — the average wait time for a vehicle fell. The length of the average trip — including time spent waiting for the car to show up — declined by 30 seconds from 14 and a half minutes to 14 minutes.
Finally, economies of scale should make self-driving taxi fleets more profitable as they get larger, as cars will spend less time waiting around (or driving back and forth) to get the next passenger. Assuming healthy competition, this should translate to even cheaper fares.
This research provides a lot of insight into how self-driving taxis will change the transportation market. However, some likely effects weren't captured by the simulation.
One is changes in housing patterns. Self-driving taxis will make housing that's relatively close to downtown but not well-served by transit relatively more attractive. At the same time, because self-driving taxis won't need parking, cities will be able to devote more space to housing people and less to housing cars. It's hard to predict exactly how this will change cities, but it seems likely that the parts of the city that are made newly convenient will experience a building boom as nearly empty parking lots are converted to housing.
Another important question not addressed in the research is how self-driving taxis will interact with transit. For example, self-driving taxis could allow increased use of the subway in the suburbs. Instead of driving to the subway station and paying several dollars to park in the park-and-ride (daily park-and-ride rates for subways in the Washington, DC, area, for example, average about $5), someone who lived two miles from the subway could take a taxi, paying $2 or or less each way. That could make subway stations practical in parts of the city that are currently too sparse to justify it.
Of course, the model may not work for everyone. Fagnant's simulation focused on a 12-by-24-mile rectangle enclosing the densest parts of the Austin metro area, excluding trips that went into outlying areas. People in these areas have long commutes, which leaves fewer opportunities for vehicle sharing. For them, owning a car outright may make more sense for the foreseeable future.
But there are millions of people who will find self-driving taxis to be a more convenient and affordable way to get to work than the alternatives.

This new 3D printing technology looks like science fiction. But it's entirely real — the scientists who created it took inspiration from the futuristic liquid metal in the movie Terminator 2.
Joseph DeSimone and the other University of North Carolina scientists who describe the technology in a new paper published today in Science call it "continuous liquid interface production." (They've also founded a new company called Carbon3D to sell the printer.)
Unlike conventional 3D printing, which prints in layers, their printer continuously forms a new object. As a result, they say, it's much faster than conventional 3D printing, taking minutes instead of hours.
This could finally bring the big advantage of 3D printing — that it lets you easily customize or tweak designs by making changes to software, rather than building new manufacturing machines — to mass consumer products.
There are a few different types of existing 3D printers, but they mostly work via the same principle: a printing head passes over a platform over and over, depositing layer after layer of a material like plastic in a precise pattern. Over time, these layers combine to form the desired object — much like a paper printer forms text on a page by putting down row after row of ink.
By contrast, this new continuous 3D printer would do away with the layers entirely. Instead, a platform draws the object continuously out of a bath of liquid resin.
<picture class="c-picture" data-cid="site/picture_element-1500876912_8582_106090" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/L7DFwusAIX2q8tvfFn-zXw2gscA=/0x0:800x450/320x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 320w, https://cdn.vox-cdn.com/thumbor/hz14USJfrP6r65FqwpbS5fe1BUA=/0x0:800x450/520x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 520w, https://cdn.vox-cdn.com/thumbor/oyRMr-i-lp1tVesnm21El0teInE=/0x0:800x450/720x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 720w, https://cdn.vox-cdn.com/thumbor/p9EJVQNOaYKDdbLiJDHshAYRAXM=/0x0:800x450/920x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 920w, https://cdn.vox-cdn.com/thumbor/DCmDrqT89O50OOiWCj9cxGaknqg=/0x0:800x450/1120x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/b5D2IcZfr9GJJHxa93AQGJfKQb4=/0x0:800x450/1320x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/e8Hh15sizrfT9VISCHdMeOnujLQ=/0x0:800x450/1520x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/R3jpZ_nZAgogk2SybU2_7unMQTg=/0x0:800x450/1720x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/QRgmYRkaVxD_vfaoEekaTECi2EY=/0x0:800x450/1920x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/x-ujXTEDDjU5PPa3B5lQKqjxWiM=/0x0:800x450/1200x0/filters:focal(0x0:800x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3508660/3d_printing_gif.0.gif" alt="3d printing">

</picture>
(Carbon3D)
The resin solidifies when ultraviolet light hits it (a process called photopolymerization). So to create the desired item, a projector underneath the resin pool shoots UV light,  in the form of a series of cross-sectional images of the object. Light, in a sense, is the blade the printer uses to sculpt its products.
Meanwhile, oxygen prevents this reaction from occurring — so to stop the object from simply hardening and sticking to the floor of the pool, there's a layer of dissolved oxygen there, creating an ultra-thin "dead zone" at the very bottom.

(Carbon3D)
With the projector and platform in sync, the object forms as it moves upward, with new resin continuously solidifying just above the dead zone.
Right now, the printer is still a prototype, used by Carbon3D to print mainly demonstration objects. Carbon3D hasn't said how much it'll cost, but it does plan to begin selling the printers to companies in about a year.

Prototype coronary stents, printed by Carbon3D's printer. (Carbon3D)
3D printing in general is exciting for one big reason: it lets you customize objects or introduce new product designs simply by altering software (that is, the data the printer uses to make the object), rather than having to retrofit the molds or other hardware used to make the actual object.
For this reason, lots of people have speculated that 3D printing could revolutionize manufacturing, or lead to people printing their own goods at home instead of buying them at stores. But so far, it's mostly been a niche process, used for prototypes, models, and other individually crafted items.
One of the reasons is that it's pretty slow. Conventional 3D printers usually take several hours to print an object — because with most printing methods, they need to individually treat each new layer of material after it's put down so that the next layer can be put down on top of it.
the new method works in minutes rather than hours
The new method is much faster because it works continuously, instead of in layers, eliminating this step. As a result, it works in minutes rather than hours — 25 to 100 times faster, its creators say, than conventional 3D printing.
The lack of layers also makes the products of this new method stronger. That's because they're solid objects, rather than layers of material stacked together.
These two factors, Carbon3D says, could make its technology practical for mass-producing common products — like, say, a toothbrush you buy in a store. In theory, it could combine the flexibility of 3D printing with the speed and strength of old-school injection molding — the current standard for mass-producing many types of products and parts, especially plastic ones.
However, people have said similar things about conventional 3D printing, but that still hasn't happened. And that's not just because of time. Conventional 3D printing falls into a bit of a gap between potential uses — it's still far more expensive than manufacturing goods the old-fashioned way, but the printers are still mostly too complex for the average person to use at home.
For it to succeed where conventional 3D printing hasn't, Carbon3D's technology will have to solve one of these problems. Its creators are betting it'll end up being cheap and reliable enough to use in mass production of goods, but right now, it's still a prototype — so we'll have to wait and see.
The Federal Communications Commission let the rest of the country in on a big secret last Thursday: how it actually plans to make network neutrality (which it voted for two weeks earlier) work.
In a massive 400-page PDF, the agency laid out its vision for net neutrality. Reading the document closely — as I've spent the past four days doing — reveals just how controversial the regulations will be. The concept of network neutrality has attracted broad public support, but translating that concept into specific rules turns out to be surprisingly tricky. Even after hundreds of pages of explanation, the FCC left a number of important questions unanswered.
The document was so massive because both sides of the debate are preparing for a legal battle over whether the FCC has overstepped its authority. "The commission is aware that this is going to be subject to challenge," says Harold Feld of the pro-network-neutrality group Public Knowledge, adding that the agency has been "exceedingly thorough laying out its reasoning, pointing to every exception, pointing to the record of evidence."
Ultimately, the document makes clear that last month's vote was not so much the end of the network neutrality debate, but rather the beginning of a new phase. The courts still need to decide whether the new rules are within the FCC's power. They will also have to deal with arguments that the FCC rushed the rules through faster than the law allows. And if the rules are ultimately upheld, it will still be many years before we know what they really mean.



The three Democrats on the FCC: Mignon Clyburn, Tom Wheeler, and Jessica Rosenworcel. (Mark Wilson/Getty Images)
To obtain the authority it needs to enact strong network neutrality regulations, the FCC used a legal tactic called reclassification. This puts broadband service in the same legal category as old-fashioned telephone service.
Conservative critics charge that these utility-style laws, known to telecom nerds as Title II of the Communications Act, are outdated and will impose heavy-handed regulations on the internet. But after the courts nixed efforts to protect network neutrality without reclassifying, supporters felt they had little choice. Responding to a grass-roots lobbying campaign, President Obama endorsed the option in November, and FCC Chairman Tom Wheeler announced last month that the agency would use Title II.
But Title II doesn't just provide a legal foundation for network neutrality rules — it's a complex body of law in its own right. A key requirement is that telecommunications providers must behave in a "just and reasonable" fashion.
The FCC used this as the foundation of its network neutrality rules, declaring that it was not "just and reasonable" to block websites, slow them down, or create "fast lanes" for websites that paid extra.
The new regulations also bar "unreasonable interference and discrimination," a deliberately open-ended standard that will allow the FCC to police provider misconduct that doesn't run afoul of the other three rules. The standard is so broad that even the left-leaning Electronic Frontier Foundation urged the FCC to rethink it — which it didn't.


FCC Chairman Tom Wheeler. (Mark Wilson/Getty Images)

The FCC could have stopped there. While Title II includes a lot of other requirements, Congress gave the agency authority to decide not to enforce rules it judges as counterproductive. The FCC could have promised to police violations of network neutrality as contrary to the "just and reasonable" standard but declined to enforce other provisions of Title II.
But that's not what the agency did. Instead, the new rules invite the public to submit complaints if a broadband provider's conduct is not "just and reasonable" — even if the conduct doesn't run afoul of network neutrality principles.
A big motivation for doing this was to allow the FCC to deal with controversy over the ways big broadband providers have negotiated with content providers. For example, last year Netflix accused Comcast of forcing it to pay a "toll" to reach Comcast customers. This kind of negotiation is not governed by conventional network neutrality rules, but the hardline position Comcast took does raise many of the same concerns as conventional network neutrality violations.
Rather than try to write specific rules to settle this complex and volatile issue, the FCC is going to address it on a case-by-case basis. Aggrieved parties will be able to file complaints alleging that broadband providers' interconnection decisions are not "just and reasonable," and then the FCC will figure out what the phrase means.


(Andrew Burton/Getty Images)

The kind of open-ended regulatory scheme the FCC has developed here comes with a big downside: it makes it harder for broadband providers to predict which business models will be considered legal. And that, in turn, could discourage investments in new infrastructure and experiments with new business models.
Here's an example: some wireless providers cap the amount of data customers can download (without paying extra), but exempt certain apps from the limit. T-Mobile, for example, offers a "music freedom" feature that allows users to stream an unlimited quantity of music, while limiting how much data other apps can consume. Critics have called this a violation of network neutrality. T-Mobile, naturally, defends it as a valuable benefit to consumers.
So what does the FCC say about arrangements in which some content is counted against data limits and other content is not? The agency writes that "the record reflects mixed views" on whether this practice is beneficial to consumers. So rather than give clear guidance on such arrangements now, the agency plans to apply its vague "no unreasonable interference/disadvantage" standard on a case-by-case basis.
The agency is taking the same stance with regard to the data-use limits: they're not necessarily illegal, but any company that uses them could wind up getting tied up in a lengthy and expensive court case.


FCC Commissioner Ajit Pai. (KAREN BLEIER/AFP/Getty Images)

The 400-page document ends with the comments of the two Republican commissioners, Ajit Pai and Michael O'Rielly, who made the case against the new rules. A key argument, articulated best by Pai, is that the FCC failed to provide the public with adequate notice of its proposal, depriving people of an opportunity to comment on the proposal and violating the Administrative Procedure Act in the process.
This is a crucial question, because regulations that don't follow the requirements of the APA can be struck down by the courts. That wouldn't permanently prevent the FCC from enforcing the rules, but it would force the agency to start the entire rule-making procedure over, delaying the rules from taking effect for two to three years.
The APA requires an agency to notify the public of its proposed rules, accept public comments, and then take those comments into account. But critics say the final regulations were so different from the original proposal that the public didn't have an opportunity to comment on the rules the agency actually chose.
In its original notice last May, the FCC proposed much weaker network neutrality rules that were not based on reclassification. Pai and other critics say the FCC should have released a new version of its rules and taken public comments before voting on them. They argue that by failing to do so, the agency deprived the public of an opportunity weigh in on the final rules.
But supporters of the ruling point out that the FCC did mention reclassification as an option in its initial notice. And they point to the flood of public comments the FCC received — both for and against reclassification — as evidence that the public had plenty of notice that reclassification was a possibility.


(Michael Dorausch)

The FCC wants to impose network neutrality rules for both the wired networks that connect our homes and the wireless networks that power our smartphones. But there's a significant possibility that the courts will strike down the wireless rules, leaving only the rules that govern wired networks.
The decision to regulate wireless networks is a change from the FCC's previous rules, enacted in 2010, which largely exempted wireless. So under the APA the FCC needed to give notice about — and provide legal justification for — the change. But critics say the agency's May notice didn't adequately explain how it planned to regulate wireless, and that its legal justifications are weak.
For example, the law limits regulation of networks that are not connected to the "public switched network," which has traditionally meant the public switched telephone network that uses 10-digit telephone numbers. Because wireless data services are not part of this network — mobile web browsers use IP addresses and domain names, not phone numbers, to make connections — mobile data service has traditionally been exempt from most regulations.
The FCC's solution to this problem is to redefine the term "public switched network" to refer to both the traditional phone network and the internet. Network neutrality supporters such as Public Knowledge argue this is the FCC's right, as Congress gave the FCC the authority to choose a definition for the term. The FCC also notes that people can use apps such as Skype to make phone calls using mobile data service, so mobile data services are connected to the public switched network even under the old definition.
But Ryan Radia, a network neutrality critic at the Competitive Enterprise Institute, says that this redefinition goes too far. He points to the legislative history from 1994, the last time wireless laws were overhauled, suggesting that legislators regarded the term "public switched network" as synonymous with "public switched telephone network." In Radia's view, Congress couldn't have intended for the FCC to expand the phrase to encompass the internet, a totally separate network.
Feld — a network neutrality supporter — disagrees. He argues that Congress delegated the task of defining PSN to the FCC precisely so it could update the definition to reflect technological changes.
Many network neutrality activists viewed last month's vote as the end of a hard-fought battle to protect network neutrality. But in many ways, the vote was just the beginning.
It will take several years for the courts to decide the inevitable lawsuits over the regulations' legality. During this period, the FCC's efforts to enforce the rules will be hampered by uncertainty about their legal status.
And if the rules are upheld, it will still be a while before it's clear what they mean.
The word "reasonable" comes up over and over again in the new rules: "reasonable network management," "just and reasonable," "unreasonable interference." And what's reasonable is not self-evident. The precise meaning of these terms will only become clear after the FCC builds up a body of precedent that helps define exactly which practices are reasonable and which are not.
If a Republican takes the White House, a new Republican majority could toss out the rules
It's these decisions that will determine how the rules actually shape the internet economy. If enforced too aggressively, they could hamper worthwhile innovations and become an obstacle to further growth of the internet economy. Conversely, permissive rulings could make the regulations basically toothless.
And while the FCC tries to sort out these questions, the 2016 election will be looming. If another Democrat takes office in 2017, we can expect the agency to continue the effort it started last month. On the other hand, if a Republican takes the White House, a new Republican majority could toss out the rules and start over.
In short, these new rules are nowhere close to finally settling the network neutrality fight. But they at least give us a much clearer sense of where the battle lines will be.
Let's say your bank disappeared tomorrow, and with it all of your credit cards and accounts. How would you save money or get a loan? There's the proverbial practice of stowing your money under your mattress. Or you could beg a parent or sibling for a loan so you could make your next rent payment.
But many Americans have other, more organized ways outside the financial system to build up savings and credit. One of those is the rotating savings group. These go by different names — rotating savings and credit associations (RoSCA) is one way experts refer to it — but they are often informally called savings circles.
The concept is simple: you get together with a group of your most trusted family members or friends, and you all agree to pay $50 a week into the pot. If there are 8 of you, you will pay $50 in for 7 weeks, then get the full pot ($350, not counting your $50) one of those 8 weeks.  It puts behavioral economics to work for users — you don't want to let your relatives down and cause them to miss out on their lump sum this week.
A diagram of how a savings circle works. (Source: US Financial Diaries)
Eight percent of American households are unbanked, according to the FDIC — that means that around 1 in 12 households doesn't have a checking or a savings account. And according to new research, the savings circle is one key way many Americans make ends meet.
The US Financial Diaries Project, in which researchers from NYU and the Center for Financial Services Innovation (a New York-based nonprofit) closely followed the financial lives of 200 US families with low to moderate incomes, found that 9 percent of those households use circles. The households aren't a representative sample, but the findings do suggest that significant numbers of certain populations, like immigrants, make particularly heavy use of the circles.
They solve one big problem lower-income Americans have: The researchers (and other studies) have found that these households often have troubles building up lump sums of savings, whether for short- or long-term use.
The strategy isn't just for the unbanked, of course. One savings circle user, Argelia Diaz, says she uses the structure in addition to her bank accounts. Diaz lives and works near Bakersfield, California, and has participated in circles with her family members for five or six years, she says. Circles are a tradition in her Mexican-American family, and she talks about it using language that evokes both loans and savings accounts.
"It's just an easier and quicker way to save up money on the side without having to accumulate interest at the end or paying it off," she says. "It's a quicker way to establish money on the side — something you need within weeks or so. For me it's short-term."
Diaz uses circles for short-term saving, but many of her family members have other reasons, she says. Many aren't well educated on how to use banking services she says, and some people she knows are undocumented and don't have the paperwork necessary to establish a bank account.
But she adds that it also comes easily in a tight-knit family where she, her mother, and her siblings see each other every week or even every day.
because savings circles are informal structures built on trust and often used in non-white cultures, it can be easy to diminish them as "quaint"
People who regularly "borrow" money in these structures miss out on big benefits of formal finance — particularly, credit score benefits. But there is a push to change that. The San Francisco-based Mission Asset Fund has been working to make circles more of a formally recognized structure by reporting to credit agencies.
Step one has been stopping calling them "savings circles," he says. The concept of circles isn't new, says John Quinonez, CEO at MAF. It has been around for centuries, and in many cultures — Businessweek earlier this year wrote about Pakistanis using the circles.
But for the purposes of emphasizing the credit-building and money-lending aspect of them, he has been applying other labels to the practice.
"Every time we talk about our work, about lending circles, that is just our way of articulating or sort of translating that activity that is invisible to the financial mainstream in a way that it can be understood here," he says. "If we formalize it and define everything as a social loan … then we can report [payments on that loan] to a credit bureau."
But he also adds that he wants to change cultural perceptions. The fact that savings circles are informal structures built upon family trust and often used by people from non-white-American cultures, says Quinonez, means anthropologists and other writers often talk about them in a quaint light, making them sound "cute." The point, he says, is to both legitimize the practice but also link it to the formal financial system.
"What was critical for us was to see beyond the nomenclature of savings circles and see the activity in the circles in a different light," he says. "We went beyond celebrating the fact that people save informally together to formalize that activity in a way that they could build their credit history."
In the 1960s, the United States had an extensive network of passenger rail trains. All the major cities in the Midwest and South were linked by regular train service. You could get service on smaller routes, like the one from Boise, Idaho, to Portland, Oregon, three times a day.
Then a lot of lines got shut down in the late 1960s and 1970s, as this animation shows.
<picture class="c-picture" data-cid="site/picture_element-1500895494_1165_21673" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/1GY2BLA7k8Lui7qEa4-90iMUxbo=/0x0:800x600/320x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 320w, https://cdn.vox-cdn.com/thumbor/jJkJ4V9ytV9NPMwkdweEihp4G0Y=/0x0:800x600/520x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 520w, https://cdn.vox-cdn.com/thumbor/_I95zI_dUUpoQgmT5lxetX5S60A=/0x0:800x600/720x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 720w, https://cdn.vox-cdn.com/thumbor/LlcSDXePV-aGFm3tWBTsd5G_lfQ=/0x0:800x600/920x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 920w, https://cdn.vox-cdn.com/thumbor/NDRjpnscBZoFDCwdGKAT1eOXaE0=/0x0:800x600/1120x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/JxkEE_KJcNPeCT5Ioc2pywmgOEc=/0x0:800x600/1320x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/xwmA2KabQsoHHidZlgawrMTZJcQ=/0x0:800x600/1520x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/oIXiWcDVlD7OseB1P4Cj-2SScWA=/0x0:800x600/1720x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/4GVQPfK1kKZd3xVT8W7HbRbw-f0=/0x0:800x600/1920x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/9Xn63LdMR_NPKs2bpmbYW5J4Czs=/0x0:800x600/1200x0/filters:focal(0x0:800x600):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3493914/railway_service_v2.0.gif">

</picture>

(Maps from the National Association of Railway Passengers and Malcolm Kenton via Greater Greater Washington. Animation by Joss Fong)

What's striking about this map is how differently the various parts of the country have fared. Service has been cut back in the Northeast, but the reductions weren't nearly as drastic as in other parts of the country. Amtrak's line between Washington, DC, and Boston is still heavily used by the region's business travelers.
Chicago, the Northwest, and parts of California have also retained significant rail coverage. California, in particular, has seen some new lines and service upgrades in recent years.
But for the rest of the country, the rail situation has been all downhill. The extensive network that once crisscrossed the American West has been reduced to just three east-west lines that don't cross one another at all. A lot of Southern cities are served by just one train a day, if they're served at all.
There's a new social media fad that's going crazy on Twitter — people have started linking to a service called Meerkat. If you click these links fast enough, it will take you to a live video stream — probably of your friend doing something mundane like walking down the street or eating lunch.
Meerkat has attracted tens of thousands of users in just a couple of weeks. And it seems silly. But most social media startups seemed silly when they were founded. Instagram seemed frivolous. Twitter seemed downright ludicrous.
There have also been plenty of social startups that seemed silly and were silly — think of Yo or Ello. We don't know yet if Meerkat will be a big hit or a one-hit wonder.
To use Meerkat, you need two things: an iPhone and a Twitter account. You download the Meerkat app to your iPhone, enter your Twitter credentials, and can then start broadcasting live video with a few taps. (Right now, it's for iOS only, but an Android app is in the works.)
Here's an example. I borrowed my colleague Lauren Katz's phone and gave a tour of the Vox office. We captured video of the stream — though normally you would only get to see it live. The quality of the video is terrible, but that's mostly my fault for waving the phone around too quickly.

Meerkat is best seen as a cousin of other services like Twitter, Instagram, and Vine that allow people to share nuggets of information with their friends and the world. Unlike other video-sharing platforms such as YouTube, however, Meerkat streams are ephemeral. Once the live stream is over, the video disappears from the site. It's something like Snapchat, except that you're sharing with anyone who wants to watch, not just your friends.
Meerkat puts a new spin on the old concept of a live-streaming video service.
There are some well-known live-streaming video services out there, including UStream and Livestream. YouTube has a live video feature, too. But these services are geared toward large-scale, professional broadcasts such as corporate conferences or sporting events. Meerkat is simpler, cheaper, and better suited to amateurs.
Perhaps the closest analogue here is Justin.tv, a 2007 startup whose founder, Justin Kan, live-streamed his life on his site continuously for several months to generate interest in the company. Justin.tv was not a big hit, but it evolved into into Twitch.tv, which allows people to live-stream video-game play. It was acquired by Amazon last year.
Another live video–sharing app, Qik, was acquired by Skype in 2011 and has since shifted focus to sending private video messages.
The main thing Meerkat adds is a social media dimension. Meerkat broadcasts are automatically announced on the user's Twitter account to attract viewers. And viewers must log into Twitter, as well, allowing broadcasters to know who is watching them.
Ironically, Business Insider has reported that Twitter recently acquired a company that was building a live-streaming app called Periscope that works a lot like Meerkat. That service hasn't launched yet.


(Matt Cardy/Getty Images)

If you look at random Meerkat streams (I did this by searching Twitter for the word "meerkat"), most of the broadcasts are pretty boring. I found a woman streaming her drive from Oregon to Washington State, a couple of women walking down the street in San Francisco, a guy hanging out at a mall, and a group of people at some kind of meeting.
However, looking at a random video isn't a good way to judge the service's utility. After all, if you looked at the average tweet or Instagram photo, it would look pretty boring, too. The point of Meerkat is to allow people to share snippets of their life with friends and family. And while watching snippets of a random person's daily life might be boring, getting a window into the life of your sister, best friend, or favorite celebrity might be more interesting.
Meerkat was created by a San Francisco–based startup that has undergone multiple rebrandings since its founding in 2012. The current incarnation has only been around since February.
The company previously created two apps called Yevvo and Air, but neither gained traction with users. Then, according to the Verge, one of the company's investors suggested building a simplified video-sharing app that just did one thing well: live video streaming. The result, which the company originally saw as a side project, has proved so popular with users that the company is now making the app its primary focus.
Over the years, quite a few apps have suddenly caught the public's imagination. Some of these, like Twitter and Instagram, went on to become huge, successful companies. Others, like Yo and Ello, quickly fizzled out after a brief flurry of interest.
It's too soon to say which category Meerkat will be in, but there are some reasons for skepticism. For one thing, past efforts to build amateur live streaming apps have not been very successful. Justin Kam, the founder of Justin.tv, says he tried some of the same strategies Meerkat is pursuing before he finally gave up on live video streaming in favor of Twitch, the video-game streaming service he sold to Amazon.
On the other hand, sometimes a startup will find a sweet spot that similar startups previously missed. YouTube was far from the first video-streaming website, but it launched at exactly the right time and with exactly the right features to become a huge hit. Perhaps Meerkat will be the startup that finally figures out how to make live, amateur video a viable business.
So far, most of the attention over Hillary Clinton's use of a private email account has focused on transparency concerns. But as I argued last week, the more serious concern is about security. By building her own homebrew email setup, Clinton may have made it easier for foreign intelligence agencies to keep tabs on her actions as secretary of state.
She was asked about this concern at today's press conference, and her answer was not reassuring.
If there were a security breach, there's no reason to think she would know about it
"The system we used was set up for President Clinton's office," she said, adding that it "had numerous safeguards."
Clinton said the server was "on property guarded by the Secret Service and there were no security breaches."
She didn't elaborate on those "numerous safeguards."
The reality is that if there were a security breach, there's no reason to think she would know about it. If a foreign intelligence agency had managed to hack into her server, they wouldn't have told anyone. Instead, they would have silently collected copies of her communications and sent them back home for analysis.
To be clear, there's no proof this actually happened. But there's ample reason to believe foreign intelligence agencies would have been trying to gain access, and that using a homebrew email system made Clinton more vulnerable.
And the fact that she would flatly state there were "no security breaches" — something she can't possibly know — suggests she either doesn't understand the challenges of keeping an email server secure or hasn't been taking the threat seriously.
Update: Clinton's office has put out a statement on the email controversy, but it don't provide much more detail on the steps she took to secure the system:
The security and integrity of her family’s electronic communications was taken seriously from the onset when it was first set up for President Clinton’s team. While the curiosity in the specifics of this set up is understandable, given what  people with ill-intentions can do with such information in this day and age, there are concerns about broadcasting specific technical details about past and current practices. However, suffice it to say, robust protections were put in place and additional upgrades and techniques employed over time as they became available, including consulting and employing third party experts.
Correction: I originally described the conference as a White House press conference, but of course Clinton is no longer in the Obama administration.
One of the first questions to come up in almost every discussion of the Apple Watch is: what is it good for? People have trouble imagining why anyone would want a tiny, underpowered computer strapped to their wrist.
But the funny thing is that people ask this question every time a new computing platform comes along that's an order of magnitude smaller than the one that came before. And people keep being surprised by how useful smaller computers can be.
Perhaps the Apple Watch will surprise us, too.


(Daniel Bagel)

In the late 1970s, Apple and other companies began selling personal computers. By the standards of the day, these new computers were tiny, cheap, and ludicrously underpowered. They couldn't run the powerful business applications of the day's conventional computers, which were the size of a washing machine and cost tens of thousands of dollars. People who were used to these larger computers couldn't imagine what they'd do without it.
The answer, it turned out, was run a new generation of applications that wouldn't have made sense on larger computers. People used PCs for word processing, spreadsheets, graphic design, computer games, and more.
These are all applications that only make sense on computers small and cheap enough that there can be one on everyone's desk. It would have been absurd for a company executive to go down to the computer room and tie up a $100,000 mainframe typing a memo. It was a lot cheaper and more convenient to use a typewriter — or to dictate the memo and have a secretary type it up. But once people had computers on their desk, it became obvious that word processors work a lot better than typewriters.


(Oscar Avellaneda-Cruz)

The same point applies to cellphones. It's hard to remember now, but a decade ago the idea of a cellphone with a camera in it seemed ridiculous. People mocked early BlackBerry users for trying to check their email on the go. But over time, people discovered that having a tiny, connected computer in their pocket is extremely useful.
And once again, people invented new apps that wouldn't have made sense on a PC. Apps like Uber or Instagram only make sense in a device that's small enough to always be in your pocket.
In both cases, what skeptics missed was that greater convenience (and lower cost) would lead people to use the new technology a lot more. If you've spent your life using film cameras — where developing a roll of film takes an hour and costs $5 — Instagram seems ridiculous. But once it takes five seconds to snap a photo and share it with your friends, people are going to do it a lot more.

Apple CEO Tim Cook describes the Apple Watch on September 9, 2014. (Justin Sullivan/Getty Images)
A similar point applies to smartwatches. It's true that any individual use for a smartwatch — say, reading a text message on your wrist rather than having to pull out your phone — is going to seem trivial.
But the thing skeptics are missing is that smartwatches won't just allow people to do the things they already do more efficiently. It could cause people to do more and different things. Smartwatches eliminate the small but real time-cost of pulling your phone out of your pocket. So short interactions that would have seemed too trivial to be worth pulling your phone out of your pocket suddenly make sense.
Of course, this is hard to imagine, just as it was hard for a PC user circa 1999 to imagine Instagram or Uber — or a mainframe user circa 1975 to imagine Excel or Photoshop. By the same token, we don't notice the things we're not doing with our smartphones because it's too much work to pull them out of our pockets.
But in the aggregate, these interactions could create a lot of value. Chris Mims runs through some of the applications developers are working on. For example, our watches might help us find items on our shopping list as we walk through the grocery store, alert us to historical markers as we pass them during vacations, or let us know when friends are nearby. These are all things we could do with our cellphones, but it's annoying to have our phones buzzing in our pockets all the time. Once our computers are on our wrists, they might seem a lot more compelling.
But the really important apps are likely to be ones no one has thought of yet. Steve Jobs wasn't trying to revolutionize the taxi business when he created the iPhone, but Uber and Lyft wouldn't exist today without multi-touch smartphones. By the same token, there may be apps that only make sense once millions of people have computers on their wrists. We just don't know what they are yet.


Apple is obsessed with making its laptops as thin as possible. On Monday, company execs touted the latest Apple laptop, the MacBook, as its thinnest yet.
The image above comes from the company's presentation, and it shows something astonishing: when you crack open the laptop's case, most of the space is taken up by its battery. Or, more accurately, batteries — plural. The irregular brown rectangles in the laptop's four corners, as well as the big one in the middle, are all batteries. The device's logic board — the brains of the laptop — is at the top. At the bottom of the image you can see the underside of the trackpad.
there's no Moore's law for batteries
This image provides a beautiful illustration of the differing trajectories of computer chips and batteries, the two inventions that have driven the mobile-computing revolution. A decade ago, that little logic board at the top would have been a lot bigger. But because of Moore's Law, chips keep getting smaller, cheaper, and more powerful, meaning we can now cram a full-powered computer into an area not much bigger than a deck of cards.
But there's no Moore's Law for batteries. While battery technology does get better, the pace of progress is glacial compared with the speed of Moore's Law. The amount of power a given volume of battery can hold hasn't changed much over the past decade. So each time Apple has squeezed a few millimeters of thickness out of its laptops, it has been forced to devote a larger fraction of the internal space to the battery. This has progressed to the point where the latest MacBook is mostly battery inside.
The most striking thing about today's Apple event is the price of the luxury edition of the Apple Watch. While the low-end Apple Watch Sport starts at $349, the high-end version starts at an astronomical $10,000.
Why did Apple do this? The obvious reason is: because it can. Presumably, the profit margin on a $10,000 watch — even an 18-karat-gold one — is huge. So if Apple thinks people will pay that much, why not do it?
But making a super-expensive version of the Watch serves another purpose, too. Apple's big challenge is convincing people that a watch can be a status symbol rather than a funny-looking gadget you strap on your arm. To solve this problem, Apple is using a strategy that previously helped Tesla make electric cars cool.
It's hard to remember today, but a decade ago electric cars didn't have a great reputation. Carmakers had experimented with a few electric vehicles, but these had not been a commercial success. The cars' primary selling point was their high fuel economy, but this wasn't very appealing when the cars themselves cost dramatically more than gasoline-powered alternatives.
Smartwatches have a reputation as impractical devices for nerds
Tesla's solution to this problem was to focus on the very high end of the market. The first Tesla car, the Roadster, cost $109,000. And Tesla's marketing focused not on its energy efficiency but on the sports car's extremely fast acceleration, made possible by its powerful electric motor.
This strategy of defying stereotypes about electric cars helped Tesla become one of the most prestigious brands in the auto industry. And as it has moved downmarket (the company introduced a $57,400 Model S in 2012 and is working on a vehicle that will cost $30,000), it has been buoyed by the luxury reputation the Roadster helped to establish.
Apple faces a similar challenge with its Watch. Smartwatches have a reputation as impractical devices for nerds. Apple's strategy is to defy this stereotype by creating luxury smartwatches that (Apple hopes) people will pay $10,000 for.
If this strategy works and Apple persuades people that its gold watches are in the same category as watches from Rolex and Cartier, it will create a halo effect that should boost the rest of Apple's product line. If rich and famous people are willing to shell out $10,000 for a gold Apple Watch, that will help persuade people that Apple Watches in general are cool.
Of course, the reverse is also true. It's possible that those $10,000 watches will sit on the shelf unsold. If this happens despite Apple's legendary marketing savvy, it will confirm that smartwatches remain hopelessly uncool.
Correction: I originally described the Apple watch as gold plated, but the watches are solid gold.
Apple held a big event on Monday, showing off the Apple Watch and unveiling other new products. Here are the three biggest announcements.

The Apple Watch. (Apple)
The Apple Watch will be available on April 24, with many of the features of a cellphone. Apple emphasized the watch's notifications, which will alert users of scheduled events, social media happenings, and breaking news. The watch will also let people make and take calls, read and send messages, make payments with Apple Pay, and track workouts, among other features. It will work with other Apple devices to navigate and install apps.
Apple said the battery will last up to 18 hours.
Apple Watch Sport, with a lightweight band, will start at $349. The mid-range Apple Watch will start at $549. The Apple Watch Edition, with an 18-karat gold band, will start at $10,000.

HBO Now is coming to Apple TV. (Apple)
Starting in April, Apple will offer a new HBO Now service on Apple TV, iPhones, and iPads called HBO Now. The service will cost $14.99, with a free month for new subscribers. Unlike HBO Go, HBO Now won't require any sort of cable service — just the online subscription.
CNN's Brian Stelter reported that HBO Now is supposed to be exclusive to Apple for the first three months, but Re/code clarified that HBO's existing TV providers may offer it before then.
Apple will also cut the price of the Apple TV from $99 to $69.

The new MacBook. (Apple)
The new MacBook, shipping on April 10, will be the lightest and thinnest in Apple's history, Apple said. It will have no fan to provide silent operation. The keyboard is also a new model in the hopes of offering a new, stronger type of click. The battery will last up to nine hours, thanks to a contoured design that packs batteries into a smaller space. The new MacBook will cost $1,299.
Steve Jobs famously said that "people don't know what they want until you show it to them." And no one is better than Apple at making us want things we didn't know we wanted. Today, the company is going to try to make us want new watches.
But the Apple Watch faces an extra hurdle that the iPod and iPad didn't, and the company knows it. As Reuters reported, CEO Tim Cook summed up the challenge as follows: "We've never sold anything as a company that people could try on before."
Reuters presents it as a question of whether the watch is a fashion statement or a gadget. But the problem is that the device seems likely to fail on both counts. Viewed as a gadget, the device is just too expensive given its limited functionality. Yet it's going to be an uphill battle to sell a square, bulky touchscreen device as a fashion statement. In trying to be both a gadget and a luxury item, it's at high risk of falling in the no-man's land between the two.

(Justin Sullivan/Getty Images)
Apple has its work cut out for it. The watch starts out at $350 for a Watch Sport — not stratospherically expensive, but by no means cheap ... and even the midrange watch starts at $550. It also requires an iPhone for most of its functions. That means the prime Apple Watch audience isn't just going to be iPhone users (or people willing to go out and buy an iPhone purely for the watch), but iPhone users who will buy wearables and find the watch attractive and want to splurge.
Right now, sales estimates for the watch are scattershot, as Business Insider reports, ranging from 10 million up to 60 million. No one seems to know exactly who will be buying the thing.
Apple is limited to iphone users who will buy wearables, think the watch is pretty, and want to splurge
One challenge will be convincing people to buy this new gadget when it doesn't quite feel so new — that is, when they already have lesser versions of it on their wrists. But getting people to buy the Apple Watch will require a bit more convincing, in large part because it doesn't quite feel so new.
"As they compare the Apple Watch and their current Swatch, Fitbit, or mobile app, many are concluding that it doesn’t solve an unmet need," wrote market research firm Forrester Research in a November report on the watch. They added, "The iPhone 6 is the immediate must-have, while the Apple Watch is an eventual 'might-have.'"
A lower price point might make people think differently about what sort of computer they want strapped to their wrists. But if customers perceive the watch is simply a few of their existing products mashed into one, lining up for an Apple Watch (particularly at $350 and up) might not seem all that necessary. And that $350 is just for the lowest-end Watch Sport. The more professional-looking Watch, with its metal or leather bands, will start at $550.
Of course, it's impossible to know just how useful a gadget is until people have it and put it to use. The watch may have features we don't know about yet that prove so indispensable people find they can't live without it. Techcrunch, for example, went so far as to suggest that wearing the watch will give people more time in their lives — time they'd normally spend poking at an iPhone. Indeed, the watch does some cool things, like sending messages and tracking heartbeats. So maybe many people just don't know they want it yet. But right now, it's hard to see how the Apple Watch's feature set — which largely consists of allowing you to look at your wrist instead of your phone — could justify its price tag of $350 or more.

(Self magazine)
Yes, Apple is known for its design chops (see Apple design guru Jony Ive's tech-celebrity status for proof). But never before has Apple created a product that people will display on their wrists all day long.
This puts the watch in a different category from Apple's other products that hide in purses and pockets. Even if the watch is as beautiful and well-functioning as Apple can make it, it's still going to look the way it looks. The question is whether people will like it. And if people don't want a light-up, square watch on their wrists, they won't wear it.
Apple may find women to be tougher customers than men. Watches are the one type of jewelry men commonly wear, while women accessorize in lots of other ways, as Euromonitor writes in a recent report on the watch market.
many women want their watches to look like bracelets, not timepieces
"Women are less likely to be interested in luxury watches, as wearing jewelry is part of the gender norm," they write. "On the other hand, men are more likely to be interested in purchasing luxury watches, because wearing jewelry outside of wedding bands is less the norm. A luxury watch can be a man’s one fashion statement."
Not all of Apple's watches are exactly "luxury" watches (though the gold-cased Apple Watch Edition, which could cost several thousand dollars, certainly fits this bill), but $350 is still $350. Getting people (women or men) to put money down for it will mean convincing them that this is a piece of jewelry they want to flaunt — even if they don't quite think of it as jewelry.
Not only that, but as Euromonitor also notes, women prefer smaller watches than men do. Apple does have two sizes, but the smaller Apple Watch is still 38 millimeters — not exactly delicate enough for those who want something that looks more like a bracelet and less like a timepiece (especially a square, digital timepiece). For proof, look at the watch on the Self magazine cover or at Apple's 12-page advertising spread in Vogue; you can make the case that the watch looks good, but doesn't exactly look like it could blend in.
Apple clearly knows it has to make not just the tech case for the Apple Watch (which it barely even needs to do, given the tech news and blogosphere's obsessive coverage of all things Apple) but also the fashion case. Making sure the product is highly visible not just in Macworld and TechCrunch but in fashion publications, like the Self cover and Vogue spread (not to mention Vogue's Ive profile), could go a long way toward making people see the watch as attractive...but never before has that attractiveness bar been set so high for Apple. So maybe many people just don't know they want it yet. But right now, it's hard to see how the Apple Watch's feature set could justify its price tag of $350 or more.
Back in 2014, lots of tech-watchers were hoping the much-hyped Apple Watch would feature kinetic charging. The idea is that the movements of the wearer would charge the watch's battery.
Unfortunately, the Apple Watch — out today — has no such thing, and the watch will have to be charged overnight. But kinetic charging wasn't a totally unrealistic dream. Seiko already has a line of kinetic watches, and Apple filed a patent for a kinetically charged device in 2009.
In fact, watches that charge themselves actually go back more than 200 years.

The interior of the perpetuelle watch. (The British Museum)
Abraham-Louis Breguet invented the first wristwatch in 1810 and designed watches for Marie Antoinette, Napoleon, and other royal clients. But one of his most striking creations was this pocket watch, created in 1787 in Paris, that included an automatic winding system called a "perpetuelle."
Inside the watch, a silver-filled platinum weight would wind the watch, driven by the constant movement of the wearer. It was an incredible innovation, and Breguet's fanboys were just as fanatical as Apple fans are about the Apple Watch today. People gathered in crowds to see the self-winding watch when it was put on display, and Marie Antoinette was the first person to order one. The watch had other bells and whistles, too, like an alarm that sounded every hour and quarter hour, and a dial that showed the state of the watch's "charge."
Breguet died in 1825, but his name lived on through his company. And in 1835, that company built another watch based on its founder's idea. It might sound familiar: it was a pocket watch that could "dock" in a larger clock and "charge" overnight.
It's probably unfair to compare the perpetuelle to the Apple Watch — only one of them has to send stock updates. Still, at least Jony Ive has a resource when brainstorming his company's next watch. Maybe he'll catch up.
Andrew Nacin has noticed what might be the most consumer-friendly innovation in Apple's newest MacBook: fliers may be able to use the laptop during airplane takeoff and landing.

A two-pound MacBook is exactly light enough per FAA regulations be used during taxi, takeoff, and landing.


The FAA guidelines to which Nacin refers were written in late 2013 and, indeed, do require that all personal electronic devices, or PEDs, that weight two or more pounds must be stowed as the plane lifts off and lands. There is, however, some discretion given to the pilots. They are allowed to ask passengers to stow lighter devices if they "are of a size that would impede egress."

(FAA)
Will pilots look kindly on the flier who protests the request to "close all laptops," noting that theirs weighs two pounds? Probably not, but who knows! Either way, we're about to find out.
Price: $349 (38 mm), $399 (42 mm)
The sport is the lowest-end watch. Apple says the Sport is lightweight, with a scratch-resistant, ionX screen and an aluminum case that the company engineered to be extra strong. The case comes in steel and space gray. The band comes in fluoroelastomer, and in five colors: white, blue, green, pink, and black.
Price: $549–$1,049 (38 mm), $599–$1,099 (42 mm); price depends on band
The Apple Watch cases will come in two colors: stainless steel and space black. The stainless steel, like the Watch Sport's aluminum, is made to be extra-strong and nick-resistant. The black version has a carbon coating. The Watch allows for a wider variety of bands than the Sport — leather, metal links, metal mesh, and a fluoroelastomer sport band.
Price: starts at $10,000
This is the luxury edition of the Apple watch, and according to Cook, it will only be available in "select retail stores." Not only is the Watch Edition's case fashioned from 18-karat gold; it's a sort of supergold that Apple crafted to be "up to twice as hard as standard gold," according to the company's website.
There's been a lot of discussion about the technical specs and features of the new Apple Watch. But in this video, NYU professor Scott Galloway says he believes the Apple Watch is about something more primal: sex.
"Tesla is not an environmental car," he says. "The core axiom of evolution is men paying $150,000 for cars that can go 160 miles an hour in domains where you can only go 55. Women will continue to pay $600 for ergonomically impossible shoes to try and solicit inbound offers from those same men."
Galloway believes the Apple Watch is part of the company's effort to transform itself into the next great luxury brand. These brands are able to charge outrageous prices not because they're dramatically more useful than cheaper alternatives, but because owning luxury products is a way of signaling that you have good taste and — yes — that you're wealthy. Which, as Galloway sees it, will improve your prospects on the dating market.
(Hat tip: Joshua Brown)
Google is getting into the wireless business, a company executive admitted last week. That might mean cheaper wireless service for all of us.
Google isn't building its own cellular towers — that would be way too expensive. Instead, Google will purchase capacity from other wireless carriers and resell it as a Google-branded service. The new service might launch before the end of the month.
By seamlessly combining expensive cellular service with cheap wifi, Google is expected to offer a service that's a lot cheaper than conventional wireless plans. Google wouldn't be the first to use this technique — it was pioneered by a startup called Republic Wireless — but a Google service would help to push the concept into the mainstream. And that will put pressure on wireless providers to cut their prices.



Google, state, and city officials gathered at the Provo Convention Center to announce that the city has been chosen as the third city in the country to get Google Fiber on April 17, 2013. (George Frey/Getty Images)

The wireless project bears some similarities to Google Fiber, the effort to build a super-fast fiber optic network in Kansas City — and later other metropolitan areas. When the Google Fiber project was launched about five years ago, it helped to highlight how far behind the curve incumbent phone and cable companies had fallen.
When it launched, that network was 10 to 50 times faster than service available in other parts of the country. Building it pressured broadband providers across the country to upgrade their networks, which made Google products — especially the bandwidth-hungry YouTube — work better.
Google may be trying to do something similar in the wireless market. The two biggest wireless providers, AT&T and Verizon, have been charging high prices for plans that limit how much data users can download. If Google is able to offer a cheaper service, it would pressure conventional wireless providers to offer cheaper plans with fewer restrictions. That can only help Google's many online services. And it would be good for consumers, too.


(hon ning tse / Getty)
Google's goal here probably isn't to dominate the wireless industry. That would be too expensive even for the deep-pocketed search giant. Building a wireless network from scratch requires constructing thousands of cellular towers and buying billions of dollars' worth of electromagnetic spectrum. These high costs are a big reason there are only four national wireless carriers: AT&T, Verizon, Sprint, and T-Mobile.
Instead, Google is planning to become a mobile virtual network operator (MVNO). That's a company that resells other companies' wireless service under its own brand. Examples of existing MVNOs include Boost Mobile, Cricket Wireless, and Virgin Mobile. From the customer's perspective, the distinction between MVNOs and conventional carriers doesn't matter very much. Many customers won't even realize that Google is reselling service from other companies.
According to the Wall Street Journal, Google is planning to partner with Sprint and T-Mobile, the two smallest of the nation's four wireless providers.


(John Moore/Getty Images)

So why jump into the wireless business? It looks like Google's plan is to save money by helping people use cheap wifi networks more — and expensive cellular networks less.
Wifi equipment is so cheap and user-friendly that anyone can set up a wifi network for their home or office. But most cellphones aren't set up to take full advantage of these potential savings. Switching from a wifi network to a cellular network in the middle of making a phone call or browsing the web causes dropped connections. As a result, our smartphones consume a lot of expensive cellular bandwidth when they could be using cheaper wifi service instead.
In 2011, a startup called Republic Wireless launched a new service designed to use wifi networks more efficiently. Today, the company offers unlimited talk, text, and data for $40 per month using a high-speed 4G network. Or, if you can live with the slower speeds of older 3G networking technology, you can get unlimited talk, text, and data for $25 per month. That's two to four times less than the cost of a conventional wireless plan.
Republic Wireless's service only works with Android-based Motorola phones that Republic has customized to support seamless switching between wifi and cellular networks. The Wall Street Journal reports that Google's service will have a similar limitation: it will only work with the Nexus 6, a phone that's also made by Motorola.
According to the Journal, Google "expects to launch the service in coming weeks, but the start may be delayed."
Correction: This article originally stated that Motorola was a Google subsidiary, but the unit was sold to Lenovo in late 2014.
The Apple Watch, due out on Monday, will have a display made from a pretty exotic material: scratch-resistant sapphire glass.
Rumors long held that the iPhone 6 would actually be made of sapphire glass. But those rumors were wrong, and Apple elected to use the material in a watch instead.
Here's an explanation of what sapphire glass actually is — and why it might make more sense for a watch than a phone.
Sapphires are most well known as rare blue gemstones that form naturally. But just like diamonds, sapphires can be made synthetically — in fact, the first synthetic sapphires were made back in 1902.
The process used to make sapphire today is essentially the same as it was a century ago. The natural compound aluminum oxide is ground into a powder, then heated to at least 3,600 °F. For use in a device like a watch, it's then processed into sheets — and without any impurities present, the resulting sapphire glass is a totally clear material.
The Apple Watch certainly isn't the first use of sapphire glass in a consumer electronics device. The iPhone 5 and 5S made use of sapphire glass in their camera lenses, which made them virtually unscratchable. Plenty of high-end watches also use sapphire-glass faces for the same reason.

(LOIC VENANCE/AFP/Getty Images)
The reason why you might want a watch with a sapphire-glass display is pretty straightforward: it's extremely difficult to damage. As materials scientist Neil Alford told Forbes, sapphire is a nine on the Mohs hardness scale. The hardest material on it — diamond — is a 10.
Covering a watch in sapphire glass will make it much more scratch-resistant than the iPhone. This video isn't showing an actual iPhone 6 display, but Alford did tell the Guardian that it seems to be sapphire glass anyway. In theory, the Apple Watch should be just as hard and difficult to scratch as the piece of glass in the video:

To date, smartwatches haven't really taken off. There are a few reasons for this, but one might be that people are hesitant to shell out hundreds of dollars — in addition to buying a smartphone — for a fragile piece of electronics that could get cracked or broken anytime a user merely hits his or her wrist on a doorway. Unlike phones, smartwatches can't be used with a case.
Apple presumably hopes to remedy this situation by billing the watch as a totally scratch-proof technology.

(Sean Gallup/Getty Images)
There are a few possible reasons why Apple still hasn't decided to use the material in its phones.
One is cost. Right now, sapphire glass is more expensive than Gorilla Glass, mainly because it has to be heated to a higher temperature and purified more thoroughly during production. Using tiny pieces of sapphire glass for the camera lens and home button isn't a big deal, but larger sheets covering every iPhone could substantially raise the production cost.
But this price could come down, experts say, if Apple (and other companies) begin using enough sapphire glass to significantly increase the scale of production. In that event, putting small pieces of sapphire glass in watches could be a gateway to putting larger ones in phones.
However, there may be a reason why sapphire glass won't be suitable for phones at all. It's super-hard, but some experts note that it may be a bit less flexible than the Gorilla Glass used in iPhones. This could make it more prone to shattering upon being dropped if a big slab of it were used to support a large, 5.5-inch phone.
Read more:
On Monday, March 9, at 1 pm eastern, the world will get a long-awaited introduction to the Apple Watch. Well, call it a re-introduction; we got the first look at it in September, when the company also revealed Apple Pay and its new iPhone 6 models. But Apple's announced "Spring Forward" event is expected to be all about the Apple Watch, giving us the specifics on when we can get it, how much it will cost, and what, exactly, it will do. Here's what we know right now.
Sometime in April, as Tim Cook announced in January. On Monday, everyone should know for sure when to start lining up (or avoiding) their nearest Apple Store.
The starting price is $349, Apple announced in September, but some versions of the watch could be far more expensive. There are three versions: the regular watch, the Watch Sport, and the Watch Edition. The Edition is the highest-end model, available in yellow gold or rose gold, and guesses of its price are all over the place — back in September, one estimate was $1,200, but now some are saying it could be several thousand dollars.
No. But there are so many colors of cases and bands that you can probably find something you like. On the website MixYourWatch, you can see what different combinations look like.
No — it's more of an add-on. The watch will communicate with your iPhone via Bluetooth, showing you when calls and messages are coming in, for example. But you'll still need an iPhone nearby in order to make phone calls.
All sorts of things. Thus far, we know the Apple Watch will:
We've learned a bit more about the technical side of the watch. For example, Apple is trying to ensure battery life of around 2.5 hours with "heavy" application use, according to 9to5Mac, and 4 hours of "exercise tracking." But then, with normal wear, the screen won't always be on, which should make for a much longer life — the site also reported that Apple was, as of last year, shooting for 19 hours of battery life, including those periods when it's asleep. Altogether, the battery life is looking to be a lot like that of other smartwatches, according to The Verge.
We're also learning about how apps will look on the watch. AppAdvice has created an Apple Watch apps site, WatchAware, that shows how a wide variety of apps will look and work on the Apple Watch.
On a more conceptual level, we've learned that Apple is really making a push for selling the watch as an accessory, not just a gadget. We already knew Apple hired watch designers from luxury brands like Tag Heuer to design the watch, as Vox's Kelsey McKinney reported last year. But in the past few weeks, it has also appeared on the cover of Self magazine and in a 12-page advertising spread in Vogue, signaling that Apple really wants to emphasize the watch's look, not just its functionality.
What do you do when all the good world records have been set? Hire Guinness to help you invent some new ones.
On January 28, 2015, workers at United Biscuits stacked a bunch of books in a line to achieve a new world record: "Most books toppled in a domino fashion." They ended up toppling 5,318 books (for the sticklers out there, 182 of the initial 5,500 books were disqualified, but there were still enough to break the record).

It was impressive, but it's also a metaphor for Guinness's changing business model. As the books fall, something else has to take their place. Today, Guinness World Records doesn't make all of its money off selling record books. Instead, a big chunk of its business comes from helping companies invent and break new records — to get publicity.

The world's shortest man with a stack of Guinness World Record books. (Andrew Cowie/AFP/Getty Images)
To be clear, Guinness still sells plenty of record books — reportedly 1 million copies every year. But with the book industry in a state of turmoil, the company is increasingly trying to diversify.
So, since being acquired in 2008 by the same company that owns Ripley's Believe It or Not! museums, Guinness has vigorously experimented. In addition to building museums that follow the Ripley model, it's expanded into areas like "consulting services," which in 2013 made up 20 percent of the company's revenue.
What does Guinness consulting look like? Basically, Guinness sends its judges (dressed in their official uniform, of course) to judge "records" set by various companies (like United Biscuits). These records, in turn, receive some media attention, a service that Guinness has valued at $330,000.
It's easy to find similar "records" being set by CBS, Planetside 2, Nissan, and others. For those keeping track of media trends, Guinness is essentially a native advertising firm now, seamlessly mingling content with marketing. And it's pretty good at it.

Part of that business model change may be because Guinness doesn't have records to itself anymore. Today, internet companies like RecordSetter directly compete with Guinness by expanding the "record" formula and making it even more absurd. If you want to snuggle in a hammock with bunnies or hold 9 barstools in the air, you can set a record.
That competition shouldn't be a surprise. Many of Guinness's records — like "world's longest fingernails" — were tailor-made for today's internet culture, and other companies are gleefully pursuing the concept. YouTube channels like Dude Perfect — where friends make a bunch of trick shots — may not have Guinness's legacy or official "record" patina, but they do have almost 4 million more YouTube subscribers than Guinness.
That's the reason Guinness is working so hard to be more than a book company. It has a lot of competition to get eyeballs, not just book buyers. And it knows that a judge is waiting nearby with a notebook in hand — because, eventually, that last book will fall.
This week, Katharine Zaleski confessed her sins against motherhood on Fortune, and it went viral.
Zaleski is now the cofounder and president of PowerToFly, a firm that works to match women with flexible jobs. But before that, she was working in media, at the Washington Post and Huffington Post.
Her column no doubt did well for the sheer shock value. (She recounts how she said nothing when an editor proposed firing someone "before she 'got pregnant.'") But another reason it resonates so strongly could be that the worst of Zaleski's actions line up with emerging research around the ways women — especially moms — are discriminated against in the workplace. Women have felt this for years. But the research, and now the confessions, are catching up.
Zaleski recounts a few of her worst transgressions:
1. I secretly rolled my eyes at a mother who couldn’t make it to last minute drinks with me and my team. I questioned her "commitment" even though she arrived two hours earlier to work than me and my hungover colleagues the next day.
2. I didn’t disagree when another female editor said we should hurry up and fire another woman before she "got pregnant."
3. I sat in a job interview where a male boss grilled a mother of three and asked her, "How in the world are you going to be able to commit to this job and all your kids at the same time?" I didn’t give her any visual encouragement when the mother – who was a top cable news producer at the time – looked at him and said, "Believe it or not, I like being away from my kids during the workday… just like you."
4. I scheduled last minute meetings at 4:30 pm all of the time. It didn’t dawn on me that parents might need to pick up their kids at daycare. I was obsessed with the idea of showing my commitment to the job by staying in the office "late" even though I wouldn’t start working until 10:30 am while parents would come in at 8:30 am.
It's easy to see why the column went viral: it's not only enraging, but it's also a conversion story — once Zaleski had a baby herself, the scales fell from her eyes and she realized the error of her ways.
we're very good at honoring motherhood. but we seem to have trouble when moms need a paycheck or have career aspirations.
She also gets into some of the very issues researchers have begun uncovering.
For example, many working moms know that "opting out" isn't always opting out. Zaleski's story echoes an eye-opening December study of Harvard Business School alums. Many of those high-achieving women had stopped working, not because they wanted to be stay-at-home moms but because the working world had started to shun them.
[T]he vast majority leave reluctantly and as a last resort, because they find themselves in unfulfilling roles with dim prospects for advancement. The message that they are no longer considered "players" is communicated in various, sometimes subtle ways: They may have been stigmatized for taking advantage of flex options or reduced schedules, passed over for high-profile assignments, or removed from projects they once led.
Some women get subtle messages, as Harvard's researchers write...and as Zaleski shows, some women get interviewers asking them how they'll commit to a job and kids at the same time.
A lack of flexibility for parents can also show up in women's paychecks. For example, Zaleski expected parents to conform to a non-parent schedule, coming to 4:30 pm meetings. That kind of rigidity can prevent women from keeping up with men. Harvard economist Claudia Goldin found in a 2014 study that flexibility in hours plays a huge part in creating more pay equality between men and women. As she wrote, "The gender gap in pay would be considerably reduced and might vanish altogether if firms did not have an incentive to disproportionately reward individuals who labored long hours and worked particular hours."
It's true that Zaleski and Harvard Business School alums are breathing some rarefied air. But even the most basic kind of flexibility is unavailable to many American workers. According to the White House, only 39 percent of US workers report having access to paid family leave for the birth of a child. Even more shockingly, employers say only 11 percent of workers are covered, meaning some employers may be offering informal arrangements.
It's true that not all bias in the workplace is as deliberate as that in Zaleski's former world — indeed, a lot of it may be subconscious. But it reflects a twisted attitude — that our society values motherhood but not the mothers themselves. In cards, poems, songs, movies, books, even commercials, we are very good at honoring mothers for being moms. What we seem to have trouble with is when those moms need to earn money or want to advance their careers.
Most of the criticism following the revelation that Hillary Clinton used a personal email account for official business as Secretary of State has been based on suspicions that she was trying to evade transparency laws that require federal officials to preserve their  communications.
But the more serious problem with Clinton's do-it-yourself approach to email isn't about transparency. It's about national security. Creating a secure email system is difficult, and it's unlikely that Clinton's homebrew email system was as secure as the official email system that would have been provided to her by the State Department.
That means that for four years — years when she was involved in numerous high-stakes negotiations — she was communicating in a way that made it easier for foreign intelligence services to keep tabs on her. We don't know if any foreign spy agencies took advantage of this opportunity. But it was reckless to give them the opportunity.


National Security Agency headquarters in Ft. Meade, MD. (NSA)

According to an Associated Press story published this morning, Hillary Clinton didn't just have her own, private email address. She set up a private system to host her email. The AP suggests this server may even have been located in her house in New York.
Running a secure online service is difficult no matter who you are. Online security is an arms race: hackers are constantly discovering new security flaws, while software makers are rushing to patch them before they can be used to hack into vulnerable software. This is why big software companies like Google and Microsoft have hundreds of people on staff who do nothing but deal with security threats.
Most people who run their own email servers have one big advantage: no one is likely to target them personally. But of course Hillary Clinton wasn't an ordinary person between 2009 and 2013. She was the top diplomat of the most powerful country in the world. Every foreign intelligence service on the planet was interested in her private communications.
And securing a server against foreign governments is a lot more difficult than securing it against garden-variety hackers. Foreign countries like China and Russia have their own versions of the National Security Agency — agencies full of smart hackers who have spent years studying how to break into computer systems. It's likely that these governments — like the NSA — have an inventory of security vulnerabilities that haven't yet been discovered by the broader hacker community (information about flaws in popular software can be purchased in underground markets).
And while the federal government is not generally known for its IT savvy, the feds do take IT seriously when it comes to issues of national security. It's likely the NSA has worked with the State Department to ensure that agency's email is as secure as possible.
We asked a Clinton spokesman if she had taken measures to secure the domain against foreign attackers. He answered with a single word: "absolutely." But he didn't provide details.
Of course, it's possible that Clinton hired a small army of computer security experts to administer her server, and they made it just as secure as Gmail or the State Department's email system. But it's not very likely. And more to the point, it would have been hard for Clinton — who is not, herself, an expert on computer security — to know whether she had taken sufficient precautions.


Knowing which aides have a Secretary of State's ear during negotiations can be a powerful advantage. (Jonathan Ernst/Getty Images)

The Clinton camp has emphasized that Clinton did not send any classified information from her personal email address. Even if this is true, it doesn't excuse Clinton's decision to use a personal email address for official business.
During her time as Secretary of State, Clinton was intimately involved in a wide variety of sensitive negotiations with foreign governments. In this type of high-stakes negotiation, seemingly mundane information can provide valuable insights.
For example, the tone of emails she sent could give insight into the Secretary's mood, which could inform decisions about when to push for a deal and when to delay negotiations. Information about how frequently Clinton met with different aides could give insight into whose advice she trusted most (and therefore what the US negotiating posture was likely to be). Similarly, information about which domestic interest groups got meetings with the Secretary could provide valuable information about US priorities.
In short, knowledge is power. By creating her own personal email server, Clinton took the risk that America's adversaries could gain invaluable information about her private communications. That was a big mistake.
The furniture giant Ikea has announced a new line of furniture with built-in wireless charging pads. If you have a compatible phone, you can set it on top of the pad, and it will draw power without having to plug anything in.
Ikea is entering the market with a range of products including tables, desks, and lamps, which will go on sale in the United States on April 15.
Many cell phones already support wireless charging, and this is expected to become a standard feature in the next few years. But a big obstacle to widespread adoption is the lack of a universal industry standard. There are two competing technologies, and phones designed for one won't work with charging pads built with the other.
Wireless charging will only work if your smartphone supports the same charging standard as the charging station. And right now, there are two different wireless standards being developed, each with a roster of influential companies behind it (Some major vendors, including LG and HTC, are members of both groups.):


This battle is of interest not only to device makers, but also retail establishments that might offer charging stations. For example, Starbucks has signed on to offer Powermat charging stations in its San Francisco stores.
Ikea joining the Wireless Power Consortium is a bit of a risk because it means that if the Alliance for Wireless Power eventually prevails, the charging stations in Ikea's furniture could quickly become obsolete. Then again, Ikea's support could help the Wireless Power Consortium win.
This kind of standards battle isn't uncommon. Thirty years ago consumers had to choose between the VHS and Betamax standards for VCRs (VHS eventually won). More recently, there was a fight between the HD-DVD and Blu-Ray standards for high-definition video discs (Blu-Ray won).
At some point in the next few years, we can expect this race to reach a tipping point, where a critical mass of companies endorse one standard and support for the other one collapses. That means winning a prominent supporter like Ikea is a big deal because it increases the chances that the WPC will prevail.
Warren Buffett's annual messages to the shareholders of Berkshire Hathaway are always full of interesting observations about the business world. This year he treated us to a brief explanation of how the tax code, the predatory instincts of Wall Street, and the frailties of human nature create an opportunity for him to make money:
At Berkshire, we can — without incurring taxes or much in the way of other costs — move huge sums from businesses that have limited opportunities for incremental investment to other sectors with greater promise. Moreover, we are free of historical biases created by lifelong association with a given industry and are not subject to pressures from colleagues having a vested interest in maintaining the status quo. That’s important: If horses had controlled investment decisions, there would have been no auto industry.
What he's saying is that some businesses are profitable, some businesses are promising. Coal mines, for example, make money. But solar power is exhibiting more potential for growth. There's money to be made in shifting funds from the profitable businesses to the promising ones.
Shifting money from profitable businesses to promising businesses is what financial markets are supposed to do. But, Buffet says, there are three impediments that make it harder to do this — impediments that his company is in a unique position to overcome:
Of course these structural explanations for Berkshire-Hathaway's success only take you some far. Picking the right investments is still hard. But Buffett's letter is a reminder that his success isn't just skill or luck, it's also based on some big structural factors.
Yesterday the Federal Communications Commission established America's strongest network neutrality rules yet. The document, which reportedly weighed in at more than 300 pages, will transform how the nation's broadband services are regulated.
But if you want to read it, you'll need to wait a few days. Or maybe weeks. That's ridiculous.
It's true, as the Washington Post's Brian Fung writes, that there's nothing unusual about the delay. Administrative agencies often keep drafts of their rules secret while they're working on them, and it's not uncommon for it to take a few weeks for rules to be published. The delay certainly isn't evidence that anything sinister is going on.
But the FCC's secretive approach during rule drafting forces media to report on summaries, spin, and snippets. The result is less accurate and less comprehensive coverage. Meanwhile, the lack of transparency gives disproportionate influence to big players who can leverage their connections to insiders to find out what's really going on.
The FCC isn't alone. It and other government agencies can and should be more transparent. Publishing draft rules before they're voted on, and publishing final rules as soon as they're approved, will make it easier for voters to understand and influence the process, for the media to provide accurate and comprehensive coverage. It will also curb the unfair advantages of special interests.


The Administrative Procedure Act, which still governs agency rulemaking, was signed by President Harry Truman. (Keystone/Getty Images)

Modern administrative law has its roots in the 1946 Administrative Procedure Act, which established the process the FCC followed to put its network neutrality regulations into effect. The process started with the FCC publishing a notice of proposed rule-making, which in this case happened last May. Then, there was a mandatory public comment period, which generated more than 4 million responses.
FCC Chairman Tom Wheeler completed a draft of his proposed network neutrality rules three weeks ago and distributed them to other FCC commissioners. He announced the rules in a Wired op-ed and posted a 4-page summary to the FCC website. But he didn't release the actual language of his proposed regulation to the public. Eventually, the new rules will become public when they're published in the Federal Register. But that might not happen for a few more weeks.
This was considered a transparent process by the standards of 1946. But in the age of the internet, the public justifiably expects more from the government. And administrative agencies like the FCC have not been keeping up.
A big problem with the current approach is that it gives insiders unfair influence over the FCC's deliberations in the final days before the regulations are approved. As far as I know, no one outside of the FCC had access to full drafts of the final rule. Still, someone was feeding well-connected interest groups information about what the FCC was planning. For example, Google somehow got wind of a provision it thought would be counterproductive and sent the FCC a letter last Friday urging a change. Reuters reported on another last-minute lobbying blitz against a provision that many regarded as too vague.
In theory, the public was supposed to give the FCC this kind of feedback last year, during the official public comment period. But the FCC's plans have changed significantly since last May. Most of the language that sparked last-minute lobbying this month wasn't in the original proposal. So this kind of last-minute feedback is essential to helping the FCC avoid making a costly mistake.


These didn't exist in 1946. (Torkild Retvedt)

But there's no good reason for these things to be linked. Wheeler could have posted the full text of his proposal to the FCC's website three weeks ago, and then posted periodic updates. Then anyone — not just deep-pocketed interest groups — could read the draft and submit feedback to the FCC. That kind of public scrutiny would lead to better rules that are less tilted toward the interests of insiders.
Nor is there any good reason to withhold the final text of the rule after the vote. Reportedly, a big reason for the delay is that the FCC's five commissioners are still working on their official public comments on the new regulations. We can expect the two Republican commissioners to make the case against the rules and the Democrats to make case for them. But the agency could easily release the text of the rule first, and these statements later.
Withholding the actual text puts journalists at the mercy of the FCC's PR operation for information about what the regulation does. There's intense public interest in the FCC's new rule on the day it's approved. But if the text isn't public, we can only repeat the summaries the FCC has provided us. That summary might be biased or leave out important details.
The FCC could learn a lot from the Supreme Court, which also publishes opinions making the case for and against the majority's decision. But the Supreme Court gets all of its opinions properly edited before the decision is released to the public. That means that the press and the public can read the full text of a Supreme Court opinion within minutes of when the court announces its decision. That allows the media to report on the court's full decision, instead of having to rely on summaries or leaks.
The basic problem here is that regulatory agencies haven't adjusted to the capabilities of the internet. Back in 1946, there was no easy way for agencies to make draft regulations widely available — agencies didn't have websites, after all — so the procedures Congress laid out didn't require it. But thanks to the internet, agencies can and should be more transparent and move faster.

The Federal Communications Commission on Thursday approved its strongest set of net neutrality rules yet. Prior to the vote, FCC Chair Tom Wheeler pointed to the 4 million comments his agency received from the public throughout the process, using them as an example of why corporations shouldn't dictate access to the internet.
"Those 4 million comments also illustrate the importance of an open and unfettered network, and the role it plays as a core of free expression and democratic principles," Wheeler said. "While some other countries try to control the internet, the action that we take today is an irrefutable reflection of the principle that no one, whether government or corporate, should control a free and open access to the internet."
Wheeler hit the same point again and again in his speech: "The internet is the ultimate vehicle for free expression. The internet is simply too important to allow broadband providers to be the ones making the rules."
Listen to the best segments of the speech above.
When the Federal Communications Commission voted Thursday for stronger network neutrality regulations, liberals cheered. Conservatives, on the other hand, blasted the new regulations as a dangerous government overreach, and GOP lawmakers vowed to pass legislation to partially reverse the agency's actions.
But while this week's vote was a setback for conservatives, the right is winning the broader debate over internet regulation. Even after the vote, the government will take a more hands-off approach than it did during the Clinton years. Indeed, the approach Clinton's FCC pursued has become politically toxic. And FCC chairman Tom Wheeler has emphasized that he has no intention of exercising the full authority granted to him by a Republican Congress in 1996.
While conservatives might be out of power, their philosophy continues to shape how we regulate the internet. The dangers of excessive government regulation are accepted across the political spectrum, while concerns about big telecom companies abusing their monopoly power have become less and less salient.



(Chip Somodevilla/Getty)

The most contentious issue in the contemporary network neutrality debate has been "reclassification," a legal maneuver that gives the FCC broader authority to regulate the internet. The FCC needed to reclassify in order to enact strong network neutrality regulations, but conservatives warned that doing so would open up a Pandora's box of burdensome regulations.
The awkward thing about this is that the rules were drafted by a Republican Congress in the 1996 Telecommunications Act. In that legislation, Congress created two legal categories for online services: a low-regulation category for online services (known unimaginatively as Title I) and a high-regulation category for companies that provide basic infrastructure (called Title II).
When telephone companies began offering broadband access using a then-new technology called Digital Subscriber Lines, it was widely accepted that Title II — the stricter regime designed for basic infrastructure — would apply. After all, telephone companies had been governed under Title II for decades before that. Title II rules had ensured that telephone companies didn't strangle the burgeoning market for dial-up ISPs, which provided internet access over telephone lines.
But that began to change when the FCC under George W. Bush decided not to apply the stricter regime to the new technology of cable internet service. That led to a lawsuit arguing that the law required both cable and DSL internet service to be classified under Title II. The case went all the way to the Supreme Court, which ruled that it was up to the FCC to decide how to regulate broadband.
The Supreme Court vote was 6 to 3, but interestingly the vote was not along party lines. The conservative Antonin Scalia, who had practiced telecommunications law before joining the court, wrote a colorful dissent arguing that the law required the application of the stricter rules to the internet.
A decade later, many conservatives argue that applying these stricter rules to network neutrality rules would constitute a dangerous government takeover of the internet. They usually don't mention that the rules were drafted by Republicans, and that Justice Scalia believed the law required them to be applied to broadband networks.


(Frédéric BISSON)

In the 1990s, liberal advocates for an open internet were not focused on network neutrality, a term that hadn't been invented yet. Instead, most favored a totally different regulatory strategy called unbundling.
The best way to understand unbundling is to think about how internet access worked in the dial-up era. Back then, your telephone company usually wasn't your ISP. Instead, your ISP was an independent company like AOL or Earthlink that used a phone company's lines to reach customers. These ISPs were protected by strict regulations that prevented telephone companies from shutting dial-up ISPs out of the market and taking their business for itself.
Unbundling was an attempt to transfer this model to the broadband era. It was a set of regulations requiring telephone companies to "unbundle" — or share at regulated rates — access to portions of their networks, so third-party ISPs could provide their own DSL service. In the late 1990s there were hundreds of ISPs that provided internet access over DSL lines.
This mode is still common in much of the developed world — especially in Europe. In these countries, most households have several options for internet access, all of them delivered over a shared connection owned by the local telephone monopoly.
Congress established unbundling rules in 1996, and the Clinton administration put them into effect. Many open internet advocates saw it as the foundation of a competitive market for internet access. But the rules were abandoned under President George W. Bush. And by the time Barack Obama took office in 2009, they had become so discredited that the FCC didn't try to revive them.


FCC Chairman Tom Wheeler (Mark Wilson/Getty Images)

One sign of how powerful the conservative worldview has become in the network neutrality debate is how strongly network neutrality advocates have disavowed any intention to use the full powers Congress has given the FCC.
For example, one big issue in the network neutrality debate is price controls. Such controls used to be a common feature of telecom regulation. Phone companies would have to get approval from regulators whenever they wanted to change their prices. Republicans have warned that reclassification could bring back those regulations, and they also argue that network neutrality itself is a kind of price control. Liberal activists have furiously denied these charges, underscoring how toxic the concept has become.
Similarly, services governed by Title II are subject to taxes to help subsidize access in rural areas. But this idea is so unpopular that Wheeler has pledged not to impose new taxes or fees on internet access.
If you want to see a serious liberal agenda for broadband, there's no better spokesman than Susan Crawford, a legal scholar we interviewed last year. She called for a "public option" for internet access, in which governments invest serious resources in next-generation internet access.
But in an era of tight budgets, there's no real prospect of this happening. Wheeler's FCC did preempt state-level laws that prevent local governments from investing in broadband infrastructure, but there's no real prospect of serious federal money being spent on broadband infrastructure.
Today the conservative vision for broadband infrastructure, in which networks are privately owned and lightly taxed and regulated, is accepted virtually across the political spectrum. Democrats are more reluctant to tax or regulate telecommunications infrastructure today than Republicans were 20 years ago. Today's network neutrality vote represents a small step toward greater regulation, but the broader trend has been in the opposite direction.
Verizon is one of the strongest opponents to the network neutrality rules the Federal Communications Commission approved today, so it's not surprising that the company put out a press release criticizing today's vote. However, the way the company chose to do it was a bit of a surprise:

Verizon wrote this press release with a typewriter font, and it dated it 1934 rather than 2015. Here's why.
The most controversial aspect of the FCC rule is a legal tactic called reclassification. Telecommunications law distinguishes among different categories of service — Title I governs online services like YouTube and Facebook; Title II governs utilities like telephone service.
For the past decade, the FCC has classified broadband service under Title I, a category that limited the FCC's ability to impose strong network neutrality regulations. By reclassifying broadband as a Title II service, the FCC gains stronger authority to regulate it.
Verizon, of course, hates this change. And one of their key arguments is that the Title II rules are outdated. Opponents love to point out that Title II has its origins in the 1934 Communications Act, which was written to regulate the old AT&T monopoly. In Verizon's view, such an old law can't possibly be a good fit for the modern internet — hence the 1934 date and the typewriter font.
There are a couple of important counterarguments, however. First, while Title II was originally written in 1934, it was last updated by 1996, and by a Republican Congress. DSL service was classified under Title II as recently as 2005. So it's not like the FCC is resurrecting ancient laws that haven't been used in decades.
Second, when Congress overhauled the law in 1996, it gave the FCC a power called forbearance, which allows the agency to choose not to enforce provisions of the law it regards as out of date. The FCC's new rules use that power aggressively to avoid imposing counterproductive regulations on the internet. For example, Title II gives the FCC the power to regulate the prices broadband providers charge, but the agency is choosing not to use that authority.
Network neutrality is the idea that internet service providers (ISPs) should treat all internet traffic equally. It says your ISP shouldn’t be allowed to block or degrade access to certain websites or services, nor should it be allowed to set aside a "fast lane" that allows content favored by the ISP to load more quickly than the rest.
The rules the FCC approved on Thursday were stronger than the ones Wheeler originally proposed last May. That proposal had attempted to protect network neutrality while staying within the bounds of a 2014 ruling that had invalidated the FCC's previous network neutrality rules. Critics argued that Wheeler's initial proposed rules were too weak, leaving a big loophole that would allow broadband providers to engage in exactly the kind of discriminatory behavior that network neutrality rules are supposed to prevent.
Network neutrality advocates wanted to regulate broadband providers as public utilities, a step known to insiders as "reclassification." This move would give the agency broader authority to establish network neutrality rules. The activists mounted a successful lobbying campaign, submitting millions of comments to the agency urging a stronger stance. They gained an important ally in November when President Barack Obama endorsed reclassification.
The protests worked, prompting Wheeler to back stronger rules earlier this month. Here are Wheeler's comments prior to today's vote:

The FCC vote fell along party lines, with the two Republicans on the commission opposing Chairman Wheeler's proposal. In comments before the vote, both commissioners blasted the move as a big government overreach.
"We need to be focused on ways to promote deployment," said Commissioner Michael O’Rielly. He argued that with its network neutrality vote, the FCC was "creating a vicious cycle where regulation deters investment in broadband, which stimulates more regulation."
The other Republican on the commission, Ajit Pai, agreed. He described the vote as a "monumental shift toward government control of the internet."
Wheeler disagreed. "This is no more a plan to regulate the internet than the First Amendment is a plan to regulate free speech," he said. "The action that we take today is about the protection of internet openness."
Pai and O'Rielly are in the minority on the FCC, but they have powerful allies in Congress. In January, two key Republican leaders announced plans to draft legislation that would protect network neutrality but take reclassification off the table. But so far that proposal has gotten a cold reception from Democrats, who prefer the stronger rules the FCC approved today.
Consistent with longstanding practice, the FCC did not release its proposal in advance of today's vote. And the agency is not expected to release its rules, which are reported to be 317 pages long, later today either.
However, the agency has released a four-page fact sheet describing its major provisions. And it reads like a wishlist for network neutrality activists. The rules will cover both wired and wireless networks, and it may also govern negotiations between last mile ISPs (such as Comcast or Verizon) and content providers (such as Netflix or Facebook).
The rules would prohibit ISPs from blocking or throttling disfavored content. They would also ban paid prioritization — the practice of accepting payment to give some content a higher priority than others. Finally, it would require ISPs to be more transparent about how they run their networks.
Later today, the Federal Communications Commission is expected to approve the strongest network neutrality rules the United States has ever had. Much of the debate has focused on an esoteric legal maneuver called reclassification, which allows stronger regulations by treating broadband service as a public utility. But the rules make another big change that has received less attention: it extends network neutrality rules to the wireless service that powers our smartphones.
That represents a significant change from the FCC's previous network neutrality rules, which were drafted in 2010 and struck down by the courts last year. Those rules focused primarily on home internet access delivered over a physical cable. Wireless networks from providers such as Verizon Wireless, Sprint, and T-Mobile were exempted from most regulations because in the agency's view it was "at an earlier stage in its development than fixed broadband and evolving rapidly. "
Now the agency is changing its mind, applying the same rules to both types of service. Critics say that's a mistake — that the arguments that persuaded the FCC to exempt wireless networks from regulation five years ago are still valid today. If they're right, the new rules could hinder innovation in the wireless market — the exact opposite of what they're supposed to accomplish.



(Apple)

Technically speaking, residential broadband is relatively simple. Internet access is delivered over a cable that runs to the customer's home, and customers can rely on a stable amount of bandwidth.
Wireless networks are different. The capacity available at any given time depends on a number of factors, such as a smartphone's location, the frequencies it is using to communicate, how recently the nearest cell phone tower has been upgraded, and other factors. A customer's connection can be working perfectly one minute, only to slow to a crawl the next minute as she switches to a cell phone tower that's in greater demand.
The greater scarcity of wireless broadband has prompted wireless companies to limit the use of bandwidth-heavy applications on their networks. For example, a few years ago AT&T limited the use of Apple's FaceTime application over its network. Critics blasted that as a violation of network neutrality, but AT&T argued that the restriction was needed to prevent the app from overwhelming its network.
Ryan Radia, an analyst at the libertarian Competitive Enterprise Institute, says that makes it important to give wireless providers flexibility to make these kinds of decisions to ensure that bandwidth-heavy applications don't make the network unusable for everyone.
"Different applications are hindered by reduced bandwidth in different ways," Radia says. For example, if you're watching a pre-recorded video, a few seconds of buffering might not matter much at all. On the other hand, buffering can make realtime video chat services like Skype or Facetime useless. Radia argues that letting wireless providers choose which types of content to prioritize can help them ration scarce bandwidth and provide a better customer experience overall.
Michael Calabrese, a network neutrality supporter at the New American Foundation, concedes that mobile networks are more vulnerable to unpredictable congestion problems. But he argues that network neutrality rules can take this into account, but allowing wireless providers to engage in what he calls "application-agnostic" prioritization. Such a rule would allow wireless carriers to prioritize all video-chat apps, for example, over other types of traffic. However, wireless companies wouldn't be allowed to provide better performance to one app (such as FaceTime) over another (Skype).


(Chris Hondros/Newsmakers)
A typical American home has two options for broadband service: the local phone company (such as Verizon or AT&T) and the local cable company (such as Comcast or Time Warner Cable). Only a few cities, such as Kansas City or Austin, have a third option such as Google Fiber.
Even worse, in many parts of the country the local phone company is still relying on ancient and pokey digital subscriber line (DSL) technology to deliver broadband service. If households in these areas want to use bandwidth-intensive applications such as video streaming, they have one realistic option: the local cable company. Concern over the growing power of the largest cable companies has helped fuel public support for network neutrality rules.
The barriers to entry are lower in the wireless market
There's more healthy competition in the wireless market, Radia says. "We've got four nationwide carriers in the US," he adds. And they've been competing fairly aggressively. For example, AT&T and Verizon have been boosting the amount of data customers can get for their money.
As a result, Radia argues, there's less reason to worry about mobile providers abusing their power than there is with incumbent cable and telephone companies. If a wireless company started arbitrarily blocking popular apps or services, customers can switch to one of several competitors.
Residential broadband is an older and more mature technology. Wireless networks are still changing rapidly. Today's state-of-the-art wireless technology, called LTE, has been around for less than five years.
This rapid pace of change increases the danger that the rules the FCC adopts today could prove to be a poor fit for the wireless networks of the future. Legal or technical distinctions that seem to make sense for today's generation of technology may become increasingly out of date as wireless technology evolves. That's less likely for home internet access, which is a simpler technology that has evolved more slowly.
Related, Radia says, the barriers to entry are lower in the wireless market. Building a new wired broadband network requires digging up thousands of streets to lay fiber optic cables. A new wireless network requires a comparatively small number of cell phone towers. So there's more reason to worry about excessive regulation becoming a barrier to entry for future entrepreneurs in the wireless market.
Radia is a network neutrality skeptic. But he argues that if there are going to be regulations, it makes more sense to start by regulating wired broadband connections and worry about wireless later. The issues are less complicated in the residential broadband market, and the FCC might learn valuable lessons that could help it craft more sensible rules for wireless markets.
The FCC's new rules are expected to be more than 300 pages, and the agency will be navigating a variety of tricky technical and legal issues. If the FCC makes mistakes, those mistakes will have a smaller impact if the rules only affect wired networks. And the FCC's experience with applying network neutrality to wired network can help inform later regulations on wireless.
Calabrese, however, argues that it's important that the same rules apply across the board. "A disproportionate number of low-income, young, and minority people are relying either exclusively or primarily on mobile networks for internet access," Calabrese says. He worries that exempting wireless networks from net neutrality rules could create a two-tiered internet, in which some customers enjoyed stronger network neutrality protections than others.
Of course, that argument cuts both ways. If Radia is right, then excessive regulations could prevent wireless providers from effectively managing scarce bandwidth on their networks, providing low-income users with inferior service.
Most city leaders would be overjoyed to be selected as the site of a new headquarters for one of the world's richest companies. But according to the New York Times, the Mountain View City Council has been unenthusiastic about Google's plans to build a new headquarters there.
City leaders are apparently worried about the traffic, and about further development changing the character of their city. They're also worried that Google employees could become a majority of the city's voter base, giving the company outsized influence over the city's politics.
Other technology companies in the region have also faced resistance from not-in-my-backyard (NIMBY) advocates. The result: not only is the Valley failing to deal effectively with growing congestion and soaring housing costs, these myopic local policies could end up hampering the country's most important driver of economic growth. So what looks like a local issue has broader implications.
Ignoring the pressure for more development is short-sighted. A better approach would be to accept that growth is inevitable and start planning ways to accommodate it gracefully. That means allowing high-density development in certain areas, positioning these developments so that some residents will be able to walk or bike to work, and making sure these areas are well-served by transit so they don't overwhelm the city's streets.
One of the biggest problems in Mountain View (and surrounding cities) is that more than 85 percent of workers there get to work by car. That works fine in a typical suburb, but it's becoming increasingly untenable as the region becomes more populous.
If Mountain View allowed high-density housing to be built in the area around Google's headquarters, that could not only help lower the area's sky-high housing costs, it could also encourage more people to walk or bike to work, relieving some of that congestion.
Higher densities work best in concert with a better system of public transit. Right now, the region's car-oriented development pattern makes it difficult to build a useful transit system. But if Mountain View allows the development of a walkable, high-density portion of the city, and other nearby cities do the same, that will make it more practical to build a system of buses — or perhaps someday a subway system — connecting them together.
Another sign of how desperately the region needs better shared-transportation systems is the fact that Google and other companies have been forced to construct their own private bus systems to bring employees in from San Francisco. These systems work fine for employees who have access to them, but it would be better for the region if Silicon Valley's transit infrastructure were good enough to make them unnecessary.
The problem, as a city councilor in Apple's hometown of Cupertino put it to the Times, is that "Nobody wants change." A lot of residents in the area like their towns the way they are — or more precisely, the way they were 20 years ago before the dotcom boom started — and don't want to see the area gradually transformed into an urban area.
But keeping things the same isn't really an option. These companies aren't going to stop growing. Traffic problems are going to get worse and worse. And sooner or later, technology companies are going to convince some cities in the area to allow more development.
Addressing these pressures proactively should allow cities to channel this growth in ways that will minimize disruption for longtime residents. Allowing new development in some parts of town can relieve road congestion and housing shortages in other neighborhoods.
In fact, if Silicon Valley had more flexible housing markets, hundreds of thousands of people could move to the Bay Area to take advantage of the tight labor market and high wages in the area, boosting not just the region, but the nation's growth rate.
Instead, these prospective workers are locked out by astronomical housing costs. We're all worse off for it.
Disclosure: My brother is an executive at Google.
When do you hope to retire? 65? 60 if you really get frugal? Mr. Money Mustache left the working world at 30, and he wants you to, as well. The popular personal finance blogger (who only reveals that his first name is Pete) has gained a loyal following by insisting that early retirement is really pretty easy, if people only shake off their wasteful attitudes about debt and consumerism. He spoke with Vox via email about how people can amp up their saving and investing and quit their jobs a few years earlier.
DK: What's the most common mistake you see people making with their money?
MMM: You could probably sum it up as taking a very short-term view on money and life: "I have $5 in my wallet right now, so I can afford this coffee," or "I make more than $399 per month, so I can afford to borrow money for this car."
Instead, I try to get people to think of things in 10-year chunks at a minimum and then move on to a lifetime perspective. For example, spending $100 per week on restaurants equates to a $75,000 hit to your wealth every ten years, compared to keeping that money and just investing it in a conservative way.
"if you have credit card debt, you should feel like your hair is on fire"
Instead of thinking of income as a temporary stream of cash that keeps you afloat, think of every dollar as a potential permanent lifetime employee that will work for you as long as you keep and invest it. But once you spend it, that particular dollar is gone.
DK:  I really appreciate that you phrase your philosophy on money in terms of happiness. What's a good way to put that into practice, though -- if i'm standing at the store and thinking, "That dress would make me happy," what can I ask myself to figure out if I really should buy it?
MMM: The first trick is to remind yourself that buying something — pretty much anything — is very unlikely to improve your long-term happiness. Science figured this out for us long ago, but not many people got the memo. Go to your junk electronics drawer and look at your old flip phones or your dusty iPad 1. Look at the clothes you've recently pruned from your closet that are now headed to the Goodwill. You traded a lot of good dollars for those, not very long ago at all. Are they still making you happy today?
Then think about what would really make you happy. For me, it was the freedom to choose how I spent my days, with no worries about money for the rest of my life. Again, every dollar that you keep for yourself will immediately start paying dividends towards this freedom. Your stress about money drops away, and you can walk away from a job or a boss you're not fond of — the options start to open up with breathtaking speed as you step away from the financial cliff.
DK: What do you and your family splurge on?
MMM: I feel that we splurge on everything. For example, we live in a house that looks like it came from the pages of a modern architecture magazine, overlooking a park and within walking distance of downtown. I have not just one car, but two of them, which we never even use because we also have six bicycles between the three of us. We also eat ridiculously fancy food at home and take some pretty exotic vacations. Everything seems really over-the-top, considering the fact that we could be just as happy with much less.
But for other people, my life might seem like the opposite of a splurge: "What? Three people live in only 1,500 square feet? Their cars are from 2005 and 1999? That sounds like a really extreme life of frugality!"
The key to all of this is to zoom out a bit and put things in perspective. Both my life and your life are ridiculously abundant and safe compared to almost every human who has ever lived before you in the history of this planet. If we can't be happy in this incredible place of privilege, we need to punch ourselves in the face and try again.
DK: How did you get started in the area of personal finance? And what informs your views here — did your parents talk money much with you growing up?
MMM: I was born as the stereotypical engineer kid, which means I was always interested in optimizing everything. Money was just one of those things.
It was only after I turned 30 and had enough money to retire from real work that I started getting these incredulous comments from friends and coworkers, like "What do you mean you are retiring? How will you get the money to pay your car loan and your mortgage? I'd be sunk within a month if I lost my job."
"[when i became a dad] i suddenly realized that the real issue is not a shortage of money but a constant shortage of time"
To me, their stories were much more amazing than my own story of early retirement. They were the same age as me or older, and had equal or higher salaries. I couldn't imagine having a shortage of money in such amazing conditions. Then I looked even higher up the income scale and found the same phenomenon. It turns out that humans are capable of blowing almost any amount of money, without realizing they are doing it.
This is what led me to start the Mr. Money Mustache blog to explain my perspective on money.
DK: My sense is that people have a better instinctual grasp of how to save than invest. Let's say someone has the cutting-back part down. Where does a beginner begin on investing?
MMM: Investing is scary until you understand how simple it is. The key for me was to recognize that stocks are not gambling instruments - they are slices of ownership in real, productive companies that will work with you for life. You eliminate all the risk by holding thousands of stocks simultaneously through a low-cost index fund.
For example, you can beat most of the world's investors by just buying and holding Vanguard's Total Stock Market Index Fund. Throw in all your paychecks, ignore the news headlines, and let the dividends reinvest for your whole working career. You'll do just fine.
Nowadays, I feel you can do slightly better by owning an even wider basket of investments — for example, Vanguard LifeStrategy growth fund or a 90-percent stock index portfolio through Betterment, which I have started an experiment with myself, documenting it on the blog.
I think of money invested in index funds as being safe, and hard at work for me. Money sitting around in cash is in danger — not working, tempting me to buy a Tesla Model S, and being eroded by inflation. So I keep all money invested.
DK: You advise people to get rid of debt emergencies. But how should someone decide how much debt is OK and what debt will be a problem?
MMM: Most people are far too complacent about debt in this country, so I try to shake up that perception a little. For example, it is considered normal to borrow money when buying a new car, when in fact it is a completely ridiculous bit of financial suicide. People accept credit card debt (and pay 20-percent interest on it) with a sigh of resignation, while continuing to do things like buy gourmet coffee or go out to dinner.
If you have credit card debt, you should feel like your hair is on fire. You shouldn't be eating anything beyond baked potatoes and tap water or doing anything besides working overtime and sleeping until you get out of that emergency. I've never been that frugal myself, but that's because I have never gotten into credit card debt.
Really, it boils down to the interest rate and the purpose of the loan. If you mortgage a home at today's rates, then live a reasonable life and invest your surplus income in retirement savings, you'll do fine: on average the house will appreciate almost as fast as the interest rate, plus it pays you "dividends" in the form of not having to rent an apartment.
But suppose you have some student loans at 6-percent interest kicking around in the background as well. They might have a low minimum monthly payment, but they are still draining your wealth at a significant rate. You need to pay those off before you go on to more frivolous spending, like regular nights out on the town or trips to the Caribbean.
You're in debt, which should be considered a problem that needs to be resolved. Otherwise, you are effectively financing everything you buy at 6 percent, instead of putting that money to work by eliminating interest costs.
"money ... is like tap water, just there in the background to meet our needs"
DK: How has having a partner -- and, I imagine more importantly, a kid — changed how you think about money?
MMM: If you and your partner share a common philosophy about what it means to live a good life, this part is easy. Back in the early 2000s, my wife and I were starting to think about having a kid or two eventually. But we realized that the demanding nature of our jobs in high-tech were not a good match for this — kids get sick and need you at home, school adjourns for three months every summer, and software projects ramp up and demand that you work late or travel occasionally. We decided that the most efficient way to handle that situation was to eliminate the need to work for money before having the first kid. So we saved and invested most of our paychecks together.
Once we retired and our boy was born [nine years ago], the thoughts about money didn't really change. Babies are much less expensive than people assume they are. But they are also much more work. Becoming a dad hit me like a freight train initially, when I suddenly realized that the real issue is not a shortage of money, but a constant shortage of time. I was incredibly thankful that I wasn't also trying to balance a full-time job in with this activity.
Money is something we don't think about at all — it is like tap water, just there in the background to meet our needs. You use whatever you need and you know it will never run out, but there's no thrill in letting it go to waste either.
For me, early retirement has never been about ceasing work or productive activity. Just breaking free of working to somebody else's agenda and schedule, or having the threat of running out of money influencing my decisions of what to work on. The good life is all about plenty of hard work doing stuff you love to do.
This interview has been edited for clarity and length.

A common argument against network neutrality regulations is that restricting how broadband providers run their networks — for example, by prohibiting them from charging certain content providers extra to put their content in "fast lanes" while everyone else's content gets stuck in the slow lane — is that this kind of regulation will make it too difficult for network providers to recoup their investments in broadband infrastructure.
So it's interesting to look at the 2014 financial results from the nation's largest broadband provider, Comcast, which came out today. Comcast's cable division (the company also owns NBC Universal) had operating cash flow (revenues minus operating expenses) of $18 billion. Of that sum, Comcast re-invested $6 billion in its network. But it also gave $6.5 billion in profits back to shareholders, and the company expects to return an even larger sum to shareholders in 2015.
This isn't a surprise. The company has posted a generous — and usually growing — profit every year since at least 2006. Clearly, this is not a company that's struggling to find the funds it needs to maintain and upgrade its network.
To be clear, there's nothing wrong with companies earning profits and giving them back to shareholders. You couldn't have a capitalist economy if shareholders couldn't earn a return from their investments. But I think we can draw two lessons from Comcast's financial results.
First, we're nowhere close to the point where increased regulations will make it unprofitable to own and operate broadband networks. Critics have warned that strong network neutrality regulations will reduce the incentive to invest in broadband networks, and they probably will. But even if they're right, it's likely that running a broadband network will continue to be a highly profitable activity.
Comcast doesn't seem interested in trying to steal market share from rivals
Second, Comcast's high profits are evidence of high barriers to entry in the broadband industry. Ordinarily, a company that consistently made billions of dollars in profits would attract new competitors seeking to capture a piece of the market.
But with a few exceptions — such as Google's projects in Kansas City and elsewhere — this hasn't really happened. In most parts of Comcast's service territory, consumers' only alternative for broadband service is the local phone company.
Conversely, Comcast doesn't seem interested in trying to steal market share from rivals. Comcast could expand into the service territory of neighboring cable companies or it could spend money building a next-generation fiber optic network the way Verizon and Google have done. Instead, they've chosen to spend more money rewarding shareholders than investing in their networks.
Again, there's nothing wrong with a company spending money on dividends and share buybacks. But this is all worth keeping in mind as policymakers decide whether to approve Comcast's merger with Time Warner. Broadband and cable television are already highly concentrated markets with minimal competition. Having the nation's two largest cable providers merge will make the problem even worse.
Disclosure: Comcast Ventures is an investor in Vox Media, the parent company of Vox.com.
Sitting right in the heart of Melbourne at the moment is something kind of amazing — an 800 square foot modular home that's not just carbon neutral, it actually produces more energy than it consumes. It's a product of an Australian architecture firm called Archiblox that specializes in modular homes and is rolling out a series of carbon positive options.
Here's what the one in Melbourne looks like on site:

Carbon Positive House, Melbourne (Archiblox)
Dezeen magazine drew this graphic showing how it works — the house is airtight and super-insulated, cooled not by air conditioning but by underground pipes that tap into the chillier temperatures below.
It's got a whole host of green features, and solar panels on the top are supposed to generate more than enough electricity to get by. Of course this all probably works better in relatively warm and sunny Australia than it would in Minnesota or Germany.

(Dezeen)
The floorplan shows a pretty snazzy and spacious one bedroom dwelling:

According to Archiblox, the design is "priced from" 260,000 Australian dollars plus sales tax. Including tax, that would come out to a bit over $220,000 US dollars. But of course you would also need to buy some land on which to place the house.
Hedge funds are actively-managed investment plans that are supposed to help wealthy investors (as well as institutions such as pension plans) beat the market. Symmetric, a website that rates hedge fund investors, crunched the numbers and found that a lot of hedge funds didn't do so well in 2014:

Symmetric looked at the stocks each hedge fund invested in, and then compared them to the average performance of other stocks in the same category. For example, "if a manager picked Apple, did it perform better than the tech sector?" The bars in this chart show how each hedge fund performed compared to someone who just bought all the stocks in the categories hedge funds chose.
As you can see, the results are not pretty. Fewer than 20 percent of hedge funds achieved better returns than they would have gotten if they'd just invested in broad industry categories. Over a longer, three-year time horizon, hedge funds appear to have done about as well as the broader market, with about half of hedge funds earning above-average returns and half earning below-average ones.
So does this mean people (at least those rich enough to invest in hedge funds in the first place) should buy into one of the funds with the above-average returns in 2014? Probably not. While it's possible that these funds are run by managers with a knack for beating the market, there's also a good chance they just got lucky. Studies have shown that it's very difficult to beat the market, and most mutual funds that try to do so fail. A fund that over-performs one year is just as likely to under-perform the next year. There's little reason to think hedge funds are different.
But hedge funds have a huge disadvantage over most other investment vehicles: every year, they generally charge customers two percent of the funds invested, and 20 percent of any profits earned on top of that. That acts as a consistent drag on returns. This might explain why the average hedge fund has dramatically under-performed the broader market over the last decade, as shown in this chart from Mark Perry:
AEI / Mark Perry
AEI / Mark Perry
A better investment strategy is to simply accept that you're not going to be able to get above-average investment returns and focus instead on keeping management expenses as low as possible.
Update: Hedge funds think it's unfair to compare them to a portfolio of stocks and bonds. "Whether it is portfolio diversification or risk management, each hedge fund allocation is done to meet specific needs and performance is only accurately measured against that objective, not unrelated investments like stocks or bonds," says Nick Simpson, a spokesman for the Managed Funds Association.
Still, if your goal is to enjoy a comfortable retirement, then you should care about whether these funds can outperform stocks and bonds. Investing in low-cost index funds is likely to be a better choice.

You can read the six page memo for yourself. But the key reforms promised here mostly relate to the tax code and tax administration. Before the financial crisis, Greece was essentially running a European-style level of public spending with an American-style level of tax collection. The area where Greece's new left-wing government and Greece's European partners have the most room for common ground is on trying to raise Greek tax revenue. This is where Syriza's reform promises are most specific and enthusiastic.
Syriza also promises to crack down on several dimensions of corruption, including promises to reduce civil service spending on things other than wages and pensions. For a flavor of what this means, even as the Greek stock exchange boomed on the news of the deal, shares in Greece's number one office furniture company tanked.
yep, Greece's leading manufacturer of office furniture is tanking, after an announcement they'll focus on govt procurement fraud. awkward
Elsewhere the deal largely reflects Syriza abandoning campaign promises and replacing them with verbal wiggle room about maybe doing things later. A promised doubling of the minimum wage is postponed indefinitely, and proposed rollbacks of changes to collective bargaining is turned into a proposal for "a new ‘smart' approach to collective wage bargaining that balances the needs for flexibility with fairness."
The new Greek government also promises not to renege on privatizations that are already in progress, but affords itself the opportunity to slow down or perhaps avoid any future privatizations.
Last but by no means least, the memo pays lip service to Syriza's promises to increase social spending to alleviate the humanitarian crisis in Greece. But it also commits Syriza to balanced budgets. Consequently, their ability to deliver on this in practice is going to be very linked to their ability to actually increase tax revenue.
The standoff is often portrayed as a kind of zero-sum conflict between Germany and Greece. In that view, Germany pretty clearly "won" as Greece has little objective leverage. But in the real world, public policy is not zero sum and both Germany and Greece would benefit from improved policy in Greece and suffer from bad policy.
In that view, this is a decent deal. The old arrangement in which a grand coalition of Greece's two long-governing parties were supposed to tackle the systematic corruption that they had created made very little sense. The questionable reform agenda was undergirded by extremely tight demands for budget surpluses, and the insistence on privatization risked becoming a fire sale of potentially valuable assets.
Into the breach stepped Syriza, a far-left political party with roots in Greek Communism that had never governed before.
The deal Syriza has now agreed to substantially undercuts the radical left elements of the Syriza agenda. At the same time, it does represent a more flexible approach to budgeting and what looks like a more sensible path to reform. There is absolutely no guarantee that the new Greek government will be able to actually deliver on tax reform and anti-corruption measures that have been promised, but it's at least plausible in a way that sticking with the old team wasn't. Meanwhile, Syriza has earned some flexibility on budgeting and the implementation of privatization. It's not the dawn of a whole new era of economic thinking, but it is a chance to prove themselves and to tackle some of Greece's longstanding problems.
A 1985 article in the New York Times wondered what had happened to the fad of laptop computers, which had (the article claimed) been relatively common in the early 1980s but had since dropped in popularity. "People don't want to lug a computer with them to the beach or on a train to while away hours they would rather spend reading the sports or business section of the newspaper," the Times wrote. A 1980 article about early online news services made a similar point: "you cannot tuck a computer under your arm as you head for the subway."
The recent swirl of speculation around Apple making a car has provided many opportunities for people to make a similar mistake — this time about autonomous cars. When they think about the future of self-driving vehicles a couple of decades from now, too many people envision a world that looks mostly like our world today except that drivers can activate a sort of super-cruise control that takes over the steering wheel. The Economist, for example, cites a research report predicting that the market for cars with self-driving capabilities will never exceed 25 percent of the market.
But the history of the PC revolution illustrates how wrong this way of thinking is. As PCs got cheaper and more powerful, the rest of the world didn't stand still. Ubiquitous PCs made it possible for ordinary consumers to get on the internet. A wide variety of industries — music, newspapers, books, retail stores, maps, cameras — got re-built around digital devices. New services like social media and streaming video were invented that made PCs and smartphones even more useful.
The same point applies to self-driving cars. Cars in 2035 could look as different from cars today as today's iPhone looks from a PC circa 1995. A number of industries — trucking, restaurants, retail stores, delivery services, public transit, real estate — will adapt to the new capabilities of self-driving vehicles, making those vehicles increasingly central to the economy. And people will develop totally new services using self-driving vehicles that are hard to imagine today.

(Justin Sullivan/Getty Images)
Probably the biggest difference between today's car market and the self-driving market of the future is that the dominant business model is likely to be Uber-style ride-sharing, not personal car ownership. Right now, most cars are sold to individual families because the need for human drivers makes it too labor-intensive to share vehicles between multiple families. But once drivers become unnecessary, it will seem (and be) wasteful for individuals to own cars that sit idle 90 percent of the time.
And this has big implications for the economics of self-driving cars. For example, people have argued that the low-margin auto industry is a bad place for Apple, a company that has traditionally made high-margin products. As my colleague Matt Yglesias points out, this argument doesn't make much sense because Apple has a long history of building high-margin products in low-margin industries like smartphones and PCs. But it's also true that margins will become a lot less important in a future where cars are mostly sold to ride-sharing services like Uber instead of directly to consumers. Ride-sharing companies may be willing to pay a hefty premium for a car that offers extra reliability, efficiency, or other features.

Google unveiled this prototype of a self-driving car in 2014. (Google)
Today's cars all look pretty similar: most have seating for four or five passengers, a trunk, an engine powerful enough for freeway driving, and a big enough fuel tank for hundreds of miles of driving. Yet for many people, the primary use of their car is for single-person commuting for no more than 10 or 20 miles.
Self-driving cars will allow greater specialization, and therefore greater efficiency. If you're commuting by yourself, you might be able to hail a 1- or 2-seat vehicle that costs less and gets better mileage. If your trip doesn't require freeway driving, you might get an super-efficient electric car that doesn't go faster than 30 miles per hour. When you do need to transport more people or stuff, you'll be able to get a gasoline-powered minivan or pickup truck at a higher price.
The biggest change, though, may be the rise of vehicles designed for zero people. For example, right now if you order a pizza, it's usually delivered by a human driver in a full-sized car — that's thousands of pounds of steel and glass to deliver a pizza that weighs a few pounds. But once you eliminate the need for a human driver, there's no reason for delivery vehicles to be so big, heavy, and expensive.
Navigating this kind of change will be difficult for conventional car companies, which are organized around the assumption that a car must cost tens of thousands of dollars and have room for several human passengers. Gadget makers like Apple, which are used to operating on a smaller scale and squeezing out every ounce of unnecessary weight and cost, might have an edge.

A self-driving concept car from Mercedes-Benz. (The Verge)
The Economist quotes a Boston Consulting group study predicting that self-driving cars will account for just 10 percent of the market in 2035, and that demand for automated driving capabilities in general will top out at 25 percent.
Obviously, it's hard to know when fully self-driving cars will first reach the market — technological and regulatory obstacles could delay its introduction beyond the 10 years Boston Consulting is assuming. But once the technology enters the market, it's likely to reach a lot more than 10 percent of the market in its first decade.
This is because the big technological barriers remaining to full self-driving capabilities are mostly software-related. The sensors needed for self-driving capabilities exist now, and while they're currently expensive, they should be a lot more affordable in a decade. The problem is that we don't yet know how to write software that can gracefully handle all of the emergency situations a car might encounter.
But once suitable software is developed, it should be possible to deploy it widely. It might even be possible to upgrade the software on many semi-autonomous cars to give them full self-driving capabilities. Of course, our roads won't become 100 percent self-driving overnight, because people won't want to immediately junk their conventional cars when self-driving alternatives come on the market. But the convenience and safety advantages should cause people — especially younger riders — to adopt those cars very quickly.
And once self-driving cars become safer than human-driven ones, there will be a serious debate about whether people should be allowed to drive their own cars at all. After all, human-driven cars killed 33,561 people in 2012, many of which were due to drivers who were too distracted, tired or drunk to drive safely. Once a safer alternative is available, people may view that as an unacceptable hazard.

(Justin Sullivan/Getty Images)
In a couple of decades, self-driving cars are likely to control a big chunk of the conventional car market. But self-driving technology is likely to create new product categories as well.
For example, self-driving vehicles will pose a huge competitive threat to package delivery services like UPS and FedEx and catalog and online retailers that rely on them. Because we send drivers out on daily delivery routes, package delivery times are usually measured in days. But once you dispense with the driver, routes and delivery times can be much shorter. Small, automated vehicles could allow people to order everything from diapers to books in the same way we order pizzas today — and at a fraction of the delivery cost.
It's hard to predict what this market will look like, but it's safe to say that a new generation of retailers will want to buy a lot of self-driving vehicles and that these vehicles will look different from any car on the road today.

Ford CEO Mark Fields. (Bill Pugliano/Getty Images)
The Economist warns that Apple will need to "catch up with the established carmakers, which are also busy hiring software talent and which have been introducing ever more sophisticated 'assisted driving' features in their models, such as the ability to park themselves, and to navigate stop-go traffic unaided." But thriving in a software-heavy industry — which is what cars will increasingly become — requires more than just hiring a bunch of programmers.
The experience of legacy media organizations is instructive. Over the last two decades, record labels, newspapers, Hollywood, and other traditional content producers have poured millions of dollars into trying to build internet-based platforms for their content. Yet the market is increasingly dominated by outsiders — YouTube, Netflix, and Amazon Prime for video, iTunes and Pandora for music, startups like Buzzfeed and the Huffington Post for news, and so forth.
Building great software requires a certain kind of culture that Silicon Valley startups have and most other types of companies do not. For example, a big obstacle to making car software more secure and reliable is the fact that today's cars are cobbled together from components supplied by dozens of contractors. These contractors treat their software's source code as a closely-guarded trade secret, which makes it almost impossible for the company manufacturing the car to audit the software looking for bugs or security flaws.
Car companies will need to rethink how they manage their supply chains if they want to avoid producing cars with huge security flaws. In contrast, companies like Apple and Google have long experience developing secure and reliable software and are less likely to make the same mistakes.
Between cheap gasoline and the health care price slowdown, inflation has rarely been less of a problem for the American people. But there are always exceptions to any trend and price increases at Disney theme parks are a big one, with single-day passes to the Magic Kingdom shooting up from $99 to $105 this weekend.
No other major theme park has yet crosses the psychologically significant $100 barrier, but Disneyland, Disney California, Epcot, Animal Kingdom, and Hollywood Studios are all now at $99 or $97.
But don't take this as a harbinger of anything in particular. Andrea Lamond of the vacation rental company Owner Director observed last year that Disney prices have soared much faster than the overall rate of price inflation for years.

You can think of soaring theme park prices as the inverse of the general trend toward cheaper entertainment — Netflix, Spotify, and other aspects of the digital streaming revolution have made it cheaper and easier than ever to amuse yourself. But live parks have gone in the opposite direction, with little fundamental technological improvement to a business model that requires a lot of space and a lot of people standing around to monitor lines and collect tickets.
America's largest companies are investing way less in science than they used to. Decades ago, firms like AT&T and IBM ran massive labs where scientists could dream big and pursue the sort of research that won Nobel Prizes — even if it didn’t translate immediately into new products. (AT&T’s Bell Labs famously helped invent the laser and the transistor.) But that’s increasingly a rare sight.
And to see why, just look at Google.
Google, after all, is still a company where scientists pursue long-shot ideas. The firm's semi-secret research lab, Google X, has been exploring everything from self-driving cars to Google Glass to balloons that can beam down internet to poor countries. The company expects that most of these ideas will fail. But a few might succeed — and prove world-changing.
Yet to many of Google’s investors, this bet is starting to look iffy. As Conor Dougherty reports in an excellent New York Times story, Wall Street is getting antsy about many of Google’s moonshot projects — particularly after the recent failure of Google Glass:
After patiently abiding a steep increase in research and development spending on efforts that range from biology to space exploration, Wall Street is starting to wonder when — and if — Google’s science projects will pay off.
"We want companies to continue to push the envelope, but there has to be some financial responsibility around that," said Ben Schachter, an analyst at Macquarie Securities. "We have no real insight into what’s going on."
For a long time, Google could resist these pressures because it dominated the search and advertising business. The company was doing spectacularly well, and investors didn’t mind if Google tinkered with offbeat ideas like self-driving cars that had a small shot of being wildly lucrative. It also helps that Google's unusual corporate structure gives founders Larry Page and Sergey Brin majority control, leaving them better-positioned to fend off Wall Street's demands.
But now Google’s advertising revenue is growing more slowly, and analysts are increasingly second-guessing the company’s spending on wild dreams that may never pan out, like jetpacks or wind power from kites.

A prototype of Google's custom-built self-driving car. (Google)
A similar tale happened throughout corporate America during the late 20th century. When companies like AT&T and IBM dominated their respective fields, they could afford to run wide-ranging research labs. The scientists in these labs were given immense freedom, and some of their discoveries ended up being transformational. Bell Labs racked up eight Nobel Prizes for things like the transistor or the discovery of cosmic background radiation.
The problem is that this R&D work didn’t always pay off for the companies that had invested in it. Researchers at Xerox’s Palo Alto Research Center famously invented the graphical user interface. But it was Apple that harnessed the idea to create the Macintosh. The same thing happened to Texas Instruments: its research lab helped develop the integrated circuit, only to watch Intel get rich off the idea.
So, over time, the labs shrunk. Modern-day tech companies still spend a lot on R&D, but they focus far more on short-term commercial applications than on fundamental research. As The Economist reported in 2007, the R&D budgets of companies like Microsoft, IBM, and Hewlett Packard mostly go "into making small incremental improvements and getting new ideas to market fast."
A recent NBER working paper led by Atish Arora, a professor at Duke University's Fuqua School of Business, quantified the trend. Basic research makes up a much smaller portion of corporate R&D than it used to:

National Science Foundation/Division of Science Resources Statistics, Survey of Industrial Research and Development: 2007. (Arora et al 2015)
Arora and his co-authors point to a number of possible factors, such as the fact that firms are no longer as diversified as they used to be (giving them less incentive to research widely, the way companies like DuPont did). But the trend appears real.
In recent years, Google had stood out as an exception — a company that still shot for the moon. But even Google’s now facing calls to show more immediate results by investors with shorter time horizons.
As Dougherty reports, the company is trying to placate Wall Street by pointing to some of its computer-science research like Google Brain, a neural network that helps computers read text and will have more obvious practical implications. Google officials told the Times that the company's R&D efforts — which now amount to 12 percent of revenue — have paid for themselves with this breakthrough alone.
Broadly speaking, this is what economists have long predicted will happen. The value of basic research is greater to society as a whole than it is to any one individual company. So, in theory, companies are likely to invest less in this sort of research than is socially optimal. It’s quite hard for corporate research labs like Google X to persist over time.
That’s a potential problem because science and basic research has long been a huge driver of US economic growth. So if private companies are investing less in it, someone else needs to pick up the slack.
In the United States, that slack has been picked up since the 1980s by universities and the federal government, which are bearing more of the research load. (Indeed, Google owes its existence to a page-rank algorithm developed at Stanford University under a federal research grant.) The only hitch is that Congress has been reining in federal spending on basic research in recent years.

(AAAS)
Experts are still debating what this potential cutback will mean for the future. Will it mean less innovation going forward? Will China and other countries fill in the gaps as they spend more? Is it possible that we’re now investing in R&D more efficiently than we used to? Whatever the case, it’s a big change in how American science gets financed.
Further reading: American companies are investing way less in science than they used to
There are dozens of ways in which Apple's apparent effort to build an Apple-branded car could go wrong, but there's one argument against the idea that I'm hearing a lot of that really doesn't make sense. From Henry Blodget to former GM CEO Daniel Akerson to the LA Times to Yahoo Finance people are saying this won't work because the car industry is a "low margin" business in contrast to the fat margins Apple is used to earning most of all on its workhorse iPhone.
The misperception here is that Apple earns high margins because Apple operates in high margin industries. The truth is precisely the opposite. Apple earns high margins because it is efficient at manufacturing and firmly committed to a business strategy of sacrificing market share to maintain pricing power. If Apple makes a car, it will be a high margin car because Apple only makes high margin products. If it succeeds it will succeed for the same reason iPhones and iPads and Macs succeed — people like them and are willing to buy them, even though you could get similar specs for less.
Consider the smartphone industry, where Apple earns the lion's share of the profit and revenue. Apple earns 93 percent of all profits secured by handset manufacturers, with Samsung earning over 100 percent of the remainder left behind. Which is to say that if you look at the non-Apple portions of the smartphone industry, it's an exceptionally low-margin industry. Samsung is running a modestly profitable handset business based on enormous volume. Lots of players are losing money. Chinese upstart Xiaomi has a promising business built on handsets as a loss-leader for after-market services. By volume, the dominant software player in the smartphone industry is Google, which makes a phone OS that it gives away for free.
In other words, if Apple weren't already earning tens of billions of dollars in smartphone profits, people might look at this landscape and say it would be pointless for Apple to get into the market. How are you going to compete with zero-margin handsets and a free operating system?
Well, it's hard! But Apple pulled it off.

Apple isn't as successful in the PC industry as in the smartphone industry, but it's pretty successful and per Horace Dediu's chart above, the story about margins is similar. As of 2012, the non-Apple parts of the PC industry were very low margin and Apple earned high margins anyway. And since that time, the Mac has only grown as a share of the PC market.
These existing profit margins are so anomalous that people have frequently proclaimed them to be unsustainable. Others have simply regarded them as unwise, arguing that Apple's long-term business would benefit from cutting prices to gain market share. But Apple is both fundamentally committed to this high margin strategy and good at executing it.
Will they be as good at executing it in the car space? Who knows.
But the logic that says Apple can't have a high margin car business would also say Apple can't have a high margin smartphone business. The reality is that earning profits in competitive industries is really hard. If you are looking for a guaranteed return, you need to be in a monopolistic industry (owning telecommunications networks or copyrights to popular comic book characters) rather than making consumer products.
Making an Apple-branded car is a big risk with a high chance of failure, but it's not qualitatively different in that regard from making an MP3 player or a smartphone. If it were easy to do these things profitably, everyone would do it and the profits would be competed away. Apple's entire success over the past 15 years is built on having defied those odds before, so you can understand why the company's executives might think they can do so again.
By Jane Greenway Carr
Jane Greenway Carr is an ACLS Public Fellow and Contributing Editor at New America.

This piece was originally published in New America's digital magazine,The Weekly Wonk. Sign up to get it delivered to your inbox each Thursday here, and follow @New America on Twitter.

"It's meant to be a thriller," says Steve LeVine of his new book, The Powerhouse: Inside the Invention of a Battery to Save the World, that "takes the reader into the world of the battery scientist." While a bit tongue-in-cheek, this description underscores the high stakes involved in the global dash to create a battery powerful enough to run an electric car 300 miles on a single charge. The current sprinters? Japan, South Korea, China and the United States.
There aren't very many inventions that can do substantial good in the world and help their makers get wildly rich in the process. But according to LeVine, Washington correspondent for Quartz and a Future Tense Fellow at New America, a superbattery-one that will improve upon the lithium-ion battery and thereby take electric cars mainstream-is just that kind of invention. Those who bring it to market will cash in to the potential tune of $300 billion and the rest of us will breathe progressively less polluted air as we traverse the roadways in our all-electric vehicles.
In The Powerhouse, LeVine reveals the drama generated by the lithium-ion battery by tracking two parallel narratives: the work at Argonne National Laboratory's battery program, home to scientists LeVine calls the world's "battery geniuses," and efforts of Silicon Valley start-ups like EnVia Systems (the first licensee for Argonne's material). Researchers in both settings are racing to build a product marketable enough to secure contracts and a billion-dollar IPO. The book, says Levine, is "reflective of that environment...where so much hope and buzz and really a fever had come to center on the battery."
As these dual stories unfold, LeVine explained at a recent event at New America, "It's not quite a collision course, but they're driving down the same lanes." As a storyteller, he added, it was important to him for the book "not to be a hagiography about technology and invention," but rather an account of how innovation happens, viewed through the lens of a colorful set of characters.
One of those characters is Jeff Chamberlain, manager of the Argonne battery program, who is "this evangelistic motivator, painting the stakes in very large colors." Those brush-strokes add up to a portrait of fear, notes LeVine, because the pressure is fierce to hit the finish line first. Since Sony commercialized the lithium-ion battery in 1991 and Toyota unveiled the Prius in 1996, transformative battery innovations have been scarce, and both President Obama and China's Minister of Science and Technology have vowed publicly to put one million electric cars on the road in 2015 (a goal that neither will achieve this year but to which both remain committed in the longer term, though China recently saw a surge of electric vehicle sales in 2014 ). The idea that China might win the battery race is, to LeVine's mind, the "bête noir" for scientists like Chamberlain.
Another theme that LeVine emphasized in his conversation with Donna Harris, co-founder of the start-up hub 1776, was the effect of what could be called the "Bell Labs diaspora." Alumni of Bell Labs, which developed the transistor in the late 1940s, populate the entire ecosystem of the battery race, from university laboratories to government agencies to industry. Between Energy Secretary Steven Chu's proposed creation of "Bell Lablets" and the widespread realization that Bell's managerial system could be conducive to greater innovation, previously bitter rivals like Matt Thackeray's Berkeley lab and Chamberlain's team at Argonne managed to forge collaborations that made them both more competitive in the superbattery sprint.
It's important to remember that neither the electric car nor the superbattery are fait accompli, LeVine pointed out: "Just because we want them and the stakes are so high doesn't mean they will happen." To reap the dividends, all the stakeholders in the race need to re-think their assumptions. For Chamberlain and his compatriots, this meant admitting that they need a new roadmap, to "understand the science [of batteries] at the atomic level" and work from there.
For those in business and government, LeVine argues, re-thinking things means putting together a format for participation that "jettisons our allergy to violating [a] free market ethos and coming up with a formula of intellectual property-sharing that involves industry and the inventors." He dismisses as "foolhardy" the industry forecasting that predicts that 25 years from now, electric, fuel-cell, natural gas, and plug-in hybrid cars will only comprise 5 percent of the market. "We live in an age of utter disruption," he marveled, citing shale oil and gas as two examples of game-changers that no one predicted.
Along with cutthroat competition and the promise of future innovation in the race for the superbattery, warns LeVine, comes a healthy dose of bullshit, which he says is often the cost of doing business in technology-no matter whether you're in a lab or a start-up. Looking back on his research for The Powerhouse, LeVine was surprised by the pervasiveness of the "exaggeration, hype, and lies." He reflected to Harris, "Edison famously said in the 1920s that batteries-especially rechargeable batters-are a special province of liars. And there is a twist in the book where we learn that law. That was a very big shock to me."
But when you've published a book about a technology race that's still being run, twists and turns come with the territory.
Ever since he won election in 2013, New York City Mayor Bill DeBlasio has talked a lot about affordable housing. On Friday afternoon his administration rolled out its most promising initiative on this yet — a broad change to the city's zoning code that should allow for the construction of housing units.
The proposed reform has three main elements:
None of this alters the key zoning metric known as Floor Area Ratio, which is the ratio of built-out floorspace to total land occupied. In other words, if you have 6000 square feet of apartments sitting on top of a 2000 square foot lot, you have an FAR of 3. But it all works together to make it considerably cheaper and easier for developers to craft structures that maximize the permitted floor area ratio.
Parking: Currently, outside of central Manhattan essentially all new buildings in New York City are required to include new parking spaces — driving up the cost of real estate in a city where land is extremely scarce. DeBlasio is proposing to eliminate minimum parking space regulations for senior citizen or low-income housing if it is either near a subway station or includes access to an off-site parking facility. He is also proposing to reduce the amount of parking required for senior citizen or low-income housing even if it's far from transit. Last, he wants to "create a process to allow, where appropriate and on a case-by-case basis, reduction of parking requirements to facilitate mixed-income development, or affordable housing developments with existing underutilized parking facilities to be redeveloped."
Building height: DeBlasio is proposing, essentially, that developers should have the flexibility to build structures that are tall enough to reach the maximum FAR allowed. Currently, height restrictions are often poorly matched to FAR rules. A zone might allow for an FAR of 5.0 but also prohibit buildings that are tall enough to achieve this in a sensible way. At best, developers can make it work by employing either short ceilings or very boxy buildings with no setbacks or courtyards. At worst, they simply don't build out to the maximum FAR. This is especially important because current law offers developers FAR bonuses for including affordable housing in their projects. Often, however, height limits make it impossible to take advantage of this opportunity. The new rules should increase the production of both subsidized and market rate housing.
Senior housing: DeBlasio is proposing to allow more flexibility in terms of combining nursing home units with other types of senior-focused housing, as well as easing the permit process to get permission to build assisted living units.
These are very positive steps to address a huge problem that costs the American economy billions of dollars in output each year. But of course New York City could go further. Regulatory mandates that new buildings include parking spaces, for example, are no more reasonable for market rate housing than for subsidized affordable units.
More to the point, even though New York City is the country's largest city, it is only a relatively small slice of the overall affordable housing problem. Most residents of Greater New York, and of every other metropolitan area, live in suburban jurisdictions where the anti-affordability rules are generally even more severe. Tackling the nationwide affordability crisis will ultimately require zoning relaxation not just in New York, but in central cities and their suburbs up and down both coasts.
As negotiations between Greece and other Eurozone member states — most of all Germany — continue, there's growing speculation that Greece will be forced to leave the Eurozone. And if no deal is reached it might. But there is another policy the country can adopt that is in many ways politically and legally more likely: capital controls.
That's finance jargon for legal restrictions on the ability to move money across national borders. Capital controls are in place in a lot of countries, ranging from China to Argentina. But they are rarely seen in the richest countries, and the idea of imposing capital controls on a country that is in a currency union is a little paradoxical. But capital controls are already in place in the small Eurozone state of Cyprus, and they could provide a solution — or at least a "solution" — to the Greco-German standoff that doesn't involve Greece leaving the Eurozone.
Greece has a lot of problems. But its specific problem right now is that for Greek banks to keep functioning, they need to be backstopped by the European Central Bank. At the same time, the Greek government is deeply in debt to a bunch of other Eurozone countries as a result of a debt bailout it received years ago. Under the terms of that bailout, Greece needs to abide by a policy of fiscal austerity and also commit itself to various privatizations and labor market deregulations. A new government came to power in Greece in January promising to reverse all that, but they have not succeeded in convincing Germany to let them.
The ECB has made it pretty clear that it won't keep supporting Greek banks if Greece can't reach a deal with its Eurozone creditors. And if the ECB pulls its support, the entire Greek banking system would collapse.
There is one way to save the banking system in that scenario: the Greek government could start issuing a new currency of its own and use that currency to support its banks outside the ECB's purview. That, of course, would mean leaving the Eurozone.
One big problem with leaving the Eurozone ("Grexit" they call it) is that there's no legal mechanism through which it can be done. That doesn't mean it's impossible, but it does mean it would be quite chaotic. For one thing, the Greek economy relies on contracts that are written in terms of euros, which would all have to be revisited in light of an exit.
Another, potentially more cooperative way forward is capital controls. Greece could impose severe legal restrictions on Greek people's ability to shift their euros out of the country, leaving them with no alternative but to trust the Greek banking system. That, combined perhaps with some limited support from the ECB, could keep Greek banks running even in the absence of a deal.
Greek people and companies would still be able to fulfill the terms of old euro-denominated contracts without entering into a legal grey zone, and European visitors to Greece could keep spending their euros.
A clear precedent for this exists in Cyrpus, where a 2013 banking and fiscal crisis was resolved with the use of capital controls, among other things.
Cyprus still uses the euro as its currency, but as you can read on their central bank's websites there are tons of legal restrictions on what a Cypriot can do with his euros. Cypriot euros are semi-trapped inside Cyprus, whereas as Belgian euro can fly all around the eurozone or even be traded for dollars. Consequently, in practical terms a Cypriot euro is less valuable than a Belgian (or Finnish or Irish or Portugese or German) euro. This raises some metaphysical questions as to whether Cyprus really has the same currency as the rest of the Eurozone — after all, lots of currencies are called dollars but that doesn't make them US dollars — but officially the capital controls are only "temporary" and Cyprus is a member of the club.
You could imagine something similar happening in Greece. Cyprus' temporary controls are still in place with no end in site, and Greece might languish in capital control land for a long time. But unlike an official exit from the Eurozone, a capital control scenario wouldn't be irreversible. The Syriza government could collapse, and the Eurozone could hold out the promise of reversing the capital controls if a new coalition comes to power and returns to the bargaining table.
It can be hard to remember, but at one point, Dove just sold soap. Plain, uncontroversial soap that didn't come with any ideological baggage. Fast forward to today, when you have to sit through three minutes of one of the company's viral ads before a brand name shows up (and the products sometimes are never even seen).

Thirty years ago, Dove's ads were more conventional — that is, they emphasized their product and what it did. To this day, anyone who watched TV in the 1980s can recite that Dove is one-quarter moisturizing cream.

How did Dove go from a soap to a brand that makes you love your body? It's not exactly that Dove suddenly cared about women crafting healthy body images. Rather, that new branding was part of a corporation-wide growth strategy to give brands distinct identities, rather than having them simply stand for products,
In 2000, Dove parent company Unilever crafted a strategy plan called the "Path to Growth," in which it cut down 1,600 brands to 400, according to a 2007 Harvard Business School case study from HBS Professor John Deighton. A few of the lucky surviving labels were selected to be what are called "Masterbrands" — brands that were "mandated to serve as umbrella identities over a range of product forms," as Deighton puts it. Dove was one of them.
dove's jump into hair mousse is why the brand is now synonymous with "real" women posing in their undies.
In other words, Dove would now make the jump from being just a soap to being a brand that covered all sorts of products: shampoo, conditioner, deodorant, and so on. And that jump into lotion and hair mousse is why Dove became synonymous with "real" women posing in their undies.
No longer could Dove simply advertise itself as the best moisturizing soap on the market. And instead of trying to craft a complicated brand image that simultaneously made the company appear to be the best at hair care, skin care, and controlling body odor, Unilever decided to take a different tack.
"Unilever decided, instead, that Dove should stand for a point of view," Deighton writes.
All that was left to do was figure out what, exactly, Dove's point of view would be. Dove's global brand director, Silvia Lagnado, found it when her research found that women worldwide were discontent with the way "young, white, blonde, and thin" were constantly equated with beauty. After consulting with leading experts in psychiatry and women's views of beauty, Dove honed its message and found a new niche: advertising to "real women." Soon, unconventionally pretty ladies were all over the advertising, telling the world about the very real tragedy of women not believing they were beautiful.
soon, unconventionally pretty ladies were telling the world about the tragedy of women not believing they were beautiful.
Dove has ridden the Campaign for Real Beauty wave for around a decade now, but there are signs that people are growing disenchanted. The company's 2013 "Real Beauty Sketches" ad was one advertisement that drew consumer backlash.

The problem with Dove's message that women need to have more confidence in their looks, critics say, is that it still upholds the idea that women's beauty is of utmost importance, albeit in a warm and fuzzy way. In the sketches ad, others have argued, it's clear that the (mostly white and slender) women subjects equate beauty with being even more slender, not to mention younger.
Some (myself included) also pointed out that Unilever is selling "real beauty" even while it sells products like Slim-Fast and Axe, a line whose identity is in part built on the idea that body spray is irresistible to well-endowed, bikini-clad women. As a result of the earnest ad, parodies sprang up, including a simple gender-reversal take, as well as a hilariously NSFW remake.
The backlash to the company's "beauty patch" ad has been quick and harsh. Though Dove appears to have gone for a more diverse crowd this time around, critics have found many other weaknesses. New York Magazine called it "garbage," lambasting Dove for making women seem "dumb" by duping them with a faux scientific study (and by showing them laugh, not rage, in response). Fast Company called the ad "condescending," instead recommending a (pretty funny) parody ad.
Dove, of course, isn't the only company that has taken criticism for selling products by using a woman-friendly message. Pantene's "Labels Against Women" ad suffered similar blowback from consumers who saw it as manipulative. And Goldieblox, a toy company that says it sells "engineering toys for girls," likewise raised questions about the ethics of selling feminism.
For his part, Deighton doesn't believe Dove has overplayed the real beauty hand just yet. To him, the ads are "sanctimonious and lachrymose, yes, and eventually it will wear out, but I see no evidence that we've reached that point," he says in an email.
Once that point is reached, however, the question for Dove may soon be what sort of new "point of view" it wants to sell (alongside soap and lotion).
I've written a lot over the years about the harmful impact of restrictions on new residential housing in American cities. But it's really a global issue, and some of the most egregious cases happen in foreign countries. In fact, a new initiative to upzone Mumbai, India is probably the most important urban-policy development in the world today. It should fairly dramatically increase living standards in one of the biggest cities on the planet and possibly do a great deal to drive economic growth forward throughout India.
Zoning news from the third world isn't the kind of thing most people in the west are going to pay attention to. But as India is both the world's largest democracy and has the world's largest concentration of poor people, its success or failure in generating rising living standards is a huge deal. And getting urban planning right is a huge piece of that.
One important measurement in the urban-planning world is what Americans call Floor Area Ratio (FAR) and what Indians call Floor Space Index (FSI). FAR/FSI measures the ratio of built-out floor space to land area. In a suburban area full of one-floor buildings, large lawns, and generous parking lots you would expect FAR to be well below 1. In midtown Manhattan, which is full of very tall buildings, FARs get as high as 15.
Mumbai currently has a regulatory ceiling of 1.33 FAR for the central city and 1 for more outlying areas. In the United States, a 1.33 FAR would probably be a neighborhood full of three story row-houses. In other words, a kind of low-density residential urbanism.
But making this the maximum allowed building density in a low-income city of 12 million people has created a very different situation: Mumbai's infamous hyper-crowded slums, as seen in Katherine Boo's Beyond the Beautiful Forevers. Alain Berteaud points out that contrary to what you might guess, "a lot of slum dwellers are gainfully employed and are not poor in terms of their relative income. Rather, they are the victims of a number of misguided land use policies and of a lack of government investments in infrastructure."
By Indian standards, in other words, Mumbai has good opportunities for jobs and incomes. So people have flooded into the city. But the city has not allowed for remotely adequate levels of new construction. Consequently, by 2009 the average Mumbai resident had just 48 square feet of residential space at his disposal compared to about 365 square feet in Shanghai.
Greater Mumbai's governing authority is proposing a sweeping change to the permitted FARs in the area. Under the plan, Mumbai would be divided into five zones with an FAR of 8 allowed in the very densest areas and FARs in the 5-6 range in places well-served by mass transit. Fifty-eight percent of the city's land area would remain below 3.5, but even that could mean significant increases in the amount of building allowed in many areas.
New construction should have four major economic impacts:
The proposed change doesn't come directly from the central Indian government, but does reflect priorities of the still-relatively-new prime minister Narendra Modi. As leader of the Indian state of Gujarat he increased density in several cities and often linked new building permits to infrastructure funding.
Even a city as large as Mumbai contains only a relatively small fraction of India's vast population. But it is in many respects the country's most economically dynamic metropolis, so its decisions have big national implications. And if the change goes through and is seen to pay off, it could inspire further reforms across the country that give urban Indians the opportunity for better homes and better lives.
It seems like the United States economy is enjoying more innovation than ever before. At the same time, statistics show the economy suffering from its slowest growth in decades.
Analysts often try to resolve this by arguing either that conventional statistics aren’t properly measuring the value of innovation or else that the apparent speed-up in innovation is actually an illusion and progress is slowing down. Another possibility is that things are exactly as they seem: Rapid technological innovation is real, and so is slow economic growth. In fact, in a sense the innovation is causing the slow growth.
Call it the productivity paradox, and recognize that it explains a lot about the current state and the future direction of the American economy.
Most of the progress in recent decades has involved making cheaper and more convenient versions of products that already existed. Phone calls and photographs, for example, have been around for a long time, but over the past 20 years we’ve seen a revolutionary decline in the cost and massive increase in the convenience of snapping photos or making long-distance calls.
As innovation has pushed down the cost of certain types of products (mostly durable goods such as televisions, furniture, and clothing), Americans have used the savings to spend more on other things — especially education, health care, child care, and housing — where productivity growth has been much slower.
Over time, low-productivity sectors have become a larger share of the economy, while high-productivity goods production has become a smaller share. And an economy dominated by industries with low productivity growth is going to grow slowly.
Slow growth sounds bad, but the future implied by the productivity paradox isn’t actually so terrible. It means that in the future a small minority of people will produce the world’s material goods and automated services, while the rest of us are focused on providing personalized services to each other. It’s a future of material abundance and plentiful jobs.
Indeed, one way to think about it is that middle-class Americans are getting close to enjoying as much material comfort and convenience as it’s possible for any society to provide for ordinary people. Accumulating even more stuff isn’t going to make us much happier, so we’re devoting more and more of our incomes to personal services that don’t see rapid productivity growth but do a lot to make our lives better.
Two things can happen when a given industry enjoys soaring productivity — it can expand, as new production techniques lead to a surge in output and consumption, or it can shrink, as a smaller and smaller number of people are needed to serve a fixed market. The history of the textile industry provides examples of both dynamics.
Americans started to mechanize the production of cloth in 1814. Productivity per worker steadily improved, and at first these gains powered a rapid expansion of the textile industry. People in the 19th century owned very few clothes, so as cloth got cheaper, people bought more.
But by the 1950s, this process had reversed. People already had plenty of clothes, so as prices continued to fall, people just spent less on clothing and pocketed the savings. As a result, apparel spending as a share of the typical household’s income has fallen steadily for the past 60 years.
Agriculture tells a similar tale. In 1900, farming was the biggest industry in America, employing about 40 percent of workers. A century later, farms were more productive than ever, but they employed less than 2 percent of the workforce. And because people only need so many calories, spending on food has plummeted.
In the mid-20th century, consumers took money they were saving from cheaper food and clothing and used it to buy a wide range of other manufactured goods that had recently been introduced: telephones, electric lighting, cars, radios, washing machines, refrigerators, televisions, air conditioners, and so forth.
Most of these products experienced a life cycle similar to the one I described for clothing. Cars went from nonexistent to a rare luxury item to a mass-market consumer product that employed a vast army of factory workers. The same happened for vacuum cleaners, telephones, refrigerators, and other household applies. But eventually, we reached a point where almost every home had a refrigerator and there was little room left for quality improvements. At that point, further productivity gains in manufacturing mostly meant that refrigerators got cheaper and consumers spent less on them.
This process can take a few decades, which means the many significant inventions between 1900 and 1940 allowed the manufacturing sector to continue growing through the 1970s.
The past few decades have been different, as economist Robert Gordon has argued. The list of major new inventions in the past 40 years is pretty short, and it’s dominated by computing gadgets — PCs, gaming consoles, DVD players, smartphones. In most other areas of our lives, Americans largely buy the same things we bought 20, 40, and even 60 years ago.
Innovation in manufacturing hasn’t stopped. American factories now produce about twice as much per worker as they did in the 1980s. But we’ve mostly gotten cheaper goods or modest quality improvements — not the invention of major new product categories. As a result, the manufacturing sector is winning a smaller and smaller share of consumer spending.
And as the chart above shows, this isn’t just an American phenomenon — and it’s not primarily about jobs moving overseas. Manufacturing’s share of the global economy has been shrinking, just as it has in the US.
When thinking about manufacturing’s declining share of the economy, it’s easy to think there must be something wrong with the manufacturing sector. But the truth is closer to the opposite: Manufacturing industries are victims of their own success. In recent decades, the manufacturing sector has consistently enjoyed higher productivity growth than the economy as a whole. Manufacturing is shrinking relative to the broader economy precisely because it has continued to get more productive even as demand for manufactured goods plateaued. That’s the productivity paradox.
With few new manufactured goods to spend money on, consumers have devoted more and more of their income to industries where productivity growth is slow or non-existent. These tend to fall into two big categories. Some industries, such as health care, education, and child care, suffer from low productivity growth because they are labor-intensive and difficult to automate. Others, notably housing in affluent areas, have become more and more expensive due to natural and legal limits on supply.
So to deliver high growth rates over the coming decades, one of two things would have to happen. One possibility is a series of major new inventions — perhaps flying cars, space tourism, holodecks, or nanorobots that cure cancer — big enough to entice consumer dollars away from low-productivity service industries. This seems unlikely to me — it would take some really impressive breakthroughs to reverse a 50-year trend — but it’s impossible to rule it out.
The more likely option is to figure out ways to automate industries that are labor-intensive now. An obvious example would be taxi and truck drivers being replaced by self-driving vehicles. If this kind of thing happened across a range of other industries, economic growth would soar. And many people think artificial intelligence software is about to make that happen.
I think that’s unlikely no matter how sophisticated AI software gets. The reason is that the productivity paradox operates within industries as well as among them. To see how this works, consider the case of coffee shops
In 2012, the Wall Street Journal reported that “Starbucks baristas are being told to stop making multiple drinks at the same time” as a result of “customer complaints that the Seattle-based coffee chain has reduced the fine art of coffee making to a mechanized process with all the romance of an assembly line.”
A Starbucks barista in Minnesota griped that the new rules had "doubled the amount of time it takes to make drinks in some cases."
People don't go to Starbucks simply to get a cup of coffee — after all, there are lots of cheaper and faster ways to get a cup of joe. People go to Starbucks because they want a cup of coffee and the “romance” that comes from getting personal service from a human being.
This means that even if Starbucks invented a vending machine or robot that could make and sell coffee as well as a human barista, it wouldn’t make sense for Starbucks to lay off its human workers. Baristas aren’t just an expensive way for people to get the coffee they want; they’re essential to Starbucks’s strategy for distinguishing itself from lower-cost options like making coffee at home or the office or buying it from McDonald’s or Dunkin’ Donuts.
A lot of other service industries work the same way:
Automation treats human labor as a cost to be reduced or eliminated. But this attitude misunderstands the value of the human workers in these industries. The opportunity to interact with other human beings is a big selling point for fancy restaurants, farmers markets, and in-person fitness classes.
If we ever figure out how to automate aspects of education, health care, or other major labor-intensive industries, something similar is likely to happen.
If people develop online educational technology that works better than traditional lectures, tests, and so forth, that could be offered as a separate product for frugal students. But parents who can afford it are likely to prefer traditional universities. Traditional universities can always adopt educational technology for aspects of the college experience where it’s really better. But they can also offer personalized services  — like faculty mentoring and face-to-face interactions with other students — that no online service can offer. So online learning will always be a cut-rate alternative to a four-year university, just as an exercise video or app is a downscale alternative to a fitness class or personal trainer.
Similarly, we may eventually invent software that can diagnose medical problems as well as a human doctor, and that would provide a low-cost option for people who can’t get time with a human doctor. But doctors do a lot more than diagnose diseases — they perform physical examinations and surgeries, answer patient questions, coordinate patient care, and so forth. So people who can afford it will prefer to talk to a human doctor — who may integrate the latest diagnostic software into their practice — just as most people prefer a tax accountant over TurboTax.
That’s what I mean when I say the productivity paradox works within industries as well as among them. As society gets wealthier and manufactured goods get more affordable, people spend a larger and larger share of their income on upscale, labor-intensive alternatives within any given industry.
An important consequence of the productivity paradox is what it does to prices and wages. When a particular industry gets more productive, it tends to benefit both workers in the industry (who may get raises) and customers (who enjoy price cuts).
You might expect the converse to hold for low-productivity industries: that if productivity doesn’t improve, then wages and prices won’t change either. But that’s not how it works.
If you run a small-town restaurant that pays waiters $10 per hour and the factory in town announces it’s giving entry-level workers a raise from $11 to $13 per hour, you’re going to have to pay your waiters more too or risk having them quit for factory jobs. And because they won’t be getting any more work done than before, this likely means you’ll have to raise your prices.
This is a general economic principle: When some industries enjoy high productivity growth, industries with slower productivity growth tend to raise wages and, therefore, prices. A barber today can perform about as many haircuts as his predecessors 100 years ago, but barbers today make a lot more money than barbers did a century ago. As a consequence, haircuts cost a lot more, in inflation-adjusted terms, than they did a century ago.
In the economics world, this is known as Baumol’s cost disease. It’s named after William Baumol, the economist who first described the phenomenon in the 1960s. Baumol was trying to explain why performing arts institutions kept getting more expensive to run (he observed that playing a string quartet took exactly the same amount of labor as it had in the 19th century), but the principle he identified applies quite broadly:
This chart shows how prices in various industries have changed since 1978 — relative to the overall price level and adjusted for quality improvements. You can see that manufactured goods like cars, clothing, furniture, and toys have steadily gotten cheaper.
Meanwhile, medical care and college tuition have been afflicted with Baumol’s cost disease, as hospitals and schools have had to pay more to attract skilled workers to be doctors, nurses, professors, administrators, and so forth. The trend lines look similar for other service industries, including veterinary services and child care — costs have soared in recent decades.
Still, the name “Baumol’s cost disease” is unfortunate, because there are actually two sides to this coin. From the customer’s perspective, rising prices amount to a troubling “cost disease.” But if you work in a service job with low productivity growth, you’ll be happy about the phenomenon Baumol described: that workers in low-productivity-growth industries tend to get raises whenever their peers in high-productivity-growth industries do. We might call it “Baumol’s wage bonus.”
Baumol’s wage bonus is a big reason why we shouldn’t be alarmed by the prospect of more and more of our economy — and, therefore, our jobs — being focused on providing personal services. Many people believe that because services workers like teachers, nurses, barbers, and police officers tend not to become more productive over time, they will inevitably lag further and further behind manufacturing jobs in terms of pay.
But that’s wrong. Baumol’s work showed why it’s wrong in theory, and the data shows that it’s wrong in practice:
Until 2006, workers in the manufacturing sector did make a bit more than workers in the service sector. But in the past decade, the trend has actually reversed, with manufacturing wages lagging a bit behind service sector wages. But regardless of which sector is ahead at any particular point in time, the more important point is that manufacturing wages are unlikely to dramatically diverge from wages in the service sector. The reason is simple: If a persistent gap opened up, young workers entering the workforce would flood into the higher-paying sector until they were brought back into balance.
People often dismiss service sector work as burger flipping, but that’s a mistake for two reasons. The service sector isn’t limited to low-paying restaurant and retail jobs. Doctors, college professors, financial advisors, real estate agents, and the like are all in the personal service sector. The service sector offers work up and down the wage scale, just as the manufacturing sector does.
But the more important point is that factory jobs used to be awful. That changed slowly and painfully over the course of the late 19th and early 20th century as society developed institutions like labor unions that helped ensure ordinary workers were treated fairly.
There’s probably nothing we can do to stop the growth of service sector jobs. What we should be doing instead is taking this shift seriously and thinking more about how to make service sector jobs better. Depending on your politics, you might think that would mean stricter enforcement of labor laws, stronger union organizing, lowering of barriers to entrepreneurship, better worker training, etc. A serious debate about those alternatives would be a lot more productive than complaining about the decline of manufacturing — a long-term trend that can’t and shouldn’t be reversed.
At this point, it should also be clear why I think people are mistaken when they predict that automation will lead to a jobless future. Automation will certainly eliminate many jobs, just as it has done for the past 200 years. And some economists worry that the premature decline of manufacturing in developing countries will stunt their long-term growth. But a wealthy society has a basically unlimited demand for workers to provide personal services.
Most parents would like to send their young kids to day care options with fewer children per adult, and their older children to schools with smaller class sizes. People would like to provide their elderly parents with better elder care services with more human interaction.
People would like their doctors to have more time to talk to them. They’d like to go out to more fancy dinners and take vacations at fancier resorts. They’d like to have personal fitness instructors and life coaches. They’d like to go to more concerts, plays, and comedy clubs. They’d like to have people renovate their kitchens and bathrooms.
Demand for these services will always outstrip supply because each worker only has about 2,000 hours of work to offer to the market each year, and there’s a lot more than 2,000 hours of work each of us would like to have other people do for us. Most of us can’t afford all the human services we’d like to consume, so we buy a Roomba instead of hiring cleaners, buy frozen dinners instead of eating out, and so forth. But if automation made us richer, we’d spend more on these services and employ more people as a result.
In 1930, the economist John Maynard Keynes wrote a famous essay called “Economic Possibilities for our Grandchildren,” in which he speculated that the workweek could continue falling to 15 hours over the next century.
It doesn’t look like that’s going to happen, and our demand for personal services helps to explain why. Americans with above-average incomes could work a lot less and still support their families. A blogger named Mr. Money Mustache brags about how he retired at age 30 after living frugally as a software engineer during his 20s. Lots more people could do this if they really wanted to.
But most of us don’t want to. We’d rather work more and enjoy more luxuries. And while luxuries can take a variety of forms — with expensive housing being a big one in coastal cities — the most expensive ones are increasingly the ones that are the most labor-intensive.
So I think the future will look like the present — but even more so. A tiny minority of the population will produce the world’s clothing, smartphones, cars, household appliances, and other material goods. Almost everyone will work providing each other with personalized services — and these services will consume a growing share of our incomes.
When word leaked on Friday that AT&T, the wireless carrier that also owns Direct TV and the smallish U-Verse wireline fiber optic service, was preparing to purchase Time Warner, shares of the telecom utility immediately plummeted and those of the media conglomerate soared. In subsequent days, analysts have put forward various versions of the story from insiders in both companies as to why this is a good idea.
But it’s worth taking that initial market reaction seriously. The combined company, if it comes together, may well prove to be a well-managed and profitable conglomerate. But in order to purchase Time Warner, AT&T and its shareholders are going to have to pay a premium over the current price of its stock.
But there’s no reason to believe Time Warner’s shares are undervalued. There’s also no reason to believe useful synergies will flow from combining Time Warner’s portfolio of television and movie content with AT&T’s portfolio of cell towers, satellites, and fiber optic cables.
AT&T’s board and management, in other words, appear to be simply wasting AT&T’s shareholders’ money. What’s in it for them isn’t so much the opportunity to build a great new business as to break out of the dreary reality that their current business is boring. As the leaders of larger conglomerate, they’ll be able to pay themselves higher salaries and hang out with movie stars.
People consume video content over various “pipes” that AT&T controls, and Time Warner either producers or owns the rights to a lot of video content. In theory, you certainly could combine these businesses. Right now, for example, many NBA games are exclusively available on Time Warner’s TNT network, which is only available to cable subscribers. A merged company could let cord-cutting AT&T wireless users stream those games without buying cable, enticing basketball fans to switch from Verizon or Sprint. Or HBO Go subscriptions could be sold at a discount as part of a “bundle” with AT&T telecom services.
One problem here is it’s not clear that the economics of this kind of integration pencil out. Nothing is stopping Time Warner’s constituent elements from striking these kinds of deals with today’s wireless companies. The deals don’t get done because there aren’t mutually advantageous terms. Combining the two companies into one could force the component elements to come to terms, but those arrangements wouldn’t necessarily result in higher profits — they would just shift gains from one subsidiary to another.
But even if some of these ideas do make sense, the government probably won’t let them happen.
We have a clear precedent from back in 2010 when Comcast, the gigantic cable company, bought NBC Universal, a media conglomerate similar to Time Warner (and also an investor in Vox Media, which owns this website). When the takeover plan was announced, the merging companies had all kinds of grand plans for bringing content and infrastructure together. That raised huge red flags for regulators who worried that Comcast was seeking to use its strength in the relatively low-competition infrastructure industry to gain leverage in the content industry.
Consequently, the government agreed to approve the merger only on condition that Comcast and NBC Universal disavow making any special deals with each other that were not available to other companies. The approval notice from regulators required the creation of “an improved commercial arbitration process for resolving disputes about prices, terms, and conditions for licensing Comcast-NBCU’s video programming” and “requir[ed] Comcast-NBCU to make available through this process its cable channels in addition to broadcast and regional sports network programming,” among other things.
This was considered, at the time, a relatively lenient settlement, and since then the regulatory environment has gotten more — not less — skeptical of this kind of merger. The Obama administration is widely perceived to have become more skeptical of mergers in the intervening years. Hillary Clinton has promised to step up antitrust enforcement relative to where it is today. And Donald Trump outright promised to block the deal during a Saturday speech.
The AT&T/Time Warner proposed merger will be a really good test to see if Clinton plans to live up to her rhetoric on antitrust.
We don’t know if the deal will ultimately be approved. AT&T badly misjudged the regulatory climate back in 2011 when it tried to buy T-Mobile only to have it disallowed by the Federal Communications Commission and Justice Department. So this could prove to be another overreach. But if regulators do approve the terms, they will surely insist on Comcast-esque terms that vitiate the ostensible business rationale for the deal.
Why did Comcast go through with the deal even after regulators axed the supposed synergies it was supposed to create? The cynical answer is that Comcast is confident it will find a way to cheat. The even more cynical answer is that Comcast’s executives don’t really care. Being a cable company is a great business, but it’s boring and unglamorous, plus everyone hates you.
The executives of a media company, by contrast, get to hang out with A-list celebrities and star athletes.
They also get paid very well. As the Associated Press reported last year, “six of the 10 highest-paid CEOs last year worked in the media industry.”
None of the top 10, by contrast, was the head of a utility company. Well, except for Brian Roberts, the CEO of Comcast, who counts for the purposes of AP’s list-making as a “media industry” CEO because his cable company also owns NBC Universal.
All of which is to say that AT&T CEO Randall Stephenson, who is currently paid less than Time Warner CEO Jeffrey Bewkes, and his team of executives have a perfectly good reason to want to buy Time Warner — whether or not it makes business sense.
Talk of buying Time Warner naturally brings to mind AOL’s disastrous 1999 acquisition of Time Warner, which over 15 years later is still remembered as the most catastrophically failed merger of all time.
This serves, in an odd way, to set the bar unreasonably low for an AT&T takeover. Pieces making the case for the merger frequently invoke the comparison only to debunk it, explaining that the current situation is totally different. And it really is different! This deal, if it goes through, almost certainly will not go down in history as the worst deal of all time.
In fact, the combined company should even be successful. AT&T is a profitable phone company and Time Warner is a profitable media company, and if you slap them together you’ll have a big, profitable company. The merged Comcast-NBC Universal entity isn’t doing anything special, but it’s a well-managed business that makes money. There’s no reason AT&T couldn’t pull off the same thing.
But when you pay a premium to buy another company, the test isn’t supposed to be “will the combined entity avoid being a huge catastrophe that ruins everyone’s lives and careers?” The test is supposed to be “will this be worth the money?” In the case of AT&T/Time Warner, the answer seems to be no. But it’s the shareholders’ money, so who’s counting?
If you open up your wallet, you probably have an assortment of $1, $5, and $10 bills — and maybe a few $20 bills. You almost certainly don’t have a thick stack of $100 bills.
Yet statistics show that $100 bills account for a large majority of the value of cash in circulation. There is $1.38 trillion worth of cash in circulation; $1.08 trillion of this is in the form of $100 bills. If you do the math, that works out to 34 hundreds in circulation for every man, woman, and child in the United States — even though a normal American rarely carries even one.
Of course, this cash isn’t evenly distributed. No one knows exactly who has all those large bills because physical cash, by its nature, is hard to track. Studies suggest that's precisely its appeal, and consequently most C-notes are used for a variety of illicit purposes —  tax evasion, drug dealing, bribery, and so forth — both in the United States and overseas.
Harvard economist Kenneth Rogoff believes that the solution is to get rid of cash. In a new book, he argues that abolishing $100, $50, and perhaps even $20 bills will seriously inhibit crime and tax evasion while doing little to hamper legitimate commerce.
We spoke on the phone in early October. The transcript has been edited for length and clarity.
You call your new book The Curse of Cash. What is the curse of cash and what should we do about it?
There's a lot more cash out there than we really need for the legal economy. A big chunk of the cash that the US, the eurozone, Japan, other advanced countries have printed is floating around in the world underground economy. It’s facilitating drug trafficking, human trafficking, extortion, money laundering. It also plays a role in illegal immigration.
My recommendation is not to get rid of cash. It is not to go to a cashless world. It's to get rid of the big bills, which don't have an important use in normal transactions. And I propose doing this very slowly over a long period. I go as far as to get rid of the $20 bill, though we could debate that.
I'm trying to interfere as little as possible with ordinary uses while making it as hard as possible to hide and launder money, which is why the $100 bill is so popular.
I also have a proposal for financial inclusion: providing debit cards just to protect low-income people from adverse effects. They are not the ones mainly using the $100 bills anyway.
There’s a ton of cash in circulation, and in your book you say that no one knows for sure who has it and how it’s being used. But just to help readers understand this issue, could you give us your best guess about who has it and why?
At least half of $100 bills are held abroad. The Fed used to think they were almost all held abroad, but we now know that's not true. In fact, when you look at cross-country comparisons, it seems that a lot of them must be held at home.
It's a really hard to know to apportion it between tax evasion and crime, but I'm guessing that of the ones that are held domestically, 75 percent or 80 percent are for tax evasion and crime. The Fed has tried to demonstrate that there's a lot in legal usage, and they can't.
Other countries have done studies. The British did this very detailed study and found these massive hordes of cash being used in illegal activity. A lot of $100 bills are used by Mexican drug lords. Columbian FARC rebels use them a lot. Oligarchs in Russia hold them a lot. In China they're used a lot by wealthy people to do transactions off the radar.
Some of that we might say is doing a public good. But it’s hard to say that about Mexican drug lords.
The Bank of Canada produced a report recently showing a very large supply is unaccounted for and they found it in places like construction contractors' basements.
Let’s take construction companies as an example. Why specifically would a construction company hold so much cash, and what are they doing with it?
The construction industry is an area where people do a lot of payments off the books. There’s a lot of hiring undocumented workers. There’s some avoidance of regulation and some avoidance of taxes.
In Boston, it used to be the case that there were sites you could show up and get hired for certain types of daily construction work. They were undocumented workers.
I actually favor a broad amnesty program for existing illegal immigrants. One of the objections to amnesty is that you open the floodgates for more people to come in. Right now the payments from employers in cash are the big magnet, maybe it wouldn't be as extreme as it is now.
What about concerns that phasing out large bills would hurt poor people, many of whom prefer to deal in cash? You’ve proposed giving debit cards to everyone, but low-income consumers haven’t always had good experiences with debit card systems.
Other countries manage to deal with this fairly straightforwardly. Nordic countries give everyone who gets government transfers free debit accounts. It's very inexpensive.
But more broadly, I think the idea that this is bad for poor people has it backward. The tax evaders are at the upper part of the income distribution. Payment recipients, like cleaners, don’t owe taxes. And if they’re paid under the table, then when they reach retirement age and try to get their Social Security, there isn't any. This is not something that favors poor people.
Also, crime falls disproportionately on the poor communities. So it is an important question and a tough question.
In addition to the crime-fighting benefits, you argue that phasing out large bills will make monetary policy more effective by allowing the Fed to boost the economy by setting negative interest rates. You argue that negative rates could be necessary if interest rates stay at their current low level, and you worry that people could defeat negative rates by stockpiling $100 bills in warehouses.
The thing I wonder about here is: Wouldn’t it be simpler to just set a higher inflation target? What really matters for monetary policy is inflation-adjusted interest rates. So if the Fed raised its inflation target from 2 percent to 4 percent, then a nominal interest rate of zero would be equivalent to a real interest rate of -4 percent — which seems like it should provide the Fed with plenty of breathing room. This seems like it would be simpler and less controversial than trying to phase out cash so we can force people to accept negative interest rates.
The biggest argument against changing the inflation target is that it will confuse the heck out of people. If Federal Reserve chair Janet Yellen and European Central Bank President Mario Draghi had a press conference and said, “we told you that 2 percent is nirvana but now it's 4 percent. We're sorry about our mistake,” I think it would be very hard to anchor those expectations.
I think you could literally have a financial crisis out of that. And then who believes the 4 percent target?
A subtle but really important argument that Stan Fisher has made is if you have 4 percent inflation, you’ll have more inflation indexing. People will change wages and prices more often. And in theory if prices and wages change all the time, monetary policy does nothing. So it's perfectly possible that you raise the inflation target to 4 percent and then you need all of it because monetary policy is less effect.
Another problem is that the distortions caused by a higher inflation target are pretty substantial. Let's suppose people don't change prices more often. Then when it comes time to make a change, you're going to make a much bigger change. So there will be larger economic distortions.
In 2012, Narayana Kocherlakota did something that’s rare for a policymaker of his prominence: He changed his mind. Kocherlakota was the president of the Minneapolis Federal Reserve Bank, which gave him a rotating seat on the powerful Federal Open Market Committee. That’s the committee that decides whether — and to what extent — the Fed should use its control over the money supply to boost the economy.
When Kocherlakota took the helm of the Minneapolis Fed in 2009, the Minneapolis Star Tribune described him as “openly suspicious of government's ability to bolster economic growth.” That view was evident in 2011, when Kocherlakota cast a rare dissenting vote against a stronger Fed effort to boost the economy. He argued that the Fed’s dovish policies could create too much inflation.
But the inflation Kocherlakota feared never came, and a year later Kocherlakota’s thinking had changed dramatically. In September 2012, he began calling for the Fed to do more to boost the economy. In 2014, he dissented three times from Fed decisions, each time calling for the Fed to be bolder about growth and less worried about inflation.
Kocherlakota’s term at the Minneapolis Fed ended earlier this year. He now teaches economics at the University of Rochester and writes a column for Bloomberg. But he has continued to argue that the Fed is too cautious.
If he’s right, it could be a really big deal. The current recovery has been the slowest in decades; the economy has fallen trillions of dollars short of its pre-2007 trajectory. Kocherlakota believes inadequate monetary policy is partly to blame for this shortfall.
And his view is becoming increasingly mainstream. Indeed, in a speech last week, Fed Chair Janet Yellen suggested that stronger Fed action might be needed to boost the economy’s growth rate. The comments come at a time when the Fed is widely expected to raise interest rates within months. But Yellen’s comments — which echo Kocherlakota’s arguments — suggest that the Fed might want to keep rates low for much longer than that.
When Kocherlakota took over as the head of the Minneapolis Fed in 2009, he believed there simply wasn’t that much the Fed could do to boost the economy. By 2011, the unemployment rate was still around 8 percent. However, Kocherlakota told me, “I was concerned that a large amount of the unemployment was due to structural forces that would be very difficult for monetary policy to influence.”
For example, workers in areas with high unemployment might find it difficult to move to other cities where jobs were more plentiful. Or it might take time for workers in declining industries to be retrained in industries where demand was rising. If these kinds of factors were responsible for high unemployment rates, Kocherlakota reasoned, pumping more money into the economy wouldn’t boost growth; it would just push up prices.
“The way that would manifest itself is by inflation rising above the committee's 2 percent target,” Kocherlakota said. “That was my concern in 2011.”
But two factors caused him to change his mind. One was that the inflation he and other hawks feared never materialized. Inflation fell in 2012 and has stayed below the Fed’s 2 percent target ever since.
Kocherlakota said he was also influenced by new economic research. In particular, a 2012 paper by economists Edward Lazear and James Spletzer convinced him that structural explanations — like a mismatch between the skills workers have and the skills employers are demanding — couldn’t explain the weakness of the labor market.
“The main conclusion was that the unemployment that was in place in 2011 and 2012 was largely attributable to non-structural influences that could be amenable to monetary policy,” Kocherlakota said. In other words, he became convinced that if the Fed pumped more money into the economy, we’d get lower unemployment and higher growth instead of just more inflation.
In 2012, Kocherlakota’s newfound belief in the power of monetary policy to boost growth ran counter to economic orthodoxy. The conventional view held that monetary policy has the biggest effects for 12 to 18 months after a major shock like the 2008 financial crisis. After that, further efforts to boost the economy would simply produce more inflation.
This conventional view focused on the role of wage and price changes in smoothing out economic fluctuations. For example, if an industry is in decline, a fall in workers’ wages may be necessary to avoid the need for layoffs. The Fed can help this adjustment process along by boosting the inflation rate (or preventing a burst of deflation). That allows workers’ real (inflation-adjusted) wages to fall without the need for morale-destroying reductions in workers’ nominal wages.
“There's been a ton of work done in economics on trying to measure how quickly prices change. And most of the work has found that prices change pretty rapidly,” Kocherlakota told me. This means that unless the Fed totally screws up, this adjustment process should be complete within 18 months of a major downturn.
If that view were true, then it would have been pointless for the Fed to try to boost the economy in 2011, because by that point — more than two years after the 2008 financial crisis — the market’s natural adjustment process would have already run its course.
But Kocherlakota now believes this view is mistaken. He believes that especially in the current environment of low interest rates and low inflation, what really matters is the Fed’s ability to affect the market’s expectations about future growth rates.
This is because businesses take future economic conditions into account when they make today’s investment decisions. “If they see better demand conditions in the future, they're more likely to implement ideas and to engage in innovation, and we'd have faster productivity growth as a result of that,” he argued. This means that if the Fed can make a credible promise to boost growth in the next few years, it can result in a self-fulfilling prophesy where businesses invest more today.
In Kocherlakota’s view, easier money wouldn’t just help reverse the decade-long decline in Americans’ workforce participation rate. He argues that stronger monetary policy could actually increase workers’ productivity by giving companies the confidence they need to make long-term investments in technologies that boost worker productivity.
Instead, the Fed has talked incessantly about raising interest rates, a signal that it’s preparing to withdraw support from the economic recovery.
“There is a growing lack of confidence in central banks' ability or willingness to offset persistent downside shocks,” according to Kocherlakota. “That makes people less willing to spend [and] less willing to invest if you're a business owner, and that creates downward pressure on interest rates. People feel that both fiscal authorities and monetary authorities seem to lack the will or the ability to offset shocks, and that's going to make them very guarded about spending.”
When Kocherlakota first articulated these views in 2012, they were far outside the mainstream of economic thinking. Most people — including Kocherlakota himself just a year earlier — believed that the Fed had done plenty to support the economic recovery and that the slow growth of the post-2009 period was due to other factors.
But as the slow recovery has continued year after year, his views have started to seem more plausible. In a speech last week, the nation’s top monetary policymaker, Fed Chair Janet Yellen, floated some ideas that sound a lot like the ones Kocherlakota has been championing over the past four years.
Yellen suggested that insufficient spending as a result of weak monetary policy could have negative long-term effects on the economy’s productive capacity — for example, by causing discouraged workers to drop out of the labor force. She then asked whether these effects could be reversed by “temporarily running a ‘high-pressure economy,’ with robust aggregate demand and a tight labor market.”
“One can certainly identify plausible ways in which this might occur,” Yellen said. “Increased business sales would almost certainly raise the productive capacity of the economy by encouraging additional capital spending, especially if accompanied by reduced uncertainty about future prospects.”
Meanwhile, she said, “a tight labor market might draw in potential workers who would otherwise sit on the sidelines and encourage job-to-job transitions that could also lead to more efficient — and, hence, more productive — job matches.” It could also boost productivity by “prompting higher levels of research and development spending and increasing the incentives to start new, innovative businesses.”
In short, the Fed might still have a lot of room to boost the economy.
Yellen made clear that she isn’t endorsing these arguments — yet. She said more research was needed, and emphasized that keeping money loose for too long could have significant downsides. Still, her speech makes it clear that these ideas are becoming increasingly mainstream, and Kocherlakota deserves a lot of credit for that shift.
Back in 2014, Apple launched a massive project, code-named Titan, to build a car. But a couple of years later, Apple is drastically scaling back its ambitions. According to Bloomberg, the company has given up on the auto-manufacturing dream entirely. Instead, it’s focusing on writing self-driving car software that could power cars manufactured by traditional automakers.
Silicon Valley moguls have gotten into the habit of jumping into new industries and quickly turning them upside down — as Apple’s iPhone did to the cellphone industry. But Apple’s car struggles are a reminder that not every industry is as ripe for disruption.
Manufacturing a car is really hard. And succeeding at it requires a different kind of corporate DNA than succeeding in the computing sector. Tesla has been slogging through these challenges head on for a decade, and profitability is still years away. Google seems to have decided that car manufacturing isn’t worth it — it’s focused on creating software that will eventually run on cars manufactured by others.
Now Apple seems to be seeing the wisdom of Google’s approach, implicitly conceding that car companies have unique capabilities that Silicon Valley can’t easily duplicate.
The best explanation I’ve seen of Silicon Valley’s struggles to build its own cars comes from industry analyst Edward Niedermeyer, whom I interviewed earlier this year.
Niedermeyer pointed out that cars are complex products with hundreds of moving parts, and customers expect them to work reliably for years, over tens of thousands of miles, and in all kinds of terrain and weather conditions. These challenges are magnified by the massive scale required to turn a profit in the car business — which means that every production mistake costs millions of dollars to fix.
That means that succeeding in the car business requires a degree of regimentation that’s rare in Silicon Valley, where innovation is often valued more than flawless execution. Car companies plan the manufacturing process in great detail and have extensive systems for detecting and fixing flaws. Building up the necessary knowledge, equipment, and organizational structure takes years — even decades — of expensive trial and error.
Niedermeyer offered an example of the kind of challenge Tesla has faced as it has tried to grow from a luxury carmaker into a mainstream one:
A great example is the problem of mold growing from inside the Model S's roof, particularly in Norwegian cars. Because its large panoramic sunroof is difficult to manufacture and install to a precise specification, Model S roofs often leak. A lot of those leaks are so small that customers might not notice. But because Tesla used an organic-fiber pad at the edge of the sunroof, aggressive molds invade at alarming rates in certain climates.
Of course, an iPhone is also a complex product with many components that have to fit together perfectly. But cars are much bigger, have a lot of moving parts, include many different types of material, and are expected to work in punishing conditions ranging from blizzards to tropical rains. That means there are a lot more ways a car can break down, and there’s no substitute for years of experience testing cars in a wide variety of real-world conditions.
Of course, just as technology companies can’t easily duplicate car companies’ manufacturing prowess, the same is true in reverse. Building great software requires a particular culture, structure, and set of skills that technology companies have and car companies mostly don’t. Which is why car companies and technology companies are increasingly rushing into each other’s arms.
And so far, it looks like technology companies have the upper hand. There are only a handful of major technology companies known to be working on self-driving car software — Apple, Google, and Tesla are most prominent — whereas there are lots of car companies looking for tech sector partners. So if Apple can develop self-driving software that rivals Google and Uber’s, it won’t be hard to find automakers eager to incorporate its software into their cars.
Focusing on self-driving software allows Apple to keep its options open. It can potentially work with several different car companies and focus resources on the partnerships that prove the most promising.
This leaves Tesla as the only Silicon Valley company trying to bring Apple’s traditional strategy of selling both hardware and software over to auto manufacturing. Tesla is betting that doing both will allow it to reimagine the way cars are designed and deliver a more elegant, compelling product. But there’s a big risk that CEO Elon Musk has simply bitten off more than he can chew.
Recent breakthroughs in artificial intelligence and machine learning are enabling computers to understand the world and respond intelligently to it. Google is already embracing these technologies for Android, but they’re poised to have bigger implications, touching everything from drones to medical diagnosis.
At least that’s the view of Marc Andreessen, a prominent venture capitalist at the firm Andreessen Horowitz. And he should know. He made his fortune as co-founder of Netscape two decades ago, and more recently his firm has invested in successful companies like Facebook, Twitter, Airbnb, Slack, and Lyft. Andreessen is in constant contact with entrepreneurs and investors trying to build the next great technology company.
Andreessen argues that recent breakthroughs mean artificial intelligence has the potential to spawn a new generation of big, important technology companies. At the same time, he acknowledges that certain industries have proven stubbornly resistant to technological change — and he argues that more work is needed to bring the power of software to every corner of the economy.
We spoke by phone in late September. The transcript has been edited for length and clarity. You can read part two of the conversation here.
Where do you think the next great technology companies will come from? In the 1990s you had Google and Amazon, and in the 2000s you had Facebook and Uber. Obviously there might be a startup I haven’t heard of yet that’s about to get a big break. Still, it’s hard for me to think of any companies founded in the last six years that have a shot at becoming a Google or Facebook or Amazon-sized company.
The traditional way this happens is with new platforms and architectures. New generations of technology that emerge. The last big category of technology was the smartphone and smartphone apps. Smartphones materialized in 2007, many of the app categories were identified in 2010 or 2011. It’s becoming clear that there are some major new smartphone-centric companies that are going to be important companies. But four years ago or even two years ago that wasn't clear as it is today.
So if smartphone architecture was the last one, it feels like artificial intelligence, virtual reality, autonomy, voice, and the internet of things are all candidates for the next wave. The obvious example right now is AI. It sure feels like there are going to be a new set of products and companies that are going to be AI-powered at their core.
Facebook and Google and Amazon have these giant first-class efforts in this space. But we’re also seeing a legion of startups. I think there will be a whole generation of new very important AI companies that come out — many of which are just getting started right now.
People have been talking about AI for a long time, but commercial success has been elusive. What makes you think things are different now?
I was really skeptical at first. It’s not widely known, but there was an AI bubble in the 1980s where there were a whole bunch of venture-backed companies that got funded and they basically all blew up and torched all the capital.
We feel like we're seeing something different now. The really big change was the ImageNet competition in 2012. In 2012, computers became better than people at recognizing objects in images. This is an actual competition where they’ve calibrated how to measure this.
Basically what we've seen in the last four years is breakthrough after breakthrough after breakthrough. First was the breakthrough in recognizing objects in still images. There are corresponding breakthroughs happening right now in recognizing objects in videos — entirely new kinds of video classification. If you can do video recognition you can do realtime video, which means you can do autonomy.
We’ve invested in a company called Skydio that’s doing full autonomous consumer drones. It's such a different product than you can get today, with such different capabilities, it’s almost eerie. It's following you around with no human guidance at all. You run into a forest and it’s navigating and flying between tree branches entirely by itself. And it’ll be at a consumer price point. That's something out of a science fiction movie.
We’re seeing deep learning applied to pre-detection of cardiac events. We have a company called Freenome doing deep learning applied to blood biopsies for cancer diagnoses that seems to be working very well.
There’s a classic tech industry question: “Is this a product or a feature?” You see Google, Facebook, and Amazon all putting a lot of money into artificial intelligence. Siri began as a startup but was quickly acquired by Apple. So is AI going to spawn big, independent companies with new products? Or is it more likely that these innovations will be absorbed by existing big companies to improve their existing products?
Two years ago, I thought the big companies would dominate. The big companies had several big advantages:
What's happened in the last two years is that every single one of those factors has changed to at least some degree. All of a sudden, you have a lot more computer science graduates coming out knowing how to do this because this has become the hot new area of computer science. You also have a lot of the engineers who have been at the big incumbents working on this stuff who are now realizing they can start their own companies.
There's a whole new generation of autonomous vehicle startups that are spinning out of Google. Otto (recently acquired by Uber) was a prominent one, but there are, like, six others that are in flight right now.
Meanwhile, the technology itself is becoming more tractable. A lot of the interesting new projects we’re seeing don't need 1,500 people. They need five. Google open sourced this thing called TensorFlow, which is one of the building blocks of deep learning. We’re seeing startups all over the place picking that up and running with it, which would not have been possible a couple of years ago.
The science itself keeps advancing. People are learning how to do deep learning on small data sets.  We’re seeing startups that either figure out a clever hack to get the big data set, or figure out a way to run the algorithms in a way where they only need a small data set.
A lot of these potential AI applications seem like viable businesses but not necessarily big businesses. And for the really big opportunities — like self-driving cars — it seems like the big companies have advantages that will be hard to match.
I still think you're thinking of this as you'll take an existing product and add some AI to it. That’s not what we’re seeing. What we’re seeing is an entirely new kind of product that wasn't possible before.
Let's talk about drones for a second. You buy a drone today and pilot it yourself and 20 minutes later you crash into a tree. You say “boy that was fun,” and you have to buy a new drone.
The incumbent drone-makers have been talking for some time about adding a feature they call “follow me.” The number of drone companies that are either incumbent drone companies that are deciding they want to add that feature, the number of Kickstarter projects that are promising to add that feature, is dozens or hundreds. But nobody’s been able to make it work.
The reason is because it's not a feature; it's a totally new architecture. The drone has to be built on AI from the ground up. The bet that DJI and other drone makers are making is that it's a feature. The bet that we’re making is that it requires a brand new architecture.
That's an example of fundamental reinvention. If our thesis on that is right, then all the existing drones become obsolete. They just don't matter because they can't do the thing that actually matters.
If you talk to the automakers, they all think that autonomy is a feature they're going to add to their cars. The Silicon Valley companies think it's a brand new architecture. It’s a bottom-up reinvention of the fundamental assumptions about how these things work.
So it sounds like we have a lot of innovations coming out. At the same time, interest rates are very low and growth is slow in the economy overall. The way it’s supposed to work is that when interest rates are low, it’s easy to borrow money and easy to raise money, and we should have this surge of investment. But the statistics seem to show that there’s a lot more money being saved than invested. What do you think is going on?
Right now there are two different kinds of industries. There are the industries that have rapid technological adoption and productivity improvement. Television sets, computer equipment, media, food. Bloomberg had a story that food prices are plummeting because food production is getting much more sophisticated.
So you've got these sectors of the economy where there's rapid productivity growth. Prices are falling fast. Those are the industries where everyone is worried that the jobs are going away — or to China or Japan or Mexico. People say there's too much disruption — too much technological change. The Silicon Valley kids are wreaking havoc on the economy.
Then you have the sectors in which prices are rapidly rising: health care, education, construction, prescription drugs, elder care and child care. Here there’s very little technological innovation. Those are sectors with insufficient productivity growth, innovation, and disruption. You’ve got monopolies, oligopolies, cartels, government-run markets, price-fixing — all the dysfunctional behaviors that lead to rapid increase in prices.
The government injects more subsidies into those markets, but because those are inelastic markets, the subsidies just cause prices to go up further, which is what is happening with higher education.
And so in these sectors, people are irate that there's not enough productivity growth. There’s not enough technological growth and we’re paying too much.
You sum those together, you get this muddle in the middle where it looks like we're puttering along. But this masks what’s actually happening.
You have some sectors falling in prices very fast, some are rising very fast. What happens over time is that the rising-cost sectors eat the entire economy. Consumers see their incomes being eaten by health care and education.
To me the problem is clear: The problem is insufficient technological adoption, innovation, and disruption in these high-escalating price sectors of the economy. My thesis is that we're not in a tech bubble — we’re in a tech bust. Our problem isn't too much technology or people being too excited about technology. The problem is we don't have nearly enough technology. These cartel-like legacy industries are way too hard to disrupt.
One thing that most of these low-growth industries have in common is that they’re very labor-intensive. A big chunk of what you’re paying for is another human being to spend time with you — a nurse, a teacher, a nanny, etc. You’re probably familiar with the concept of Baumol’s cost disease — that as manufactured goods become cheaper, people are going to devote more of their resources to the thing that’s scarce, which is human labor.
So I wonder if this is a problem that’s just inherently unsolvable. There are always going to be some labor-intensive industries with slow productivity growth, and those industries are always going to have costs going up rapidly relative to the others.
On the macro level I agree with that. I think that’s an accurate description of what’s happening, and I do think Baumol's disease plays a big role in how the cost shifts.
The thing that I would point to is just because we think that an industry has to be labor intensive because it always has been, that doesn’t mean it has to be going forward. If you go to the productivity literature of the 1980s, one of the things they all knew for a fact in the 1980s was that you could automate production but you couldn’t automate retail. It was taken as a given that retail was always going to be labor-intensive. Distribution would always be labor-intensive. You’ve got the person who stocks the shelves, you’ve got the checkout person, you’ve got the person who helps carry stuff out to the car.
The big advance at the time was computer-based checkout and laser scanning. But it turned out the laser scan didn’t help productivity. The laser scan took time. Half the time it didn’t work and then you had to do a price check. Maybe it even degraded productivity because with the laser scan you didn’t have a price tag on the object because you didn’t think you needed one.
So there was a lot of disillusionment at that time that you’d never get retail to be more productive. Of course, in the last 20 years, retail has become radically more productive. First there was Wal-Mart with their modern approach to the supply chain. And then there was Amazon. And then I would argue the transition from physical products to software products is a third layer of productivity improvement, delivering music as an MP3 or a stream is a much more productive way of doing it than having a physical CD through stores.
So you have this giant industry of retail that was held to be completely hand-crafted. And now it turns out it can be almost completely automated. There’s a point where everyone is upset that the retail jobs are going away.
Are they though? Retail stores employ almost 5 million people, and the Labor Department has projected that to grow by 7 percent over the next decade.
That’s right. This is the thing where the luddites just keep getting it wrong. It’s an application of what you said, which is that the scarce thing becomes valuable. Retail clerks are growing.
The other thing that's been growing for decades is bank tellers. That one might actually finally begin to decline. But bank teller jobs have continued to grow for the last 30 years as ATMs and online banking were rolled out exactly for the reason you said. Which is all the sudden there’s an opportunity to differentiate by providing a higher level of service by providing a person.
Vinod Khosla has written all these stories about how doctors are going to go away. He thinks computers are going to be so much better at diagnosis that there’s no room for doctors any more. And I just think he's completely wrong. I think the job of a doctor shifts and becomes a higher-level, more important job that pays better as the doctor becomes augmented by smarter computers.
That's why I'm so optimistic about the economy. That’s why I think the Luddites and the slow-growth people are wrong. We can have tremendous amounts of job creation and have huge productivity improvements. They’re not actually in conflict, despite what everyone thinks right now.
Google’s Android dominates the smartphone market overall, but Apple has attracted a disproportionate share of high-end users — and consequently an outsize share of smartphone profits.
At a Tuesday event, Google unveiled a two-pronged strategy to change that. Part one was the Pixel, the first smartphone that will be designed and manufactured by Google. Google is betting that building its own phone will allow it to offer the same kind of seamless user experience Apple provides its own users.
But the second prong of Google’s strategy is more original and received more attention on Tuesday. The company wants to make voice-based artificial intelligence a much bigger part of how people interact with their smartphones. Google envisions a future where you’ll make restaurant reservations, look up photos, and play music by talking to your phone instead of tapping and swiping on its screen.
Obviously, this isn’t a totally new idea, as all the major smartphone platforms have had voice-based personal assistants — Apple’s Siri, Microsoft’s Cortana — for several years. But Google says it’s about to make this technology a lot better — so much better that people will use it a lot more.
If anyone can pull this off, it’s Google. Making AI really good requires a lot of data to “train” sophisticated machine learning algorithms. Wrangling large amounts of data has always been Google’s specialty. But even if the company can build a voice-based AI that can really understand a wide variety of requests, I’m still skeptical it will change the smartphone game as much as Google hopes.
Apple has a designed-focused culture and is known for its polished, elegant, and user-friendly user interfaces. By contrast, Google has a culture that’s focused on delivering fast and reliable online services.
Google’s business model for Android puts it at a further disadvantage in the user interface department. Apple designs both the hardware and software for the iPhone, allowing it to guarantee users a seamless experience. Google, by contrast, licenses Android as open source software to dozens of smartphone manufacturers, many of which customize it themselves, leading to a cacophony of different and often mediocre user interfaces.
The iPhone’s greater polish is a big reason the iPhone is disproportionately popular at the high end of the market, and why Apple is able to charge a healthy premium for the iPhone. Android has the biggest market share in the smartphone business overall, but Google earns much less in profit from the smartphone business than Apple does.
Many iPhone users nevertheless enjoy Google services like search, maps, and Gmail. But the fact that the iPhone’s operating system sits between Google and many of its users gives Apple a lot of leverage. In 2014, Google paid Apple $1 billion to maintain its status as the default search engine on the iPhone.
The executives onstage never said so explicitly, but several of Google’s announcements on Tuesday were clearly aimed at knocking Apple from its high-end smartphone throne. Most obviously, the Android Pixel is Google’s most direct challenge yet to the iPhone.
Google’s earlier line of Nexus phones were designed and manufactured by third parties; by contrast, Google is planning to bring most of this work in house for Pixel. The hope is that by owning the whole “stack” — software, hardware, and online service — Google will be able to match the seamless user experience Apple has long offered to its users.
But Google doesn’t just want to ape the iPhone; it wants a way to differentiate its products from the iPhone. Google believes its real secret weapon is a new user interface based on voice recognition and artificial intelligence.
In a sense, this is just a souped-up version of Google’s existing voice recognition feature, Google Now. Apple and Microsoft have their own competing versions, Siri and Cortana. And these products don’t seem to have had a big impact on the market.
But Google believes that’s just because the technology is not good enough yet. Google has been working to improve its voice feature in three directions:
An example can help to illustrate what Google has in mind here. Right now, if you want to look at photos from a vacation you took last summer, you’d open your photo app and scroll back until you find the date you want. Google envisions a totally different approach. You’d say, “Okay, Google, show me pictures from my vacation last July.” Android would understand the request and call up the photos.
Google’s Photos app demonstrates that Google is already well on its way to developing the image recognition technology to make this work. You can already ask Google Photos to show you photos that contain snow, or a dog, or a particular friend. Google hopes to bring these capabilities — and more — to its personal assistant, so you can ask complex queries like, “Show me pictures from 2014 that have Aunt Lisa and dogs in them.”
It’s easy to be skeptical of this kind of thing, since the existing smartphone “personal assistant” technologies aren’t very good. They get confused often enough that it’s usually easier to just do things the old-fashioned way. But artificial intelligence technology is advancing rapidly, and Google insists that it will soon be good enough that voice-based personal assistants will “just work.”
If voice-based search becomes capable enough, it could reach a tipping point where it’s easier to just ask the voice assistant for the information you need than to open up the appropriate app and find it the old-fashioned way.
This would be particularly good news for Google because it would play to the company’s strengths. It would essentially be putting search back at the center of the user experience.
Making this kind of smart voice assistant work will require oceans of information. Computer scientists have found that tasks like image and voice recognition work best when they have huge numbers of examples they can use to “train” the algorithms. A smart AI system also needs to know lots of facts about the world so that it can respond to complex queries. Collecting and organizing information has always been one of Google’s strengths — after all, Google’s mission statement is to organize the world’s information.
At the same time, it would downgrade Apple’s big strength — the ability to make elegant, user-friendly devices. If the main way people interact with smartphones is by asking them questions, the particular device will become less important — just as the advent of the web made the difference between PCs and Macs much less important.
Google is also hoping to continue the shift toward more and more user data stored online instead of on users’ local devices. Pixel buyers get unlimited, free storage for their photos and videos. That’s a good selling point for the Pixel, but more importantly, it will mean that Google can offer users access to their content from any device. Google envisions a future where users ask their Google Home smart speaker to put photos from their vacation on the TV. That kind of future would play to Google’s strength — managing massive quantities of data online.
It’s easy to understand why Google would like to essentially make voice-based searches a central part of how people interact with their phones and other devices. But even if Google manages to build a sophisticated voice assistant that can respond to a wide variety of requests, I’m skeptical that will give Google a significant leg up in the smartphone wars.
The canned demos in Google’s presentation were impressive, of course — canned demos usually are. But the question to ask is how much of the time we spend interacting with our smartphones would be improved by a smart voice assistant.
One problem is that talking to your phone isn’t always convenient. There are many social settings — at the office, in line at the grocery store, on the bus — where people around you are likely to be annoyed if you’re constantly barking commands at your phone. In those situations, you’re going to want to discreetly type or scroll your way to the information you’re looking for, so people are still going to care how user-friendly the old-fashioned touch-based interface is.
But more importantly, a lot of the time people spend on their phones — perhaps most of it — just wouldn’t be improved by a personal voice assistant. People spend a ton of time scrolling through posts on Facebook, Twitter, or Instagram, reading text messages, swiping through Tinder profiles, and so forth.
Even with a task like finding photos, scrolling quickly through photo thumbnails will often be an easier way to find photos than trying to describe the photo you’re looking for. Often if you’re looking for an old photo, you don’t remember exactly when it was taken or what was in the photo. It’s helpful to scroll back to roughly the right time, look at a few photos at random, and use that to jog your memory about the context of the photo. This kind of browsing will probably always be faster on an old-fashioned touch-based interface than with voice-based queries.
Disclosure: My brother works at Google.
Tucked away in a fact sheet released on the Clinton campaign website Monday is a little-noticed set of bullet points that signals something important about how Hillary Clinton would govern. The campaign outlined an aggressive plan for beefing up the nation’s antitrust laws in order to “address excessive concentration” among major industries and end the “abuse of economic power” by corporations.
The proposals are significant because they don’t require passing legislation in Congress. Simply by choosing officials devoted to more vigorous enforcement of antitrust laws, Clinton can bring about a big shift in the way the nation’s antitrust laws are enforced.
The Obama administration has already taken a stronger stance on antitrust issues than President George W. Bush did. The antitrust principles outlined in Clinton’s fact sheet suggest she could beef up antitrust enforcement even further. The big question is how ambitious she’ll be about it.
Barack Obama came into the White House vowing to be tougher than George W. Bush. Bush was widely seen as weakening antitrust enforcement compared with the vigorous policies of President Bill Clinton. The Clinton administration, in turn, was generally seen as more active in antitrust enforcement than the Reagan and first Bush administrations.
These partisan divisions were best illustrated by the Microsoft antitrust case of the 1990s. The Clinton Justice Department concluded that Microsoft had violated antitrust laws by integrating its web browser, Internet Explorer, with the Windows operating system. It launched an epic legal battle that ultimately led to a victory in court for the government in 1999 and an order to break Microsoft up in 2000.
But the case dragged on into the George W. Bush administration, which decided to settle the case quickly and on terms relatively favorable to Microsoft. Microsoft never faced a punishment anywhere near as drastic as being split in two.
Yet it’s easy to overstate the degree of difference between recent Democratic and Republican administrations. Antitrust policy is a technocratic enterprise, and antitrust technocrats in both parties largely share a common intellectual framework. Democrats have been a bit more aggressive than Republicans about blocking mergers and suing companies for anticompetitive conduct. But as a 2002 article put it, antitrust officials “seem to play the game between the 45 yard lines.”
To find the last big change in antitrust policy, you have to go back to the 1970s — a period of much greater skepticism of concentrated economic power. Back then, antitrust officials were suspicious of large companies in general, whether or not they were engaged in anticompetitive behavior. They were particularly skeptical of national chains, fearing that their concentrated power could drive mom-and-pop stores out of business.
Then economists centered at the University of Chicago launched a sustained critique of this framework. They pointed out that up to a certain point, more concentration can actually be good for consumers. A big chain like Walmart, for example, can use economies of scale and superior supply chain technology to deliver much lower prices than mom-and-pop stores.
The courts started to accept these arguments in the 1970s. And they were embraced with gusto by antitrust officials in the Reagan administration. Under Reagan, federal regulators became much more sympathetic to arguments that mergers would benefit consumers by increasing efficiency and thereby lowering prices.
Republican administrations have embraced this shift most enthusiastically, but Democratic officials were tugged along by the same intellectual currents. The Clinton administration enforced antitrust laws more vigorously than the Reagan administration had done, but they weren’t as reflexively suspicious of mergers as pre-Reagan antitrust officials had been.
The story has been similar for the Obama administration, which has been somewhat more aggressive than the George W. Bush administration but still approved controversial mergers like Comcast’s acquisition of NBC Universal. (NBC Universal is an investor in Vox.com’s parent company, Vox Media.)
So one possibility is that Clinton will follow in the footsteps of her husband and President Obama, closely scrutinizing mergers but still operating within the relatively merger-friendly intellectual framework that has guided antitrust thinking since the 1980s.
The other possibility is that she’ll push further than Obama has gone, developing new rationales for blocking mergers that go beyond Chicago School thinking. If she did choose this option, she’d have some enthusiastic allies among her fellow Democrats.
Leading the charge is Sen. Elizabeth Warren, who has been beating the drum for stricter antitrust scrutiny all year.
One big theme of Warren’s thinking is the need to think more about factors beyond prices as the main criteria in determining whether a merger or company practice is good for consumers.
Warren has trained her fire on tech giants like Google, Apple, and Amazon, arguing that these technology behemoths have acquired too much power and are at risk of squelching competition. Traditional antitrust analysis might focus on the fact that Amazon has among the lowest prices in the retail industry and Google gives away most of its products for free. But Warren argues that’s the wrong way to think about it — the larger issue is that these companies’ dominance of key technological platforms could allow them to shut out smaller firms with innovative ideas.
You can make a similar point about one of the Obama administration’s most famous antitrust decisions. In 2011, the Obama administration rejected AT&T’s bid to acquire T-Mobile, which would have left the nation with just three wireless carriers.
If that merger had been approved, it might have led to higher prices for cellular service. But it also would have deprived the world of T-Mobile CEO John Legere’s “uncarrier” strategy, in which he’s blown up widely disliked wireless provider policies like two-year contracts and early termination fees and experimented with offerings like unlimited music and video streaming.
Similarly, critics of Comcast’s proposed merger with Time Warner — which was rejected in 2015 — weren’t so much worried about higher prices, since Comcast and Time Warner didn’t compete directly, but rather that the combined firm would use its power to stifle innovation in online services and diversity in television content.
If Clinton embraces Warren’s thinking — and appoints antitrust officials who share it — it could lead to reopening questions that have been considered closed for more than 30 years.
It’s far from obvious where this new thinking would lead. Even if antitrust officials conclude that big tech companies’ size is a danger to competition, it’s not obvious how they can best rein them in. But antitrust officials do have a lot of discretion. So if they take office determined to change how we think about antitrust, it could have a big impact on the economy.
Deutsche Bank, Germany’s largest bank, is facing its biggest crisis since the global financial meltdown in 2008. A couple of weeks ago we learned that US regulators were seeking to fine the company $14 billion — not just a large sum of money but actually enough to fundamentally threaten the viability of the bank. And that was only the latest in a series of setbacks that have cost the company’s stock more than half its value over the past year:
And now Deutsche Bank is facing a multibillion-dollar fine.
Things have gotten so bad that people have started to worry about the bank’s solvency. Last week, Bloomberg reported that a few of the bank’s clients had curtailed their business with Deutsche Bank due to fears about its financial health. That led to chatter that the bank’s failure could trigger a broader 2008-style crisis.
At the same time, regulators and banks have made a lot of changes since 2008 to prevent another crisis. European officials say that thanks to these reforms, Deutsche Bank — and other major European banks — is in a better position to weather future financial problems.
But those precautions have never been fully put to the test, and for years critics have worried that they may be insufficient. If Europe experiences an economic downturn, it could threaten the financial health of the continent’s banks — with Deutsche Bank one of the most at risk. And strict new anti-bailout rules passed as part of a backlash could hamper German leaders’ ability to respond effectively to a new crisis.
The 2008 financial crisis occurred because banks (as well as insurance companies and some other financial institutions) were making big, risky bets with borrowed money. Bank shareholders didn’t have very much of their own cash on the line, so when their bets went bad, shareholders could get wiped out quickly.
And because many banks owed money to each other, the failure of one institution threatened the solvency of others. That created the danger of a domino effect that could cripple the global financial system. In the fall of 2008, US and European regulators stepped in to rescue the banks before this could happen.
Since then, regulators have taken a number of steps to prevent this from happening again. One of the most important is to require bank shareholders to put more of their own money on the line. That way, if a bank’s bets don’t pay off, the costs will be eaten by shareholders rather than the bank’s creditors or (ultimately) the government.
European and American regulators have performed a series of “stress tests” to try to predict how banks will fare in the event of another economic downturn. If banks fail these tests, they’re required to beef up their reserves.
Deutsche Bank has been one of the worst performers in these tests, and last year it was forced to suspend dividend payouts to shareholders to allow it to build up its cash reserves.
At the same time, regulators have punished banks for their role in the 2008 crisis. The Obama administration has sought a series of stiff fines against banks that allegedly sold bundles of low-quality mortgages without fully informing customers of the associated risk. Deutsche Bank faces one of the biggest fines — $14 billion. But the bank is widely expected to negotiate a settlement that will require it to pay a fraction of that amount —  as little as $5.4 billion, according to one report.
To a large extent, these two regulatory efforts work at cross purposes. On the one hand, regulators are pushing banks to build up a bigger financial cushion to help them weather future economic downturns. But levying multibillion-dollar fines erodes that cushion, making banks more likely to become insolvent if they hit an economic rough patch.
It’s inevitable that a big, struggling bank will invite comparisons to 2008. And there are some obvious parallels. But the two situations also differ in some important ways.
In a financial crisis, it’s important for banks to have liquidity — cash or assets like government bonds that they can easily sell to raise cash. The Wall Street Journal’s James Mackintosh notes that Deutsche Bank’s liquid assets are about 12 percent of its total assets. For comparison, Lehman’s liquidity was just 7.5 percent of total assets a month before it collapsed.
The 2008 crisis occurred because Lehman Brothers, AIG, and other financial institutions had loaded up with “toxic assets” — complex financial instruments assembled using a lot of low-quality mortgages. Deutsche has about €37 billion of assets on its balance sheet that are not easy to price, which has created concerns that it’s in a similar situation.
Is it? It’s hard to say. As the Financial Times puts it: “The equity stakes and loans could be to thriving companies or businesses in deep trouble. The debt could be ‘distressed’ or in the form of high-grade private placements that are only illiquid because they were sold to family offices and institutions that tend to hold investments to maturity.”
Nobody outside Deutsche Bank knows for sure, which is one reason the bank’s stock price has been battered in recent months. Some traders are assuming the worst. At the same time, these assets represent a small fraction of the bank’s overall €1.8 trillion balance sheet. And the fact that some of these assets could be bad doesn’t mean they are bad.
The 2008 financial crisis happened after US officials refused to organize a bailout of Lehman Brothers, starting a chain reaction that brought down other companies that had been heavily exposed to the mortgage market. Ever since then, policymakers in both the US and Europe have been trying to change the rules to make another bailout unlikely.
In an acute crisis, Deutsche Bank and others could count on getting short-term loans from the European Central Bank. But if a bank winds up insolvent, European rules prohibit national governments from providing a no-strings-attached bailout. Instead, the rules require governments to first “bail in” a failing bank’s creditors — forcing them to accept that they’ll be repaid less than 100 cents on the euro.
This approach seems reasonable in principle, but it can lead to practical problems. In Italy, for example, banks’ creditors are not always large, sophisticated financial institutions. According to Bloomberg, 45 percent of Italian bank debt is held by ordinary Italians. That means complying with the EU rules could mean some Italians lose a big chunk of their life savings.
Italian Prime Minister Matteo Renzi got a taste of the potential backlash back in December, when the Italian government rescued four banks in accordance with EU rules. Creditors took losses in the process, and one of them was an Italian man who lost $110,000 he had invested in bonds issued by one of the failing banks. The man killed himself, leaving a suicide note criticizing his bank.
Earlier this year, Renzi was lobbying other European leaders for permission to inject taxpayer money into Italian banks to prevent a repeat of this fiasco. But German Chancellor Angela Merkel said no, insisting on strict adherence to the eurozone’s no-bailout rules. And she’s been consistent at home, with a German magazine reporting that Merkel has privately vowed not to use German taxpayer money to rescue Deutsche Bank.
That position is good politics, as bank bailouts are unpopular among German voters. But if Deutsche Bank were to actually fail, Merkel’s resolve would be tested. The losses from a Deutsche Bank failure could be felt widely across the German economy. And there’s always a risk that the failure of one big German bank could be the first domino that leads to a larger financial crisis.
“The internet is still at the beginning of its beginning,” writes Wired co-founder and Silicon Valley guru Kevin Kelly in his new book The Inevitable. Kelly argues that adding machine intelligence to everyday objects — a process he calls “cognifying” — “would be hundreds of times more disruptive to our lives than the transformations gained by industrialization.”
Is he right?
Kelly’s extreme optimism represents one pole of this debate. At the opposite pole is economist Robert Gordon, who believes the IT revolution is basically over. In his new book The Rise and Fall of American Growth, Gordon documents the dramatic economic changes of the 20th century — electricity, cars, indoor plumbing, antibiotics — and predicts that nothing of that scale is on the horizon.
“The economic revolution of 1870 to 1970 was unique in human history, unrepeatable because so many of its achievements could happen only once,” Gordon writes. He acknowledges that since 1970 there have been big improvements in televisions, smartphones, and other information technologies. But he argues that many other aspects of the economy — food, clothing, transportation, health care, and so forth — have changed little since the 1970s and are unlikely to change much in the next couple of decades.
Kelly and Gordon don’t just have opposite predictions about the future — they represent opposite approaches to thinking about an uncertain future. Gordon has difficulty imagining how computers could continue to transform our lives, so he assumes they won’t. Kelly’s life has been so transformed by computers that he can’t imagine how anyone doesn’t see their continued potential.
Reality, of course, is likely to be somewhere between these extreme views. It’s hard to believe that the IT revolution will be “hundreds of times more disruptive” than the Industrial Revolution — or even to figure out what that would mean. At the same time, Gordon is too cavalier about dismissing technologies like self-driving cars that really do seem poised to have a big social and economic impact.
But ultimately, I think Gordon gets closer to the mark than Kelly does. Kelly has spent his career in Silicon Valley, the place that has reaped the biggest gains from the exponential improvements in computing power. So it’s natural to assume that any problem can be solved — and any industry can be disrupted, or at least wildly improved — if we just bring enough computing power to bear.
He even has a sort of rallying cry for his perspective. “Who knows? But it will come!” The line is tucked into a chapter where Kelly tries to imagine different goods and services after they’ve been “cognified” by computers. “Cognified knitting” is one of the possibilities he imagines. What does that mean? “Who knows?” Kelly writes. “But it will come!”
Indeed, “Who knows? But it will come!” has become the de facto rallying cry for a lot of recent Silicon Valley innovations with more hype than obvious applications, and it emerges out of a foundational experience: watching the internet be underestimated after it emerged, and then mocked after the tech bubble popped, only to change the world directly thereafter.
But it-will-come-ism has fallen flat in recent years, and I think it’s going to continue failing in the years to come. There are a number of industries — with health care and education being the most important — where there’s an inherent limit on how much value information technology can add. Because in these industries, the main thing you’re buying is relationships to other human beings, and those can’t be automated.
It’s not surprising that Silicon Valley — a place that grew rich and powerful by building the internet economy — is full of technology optimists. Silicon Valley elites aren’t just used to changing the world with software. They’re used to being underestimated as they do it.
When I interviewed venture capitalist Marc Andreessen a couple of years ago, for example, he told me about his experience as a young startup founder in the early 1990s trying to convince big companies to take the internet seriously. Established CEOs laughed at him when he argued that the internet could disrupt industries like music, retail, media, and telecommunications.
Obviously, no one is laughing now.
Many tech elites believe history is about to repeat itself, only on a much larger scale. Andreessen made the case in a 2011 article called “Why software is eating the world.”
Until that point, the internet had mostly disrupted businesses that dealt in information. Now, Andreessen argued, the tech sector was coming for the rest of the economy.
In 2011, it seemed like the signs of this second digital revolution were sprouting up all over. Airbnb was widely seen as a pioneer of a new “sharing economy,” with Uber and Lyft announcing ride-hailing services in 2012. 3D printing seemed poised to render conventional manufacturing obsolete. The “internet of things” promised to embed cheap, tiny wifi-connected computers in everyday objects.
Startups like Khan Academy and Udacity were promising to revolutionize the education market with online classes. Bitcoin seemed to offer a new digital foundation for the financial sector. An IBM supercomputer called Watson beat the world’s best Jeopardy players, and IBM vowed to apply the technology to medical diagnosis.
It all seemed like it could be a really big deal. The industries the internet has disrupted so far — music, news, mapmaking — add up to a relatively small fraction of the overall economy. If digital technology can disrupt sectors like health care, education, manufacturing, finance, and government, the economic benefits could be massive.
Kevin Kelly thinks this future is right around the corner. “70 percent of today’s occupations will be replaced by automation,” he writes. “Most of the important technologies that will dominate life 30 years from now have not yet been invented.”
Until recently, I was very sympathetic to this point of view. But recently I’ve become more skeptical. One thing that started to change my mind was reporting on (and then buying a house using) the real estate startup Redfin.
In its early years, Redfin seemed like exactly the kind of disruptive startup Andreessen and Kelly expected to transform the conventional economy. In a 2007 interview on 60 Minutes, Redfin CEO Glenn Kelman described real estate as “by far the most screwed-up industry in America” and vowed to do for it what Amazon had done for bookselling and eBay had done for the sale of collectibles.
Back then, Redfin was charging homebuyers about a third of what a conventional real estate agent would charge for buying a house. To turn a profit, Redfin had to offer customers much less access to human real estate agents.
But customers hated this early, bare-bones product. For most of them, a personal relationship with a human agent was the main attraction of hiring a real estate firm. Facing the biggest purchasing decision of their lives, customers wanted someone available to answer questions and walk them through the steps of the home-buying process.
So over the past decade, Redfin has hired more agents and dramatically raised its fees. Today, the company looks more like a conventional real estate agency — albeit an unusually tech-savvy one — than the scrappy, disruptive startup Kelman led a decade ago. The real estate business wasn’t as ripe for disruption as Kelman thought.
Even if Kelman’s original vision had been more successful, Redfin would still have represented only an incremental improvement over conventional real estate services. It would have been cheaper and perhaps a bit more convenient, but it wouldn’t have fundamentally changed the process of buying a home.
And the same is true of a lot of recent startups that have aimed to disrupt conventional industries. Food delivery startups make it more convenient to order takeout. Uber and Lyft streamline the process of calling a cab. Zenefits provides a cheaper way for small businesses to manage payroll. Even Amazon mostly provides a cheaper and more convenient alternative to driving to the mall.
These are all perfectly good business ideas. The internet is creating lots of opportunities to squeeze inefficiencies out of the system. But Gordon’s book reminds us that this isn’t what a real technological revolution looks like.
The world inhabited by a typical American family in 1900 looked radically different from today’s world. Automobiles were expensive toys for the wealthy. Traveling from New York to Los Angeles required a train and took several days.
Washing machines, refrigerators, dishwashers, and vacuum cleaners were still in the future, making housework a back-breaking full-time job. Electric lighting was out of reach for most families, so they had to rely on dim and dangerous candles or kerosene lamps — and most simply didn’t try to do very much after dark.
Most homes lacked running water and flush toilets, leading to recurrent sanitation problems. And with no antibiotics and few vaccines, it was common for families to lose young children to infectious diseases.
By 1960, in contrast, a typical American family enjoyed a lifestyle that would be familiar to us today. Running water, flush toilets, electric lighting, cars, refrigerators, and washing machines were all commonplace. Deaths from infectious diseases like influenza, pneumonia, and polio were plunging. Ubiquitous cars and newly developed freeways meant that you could drive across town about as quickly as you can today (maybe faster at rush hour), and newly invented passenger jets could fly from New York to Los Angeles in five hours.
The rapid progress of the early 20th century depended on two factors. One was a series of technical breakthroughs in science, engineering, and medicine. But the other was the fact that in 1900, the human race had a bunch of big problems — dimly lit homes, slow transportation options, deadly diseases, a lot of tedious housework — that could be solved with new technologies.
The situation today is different. America hasn’t completely conquered material wants, of course. There are still tens of millions of people — far too many — who struggle to afford the basics.
But unlike in the early 20th century, these Americans represent a minority of the population. Among the affluent majority, food is cheap and easy to buy, closet space is scarcer than clothes, refrigerators and washing machines are ubiquitous, and there are often as many cars in the driveway as adults in the house.
Instead, these more affluent Americans have a different set of worries. Can I get a house in a good school district? Can I afford to pay for child care? Can I afford health insurance coverage? Will I be able to send my kids to college?
Indeed, the trend can be seen graphically in this chart:
The chart shows how various goods and services have changed in price relative to the overall price level. Over the past four decades, manufactured products like clothing, toys, cars, and furniture have gotten more affordable. At the same time, services like education and medical care have gotten a lot more expensive.
These trends are connected. Technological progress (and increased trade with low-income countries like China) has pushed down the cost of manufactured goods. But families don’t need an infinite number of televisions, cars, or clothes. So they’ve taken the savings and plowed them into other sectors of the economy — sectors where technology can’t easily boost output. With demand often outstripping supply, the result has been rising tuition, rising housing costs in trendy neighborhoods, rising child care costs, and so forth.
At this point, you might object that this just shows the need for disruptive innovation in education and child care. After all, aren’t startups like Udacity and Khan Academy working to create online learning alternatives?
But disrupting the education industry will be hard for the same kind of reasons it was hard for Redfin to disrupt the real estate business. Udacity aims to streamline education by reducing the number of hours staffers spend grading papers, answering student questions, and so forth. But from the student’s perspective, time talking to professors, TAs, and administrators isn’t wasted — it’s an important part of the educational experience.
Much of the value people get from attending a four-year college comes from interaction with other people. People spend their college years forming a circle of friends and a network of acquaintances that often become invaluable later in their careers. They gain value from group study and extracurricular activities. There is real benefit from mentorship by professors.
The social experience of college also serves as a powerful motivator. An early, free, Udacity course, for example, had a dismal 4 percent completion rate. It’s hard to motivate yourself to study hard when you’re only interacting with a computer program. The process of having human instructors regularly checking assignments — and students comparing grades with their peers — is core to students’ success, especially for less disciplined kids. So parents who can afford to send their children to a conventional college are unlikely to choose a cut-rate online university instead.
The same point applies to health care. Even if AI gets better at diagnosing diseases, people are still going to want a human doctor around to answer questions about the diagnosis and possible treatment options, to make sure the patient’s overall treatment process stays on track, and provide a comforting bedside manner. And they’re going to want a human nurse — not a robot — to tend to their needs during their hospital stay.
None of this is to say that technology can’t add value to industries like education and health care. Technology is likely to serve as a complement to these conventional services. Software will continue to help doctors get better at their jobs by providing better software for scheduling, diagnostics, and so forth. And technology may also provide affordable alternatives for people who don’t have access to a traditional university or hospital.
But it’s unlikely that today’s schools and hospitals are headed for the fate of Borders or Kodak.
So as long as technologists are merely finding ways to make it modestly cheaper or more convenient to do things people have been doing for decades, their impact on the overall economy will be necessarily modest. To have a bigger impact, they need to invent broad new product categories — which necessarily means finding big, unmet needs that can be addressed by new inventions.
Self-driving cars could be one example. Robert Gordon is dismissive of this emerging technology, and I think that’s a mistake. Autonomous vehicles will not only make people’s morning commutes more convenient, but they also have the potential to revolutionize the retail sector, change how people plan cities, and more.
Also, of course, in recent years we’ve seen a steady progression of entertainment and communications gadgets: DVD players, video game consoles, smartphones, and now VR headsets.
But outside the worlds of entertainment and communication, it’s hard to think of major new products in the recent past or likely in the near future. And Kelly doesn’t offer any plausible examples of big breakthroughs that could be on the horizon.
The one chapter of his book that focuses on this question is called “Cognifying.” It argues that embedding computer chips into everyday objects could dramatically change our lives. Yet his examples are not impressive:
We’ve see the same faith in the transformational potential of computing power at work in discussions of other recent innovations that have generated a lot of buzz in the media but haven’t been big hits with consumers. For example, there’s been a lot of discussion about the “internet of things” — an effort to embed computer chips in everything from thermostats to light bulbs. These products have been on the market for about five years, yet it’s hard to think of any cases where the addition of computer chips and software has added a lot of value.
You can say the same about home 3D printing. 3D printers have carved out an important but still niche application for prototyping in industrial labs and universities. But early predictions that 3D printers would become standard equipment in people’s homes have not been borne out.
Similarly, when Bitcoin burst into the mainstream in 2013, there was a lot of speculation (including from me) that it could disrupt the financial sector. But three years (and more than $1 billion in venture capital investments) later, we seem to be no closer to finding practical applications for the technology.
Of course, it would be a mistake to say that because these technologies haven’t produced much value yet, they won’t do so in the future. As technologists are quick to point out, people underestimated revolutionary technologies like PCs and the internet in their early years too.
But the fact that so many of these efforts seem to be falling short of expectations makes me skeptical of the view that computing power will inevitably transform every sector of the economy. Computers have proven that they’re great at transforming industries — music, news, maps, phone calls, and so forth — that are fundamentally about collecting, processing, and distributing information.
But software companies are now entering industries — from health care and education to lightbulbs and thermostats — that are primarily about managing physical objects or human relationships rather than information. That’s a bigger challenge, and in many of these industries I think technology companies will discover there just isn’t much room for them to add value.
The American economy in 2016 is full of contradictions.
On the one hand, we’re in an era of rapid technological progress. The internet has disrupted industries from retail to music. Emerging technologies like self-driving cars and virtual reality promise to take the trend a step further, creating whole new industries while rendering many conventional jobs obsolete.
At the same time, the current recovery has delivered the weakest GDP growth in many decades. Incomes and worker productivity have grown slowly. Despite record-low interest rates, business investment has been weak ever since the recession ended.
So what’s really going on? It’s a question that’s far too big to answer in a single article. In fact, we think it’s big and important enough to be worth its own section at Vox.
We think it’s impossible to really understand the changing economy without a deep understanding of technology. The internet and smartphone have already upended a number of conventional industries. Advocates say a wave of new technologies — Bitcoin, self-driving cars, the “internet of things,” and so forth — are poised to be even more disruptive. We’ll take a careful look at these emerging technologies, explaining how these technologies work and exploring what they can — and can’t — do.
And this works in reverse too: The technology sector is strongly affected by larger economic forces. Record-low interest rates have helped fuel Silicon Valley’s investment boom. Crippling housing shortages in the San Francisco Bay Area have limited the growth of technology startups. Decisions made by government regulators will have a big impact on emerging technologies like drones and cryptocurrencies. And broader economic statistics often serve as a much-needed reality check on the relentless hyping of new technologies.
So New Money will explain economics for people who love technology. And we’ll explain technology for people who are fascinated by economics.
Of course, we’ll also track and explain day-to-day business stories that have a bearing on these larger questions. This week, for example, I’ll have my eye on the problems at Deutsche Bank and Wells Fargo and rumors of an impending sale of Twitter.
We’ll cover Apple product introductions, Federal Reserve meetings, and everything in between. But our goal won’t be to break news or provide comprehensive coverage of these topics. Rather, the goal will be to help readers connect the dots between today’s business news and broader technology and economic trends.
These are topics I’ve enjoyed writing about for a number of years, and I’m excited to focus on them full time. I hope you enjoy reading about them!
You can read the first New Money article here. Future articles will appear on the New Money front page.
Correction: This article originally reported that urban households had seen their median incomes rise in 2015, while incomes in rural areas fell. But that appears to have reflected a statistical anomaly in the Current Population Survey. More reliable data released later in the week by the American Community Survey — another program of the Census Bureau — found that median household income in rural areas gained 3.4 percent, while urban and suburban households gained 3.6 percent. The text below has been corrected.
Earlier this week, the Census Bureau released data on income and poverty has good news for almost everyone. The data, the result of the Census Bureau's Current Population Survey, shows the first significant growth in average household incomes in almost a decade — 5.4 percent between 2014 and 2015 — with all races, age groups, and regions of the country enjoying gains.
But it appeared to show a big gap between the gains of urban and rural households. It reported that households outside of metropolitan areas (which I'll slightly imprecisely call rural) saw their incomes drop by 2 percent, while suburban households gained 4 percent and urban households gained 7.3 percent.
It seemed like a big deal, so I wrote an article about it.
Unfortunately for me — but fortunately for people in rural areas — it wasn't true.
What actually happened is that the Census Bureau changed how it defined rural households (technically, households outside of a metropolitan area) between 2014 and 2015. As a result, the 2014 statistics were measuring the incomes of different households than the 2015 statistics. Unsurprisingly, that resulted in a big apparent change. But this didn't reflect changes in anyone's income, it was just a statistical anomaly.
Later in the week, the Census Bureau also released statistics from a separate survey called the American Community Survey. This survey was larger and didn't make a big change in the way it defined urban and rural households, making it more reliable for this purpose. And it found there was hardly any difference between rural and non-rural households. Rural households saw their incomes gain by 3.4 percent, while non-rural households gained 3.6 percent.
I was inclined to believe the original Census numbers because they were consistent with a trend I’ve reported on before: The current recovery is seeing big cities reap the largest economic gains. That was a big change from the economic boom of the 1990s, which saw less populous areas gaining more.
In the past, smaller counties tended to grow faster than larger counties. This made a certain amount of sense — large counties like Los Angeles or Dallas were already expensive and crowded places to live, so it was easier for economic growth to happen in smaller towns or outlying suburbs.
But in the latest recovery, the pattern has reversed. The largest counties saw the fastest growth in jobs, with Los Angeles County, Miami-Dade County, and Kings County (Brooklyn) leading the way. Meanwhile, the least populous counties have been suffering the weakest recovery in decades.
But while major urban areas are seeing larger job gains, that's apparently not translating into big differences in household incomes.
Monsanto. It’s hard to even say the name without triggering a fierce reaction. The company has long been the public face of GMOs, thanks in part to the sheer dominance of its corn, soy, cotton, and other crops engineered to be resistant to the herbicide Roundup.
And pretty soon, Monsanto may no longer exist. At least not in its current form.
On Wednesday, the German chemical conglomerate Bayer offered to buy up Monsanto for $56 billion, in what could prove to be the largest corporate merger of the year. Monsanto has accepted the bid. And if the deal is approved by regulators — which is still an open question — the new company would become the largest agribusiness on the planet, selling 29 percent of the world’s seeds and 24 percent of its pesticides.
That would put the new firm in a commanding position vis-à-vis our food supply. Which is why European Union regulators and the US Department of Justice are likely to scrutinize this deal more closely than usual, to make sure it doesn’t create an all-consuming monopoly that can crank up prices on farmers and shoppers. The deal comes amid a blurry rush of agribusiness consolidation in recent months, with ChemChina-Syngenta and DuPont-Dow Chemical forming their own multibillion-dollar Voltrons.
Some onlookers are fretting that the reduced competition could shrivel up innovation, leading to slower improvements in crop yields. Others worry that these new agricultural giants may have outsize political power. "They’ll have more ability to lobby governments," says Phil Howard of Michigan State University, who studies consolidation in the food industry. "They’ll have a lot more power to shape policies that benefit themselves at the expense of consumers and farmers."
It’s a big story, and not just because Monsanto is such a famous (or infamous, if you prefer) brand. The consolidation of the world’s seed, chemical, and fertilizer industries over the past two decades has been astonishing, with potentially large ripple effects for farms and food systems all over the globe.
Back in 1994, the world’s four biggest seed companies controlled just 21 percent of the market. But in the years since, as crop biotechology advanced, companies like Monsanto, Syngenta, Dow, Bayer, and Dupont went on a feeding frenzy, buying up smaller companies and their patents. Today, the top four seed companies and top four agrochemical firms command more than half their respective markets.
And the pressures to merge have only become even more intense. Due to an economic slowdown in China and a glut of food production over the past few years, the global agricultural economy has been slumping. Commodity prices have fallen sharply, and farmers have less to spend on supplies (as well as on pricier biotech seeds). And the major seed, chemical, and fertilizer companies haven’t been able to churn out enough innovative new products to counteract this trend.
So their only choice at this point is to consolidate further, hoping to convince shareholders that they can slash costs and keep profits high.
Monsanto, the world’s largest seed producer, has found itself in a surprisingly precarious position. For years, the company reaped huge profits from selling its popular weedkiller, glyphosate (known as "Roundup") in tandem with crops genetically engineered to withstand glyphosate (known as "Roundup Ready" crops). But thanks in part to improper use, more and more weeds in the United States are developing resistance to glyphosate — and Monsanto is racing to find a replacement. The company is currently investing $1 billion to develop crops resistant to dicamba, another herbicide, but a merger would help it maintain market share in the meantime.
Last year, Monsanto put in a failed bid to buy up Syngenta, the world’s largest agrochemical producer. After the deal fell through, Syngenta CEO Mike Mack said the bid showed that Monsanto’s "core markets have been saturated" and that the company lacked "fundamentally new innovation" to drive growth. You might say the same about the Bayer-Monsanto merger.
Monsanto’s not alone here. Last year, Dow Chemical and Dupont agreed to combine their crop science divisions, and are waiting on US and EU regulators for approval. This year, the China National Chemical Corporation got the okay from US regulators to buy the Swiss seed company Syngenta in a $43 billion deal. Last week, in Canada, Potash Corporation of Saskatchewan and Agrium joined forces to create a fertilizer giant amid slumping fertilizer prices.
If all these mergers go through, Tom Philpott of Mother Jones points out, the three biggest companies that will emerge (Bayer-Monsanto, ChemChina-Syngenta, and DowDupont) will sell 59 percent of the world’s patented seeds and 64 percent of all pesticides. The behemoths are getting behemoth-ier.
There are a couple of reasons to be concerned about an agricultural landscape dominated by just a handful of giant companies. If firms can corner key markets in seeds and chemicals, they might be able to raise prices of their products on farmers, which in turn could make food more expensive. For this reason, groups like the National Farmers Union have been opposing many of these deals.
The other fear is that if these behemoths face less competition, they may face less pressure to pursue the sorts of innovations needed to improve crop yields and help feed a rapidly growing world. Some worry that these newly merged companies would end up focusing more on their most profitable crops rather than branch into smaller and underserved markets such as Africa.
"As these industries have consolidated, they’ve spent less on research, and what research they do has been steered toward big blockbuster profits with commodity crops such as corn or soy," Howard says. That means they’ve been spending less on smaller crops and even focusing less on smaller markets like the Southeast US.
Last year, when Monsanto was trying to buy up Syngenta, the company argued these fears were unfounded. Among other things, the company contended that innovation might actually be quicker, not slower, if research labs were consolidated.
The big question now is whether regulators will buy these arguments. The US Justice Department’s antitrust division will have to decide whether to approve the Bayer-Monsanto deal, block it, or add conditions before it can go through.
For their part, Bayer and Monsanto are arguing that the two companies have little overlap: Monsanto focuses on seeds and biology, Bayer on chemicals. But, for instance, Jack Kaskey of Bloomberg points out that the newly merged Bayer-Monsanto company would control about 70 percent of cottonseed sales in the United States — so that may be one possible area of focus (and perhaps the new firm will have to divest its cottonseed assets).
In years past, this deal might have been a foregone conclusion, as US regulators regularly waved through similar deals with few changes. But more recently, DOJ has become much more active in scrutinizing agribusiness mergers. As Philpott points out, just two weeks ago, the DOJ halted a deal in which Monsanto would’ve sold its precision planting division to John Deere — because the latter would have had 86 percent of the market in these technologies. Not an auspicious sign for Bayer.
On the other side of the Atlantic, EU regulators tend to be extremely critical of GM crops, so they may put up even more of a fight. "There is a risk of a lot of regulatory and political scrutiny. We put chance of approval at 50 percent," Jeremy Redenius, an analyst at Bernstein bank, told the Financial Times.
Another question is whether Bayer would keep the Monsanto name if the deal goes through.
After all, the name "Monsanto" carries a lot of baggage, much of it negative. When people express fears about corporate control of food or biotechnology, they invariably point to Monsanto. It’s widely viewed as the company that patents seeds and ruthlessly sues farmers who try to misuse them (even if the reality is considerably less sinister than the perception).
People in the company — and many crop scientists outside of it — have long seen that reputation as unfair. To them, the anti-GMO movement has spread a lot of baseless information about genetic engineering and has caricatured onto Monsanto as the face of evil. The company has tried a series of rebranding moves over the years to burnish its reputation. (Witness this Wired story: "Monsanto Is Going Organic in the Quest for the Perfect Veggie.")
Alas, none of it has flown. A telling anecdote in the New Yorker: In 2013, David Friedberg sold his innovative weather data company, the Climate Corporation, to Monsanto for $1 billion. His own father’s first reaction was: "Monsanto? The most evil company in the world? I thought you were trying to make the world a BETTER place?"
Given all that, Bayer may consider going all in and changing the name entirely. "It is too early to speculate about what the name of the company is going to be," Bayer CEO Werner Baumann said in an interview in May. "But let me tell you that Bayer’s name and Bayer’s reputation stand for science, innovation and an utmost level of responsibility for societal needs, and that is what we are going to leverage on, also for the combined company going forward."
— The Wall Street Journal offers more context around flagging biotech seed sales: "Behind the Monsanto Deal, Doubts About the GMO Revolution."
—This is an excellent timeline of Monsanto's history. And a few years ago in Modern Farmer, Lessley Anderson wrote a great piece on how Monsanto became so reviled in certain corners.
Nintendo dropped huge news on Wednesday: It will develop and release a Mario game, called Super Mario Run, for the iPhone by December and other mobile devices later on.
For Nintendo and gamers around the world, this is very big. Since it got into video games in the 1970s, Nintendo has largely restricted its big franchises, and particularly the games in those franchises that it directly develops, to its own hardware — the original Nintendo, Super Nintendo, Nintendo 64, Game Boy, Nintendo DS, and so on. With its announcement, the company is showing a serious commitment to the mobile phone market — and doing so with Apple as a major ally.
But Nintendo didn’t decide to stroll out Shigeru Miyamoto, the legendary creator of games like Super Mario Bros. and The Legend of Zelda, to the stage of Apple’s iPhone 7 event on Wednesday on a whim. This news has been long in the making — not solely the specifics of working with Apple, but Nintendo’s embrace of the mobile market in general.
Although Nintendo is one of the most recognized — and best — game developers, its hardware business is seriously struggling. The Wii U, the successor to the very popular Wii, is an absolute flop. And the Nintendo 3DS, the handheld successor to the also very popular DS, isn’t doing too much better, with 3DS sales consistently lagging the DS.
So Nintendo is looking to shore up in alternative markets — like the iPhone. And it’s not just with Mario — Nintendo in April also announced mobile games for two of its smaller franchises, Fire Emblem and Animal Crossing. This is a significant move for the company — and it tells us a lot about where much of the gaming industry is headed.
The numbers tell the story. Since it launched in 2012, the Wii U had, as of earlier this year, sold below 11 million units. In comparison, the Wii had sold nearly 10 times that since it launched in 2006, and the GameCube sold twice that amount since its release in 2001 (mostly through 2006, when the Wii replaced it).
The 3DS is doing much better, with more than 54 million units sold. That’s a promising number, but far below expectations. Every once in a while, analyst VGChartz looks at how the DS, the 3DS’s predecessor, was doing at the same point in its lifespan as the 3DS. The results are brutal for the newer console:
It’s no surprise, then, that Nintendo’s stocks remain down about 60 percent since the peak of the Wii and DS in late 2007.
This isn’t because the console market is dead. As Eurogamer reported, the Xbox One and PlayStation 4 have so far outsold their predecessors. Nintendo’s struggles are unique — driven by what the company now admits was poor marketing for the Wii U, and at least some hemorrhaging in the 3DS handheld market to the growing mobile gaming market. (The latter reportedly led former Nintendo President Satoru Iwata to call Apple the “enemy of the future.”)
One clear example of the poor marketing is in the name: For the casual consumer, how is the difference between a Wii and a Wii U or a DS and a 3DS entirely clear just based on the name? It’s clear, based on the name alone, that the PlayStation 4 is an upgrade to the PlayStation 3, but not so much for the Wii U or 3DS. Worse, the Wii U and 3DS look very similar to their predecessors, suggesting that they may just be an optional addition to the existing consoles — for example, maybe the Wii U’s tablet is just a new controller for the Wii and the 3DS is just a DS with a 3D add-on.
Now, Nintendo plans to release a new console sometime next year — codenamed the NX. So Nintendo isn’t looking at these numbers and abandoning its hardware business altogether. Instead, it is seemingly trying to hedge its bets.
The mobile market is a natural place for that: As Nintendo’s hardware business lags, the mobile gaming market is booming.
As hardware on mobile devices has become more capable of running more advanced games (not that there’s anything wrong with Snake or Tetris, but come on), developers have begun to take mobile gaming more seriously. And so have consumers: According to Statista, the number of mobile phone gamers in the US doubled to more than 164 million from 2011 to 2015 — and appears set to reach more than 210 million in 2020.
To put that in context, mobile phones hold a bigger platform of gamers than any one Nintendo console — even the massively successful Wii and DS — ever had. Based on the sales numbers for Nintendo hardware above, US mobile gamers make up nearly three times the population of gamers on the current Nintendo consoles, the Wii U and 3DS.
This holds up even when looking at other game developers: The most successful game console of all time — the PlayStation 2 — has sold just shy of 54 million units in the US since 2000, according to VGChartz. That’s still less than a third of the number of total US mobile gamers.
Mobile users aren’t necessarily as profitable per person as console gamers — mobile games tend to cost a few bucks or nothing at all, while console games are typically between $40 to $60. But mobile offers a huge user base nonetheless — and big game developers, from Nintendo to Square Enix (creators of the Final Fantasy series), are taking note of that.
The mobile games market is also particularly big in Japan, where Nintendo is based. Although the Japanese market is smaller in size, users are apparently more willing to spend cash: According to Statista, the average user in Japan is willing to spend nearly twice as much as the average US consumer on mobile games each year — $64 in 2016 in Japan versus about $33 in the US. This is why market analyst SuperData concluded that “Japan is the world’s largest mobile games market” despite its smaller user base.
For Nintendo, getting into these markets is potentially a very profitable venture — and not just because of software sales within that market.
One lesson from the smash hit of this summer’s Pokémon Go is that the success of a popular Nintendo franchise in the mobile market doesn’t have to be exclusive to the mobile space.
After the release of Pokémon Go, Nintendo’s stocks skyrocketed — more than doubling over the course of July. The company later clarified that it did not expect to make too much money from Pokémon Go, as a bulk of the profits will go to Niantic, the creator of the game, and Alphabet (formerly Google), which invested in the product.
But Nintendo’s stock was still 73 percent higher in early September compared to June — meaning it still benefited overall.
Similarly, after Pokémon Go, other Nintendo products massively benefited. The latest Pokémon games for the 3DS, Omega Ruby and Alpha Sapphire, sold 80 percent more this July than they did in July 2015. Nintendo 3DS hardware, meanwhile, had its best-selling month ever in July. Nintendo attributed some of these increases to the release of the popular game Monster Hunter Generations and a price drop for one of its handhelds, but it also said the buzz around Pokémon Go significantly helped.
I can personally vouch for this: After not getting into a Pokémon game for a few years, I bought Omega Ruby in August after getting caught up in the hype surrounding Pokémon Go. (It was well worth the purchase: It’s a good game, as Polygon’s review notes.)
Other successes in the mobile market could play out similarly. Do you like Super Mario Run on the iPhone? Maybe you’ll be more interested in checking out the new, bigger Mario game for the Nintendo NX. Maybe you’ll even buy the Nintendo NX to check it out.
This is the gamble Nintendo is playing here: Not only could the mobile market provide a new source of revenue for a somewhat struggling company, but it could shore up its more traditional businesses too.
Correction: A reference to the Xbox One in this article initially called it the Xbox 360.
Lara Croft is one of the most recognizable female characters in video gaming, having starred in a dozen editions of Tomb Raider since the series debuted in 1996. And that makes her a perfect window into the rapid pace of progress in 3D graphics over the last two decades:

(HalloweenCostumes.com)
At the left is the Lara Croft character as she appeared in the original 1996 game. On the right is Croft as she appeared in 2014's Tomb Raider: The Definitive Edition.
The increasing realism is a reflection of Moore's law, which holds that the amount of computing power per chip doubles every couple of years. Video games represent 3D scenes as a sequence of polygons; the more computing power you have, the more polygons you can render. The original Lara Croft was rendered with a few hundred polygons. The latest models use tens of thousands, producing images that look almost indistinguishable from the real thing.
See more images of Lara Croft's evolution here.

When Uber announced Thursday that it would begin offering rides in self-driving cars to customers in Pittsburgh, it caused a lot of consternation among people worried about job losses. After all, sharing economy companies like Uber are supposed to represent one of the economy’s big sources of job growth. If even Uber is automating its fleet, doesn’t that mean workers are doomed?
But in an interview with Business Insider, Uber CEO Travis Kalanick argues that Uber drivers shouldn’t worry. He expects to continue offering work to drivers for a long time:
If you're talking about a city like San Francisco or the Bay Area generally, we have, like, 30,000 active drivers. We are going to go from 30,000 to, let's say, hypothetically, a million cars, right? But when you go to a million cars, you're still going to need a human-driven parallel, or hybrid. And the reason why is because there are just places that autonomous cars are just not going to be able to go or conditions they're not going to be able to handle. And even though it is going to be a smaller percentage of the whole, I can imagine 50,000 to 100,000 drivers, human drivers, alongside a million-car network. So I don't think the number of human drivers will go down anytime soon.
Obviously, Kalanick has an interest in putting a positive spin on this since he depends on Uber drivers to make the service operate today. But his argument isn’t crazy. Similar things have happened in other industries.
For example, when automated teller machines were developed, many people thought ATMs would put most bank tellers out of work. But that didn’t happen. ATMs made it cheaper to open a bank branch, allowing banks to open many more branches in the 1990s. As a result, teller employment has actually grown slightly over the last 40 years, as this chart from economist James Bessen shows:
The same logic could apply to the car market. If self-driving cars make taxi rides a lot cheaper, people will take a lot more taxi rides. And that could create more jobs even if the number of jobs per ride goes down. In the long run, there won’t be someone sitting in the driver’s seat, but there will be lots of other jobs supporting cars — things like maintaining, repairing, and cleaning the vehicles, handling customer service calls, keeping maps updated, and so forth.
Some jobs will be destroyed; others will be created. The net impact on the job market isn’t obvious.
Correction: I originally said that the number of bank tellers had declined after 2008, but better data shows employment rising.
Gawker.com, a gossip blog that spawned a multimillion-dollar media empire, is shutting down next week. The decision comes just two days after Univision won an auction to acquire Gawker Media, the parent company of Gawker.com as well as websites like Gizmodo and Lifehacker.
It might seem surprising for Univision to spend $130 million for the company and then immediately shutter its flagship brand. But the business logic behind the decision seems pretty clear: Gawker.com’s brand had become so toxic that continuing to operate the site could have posed significant financial risks.
Shuttering Gawker.com will allow Univision to get a fresh start. Other Gawker Media sites will apparently continue operating, and Univision’s management will be able to focus their full energies on them.
Gawker Media’s path to bankruptcy began with a decision by Gawker.com editors to publish a video of Hulk Hogan having sex — without the permission of either Hogan or his partner. Hogan sued, arguing that this was a violation of his privacy. A Florida jury agreed, awarding Hogan $140 million in damages earlier this year.
Gawker Media didn’t have $140 million, so the company was forced to declare bankruptcy. The company was put up for auction, with the proceeds used to pay part of Hogan’s judgment.
We didn’t know it at the time it was filed, but Hogan’s lawsuit was secretly funded by technology billionaire Peter Thiel. Thiel has borne a grudge against Gawker since 2007, when Gawker published a post titled “Peter Thiel is totally gay, people.” Thiel started to look for opportunities to punish Gawker for what he saw as irresponsible journalism.
These were not isolated incidents. Gawker has outed others, including CNN anchor Anderson Cooper and Shepard Smith of Fox News. In one of its most infamous stories, Gawker reported on a New York media executive soliciting the services of a male escort. The man was not a public figure, and the piece was later removed after founder Nick Denton decided that the story had gone over the ethical line.
In court, Hogan's lawyers sought to portray Gawker as an organization without a moral compass. It wasn't a hard argument to make. During one deposition, Hogan's lawyers asked a former Gawker editor if there were any situation in which a celebrity sex tape would not be newsworthy.
"If they were a child," replied the editor, Albert Daulerio.
"Under what age?" the lawyer asked.
"Four," Daulerio replied sarcastically.
As a result, arguments about media freedom fell on deaf ears in the jury box. Jurors didn't buy arguments that the First Amendment protected Gawker's right to humiliate random celebrities by publishing video of their most intimate moments.
Whatever your view of Gawker’s journalism, the case does raise questions about whether billionaire-funded lawsuits could threaten freedom of speech.
Gawker isn't the only publication to be targeted by a disgruntled billionaire. Last year, the liberal magazine Mother Jones defeated a defamation lawsuit filed by Republican donor Frank VanderSloot. Winning the lawsuit cost Mother Jones, a relatively small nonprofit organization, and its insurance company $2.5 million in legal fees.
If VanderSloot's goal was to punish Mother Jones for writing an accurate but unflattering story about him, a loss was almost as good as a victory. His lawsuit sought $74,999 (staying just under the $75,000 threshold that would have allowed Mother Jones to move the case to federal court and away from an Idaho jury that might have favored the hometown plaintiff). So "winning" the lawsuit cost Mother Jones and its insurance company 30 times as much as the amount they would have had to pay if they had lost.
What was really ominous was what happened after VanderSloot's loss. He "announced that he was setting up a $1 million fund to pay the legal expenses of people wanting to sue Mother Jones or other members of the 'liberal press.’"
As far as I know, no one has taken him up on the offer. But the threat to freedom of the press is obvious. Any news organization doing its job is going to make some enemies. If a wealthy third party is willing to bankroll lawsuits by anyone with a grudge, and defending each case costs millions of dollars, the organization could get driven out of business even if it wins every single lawsuit.
Thiel insists that he has no quarrel with news organizations that conform to mainstream journalistic norms. But the key thing about his strategy is that he didn't sue Gawker for outing him — a case he probably would have lost. Instead, he waited for years until he could find other plaintiffs with stronger cases.
That's a tactic that any billionaire could use against any news organization. And because most news organizations cover a wide variety of topics, the story that provoked a billionaire's ire might have nothing to do with the stories that actually trigger a lawsuit funded by that billionaire.
In short, Thiel's war on Gawker could become a template for other extremely wealthy people with personal or ideological scores to settle against news organizations. And that’s something to worry about even if you think Gawker deserves what it’s getting.
With its purchase of Gawker Media, Univision got a number of valuable assets. Aside from Gawker.com, Gawker Media operates six other websites. There’s a sports site called Deadspin, a gadget site called Gizmodo, a car site called Jalopnik, and a video game site called Kotaku. The site also published Lifehacker, which focuses on productivity tips, and Jezebel, which covers culture from a feminist perspective. Univision also gains control of the technical and business infrastructure that allows Gawker to sell ads and turn a profit.
One of Gawker’s big downsides is that the site’s sensationalistic style and cavalier attitude toward personal privacy creates a lot of financial risk. There’s the obvious risk that the site could publish another post that subjects Gawker — and the deep pockets of its parent company — to a multimillion-dollar lawsuit. There would also be a risk that a story could create so much controversy that it could poison relationships with advertisers.
Last year’s controversy over the story on a media executive soliciting a male escort is a good example. Multiple advertisers threatened to pull their ad campaigns if the story wasn’t killed. After Denton decided to pull the story, two Gawker editors resigned in protest.
While editorial independence is an important principle, it’s also important that senior editors exercise good judgment and avoid publishing stories that invade people’s privacy. If Univision had kept Gawker.com running, it might have faced the same kind of management headaches Denton has in the past few years.

For the past several years, Google and other companies have been testing out self-driving car technology on public roads. But if you were a member of the general public, there was no way for you to ride around in a self-driving car.
Uber is about to change that. Later this month in Pittsburgh, the ride-hailing company will offer the first self-driving car service that’s available to the general public. It represents a big step toward transforming self-driving cars from a research prototype into a commercial service.
Yet the service also comes with a big asterisk. While the new program will be open to the general public, it’s still very much a work in progress. Rides will initially be free, and they’ll still have a driver behind the wheel making sure nothing goes wrong.
This means Uber CEO Travis Kalanick is still far from his dream of offering a fully autonomous ride-hailing service that could slash prices and boost Uber’s profits. Rather, the new service reflects the start of a new project to make sure Uber doesn’t fall behind its rivals — especially Google — in self-driving technology. It will be years before you’ll be able to hail an Uber and have it show up with no driver inside.
Kalanick has long seen self-driving cars as the long-term future of his company. In early 2015, he began to make it a priority. And he decided to base Uber’s new self-driving research center in Pittsburgh so he could raid Carnegie Mellon’s top-tier computer science school for self-driving car talent.
In a matter of months, Uber hired about 50 researchers and scientists from CMU. The team began to apply what they had learned in the lab to the real world, building self-driving car prototypes. By May 2016, Uber’s self-driving car prototypes could be seen driving around on Pittsburgh streets.
Extremely accurate maps are essential for a fully self-driving car, so in 2015 Uber acquired a mapping startup to help build its own maps and began building detailed maps of Pittsburgh’s urban landscape. Uber plans to dramatically scale up that project, spending $500 million to build maps around the world.
A big challenge for developing self-driving car technology is to collect massive amounts of real-world data. Collecting millions of hours of real-world data provides the raw material that software engineers use to refine their self-driving car software, finding and weeding out bugs that could lead to a fatal crash.
Google has had to do this the hard way, hiring dozens of test drivers to ride around the San Francisco Bay Area (and more recently Austin and other cities) while watching carefully to make sure the car doesn’t crash.
Uber’s existing ride-hailing business should make this process more cost-effective for the company, since it will be able to ferry passengers around — earning some revenue — while collecting test data.
But Uber evidently doesn’t think its technology is quite mature enough for that yet. According to Bloomberg, Uber’s “self-driving” cars will have not only a safety driver ready to grab the wheel at a moment’s notice but also a “co-pilot” in the front passenger seat monitoring the car’s software to make sure nothing goes wrong. Right now, for example, the human driver has to take over when a car is crossing a bridge. In other words, this is still very much a research project rather than a service that has any hope of making money.
Presumably, Uber’s plan is to gradually change that, replacing the Uber employees who will serve as the initial test drivers with ordinary Uber drivers, and then eventually eliminate the drivers altogether. Uber’s vast database of both customers and drivers means the company will be able to scale up the program quickly once it’s convinced that it’s safe to put ordinary Uber drivers behind the wheel.
Of course, the barriers here might not only be technological. A variety of state and federal regulations could prevent Uber from entirely dispensing with human drivers. Uber — along with other companies working on self-driving technology — will likely have to convince policymakers to modify or reinterpret these regulations before it will be allowed to send anyone a car with no driver at all.
Uber isn’t planning to build cars itself; its plan is to collaborate with conventional carmakers, which will make the actual vehicles. On Thursday it announced a new partnership with Volvo. Uber’s first self-driving cars will be Volvos modified with Uber’s technology, and the two companies plan to spend $300 million to jointly develop a new self-driving car model. The two companies are aiming to have the car on the road by 2021.
That date is significant because Ford also recently vowed to bring fully self-driving cars — cars without steering wheels or pedals — to market in 2021. That’s roughly consistent with statements executives from other companies — including Tesla, Google, and major carmakers — have made about their own plans for self-driving cars.
Of course, overconfidence is common when bringing ambitious new technologies to market, and few efforts are more ambitious than fully autonomous cars. It’s likely that some of these projects will fall behind schedule, and others may wind up being only partly autonomous, with drivers having to stay ready to grab the wheel in case of emergency. (This is how Tesla’s Autopilot feature works now.)
Still, with billions of dollars being poured into self-driving car research, companies have every reason to worry about being left behind. So lots of companies are now making ambitious goals to bring self-driving technology to market by the early 2020s.
And Uber’s position in the market gives it a big advantage: Because it doesn’t make cars itself, it can partner with multiple car companies, play them off each other, and ultimately work with whoever gets self-driving technology to the market first. Uber’s deal with Volvo is nonexclusive, and the company may sign similar pacts with other carmakers in the coming months.
No matter who makes the best self-driving cars of the 2020s, there will be millions of consumers who have grown accustomed to hailing rides using their Uber app. Hence, it will likely be an easy sell for Uber to convince those customers to use the same app to hail a self-driving car.
Big changes are coming for the automobile industry, and everyone in the industry knows it. This week, Ford and the Chinese technology company Baidu announced a $150 million investment in Velodyne, makers of powerful LIDAR sensors that are widely used in self-driving cars.
It's only the latest in a long sequence of deals linking car and tech companies together over the past year:
The proliferation of deals represents a growing realization among car companies that they are going to need help navigating the major changes of the next decade — Ford says it wants to start offering fully self-driving cars by 2021.
The auto industry is facing three big innovations — car sharing, battery-powered electric vehicles, and autonomy. By itself, any one of these shifts would represent a significant but manageable challenge. But the real problem is that all three trends are converging, and they jointly represent an existential threat to today's dominant car companies.
So far, car sharing is the innovation that has had the biggest practical impact on the way people get around. Ride-hailing services are still limited to a narrow elite — just 15 percent of Americans had ever used Uber or Lyft in 2015 — but investors are betting that they will grow quickly.
The big question for the auto industry is whether ride-hailing services will start to displace car ownership as the primary way people get around. Even before Uber and Lyft came along, there were a few areas in America — like Manhattan — where it was common for people to forgo car ownership and get around using mass transit and (for the more affluent) taxis.
Uber and Lyft are making this lifestyle both cheaper and more convenient, which could cause more families to give up their cars. Short-term car rental services like Zipcar are also helping people get by without owning a car, knowing that one will be available to them in a pinch.
By itself, the shift to greater car rental isn't necessarily a problem for the car industry. Someone still has to manufacture and sell the cars that Uber, Lyft, and Zipcar are renting out, and there's no reason Ford, GM, and Toyota couldn't be the companies that do it.
But selling cars to ride-sharing drivers or the corporate fleets of companies like Zipcar is a different business than selling cars directly to consumers. And Detroit benefits from an incestuous relationship with conventional car dealers.
For example, one of the big barriers that has held back Tesla's growth is the network of dealers conventional car companies use to sell their vehicles. Not only do conventional car companies have a lot of experience selling cars through these dealerships, but state laws often require cars to be sold this way, creating a barrier to entry for startups like Tesla.
In a future where on-demand car rental is the default way people get around, the key to success in the auto industry may be winning big orders from companies like Zipcar, Uber, and Google. And that could create openings for companies focused on creating different kinds of vehicles and selling them in new ways.
Still, car sharing alone doesn't pose a big threat to the auto industry for the simple reason that today's ride-hailing services are too expensive for mass adoption. If you live in a suburban area with plentiful parking, it's cheaper and more convenient to buy a car and drive it around yourself. And even many people who live in high-density areas and don't have a car rely on mass transit (and walking and biking), because these options are more affordable than hailing a ride.
Internal combustion engines are marvels of engineering, channeling rapid-fire explosions to power a vehicle as it moves down the road, and modern car designs are deeply influenced by the strengths and weaknesses of internal combustion engines. Conventional car companies have expertise not only in engines but also in transmissions, radiators, gas tanks, and more — and a lot of that would be rendered obsolete if cars were powered by batteries and electric motors.
This is the basic premise behind the creation of Tesla. CEO Elon Musk and his financial backers are betting that a company specifically created to build electric vehicles will be better at it than a conventional car company trying to make the switch from gasoline to electricity.
Yet so far, electric vehicles haven't seemed like much of a threat to conventional vehicles. In 2015, there were 17 million new cars sold in the United States. Of these, just 115,000 — fewer than 1 percent — of them were battery powered or plug-in hybrids.
The basic problem is that electric vehicles don't provide a very compelling value proposition for ordinary consumers. They might save money on fuel, but they tend to cost significantly more than gas-powered equivalents — even after you factor in generous government subsidies. With long charging times and relatively few charging stations in most metropolitan areas, they're significantly less convenient than conventional gasoline-powered cars.
Self-driving capabilities would represent the most radical change in car technology in decades — and the biggest threat to conventional car companies. Making cars drive themselves is mostly a software problem, and software has never been Detroit's strong suit. Google is investing heavily in its self-driving car program, betting that its expertise in software development will allow it to claim a major role in the car industry of the 21st century.
Yet even here, conventional car companies have managed to keep their heads above water by outsourcing the hard technical problems to third parties.
A bunch of car companies — including Tesla and several conventional firms — have begun offering cars with "advanced cruise control" or "autopilot" capabilities. And several of them have purchased their technology from Mobileye, an Israeli startup that  builds car sensors and software that allows cars to stay in their lane and avoid hitting the car in front of them.
Detroit's vision is that this self-driving technology will gradually get more and more sophisticated. Cars will continue to look more or less like they do today, but over time you'll have to grab the steering wheel less and less frequently. Eventually, grabbing the steering wheel will become so rare that it will make sense to sell cars with no steering wheel at all.
If that's how the market will evolve, it's not such a scary prospect for incumbent car companies. They have decades of experience integrating third-party components into their vehicles, and their existing manufacturing and distribution facilities will give them a big advantage over companies that try to start building self-driving cars from scratch.
So incumbent car companies would be able to cope with any one of these three trends taken individually. The problem for Detroit is that these changes are not going to come one at a time. They're happening all at once, and each of them is likely to accelerate and magnify the impact of the others.
For example, it's hard to make electric cars compelling to consumers, but it should be easier to make them attractive for car-sharing services. A ride-hailing car doesn't need the 300-mile range of a conventional gasoline-powered car. It just needs enough power to get through a morning of driving; the driver can then recharge it during his lunch break.
So electric cars purpose-built for sharing use might have smaller batteries, which can reduce vehicle weight and further improve energy efficiency. And of course ride-hailing drivers care a lot about the energy efficiency of the vehicles they drive, since a gas-guzzling car will cut into their earnings.
Self-driving technology will magnify this effect still further. As long as taxis need human drivers, they're going to mostly be sedans with room to carry three or more passengers. Nobody would want to drive a two-seat taxi and miss out on fares because he only has one passenger seat available.
But once you get rid of the driver, much smaller and lighter vehicles become viable. Lots of people take taxi rides alone, and they could take these rides in tiny one-passenger electric vehicles. These lighter vehicles would be more power-efficient and require smaller batteries, which in turn would further lower the cost of taxi service.
The optimal one- or two-seat electric car is likely to look significantly different from the best five-seat sedan — especially if the car doesn't need a driver's seat. So the shift to self-driving, electric ride-hailing cars will create a bigger opening for new companies to disrupt the car market.
And of course, with improved efficiency and no driver, these automated taxis will cost a lot less to run. That will bring them into financial reach for many more customers, dramatically expanding the market for ride-hailing services.
At the same time, the shift to ride hailing will help accelerate the shift to self-driving technology. One big reason for this relates to mapping. Right now it's widely believed that Google has the world's best self-driving car technology, and Google's technology depends on having extremely detailed maps of every street where a Google car drives. Uber has traditionally relied on Google's map data, but it recently announced plans to create its own independent mapping data.
If you're trying to sell cars to consumers, that's a huge problem, because it means you have to map the entire country before you sell your first vehicle — no customer is going to buy a car that refuses to drive in rural areas. On the other hand, if you're renting cars, it's not such a big problem. You can roll out your car rental service one metropolitan area at a time. Nobody minds renting a taxi that will only go to destinations in the same metropolitan area.
Renting self-driving cars will have other advantages too. Companies that write self-driving software will be concerned about safety (and the liability that comes with accidents). Maintaining ownership of the vehicles will allow them to guarantee that they get regular maintenance and that defective parts are replaced promptly.
So there's a good chance that fully self-driving cars will initially be available only for use as part of a ride-sharing service. If that happens, it will undermine the advantage provided by car companies' dealership networks and experience selling cars directly to consumers.
Electric, self-driving cars designed for a rental market are likely to look dramatically different from today's cars. With no driver and less space needed for an engine, we're likely to see companies experimenting with different shapes and configurations — rear-facing seats, built-in desks and mirrors, big touchscreen displays and televisions, perhaps even beds for long nighttime trips.
So conventional car companies are going to face some serious competitive threats over the next two decades. But it would be a mistake to write them off, because they have one big advantage over Silicon Valley upstarts: They know how to manufacture millions of cars.
Tesla is the only Silicon Valley company to even attempt to manufacture cars at a significant scale, and it's been learning the hard way that it's really difficult. Tesla CEO Elon Musk has become notorious for announcing production delays and cost overruns.
All three of Tesla's cars so far came to market later than originally announced, and Tesla recently announced it was raising $2 billion to fund further expansion of its manufacturing facilities. If all goes according to plan — and it probably won't — that will allow Tesla to produce 500,000 cars a year, about 3 percent of US car sales in 2015.
Manufacturing a big, complex object like a car is difficult, and conventional car companies have a 100-year head start on learning how to do it. That explains why Silicon Valley has been as eager to partner with Detroit as Detroit has been to partner with Silicon Valley.
The big question is how these partnerships will work. Will Google, Uber, and other Silicon Valley giants design the cars and rely on their Detroit partners to assemble them, much as Chinese companies like Foxconn assemble smartphones for Apple and Motorola? Will car companies treat Google as just another supplier and Uber as just another distribution channel? Or will a new generation of companies emerge that combines the strengths of both sides? Companies in Detroit and Silicon Valley are spending billions in the hope that it will help them come out on top.
A robot vacuum cleaner sounds like a great idea. I have a Roomba, one of the most popular models, and most of the time it works great. But sometimes there are unexpected problems.
In a recent Facebook post, an Arkansas man described just how bad these problems can be. His dog had an accident on the floor, and then the Roomba started its scheduled cleaning.
"If your Roomba runs over dog poop, stop it immediately and do not let it continue the cleaning cycle," the man wrote. Unfortunately, he happened to be asleep when the Roomba ran. The result: it "spread the dog poop over every conceivable surface within its reach, resulting in a home that closely resembles a Jackson Pollock poop painting."
Silicon Valley optimists like venture capitalist Marc Andreessen have predicted that digital technology would revolutionize every facet of our lives. And of course that's been true for industries like music, news, and maps. But other tasks have proven more resistant to digital transformation.
Earlier this year, I wrote about Nest, whose popular smart thermostat made it a poster child for smart homes. But the company, which was acquired by Google in 2014, has struggled to develop new products, raising questions about whether Google overpaid for the company.
A similar story can be told about iRobot, the company behind the Roomba robotic vacuum cleaner. The company is hardly a failure, having sold 15 million units since it was introduced in 2002. But the Roomba remains a niche product, and iRobot hasn't come up with another hit.
These companies are struggling for similar reasons: Their products demand too much from their users while providing too little value in return.
Last year, iRobot sold 2.4 million Roombas. By any reasonable metric, that's a successful product. But in a nation of 320 million people (not to mention a world with more than 7 billion people), it's still a niche product. The vast majority of American households don't have a Roomba or any other robot vacuum cleaner and seem to be in no hurry to buy one.
And if you talk to Roomba owners, it's not hard to see why. "It gets stuck a lot," my Vox colleague Sarah Kliff told me. "I can't really leave it at home unsupervised."
Sarah has a table with a curved metal bottom that her Roomba finds fiendishly difficult to navigate. Often she'll come home to find that it drove up the table's leg and got stranded, the cleaning job unfinished. The Roomba also terrifies Sarah's dog.
(Sarah Kliff / Vox.com)
Sarah's dog Spencer hiding from Sarah's Roomba
My Roomba also has problems with getting stuck. But I've also found that it just doesn't save me that much time. I still have to tidy up the room before letting the Roomba loose. Then when it's done, I have to empty the dustbin and — often — dig out debris that got caught in the rollers. It's not as much work as using an old-fashioned vacuum cleaner, but it's not that much less work.
And then there are the times when the Roomba wreaks havoc. Asked about poop-related accidents, a spokesman for iRobot told the Guardian that "quite honestly, we see this a lot." Neither Sarah or I have experienced this particular misfortune, but we've had other, less traumatic problems with our Roombas.
"My old roommate had a Roomba that ran into my mirror," Sarah told me. "The mirror toppled over and broke."
One day, my Roomba got ahold of a spool of thread. When I got home, it had unwound the entire spool and wrapped it around the cleaning brush roll. It took several minutes to get it unwound, and I had to throw away the rat's nest of thread that was left.
I have a $399 Roomba 650. iRobot recently introduced a new high-end model, the $899 Roomba 980, which comes with a built-in camera, a longer-lasting battery, and other improvements. But as Fortune's Kif Leswing pointed out in a review last October, these improvements only get you so far. The longer battery life doesn't help if the dustbin gets full or your home has multiple levels. And the latest Roomba seems about as clumsy as its cheaper cousins — Leswing says it "beached itself on the legs of my Ikea Poang chair." And it ate one of his cat toys, damaging one of the robot's wheels.
The Roomba is by far the iRobot's most successful product. Over the years, the company has built a couple of mopping robots, a pool-cleaning robot, and a device for cleaning out your gutters. None of them have been big hits.
Other companies have tried to create internet-connected lawn sprinklers, crock pots, and lightbulbs.
A fundamental problem here is that for many tasks in the physical world, there just isn't that much room for software and complex electronics to add value.
The home appliances that have done the most to improve people's lives are the ones like dishwashers and washing machines that took a really time-consuming and tedious task and made it dramatically faster.
But in many cases, the preinternet devices in our homes are already pretty good. There isn't a ton of room for further improvement. People don't spend a lot of time adjusting their thermostats, so the better interface on a Nest Learning Thermostat doesn't add a ton of value. Smart lightbulbs or robotic gutter cleaners seem even more like a solution in search of a problem.
Machines add the most value when they can be operated at scale in a controlled environment — washing machines and dishwashers are useful because you can wash dozens of dishes or shirts at the same time. And because all the action happens inside the machine, there's less room for unpleasant surprises — like a stray cat toy getting into the gears, or dog poop being spread across the floor.
In contrast, home robots and connected home devices are trying to operate in the chaotic and nonstandardized environment of a modern home. It's an inherently more difficult problem to design a product that will work flawlessly in a wide variety of different home types.
And this is a reason to be skeptical that we'll see rapid progress in household robotics or smart homes in the coming years. It has proven difficult to build a robot vacuum cleaner or a smart thermostat that's a big hit with the public. And other home automation tasks — like iRobot's mopping robots — have been even less popular than that. The concept of smart homes and cleaning robots sounds appealing in theory, but making it useful in practice is surprisingly difficult.
In a recent interview on Fox Business, Donald Trump said that ordinary Americans should not put their retirement savings into the stock market:
"I don't like a lot of things that I see," he said. Trump said that he had personally gotten his money out of the stock market and urged ordinary Americans not to put their 401(k) funds into stocks.
Put simply, this is terrible advice. If you’re under 50 — and have another couple of decades before retirement age — you should put around 80 percent of your retirement savings in the stock market. (Read the Vox guide to retirement for all the details on how to do it.) If you don’t, you’re likely to wind up with a much smaller nest egg when you reach retirement age.
Public attitudes toward the stock market soured in 2008, when the market plunged by 37 percent. A lot of people concluded that the stock market was too risky for ordinary people to invest in.
But the stock market doesn’t look so scary if you take a longer-term perspective. Here’s a chart of the average return of the S&P 500, an index of 500 large American stocks, over 20-year periods for the past century:
For example, if you invested in the stock market between 1994 and 2013, your average rate of return would have been 6.6 percent. The thing to notice about this chart is that there has never been a 20-year period when stock market investors lost money. The worst period, between 1962 and 1981, produced an average return of a little less than 1 percent. The best period, between 1980 and 1999, produced an average return of more than 13 percent — after adjusting for inflation.
If you had the bad fortune to buy stocks in January 1929 — on the eve of the Great Depression — you would have earned your money back and then some by the end of 1948. And that was followed by a massive stock market boom in the 1950s.
Of course, past performance is no guarantee of future results. And the United States has had an unusually successful economy over the past century. But the data shows that stocks in most developed countries have produced positive returns — and returns significantly higher than you could get from government bonds — over the long run. The exceptions are countries that have experienced communist revolutions (Russia and China) or lost major wars (Austria and Germany).
Not every country has seen its stock market rise as quickly or as steadily as the United States over the past century. And there have been a few cases (like Japan between 1990 and 2010) when countries have seen negative returns over multiple decades. But these cases are relatively rare. Around the world, people who invested in stocks over the long run have usually come out ahead of those who invested in bonds or — even worse — invested in gold or put their money under a mattress.
And that's not a coincidence. Some people think the main way to make money in the stock market is to buy stock when it's undervalued and then resell it when the price rises. And it's true that in the short run, stock price fluctuations account for most of the gains investors enjoy.
But these fluctuations don't matter as much for long-term stock returns. Stocks produce positive returns because companies earn profits that they give to their shareholders, either by paying dividends or by buying shares back from shareholders (which itself pushes up stock prices). This steady flow of cash to shareholders helps ensure that stocks produce positive returns over the long run whether stock prices go up or down. Historically, that has produced an average return of 6 to 7 percent per year.
When you buy a broad portfolio of US stocks, you're essentially buying a stake in the long-term success of the American economy. Of course, there's no guarantee that the American economy will continue to prosper — a major war, revolution, asteroid strike, or other calamity could destroy the American economy and with it the value of American companies. But as long as the American economy continues to grow, companies will continue earning profits and patient investors will enjoy a healthy rate of return.
Trump’s most plausible argument against investing in the stock market is that stock prices are propped up by low interest rates.
"If interest rates every seek a natural level, which obviously would be much higher than it is right now, you have some very scary scenarios out there," he said. "The only reason the stock market is where it is is you get offered free money."
Trump is right — sort of. Falling interest rates do tend to push up the value of all assets, including stocks. If interest rates start to rise, it could cause stock prices to decline.
But this issue isn’t specific to the stock market — it applies to almost everything you might invest in. If rising interest rates push down stock prices, they’ll also push down the value of bonds, real estate, or any other income-generating assets. So unless you want to put your money under a mattress — a strategy that’s guaranteed to underperform stocks and bonds over the long run — there’s no way to avoid the risk that higher interest rates could lead to lower asset prices.
But you also shouldn’t worry about this too much. While interest rate hikes could push down stock prices in the short run, they’re associated with higher rates of return over the long run. So if you’re able to hold on to your stocks for a couple of decades, you’re likely to come out well ahead.
The growth of the US economy keeps falling short of expectations. On Friday, we learned that the US economy grew at an inflation-adjusted rate of 1 percent in the first half of 2016. That’s the slowest six-month growth rate since 2012, and it continues the slow growth that has characterized the recovery since 2009.
The weakness of the recovery has been surprising because conventional economic theory says that the bigger an economic downturn is, the bigger the subsequent boom will be. And the 2009 recession was the worst in decades, so post-2009 growth should have been massive.
Instead, the US economy has turned in its weakest performance in decades. Since 2009, inflation-adjusted output has barely grown at 2 percent per year. Business investment has been weak, wages have been stagnant, and worker productivity has improved at its slowest pace since World War II.
We’re not in a recession — the economy has grown and unemployment has fallen to a healthy 4.9 percent. But the economy isn’t delivering the kind of rising prosperity previous generations took for granted.
So what’s going on? It’s one of today’s most important economic questions, and there’s no consensus among economists. Here are eight of the leading theories.
The 20th century saw the development and widespread adoption of a ton of important new inventions: automobiles, airplanes, air conditioning, antibiotics, refrigerators, televisions, PCs, cell phones, and so forth. Yet with the notable exception of the smartphone, it’s hard to think of any major new technologies invented since 2000. Many aspects of our modern lives, from our kitchens to our streets, look little changed from 1996 or even 1976.
In a new book, economist Robert Gordon argues that this slowdown in new inventions is the root cause of the last decade’s economic malaise. He views the IT-driven boom between 1995 and 2005 as a one-time event that’s unlikely to be repeated. Now, he suggests, people are going to have to get used to slow growth of incomes, worker productivity, and the economy as a whole.
Two data points seem to support Gordon’s point of view: the rate of startup formation is at record lows, and so is overall corporate investment. That suggests that — perhaps — entrepreneurs and established CEOs alike are struggling to identify promising new technologies that are worth investing in.
Discussion of this theory tends to quickly get bogged down in technical jargon. But at a basic level the theory is simple: If the government gave people more money, they would spend it. And more spending would create more jobs and higher incomes.
There’s fairly broad agreement among economists that this kind of stimulus can work during a severe economic downturn. But the conventional view holds that it becomes less effective once the economy starts growing again. Indeed, Alex Tabarrok, an economist at George Mason University, argues that it’s "crazy" to believe that a lack of demand explains the slow recovery.
"The time period in which monetary policy would have been effective is long over," he says.
Once an economy reaches full employment, he argues, there’s no way for increased spending to boost economic output — you’d just get more inflation instead.  And the US unemployment rate is currently 4.9 percent, near historic lows, a sign that a shortage of demand might not be a problem right now.
But other economists aren’t so sure. Larry Summers, an economist who led President Obama's National Economic Council during Obama's first two years in office, has championed a theory of "secular stagnation," in which peoples’ desire to save money outstrips opportunities to invest it. This leads to a vicious cycle in which slow spending growth makes companies pessimistic about future growth, causing them to cut investment spending even further.
So some economists believe it’s possible that more government stimulus — either interest rate cuts from the Federal Reserve or more spending by Congress — could set off a more vigorous economic boom that could expand the real output of the economy.
This could work in two ways. First, a boom could entice workers back into the workforce. The labor force participation rate for people aged 25-to-54 plunged after 2008 and is still near its lowest level in 30 years. A booming labor market could reverse that trend.
Second, more stimulus could actually make workers more productive. "We know the same person can be engaged in higher or lower productivity activities," says economist Josh Mason. "We have a lot of evidence that when you have a high-pressure economy, you have people shifting to high-productivity activities."
When labor markets are tight, companies are going to look harder for ways to make their employees more efficient. Companies might invest more in retraining workers for higher productivity jobs or they might invest more in labor-saving devices to economize on rising labor costs.
Tighter labor markets can also help better match firms to workers, as Mike Konczal and Marshall Steinbaum argue in a recent paper. When jobs are plentiful, people are more willing to make risky job moves because they know they can always go back to their old job — or one like it — if it doesn’t work out. In contrast, in a more sluggish economy a lot of workers become locked into jobs they don’t like very much and may not be very good at because they’re worried that a job switch could lead to an even worse situation.
Another possibility: businesses have plenty of investment opportunities, but pressure from Wall Street is discouraging them from making them. This is the "quarterly capitalism" critique Hillary Clinton has talked about on the campaign trail.
Over the last couple of decades, we’ve seen the rise of activist investors that take a substantial stake in a company’s stock — usually 5 to 10 percent — and then use that ownership stake as leverage to try to get companies to change how they do business. One of the most common demands is for the company to pay more cash out to shareholders in the form of dividends or stock buybacks.
As I argued in November, there’s not much evidence for the theory that activist campaigns are hurting shareholders. Stock prices typically go up when activists target a company, and these price increases are sustained over time — suggesting that the activists create lasting value.
But it is possible that having companies increasingly focused on the narrow interests of their shareholders is bad for the broader economy. Investments in new technologies often produce broad social benefits — think about all the non-Apple jobs created by the iPhone — that are not fully captured by a company’s shareholders. So if Wall Street is pressuring CEOs to invest less in new technologies, that could be helping shareholders but hurting the rest of us.
A major factor behind the 2008 financial crisis was the high levels of debt accumulated by both individuals and businesses. When asset prices started to fall, people found themselves underwater, leading to defaults and panic-selling.
The acute phase of the 2008 financial crisis was over quickly. But economist Kenneth Rogoff has argued that the effects of these high debt levels lingered for years after the crisis. Households and businesses realized that they had excessive levels of debt. The result, Rogoff argues, has been a prolonged period of depressed demand as households and businesses focus on paying down their debts instead of buying new goods and services.
This seems like a plausible explanation for the early years of the post-2008 recovery. But at this point, it’s been almost eight years since the financial crisis. That should be more than enough time for households and businesses to get their debts down to manageable levels. So the longer growth remains sluggish, the less plausible this theory becomes.
This is probably the most popular theory on the political right: that burdensome regulations have slowed the pace of economic growth. This theory is catnip for Republicans because it places blame squarely at the feet of President Obama, who has pushed through the Obamacare, the Dodd-Frank financial regulation bill, stricter environmental regulations, and more.
Others point to burdensome regulations beyond Obama’s agenda. The White House itself has pointed to the proliferation of occupational licensing laws — for everything for barbers to florists — as an impediment to economic growth. A recent paper by economist James Bessen finds evidence that regulations have created barriers to entry that boost the profits of incumbents in certain industries while reducing the dynamism of the economy as a whole.
Yet it has proven hard to find evidence that this is a major reason for the slow recovery. "I thought that regulation was probably one of the major causes of declining dynamism," says Tabarrok, who co-authored a study on this topic in 2014. But he and his co-author were unable to find evidence to back up the theory. "The basic reason is pretty simple," he says. "You see declining dynamism in pretty much all industries."
The theory that regulation is the major factor choking off innovation is hard to square with the historical record. The US economy enjoyed its fastest growth in worker productivity in the half century between 1930 and 1970. This happens to be the period when many sectors of the economy were subject to burdensome New Deal-era regulations.
Policymakers relaxed these regulations over the course of the 1970s and early 1980s, deregulating industries like trucking, airlines, telecommunications, energy, and more. And yet, the growth of productivity and wages was slower between 1975 and 1995 than they had been in previous decades.
Tabarrok is quick to point out that this doesn’t mean regulation is harmless — it’s possible that many individual industries would be more productive with less regulation. But growing regulation does not seem to be the primary reason for the productivity slowdown of recent decades.
Housing regulations are, of course, a subset of regulations generally. But there’s reason to think they could be significant.
Big cities and their surrounding suburbs have strict regulations that effectively limit how much housing can be built in the most economically dynamic metropolitan areas. The result has been skyrocketing housing prices and — more importantly — slow population growth in metropolitan areas like San Francisco, New York, and Boston. And that’s a problem because these cities account for a disproportionate share of innovation and job growth in today’s economy:
The chart shows the growth of establishments — that is, business locations like restaurants, car repair shops, or factories — during the first five years of the past three recoveries. In the past, smaller counties tended to grow faster than larger counties. This made a certain amount of sense — large counties like Los Angeles or Dallas were already expensive and crowded places to live, so it was easier for economic growth to happen in smaller towns or outlying suburbs.
But in the latest recovery, the pattern has reversed, with large counties like Los Angeles County, Miami-Dade County, and Kings County (Brooklyn) enjoying a disproportionate share of business expansion. The same pattern holds for job growth.
Obviously, this is bad news for people who live in small towns. But it may also help to explain the slow growth of the economy as a whole. Because it’s possible that big cities would be creating new jobs at a much faster rate if there were more workers available. But big cities’ housing restrictions mean that there’s nowhere for additional workers to live.
The period since 2010 has been bad for ordinary workers, but they’ve been great for corporate America. In the last six years, corporate profits have been at their highest level — as a share of the economy — since the 1960s.
Some commentators have argued that this reflects lax enforcement of antitrust laws, which has allowed many industries to become increasingly concentrated. With larger market shares, these big firms have more power to raise prices, and they’ve also become more effective at locking new firms out of the market.
There’s little doubt that there has been a trend toward industry concentration in many important industries, and it seems plausible that this is a factor in the growing profitability of corporate America. What’s not so clear, however, is whether this is leading to slower innovation.
Two well-known advocates for the view that industry concentration is holding back economic progress are Phillip Longman and James Schmitz. But I found their arguments hard to evaluate because they seemed highly backward-looking.
Longman, for example, argues that deregulation of the railroad, trucking, and airline industries allowed industry consolidation that has, in turn, hurt smaller cities and towns. That might be true, but it’s hard to believe that it’s a major factor driving recent economic trends. After all, the fastest-growing industries of recent decades — like software and finance — are not very dependent on railroads or trucking   to get their goods to market.
For his part, Schmitz writes about the sugar industry between the 1940s and and the 1970s, the cement industry in the 1970s and 1980s, and the construction industry in the 1920s. His stories do a good job of illustrating his theoretical argument, but they don’t shed much light on whether growing industry concentration is a serious problem today.
A final theory suggested to me by Tabarrok is demographics. Americans are having fewer babies than they did in the past, and this has had two related effects: The population as a whole is growing more slowly, and the average age of the population is rising.
There’s reason to think that both trends are bad for economic growth. Younger people are more likely to pursue new ideas, take risks, and start new businesses. So an aging population is likely to lead to a less dynamic economy.
Slower population growth can also be a source of economic stagnation in its own right. A rapidly growing population means rising demand for products of all kinds — new homes, restaurants, shopping malls, and so forth. So more businesses will be started in general, which means more opportunities for experimentation. Successful stores, restaurants, and other businesses can be expanded or franchised to other metropolitan areas, allowing good ideas to spread quickly.
In contrast, in a country with a more stagnant population, starting a new business requires replacing an existing business. Even if a young person has an innovative idea for a new company, the practical difficulties of getting the business started might be too great for putting the idea into practice. And so change can only happen by convincing existing business owners to change their behavior — an inherently slower and more difficult process.
Correction: This article originally misstated Larry Summers' role in the Obama administration.
Internet access is a lot faster in some places than others. Reddit user DMan9797 made this map showing broadband speeds around the world as of 2014:


The data comes from Speedtest.net, a website that lets users test their own internet connections. It indicates that the fastest internet in the world is in Hong Kong, with an average of almost 80 million bits per second (Mbps). Other high-speed countries include Japan, South Korea, Sweden, Romania, the Netherlands, and Switzerland. The United States clocks in at number 30, with average speeds of 24 Mbps.
It's important to note that these figures are based on a self-selected sample: users visiting the Speedtest.net website to test their own broadband speeds. It seems likely that users with fast connections would be most likely to try it. So these data likely overstate average broadband speeds somewhat — other measures, for example, peg the average US broadband speed at more like 12 Mbps than 24.
Still, the map gives a pretty good sense of which countries enjoy fast internet access (mostly in Northern Europe and parts of Eastern Asia) and which ones are relegated to the slow lane (much of the developing world).

One of the most important companies of the first dot-com boom, Yahoo, has reached the end of its life as an independent company. Yahoo’s board approved the sale of Yahoo’s core business to Verizon in a deal valued at $4.8 billion. The company’s shareholders and regulators must still approve the deal — the companies expect it to close in early 2017.
The deal represents a stunning decline for a company that was valued at more than $100 billion at its 2000 peak. Yahoo was never really able to adapt its technology and culture for a post-2000 internet that was focused on social media and mobile devices, and so it steadily fell behind rivals such as Google and Facebook.
After the Verizon acquisition, signature Yahoo properties like its search engine, email service, photo sharing site Flickr, and blogging platform Tumblr will presumably continue operating. But it’s hard to imagine that Yahoo will ever again play the kind of high-profile role online that it did two decades ago.
Ironically, what ultimately forced the hand of Yahoo CEO Marissa Mayer wasn’t the dismal performance of Yahoo’s online properties so much as an investment by Yahoo that worked too well. In 2005, Yahoo invested $1 billion in one of China's hottest technology startups, Alibaba. That bet paid off so spectacularly that by last year Yahoo’s Alibaba shares accounted for the large majority of the company’s value.
Shareholders worried that Yahoo management would eventually squander this windfall to prop up Yahoo’s declining internet businesses. The problem was that if Yahoo sold off the shares and gave the money to shareholders, it would trigger a massive tax bill. So instead of selling the Alibaba shares, Mayer was forced to sell the rest of the company, effectively putting herself out of a job.
It’s a humiliating end for Mayer, a Google veteran who joined Yahoo in 2012. Her turnaround effort didn’t work, and now Yahoo will be folded in with AOL, another struggling internet brand that was acquired by Verizon last year.
The most successful companies in Silicon Valley — including Google, Facebook, and Apple — have an intensely technology-focused culture. These companies are obsessive about hiring the most talented engineers (and in Apple's case, designers) so they can build the best technology products. And this culture tends to be self-perpetuating — very skilled, highly motivated people like to work with other very skilled, highly motivated people. Once you have a critical mass of such people, it becomes easy to recruit more of them.
Yahoo never had the same kind of obsessive focus on recruiting technical talent. Paul Graham, a well-known Silicon Valley investor who sold his company to Yahoo in 1998, has written that even in the late 1990s, Yahoo was ambivalent about its status as a technology company.
"One of the weirdest things about Yahoo when I went to work there was the way they insisted on calling themselves a 'media company,'" Graham wrote. Yahoo employed a lot of programmers and produced a lot of software, of course — and still does. But it never made software as core to its identity as some of its major competitors.
That's probably because at the time Yahoo was founded, in 1994, no one had ever heard of an ad-supported software company. Back then, software companies sold their products in shrink-wrapped boxes at Best Buy. Yahoo had the same business model as CNN and the New York Times — build up a large audience and then make money by selling ads — so it was natural for Yahoo to think of itself as being in the same industry. But one consequence of this was that Yahoo didn't focus as much as it could have on recruiting the best programmers.
Marissa Mayer's roots are as an engineer at Google, and she made an effort to beef up Yahoo's technical talent. She instituted a more rigorous hiring process, and the company worked hard to hire more computer scientists, especially from top universities.
But there's little sign that these moves have changed the culture or improved morale among Yahoo's programmers. "I just try to ship products that I’m not ashamed of," a Yahoo executive told the New York Times in December. This is not an attitude that tends to produce excellent products.
At the same time, Mayer doubled down on the "media company" side of Yahoo's personality. In 2013, she hired television news anchor Katie Couric for Yahoo's news site. Couric's contract was renewed last year in a deal reportedly worth $10 million. Mayer also recruited gadget reviewer David Pogue from the New York Times to anchor Yahoo's relaunched technology news section.
But despite these investments, Yahoo didn’t have nearly the prestige of a New York Times or a CBS. The company was seen as something of an also-ran both in Silicon Valley and in the media world. Yahoo created technology products that people use and media properties that have an audience, but its attempt to be a technology company and a media company simultaneously resulted in an organization that was less than the sum of its parts.
In the past few years, Yahoo's media and tech businesses were overshadowed by a third line of business: venture capital. At the same time that Yahoo's core business was in decline, its Alibaba investment was soaring in value. Indeed, earlier this year if you subtracted the value of Yahoo's major assets from the total market value of the company itself, you got a large negative number.
The uncharitable way to interpret this is that the core Yahoo business was actually destroying value. It's possible Mayer could have increased her stock price by simply announcing that she was shutting down all of Yahoo's websites and laying off all of its employees.
But there's another major factor in Yahoo's depressed share price: taxes. On paper, Yahoo's Alibaba share was worth around $25 billion. However, if Yahoo ever tried to sell its stake and pay out the proceeds to shareholders, it would have owed billions of dollars in taxes to the IRS.
After adjusting for these tax liabilities, it's possible to get a positive number for the value of Yahoo's core business. But it's still a small number. When Bloomberg’s Matt Levine crunched the numbers in December, he concluded that Yahoo's core businesses were worth just $1.7 billion, about 5 percent of Yahoo's overall market value at the time.
So Yahoo's search engine, email service, news site, and other properties might not literally be worth less than nothing. But the stock market didn’t seem very optimistic about the chances.
The big fear of Yahoo's Wall Street critics wasn’t just that Yahoo management would fail to turn a profit; it was that they'd burn up billions of dollars in a futile effort to turn Yahoo around. Yahoo had enough cash in the bank to continue its current losses for a few more years, and after that it could have sold its Alibaba and Yahoo Japan stakes to buy itself more years of money-losing operation.
But while Yahoo's management and employees obviously like to have a big cash cushion, shareholders weren’t interested in endlessly subsidizing a money-losing business. And so last year, Wall Street started to ratchet up the pressure on Mayer to separate Yahoo's core internet business from its stakes in Alibaba and Yahoo Japan.
To mollify Wall Street, Mayer announced a plan last year to spin off Yahoo's Alibaba shares into a new holding company. Under tax law, a company can spin off part of its business tax-free if it's doing so for a legitimate business purpose, but it can't do so merely as a tax dodge. In the past, the IRS hasn't enforced this rule very strictly, but when Yahoo asked the IRS to bless its spinoff proposal, the IRS demurred. That meant Yahoo could face a multibillion-dollar tax bill. So in December, Yahoo announced that it was canceling the spinoff.
In a January letter, the hedge fund Starboard Value was scathing about Mayer's performance. "The management team that was hired to turn around the Core Business has failed to produce acceptable results," the firm wrote.
So Starboard urged Yahoo's board to sell Yahoo's core business to another company. That would provide Yahoo shareholders with several billion dollars in cash while avoiding tax liability for the Alibaba shares.
Starboard wasn't just making a suggestion. Starboard is an activist investment firm that buys a significant stake in company shares and then uses it as leverage to force management to make changes. In 2014, for example, Starboard successfully ousted the management of the Olive Garden after writing an epic 300-page slide deck criticizing the company's management.
Starboard threatened to take that same approach at Yahoo. "If the Board is unwilling to accept the need for significant change," the company wrote on January 6, "then an election contest may very well be needed so that shareholders can replace a majority of the Board with directors who will represent their best interests."
The threats worked. Mayer began shopping Yahoo around to potential buyers, and Verizon emerged as the leading contender.
One reason Verizon was a strong candidate to acquire Yahoo is that the company has done this before. Verizon bought another struggling internet company, AOL, last year. And AOL has a lot in common with Yahoo. So the lessons Verizon learned from its AOL acquisition could prove valuable as Verizon digests Yahoo.
Both AOL and Yahoo are well-known internet brands whose best days are a decade or more in the past. Like AOL, Yahoo makes a lot of its money by creating internet content and selling ads against it.
When Verizon purchased AOL, it emphasized the company's portfolio of media brands, including TechCrunch and the Huffington Post. But as Matt Yglesias wrote for Vox last year, Verizon may have also been interested in AOL's ad technology business — and in particular how Verizon could use data gathered from its vast broadband and mobile networks to help AOL content companies target ads more effectively.
Either way, if Verizon was happy with its AOL acquisition, buying Yahoo, a company with a similar portfolio of technology, media, and advertising products, seems like a logical next step.
In recent years, scale has become increasingly important in the online advertising business. Advertisers prefer to make a few big ad deals rather than many small ones, and larger media companies are often able to command premium prices. With Yahoo and AOL under one roof, Verizon will be able to integrate their ad sales teams and offer advertisers packages that include media brands from both companies.
According to Yahoo's release about the deal, "Yahoo will be integrated with AOL under Marni Walden, EVP and President of the Product Innovation and New Businesses organization at Verizon" — suggesting that Mayer may end up out of a job, with the combined AOL/Yahoo unit reporting to Tim Armstrong, who was AOL's CEO prior to the Verizon sale and was asked to stay on afterward.
Elon Musk, CEO of the electric car startup Tesla, is one of the most ambitious businessmen on the planet. Tesla is the first successful American car startup in decades, and its first two cars — the Roadster and the Model S — have dramatically raised the profile and prestige of electric vehicles.
In a Wednesday evening blog post, Musk signaled that he was just getting started. He wrote that he has an even more ambitious project road map to follow next year’s release of the mid-market Model 3.
Musk wants to merge Tesla — which makes batteries in addition to cars — with the solar panel company SolarCity to offer integrated in-home power systems. He wants to expand into self-driving trucks and self-driving buses. And he signaled that he plans to compete directly with Uber by enabling Tesla owners to rent out their cars to other passengers when they’re not in use.
Taken individually, each of these ideas seems like a reasonable direction for an electric car company to go. But Musk isn’t planning to take them individually. He’s planning to pursue all of them simultaneously — at the same time as he faces growing questions about his ability to deliver the Model 3 by its late 2017 target date.
Maybe Musk will surprise us once again and execute on this ridiculously ambitious plan. But there’s also a big risk that he's bitten off way more than he can chew.
While Tesla is known for its innovative designs, it’s not known for its flawless execution.  All three of the company's previous vehicles faced production delays before they were finally delivered to customers. And there are mounting questions about whether Tesla can meet the Model 3’s 2017 deadline.
The problem, as industry analyst Edward Niedermeyer told me last month, is that the higher volume and lower price of the Model 3 makes it a much bigger production challenge. Tesla has not had a great track record for quality and reliability, but Niedermeyer argues that high-end customers tend to be more forgiving of quality flaws since they typically have another car to fall back on (or can afford to hail a taxi) if one of their vehicles breaks.
Also, producing cars at mass-market scale requires a ton of capital. Earlier this year, Tesla announced that it would raise $2 billion to fund expanded production facilities for the Model 3 — and the company might need all that cash and more to get its Model 3 assembly line up and running by next year.
All of which means that Tesla doesn’t seem like a company with a lot of spare capacity to tackle additional projects. Musk has vowed to put his desk at the end of the assembly line and sleep there while he sorts out the company’s production delays. That seems like a smart move, but a CEO who is focused on fine-tuning the company’s assembly line does not seem like a guy who will have a lot of spare bandwidth for tackling ambitious new initiatives in home power, ride-hailing, and self-driving.
So we definitely shouldn’t expect Musk to deliver on his ambitious vision on time or under budget. There will be setbacks along the way, and there’s a real danger that Wall Street will grow tired of these problems and refuse to give Musk more capital.
That said, the case for optimism here is twofold. First, if anyone can deliver on an agenda this ambitious, it’s Musk. He is already doing something most people would find impossible — running Tesla and another startup, SpaceX, simultaneously — so perhaps his impressive management abilities will stretch to allow him to manage a few additional projects.
Second, the markets are hungry for investment opportunities with high potential returns. One of the biggest problems facing the US economy right now is a shortage of high-return investments for the trillions of dollars Americans (and foreigners wanting to invest in the US) have accumulated. So if Musk can convince the markets that he will eventually deliver on his lofty promises, they might be willing to cut him a lot of slack — and give him a lot more money — along the way.
And Musk has one other advantage: Most of Tesla’s competitors are in an even worse position to deliver on the future of cars than Tesla is. Tesla’s roots in Silicon Valley give the company a leg up over old-fashioned car companies that lack the software expertise that will be required to succeed in self-driving and ride-hailing technology. Meanwhile, technology companies like Apple, Google, and Uber lack practical experience building self-driving cars.
So Tesla’s road map will likely prove slower and harder than anyone thought. But Tesla has unique advantages that could allow it to stay a step ahead of the competition. And as long as Musk is doing that, he should be able to find investors willing to bank on his eventual success.
A key job of the president is to choose the chair and other key officials of the Federal Reserve’s Open Market Committee. The Fed is way more powerful than most people realize: If the Fed raises interest rates at the wrong time, it can trigger a recession that can destroy a president’s career. (George H.W. Bush blamed his 1992 loss on Fed Chair Alan Greenspan, for example.)
Since 2008, there’s been an important debate about whether the Fed has been doing too much or too little to support the economy. Many economists believe that the Fed’s quick action in late 2008 saved the country from a more severe economic downturn. But critics, including many conservatives, argue that low interest rates between 2008 and 2015 have been counterproductive.
Personally, I think the loose-money side of the debate is right — we’re lucky the Fed took decisive action in 2008, and it probably should have done even more. And this is a lot more than an academic debate, because the Fed is going to face the same choice during the next economic downturn. If the Fed does too little to support the economy, it could make the next recession a lot more severe than it needs to be.
As often happens, Donald Trump has had conflicting views on the topic. Back in November, he argued that "Janet Yellen should have raised the rates" — a tight-money policy that could cause the economy to slow down. Then in May, Trump took a seemingly contradictory position, saying that Yellen "is a low interest rate person, she’s always been a low-interest-rate person, and let’s be honest, I’m a low-interest-rate person."
But while Trump’s views on monetary policy are vague and seemingly contradictory, his running mate Gov. Mike Pence’s views are clear and — for fans of monetary stimulus — rather ominous.
"During 2008 and 2009, the Fed pushed well over $1 trillion into the financial system in an attempt to rein in unemployment through more government stimulus," Pence argued in a November 2010 speech. "Yet the national jobless rate has been well above 9 percent for a record-tying 18 straight months."
"Printing money is no substitute for sound fiscal policy. The Fed can print more money, but it can’t print jobs."
Right now, the Fed has a mandate to boost employment while also keeping inflation under control. In his 2010 speech, Pence called on Congress to drop the employment half of the Fed’s mandate. That, presumably, would mean that the Fed would do less to contain the next recession, which could lead to greater job losses.
At the time, many conservative commentators were warning that the Fed’s easy money policies would bring about high inflation rates. Instead, the opposite occurred: Inflation rates have been below the Fed’s 2 percent target for most of the past eight years. That suggests that the Fed’s efforts to boost the economy were not as costly as Pence feared at the time.
In the same speech, Pence also flirted with returning to the gold standard. "The time has come to have a debate over gold and the proper role it should play in our nation’s monetary affairs," he said. Many economists believe the gold standard played a central role in worsening the Great Depression. Even free-market economist Milton Friedman argued that a return to the gold standard would be a mistake.
In his 2010 speech, Pence was echoing what had become the orthodox conservative line. Ever since Fed Chair Paul Volcker brought inflation under control during the administrations of Jimmy Carter and Ronald Reagan, hawkishness against inflation has been a standard conservative position.
But in the wake of the 2008 financial crisis, this position has become more contested.
Hawks kept predicting inflation, and it kept not happening. So some conservative and libertarian thinkers began to rethink the hawkish position on monetary policy. Ramesh Ponnuru, a prominent conservative writer, was one of the first conservatives to argue that money had been too tight in the wake of the 2008 crisis.
His frequent co-author on monetary topics, economist David Beckworth, was recently hired by the libertarian Mercatus Center to write about monetary policy, where he joined economist Scott Sumner, another early advocate of the view that money was too tight in 2008. James Pethokoukis, an economist at the conservative American Enterprise Institute, has made similar arguments.
But while this point of view is gaining support among right-leaning intellectuals, it’s not clear how much traction it has among rank-and-file Republican voters. Many Republicans are old enough to remember the high inflation of the 1970s. And despite decades of falling inflation, they still believe that vigilance against inflation should be the Fed’s highest priority. Trump’s choice of Pence could help to cement that conventional wisdom among Republican elites for another four years.
To make progress in Pokémon Go, a mobile game that’s taken over America in the past week, you can’t just sit on your couch. You have to get out of the house and travel around town. Some Pokémon can only be found in watery locations. Others are only available at night.
When you find a Pokémon, the game shows the creature superimposed on your actual surroundings. Move your phone around, and the animated image moves too, making it appear as though the Pokémon is located in the real world.
This technology of blending the physical world with virtual objects is known as augmented reality, and it’s destined to become a huge deal over the next decade.
But before it can do that, the technology has to get better. That’s partly about better software, but augmented reality won’t really come into its own until companies like Apple and Samsung create better hardware for seamlessly merging the real and virtual worlds.
Pokémon Go is augmented reality in only the most superficial sense. When I first started playing the game yesterday, a Pokémon showed up on top of my desk. Then when I backed up, it slowly slid toward me until it appeared to be bouncing around on the floor under the desk. As I walked over to the window, it appeared to be floating through the air and then bouncing on the ledge outside.
In short, the creature didn’t seem to be very firmly connected to the physical world. And that broke the illusion augmented reality tries to create.
The basic problem here is that my iPhone is only aware of its location and surroundings in the crudest sense. It has a GPS chip, a compass, and an accelerometer that tells it very roughly where I’m located and which way my phone is pointing. But the iPhone’s camera doesn’t have the ability to recognize or precisely track objects — something that human beings take for granted.
Technology companies have been working on technology to fix this problem. Last year, Intel introduced RealSense, a new category of chips that allow the creation of 3D photos. A RealSense-equipped phone would not only capture a 2D image of my desk but would also instantly capture its three-dimensional shape (using either a range-finding sensor or a pair of cameras that work together).
This kind of advanced sensor would enable apps like Pokémon Go to offer much more realistic augmented reality. Pokémon Go would know the exact size, shape, and location of my desk, allowing the game to appropriately scale the Pokémon image and place it in a precise location in 3D space. If an object passed in front of the Pokémon, the augmented reality camera would recognize this and render the nearby object in front of it.
A character in this more sophisticated version of Pokémon Go could also interact with its surroundings. It could leap off my desk onto the floor and start walking down the hall, or hide under the desk.
While games are the most obvious application for augmented reality, they’re far from the only one. For example, if you had a smartphone with a built-in 3D sensor, you could take a photo of a room and have it automatically compute the size of objects in the shot. Ikea might make an app allowing you to visualize how new furniture would look in your living room. Or an architect could show a client proposed changes as they walk through a building.
In the 18 months after Intel’s RealSense chips were announced, there hasn't been a lot of progress in integrating this kind of technology into smartphones. But I think it’s only a matter of time before this technology becomes commonplace. Google has a project called Tango that aims to bring augmented reality to Android phones.
But there still seems to be room for Apple to set the standard for smartphone augmented reality.
Building a high-quality augmented reality platform will require combining hardware and software innovations. Smartphones will need both 3D sensors and a software platform that allows app developers to make effective use of them.
Apple is the only company that makes both a popular smartphone and a mobile operating system (the iPhone and iOS). That means Apple is the only company that can guarantee to app developers that there will soon be millions of phones out there with both hardware and software support for its augmented reality platform.
This kind of hardware-software integration has long given Apple a leg up in pushing new technologies like Apple Pay and TouchID. I’d love to see the company follow the same approach to bring better augmented reality to a future iPhone.
Update: I added information about Google's Project Tango.
The interest rate the US government pays to borrow money for 10 years fell below 1.4 percent last week. Those are the lowest borrowing costs Washington has faced — ever. This chart from Quartz tells the story:
<picture class="c-picture" data-cid="site/picture_element-1500882786_3912_57124" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/0a9f45tjE2OWOm9ycHTFM7nIJKU=/0x0:640x360/320x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 320w, https://cdn.vox-cdn.com/thumbor/106Mu5I85lgdfKsMMl-DPHeKz44=/0x0:640x360/520x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 520w, https://cdn.vox-cdn.com/thumbor/gbx4TQYUoMANOAhDqAyIlS3WFJw=/0x0:640x360/720x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 720w, https://cdn.vox-cdn.com/thumbor/YU3lVf2c4mEap9JUz-VXy6q0xIg=/0x0:640x360/920x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 920w, https://cdn.vox-cdn.com/thumbor/fEsf2G2GU6JTUhJdHWRNz7-werU=/0x0:640x360/1120x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/LEg4BaGe_xH3YXAP3cCbaj3DcSM=/0x0:640x360/1320x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/9R-QRCz0tON40VyZDiqUcKdgypI=/0x0:640x360/1520x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/XbDIB_Tp624pnIpyMpTMz3l1ew4=/0x0:640x360/1720x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/finPp5Y_iT6HzPGiKBG89azSltE=/0x0:640x360/1920x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/SsVsXuu8Jvbe3TQA2JSAlF__WB4=/0x0:640x360/1200x0/filters:focal(0x0:640x360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/6773427/yield_on_us_10-year_government_bonds_close_chartbuilder.0.gif">

</picture>
The falling interest rates of the past decade have surprised a lot of people. When I bought a house a year ago, people told me I should hurry up and close a deal before interest rates rose again. (Mortgage rates and government bond rates are different, but they tend to move up and down together.) Instead, mortgage rates have fallen further.
For almost a decade, people have been predicting that rates would rise soon — even as they kept falling and falling. Many people still assume it’s only a matter of time before rates start drifting back up toward "normal" rates of 6 to 8 percent (for mortgages) and 4 to 6 percent (for government bonds).
But looking at interest rates over a longer time period suggests a different possibility: Today’s interest rates are normal.
Suppose you showed someone a chart of government 10-year borrowing costs from 1800 to 1960 and asked them to project rates in the 2010s. They would probably observe the fairly steady downward trend and predict that rates in the 2010s would be very low — perhaps around 1.5 percent, where they stand today.
The reason people have such a strong intuition that 6 percent interest rates are normal and 1.5 percent interest rates are abnormal is that the human life span is only about 80 years. Few people alive today remember the ultra-low interest rates of the 1940s, and no one today remembers the steadily declining interest rates of the 1800s. But lots of people remember that interest rates were a lot higher than the 1970s, '80s, or '90s, and they’re expecting those high rates to come back.
But there’s good reason to think that the period from 1960 to 2010 was an anomaly driven by the high inflation rates of the period. Bond markets in the 1970s worried that inflation would erode the value of their investments, so they demanded higher interest rates to compensate. But when inflation rates started to fall in the 1980s, interest rates fell too.
And if you think about the big picture, falling interest rates make perfect sense. Like any price, interest rates are driven by supply and demand. And America is getting richer and richer, driving up the supply of capital. So of course the price of capital is going to fall.
The newspaper publisher formerly known as Tribune Publishing has rebranded itself "Tronc" as part of an ambitious plan to reinvent itself as an online news organization. A key plank of its new strategy: producing 2,000 videos per day.
You might think that sounds unrealistic — the Vox.com video team, for example, has produced only a few hundred videos in its two-year history — but a New York Times article explains how Tronc expects to accomplish the goal: automation. Tronc is going to deemphasize the traditional, labor-intensive process for producing video content in favor of software tools that allow it to churn out hundreds of videos per day with minimal human involvement.
Tronc’s business logic is straightforward: Advertisers pay top dollar to run ads before videos. So if Tronc can produce a lot of videos, it will be able to sell a lot of high-dollars ads and make a lot of money.
"Video is video," Tronc’s chief technology officer, Malcolm CasSelle, told the Times. "We’re producing it because it’s strategic and important."
The strategy Tronc is pursuing here isn’t really new. For at least a decade, some media companies have churned out text-based articles in a process known as "content farming." Tronc appears to be updating this strategy for the video age. The problem is that content farming has been a total disaster for companies that have tried it.
A company called Demand Media provides an object lesson in the dangers of this strategy. Starting in 2006, it produced a huge amount of content optimized for prominent placement in search engine results.
Demand Media paid writers a fraction of what more traditional outlets would pay — one writer reported making between $7.50 and $15 per article in 2010, a rate that hadn’t changed significantly by 2015. Obviously, the only way to make a living at this is to write extremely quickly, churning out one or more articles per hour. These articles would appear on Demand-owned websites like eHow.
Articles written this quickly aren’t very likely to be good. But Demand Media was betting this wouldn’t matter very much. Demand Media’s goal was to rank highly in Google, and Google’s search algorithms can’t tell the difference between a well-reported, in-depth article and one dashed off in an hour.
Traditionalists wrung their hands, but for a while it looked like Demand Content’s model was working. The company even signed a syndication deal with Hearst Newspapers in 2010 to provide some content for the San Francisco Chronicle and the Houston Chronicle. Demand was briefly worth more than $1 billion after its 2011 IPO.
But then disaster struck. Or, more specifically, Google’s search quality engineers struck. Because while Google’s algorithms couldn’t tell the difference between a bad article and a good one, its human programmers sure could. A few weeks after Demand Media’s IPO, those engineers tweaked Google’s algorithm to downgrade spammy sites. Within days, Demand Media’s eHow site lost more than 50 percent of its traffic, and other content farming sites saw even more severe traffic declines.
Demand Media never really recovered. The company is still around, but its stock has plummeted, and nobody thinks its business model represents the future of online content.
The broader lesson here isn’t just that media companies should stay on Google’s good side. It’s that quality actually matters — even if it doesn’t look like it in the short run.
For a little while, you can generate traffic by stuffing garbage articles full of relevant keywords. If you’d looked at Demand Media’s traffic and revenue data around 2009, you could have fooled yourself into believing the company had found a new model for producing content profitably.
But people aren’t stupid. They gradually realized that articles on sites like eHow were no good. Google realized that its users didn’t want to be shown a bunch of garbage articles when they searched, so it changed its algorithm to show people articles they were more likely to actually enjoy and value.
Tronc’s "video is video" strategy appears to be updating the Demand Media business strategy for the video age. And it’s probably true that in the short run, a low-quality video with a catchy title and cover image will generate as many clicks as a high-quality one.
But as with Demand Media’s content, you can’t fool people for very long. If Tronc videos aren’t good, Tronc’s audience will figure it out and stop clicking on them. Facebook will figure it out and stop putting them in people's newsfeeds. Advertisers will figure it out and take their money elsewhere.
And while Demand Media started from scratch, Tronc is starting with high-quality brands like the Los Angeles Times and the Chicago Tribune. Stuffing their articles full of low-quality video isn’t just going to fail to produce a sustainable business model — this spammy video business model is likely to tarnish these newspaper brands for years to come.
In the United States, we view the economic crisis that started in 2008 as something that ended years ago; the story now is the slow pace of recovery. But in Europe, the crisis genuinely hasn’t ended. Greece had a major debt crisis as recently as last year, and Spain is still suffering from an unemployment rate above 20 percent.
Last month’s vote for Brexit has led to a renewed flare-up of anxiety about the European financial system, and it looks like Italy may be the next European country to face a crisis. Italian banks have about $400 billion in bad loans on their balance sheets, and markets have started to panic. One Italian bank has lost 80 percent of its value over the past year, and observers worry that some banks could be on the verge of collapse.
Italy’s prime minister, Matteo Renzi, wants to use about $45 billion in Italian taxpayer funds to shore up Italian banks and head off an economic crisis. But his plan runs afoul of European Union rules, which prohibit countries from bailing out their banks without making the banks’ investors pay first.
This is exactly the kind of rule that bailout critics in the United States and elsewhere have demanded since 2008. They want to make sure that investors, not taxpayers, foot the bill for bank failures. But there’s a danger that strict adherence to this principle could prevent the government from taking measures to contain a financial crisis that could have much larger costs in the long run.
Italian banks are facing a problem that’s broadly similar to the problem some American banks faced in 2008. They made a lot of loans to people who aren’t paying them back — a situation that’s been made worse by years of weak economic growth in Italy.
Renzi is worried that this will lead to a collapse of several major Italian banks, which could trigger a broader financial crisis. So he wants to organize a government bailout of Italian banks, injecting $45 billion into the banks to provide the cushion they need to ride out a wave of loan defaults.
This is the kind of bailout that the United States and many other countries orchestrated in the recent past, but Renzi has a problem doing it for Italy: Relatively new EU rules prohibit governments from doing this kind of no-strings-attached bailout. Under European law, a bank’s own creditors — investors in the banks’ bonds — must take losses before the government can spend taxpayer money shoring up the bank's finances.
That’s exactly what critics of America’s TARP bailouts wanted to happen in 2008. They said it wasn’t fair to make taxpayers pay billions of dollars to bail out a bank while people who made loans to risky banks get 100 cents on the dollar.
They also argued that making creditors pay before taxpayers would create an incentive to do due diligence on a bank’s finances before lending it money. They thought making creditors pay would make them more wary of lending to banks making reckless investments. That, in turn, would force banks to be more prudent, making future crises less likely.
This argument assumes that a bank’s creditors are wealthy, sophisticated financial institutions that understand the risks they’re taking on. But in Italy, that assumption doesn’t necessarily hold. According to Bloomberg, 45 percent of Italian bank debt is held by ordinary Italians. That means complying with the EU rules could mean some Italians lose a big chunk of their life savings.
Renzi got a taste of the potential backlash back in December, when the Italian government rescued four banks in accordance with EU rules. Creditors took losses in the process, and one of them was an Italian man who lost $110,000 he had invested in bonds issued by one of the bailed-out banks. The man killed himself, leaving a suicide note criticizing his bank.
Renzi is understandably reluctant to repeat this experiment on a broader scale. So he’s been lobbying EU leaders for an exemption from the EU’s anti-bailout rules that would allow him to inject cash directly into Italian banks. But European leaders are unconvinced. German Chancellor Angela Merkel, the most powerful EU leader, has refused to budge, insisting that it would set a bad precedent to relax the EU’s anti-bailout rules just two years after they were overhauled in 2014.
If this were just a debate about the solvency of a few random Italian banks, there’d be no reason the rest of us should care. The concern is that an Italian banking crisis could have broader effects in the Italian economy — and potentially the rest of Europe.
The reason is that banks play a central role in modern economies. Making and receiving payments is an essential function for any business. If these payment functions were disrupted by a wave of Italian bank failures, it could have an outsize impact on the Italian economy.
And while the goal of discouraging banks from making too many risky investments seems sensible, it’s important to remember that a financial crisis can transform otherwise sound investments into money losers.
In a crisis, financial institutions tend to sell assets in order to shore up their cash reserves. But that can make things worse by pushing down asset values. Suddenly, banks that were perfectly sound prior to the crisis find their assets are worth less than their liabilities. They might be forced to start selling assets themselves to make sure they have enough cash on hand if the crisis gets worse. The result can be a downward spiral that takes down responsible banks along with irresponsible ones.
So if authorities are too fastidious about refusing to bail out banks that have been irresponsible, it can wind up taking down banks that never did anything wrong.
This is why Renzi wants to rescue banks now — before panic starts to set in, and without worrying too much about making banks’ creditors pay.
At this point, you might be wondering why EU officials care so much about Italian banking policies. If Italy’s elected prime minister wants to bail out Italy’s banks using Italians’ taxpayer money, why not just let him?
The problem is that Italy, Germany, and a bunch of other EU countries share a currency. And the shared currency effectively links their economies in other ways.
Back in 2012, investors lost confidence in bonds issued by the government of Italy and a few other countries in Europe’s periphery. Italy had a big national debt and a slow-growing economy. Financial markets worried their debts would spiral out of control — and the more they worried, the higher Italian interest rates got.
That, of course, made the Italian budget deficit even bigger, making the country’s debt problems even worse. Without the ability to print its own currency, there was a real danger that Italy would be forced to default, which could have led to a crack-up of Europe’s common currency area.
To prevent this from happening, the European Central Bank in 2012 promised to guarantee bonds issued by Italy and other eurozone countries. Because the ECB can print an unlimited number of euros, that quickly calmed markets and brought interest rates down.
But an ECB backstop for Italian debt essentially means that the rest of Europe has a financial stake in keeping Italian government debt under control. If Italy spends beyond its means, other European countries could get stuck with the tab. And so it’s not too surprising that other countries are insisting the Italian government not be too generous with its bank bailouts.
But there’s also an obvious problem with a situation in which German and French leaders get an effective veto over Italian economic policy. It’s easy for Merkel to insist that Italy must strictly adhere to EU rules regardless of their effect on the Italian economy — she doesn’t have to worry about winning reelection in Italy.
And there’s a real danger that this kind of standoff will hamper an effective response to Europe’s next economic crisis — whether it involves Italian banks or problems elsewhere on the continent. Each European leader is accountable only to voters in her own country. In cases where different countries have divergent interests, there’s no good mechanism for resolving the disagreement.
In the long run, this situation doesn’t seem sustainable. If economic policy is going to be made on a Europe-wide basis — and the euro is pushing the continent in that direction — then it should be made by a Europe-wide, democratically elected body like the European Parliament. That would mean shifting functions like taxation and bank regulation up to the EU level.
If, on the other hand, voters want to maintain national control over economic policy, then Europe might be forced to reconsider the wisdom of a shared currency.
The US economy gained 287,000 jobs in June, the strongest monthly result of 2016. The unexpectedly strong result helps put to rest fears of the US economy tipping into recession — a recession that would have been bad for Hillary Clinton’s chances of capturing the White House in November.
In recent years, the economy has gained about 200,000 jobs in a typical month. That’s more than enough to keep up with population growth, which is why the unemployment rate has been gradually declining over the past few years.
But last month, economists got a nasty surprise: The economy gained only 38,000 jobs, far below the level needed to absorb new workers. That created fears that the economy was falling into recession.
But now it looks like those fears are unfounded, as the latest number shows robust job growth:
The weak job numbers in May likely contributed to the Federal Reserve’s June decision to delay further interest rate hikes in an effort to boost the economy. And supporters of Hillary Clinton worried that a weak economy would help Donald Trump in his bid for the White House, since the party in power tends to do better when the economy performs well.
However, a single month of bad jobs data can simply be statistical noise — and that appears to have been the explanation for May’s poor results. In today’s release, the Bureau of Labor Statistics actually revised the May figure down further to 11,000 jobs. But the strong June result suggests that May’s numbers weren’t the start of a larger trend.
The latest report also includes some other moderately good news. Workers’ wages grew at a respectable 2.6 percent over the past year — slightly better than the rate of inflation:
The unemployment rate ticked up slightly, from 4.7 percent to 4.9 percent. But this isn’t necessarily a bad sign, as it partly reflects workers who had previously left the labor force being lured back into job seeking by the relatively strong economic recovery.
Years ago, I heard an argument from a guy who later went on to serve at a high level in the Obama administration that I thought was really smart and persuasive: American politics massively overstates the importance of trade policy in causing the big shock to the American economy that was induced by foreign manufacturing in the early 21st century.
The reason you can tell is that the big change in trade policy regarded Mexico (NAFTA, in other words), but the big change in terms of actual trade regarded China and the United States didn’t do anything to lower tariffs or other barriers to Chinese imports. The result is a kind of nonsensical deadlock in which people talk a lot about NAFTA, which was a real policy change, but are mostly angry about second-order consequences of trade with China, the country with which the United States runs far and away the biggest trade deficit.
The problem, on this account, is that Chinese exports surged primarily because China got better at making stuff, not because of anything that happened in American politics.
I found this convincing and have believed it for years. I’ve repeated it to other people, some of whom may also have found it convincing. And over the weekend I read a piece of research that convinced me I’ve been wrong this whole time. We didn’t lower tariffs on Chinese goods, but we did make a subtle policy change right at the end of the Clinton administration that’s made a big difference.
Here’s the subtle policy shift. Starting in 1980, Chinese-made goods were taxed at the relatively favorable rates applied to countries that enjoyed what was known in legal terms as normal trade relations with the United States. That status had to be affirmatively extended each year by Congress or it would expire, and it was extended each and every year for 20 years.
Starting in 2000 that changed, and China was granted permanent normal trade relations. That meant it would automatically keep the low tariff rates it had enjoyed since 1980 unless Congress affirmatively took them away.
Clearly, that’s a change. But since Congress really had routinely approved NTR for two decades, it never seemed to me like a particularly large change. Certainly not a big enough change to explain the wholesale transformation of the industrial landscape that’s taken place in the 15 years since it happened. Clearly the action must have been things that happened in China rather than this extremely modest shift in US trade policy.
But Justin R. Pierce from the Federal Reserve and Peter Schott from Yale’s School of Management have convinced me this is wrong.
In their paper “The Surprisingly Swift Decline of US Manufacturing Employment,” they deploy two statistical tests that reveal that the modest-sounding change was a really big deal in practice. They say the effect is plausibly large enough to explain the 18 percent decline in manufacturing employment that occurred between March 2001 and March 2007.
Pierce and Schott’s primary strategy is to exploit the fact that the gap between the NTR tariff rate and the non-NTR tariff rate varies from industry to industry. If the switch from NTR to PNTR were a big deal, we would expect to see bigger changes where the gap between the NTR and the non-NTR rates was biggest.
And, indeed, their regression analysis reveals “a negative relationship between the change in U.S. policy and subsequent employment in manufacturing that is both statistically and economically significant.” This change remains significant even when they control for changes in Chinese policy.
They also exploit the fact that the European Union, another large, high-wage economy, gave China its equivalent of PNTR many years earlier and had no significant policy change in 2000. They find “no relationship” between “the US NTR gap and EU manufacturing employment,” confirming that the correlation that exists in the American context isn’t spurious.
So why did American trade policy make such a big difference, even though tariffs didn’t fall? Pierce and Schott can’t say for sure, but they speculate that it has to do with patterns of investment.
Giving Chinese companies confidence that tariffs would stay low encouraged them to invest in production capacity aimed at supplying the American market. And giving American companies confidence that tariffs would stay low encouraged them to build supply chains around Chinese manufacturers.
Shifting production to Asia to save a few bucks on each item sold, in other words, might not make sense if there was a chance that you’d have to shift it back a year or two down the road. The old practice of keeping tariffs low but requiring the low-tariff status to be renewed on an annual basis gave US-based producers a significant amount of hidden protection. Despite the superficial appearance of openness to imports, the temporary nature of the low tariffs discouraged companies from making plans built around that openness.
Twenty years of repeated extensions of normal trade relations had only a relatively modest impact on the American economy, but making NTR status permanent led to a very rapidly displacement of American manufacturing work by Chinese imports in a way few PNTR proponents anticipated or have even acknowledged.
This election season has seen a great deal of negativity about the state of the US economy. And it’s true that economic growth since 2008 has been slower than some earlier periods in US history.
But this chart from the Organization for Economic Cooperation and Development helps to put the performance of the US economy in perspective:
The US economy has grown by a bit more than 10 percent, adjusted for inflation, in the eight years since the financial crisis began. In contrast, the euro area grew by less than 1 percent, and Japan’s economy is essentially the same size it was in early 2008.
This partly reflects a difference in population growth — the US population has grown by about 6 percent since 2008, while the eurozone grew about 2 percent and Japan’s population actually fell. But even adjusting for population, the US economy has been outperforming the economies of Japan and the euro area.
The euro area only includes countries that have adopted the EU’s common currency, the euro. It doesn’t include Great Britain, and so this slow growth doesn’t directly explain why so many Brits were anxious to leave the EU. However, this kind of anemic growth certainly didn’t help British supporters of EU membership make their case.
What explains this anemic growth? Monetary policy, in large part. The European Central Bank has made a series of blunders over the past eight years that have prolonged and deepened the eurozone’s depression. Meanwhile, Japan has been struggling with an aging population. With fewer and fewer working-age people, it’s hard to keep economic growth going.
In a blistering speech whose prepared text Donald Trump's campaign leaked to Politico early Tuesday afternoon, the Republican candidate hammers free trade policies in terms starkly reminiscent of Bernie Sanders' presidential campaign.
"Globalization has made the financial elite who donate to politicians very wealthy," says Trump. "But it has left millions of our workers with nothing but poverty and heartache."
He says he'll bring back manufacturing jobs by renegotiating NAFTA, slapping China with punitive tariffs, and a range of other measures designed to put America First and make the country great again.
American trade policy could certainly be improved upon, but the fact of the matter is that nothing Trump or any other trade skeptic proposes is going to bring back the heyday of American manufacturing jobs, for the simple reason that when you look at the data, the decline of manufacturing employment actually doesn't reflect a broader decline in the state of American manufacturing. In fact, the output — as measured in inflation-adjusted dollars — of the US manufacturing sector is higher than it's ever been, even as manufacturing employment has barely recovered from its recession-era lows:
One reason for these divergent trends is that as you might expect, the segments of the manufacturing supply chain that tend to migrate to Mexico or Asia are the ones that are the most labor-intensive and have the lowest value added in terms of complexity or intellectual property. So when factories go overseas, they tend to be unusually "jobful" factories relative to the ones that stay.
The other reason is that companies involved in manufacturing are working relentlessly to improve the productivity of their operations and do more with less labor. This is, in some respects, a cause of the relatively high wages we associate with the manufacturing sector — workers can get paid more when their work generates a lot of value. And it's in some respects a consequence of relatively high wages. If you have to pay a lot for your workers, it makes sense to invest in figuring out ways to use less of them.
Either way, the very strong implication is that any steps we take to strengthen the manufacturing sector are going to have a fairly marginal impact on manufacturing employment.
For better or for worse, the bulk of employment growth in the future is going to come from health care and other in-person services — and we're going to have to find a way to make a services-oriented economy work, not waste our time pining for the good old days of factory work.
On Thursday, Britain voted to leave the European Union— an option dubbed "Brexit." Almost 52 percent of Britons voted in favor of leaving.
Although the "leave" campaign often focused on emotional arguments about immigration, there are in fact many reasons those in favor of leaving believed it would benefit the UK. They came from across the political spectrum, and some of the arguments even contradict others. Here are seven of the most significant.
This is probably the most common argument among intellectual-minded people on the British right, expressed by Conservative politicians such as former London Mayor Boris Johnson and Justice Minister Michael Gove.
Over the past few decades, a series of EU treaties have shifted a growing amount of power from individual member states to the central EU bureaucracy in Brussels. On subjects where the EU has been granted authority — like competition policy, agriculture, and copyright and patent law — EU rules override national laws.
Euroskeptics emphasize that the EU’s executive branch, called the European Commission, isn’t directly accountable to voters in Britain or anyone else. British leaders have some influence on the selection of the European Commission’s members every five years. But once the body has been chosen, none of its members are accountable to the British government or to Britons’ elected representatives in the European Parliament.
Critics like Johnson say the EU’s regulations have become increasingly onerous:
Sometimes these EU rules sound simply ludicrous, like the rule that you can’t recycle a teabag, or that children under eight cannot blow up balloons, or the limits on the power of vacuum cleaners. Sometimes they can be truly infuriating – like the time I discovered, in 2013, that there was nothing we could do to bring in better-designed cab windows for trucks, to stop cyclists being crushed. It had to be done at a European level, and the French were opposed.
Many British conservatives look at the European bureaucracy in Brussels the same way American conservatives view the Washington bureaucracy. Gove has argued that EU regulations cost the British economy "£600 million every week" ($880 million). (Though this figure is disputed.)
This is the mirror image of the previous two arguments. Whereas many British conservatives see the EU as imposing left-wing, big-government policies on Britain, some on the British left see things the other way around: that the EU’s antidemocratic structure gives too much power to corporate elites and prevents the British left from making significant gains.
"The EU is anti-democratic and beyond reform," said Enrico Tortolano, campaign director for Trade Unionists against the EU, in an interview with Quartz. The EU "provides the most hospitable ecosystem in the developed world for rentier monopoly corporations, tax-dodging elites and organized crime," writes British journalist Paul Mason.
This left-wing critique of the EU is part of a broader critique of elite institutions more generally, including the World Trade Organization, the International Monetary Fund, and the World Bank. Brexit supporters on the left would have a lot in common with Americans who are against trade deals like the Trans-Pacific Partnership.
The United Kingdom has had a significant faction of euroskeptics ever since it joined the EU in 1973. But until recently, this was a minority position.
"There are nearly 130 Conservative MPs who have declared for leaving the EU," economist Andrew Lilico told me last week. "If you went back 10 years, you would have struggled to find more than 20 who even in private would have supported leaving the EU."
So what changed their minds? The global recession that began in 2008 was bad around the world, but it was much worse in countries that had adopted Europe’s common currency, the euro. The unemployment rate shot up above 20 percent in countries like Greece and Spain, triggering a massive debt crisis. Seven years after the recession began, Spain and Greece are still suffering from unemployment rates above 20 percent, and many economists believe the euro was the primary culprit.
Luckily, the UK chose not to join the common currency, so there’s little danger of the euro directly cratering the British economy. But the euro’s dismal performance still provides extra ammunition to Brexit supporters.
Many economists believe that deeper fiscal and political integration will be needed for the eurozone to work properly. Europe needs a common welfare and tax system so that countries facing particularly severe downturns — like Greece and Spain — can get extra help from the center.
But that makes Britain’s continued inclusion in the EU awkward. Britain is unlikely to go along with deeper fiscal integration, but it would also be unwieldy to create a set of new, parallel eurozone-specific institutions that excluded the UK.
So, the argument goes, it might be better for everyone if the UK got out of the EU, clearing the path for the rest of the EU to evolve more quickly into a unified European state.
The intellectual case for Brexit is mostly focused on economics, but the emotional case for Brexit is heavily influenced by immigration. EU law guarantees that citizens of one EU country have the right to travel, live, and take jobs in other EU countries.
British people have increasingly felt the impact of this rule since the 2008 financial crisis. The eurozone has struggled economically, and workers from eurozone countries such as Ireland, Italy, and Lithuania (as well as EU countries like Poland and Romania that have not yet joined the common currency) have flocked to the UK in search of work.
"In recent years, hundreds of thousands of Eastern Europeans have come to Britain to do a job," British journalist and Brexit supporter Douglas Murray told me last week. This, he argues, has "undercut the native working population."
The UK absorbed 333,000 new people, on net, in 2015. That’s a significant number for a country Britain’s size, though according to the CIA the UK still received slightly fewer net migrants, relative to population, than the United States in 2015.
Immigration has become a highly politicized issue in Britain, as it has in the United States and many other places over the past few years. Anti-immigration campaigners like Nigel Farage, the leader of the far-right UK Independence Party, have argued that the flood of immigrants from Southern and Eastern Europe has depressed the wages of native-born British workers. Some voters are also concerned about immigrants using scarce public services.
"One of the causes for the great public disgruntlement," Murray argues, is that Labour governments at the turn of the century "massively understated the numbers [of immigrants] to be expected," creating public distrust of current pledges to keep migration under control.
While many Brexit supporters simply want to reduce the amount of immigration overall, others argue that the UK could have a more sensible immigration system if it didn’t have the straitjacket of the EU.
EU rules require the UK to admit all EU citizens who wants to move to Britain, whether or not they have good job prospects or English skills.
"Leave" advocates argue that the UK should be focused on admitting immigrants who will bring valuable skills to the country and integrate well into British culture. They mention the point-based immigration systems of Canada and Australia, which award potential migrants points based on factors like their language and job skills, education, and age. That, "leave" advocates argue, would allow the UK to admit more doctors and engineers who speak fluent English, and fewer unskilled laborers with limited English skills.
The EU doesn’t have the power to directly collect taxes, but it requires member states to make an annual contribution to the central EU budget. Currently, the UK’s contribution is worth about £13 billion ($19 billion) per year, which is about $300 per person in the UK. ("Leave" supporters have been citing a larger figure, but that figure ignores a rebate that’s automatically subtracted from the UK’s contribution.)
While much of this money is spent on services in the UK, Brexit supporters still argue that it would be better for the UK to simply keep the money and have Parliament decide how to spend it.
The United Kingdom voted to leave the European Union on Thursday. And global financial markets, reacting to the decision, started this morning with sharp drops in London and around the world, meaning that the vote to "Brexit" caused a tremendous loss of wealth not only in the UK but throughout Europe and Asia.
London’s FTSE 100 index opened to an 8.7 percent drop, and the FTSE 250 index, which is considered a better barometer for the British economy, fell 12 percent.
The British pound is now worth just $1.37 against the dollar — an 8 percent drop and its lowest value in 30 years.
And the economic ripples have reached far beyond London. The DAX, the most widely used German stock index, has fallen 7 percent. France’s CAC index has fallen 8.6 percent. The IBEX, representing Spain, is down 11 percent:
It’s not just Europe. Japan’s Nikkei index is down 8 percent, and other Asian markets have fallen, although less dramatically. The United States is likely to be next. Trading hasn’t yet opened, but Dow Jones futures dropped 3 percent last night:
The big British banks were faring even worse. Stock in Lloyd’s and Barclays, two of the UK’s major financial institutions, were down nearly 20 percent.
Before the vote, economists predicted that leaving the European Union would be economically catastrophic for Britain. The British government estimated that the economy could shrink by up to 8 percent by 2030. Some of the biggest British banks said they’d have to shift some of their operations to other financial centers such as Paris or New York.
The governor of the Bank of England has promised to do whatever it takes to shore up financial markets, perhaps through quantitative easing or lower interest rates, the Guardian reported.
But the global impact so far is happening largely because Britain’s vote to leave is creating a tremendous amount of uncertainty — no one can say for sure how long leaving the EU will take, what kind of trade deals the UK will end up negotiating, or what the impact will be on British businesses. The European Union is the United States’ biggest trading partner, and an economic slowdown there would affect Americans as well.
It’s possible that markets will stabilize some as the day goes on. But for now, the news is bad. Bloomberg reported this morning that the investment firm T. Rowe Price estimates that a global recession is now more likely than not.
The Brexit results are in: The British people have voted to leave the European Union in a historic referendum.
This doesn’t mean Britain has actually left the European Union, but it does mean that they will leave soon. Unlike a typical nation-state, the EU does have an exit procedure that’s laid out in law. It’s not an exit procedure that’s ever been actually put to the test, so we don’t have a great sense of how it will work in practice. But the broad outline is that the referendum sets into motion a two-year period for a negotiated divorce during which time the British government and the EU are supposed to unwind their fiscal ties and lay out a new framework for how the country will relate to the trading bloc.
This could, in practice, mean almost anything — ranging from something like Norway’s extreme close relationship to the EU to something like the arms’ length relationship that Australia or the United States has.
Here’s who won and who lost.
An intriguing contrarian case for Brexit was British economist Andrew Lilico’s argument that "Leave" should win precisely in order to make it easier for the rest of the EU to integrate more deeply.
The eurozone, after all, is a bit of an odd beast. Having a bunch of countries that share a currency but don’t share a tax system or a welfare state means that when particular places fall on economic hard times, they have no escape.
A truly independent country facing the kind of loss of external investment funds that struck Spain during the financial crisis would experience rapid depreciation of its currency. The suddenly much cheaper country would become a more attractive tourist destination, more attractive maker of export goods, and more attractive magnet for a new round of foreign investment, thus helping it recover from the financial crisis.
Conversely, a member of an integrated welfare state facing a rapid collapse of its local housing market (think Florida in 2008) would be stabilized by continued federal inflow of dollars to its health care, retirement, and unemployment insurance systems. Not a bailout of debts incurred by the local government authority, but assistance to hard-hit citizens that helps them get back on their feet and keeps local businesses afloat.
Eurozone member states, however, are stuck in a strange limbo between these two poles, neither fully independent nor integrated into a common welfare state. Which means that when disaster strikes, their means of promoting economic recovery are limited.
Moving to that kind of integrated welfare state is a big project, and it clearly isn’t going to happen anytime soon. But with Britain set to leave the EU and become unable to block new measures in Brussels, it’s substantially more likely to happen.
Britain, after all, is richer than the average EU member state, meaning most of its citizens would probably end up paying slightly higher taxes for slightly fewer services under such an arrangement. Britain is also temperamentally skeptical of the case for deeper European integration — and, crucially, not a member of the euro, and thus not particularly desperate to make the euro work. A Europe without Britain will be one that’s set on a more rapid course to even deeper forms of fiscal integration.
In the short term, the vote to leave the European Union is going to commence a period of disruption and uncertainty in which foreign direct investment in the UK takes a temporary pause while investors wait to find out what the long-term situation will look like.
That, in turn, will cause the value of the pound to fall and likely prompt a recession whose severity and duration will have a lot to do with the short-term policy choices made by the UK government and the Bank of England.
This possibility was discussed extensively during the campaign, and evidently Britain’s voters decided that a little short-term turbulence was worth the possible long-term upside of getting out of the EU. The real risks to the British economy, however, concern something else entirely — the long run.
Right now, many large, multinational companies like to put their European headquarters in London. London is a great city to live in, and its English-speaking population and low-by-European-standards taxes make it an attractive base of operations since the European Union’s single market means you can do business throughout the continent from anywhere.
Leading Leave campaigners say that post-Brexit they will negotiate a trade pact with the EU that lets them retain that kind of access, but there’s no guarantee they will succeed. The French government might deliberately try to block them, figuring that if executives can’t station themselves in London they’ll fall back on Paris. The Irish government might see enormous upside for English-speaking Dublin.
Similarly, the UK’s major export industry is the financial services cluster in London. Thanks to the EU, London-based banks currently serve a continent-sized market just like New York-based ones. If the post-Brexit UK can negotiate deep market access with the EU, that will stay the same. But if it can’t, European banking will likely migrate to Frankfurt and Amsterdam. And the governments of Germany and the Netherlands may want to make sure that happens.
If you’re wondering how this entire referendum business came about, the answer is that British Prime Minister David Cameron had a problem heading into the UK’s 2015 general election. He and most of the other Conservative Party leaders, reflecting the preferences of the British business class, wanted to stay in the EU. But a growing number of Conservative Party voters, driven largely by anti-immigration sentiment, wanted to leave and were tempted to vote for the anti-European, anti-immigrant UK Independence Party (UKIP).
Cameron’s solution was to promise a referendum on EU membership if the Conservatives won the election — something the opposition Labour Party wasn’t promising.
Vote UKIP, Cameron argued, and you’d get Labour — and no referendum. The best way to get the UK out of the EU would be to vote Conservative, even though the Conservatives weren’t promising to leave.
This was a neat trick, but one that was stunningly short-sighted. Because though it succeeded in delivering an election victory for the Tories, the referendum campaign itself badly split the Conservative Party between Cameron’s "Remain" faction and a substantial chorus of pro-Leave politicians led by former London Mayor Boris Johnson, Cabinet Minister Michael Gove, and former Minister Iain Duncan Smith.
Cameron remains prime minister but he announced his intention to resign by the fall Friday morning. He’s just been humiliated, and the ambitious pro-Brexit politicians who won the referendum will seek to overthrow him with the support of Tory backbenchers. The argument that leaving the EU ought to be conducted and negotiated by people who actually believe in the policy seems pretty compelling, after all.
Even more clearly than his boss David Cameron, it’s George Osborne, the chancellor of the Exchequer, whose personal political career was on the line in this vote.
Osborne is essentially Britain’s Treasury secretary, except that because Britain isn’t a military superpower, his stature vis-à-vis the Foreign and Defense ministers is higher. Even more than that, Osborne is effectively Cameron’s number two (the UK only sometimes has a formally designated deputy prime minister, and now is not one of those times) as well as his intended successor as leader of the Conservative Party.
Losing the vote badly jeopardizes the ability of the pro-EU faction of the party to retain control. The win sets the party up for a lot more trouble and infighting, but Osborne is likely to come out ahead.
The EU is divided along a number of different lines. But one tension is between the countries whose political classes are deeply enthusiastic about European integration — primarily the six founding members, Germany, France, Italy, Belgium, the Netherlands, and Luxembourg, joined by countries like Spain and Greece that see the EU as guaranteeing the stability of their political systems — and a more diffuse set of countries that prefer a looser union.
The latter group includes Denmark and Sweden, both of which (like the UK) opted out of membership in the eurozone common currency union, as well as many Eastern and Central European countries like Poland and the Czech Republic, whose experience of Communist rule and non-experience of the three-decade social democratic growth miracle in the aftermath of World War II have bequeathed a more right-wing political culture.
The UK is the most significant country in this loose-union bloc, and their departure will significantly weaken its presence in Brussels and ensure that the "ever closer union" school of thought would win future policy battles.
Poll results have started to come in in this week's historic vote on Brexit— British exit from the EU. And it's looking like there's a real possibility that the United Kingdom will vote to leave. Many people view this as a disaster for the European Union.
But Andrew Lilico, a British economist at the consulting firm Europe Economics, argues that it's more complicated than that. He views the creation and expansion of the EU over the past half-century as a great accomplishment with benefits for both Britain and continental Europe. But he now believes it would now be better — for both Britain and the rest of the EU — for Britain to leave.
Why? Lilico believes that British exit from the EU became inevitable as soon as soon as the UK refused to join Europe’s common currency project. The euro has been an economic disaster, creating shockingly high unemployment rates in peripheral EU countries like Greece and Spain.
Lilico argues that the euro can only work well if the eurozone becomes a single integrated superstate. And he argues that the UK’s presence within the EU has become the most important obstacle to deeper European integration.
We spoke by phone last week. The interview has been edited for length and clarity.
Timothy B. Lee: A lot of Brexit supporters are critics of the EU. But you argue that the EU has been good for both Europe and Britain. So why get out now?
Andrew Lilico: We've gained considerably by being in the EU, but the sorts of gains we've made are gains we can't repeat from here.
Some of the key advantages have been geopolitical. Within the EU, we were able to participate in absorbing post-fascist states like Spain, Portugal, and Greece as liberal democracies. The EU united Western Europe against the Warsaw Pact. It absorbed post-communist states into the family of liberal democracies. Those are enormous gains. Setting aside a few remaining details, like absorbing Albania and Serbia, the vast majority of that project is complete.
Along the way Britain converted our European partners to a regulatory and economic philosophy that was aligned with ours. The EU embeds a very British, pro-market-oriented economic philosophy based on privatization, market liberalization, free trade, opposition to state aid, and opposition to protectionism. Those are also gains you can't make twice.
And as long as we remain within the EU, we are a blockage upon the EU achieving its proper destiny. The euro project was supposed to have the institutions to make it work. Because Britain is in the EU — and not part of the common currency — that has meant that the euro has not been able to take control of institutions properly. That has then turned into economic or political catastrophes in countries like Spain and Greece, where we've had 20 to 30 percent unemployment.
Once we withdraw, the EU will be able to become a unified state. It will allow the EU to grow faster, which will be to our advantage as well.
TBL: Walk me through the logic here. How does a British exit help the rest of the EU get where it needs to be?
AL: In order for the eurozone to work properly as an economic unit, it needs a proper system of fiscal transfers.
When a country has economic shocks, it can offset them by the population moving around. This happens within the US and within the UK. But this doesn’t happen very much between eurozone states. That means asymmetric economic shocks get entrenched and you end up with high unemployment in some areas.
If you want to have things function and maintain social cohesion, you don't want vast population movements. You need fiscal transfers. That means regional subsidies, benefits payments, tax breaks to allow individuals to keep going in tough times.
The EU has a system like this, but it's very small: half a percent of GDP. In the UK it's 3 to 8 percent of GDP, something like six to 15 times as big. If you're going to make the euro function, you're going to need much larger transfers from the richer parts of Europe — like Germany and Northern Italy —  to poorer parts — like Greece, Southern Italy, and Spain.
So they need eurozone-wide taxes, a eurozone treasury, an elected eurozone president, a eurozone parliament, and eurozone civil servants to manage expenditures.
It's going to be difficult to introduce those kinds of things with new treaties. But actually, you don't need new treaties, because the EU already has most of these things. We don't need a eurozone parliament, you have the European Parliament. We don't need a eurozone president because we have the president of the European Commission.
The reason this hasn’t happened is the eurozone is connected to a set of non-eurozone countries. Of these countries, all but two — the UK and Denmark — have a commitment to join the euro in the end.
Once the UK is out, there will be enormous pressure on other countries to say when they will be joining. Countries that refuse to join will get rolled together with Norway (which isn’t in the single market but has a free trade arrangement with the EU). Then the eurozone can take full control of the EU's institutions and be able to function properly to make it work as a currency union.
TBL: What makes you confident this will actually happen? Given the level of turmoil in the eurozone lately, will European countries really be prepared to give up even more power to Brussels?
AL: This kind of deep political integration is the official plan, as stated by the EU authorities. There have been public commitments by French President François Hollande, German Chancellor Angela Merkel, and the prime minister of Italy. The Future of Europe Group and all kinds of other bodies have declared that the ambition is much deeper integration.
People sometimes call it the United States of Europe. Ultimately I think that will occur because it's such a cool idea. And European officials understand that the eurozone has enormous problems. People worry that the next downturn could cause the entire system to collapse. So they know they have to do something.
European Council President Donald Tusk said recently that Brexit might bring about the end of Western political civilization. I don’t think Brexit will do that. The thing that could bring about the collapse of the EU — which really could be a threat to Western civilization — is failing to sort out the eurozone's issues. But the issues with the euro can't be addressed while Britain is part of the EU. It would be much better if the UK would get out of the way.
TBL: The recent crisis in Greece suggested to me that there might be a lot of resistance to further eurozone integration. The standoff created a lot of resentment — especially between Greece and Germany. Many Greeks thought the Germans were too stingy; Germans thought the Greeks had been too financially reckless. Can European countries really move past those feelings and continue toward deeper integration?
AL: I don't know whether Greece can survive as a member of the euro. I thought that it couldn't, but if they were going to go, they would have done it last year.
Here's a key thing to grasp. Apart from Britain being in the way, the great threat to eurozone integration is the continued insistence by commentators that the only way to do it is for the Germans to pay everyone else's debts. Europe can only proceed to the fiscal union if it's absolutely understood that that doesn't mean them being responsible for other people's debts. The more people say that, the more fiscal union will be seen as a subterfuge to pay the debts of the Italians. Germans won't do it.
But that isn't what fiscal union means. For example, for much of the past century, regional subsidies have been sent to Liverpool. If you go back 250 years, people in Liverpool were sending money to London. In the future people in Liverpool will probably send money to London again. But that's completely different from saying the Liverpool council will do whatever they want, then if they go bust, London will pay.
It's the first one that makes a currency union work. The second one — saying Germans have to be responsible for everyone else's debts — is what makes the currency union collapse. It’s a really important distinction that a lot of people in Britain and American don't grasp.
TBL: Brexit opponents argue that the UK gets a lot of benefit from being the de facto financial capital of Europe. With English being the world’s most widely spoken language, a lot of companies have established London headquarters to manage their European operations, creating jobs for Britons. Should we be worried that Brexit will cost the UK this kind of economic advantage?
AL: A good example here is the Markets in Financial Instruments Directive. There's a principle being established that if you're a non-EU country and you have regulatory equivalence to the EU, then you can sell into the EU as if you were an EU member.
As globalization extends, many of the EU's external barriers are being reduced. Many global barriers are low already. The advantages of being inside become greatly reduced.
Some people may move some staff. There could be some nontrivial tax impacts depending on where your headquarters is. But the UK is going to remain an attractive location. The vast majority of key activities will stay in the UK where we have comparative advantages in financial services and legal services.
A key reason financial services are in London is you need a lot of smart, highly motivated people. They're not going to want to live in a place with 80 percent tax regime like France. Also, it’s got to be a fun place to spend money. It’s no coincidence that London and New York are fun cities to spend money in.
Frankfurt and Geneva are not fun places for clever, highly remunerated people to be. It's not impossible that there will be some relocation. I won't discount that altogether. But I think it's easy to exaggerate how much of that kind of thing there will be.
The UK will do some different things over the medium term. The UK has been big in financial and legal services since the 1980s. Perhaps in the future it won't be as big as I would expect, but if it didn't and we became more IT-heavy or big in space ports or whatever tomorrow's exciting new thing is, why is that a bad thing?
TBL: I think your pro-EU case for Brexit is really interesting. But this position also seems somewhat marginal within the larger Brexit debate. My impression is that most Brexit supporters hold the opposite view — that the EU is a disaster that has been undermining British institutions, and that the UK should get out before it does any more damage. Am I wrong?
AL: I think there's a variety of points of view. There are a number of people who think the EU has always been bad. But that's not most of the current opposition.
For example, there are nearly 130 Conservative MPs who have declared for leaving the EU. If you went back 10 years, you would have struggled to find more than 20 who even in private would have supported leaving the EU. Until very recently, it was believed that we could renegotiate and find a way to get along with our European partners.
Now that project has been explored and failed. It can't be done. Because there's not a way of making it work. So it's now time to move on.
That doesn't mean that those people have always been opposed. Neither does it mean that they feel the EU has served us badly for most of history. The majority of those who are in favor, in the press, opinion formers, have only come to that view recently. Most have wanted to renegotiate. Only when they've despaired of that as a possibility, that's when they said we'll have to leave.
It's also a post-euro thing. if you go back 10 to 12 years, people argued it would unsustainable if Britain didn’t join the euro. Those people were right. That didn't mean we had to leave immediately. We got an extra 15 or 20 years in the EU. That’s a long time —  almost as long as we’ve been in [the EU] in the first place. But deciding not to join the euro started the clock ticking.
On Thursday, voters in the United Kingdom of Great Britain and Northern Ireland will go to the polls to decide whether to leave the European Union — an option dubbed "Brexit" — or stay in. Polls and betting markets suggest that British voters will probably vote narrowly to remain in the EU, but it’s too close to say for sure. But regardless of how the vote turns out, the fact that Britain is having this debate at all is a sign that the political project to unite Europe isn’t going very well.
The EU was created in 1993 (it was an expansion of the earlier European Economic Community), with "ever closer union" as one of its founding principles. European leaders hoped to gradually transform Europe from a collection of sovereign nations into a single European superstate. But that process has slowed over the past decade, leaving the EU awkwardly straddling the line between being one nation and many.
The EU has become too economically and politically integrated for its member states to function as truly independent nations. Yet it lacks the kind of continent-wide financial and political institutions — like a strong executive and the authority to levy taxes independent of member governments — that would allow it to act as a single integrated country. As a result, the EU has a tendency to become paralyzed by infighting and indecision during crisis moments like last summer's Greek financial meltdown.
If Britain leaves the EU, there's a danger that it will embolden other EU nations to follow suit, leading to the gradual disintegration of the EU. The prime minister of the Czech Republic warned in February that "Czexit" could follow close on the heels of Brexit.
On the other hand, it’s possible that removing Britain’s relatively Euroskeptical population from the EU could make it easier for the EU’s remaining members to move forward with economic and political integration.
On the other other hand, even if UK voters decide to stay in the EU, British voters have made it clear that they don't like European elites' vision of "ever closer union." So a "remain" vote could leave the EU's current dysfunctional institutions in place for the foreseeable future — which could prove even worse for the EU, in the long run, than losing the UK.
It will create some big headaches for European leaders if the UK votes to leave the European Union. They'll have to negotiate a new relationship with the Brits while simultaneously worrying that other countries will follow the UK's lead.
But over the long run, the British vote is more a symptom of the EU's broader challenges than it is a source of problems in its own right.
To see why, it's helpful to think back to last year's Greek crisis.
The Greek economy was suffering from a severe economic downturn caused in part by a Europe-wide monetary policy that was insufficiently stimulative for Greece. The downturn worsened Greece's already large deficit, which meant that Greece needed to ask European leaders for more financial aid. But European leaders were reluctant to provide it, because they worried it would establish a precedent and encourage other countries to engage in reckless spending in the future.

If Greece were an independent country with its own currency, it could have addressed the crisis by devaluing its currency and stabilizing its debt with depreciated cash.
On the other hand, if the EU were a single sovereign nation like the United States, it would have a nationwide, federally funded social safety net, which would have meant that a local economic downturn would not have been as devastating to Greece's budget.
Instead, Greece was stuck with the worst of both worlds: It didn't have the autonomy to deal with the crisis itself, nor were there EU-wide institutions powerful enough to address it effectively.
Every year, the US federal government taxes rich people in Massachusetts and Connecticut and uses the money to fund government benefits for poor people in Mississippi and West Virginia. Few Americans see that as a problem, because we identify as Americans first and citizens of Massachusetts or West Virginia second.
But Europe's political culture hasn't made the same leap. People still see themselves as Brits, Germans, or Greeks more than Europeans. So when circumstances call for shared sacrifices, things tend to get bogged down in arguments about which European nations should bear the biggest burden.
These kinds of problems are likely to crop up every time the continent has an economic or political crisis, generating resentments that will make people even more reluctant to support further integration. British taxpayers weren't on the hook for last year's Greek bailout, but observing the bitter conflict between Greece and the rest of the eurozone can't have made British voters more enthusiastic about British institutions becoming more integrated with the continent.
The Brexit debate, then, is a sign that the European political experiment isn't going very well. Whether or not British voters decide to pull out now, it's clear they don't want to see the integration process go much further. And if further integration isn't on the table, it's not clear how the EU can gain the legitimacy it will need to survive over the long run.
Britain's participation in the European project has always been controversial within the United Kingdom. In recent years, opponents of Britain's membership in the EU, known as Euroskeptics, have been concentrated in the more populist portions of Britain's political right.
The strongest Euroskeptics in Britain have a lot in common with conservative populists in America such as Donald Trump and Pat Buchanan. Just as Trump argues that the US has gotten a bad deal from recent trade deals, so British Euroskeptics contend that Britain is getting a raw deal from its membership in the EU.
In the past few years, the debate over Britain's EU membership has increasingly become a debate over immigration. Britain did not sign on to the Schengen Agreement, which established de facto open borders among many EU members on the continent. But the EU's rules still require Britain to open its labor markets to citizens of other EU nations and to offer them certain government benefits.
The EU's liberal migration rules are unpopular on the British far right.
The United Kingdom Independence Party, founded in the 1990s with an explicit goal of opposing British membership in the EU, has gained supporters in recent years by focusing on an anti-immigrant platform. The party won 12 percent of the vote in the 2015 election — good enough for third place.
The Syrian refugee crisis has created a political environment in which anti-immigrant and anti-EU politics can find broader support. Few Syrians have made it to British shores, but the flood of Syrian refugees into other EU nations and last year's terrorist attacks in Paris have raised fears about border security more generally.
While Cameron has endorsed EU membership and has induced most members of his leadership team to do the same, he still faces significant opposition within his own party. The most prominent critic is former London Mayor Boris Johnson, who announced in February that he favored a "leave" vote.
Johnson's case against EU membership focuses on the growing regulatory burden imposed by the EU and the corresponding erosion of British sovereignty. "EU law is likened to a ratchet, clicking only forwards," he writes. "We are seeing a slow and invisible process of legal colonisation, as the EU infiltrates just about every area of public policy."
"It was one thing when that court contented itself with the single market, and ensuring that there was free and fair trade across the EU," Johnson adds. Now, however, "the European Court of Justice has taken on the ability to vindicate people’s rights under the 55-clause Charter of Fundamental Human Rights, including such peculiar entitlements as the right to found a school, or the right to 'pursue a freely chosen occupation' anywhere in the EU."
Grassroots agitation to leave the EU has given British Prime Minister David Cameron leverage to seek changes to the EU's rules. In February, after months of negotiations, Cameron announced a new deal with EU leaders that confirms Britain's right to remain permanently outside the common currency and gives the UK new rights to control immigration and to limit government benefits to EU citizens who move to the UK.
This deal has been a key part of Cameron's campaign to stay in the EU, as he has argued that it addresses critics' major concerns with EU membership.
And Cameron's allies in the business community argue that EU membership has major economic benefits. The EU operates as a massive free trade area, and its standardization of national regulations make it easier to do business across borders. This makes it easier for British businesses to sell their products in countries from Spain to Poland. The EU also makes it easier for people to move between European countries to find work, allowing British business to draw on a continent-wide labor force.
EU advocates say these benefits are economically significant. One major business group estimates that being part of the EU provides Britain with a net benefit of 4 to 5 percent of British GDP — or roughly $1,500 per British person. And advocates emphasize that Britain's net contribution to the EU's budget, 0.4 percent of GDP, is comparatively small.
Of course, not everyone sees the EU's efforts to harmonize regulations in a positive light. Critics see the EU as foisting unwanted and unnecessary regulations on the British economy, and they argue that leaving the EU — and repealing many of those regulations — could provide economic benefits.
Of course, a lot depends on what kind of relationship would replace EU membership if Britain were to leave the EU. The deep ties between Britain's economy and the rest of the EU means that both sides would have strong incentives to cooperate. Cameron might be able to strike a deal that salvages many of the benefits of EU membership while enhancing Britain's autonomy. Indeed, Boris Johnson has argued that leaving the EU could allow the UK to enjoy most of the benefits of EU membership with fewer costs.
On the other hand, European leaders might decide to drive a hard bargain in order to make an example of Britain and discourage other countries from following its lead. There's a risk that Britain's exit from the EU could lead to higher trade barriers with the continent, putting UK businesses at a disadvantage compared with German and French firms trying to do business in the European market. Some companies have hinted that a British exit could cause them to move their offices from London to continental capitals to keep them within the EU.
The only way to find out for sure would be for voters to endorse Brexit. And Cameron argues that's too big of a risk to take.
There was a time when I had seen but one and a half movies in the Fast & Furious franchise.
I had always been skeptical of the films' powers, perhaps because I had only seen 2 Fast 2 Furious (easily the worst installment) and Fast Five — without sound, while on a plane (still pretty awesome).
Then I watched the first seven of them in a week.
That experience made me not just a convert, but an evangelist. The Fast & Furious movies stand as one of the best film franchises America has going for it right now — and maybe even a gloriously dumb representation of everything good about America.
They boast a healthy affection for old-fashioned, practical effects work, where most of the cars we see crashing are really cars crashing, not sprites in a computer. They have a huge, talented, racially diverse cast. They feature openly sentimental, oddly complex storytelling. They're a testament to the bravery and diversity of this great land, to its boldness of spirit and openness of heart.
And, yes, to its ability to solve pretty much any problem by hurling a car at it.
Fast & Furious is a mutant hybrid horror of a movie franchise. It starts out as a low-key story of illegal street racers and eventually becomes, for all intents and purposes, the Marvel Cinematic Universe (MCU) but with cars. Along the way, it freely appropriates tropes from the Halloween, Terminator, and James Bond franchises.
But underneath it all, Fast & Furious is a grand, glorious soap opera, with motor oil pumping through a heart measured in horsepower.
This is America reimagined as a fireball.
The Fast & Furious franchise consists of seven movies of gradually increasing mayhem, with an eighth hitting theaters on April 14, 2017.
Related
The first film is basically a small-scale character drama with some car chases thrown in here and there. The seventh film features cars parachuting out of airplanes. As you can probably surmise, things escalated over time.
Here’s a brief overview of all the films in the franchise, with quick plot descriptions, international box office totals, and the official Vox rating:
Rating
The Fast and the Furious (2001): LAPD officer Brian O'Conner (Paul Walker) goes undercover among illegal street racers to figure out who's behind a string of truck hijackings. While there, he develops an intense rivalry — and eventual friendship — with the mysterious, mountainous Dom Toretto (Vin Diesel). Worldwide box office: $207 million.
Rating
2 Fast 2 Furious (2003): Brian leaves behind everybody who was in the first movie to track down drug dealers in Miami. Also, there are car chases and street races and Eva Mendes. This movie is bad. Worldwide box office: $236 million.

Rating
The Fast and the Furious: Tokyo Drift (2006): For 99 percent of its running time, this movie has absolutely nothing to do with the previous two. An American misfit teenager named Sean (Lucas Black) goes to live in a version of Japan that seems cribbed from a Carmen Sandiego game. While there, he learns about the mysteries of "drift" racing and takes on the Yakuza. Surprisingly decent! Worldwide box office: $158 million.
Rating
Fast & Furious (2009): The franchise accidentally creates continuity by gathering up major characters from the first three films (which, remember, had very little to do with one another) and sending them after drug dealers yet again in the wake of a tragedy. The plot doesn't make much sense, but the action is better than ever. Worldwide box office: $363 million.

Rating
Fast Five (2011): The franchise's pinnacle so far mostly leaves behind car racing in favor of an elaborate heist plot, with even more characters from the series' history getting together to rip off a Brazilian crime lord. The concluding action sequence is one for the ages. Worldwide box office: $626 million.

Rating
Fast & Furious 6 (2013): The franchise takes a full turn toward melodrama, with double-crosses, amnesia, and brave self-sacrifices turning up as major plot points. It's arguably a little too much, but that's what this franchise is for now. Oh, and the action sequences are stunning. Worldwide box office: $789 million.

Rating
Furious 7 (2015): The brother of the sixth film's main villain seeks revenge on Dom, Brian, and the crew — a scenario that can only end furiously. This is an enormously entertaining movie and would serve as a great finale for the whole series, if necessary. (It won't be the finale, however.) Worldwide box office: $1.516 billion

Rating
The Fate of the Furious (2017): A new chapter begins for the series, in the first film made entirely after the death of Paul Walker in a 2013 car accident. Has Dom turned against his beloved family? Will a new group of cyberterrorists destroy the world? If you don’t already know the answers to those questions, you may not have seen these movies before. A mild step back. Worldwide box office: n/a
No. The first film is actually loosely based on a 1998 magazine article from Vibe magazine about street racers.
The 1955 film — produced by famed low-budget Hollywood maven Roger Corman — was about a criminal who breaks out of prison and has to drive really fast to stay ahead of the law with a beautiful woman at his side. Elements of that idea have been sprinkled throughout the series, but no single film in the franchise is a remake of that movie. However, Universal did buy the rights to use the title for the first film.
You can watch the full 1955 movie here.
The first Fast & Furious film is also not a remake of the 1939 Busby Berkeley comedy Fast and Furious, as the latter is about rare book dealers. Here is its trailer anyway.
The first film was directed by Rob Cohen, and his departure from the sequel was seen as something the franchise might struggle to overcome. (He left with Vin Diesel to make XXX.) Cohen’s visual style — which mostly consists of making the world look all jittery and stretched out as those super-fast cars pass by — defines that first film in a big way.
The second film was directed by John Singleton, a great director who also made Boyz N the Hood but who seemed to fundamentally misunderstand that a Fast & Furious movie should never be too serious.
The next four films were directed by Justin Lin, one of the best action directors working right now. What Lin understands intuitively is that action sequences require long shots that establish geography, so we have a better idea of what's happening to whom, and when. Here's a great example of how he establishes the geography of a major chase in Fast Five:
The seventh film was directed by James Wan, best known for his horror work on movies like Saw and The Conjuring. He's an expert at building tension, a skill he used to great effect throughout Furious 7.
The eighth film is directed by series newcomer F. Gary Gray, who previously directed the 2003 “cool cars” movie The Italian Job.
It's also worth pointing out that films three through eight are all written by Chris Morgan, who has become a kind of steward of the franchise’s characters.
The crazy thing about the Fast & Furious franchise is that no single character has appeared in all seven films. This isn't a conscious choice in the way it might be in, say, the Marvel movies, where all the characters have their own solo adventures before coming together in Avengers films. Many of the actors split off to have more successful careers elsewhere — only to come back when those careers didn't exactly pay off.
Here's a quick look at who appears in which Fast & Furious films.
These characters break down into five main groups.
The main four: This group includes former LAPD officer and FBI agent Brian O'Conner (Paul Walker), who sets the series in motion by trying to get close to street racer and small-time criminal Dom Toretto (Vin Diesel) and his girlfriend Leticia "Letty" Ortiz (Michelle Rodriguez). Naturally, Brian gets in too deep and falls for Dom's sister, Mia (Jordana Brewster). The constant twists and turns in the relationships of these four characters drive every movie but the second and third ones, though Brian is still the main character of 2 Fast.
The rest of the crew: These are the characters who sign up with the main four to pull off impossible schemes. Roman Pearce (Tyrese Gibson) and Tej Parker (Chris "Ludacris" Bridges) joined the franchise in 2 Fast, before becoming its comic relief in Fast Five. HanSeoul-Oh (Sung Kang) is a wryly philosophical drift racer from Tokyo who proved so popular that the franchise literally brought him back from the dead. (More on this in a bit.) Gisele Yashar (Gal Gadot) is a relatively minor character in Fast & Furious who joins the crew more fully in Fast Five and develops a relationship with Han. (Also in this classification but not in our graphic are Tego Leo [Tego Calderón] and Rico Santos [Don Omar].)
Friends in law enforcement: These characters start out as Fast Five antagonists but quickly realize our heroes are the good guys and help them take out supercriminals. They include Luke Hobbs (Dwayne "The Rock" Johnson), who is basically Tommy Lee Jones's relentless pursuer from The Fugitive until he and Dom become best pals, and Elena Neves (Elsa Pataky), a Brazilian police officer who's the only non-corrupt cop in Rio or something.
Wild cards: As the films move further past the Brian and Dom era, more characters are being brought in to test the group’s dynamics. These include villain-then-tenuous friend Deckard Shaw (Jason Statham) and the mysterious Mr. Nobody (Kurt Russell).
Sean: Sean Boswell (Lucas Black) is the protagonist of Tokyo Drift. Because of the series' wacky chronology, he sat out three movies and returned in Furious 7 — but only in a couple of scenes.
The most beautiful thing about the Fast & Furious franchise is that it accidentally invented a prequel trilogy, then stuck it in the middle of the run, and it's all because Vin Diesel wanted to make more Riddick movies.
As mentioned above, Tokyo Drift has nothing to do with either of the two movies preceding it, but audiences sparked to the character of Han, who trains Sean in the ways of drift racing. (Drift racing involves sliding around a curve, seemingly perpendicular to the road, in a way that seems almost magical when done well.) In the course of that film, Han dies after a race. At the film's end, when Sean has taken the title of Drift King, he is challenged by a new racer — who turns out to be Dom, who says Han used to ride with his crew back in the day.
Diesel was hoping to make more films in the Riddick franchise of sci-fi action pictures. To do that, though, he needed to get the rights for the character from Universal, which also produced the Fast & Furious movies. He agreed to cameo at the end of Tokyo Drift — as a promise of his return to the franchise in a fourth film (which eventually happened) — but instead of payment, he asked for the Riddick rights. Universal obliged, and another Riddick movie came out in 2013.
These two things — Han's popularity and Diesel's cameo mentioning Han — combined to create the franchise's twisty timeline. Because wouldn't it be fun to see Dom hanging out with Han? Yes. Yes it would. But for that to work Han had to be alive, leading to films four, five, and six being set before Tokyo Drift instead of after it. Han's death is then repeated at the end of Fast & Furious 6, revealing the villain of Furious 7 to be responsible.
The forthcoming eighth film picks up where Furious 7 left off.
Thus, the chronological order of the films is 1 - 2 - 4 - 5 - 6 - 3 - 7 - 8, and the third film (in which everybody uses flip phones and instant messaging programs) technically takes place sometime in the 2010s, even though it was released in 2006.
Here's a visual representation of that timeline:
Nah. You could watch these movies in literally any order and be fine. The chronology is complex, but it's not incomprehensible or anything.
Your best bet is the same as it is with The Chronicles of Narnia (another series where chronology doesn't reflect release order): Watch the films in the order they were released. You'll be fine! We promise!
And how!
This is "Act a Fool" by Ludacris, from 2 Fast 2 Furious. It is the most memorable thing about that film, if only because you will essentially be forced to now say the film's title in the same cadence as the song.
Make no mistake: Fast & Furious is one of the most important franchises in Hollywood. If you look at the box office totals for the first seven films above, you'll see that — outside of the blip for Tokyo Drift — they keep going up and up and up.
What's more, the franchise has been almost perfectly cultivated by its studio. Really, the only comparable franchise in Hollywood right now is the Marvel Cinematic Universe, over at Disney. And the films reflect how Hollywood has changed as they've been made.
Here are a few ways they reflect those changes.
With Fast Five, the films basically switch genres. For the first four films, this is a franchise about car racing and big chase sequences, with those elements mixing into fairly standard crime thriller plots. In Fast Five, however, the franchise takes a hard right turn into the heist movie genre, with only one (very short) car chase. And Fast & Furious 6 is much closer to a James Bond movie than anything else, with the characters having to take down a villain who could destroy the world. The franchise always prominently features cars, and the solution to every problem is always "more cars," but these aren't "car movies" anymore. It's a neat trick.
With Fast & Furious, the franchise switches templates. Before the fourth film, this is basically the Halloween franchise — three films, where the third has essentially no connection to the first two other than genre. With the fourth, though, the films accidentally become, thanks to the addition of Han to the main cast, a shared universe, where all of the characters are involved in one another's adventures — and they get there a few years before Marvel would. Along the way, they also make a stop in "the bad guys are good guys now!" territory, straight out of the Terminator movies.
The films have a surprisingly deep mythology. Okay, it's not Marvel levels of deep, but the MCU has decades of comic books propping it up. And from the fourth Furious movie on, the story of the franchise has been one story, which slowly builds on previously established character relationships and plot twists. It's kind of like a giant, cinematic TV show.
Here are some great moments from each film in GIF form.
The Fast and the Furious: Here's a quick look at how the first film portrays going really fast in a car like traveling through hyperspace in the Star Wars movies.
2 Fast 2 Furious: Literally the only moment of note in this film is when Brian jumps a car onto a boat. (This movie is bad. Did we mention that?)
The Fast and the Furious: Tokyo Drift: Drift racers have to avoid pedestrians at one of Japan's busiest intersections.
Fast & Furious: The whole opening sequence (which involves stealing gas from a truck as it's barreling down a mountain) is so cool, but here's its best moment.
Fast Five: The closing heist — involving Dom and Brian dragging a vault through the streets of Rio — is the franchise's action sequence pinnacle, but best of all is how Dom uses the vault as a weapon.
Fast & Furious 6: Dom catches Letty in midair. It's true love!
Furious 7: The seventh film has by far the most computer-assisted visual effects in the series, as you can see in this scene where Brian runs up the side of a bus that's falling off a cliff and leaps to grab hold of Letty's car. It's crazy and over-the-top in the series' best sense.
It's impossible to say why, of course, other than the fact that they are hugely entertaining blockbusters, with just the right amount of character work to go with the giant stunts. But here are my five best guesses.
1) The movies feel real. Though there are plenty of computer-assisted visual effects throughout the series, the franchise attempts to actually perform as many stunts as it can. This means that when the cars crash, some stunt driver really crashed a car. It underlines the verisimilitude of much of what happens onscreen, no matter how ridiculous. This is really happening to these characters in our universe, it seems to say, not in some fantastical one.
2) The movies' dramatic stakes build slowly. The stakes of the first film literally hinge on Brian deciding whether to betray Dom. That's it. Even in Fast Five, the stakes involve ripping off one man — albeit the most powerful criminal in all of Rio de Janeiro. It's only in Fast & Furious 6 that the idea of "saving the world" comes into play, and it's almost always an afterthought there, because ...
3) Personal stakes are always more important than plot stakes. The major story of these films is the relationships between the characters and how they shift and change. If you ever watch a Fast & Furious movie, there is at least a half-hour — and often more — smack-dab in the middle of the movie where the characters talk about how they feel about each other. The action sequences become seasoning, sprinkled throughout the rest of the story to heighten it, not to define it. The series defines itself by questions of honor, friendship, family, and redemption. It is the most sensitive major franchise out there, and the most sentimental. (See also: the tear-jerking end of Furious 7.)
4) The cast is very diverse. It seems no coincidence to me that the rise of Fast & Furious — largely on the backs of films made by a Taiwanese-American director — came right as Hollywood was realizing people of color were hungry for stories in which they were prominently featured. Of the series' major actors, only Walker fits the usual white-guy-hero mold of most Hollywood films. (Diesel's full ethnicity is unknown, though he's said he's "definitely a person of color.") That's proved quietly revolutionary.
5) This series isn't afraid to be stupid. From Tej and Roman's comic relief to Hobbs's frequent one-liners to the sheer ridiculousness of many of the series' stunts, there is nothing in Fast & Furious that is above broadly winking at the audience about how silly the entire enterprise is. That lack of self-seriousness is hugely welcome in the current blockbuster climate — and another link between this franchise and the Marvel movies.
The eighth film, The Fate of the Furious, arrives April 14 — and features Charlize Theron and Helen Mirren! — but in the wake of Walker’s 2013 death, the franchise will have to pivot from the relationship that formed its core for most of the first seven films. (Walker had completed enough of Furious 7 to appear in that film, and the filmmakers were able to construct a fitting coda for his character.)
The eighth film won’t be the franchise’s last, either. A ninth and 10th film are planned, and one thing’s for certain: They’ll probably involve Vin Diesel staring at a seemingly unsolvable problem, then smiling and driving a car through it.
When the newspaper publisher formerly known as Tribune Publishing changed its name to "Tronc," people started snickering. When the company released this video touting Tronc’s disruptive new business strategy, it was subjected to merciless mockery from across the internet:
"It’s about meeting in the middle," says Tronc chief digital officer Anne Vasquez in the video. "Having a tech startup culture meet a legacy corporate culture and then evolving and changing."
"That’s really the fun part," she says, with no hint of excitement on her face. "That’s exciting."
Reforming the "legacy corporate culture" at Tronc’s stable of local newspapers — including the Los Angeles Times, the nation’s fourth largest by circulation — doesn’t actually sound all that fun. But Tronc’s effort to reinvent local newspapers for the internet age is pretty important.
People in major cities like Orlando and Chicago rely on the journalism performed by Tronc papers, and those publications have suffered from wave after wave of layoffs over the past decade.
Painfully scripted delivery aside, the video shows Tronc management making a sincere effort to change the company’s culture and business model to adapt to the realities of the internet. The problem is that this task is stupendously difficult, and it doesn’t sound like Tronc has found a strategy that is likely to work.
In the late 20th century, owning a newspaper like the Hartford Courant or the Baltimore Sun was highly profitable. Tronc owns about 10 of these newspapers around the country.
Thanks to decades of industry consolidation, most major cities had only one or two daily newspapers, making them de facto monopolies and allowing them to charge premium rates for advertisements.
Competition from the internet changed all that:
Between 2004 and 2014, newspapers’ print advertising revenues fell by almost two-thirds, from $47 billion to $16 billion. Digital advertising generated $3.5 billion in 2014 — nowhere near enough to make up the difference.
Newspapers’ basic problem is that they were built for a world in which consumers got a wide variety of timely information in one big newspaper bundle — not only local news, weather, and sports coverage but also national and international news, national sports coverage, the comics page, movie reviews, and so forth.
But on the internet, these functions are increasingly unbundled. People can get their political news from Politico, weather reports from Weather.com, sports news from SB Nation (including local SB Nation blogs for their local sports teams), and so forth. So not only do people spend less time on a particular newspaper’s website than they once spent reading the print newspaper, but the increased competition for ad dollars means newspapers can’t charge as much.
The best-known newspapers —  the New York Times, the Wall Street Journal, and the Washington Post — have benefited from an offsetting advantage: Their brands are so strong that they’ve been able to take their product national and attract millions of new readers. This has worked especially well for the Times and the Journal, both of which have convinced huge numbers of readers to sign up for their paywalls.
But this isn’t really a viable option for midsize Tronc newspapers like the Orlando Sentinel or the San Diego Union-Tribune. Many readers outside of Orlando and San Diego haven’t even heard of these newspapers, and they certainly aren’t the kind of iconic brands that can attract paying subscribers.
So for the past decade, the kind of midsize newspapers that make up the bulk of Tronc’s portfolio have been fighting the relentless force of economic gravity. Revenues keep going down and down, forcing more and more layoffs.
The solution to midsize newspapers’ woes seems obvious: The papers need to refocus on areas where they have a comparative advantage — especially local news — and they need to use the internet to become leaner and more efficient. There is a significant audience for local news, and organizations like the Orlando Sentinel and the Hartford Courant have strong local brands that make them ideally positioned to deliver it.
But that’s a lot easier said than done. There’s no easy way to transform a complex organization like a daily newspaper into the radically different structure required to succeed in online news. A daily newspaper’s structure and culture reflect the accumulated wisdom of many decades in the newspaper business. Adapting to the web means tossing out a lot of that and starting over. There’s a risk that this will mean tossing out many of the values and skills that made the newspaper successful in the first place.
Adapting to the web is likely to involve substantial layoffs — both to reduce overall headcount and to make room to hire staff with internet-specific skills. But mass layoffs are terrible for morale. They can cause friction between a newspaper’s editorial and business wings and can scare away a newspaper’s most talented personnel.
Changing a newspaper’s culture and processes to adapt to the web is even harder than reducing its headcount. An organization’s structure and internal processes tend to be extremely durable — once people get used to doing things a particular way, it’s very difficult to get them to change.
That’s especially true because newspapers are still going to have to put out a physical publication for another decade or more. Print ad revenue may have fallen by two-thirds, but newspapers’ remaining print revenues are still worth about five times as much as digital ad revenue. So news organizations have to straddle a line between putting out an adequate print product in the short term while managing a long-term shift to the web.
This brings us to Tronc’s new video. It’s easy to mock (I did it myself), but it’s also important to give Tronc credit for trying. Tronc was absolutely right when it said in a tweet yesterday that "change can be terrifying, but we know what happens if we do nothing."
Tronc’s corporate thesis seems to be that digital technology is the source of its woes, and digital technology can also be its salvation. And once you strip away the buzzwords, most of its ideas seem sound.
Tronc plans to use software (which it calls "machine learning" and "artificial intelligence") to help reporters with the more tedious parts of writing a story — for example, choosing a photograph or video to accompany the story.
Tronc also plans to focus on embedding more videos in Tronc stories. Video ads pay better than old-fashioned banner ads, and so a lot of online news organizations have made video content a priority — here at Vox, we have a team that does exactly what Tronc is talking about, embedding videos in high-traffic posts.
Then there’s this:
It’s not clear why these newspapers are in outer space, but the basic idea seems sensible — Tronc’s corporate headquarters will have a team whose job is to help avoid duplication of effort and maximize the audience for content created by Tronc papers. If the Baltimore Sun’s restaurant critic writes a popular article that’s not Baltimore-specific, the content optimization team will look for ways to drive readers from other papers to the article.
The basic problem the company is trying to solve is that a midsize newspaper like the Hartford Courant doesn’t have either the culture or the scale required to build technology tools that allow its journalism to have the maximum possible impact and generate the maximum possible revenue. So Tronc is trying to build some technology tools that will be available for all of its papers to use.
That’s a fine theory. The problem is that making this actually work is going to be really difficult.
The basic issue is that these kinds of tools and strategies only work if the corporate office gets buy-in from rank-and-file reporters and editors. Tronc’s new content optimization tools won’t do any good if reporters ignore them.
Conversely, reporters are only going to use these tools if they actually help them do their jobs better. Centralizing development creates a danger that developers will build tools that sound like a good idea on a white board but turn out not to actually help reporters do their jobs. The more ambitious the plan is, the longer it will take for them to bring it to fruition and discover that it’s not working as they expect.
So the key to making the Tronc vision work is going to be to find ways to get Tronc’s software developers and its reporters actually working together. This tends to work best by starting with small experiments, then scaling up those experiments if they work well. The Washington Post, where I worked from 2013 to 2014, has had some success with this, launching a series of blogs and expanding the ones that caught on with the public.
And this is why I’m skeptical that Tronc’s ambitious reinvention plan will actually work. The thing the company needs most isn’t a splashy video laying out a grand vision for the future of journalism. It needs concrete examples of times Tronc’s technical talent boosted the profile of specific reporters at specific local newspapers.
Buzzword-laden promotional videos are going to make Tronc’s seasoned reporters roll their eyes and go back to doing their jobs the way they always have. If Tronc wants to actually get reporters and editors excited, it needs to start racking up a bunch of small wins in some papers that it can replicate in others.
Correction: I got the Tribune Company confused with Tribune Publishing.
This afternoon, the Federal Reserve will announce whether it's going to raise interest rates for the second time since 2008. And despite months of chatter from Fed officials about impending rate hikes, it looks like they’re likely to hold off on any increase for now.
When the Fed last raised rates in December 2015, the central bank predicted it would raise rates four more times in 2016. In March, it revised the forecast down to just two interest rate hikes for 2016. Last month, Fed Chair Janet Yellen said that the Fed was likely to raise rates "gradually and cautiously" over the next few months — perhaps as soon as the June meeting that’s happening this week.
But then the Labor Department released the worst jobs report in years, killing chatter about a June rate hike. Higher interest rates slow economic growth, and Fed officials are expected to conclude that the economy can’t afford higher interest rates right now.
This pattern — the Fed talking about imminent interest rate hikes but then delaying them due to disappointing economic performance — has been playing out for a couple of years. A lot of commentators simply treat it as bad luck, with the Fed as a mere spectator. But that misunderstands what's going on.
In reality, the Fed’s constant chatter about raising rates is itself an important cause of the economy’s sluggish performance. Markets and business leaders pay close attention to Fed statements. When Yellen signals that higher interest rates — and, consequently, slower growth — are imminent, companies respond by cutting investment spending. The result is a self-defeating feedback loop.
To understand why Fed statements can have such a big impact, it's helpful to think about things from the perspective of a business considering whether to start building a new factory. One thing the company’s CEO will likely do is ask an economist for a forecast of economic conditions. It makes more sense to open a factory if the economy is on the verge of a major boom than a recession.
Of course, no one — not even someone with a PhD in economics — knows exactly what’s going to happen to the economy. But Fed policy has a big impact on the economy's trajectory.
A perceptive forecaster will notice that the Fed seems determined to raise interest rates (and slow the economy) as soon as doing so won’t be disastrous. This means that the odds of a 1990s-style boom are fairly low, and the odds of a premature rate hike triggering a recession is higher than it would otherwise be.
Fed policy has a big impact on the economy's trajectory
Hence, every time Yellen reiterates that interest rates are likely to happen soon, the nation’s economic forecasters revise their forecasts downward a little bit. That causes the nation’s businesses to spend a little less on new investments. Less investing spending, in turn, means the economy grows a little bit more slowly. And a slowing economy forces the Fed to delay its interest rate hike.
In other words, the fact that the Fed constantly has to delay interest rate hikes in response to bad economic news isn’t just a matter of bad luck — it’s partly a result of the Fed’s own actions. We’re getting a slow economic recovery because the Fed has been signaling that it wants a slow recovery — or at least that it doesn't care enough about faster growth to make that its priority.
If the Fed wants a more robust economic recovery, it needs to convince markets that it wants a faster recovery. To do this, Yellen and other Fed officials need to stop talking about interest rate hikes and instead talk about how they're dissatisfied with the current pace of economic growth. They could say they want to see higher growth and are willing to risk moderately higher inflation in order to get it. They might even want to hint that their next move might be a rate cut rather than a rate hike.
Ironically, this strategy could actually get the Fed back to "normal" interest rate levels more quickly than its current policy of constantly talking about — and then delaying — interest rate hikes. The Fed keeps delaying interest rate hikes because the economy is underperforming, and the economy keeps underperforming because businesses don’t believe the Fed will allow faster growth. But if economic growth and inflation start exceeding expectations, then the Fed will be able to raise rates without triggering fears of more years of poor economic performance.
The larger problem here is the Fed’s ad hoc strategy for setting interest rates and explaining future decisions to the markets. At a fundamental level, the Fed’s job is to set clear and realistic expectations for the economy’s growth. If businesses believe the economy will grow quickly, they’ll invest more and help make that forecast come true.
The economy has gotten stuck in a low-inflation, low-growth, low–interest rate rut
But right now the Fed is doing a terrible job of this. The economy constantly falls short of the Fed’s projections, and the Fed keeps talking about interest rate hikes anyway. As a result, its projections have less and less credibility, and the economy has gotten stuck in a low-inflation, low-growth, low–interest rate rut.
A better approach would be for the Fed to explicitly put economic growth at the center of its decision-making. The best way to do this is with a technique called nominal GDP targeting, which has been endorsed by prominent economists like former Obama adviser Christina Romer. Under this approach, the Fed would commit to keeping the total amount of spending in the economy — in nominal terms, not adjusted for inflation — growing at 5 percent per year. If that means cutting interest rates or even restarting unconventional programs like quantitative easing, that’s what the Fed would do.
If the Fed were able to make this pledge credible, it would reverse the current bad equilibrium in which business pessimism causes the economy to consistently undershoot the Fed’s projections. If businesses believed the economy were really going to grow as fast as the Fed projected — because the Fed was committed to doing whatever it takes to hit the target — then businesses would be more inclined to spend money on new stores and factories. Growing business confidence, in turn, would help the Fed reach its targets. This would be a virtuous cycle, instead of the vicious cycle the Fed is stuck in right now.
In one of the year's biggest technology deals, Microsoft is buying LinkedIn for $26 billion.
If you’re in a profession that makes heavy use of LinkedIn, this deal may make perfect sense to you. But if you're in a profession that doesn't use LinkedIn much, you might be surprised to learn that LinkedIn is not only still in business but is worth $26 billion.
But this is no blunder. LinkedIn isn’t a very cool company, but neither is Microsoft, and LinkedIn has a thriving business focused on helping professionals find jobs and companies find workers.
Beyond the dollars changing hands, the acquisition of LinkedIn cements a broader shift in Microsoft’s corporate strategy that many consumers still haven’t noticed. Microsoft's early success came from dominating the market for PC software, followed by a period of struggle in which it tried to basically copy that business over to the mobile world and failed.
But under the leadership of relatively new CEO Satya Nadella, Microsoft is shifting to become a company that primarily sells online services to business customers. LinkedIn fits this new strategy perfectly, and it will help Microsoft both broaden the set of business customers it can serve and deepen the relationship with those it already serves.
I remember the surprise I felt a couple of years ago when I learned that LinkedIn has been enjoying robust growth. I joined LinkedIn about a decade ago, but I didn’t find it very useful. I gradually became more annoyed by the deluge of emails from distant acquaintances asking to "add you to my professional network on LinkedIn," so I eventually deleted my account, hoping that would make the emails stop. (It didn’t.)
But my experience is not universal. While journalists like me do most of their professional networking on Twitter, there are lots of professions where LinkedIn is considered an essential networking tool. Today the site has more than 100 million monthly active users.
LinkedIn is most valuable in professions where a bulging Rolodex was once a prized professional asset. If you are a sales professional, for example, LinkedIn is both an indispensable way to learn about potential clients and an essential way to find out about new job opportunities.
And while LinkedIn’s audience isn't as big as mainstream social networks like Facebook, Twitter, or Instagram, it's a highly lucrative audience. Companies are willing to spend considerable sums of money to find the best employees, and LinkedIn effectively has the world’s largest Rolodex of skilled professionals. LinkedIn's "talent solutions" business — charging businesses to post job ads and provide other recruiting services — accounted for almost two-thirds of LinkedIn’s $3 billion in revenue.
LinkedIn also makes money selling premium subscriptions to LinkedIn users and helping users in sales occupations find other users who may be interested in buying their products.
And depending on how you measure it, LinkedIn is already profitable. According to generally accepted accounting principles, LinkedIn took a modest $46 million loss in the most recent quarter. But like many technology companies, LinkedIn prefers an alternative method of computing profits that excludes the value of employees’ stock-based compensation. This measure shows the company earning a hefty $99 million in profits.
Buying LinkedIn makes good sense for Microsoft too. It represents one of the most significant steps in Nadella’s effort to reinvent Microsoft from the leading PC software maker to a company that sells business technology services more generally.
Microsoft’s initial success came from selling software for PCs — most notably the Windows operating system and Office productivity suite. During the 1990s and 2000s, Microsoft built on its dominance of the PC market by selling a growing portfolio of licensed software that runs on corporate servers — like the Exchange email server, SQL Server database, and IIS web server.
But over the past decade, Microsoft has faced two big disruptive threats. First was the online app revolution led by Google. People increasingly used online products like Gmail and Google Docs instead of desktop software like Microsoft Outlook and Microsoft Office.
Next came the mobile revolution, led by Apple. People increasingly used smartphones and tablets running Apple’s iOS — or Google’s Android — instead of Microsoft software.
In the waning years of CEO Steve Ballmer’s tenure, Microsoft made a series of increasingly desperate attempts to meet these threats head on. Microsoft responded directly to Google with products like the Bing search engine and Bing maps. It responded directly to Apple with the Windows Phone. But these products didn't catch on, and the efforts cost Microsoft hundreds of millions of dollars in losses.
Under Nadella, Microsoft's new CEO, the company finally seems to be accepting that it’s not going to play the kind of dominant role in the consumer technology market that it did in the 1990s. People are mostly going to perform Google searches on their iPhones, not Bing searches on their Windows Phones.
But while Microsoft has been bleeding market share among consumers, the company continues to be popular with business customers. So Nadella has focused on expanding and modernizing the company’s business products.
Because companies often invest millions in large, multiyear technology projects, they tend to be less fickle than consumers. If your corporate IT system is built on Microsoft software today, you’re going to be very interested in buying additional Microsoft software tomorrow. So Microsoft has been very successful at upselling existing customers on additional software products that work within the Microsoft software ecosystem.
At the moment, one of Microsoft’s fastest-growing products is its Azure cloud computing platform. This is a subscription-based service that allows businesses to run software in Microsoft’s data centers instead of on servers they run themselves. Microsoft has also been shifting customers to Office 365, an online, subscription-based version of its productivity suite.
In short, there are two big themes to Microsoft’s reinvention. First, Microsoft is deemphasizing the consumer market and focusing on business customers. Second, Microsoft is shifting from selling individual copies of software to run on customer-owned hardware to selling online services supported by subscription fees and advertising.
It’s obvious how Microsoft’s acquisition of LinkedIn dovetails with Microsoft’s shifting business strategy. There’s a lot of overlap between LinkedIn’s user base — corporate professionals — and Microsoft’s customers. And LinkedIn is already providing online services rather than selling software.
There are also some specific ways Microsoft and LInkedIn hope to strengthen each other’s products. For example, LinkedIn offers a Facebook-style newsfeed to its users. Microsoft plans to integrate this newsfeed into the Office 365 user interface, allowing users to keep track of developments in their professional network while they’re working on a spreadsheet or presentation.
Microsoft also hopes to integrate data from LinkedIn into Cortana, the personal assistant that is Microsoft's answer to Siri and Google Now. So a future version of Cortana may be able to look up the phone number of a LinkedIn contact or tell you about mutual friends.
Access to LinkedIn's data will be especially useful for Dynamics, Microsoft’s customer relationship management software. You probably haven't heard of CRM software, but it’s considered an essential software tool for any company that maintains long-term relationships with customers. Microsoft hopes to use data from LinkedIn to enhance Dynamics, giving customers access to more data about their customers and helping them find new ones.
Gawker Media, the company behind the Gawker.com website as well as sites like Jezebel and Gizmodo, filed for bankruptcy on Friday. The company was forced to take the drastic action after a jury awarded former pro wrestler Hulk Hogan $140 million in damages — a judgment the media company can’t afford to pay.
The bankruptcy process should protect Gawker from its creditors while the company tries to find a long-term solution to its legal and financial woes. That will likely involve selling the company to another media company. According to the Wall Street Journal, the digital media company Ziff Davis is expected to make an initial $100 million bid for the company, and other potential buyers will be invited to make competing offers.
Gawker's bankruptcy represents a devastating blow not only for Gawker founder Nick Denton and the site's other investors but also to the sensationalistic and privacy-hostile style of journalism Gawker represents.
Gawker has aggressively pursued stories about the private lives of celebrities, repeatedly publishing stories that more traditional news outlets would have declined to publish. That culminated with the 2012 publication of a sex tape that Hogan says was made without his knowledge or consent. If Gawker’s loss is upheld on appeal, it will force other media organizations to tread more carefully with these kinds of stories.
Gawker’s bankruptcy also represents a triumph for technology billionaire Peter Thiel. He has borne a grudge against Gawker ever since it revealed that he was gay in 2007, and in recent years he has been secretly funding the Hogan lawsuit and others against Gawker Media. There’s a real worry that Thiel’s tactics could endanger the free press by giving billionaires a new weapon to use against media outlets they don't like — a weapon that has already been used against at least one non-Gawker outlet.
Gawker is infamous for publishing stories about the private lives of the rich and powerful (and, in some cases, people who aren’t particularly rich or powerful) that more conventional media organizations would not have published. In one of its most infamous stories, Gawker reported on a New York media executive soliciting the services of a male escort. The piece was later removed after founder Nick Denton decided that the story had gone over the ethical line.
Outing gay people is something of a specialty for the digital gossip rag. Gawker was one of the first to report that CNN anchor Anderson Cooper was gay in 2009. In 2013, Gawker reported that Fox News anchor Shepard Smith was romantically involved with a male staffer.
And one of the early targets of Gawker's outing campaign was Peter Thiel. A 2007 post called "Peter Thiel is totally gay, people" apparently marked the start of Thiel's vendetta against the site.
Still, the Hogan video represented a new low for Gawker. The video of Hogan having consensual sex with the wife of a radio shock jock (who arranged the encounter and made the videotape) had no obvious news value, but Gawker decided to publish it anyway.
In court, Hulk Hogan's lawyers sought to portray Gawker as an organization without a moral compass. It wasn't a hard argument to make. During one deposition, Hogan's lawyers asked a former Gawker editor if there were any situation in which a celebrity sex tape would not be newsworthy.
"If they were a child," replied the editor, Albert Daulerio. "Under what age?" the lawyer asked.
"Four," Daulerio replied sarcastically.
As a result, arguments about media freedom fell on deaf ears in the jury box. Jurors didn't buy arguments that the First Amendment protected Gawker's right to humiliate random celebrities by publishing video of their most intimate moments.
Gawker is filing for bankruptcy under Chapter 11 of the bankruptcy code, which provides companies with protection from creditors while they reorganize their finances. The company has secured $22 million in debtor financing to give it some breathing room as it looks for a long-term solution.
That long-term solution will likely be a sale to another media company. Ziff Davis will reportedly offer $100 million, and if Hogan ultimately wins the case on appeal — or settles — a lot of that money will go to him.
If all goes well, Gawker and its sister websites will be able to continue operating under new management — and perhaps different editorial standards. Gawker's underlying business seemed to be thriving until it got into legal trouble. A version of Gawker Media that’s more careful about coloring inside the lines could be profitable, perhaps immensely so.
The larger significance of the Gawker case is the role it will play in shaping how journalists weigh the competing interests of privacy and free speech. In recent years, we've seen a number of cases where news sites have published photos, videos, and other private information about famous and not-so-famous people.
The most extreme form of this, known as "revenge porn" has triggered a backlash from privacy advocates and feminists who argue that publishing sexual content without its subjects' consent is a deep violation of their rights. But until recently, it wasn’t clear how the law viewed these claims.
But in the past couple of years, these issues have seen greater attention in the courts. The proprietors of the most egregious "revenge" porn sites have faced criminal prosecution for violating the privacy rights of their non-famous victims.
The Gawker case was different because it involved a prominent media organization and a famous subject, former pro wrestler Hulk Hogan. Gawker argued that Hogan was a public figure, and that his decision to talk about his sex life on programs like The Howard Stern Show made his sexual acts matters of public concern. If Gawker wins the case on appeal, it could give media organizations broad leeway to pierce the privacy of celebrities.
Whatever your view of Gawker’s journalism — and personally, I think publishing the Hogan tape was indefensible — the case does raise questions about whether billionaire-funded lawsuits could threaten freedom of speech. Hogan didn't fight his case alone; he was aided by a billionaire who was motivated by a broader antipathy toward Gawker’s style of journalism.
And Gawker isn't the only publication to be targeted by a disgruntled billionaire. Last year, the liberal magazine Mother Jones defeated a defamation lawsuit filed by Republican donor Frank VanderSloot. Winning the lawsuit cost Mother Jones, a relatively small nonprofit organization, and its insurance company $2.5 million in legal fees.
If VanderSloot's goal was to punish Mother Jones for writing an accurate but unflattering story about him, a loss was almost as good as a victory. His lawsuit sought $74,999 (staying just under the $75,000 threshold that would have allowed Mother Jones to move the case to federal court and away from an Idaho jury that might have favored the hometown plaintiff). So "winning" the lawsuit cost Mother Jones and its insurance company 30 times as much as the amount they would have had to pay if they had lost.
What was really ominous was what happened after VanderSloot's loss. He "announced that he was setting up a $1 million fund to pay the legal expenses of people wanting to sue Mother Jones or other members of the 'liberal press.'"
As far as I know, no one has taken him up on the offer. But the threat to freedom of the press is obvious. Any news organization doing its job is going to make some enemies. If a wealthy third party is willing to bankroll lawsuits by anyone with a grudge, and defending each case costs millions of dollars, the organization could get driven out of business even if it wins every single lawsuit.
Thiel insists that he has no quarrel with news organizations that conform to mainstream journalistic norms. But the key thing about Thiel’s strategy is that he didn't sue Gawker for outing him — a case he probably would have lost. Instead, he waited for years until he could find other plaintiffs with stronger cases.
That's a tactic that any billionaire could use against any news organization. And because most news organizations cover a wide variety of topics, the story that provoked a billionaire's ire might have nothing to do with the stories that actually trigger a lawsuit funded by that billionaire.
In short, Thiel's war on Gawker could become a template for other extremely wealthy people with personal or ideological scores to settle against news organizations. And that’s something to worry about even if you think Gawker deserves what it’s getting.

Few companies have enjoyed more hype over the past few years than electric carmaker Tesla. And not without reason: Tesla is the most successful automaking startup in decades and has almost singlehandedly made electric cars cool.
Yet the automaker has also been struggling with the quality of its vehicles. On Thursday, the National Highway Traffic Safety Administration revealed it was investigating a possible problem with the suspension of Tesla's flagship Model S sedans. The reported flaw is the latest in a series of quality and reliability problems with Tesla's vehicles.
Industry analyst Edward Niedermeyer, who blogs at the Daily Kanban, argues that Tesla's challenges with vehicle quality are only going to get worse in the coming years. Tesla is preparing to release the Model 3, whose modest $35,000 price tag is designed to appeal to mainstream customers. And Niedermeyer argues that middle-class customers are less forgiving of quality problems than the wealthy customers Tesla has served so far.
Tesla's basic problem, Niedermeyer argues, is culture. Industry leader Toyota conquered the American car market with a rigorous manufacturing process that emphasized quality and reliability above all else. But Tesla has a freewheeling Silicon Valley culture that values innovation and creativity over reliable execution.
We spoke by phone last week. The conversation has been edited for length and clarity.
Timothy B. Lee: You're skeptical that a Silicon Valley company like Tesla can become a major player in the auto business. Why do you think cars are different from software?
Edward Niedermeyer: To boil it down to the most essential issue, it's a question of scale. With software, you have a fixed cost of development that is oftentimes quite high, but once you have a viable product and you pay off that fixed cost, your variable cost to scale beyond that is almost nonexistent. You're literally just copying code.
With automobiles, not only do you have immense fixed costs in research and development, tooling up factories, creating testing, but once you've done all the development work for a car, you still have a process of scaling. Not only are the variable material and labor costs much higher than in software, but you also have a lot of details that can go wrong.
Cars have become so reliable and so easy to use that we think about them less than we ever have in the 100-plus-year history of the automobile. This is one reason we don't appreciate this depth of complexity. Not only are cars different from software in very fundamental ways, they're much more complicated than anything else consumers buy.
Cars use a wide variety of materials, built into components and subassemblies by massive global supply chains. Car companies have to choose and develop the right materials and components, maintain their uniformity and integrity throughout that supply chain, and ensure that they operate reliably in almost every imaginable condition on Earth.
A great example is the problem of mold growing from inside the Model S's roof, particularly in Norwegian cars. Because its large panoramic sunroof is difficult to manufacture and install to a precise specification, Model S roofs often leak. A lot of those leaks are so small that customers might not notice. But because Tesla used an organic-fiber pad at the edge of the sunroof, aggressive molds invade at alarming rates in certain climates. This kind of complex, cascading defect is why automakers value their accumulated institutional knowledge and spend years testing vehicles.
TBL: It seems like Tesla's early cars — the 2008 Roadster and the 2012 Model S — were lauded for their innovative designs and were well-received by customers. But you're skeptical about the Model 3, which is more affordable and aimed at a mass market. What's the difference?
EN: It's a common misperception that the more expensive the car, the more people expect out of it. The opposite is true: the cheaper the car, the more people tend to rely on it, and the more reliability and quality come into play.
The car business is a very risk-averse business by nature. It's capital-intensive and relatively low-margin. The first 50 years or so after the Model T (in 1908) was focused on technology development. People pushed the limits in terms of power, styling, futurism.
Since the 1970s or so, it's reverted to a kind of more pragmatic, utilitarian mode. The market has become more mature. Toyota and Honda have really made their names on quality and reliability, not exciting futuristic values.
In a lot of ways, Tesla is a throwback to an earlier era of the auto industry. They tap into the idea that there is new technological space to be conquered; you get there by focusing on performance, on building a very attractive, appealing car. That's what Ferrari and Lamborghini did between the 1930s and the 1960s.
I think that parallel is worth looking at, because neither Ferrari nor Lamborghini is known for quality. If you operate in the high end of the market, consumers appreciate performance and design. If their Ferrari or Lamborghini breaks down, they have their chauffeur take them in a Mercedes or a Lexus.
It's not the end of the world that Tesla's quality has been bad so far, because they're operating in a luxury space. But as they move down market with the Model 3, reliability and quality are going to be real issues. The level of quality they've achieved in the Model S is not going to be sufficient to succeed in the $30,000-to-$50,000 price range.
TBL: Is it really that hard to improve manufacturing quality? Elon Musk is a smart guy, and he recently put his desk at the end of the Model X assembly line so he can personally keep an eye on the progress there.
EN: Anything is possible. Obviously they've proven doubters wrong before. So I'm not going to say that it's impossible for them to do it again.
But raising quality is very different from the things they've done to gain market position so far.
One parallel that's worth thinking about is General Motors. This was the most successful car company in the world for the better part of a century and the most valuable company for a period of time. Then they got surpassed on quality in the 1970s, and they still haven't caught up.
So the question is what makes the quality of Japanese companies? I think you can trace that back to Toyota, which developed the Toyota production system and — just as importantly — a broader corporate philosophy called the Toyota way. It systematizes everything about the production of automobiles.
For example, the need to keep plants operating at a high rate meant you'd let defects go down the line and fix them at the end. One of the things Toyota did was when the defect came down the line, you stop the line and you trace the defect back to its root and fix it, then you restart production. This is just one example.
To this day, they're still the leaders in quality. Nobody has caught up with them.
TBL: But GM in the 1970s was a big, bureaucratic organization tied down with a lot of union rules. It seems like it should be easier for a young and nimble company like Tesla to pivot and adopt a more Toyota-like production philosophy.
EN: It's certainly more likely because they're not at the point where Ford and GM and Chrysler were when they faced that challenge — they already had tens of thousands of workers and faced much more inertia.
But in the first half of the 20th century, Detroit was the equivalent at the time of Silicon Valley today. Yes, Tesla is a startup culture, but they demonstrate an arrogance that is similar to the arrogance that Detroit demonstrated in the past. When a culture works really well, there's an assumption that it can be universalized. I think that shows in the thinking that Silicon Valley culture will apply to manufacturing.
But what does startup culture emphasize? It emphasizes flexibility, individual effort, and working long hours to reach ambitious goals. What it's not is regimented.
But the only way to make money in cars is at huge scale. And scale creates immense complexity. And as you go up the volume scale, it becomes more challenging. So if your goal is to make your car company a mass-market player, you have to bake in the regimentation and the production system from the get-go.
When I say companies are risk-averse, it's because success in the car business is not about reaching out into the unknown in order to achieve unprecedented things. It's about driving waste, inefficiency, and defects out of your production machine. That is what Toyota's innovations enabled it to do. It systematized every aspect of development and production.
TBL: What do you think about the approach Google has taken to the car business?
EN: Google's strategy is the counterfactual that makes me especially nervous about Tesla. Google's core technology is the autonomous drive capability, and I think they have to be closely watching Tesla and the struggles they've had. So Google has hired some very high-profile people from the car business. They have former Ford CEO Alan Mulally on their board. Lawrence Burns, the former research and development boss for General Motors, is a consultant for them. The head of their autonomous car program is John Krafcik, one of the auto industry's most respected veterans.
It's a dream team of real tier-one automaker experience. With their accumulated knowledge — and looking at Tesla's struggles — they know that building their own car is a fool's mission. They also recognize that Silicon Valley culture is fundamentally different from manufacturing culture.
They realize there are plenty of car companies and car factories in the world. Even before autonomous drive comes out, there's a likelihood that shared mobility will begin to impact demand for cars, leaving spare production capacity for autonomous vehicles.
What fundamentally sets Google apart is that these auto people know how hard building cars is. It is not only an intellectual challenge, it's a discipline challenge. Managing that level of complexity requires a certain amount of accumulated knowledge; building that from scratch is incredibly difficult.
And these systems are already highly automated. It's not like the car guys are doing purchase orders on paper. They already need to be highly software-driven in order to make current levels of complexity work. I'm not sure how much room Silicon Valley has to improve that. If they do, they should develop the capability and sell it to the car companies.
So Tesla is fundamentally an old-school car company. They sell you a desirable, high-performing vehicle that you own. Google is trying to transform mobility without becoming a car company. Their focus is on autonomy. They have the leading position right now in terms of self-driving capability. They're going to continue to build on that.
TBL: It seems like the danger of partnering with existing car companies is that they could be too set in their ways, and too resistant to making the kind of changes that are required for self-driving cars to be really successful.
EN: At first, there was this sense that Google was going to directly take on the car companies and take them out of business. The car companies, without question, have cultural biases that prevent them from wanting to develop autonomous vehicles.
These companies have been around for 100 years. They've only ever sold vehicles to drivers, and the vast majority of their profits came from selling cars to drivers. Because cars are low-margin, you have to find ways to pad that margin, and they do it with things that appeal to a driver, like a more powerful engine or a sport suspension.
Fully autonomous vehicles will be fundamentally different. But Google has singlehandedly pushed autonomy from being a science experiment to something that's going to be viable. They have forced the car industry to accept that things are changing.
So what Google is doing is very pragmatic. Instead of having this existential battle between human drivers versus robot drivers, they've shown that this technology works and argued that they need to work together. It's going to be very disruptive to car companies' business to manage the change from driven vehicles to autonomous vehicles. But they're not fighting it. They're going along with it.
I think this is something that's emerged in the last year. What both sides have realized is that Google can avoid massive investments in very low-margin aspects of the business, while car companies can stay with the times if they work with Google or other startups.
TBL: It seems like we're going to see some big changes in the car industry over the next decade. Which car companies do you see as best positioned to navigate those changes?
EN: You see two responses. You see General Motors and Nissan initially trying to get on this wave of excitement and saying, We're going to set aggressive timelines for autonomous capability. GM made the biggest investment by buying Cruise. I've done a bit of research on Cruise and I'm not super convinced by them. I'm not convinced that GM didn't massively overpay.
Toyota has a much different approach. They are basically making a long-term investment in the research capabilities for autonomous driving. Their deployment strategy is super conservative. They are deploying in bits and pieces. They're starting off by putting low-level semi-autonomous safety functions in all of their vehicles.
That's in part due to their culture and in part due to their experience of the unintended acceleration scandal of 2010, where they were basically accused of having self-driving cars. As far as I can tell — and I spent a lot of time covering it — it was basically bullshit and kind of a witch hunt.
But the legal liability risks are very high. It's very easy for people to make mistakes and blame the car for their mistakes. So in some ways that's an incentive to go full autonomy. But even for a company like Toyota with $80 billion in the bank, there could be liability issues that could challenge the fate of the company. So they are incredibly conservative about deployment, and they will not deploy anything unless it works in 99.9 percent of use cases.
That contrasts with what Tesla is doing, a public beta test. They say they are. They admit it. Frankly, that is an incredibly risky proposition. I think Tesla has a halo right now. I think we have a celebrity news cycle where we tend to build things up and break them down. Once Tesla reaches a critical point in that hype cycle, the public beta test of autopilot software could be part of what destroys them as a company.
I personally tend to like Toyota's approach, because they accept and own the conservative nature of the business. So they don't fool themselves that they're going to do this leapfrog approach.
One of the dangers of expressing opinions on the internet for a living is that you sometimes express opinions that turn out to be totally incorrect. After I published a piece about the failure of home 3D printing on Monday, the American Conservative's Robert VerBruggen reminded me that I had a very different perspective on the topic four years ago:
@RAVerBruggen People in 1975 couldn't think of many programs they'd want to run on a personal computer.
@RAVerBruggen I think you're underestimating hindsight bias. Those are obviously useful on today's powerful computers.
Obviously my thinking on this topic has changed. And I think there's a broader lesson for how we think about technology as it becomes increasingly intertwined with the physical world.
As I say in these tweets, people underestimated the first PCs in the 1970s. They were so underpowered that you could hardly do anything useful with them. So lots of smart, sophisticated, thoughtful people dismissed them as overpriced toys. Then, as everyone now knows, PCs took over the world.
The same thing happened with the internet. In the 1980s it was hard to use and couldn't do very much. People mocked the idea that it could eventually support billion-dollar businesses. Then we got Amazon, Google, and Facebook, and people stopped laughing.
It happened again with mobile phones. People mocked the concept of using phones to check email or take photos. And then ... you get the idea.
By 2010, these stories had become the default way technology pundits like me looked at the world. "New technologies always look overly complex and underpowered at the outset," we'd say. "But they don't stay that way."
But in this decade, we've been seeing more and more examples where the PC analogy doesn't seem to be working.
When Google Glass was introduced in 2012, supporters saw it as the next great computing platform. But normal people weren't actually that enthusiastic about having computers on their faces, and after several years of mockery, Google has put Glass on the back burner.
In 2014, Google spent $3.2 billion to acquire the smart thermostat company Nest. Its CEO, Tony Fadell, quit last week after struggling to expand to other "smart home" products. Other companies have rolled out "internet of things" products like smart lightbulbs and wifi-connected slow cookers, but consumers haven't seemed very interested.
Though iRobot has experienced modest success building its Roomba robotic vacuum cleaners, it has struggled to produce follow-on products, and Roombas remain a niche product 14 years after its introduction.
Home 3D printing was introduced with great fanfare in 2012. But so far there's been no sign that consumers want 3D printers in their homes. Instead, 3D printer companies have pivoted to selling their wares to commercial customers.
In each of these cases, optimists a few years ago argued that we needed to give the products more time to mature. They often drew explicit parallels (as I did with 3D printers) to the early days of the PC.
But there is a big difference between these products and the famous examples of the PC and the internet.
People underestimated early PCs because they were drastically inferior to their successors. A modern PC isn't two, 10, or 100 times better than an Apple II circa 1977 — it has 100,000 times more computing power.
As a consequence it can do a lot of things — like editing large graphic and video files, playing sophisticated video games, and rendering complex webpages — that would have been far beyond the capabilities of the first PCs. The first PCs were slow, expensive, and bulky, but people just had to wait a few years for Moore's law to produce computer chips that were faster, smaller, and more affordable.
But not all problems can be solved with more computing power. If an errant cat toy jams your Roomba, no algorithm is going to get it unstuck. More sophisticated software won't necessarily make people interested in having computers on their faces. A faster computer chip isn't going to bring down the cost of the fairly expensive plastic used by most entry-level 3D printers — nor will it make consumers interested in having a lot of plastic junk lying around the house.
So when trying to predict if a new digital product will get better over time, it's helpful to ask whether the big problems are related to a lack of computing power or something else. For example, I'm bullish about self-driving cars because the challenges there mostly are software-related. It seems likely that collecting enough data and throwing enough computing power at it will eventually lead to cars that can drive themselves more safely than could human beings.
But a lot of other futuristic gadgets are being held back by physical complexity, consumer inconvenience, or a simple lack of value for consumers. These are not problems that more computing power can fix.
A few years ago, Nest was widely viewed as one of Silicon Valley's brightest stars. Founded by Tony Fadell, a key figure in Apple's iPod team, Nest aimed to produce a line of user-friendly, connected home appliances. Given Fadell's Apple background and Nest's focus on hardware, many people wondered if Nest would become the new Apple.
But last Friday, Fadell announced he was stepping down as Nest's CEO after months of criticism for an erratic management style and slow growth at the company.
The company's first product, the Nest Learning Thermostat, got rave reviews when it was introduced in 2011. Nest added a smoke detector to its product line in 2013. Google was so impressed by the company that it paid $3.2 billion for it in 2014.
But since then, Nest has struggled. It acquired Dropcam in 2014 and rebranded Dropcam's flagship security camera as the Nest Cam in 2015. Beyond that, Nest hasn't introduced a single new hardware product, and it looks increasingly unlikely that it can justify that lofty acquisition price.
It's not surprising that Fadell is stepping down after years of disappointing performance. But Nest's problems go beyond the failings of any single CEO. The larger problem seems to be that consumers just don't seem that interested in buying a bunch of expensive "smart home" gadgets.
The beginning of the end of Fadell's tenure as Nest CEO came in March, when the Information's Reed Albergotti published a scathing portrait of Fadell's leadership. Albergotti portrayed a company in chaos, with low morale and a stalled product road map. Albergotti placed much of the blame for Nest's poor performance on Fadell and his abrasive and erratic management style.
According to Albergotti, more than half of the 100 Dropcam employees Nest hired when it acquired the company two years before had left by March 2016. In this kind of situation, most CEOs would be diplomatic. Not Fadell. "A lot of the employees were not as good as we hoped," Fadell told Albergotti in an interview.
Fadell's comments infuriated Greg Duffy, a Dropcam co-founder who left Nest in 2015. In a scathing Medium post, he argued that half his team had left Nest because "they felt their ability to build great products being totally crushed."
"All of us have worked at big companies before, where it is harder to move fast," Duffy wrote. "But this is something different, as evidenced by the continued lack of output from the currently 1200-person team and its virtually unlimited budget."
Fadell's critics say that he is both too prone to micromanaging subordinates and too prone to changing his mind. As a result, Nest employees seem to be stuck in an endless cycle of product revisions, causing new releases to be delayed.
Of course, much of this could have been sour grapes from a disgruntled minority of engineers. But the fact that Nest's hundreds of employees hadn't produced a new product in more than two years certainly seemed like an ominous sign.
In a Tuesday email, Nest spokeswoman Ivy Choi disputed claims that Nest has suffered from slow growth and poor employee morale. "Since Nest began shipping products 4.5 years ago, Nest revenue has grown in excess of 50% year over year," she noted.
Choi added that the most recent version of the Nest thermostat — released in 2015 — sold a million units in half the time as the previous version, and she pointed to high marks the company has earned at the employment website Glassdoor.
One reason for Nest's slow development of new hardware products is that Nest has been spending time making sure its products work together seamlessly with each other and with devices created by third parties.
There are now lots of internet-connected devices on the market, but a big problem with many of them is that they require too much effort to set up and manage. It's hard enough to convince someone that it's worth paying a premium for an internet-connected lightbulb or washing machine. It becomes an even harder sell if customers are required to separately configure devices from different companies.
Part of the value proposition for connected devices is their ability to work together — for example, to turn off all the lights in your house with a single tap on your smartphone. But this becomes more — rather than less — of a hassle if you have to open several different apps to turn off the lights.
Nest hopes to play a central role in solving this dilemma. Over the past couple of years, the company has convinced the manufacturers of a wide variety of products — from lightbulbs to washing machines — to participate in a program called "Works with Nest."
For example, you can configure internet-connected smart lightbulbs all over your house to flash when the Nest smoke detector detects a fire. Or if you have an internet-connected lock on your front door, you can program your thermostat to turn down the heat when you leave the house.
Building the software infrastructure to make all these devices work together takes more effort than merely building a suite of standalone products. But if Nest succeeds in establishing Works with Nest as an industry standard, it could give Nest a long-term competitive advantage.
When I wrote a feature article on connected devices two years ago, I argued that these tiny devices represented the latest step in a long-term evolution of the computer industry. Every decade or two, there's a new generation of computing products that is dramatically smaller and cheaper than its predecessors. The washing-machine-size minicomputer of the 1960s was displaced by the desktop PC in the 1980s, which was replaced by the pocket-size smartphone in the 2000s.
Each new generation found a much larger market than the one that came before. The PC market dwarfed the earlier mainframe and minicomputer markets. Today the smartphone industry has eclipsed PCs.
Since the smartphone revolution a decade ago, computer chips have continued to get smaller and cheaper. You can now buy a thumbnail-size computer-on-a-chip, including wifi networking capabilities, for a fraction of the cost of a smartphone. It's a reasonable guess that these tiny chips could set off another round of disruptive innovation — and that this could set the stage for the next great computing platform.
But so far, there's not much sign of this actually happening. Wifi-connected lightbulbs, thermostats, crock pots, and smoke detectors have been on the market for several years now, and they don't seem to be generating anything like the level of enthusiasm or market demand that smartphones and PCs did in previous generations.
Nest's smart thermostat has some valuable features that pre-internet thermostats were missing. But they don't offer the kind of revolutionary capabilities that caused people to line up to buy an iPhone. We just don't interact with our thermostats that much, so there's only so much a better thermostat can do to improve our lives.
In other cases, like connected lightbulbs, the value proposition is even more opaque. It's possible to think of exotic circumstances in which someone would want their lightbulbs connected to the internet. But for most people, most of the time, old-fashioned lightbulbs work just fine.
The fact that consumers have so far greeted connected household devices with a yawn suggests that the Apple business model — the high-quality, high-margin model Nest is implicitly following with its own products — might not be the one that wins this market.
Apple and its competitors have been able to sell hundreds of millions of iPhones because it's obvious why it's useful to have an internet-connected computer in your pocket. People look at their smartphones dozens of times every day, so even small improvements to the user experience are worth paying a premium for. And progress has been so rapid that Apple has been able to sell a new iPhone to customers every two to three years.
Connected home devices don't seem to be like that at all. A smarter thermostat is nice, but normal people don't spend a lot of time interacting with their thermostats. So it's not obvious that they're going to be willing to pay a big premium for the one with the best interface. And people want to upgrade their thermostats every two or three decades, not every couple of years, so the number of devices you can sell every year is going to be much smaller.
All of that means that selling smart thermostats is likely to be much less lucrative than selling smartphones.
And smart thermostats are the best-case scenario. For other connected devices — like smart lightbulbs, crock pots, and washing machines — the benefits of an internet connection seem slight and the advantage of a highly polished user interface is slighter still. When shopping for a washing machine, people mostly care about how good it is at cleaning clothes. Few are going to be upset if it has a clunky user interface and can't be controlled with an app.
Of course, it would be silly to conclude that connected devices are never going to become mainstream. Eventually, wireless chips will become cheap enough that non-technology manufacturers can incorporate them into their products without significantly increasing the sale price — much in the way that small digital clocks are now routinely incorporated into toasters, microwaves, and other appliances. And standardized software platforms will allow them to build user-friendly connected devices with minimal engineering knowhow.
But that might not leave much room for a company like Nest, whose business model depends on people paying a premium to get the best available connected devices. People may only start buying these devices en masse when they become so cheap and user-friendly that customers don't have to think about the connected features.
Home 3D printing was supposed to be the next big thing.
"You’ve heard of 3D printers, but you probably don’t own one yet," wrote Wired editor Chris Anderson in 2012. Anderson was profiling MakerBot, a company looking to bring a 3D printer into everyone's home. He compared MakerBot's new $2,200 gadget to the PCs of the 1970s.
A 3D printer lets you transform a 3D model of a digital object — say, a model of the Colosseum, a whistle, or an elaborate marble machine — into a physical object. A few years ago, enthusiasts imagined a future where ubiquitous 3D printing rendered a lot of conventional manufacturing obsolete, as people printed everything from dishes to automobile parts at home instead of buying them in a store or online.
But four years later, the home 3D printing revolution hasn't panned out, as even MakerBot spokesman Johan Broer conceded when I talked to him last month.
"We were very focused on the consumer market around 2014," he said. "Back then the expectations for the consumer market were very high."
But it turned out that the average household doesn't have a lot of need for 3D-printed goods. And when they do have use for them, it's simpler to order from an online 3D printing service than to buy a 3D printer.
"A lot of people within the industry thought the consumer market would grow faster," Broer told me in a phone interview. But the expected demand for cheap home 3D printers never materialized. So in 2015, "we changed our strategy to focus on the education and professional space."
It wasn't an easy transition. The company went through two rounds of layoffs in 2015 and had to shutter its retail stores aimed at drumming up interest among consumers. Then in April 2016, the company announced it was shuttering its domestic manufacturing operations. Instead, its products will be manufactured in China.
MakerBot's struggles in the home 3D printing business have not surprised industry analyst Terry Wohlers. "We've never felt there was a market for consumer printers," he told me in a May interview.
"This notion of consumers buying their own machine and printing for themselves just is not working out, because it's not easy," he said. "You need to have some design talent, and most people aren't designers. You need to learn design software, and most people don't want to mess with it."
And 3D printers cheap enough for the consumer market tend to be less sophisticated than the industrial-strength models, Wohlers added.
"3D printers that are affordable are limited in size, material color, surface finish, a lot of things," he said. "You're really limited as to what you're going to print with them, even if you have some design experience."
The result: Home 3D printers are too expensive for amateur tinkering but not sophisticated enough for professional use. Ultimately, they're not that compelling to anyone.
To be clear, this doesn't mean that the 3D printer market is a failure across the board. Quite the contrary. Wohlers has collected data showing robust growth in 3D printing overall even as home 3D printing companies have struggled:
Most of these sales have been to commercial and academic customers rather than home users. Engineering and design firms use the printers to help with rapid prototyping. Industrial-grade 3D printers can work with more types of materials, they can print with multiple materials at the same time, and they can print larger objects.
And while few homes are choosing to buy 3D printers, there's robust demand for 3D printing as a consumer service. Websites like Shapeways let you order 3D-printed items online. These services let you avoid all the hassle of running the 3D printer and just send you the printed result.
Unless you're in a big hurry — and people rarely have an urgent need for a plastic model of the Colosseum — ordering 3D printed items is likely to make more sense for most people. Shapeways offers a wide variety of materials — plastic, metal, ceramics, and more — more options than a consumer-grade 3D printer is ever likely to offer.
A 3D printer is extremely useful for certain tasks, like rapid product prototyping or personalization. But don't expect 3D printing to replace conventional manufacturing any time soon.
On the one hand, 3D printers are nowhere close to being able to reproduce complex gadgets. Most 3D printers can only deposit one or two materials at a time, so it's not easy to manufacture a product like a smartphone that has metal, glass, plastic, and other materials inside of it. That's to say nothing of the complex computer chips whose microscopic features are far too tiny for any 3D printer to reproduce.
On the other hand, 3D printing isn't a very efficient way to produce simple objects. Injection-molding techniques, for example, allow people to produce thousands of identical copies of plastic objects in a matter of minutes with minimal human involvement. For simple products being manufactured in bulk, conventional manufacturing techniques will just be more economical than printing them one at a time on a 3D printer.
This shouldn't be too surprising. After all, most of us have printers that — in theory — could be used to print out entire books. But in practice, it makes more sense to buy printed books produced using conventional techniques. Printing out a book on your home printer is tedious and produces an inferior result. And thanks to economies of scale, printing a book the old-fashioned way is often cheaper than home printing.
An individual retirement account (IRA) helps people shield their retirement savings from the tax man. It's especially useful for people who don't have access to an employer-sponsored 401(k) retirement plan, as well as for people who are rich enough to contribute the legal 401(k) maximum — currently $18,000 per year — and still have savings left over.
However, if you're a high earner trying to squirrel away extra cash in an IRA, you're likely to run into a big roadblock: IRAs have maximum income limits. The details are a little bit complicated (I'll explain more below), but in a nutshell if you make more than $132,000 — or more than $194,000 if you're part of a couple — you can't contribute directly to one type of IRA (called a Roth IRA) and lose a crucial tax deduction for the other type.
Presumably, Congress felt that a family making $200,000 per year was going to do fine without extra help from the tax code. But in 2005, Congress created a loophole that made these income limits effectively toothless. It's called a backdoor Roth IRA, and it provides high-income Americans with a sneaky but almost certainly legal way to save an extra $5,500 per year without paying taxes on their earnings.
A traditional IRA is like a 401(k) plan you can sign up for without help from an employer. You don't have to pay income taxes on money you contribute to your IRA, and money in the account grows tax-free. You only have to pay taxes when you start withdrawing money from the IRA during your retirement years.
The Roth IRA flips the traditional IRA on its head: You pay taxes on money you contribute to the IRA, but earnings and withdrawals are tax-free.
This is an either-or choice. In any given year, you can contribute $5,500 to a traditional IRA or a Roth IRA, but not both. Which one you should choose depends primarily on whether you expect to be in a higher tax bracket in retirement than you're in now. If you think your tax rate is going to go up, you should pick a Roth IRA; otherwise, contribute to a traditional account.
Things get more complicated as your income goes up. If you make more than $71,000 ($118,000 for married couples filing joint tax returns), you lose the ability to deduct IRA contributions from income taxes. With the biggest tax advantage of traditional IRAs eliminated, most households above this cutoff are better off investing in a Roth IRA instead.
But then when a worker's income reaches $132,000 ($194,000 for couples), she loses the ability to make Roth IRA contributions. Until 2010, people too rich to contribute to a Roth IRA just had to live with getting a smaller tax benefit from a traditional IRA. They got no tax deduction for contributing to the IRA, but there was still some benefit to being able to defer taxes on capital gains and dividends.
In 2005, Congress passed legislation that — once it took effect for the 2010 tax year — made the nominal limits on Roth contributions practically irrelevant.
You can convert a traditional IRA into a Roth IRA, but prior to 2010 you could only do this if your income was below $100,000. But then Congress eliminated that income limit, allowing anyone to convert traditional IRA money into Roth IRA money.
If a traditional IRA contains pre-tax money (e.g., the account owner took a tax deduction when he made the contribution), then the account owner has to pay income taxes when he converts the money to a Roth IRA. But wealthy taxpayers don't get an IRA tax deduction in the first place; they have to contribute to traditional IRAs with after-tax money. So when they convert a traditional IRA to a Roth IRA, they only owe taxes on the earnings — which will be small if the money was only in a traditional IRA for a short period of time.
So the backdoor Roth technique provides a two-step way for rich people to get money into a Roth IRA without running afoul of income limit. First, contribute money to a traditional IRA. Then convert the account to a Roth IRA.
I asked Jeff Levine, an IRA expert at the advising firm Ed Slott and Company, if there were any pitfalls people should watch for when making a backdoor Roth contribution.
The biggest pitfall, he told me, occurs if you already have a traditional IRA with pre-tax money in it.
"Let's say you have a $45,000 IRA account at one institution," Levine said, and that this money came from tax-deductible contributions at a time when your income was lower. Then you get a big raise that makes you ineligible for the IRA tax deduction. So "you decide to open a brand new IRA at a second institution and make a $5,000, non-deductible contribution."
You might think you can convert the $5,000 traditional IRA into a Roth IRA tax-free, since the contribution wasn't tax-deductible in the first place. But that's not how it works. The IRS treats your IRA money as if it all comes from one big bucket — as if you have a single $50,000 IRA — and treats conversions as if they drew proportionally from all of your IRAs.
In this case, since 90 percent of your total IRA funds are pre-tax and 10 percent of the money is after-tax, any Roth conversion will be 90 percent taxable and 10 percent tax-free. If you converted $5,000, you'd have to pay taxes on $4,500 of it, while only the remaining $500 would be treated as a tax-free conversion.
If you're in this situation, you have a couple of options. The best option is if you have a 401(k) plan at work that accepts incoming IRA rollovers. Then you can transfer all of your pre-tax IRA money into your work retirement account before doing a backdoor Roth conversion. Money in a 401(k) plan isn't counted when the IRS applies these IRA aggregation rules. (Click here for a detailed explanation of this strategy.)
If you don't have access to a 401(k) plan that will accept your pre-tax IRA money, then you may have to just bite the bullet and convert all of your traditional IRA money into a Roth IRA. Of course, if you have a lot of pre-tax money in IRAs, this could mean a huge tax bill. But if you expect your income to be above the Roth contribution limits for the foreseeable future, it might be worth it.
The conversion has tax benefits in its own right, since it'll save you from paying even more in taxes once you reach retirement age. And once you've done this conversion once, you'll be able to take advantage of backdoor Roth contributions every year.
A few investment experts, notably blogger Michael Kitces, have claimed that the backdoor Roth technique could get you into hot water with the IRS. The issue is a rule called the step transaction doctrine, which says that taxpayers can get into trouble if they take a sequence of otherwise legal transactions that produce an illegal result.
But Levine disagrees. "I don't have any concerns about that whatsoever," he told me, and he says he uses the technique himself.
Over the past few years, the backdoor Roth technique has become increasingly mainstream. Vanguard, one of the nation's largest mutual fund companies, has a page on its website advising clients on how to make backdoor Roth contributions with no caveat about possible legal complications. According to Vanguard's data, about 20,000 Vanguard customers made backdoor Roth contributions for the 2013 tax year, and there's no sign that any of them got into trouble for it.
If you are concerned about the fairly remote possibility that the IRS might someday start cracking down on backdoor Roth contributions, skeptics like Kitces recommend introducing a delay between the time you make the initial IRA contribution and the time you convert the money to a Roth. The longer the delay between the two steps, the harder it is for the IRS to argue that they should be regarded as a single transaction for tax purposes. A one-year delay is the safest option, but a delay of a week or a month could theoretically prove beneficial as well.
But Levine believes a year-long delay is overkill — and it means paying taxes on earnings accumulated while the money was in the traditional IRA. Levine has never heard of anyone getting into trouble for using the technique, and he notes that the IRS itself has signaled that it doesn't believe a delay is required to make the technique kosher.
One final sign that backdoor contributions are legal, Levine argues, is that the Obama administration keeps asking Congress to make them illegal. That suggests the administration believes they're currently legal. Otherwise, Obama wouldn't need Congress's help here — he could just ask the IRS to start cracking down on the practice.
And Obama has a point. Whether or not you think rich people deserve larger retirement tax breaks, the current policy makes no sense. Either rich people should be allowed to contribute to Roth IRAs or they shouldn't be — but it makes no sense to require them to go through an awkward two-step procedure to benefit from the Roth IRA's tax breaks.
The US economy created 38,000 jobs in May, the slowest pace of job growth in five years, according to disappointing statistics released today by the Labor Department. It's an ominous sign for the US economy — and for Hillary Clinton's chances of beating Donald Trump in the November election.

The US economy needs to add about 150,000 jobs a month to keep up with population growth. In the past couple of years, the economy has been doing a bit better than that, adding 200,000 jobs in a typical month.
But the May report suggests that the economy may be starting to slow down in a dramatic way. Not only did job growth fall well short of economists' expectations in May, but the Labor Department also revised its estimates for March and April job growth downward by a total of 59,000, suggesting that there are actually fewer people employed than we thought a month ago.
What accounts for the drop? One factor is the strike among Verizon workers, which cost the economy about 34,000 jobs. Those jobs should reappear in future reports. But that's hardly enough to account for a totally underperformance of more than 200,000 jobs.

There's other bad news in the report too. Over the past six months, the economy had started to reverse a years-long decline in the labor force participation rate — a sign that a healthy economy was starting to draw workers who had left the economy back in. But the latest report shows the economy has given most of those gains back, with the labor force participation rate falling from 63 percent in March to 62.6 percent in May.
And that's the right context in which to view the one piece of seemingly good news in the report: the unemployment rate falling from 5 percent to 4.7 percent. Normally, a fall in the unemployment rate would be good news, but in this case it appears that a lot of people simply stopped looking for work and left the labor force — hardly a sign of progress.
Slow economic growth is never good news, but the stakes are especially high now, six months ahead of a high-stakes presidential election. Political science suggests that the performance of the economy in the months before a presidential election has a big impact on election outcomes. In this case, poor economic performance is bad news for Democrats and Hillary Clinton in general. If this month's report signals the start of a recession, that would boost Donald Trump's chances of becoming the next president.
At the same time, it's important to note that jobs data is inherently noisy — sometimes the economy delivers a month of bad job gains and then resumes its upward trajectory. So while the latest data is a reason for workers to worry, we shouldn't panic yet.
Financially speaking, Uber's new $3.5 billion investment with Saudi Arabia isn't that significant. It is bigger than Uber's previous fundraising rounds. But Uber had previously raised a sequence of $1 billion investments over the past couple of years, so it's hardly a game changer.
But politically speaking, Uber's decision to take money from Saudi Arabia's sovereign wealth fund could become a huge deal. The Saudi government doesn't just get a 5 percent stake in the ride-hailing startup; it also gets a seat on Uber's board. That means the Saudi government will be more than a silent partner — it will have a literal seat as the company discusses big strategic decisions.
And for people worried about issues like gender equality, customer privacy, and human rights, it's hard to imagine a worse choice for Uber's newest board member. The Saudi regime is notorious for its unequal treatment of women — who aren't even allowed to drive in the Saudi kingdom — and for its disrespect for human rights in general. By cozying up with Saudi Arabia, Uber CEO Travis Kalanick is sending a clear signal that he intends to run Uber as an amoral profit-maximizing machine.
And that's a big problem, because Uber's long-term success is going to depend on earning the trust and respect of both regulators and customers. There's a good chance that car sharing will be a winner-take-all market, and Uber is trying to become the dominant player in markets around the world. Monopolies inevitably face public scrutiny and pressure for regulation, and it will be a lot harder to resist that pressure if the public views Uber as a company without a conscience.
Saudi Arabia is nominally a US ally, but the kingdom has a dismal record on human rights. According to Human Rights Watch, "Authorities subjected hundreds of people to unfair trials and arbitrary detention." The Saudi government persecutes human rights activists, subjecting them to decade-long prison sentences for advocating political reforms and talking to foreign reporters.
There's every reason to expect the Saudi government to continue its repressive policies in the coming years. And now when the Saudi government violates human rights, Uber will get bad press for it.
The stickiest issue for Uber will likely be Saudi Arabia's treatment of women. Saudi Arabia is infamous for refusing to allow women to drive and for limiting their ability to go out in public without a male chaperone. Uber is likely to face awkward questions about whether its partnership with the Saudi government amounts to an endorsement of these policies.
Uber has also faced criticism for sexual assaults committed by Uber drivers, and for allegedly downplaying the extent of those assaults. It's not clear how much blame Uber deserves for these assaults — after all, taxi drivers commit assault as well. But Uber needs to convince its women customers that it takes this issue seriously and is doing everything it can to keep passengers safe.
That's going to be harder to do now that Uber has given one of its board seats to a regime that once punished a rape victim for being alone with a male non-relative. Having a Saudi board member isn't going to prevent Uber from improving women's safety, but it does seem like a signal that women's rights are not a top priority for the company.
The Saudi royal family also invested $248 million in Uber's biggest US rival, Lyft, last December. But beyond the smaller cash figure, there were a couple of other significant differences. Lyft didn't give the Saudi royal family a board seat as Uber did. Also, Lyft doesn't have operations in Saudi Arabia. Uber does. So Uber is more directly tied to that nation's misogynistic policies.
Uber's deal with Saudi Arabia is the latest in a long line of decisions that seem to have been made without considering their impact on Uber's public image. Over the past few years, Uber has faced accusations that it has spied on its customers and suggested digging up dirt on journalists. It has generated a lot of ill will with massive surge pricing increases on busy nights.
Uber has long cultivated a reputation as a scrappy startup, willing to do whatever it takes to win. That was an appealing image when Uber was actually an underdog. But with a global footprint and billions of dollars in the bank, Uber is no longer an underdog. And when a big, powerful company adopts a take-no-prisoners approach to business, it doesn't seem charming. It seems menacing.
And that matters because the biggest long-term threat to Uber is that a public backlash against the company could lead to much stricter regulation of its business practices. So far, regulators have taken a hands-off approach in the — correct — belief that minimal regulation will allow innovation to flourish. But if Uber continues to grow — and continues to behave in ways that undermine public confidence in the company — it's only a matter of time before the political winds start to shift.
Uber has raised an astonishing $3.5 billion from Saudi Arabia's sovereign wealth fund. It's one of the biggest venture capital investments in history and brings Uber's overall fundraising haul to $11 billion. But while Uber is bragging about the investment, it could reveal a troubling trend in investment trends overall.
In the long run, economic growth depends on our ability to convert cash into productive assets like factories, trucks, machinery, or computer software. But for the most part, recent "investments" in Uber aren't like that. Uber is planning to use its billions to fund brutal, zero-sum price wars with competitors around the world.
Those investments might allow Uber to expand its share of the global ride-hailing market and make big profits for its investors. But money spent on money-losing price competition isn't investment. Price wars do nothing to increase the world's productive capacity.
So the fact that so much money is being invested in Uber — and in other companies deliberately losing millions in an effort to gain market share — could be an ominous sign. It suggests that it's getting harder and harder to spend money in ways that boost long-term economic growth.
Running an on-demand service like Uber isn't very expensive. It costs some money to build the Uber app and run the servers that power Uber's car-sharing service, of course. But the most valuable assets required to provide Uber's service — cars — are owned by drivers who work as independent contractors.
Uber says it needs money to finance expansion internationally to places like China and the Middle East. But when you run a purely online ride-hailing service that doesn't own any vehicles, there's no reason it should cost billions to expand into new markets.
Uber needs billions of dollars because it's planning to wage brutal price wars with competitors around the world. The company is planning to lose money on every ride and hope it can outlast its competitors.
I have firsthand experience with how wasteful this process can be. In 2014, I spent a week driving for Lyft. At the time, Lyft was running a promotional program where new drivers could earn $1,500 in a week if they drove for at least 50 hours. I signed up and drove 50 hours in my first week. During those 50 hours, my passengers paid a total of $596. Lyft paid me $1,500, which means that my week as a Lyft driver cost Lyft's investors $904 (I donated the full $1,500 to charity). To put it another way, Lyft's average profit margin on my rides was negative 150 percent.
This is obviously an extreme example. That $1,500-per-week offer was only in effect for the first month, and Lyft presumably hoped drivers would stay on and work for lower pay in subsequent months. But something similar is happening in other parts of the world. As the New York Times puts it, "China is a difficult battleground, as Uber is spending millions in a subsidy war with Didi Chuxing, the dominant ride-hailing start-up in the country."
Like many technology markets, ride hailing exhibits strong network effects: The more drivers a network has, the more attractive it is to passengers, and vice versa.
And network effects can be very profitable. The world's richest man, Bill Gates, made his billions from the network effects surrounding the world's most popular operating system, Windows. The world's richest man under 50, Mark Zuckerberg, is currently profiting from the network effects from owning the world's most popular social network, Facebook.
It's a reasonable guess that ride hailing will also become a winner-take-all market, with the winner reaping huge profits.
But because ride-hailing services operate in the physical world, competition happens on a city-by-city basis. Different Uber competitors — Lyft in the United States, Gett in Europe, Didi Chuxing in China, Ola in India — are strong in different parts of the world. So in each of these markets, Uber needs cash to allow it to operate at a loss — potentially for years — so it can gain market share and prevent overseas rivals from gaining the upper hand.
Uber isn't alone. Across Silicon Valley, companies are pouring millions of dollars into money-losing price wars, in hope that they'll eventually be able to turn a profit once their competitors are driven out of business.
For example, in recent years there have been dozens of companies — including Instacart, DoorDash, Blue Apron, GrubHub, and HelloFresh — offering app-based food delivery services. Amazon and Google have also gotten into the market with delivery services of their own.
While the exact business models differ, the basic idea is very similar: People use the internet to order food. And because there are so many companies with similar business models, they wound up taking big losses in an effort to gain market share. Recently companies have started slashing compensation for their delivery drivers in an effort to finally turn a profit.
These price wars were obviously great for consumers while they lasted. But the process of "investing" in money-losing price cuts as a means to gain market share is fundamentally different from investing in productive assets like factories, stores, or computer software.
When companies spend billions in a race to build more advanced factories or better software, that boost's society's total productive capacity. Tesla, for example, recently raised $2 billion to help it expand its production facilities and meet its goal of producing 500,000 electric cars per year. Even if Tesla ultimately fails to turn a profit and goes bankrupt, someone will likely acquire the production facilities Tesla is building and put them to use.
And to be sure, Uber is doing some of this kind of investment itself. Uber recently opened a research facility in Pittsburgh to develop self-driving car technology. That could produce technology of lasting value.
But a large share of Uber's money is "invested" in a price war, which produces nothing of lasting value. Venture capitalists hope their millions will buy them a share of the monopoly profits that will exist once the price war is over. But they're fighting over a fixed pie of profits — a long, expensive price war doesn't lead to larger industry profits in the long run.
The massive investments in perpetually money-losing companies wouldn't be so worrisome if it were happening alongside big investments in companies using the money in more conventional ways. The really ominous thing about Uber's investments is that they dwarf most other venture capital spending. Companies like Tesla — companies that can transform a billion dollars into productive capital assets — seem to be few and far between. And that's a bad sign for the long-term growth of the US economy.
Moments after explaining that we're all probably characters in an advanced civilization's video game, Elon Musk was asked how he hopes to see laws made on Mars if he is, in fact, successful in setting up civilization on the red planet. His answer was characteristically interesting:
Most likely the form of government on Mars would be direct democracy, not representative. So it would be people voting directly on issues. And I think that's probably better because the potential for corruption is substantially diminished in a direct versus a representative democracy.
So I think that's probably what would occur. I would recommend some adjustment for the inertia of laws. That would be wise. It should probably be easier to remove a law than create one. That's probably good. Laws have infinite life unless they're taken away.  So I think my recommendation would be something like 60 percent of people need to vote in a law but at any point greater than 40 percent of people can remove it. And any law should come with a built-in sunset provision. If it's not good enough to be voted back in...
That would be my recommendation. Direct democracy where it's slightly harder to put laws in place than to take them away and where laws don't automatically just live forever.
Musk knows far more about Mars than I do, but my guess is this is a recipe for tremendous statutory instability, which seems like a dangerous thing for a young civilization in a harsh climate. Musk is basically taking the structure of the US Senate, where the filibuster creates a 60-vote supermajority for passing laws, and adding a provision that makes undoing existing laws easier. The result is a system that is biased against action and biased toward the reversal of past actions.
I can sort of understand why you might want that system in present-day America, where we already have a lot of laws and you might see diminishing returns to new legislation and mounting costs to old legislation. But in a new society operating under harsh and uncertain conditions, it seems to me that you'd want it to be easier to act, and you wouldn't want to add political instability to what would already be a massive amount of environmental instability.
On some level, I find it particularly odd that Musk is proposing this kind of system: In order to get to Mars, he famously keeps tight control of his companies (Musk has kept SpaceX private, and said he only brought Tesla public because "he didn't have any choice"), and he is famous for backing bets and plans that most people think are nuts, and doing so till long past the point when normal investors would pull their money.
Musk is, in other words, someone who believes that tough missions require institutions where action is relatively easy and risky decisions are given ample time to pay off. The political system he favors, however, is one in which action is nearly impossible and laws would be removed the second that 40 percent of the population lost their nerve. I recognize governments should be run differently than corporations, but this seems like a very sharp correction in a very un-Muskian direction.
.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }

Correction: This post initially said neither Tesla nor SpaceX were public. In fact, Tesla is a publicly traded company.
A few years ago, the database company Oracle sued Google, arguing that Google's Android operating system infringed the copyright of Oracle's Java technology. On Thursday a jury sided with Google, ruling that copyright's fair use doctrine allowed Google to build Java-compatible software without getting a license from Oracle.
This is not the final word in the dispute. Oracle is almost certain to appeal the case to the Federal Circuit Appeals Court, which is known for its pro-patent and pro-copyright views and has already ruled for Oracle once in the case.
The immediate stakes in the case are not that interesting for anyone but the companies involved — either Google will have to write Oracle a big check or it won't. But the case will set a precedent that could have a big impact on the software industry more broadly. If Oracle's legal theory is upheld by the appellate courts, it could hamper efforts to improve software compatibility.
The lawsuit focuses on technical decisions Google made when it created the Android operating system.
Google wanted people who wrote programs in the popular programming language Java to be able to reuse their code in Android apps. To do that, Google had to ensure that Java code written for other purposes ran exactly the same on Android. But negotiations with the company behind Java, Sun Microsystems (which was later acquired by Oracle), broke down, so Google decided to create its own version of Java from scratch.
Google's version of Java didn't reuse any code from Oracle's version. But to ensure compatibility, Google's version used functions with the same names and functionality.
This practice was widely viewed as legal within the software world at the time Google did it, but Oracle sued, arguing that this was copyright infringement. Oracle argued that the list of Java function names and features constitutes a creative work, and that Google infringed Oracle's copyright when it included functions with the same names and features.
Google argued that the list of function names, known as an application programming interface (API), was not protected by copyright law.
Google's defenders pointed to a landmark 1995 ruling in which an appeals court held that the software company Borland had not infringed copyright when it created a spreadsheet program whose menus were organized in the same way as the menus in the more popular spreadsheet Lotus 1-2-3.
The court held that the order of Lotus 1-2-3 menu items was an uncopyrightable "method of operation." And it concluded that giving Lotus exclusive ownership over its menu structure would harm the public:
Under Lotus's theory, if a user uses several different programs, he or she must learn how to perform the same operation in a different way for each program used. For example, if the user wanted the computer to print material, then the user would have to learn not just one method of operating the computer such that it prints, but many different methods. We find this absurd.
Google believed that its own copying was directly analogous to what Borland had done. There were thousands of programmers with expertise in writing Java programs. By designing its platform to respond to the same set of programming commands as Oracle's Java system, Google allowed Java programmers to become Android programmers with minimal training — just as Borland's decision to copy Lotus's menu structure avoided unnecessary training for seasoned Lotus 1-2-3 users.
In 2012, Judge William Alsup agreed with Google. He ruled that copyright only protects the creative aspects of a work, not functional characteristics. Alsup ruled that because the names of Java functions was essential to achieving interoperability, they were a functional characteristic rather than a creative aspect of Java, and using them wasn't copyright infringement.
But in 2014, the Federal Circuit Court of Appeals disagreed. The court was unimpressed with Google's argument that function names were functional characteristics not protected by copyright. In the Federal Circuit's view, the list of Java functions was just another kind of "code" that couldn't be copied without its creator's permission.
But the case wasn't over. APIs might be protected by copyright law, but Google could still invoke copyright's fair use doctrine to justify its use of them. The case was sent back down to Judge Alsup's courtroom, where he was asked to assume (contrary to his previous ruling) that APIs were copyrightable and hold another trial focused on the fair use question.
Now Google has prevailed again in Alsup's courtroom, with the jury ruling that Google's use of the Java APIs were, in fact, fair use.
But the case still isn't over. It will next go back to the Federal Circuit. And given its track record, there's a decent chance it will overrule the lower court's decision once again. Then the losing party will have the chance to appeal to the Supreme Court, which declined to hear the case during the first go-round.
There's a long tradition of computer programs being designed to be compatible with other programs created by third parties. To do that, the developer of the new software needs to copy certain functional characteristics of the old software. Often, software companies have good reasons to do this even when the author of the old software objects.
One good example is the open source project Samba. It was created to allow users of open source operating systems such as Linux to share files with Windows users. To do that, the Samba programmers reverse-engineered and then duplicated the functionality of the Windows file-sharing system. They didn't copy any Microsoft software, but they did duplicate the sequence of commands needed to transfer files, read the contents of folders, and perform other functions in the Windows file-sharing system.
As an open source project, Samba became hugely popular. The early versions of Mac OS X included a version of Samba, and the software was incorporated into a lot of standalone file servers.
The legality of projects like Samba has been widely accepted for more than two decades. But if Oracle's arguments are accepted by the courts, Microsoft might be able to sue Samba for copyright infringement. If the Federal Circuit's precedent isn't overturned, companies could become more reluctant to reverse-engineer competitors' products in order to make them compatible.
A 2014 brief by the Electronic Frontier Foundation offered another example of a case where copying APIs was valuable:
Jeremiah Flerchinger is an electrical engineer with over ten years of service in the Department of Defense, after previous experience with a machine-tool company. When the National Aeronautics and Space Administration (NASA) sought to repurpose old manufacturing robots for a new project, they asked Flerchinger’s company to manufacture and program updated memory chips to store the robots’ new instructions. Configuring firmware to put on the chips required using obsolete software that wouldn’t run on modern computers. Flerchinger reimplemented the software’s API, creating modern software that could fulfill the same functions and work alongside old machines that had the same API hard-coded into their electronics.
Disclosure: My brother works at Google.
Robo-advisory firms are all the rage in the investment world, as I wrote in a recent article. In that article, I focused on Betterment and Wealthfront, two startups that position themselves as automated online alternatives to conventional human investment advisers.
I argued that for nonwealthy customers, these companies simply didn't provide enough value to be worth the significant fees they charge (though high-income families may benefit from their tax loss harvesting services). A target date mutual fund essentially provides the same service, and the best target date funds cost half as much.
But that critique doesn't apply to another popular robo-adviser service offered by stock brokerage Charles Schwab, because its Intelligent Portfolio service has no fees at all!
Before you get too excited, you need to know that the Schwab plan has a big downside. Instead of charging customers directly, Schwab makes money off Intelligent Portfolio by steering customers into investments that don't always serve customers' interests.
Conventional investment advice holds that investment portfolios should contain a mix of stocks and bonds. But Schwab requires clients to hold a significant portion of their portfolios in cash. The company's own example portfolios allocate between 6.9 and 15 percent of customer money to a cash account.
This is a bad investment strategy. Financial planners do encourage people to keep some money in cash for short-term emergencies. But the cash in a Schwab portfolio isn't really available for use in emergencies because Schwab requires customers to keep a minimum percentage of their portfolio in cash at all times. Taking money out of a Schwab Intelligent Portfolio account requires selling off some of your stock and bond funds — which is exactly what a cash emergency fund is supposed to help avoid.
Even worse, Schwab pays a very low interest rate on customers' cash. Online banks like Synchrony and Ally currently pay around 1 percent interest on deposits. Ultra-safe short-term bond funds can also be expected to earn around 1 percent. In contrast, Schwab's current rate (as of Monday) is a paltry 0.08 percent.
This mandatory cash allocation amounts to a hidden fee for using the Schwab account. If your portfolio is 15 percent cash, then the 0.92 percent gap between Schwab's 0.08 percent interest rate and the 1 percent rate you can get elsewhere amounts to a 0.138 percent hidden fee — not much different from the 0.15 percent fee Betterment charges for accounts over $100,000.
And if you're saving for retirement, it's probably better to put all your money in assets with expected returns of more than 1 percent, so the practical cost of this "cash drag" is likely to be even higher.
Of course, Schwab argues that the conventional wisdom is wrong, and holding some of your portfolio in cash makes sense, providing "ballast" in times of economic turmoil. You can read its argument for a cash allocation here. I didn't find it very convincing, but you might.
But the larger problem here is that there's an inherent tension between Schwab's claim to be acting as an "adviser" and the fact that its profits depend on steering customers to investments that make money for Schwab. You can debate whether holding 6 to 15 percent of your portfolio in cash in your portfolio is a good deal for the customer. But there's no doubt that it's a good deal for Schwab, which can invest the money in higher-yielding assets and pocket the difference.
The same critique applies to Schwab's non-cash recommendations. Like other robo-advisers, Schwab puts clients' money in exchange-traded mutual funds. But there's a big difference: Betterment and Wealthfront invest purely in third-party funds, and both companies say they never take a commission from the funds they recommend.
Schwab, by contrast, sometimes puts client money into funds operated by Schwab itself. Schwab also earns money for some of the non-Schwab funds it sells — though a Schwab spokesperson tells me that these payments are not a sales commission, but rather are for "record-keeping, shareholder services, and other administrative services" Schwab provides to third-party fund providers.
"We work hard to be open and transparent to the client," said Schwab executive Tobin McDaniel when I asked him about this on Monday.
He argues that Schwab has a rigorous process for choosing funds. He said Schwab looks for the lowest-cost option that is "large enough and liquid enough for us to trade," and he points out that low-cost Vanguard funds feature prominently in Schwab portfolios.
Still, when Schwab is choosing between its own funds and others supplied by third parties, it's hard to be confident that the best interests of customers is the company's only criteria.
Betterment and Wealthfront don't have this problem. Their business model is clear and transparent — they make their money by directly charging clients, they recommend only third-party funds, and they don't earn payments from third-party fund providers. That means they make exactly the same amount regardless of which investments they recommend.
It's still the case, as I wrote previously, that a target date fund is the best option for most retirement investors. But if you are interested in robo-advisers, it's worth picking a service with transparent pricing and no conflicts of interest. Schwab's "free" service could wind up costing you more in the long run.
Correction: I misplaced a decimal point and incorrectly quoted Schwab's interest rate as 0.8 percent instead of 0.08 percent.
Anytime a major social media platform makes even minor changes, it generates consternation. So we can expect a lot of griping in the coming hours about Twitter's announcement that it's going to change how it deals with replies and when usernames count against the 140-character limit.
And Twitter didn't do itself any favors by writing a confusing blog post on the subject. I  misunderstood Twitter's plans the first time I read the post. Several of my Vox colleagues did too, and their initial reactions weren't positive.
But now that I've read the post more carefully — and also read the less confusing version of the announcement Twitter wrote for developers — I'm convinced that the vast majority of Twitter users will like the new system for handling replies. In fact, the change is long overdue.
Twitter's handling of replies might be the platform's most confusing feature. Right now it works like this: If you start a tweet with a username, the tweet will only show up in the timelines of people who follow both you and the other person you're mentioning.
This seems natural for those of us who have been using Twitter for years. But I'm constantly seeing newer and less prolific users do this wrong, starting a tweet with a username and not realizing most of their followers won't see it. It's one of the biggest ways in which the platform seems hostile to new users.
And the reason Twitter works this way is essentially a historical accident. In the beginning, Twitter didn't have a concept of replies. Every tweet showed up in the timelines of everyone you followed.
But over time, a social convention developed that starting a tweet with a username signaled that you were replying to someone. This created clutter in people's timelines — following only one person in a conversation was like listening to one side of a telephone call. So in 2009 Twitter tried to help out users by hiding tweets from your timeline if they started with a username you weren't following.
Even after Twitter did this, however, the conversational experience was still far from ideal. The problem was that as you followed more people, multiple conversations got jumbled up in your timeline and it became harder to follow any one discussion.
So Twitter made replies a native feature of tweets. It started keeping track of which tweets were replies to which other tweets, allowing the platform to start showing users entire conversation threads instead of just individual tweets.
So for the past three years, Twitter has used two different systems for identifying conversations. It still hides tweets that start with a username you don't follow. But whether you start a tweet with a username is actually irrelevant for Twitter's threaded conversation feature — Twitter keeps track of that information directly when you click the "reply" button on a tweet.
Twitter realized that this first method for identifying conversations had become anachronistic. If the platform is already directly tracking which tweets are replies to which other tweets, it no longer needs to rely on the earlier hack of looking at whether a tweet starts with a username.
And so this week Twitter will announce that it's going to continue providing users with the same useful feature — only showing conversations when you follow both people involved — without forcing users to worry about whether a tweet starts with someone's username.
This will mean the end of one of Twitter's strangest conventions: putting a period before someone's username to make a tweet visible to everyone. In the future, you'll be able to just start a tweet with someone's username — "@ezraklein is the founder of @voxdotcom" — without having to put a period at the beginning to signal to Twitter that you want everyone to see it. And if you want everyone to see a tweet that's a reply to another tweet, you can do this by clicking the retweet button, a more natural strategy than putting a period at the beginning.
Once you start thinking about replies as a native feature of a tweet, you realize that it's not necessary for reply tweets to include people's usernames at all. If Twitter knows which tweet your tweet was replying to, then it's easy to also figure out whom the tweet is replying to. So rather than forcing you to include the other person's username in the tweet (eating up some of your scarce 140 characters), Twitter is going to start treating that as a separate bit of metadata, like the tweet's date and location, and display it outside of the tweet.
But note that this is only true of people you're replying to, not mentions in general. If you write spammy tweets that mention random people, those extra usernames are still going to count against your character count — preventing people from overusing mentions.
One big question that doesn't seem to be answered by Twitter's announcement is how the company will deal with "Twitter canoes" — situations where two or more people hijack one of your tweets to start a long Twitter argument, flooding your mentions tab with tweets you don't care about.
Right now this kind of thing is constrained by the fact that usernames are counted against character counts, so people have an incentive to remove nonessential people from the thread to give them more characters to argue with. But in the future, you won't have to list the people you're replying to, creating the possibility that dozens of people (Twitter documentation suggests the number could be capped at 50) could get dragged into long-running arguments.
But this shouldn't be a terribly difficult problem to solve. Perhaps Twitter will include a thread-specific mute button that lets you bail out of conversations that have become too tedious. Or maybe Twitter will come up with smarter ways to figure out which conversations you're likely to actually care about.
Either way, cluttering up tweets with the names of the person you're replying to was always kind of a hack, and most users will be happy to see it go away.
Bitcoin has struggled to live up to the hype that surrounded its emergence into the mainstream three years ago. Despite more than a billion dollars of venture capital funding, Bitcoin startups have failed to develop applications that appeal to mainstream customers. And over the past year, the Bitcoin community has become paralyzed by a bitter feud over how — and whether — to expand the network's capacity.
The result: For the first time since its creation, Bitcoin is in danger of losing its status as the world's leading cryptocurrency. The new challenger is a Bitcoin-like technology called Ethereum that has seen a surge of interest from users, developers, and the corporate world. The network's currency, called ether, is now worth more than $1 billion — that compares to Bitcoin's total market value of nearly $7 billion. Last week, a leading Bitcoin startup called Coinbase announced it was adding support for Ethereum to its popular currency trading platform.
The growing excitement about Ethereum reflects the fact that it's a lot more than just a Bitcoin clone. People can use the Ethereum network to make payments, just as they can with Bitcoin. But the network can do a lot more than that.
Ethereum is a new kind of virtual computing platform. Its most exciting feature is its ability to create binding financial agreements that can be enforced entirely by software — no involvement by courts or other human mediators required. That, in turn, has made possible virtual organizations that exist only on the internet. One such organization, called the DAO, has raised more than $150 million in virtual currency to fund further work on Ethereum-based technologies.
Like Bitcoin, Ethereum represents a technological breakthrough, allowing people to do things purely in software that weren't possible before. But the big question about Ethereum is whether it has practical applications. Ethereum has gotten techies excited, but so far no one has created an application for Ethereum — or Bitcoin, for that matter — that has appealed to mainstream consumers.
Bitcoin is a global payment network like Visa or MasterCard, but with an essential difference: There's no company with ownership or control over the network. Instead, computers all over the world cooperate to maintain a shared record of transactions called a blockchain.
The key innovation that made this work was a clever scheme for rewarding computers that help build this shared ledger. Computers that participate are rewarded with freshly created bitcoins worth thousands of dollars every hour. As a result, there's no shortage of volunteers to contribute computing power to helping process Bitcoin transactions.
The Bitcoin network is custom-designed to verify and record payments. In 2014, a 20-year-old programmer named Vitalik Buterin realized that he could create a Bitcoin-like network that could perform a much broader range of computational tasks. If Bitcoin is a distributed version of Visa or MasterCard, Ethereum is a bit like a distributed version of cloud computing platforms run by companies like Amazon and Microsoft.
Not only can you use Ethereum to make ether-denominated electronic payments, you can also spend ether to run programs on the Ethereum network itself.
Ethereum is a very unusual cloud computing network. Every calculation is performed simultaneously by thousands of computers around the world, making it thousands of times less efficient than a conventional online server. And because the results of these calculations are stored on the Ethereum blockchain, all data is public. So Ethereum would be a terrible choice for conventional applications like running a web server.
But Ethereum's distributed structure also gives it a unique advantage: Once a program starts running, no one has the power to modify or stop it. That means you can use Ethereum to make binding, long-term commitments — which is why Ethereum programs are known as "smart contracts."
A good way to illustrate Ethereum's capabilities is with an example. One of the biggest challenges of Bitcoin has been the currency's volatility; Ethereum offers a potential solution for this problem: a smart contract that hedges against currency fluctuations.
Two users might each submit $1,000 worth of ether to a smart contract. After a month, the smart contract would look up the current dollar/ether exchange rate, paying one user $1,000 worth of ether at the new exchange rate (which might be more or less ether than originally submitted) and sending the rest of the ether to the second user.
This works the same as a conventional hedging contract, with one important difference: The contract is enforced by a computer program running on the Ethereum network instead of by the courts. Once submitted, the program can't be modified by either party, so neither party has to trust the other.
Of course, the obvious question is why you'd want to use such a convoluted technique to execute an ordinary financial contract. Modern financial markets make it cheap and easy to hedge against a wide variety of price fluctuations, and it's not obvious people are clamoring for a weird, internet-based alternative to these products.
As with Bitcoin, some of the early uses of Ethereum are likely to involve illegal activity. You can use ordinary financial networks to hedge against changes in the price of wheat or crude oil, but if you want to hedge against changes in the street price of cocaine, a smart contract might be your only option.
Ethereum could become a platform for online betting. Bitcoin already supports simple gaming applications, but more complex Bitcoin-based gaming requires players to trust the company running the game not to cheat. Smart contracts could allow the creation of complex, provably fair online games. Ethereum could also allow people to bet on events (like elections) in countries (like the United States) where such gambling is restricted by law.
Ethereum could also prove particularly useful in countries with dysfunctional legal systems. The ability to make binding legal commitments may not be so useful in countries like the United States where legal institutions work fairly well. But in countries where the courts are corrupt, incompetent, or nonexistent, the ability to make and enforce contracts online could be attractive.
As with Bitcoin, legally dubious applications come to mind quickly because Ethereum's decentralized structure makes it hard for governments to control. But the hope is that the same characteristics of decentralization and flexibility will allow people to build entirely new classes of applications that can't be built on top of conventional financial and legal infrastructure. So far, that hope has mostly not panned out for Bitcoin, but it still could happen — and people are just getting started exploring Ethereum's capabilities.
There are a lot of different ways to use Ethereum contracts, but the application that has attracted the most interest is virtual organizations. At a fundamental level, an organization is just a bundle of agreements between groups of people — shareholders, employees, creditors, and so forth. In most organizations, these are conventional contracts enforced by the court system. Ethereum allows the creation of decentralized autonomous organizations, whose contracts and bylaws are enforced by Ethereum smart contracts instead.
This is not just a theoretical possibility. A virtual organization called the DAO has raised more than $150 million over the past few weeks. Technically speaking, the DAO is just a specific Ethereum address controlled by a computer program running on the Ethereum blockchain. People send ether to this address and get back shares in the organization.
Once the fundraising phase is complete, these shareholders will be able to vote on what to do with the money. The idea is that the DAO will act as a kind of venture capital fund for the Ethereum community. Programmers and companies will submit detailed project proposals to the DAO. DAO shareholders will then vote on which proposals to fund.
It's important to take that $150 million figure with a grain of salt. For one thing, the DAO's funds are in the form of ether, and media hype about the DAO has pushed up ether's value, so once things settle down the DAO might not actually have $150 million at its disposal. Also, the DAO has a mechanism for shareholders to request refunds, so again, the full $150 million might not ultimately get spent.
And the DAO — and DAOs in general — are going to face significant challenges.
One challenge relates to governance. The structure of conventional organizations developed over many decades, shaped by hard-won experience. They have boards of directors, CEOs, auditors, and well-defined management hierarchies to ensure that the organization behaves in a coordinated fashion and is accountable to shareholders.
The DAO is essentially starting with a clean slate, with most decisions made by majority rule. It's as if Apple asked its shareholders to vote on which products to develop. That could lead to erratic and unpredictable decisions, making third parties reluctant to enter into long-term relationships.
At the same time, the fact that the company's basic bylaws are hard-coded into the Ethereum blockchain means that a bug in the DAO's software could have disastrous consequences. If a design flaw causes the organization's operating software to behave in an unexpected and undesirable way, there might be no way to fix the problem other than to liquidate the organization and start over. There's no DAO board of directors with the power to make technical, commonsense changes to the bylaws the way they could in a conventional company.
The DAO may also encounter unwanted attention from securities regulators. In the United States, the Securities and Exchange Commission has detailed regulations that companies must follow when they offer investments to the general public, and most other countries have similar rules.
The DAO's creators don't appear to have followed any of these regulations. And indeed, it's not clear that it's even possible for a purely blockchain-based organization to comply with SEC rules, whose authors probably never considered the possibility that a company could be an autonomous computer program running on a blockchain.
In some ways, DAOs are in a similar position with respect to SEC regulations that Bitcoin was in with respect to regulations governing money-transmitting services. Bitcoin seemed to meet the commonsense definition of a money-transmitting service, and arguably should have complied with consumer protection and money laundering laws.
But Bitcoin's decentralized structure meant that there was no specific person whom regulatory authorities could fine or prosecute for flouting the law. And so regulators contented themselves with regulating Bitcoin exchanges — companies that convert bitcoins to dollars, and vice versa — and allowed Bitcoin itself to operate free of regulation.
The big question is whether the SEC (and regulators elsewhere in the world) will take the same laissez-faire attitude toward the DAO. They might decide that it's too difficult to try to force DAOs to comply with securities law, or they might choose to interpret securities laws in ways that exclude virtual, blockchain-based organizations.
But securities regulators might also take a more aggressive posture. No one directly controls the DAO, but 10 prominent members of the Ethereum community — including Ethereum creator Vitalik Buterin — serve an oversight role as "curators" for the DAO. They could conceivably face unwelcome attention from investment regulators.
It's possible that the DAO and other virtual organizations will find ways to navigate these tricky legal waters. For example, a conventional organization called DAO.LINK was recently created to provide conventional services — like invoicing and tax compliance — to blockchain-based organizations. Conceivably, organizations like this could provide legal services to DAOs and help them navigate the tricky regulatory issues they raise.
One of the hottest trends in the retail investment advising world is robo-advisers. These are online sites — two of the most popular are Wealthfront and Betterment — that allow people to manage their investment portfolios with a website.
The companies' marketing pitches are simple: They perform the same task as a conventional investment adviser, but charge a fraction of the cost. Conventional investment companies have fees as high as 1 percent of a customer's invested assets. Betterment and Wealthfront cost about a third as much.
It's true that if you're paying someone a 1 percent fee to manage your money, you should stop doing that. But it's not true that Betterment and Wealthfront are the best alternative. A class of mutual funds called target date funds cost about half as much as robo-advisers, while providing a very similar service.
Betterment and Wealthfront offer tax-related services that may be useful to customers rich enough to exceed the $23,500 annual limit on tax-free savings. But if you're not that rich, you'll probably be better off saving money with an old-fashioned target date fund.
Saving for retirement isn't complicated. You can click here for the full Vox retirement guide, but fundamentally there are three things you need to do to get the most out of your retirement savings:
A financial product called a target retirement fund makes this really easy. You choose the fund that corresponds to your expected retirement date (for example, I'm in my mid-30s so I would choose Vanguard's Target Retirement 2045 fund), and the fund does the rest, gradually shifting to safer assets as you get closer to your retirement date.
There are low-cost target retirement funds available from Vanguard, Fidelity, and State Street. Signing up only takes an hour or two, and once you've deposited your cash with one of these companies, you shouldn't have to think about it again until you reach retirement age.
The development of these target date mutual funds is great news for consumers, but it leaves professional investment advisers — at least those that serve non-wealthy clients — with little to do. But instead of admitting that they'd been rendered obsolete and shutting down, investment advising companies have built elaborate marketing machines designed to obscure the fact that most people don't need professional advice about where to invest their retirement savings.
The marketing has been pretty effective, so a lot of people pay human advisers a lot of money — an annual fee of 1 percent of invested funds isn't uncommon — for advice that they don't really need.
That has created a big opening for a new generation of companies called robo-advisers.  Their pitch is that they'll provide the same basic service as a human investment adviser for about a third the cost. They're called robo-advisers because they provide "advice" using an automated website instead of having you talk to a human investment adviser.
Robo-advisers mostly perform the same functions as a target retirement fund. As markets fluctuate, they automatically rebalance your portfolio to maintain an optimal mix of stocks, bonds, and other assets. And as you get closer to retirement age, robo-advising companies shift more money into the safest investment categories, reducing the risk that a stock market crash will devastate your finances right before you reach retirement age.
To the extent that robo-advising companies are stealing customers away from overpriced investment advisers, that's a great development for consumers. The exact fees Wealthfront and Betterment charge depend on how much money you invest with them, but most investors will pay annual costs and fees between 0.25 percent and 0.37 percent. That compares favorably with conventional advisory services that can charge as much as 1 percent.
On the other hand, Betterment and Wealthfront's fees don't compare favorably to the best target date funds. Vanguard, Fidelity, and State Street all offer target date funds with expense ratios between 0.13 and 0.16 percent — about half what typical customer will pay for service from Wealthfront or Betterment. (It's important to note that not all target date funds are this cheap — most others cost significantly more, so always check a fund's expense ratio before you invest.)
To their credit, Wealthfront and Betterment are pretty candid about the similarities between their products and target date funds. Wealthfront addresses the issue explicitly on its website, writing that "we believe the next best option to having your portfolio managed by Wealthfront is investing in Vanguard’s target date funds."
Wealthfront points to two big reasons its products are better than a target date fund. One is tax efficiency. Wealthfront offers a service called tax loss harvesting that helps investors claim tax deductions when their investments lose value. Wealthfront claims that the tax savings from using the service can add as much as 1 percent annually to investment returns.
Unfortunately, Wealthfront's methodology doesn't stand up to scrutiny — the average investor isn't going to get anywhere close to 1 percent gains from this feature. Also, there are some legal risks to automating a complex tax-avoidance process.
But more to the point, you have to be pretty rich for this feature to be useful. Tax loss harvesting only becomes useful after you max out tax-advantaged accounts like 401(k)s and IRAs. The legal limits on these accounts are $18,000 for a 401(k) and $5,500 for an IRA (note that there are also some income-related limits for both Roth and traditional IRAs). Unless you're in the small minority of workers saving more than $23,500 per year ($47,000 per year for a couple), tax loss harvesting is totally irrelevant.
Wealthfront also argues that its service is better at fine-tuning a customer's portfolio — the same argument Betterment's CEO made when I talked to him in 2012. Target date funds are relatively crude, using exactly the same portfolio for everyone planning to retire within a particularly five-year window. As a result, Wealthfront argues, "the return on the target date fund might be too high or too low for a particular buyer’s risk tolerance."
Yet it's not obvious how much value this adds in practice. Most savers — even fairly sophisticated ones — don't know how to precisely quantify their "risk tolerance." They know they want to maximize their long-term returns without taking on too much risk, but beyond that it's mostly guesswork.
And if you want more or less risk than your target date fund offers, there's a simple way to do it without paying robo-advisers' higher fees: use a target date fund for a different year than your actual retirement year. Suppose, like me, you expect to retire around 2045. If you want to take a bit more risk, you can invest in Vanguard's Target Date 2050 fund, which will keep your money in high-risk, high-reward stocks for five years longer than the Vanguard's 2045 portfolio. Conversely, if you want to play it safe you can invest in the Target Date 2040 fund, which will start shifting to safer assets five years earlier.
At root, robo-advisers' argument against target date funds is that they're out of date. Betterment emphasizes that the funds were invented more than 20 years ago and haven't changed much since then. But the fact that something is old doesn't mean it's bad. And robo-advisers just don't seem to offer much value to justify their higher costs.
Disclosure: I have most of my retirement savings in Vanguard mutual funds, and because Vanguard is structured as a cooperative, that technically makes me a Vanguard shareholder.
Correction: I originally described Betterment and Wealthfront as the two most popular robo-advisors, but Scwab's Intelligent Portfolio product is more popular than either.
Tesla's biggest problem might not be finding customers for its forthcoming $35,000 Model 3 electric sedan but figuring out how to actually build enough to meet the demand.
CEO Elon Musk has set a goal to produce 500,000 cars a year between 2018 and 2020. That's going to require expanding Tesla's production facilities, which will require a lot of money. As a Bloomberg headline put it last week: "Tesla needs billions to meet Musk's ludicrous assembly timeline."
Now we know where those billions are going to come from. Bloomberg is reporting that Tesla will sell $2 billion in new shares to the public as a way of raising extra capital. This extra cash comes on top of billions the company has raised already. And that makes Tesla a real outlier in Silicon Valley. For all the breathless coverage of Silicon Valley's alleged tech bubble, the really striking thing about most Silicon Valley startups is how little cash it takes to get them off the ground.
Fortunately, there's lots of money available to invest in fast-growing, capital-hungry companies like Tesla. The problem for investors and the US economy is that there don't seem to be nearly enough Teslas to go around.
To see how unusual Tesla is here, it's helpful to compare it to Google.
Today, Google is one of the world's most valuable companies, with a market value of almost $500 billion. Yet building the company was comparatively cheap. It raised just $26 million in outside investments prior to its 2004 initial public offering. Google has raised $1.6 billion in its IPO — money that helped fund further expansion. But the company could have gotten along perfectly well without the money, as it had already generated $106 million in profits in 2003 and its search ad revenue was growing rapidly.
Newer startups have been somewhat more aggressive about fundraising. Uber is the industry's fundraising champion, with $10 billion raised over the past seven years. Airbnb has raised $2.4 billion.
But like Google with its IPO money, these companies are largely raising money because they can get it at favorable rates — not because they particularly need it. Uber, for example, has said it's already profitable in the United States but is spending billions to gain market share in China. Uber has also spent some of its capital to fund a zero-sum price war with rival Lyft.
But none of these companies are investing all that much money in long-lasting, tangible assets. They don't manufacture physical products, so they don't need factories. Uber doesn't own the cars its passengers ride in. Airbnb doesn't own the apartments its customers stay in. Google has invested millions in its data centers, but those expenses are a small fraction of its revenues.
The ability to build a gigantic technology company with a small amount of capital is great news for the company's founders and early investors, since it meant they get to keep a large share of the company's eventual gains. But if you're someone with money to invest, the situation isn't so great.
Over the past decade, American companies have been generating more and more profits, and last year they paid more than $1 trillion out to shareholders. But shareholders have struggled to find anything productive to do with the money. If you add up all venture capital firms' investments in 2015 — including big investments in Uber and Airbnb and many smaller investments — the total was just $59 billion. Money raised in initial public offerings accounted for another $30 billion.
With nothing better to do with the money, a lot of investors have simply used their dividends to buy more stock in existing public companies. These payments go to the companies' previous shareholders — not the company itself — so they don't lead the companies to put the money to productive use.
Instead, share prices have been getting bid up. Right now, stocks in the Standard and Poor's 500 — an index of 500 large American stocks — are selling for almost 24 times their annual earnings. This is an unusually high value that signals that stocks are likely to produce below-average returns over the long run. At the same time, interest rates on government and corporate bonds are at their lowest point in decades.
What investors need is a lot more capital-hungry companies like Tesla: companies that need a ton of cash to grow quickly. Tesla is more capital-hungry than most Silicon Valley companies because it sells physical products that take complex manufacturing facilities to build. Tesla is planning to spend $5 billion on just its "gigafactory" — a vast facility to produce batteries for its cars.
And if Tesla is successful, its appetite for capital will only increase. Even if the company achieves its goal of producing 500,000 cars per year, it will still be a very small player in the overall auto market. It's going to need to build many millions of cars a year to achieve Elon Musk's goal of making electric cars the industry standard. And that will require building many more facilities for creating batteries and building cars.
The problem for investors is that there just don't seem to be very many companies like this. Too many investment dollars chasing too few investment opportunities.
This may also explain the slowing growth of the US economy as a whole. Investments in new factories, equipment, and technologies are a major way that advanced economies grow. But while there's lots of money available for this kind of investment, it seems to be getting harder and harder to find productive ways to put that money to work.
Buying a house is the biggest financial transaction most people ever make. And because you may only buy one house in your lifetime, there's a risk that you'll make a lot of mistakes.
Plus, most of the people you'll be dealing with in the home-buying process will be more experienced than you. There's a danger that they'll take advantage of your ignorance.
So here are six ways to be a savvy homebuyer. These tips will help you find a home that's right for you while avoiding common pitfalls, and could save you thousands of dollars in the process.

(Ed Suominen)
Many people want to buy a house as quickly as possible because they think paying rent is "throwing money away." But buying a home too quickly can be an even bigger financial mistake than not buying at all.
For starters, the idea that renting is throwing away money is a little misguided. Almost everyone needs to take out a mortgage to cover the cost of their first house. And in the first few years of a 30-year mortgage, only a small portion of each payment goes toward paying off principal. The majority of the money goes to interest payments, which is essentially "rent" you're paying the bank to use their money. Paying "rent" to a bank isn't any less wasteful than paying rent to a landlord.
More importantly, selling a house and buying another one is an expensive process, typically costing between 6 and 10 percent of the value of the house. So if you buy a house and then need to sell it a couple of years later, these transaction costs will wipe out any equity you might have accumulated.
So you should only buy if you plan to stay in the same house for five years or longer. If you expect you'll need a different house in the next few years — because you might move to a different city for work, you'll need a bigger house to accommodate a growing family, or you simply aren't sure what kind of house you'll want in a few years — it's better to continue renting until you're ready to settle down.

When it comes to home buying, haste makes waste. (Guy Sie)
Once you've decided to buy, it's important not to rush the house-hunting process. "When I've had clients make real estate deals they've regretted, they've almost always coincided with time pressure," said Zach Teutsch, a personal finance coach in the Washington, DC, area, in a 2014 interview. "You almost always overpay relative to what you would have paid if you were on a more cautious timeline."
That means that when moving to a new city, you should consider renting for a few months while you search for a permanent home. While it might seem like a waste to pay rent when you could be building equity, the amount you overpay due to a hasty purchase — or the cost of having to move again after buying a house that doesn't meet your needs — could dwarf the cost of a few months' rent.
In theory, you can buy a home without a real estate agent, but for most first-time buyers it makes sense to hire a professional to guide you through the process. Many buyers find realtors by asking friends and family for recommendations. You can also find a realtor through an online directory.
No matter how you find potential realtors, it's important to ask for references. The best sign of whether a realtor will serve you well is whether his past clients were satisfied with their service.
When evaluating real estate agents, it's important to keep in mind that their incentives aren't aligned with your own priorities as the buyer. You want the best home at the lowest price — and you may be willing to wait quite a while for the right deal to come along. In contrast, agents make more money when they can close deals as quickly as possible — and they make more money when their clients spend more.
The National Association of Realtors has an ethics code that obligates its members to promote the interests of their members, so in theory this kind of conflict of interest shouldn't matter. But of course, some agents are more ethical and conscientious than others.
"One indication that a person is dealing with a good realtor is if they're ready to make an offer and the realtor encourages them to think about whether that property is in poor condition or overpriced," Teutsch told me. "It's a good indication if your realtor is willing to tap the brakes instead of the gas."
Agents get paid whether or not their clients get a good deal. Indeed, if a buyer overpays, his agent actually gets a slightly larger commission. But a good real estate agent will still advise caution if he feels a buyer is bidding more for a house than it's worth, or overlooking serious flaws.
So when you're choosing a realtor, it's good to ask prior clients how often he warned them away from making offers on properties. If a prospective realtor regularly encouraged customers to keep looking for a better deal, that's a good sign. On the other hand, if buyers say they felt pressure to make an offer on every property they saw, that's a sign that the agent may not have clients' best interests at heart.

You probably don't need this much house. (Kay Gaensler)
Buying a house is an exciting experience, and there's a natural temptation to buy the biggest house you can — barely — afford. But Teutsch told me that most people will be happier in the long run if they buy a house that's cheaper than the maximum amount a bank will lend them.
Few things are more stressful than owning a house you can barely afford. It can put you one layoff or medical emergency away from financial disaster. It can also limit your freedom to take a more rewarding but less lucrative job, start your own business, or cut back your hours to spend more time with loved ones.
So it's important to decide how much you're willing to spend and then refuse to go over that amount. One way to do this, Teutsch says, is to set a limit for yourself during the mortgage preapproval process. Rather than getting preapproved for the maximum amount the bank is willing to lend, he says, you can ask to be preapproved only for the amount you're planning to spend.
Once you have this document in hand, show it to your realtor — and don't mention that you could have gotten preapproved for a larger sum. If you're trying to buy a house for less than $400,000 but your realtor knows the bank is willing to lend you $600,000, he might encourage you to consider homes above your price limit. On the other hand, if your realtor knows you're only preapproved for $400,000, then he'll only show you homes below that limit.
This might also give you a bit more leverage in negotiations between your agent and the seller. Obviously it would be unethical for your realtor to tell the agent on the other side of the table that you can afford to pay more. Still, your realtor may not be a great bluffer. When he tells the seller's agent you can't afford to pay any more, he's going to be more convincing if he actually believes it.
You can always go back to the bank and request preapproval for a higher amount if you find the lower ceiling to constraining. But the need to take that extra step will help prevent you from making an impulsive purchase that you might regret later.

(thom)
After you've made an offer on a house and it's been accepted by the seller, the next step is to get the house inspected for issues such as leaks, termites, or mold problems. Most real estate agents will offer to put a buyer in touch with an inspector. But it's generally a good idea to choose an inspector independently.
An inspection comes near the end of the home-hunting process. If the inspector doesn't find any problems, the deal will go through and the agent will get his commission. On the other hand, if the inspector does find problems, it will mean more work for the agent. At a minimum, it will mean an additional round of negotiations to get the seller to compensate the buyer for the problems. If particularly severe problems are discovered, the entire deal could fall through, which means the house-hunting process will have to start all over again.
So while it's in the buyer's interest to choose an experienced and aggressive inspector, it's better for the real estate agent to have an inspector who isn't so picky. While few real estate agents will deliberately recommend an incompetent inspector, you might get a more thorough inspection if you decline your agent's recommendation and choose an inspector based on your own independent research.
(Timothy B. Lee)
Real estate agents perform a variety of useful services, including advising the client on the state of the market, helping the client view homes for sale, writing offers, negotiating with sellers, and guiding the buyer through the purchase paperwork.
Traditional real estate services are highly personalized. An agent will often drive a buyer around town, showing her neighborhoods that meet her criteria and explaining the finer points of the local market. A traditional realtor will serve as a single point of contact for every step of the home-buying process, from initial comparison shopping to signing on the dotted line.
This approach works well for many buyers. But others prefer a more self-directed approach. And for them, the online realtor Redfin can be a good option.
Redfin performs the same essential steps as a conventional buyer's agent. A salaried Redfin agent will show you houses, write offers, and negotiate with sellers on your behalf. But Redfin uses a team-based approach where different functions are performed by different agents. And the Redfin model depends on customers to take more initiative.
"Redfin was perfect for a type-A person like me because it made it really easy to stay organized and on track," said Adrienne Aldredge in 2014, a few months after she bought a house in the Portland area. "Their agents are very knowledgeable and responsive, but they are not going to hand-hold you through finding houses to view."
One of Redfin's traditional selling points was that the company offered big rebates to customers. Traditionally, the buyer's agent gets a 3 percent cut of the sale price — meaning your agent gets about $12,000 if you buy a $400,000 house. In the past, Redfin has rebated as much as half of that commission back to customers.
But in recent years, Redfin has become more like a conventional realtor. It now offers more extensive and personalized service. That has meant smaller rebates.
For example, back in 2014 Redfin was offering a $3,300 rebate to buyers buying a $400,000 house in Washington, DC. Today the rebate has shrunk to just $1,800. On an $800,000 house, Redfin's rebate has shrunk from $8,600 in 2014 to $4,800 today.
So if you're intimidated by the idea of searching for properties online, or you want a single point of contact to take you through the home-buying process step by step, a traditional realtor might be worth the extra money. A traditional realtor is also a good choice if you're buying on a tight schedule or you have your heart set on buying in a specific, high-demand neighborhood.
But if you're willing to be patient and are comfortable searching for stuff on the internet, Redfin can save you some money.
Twitter announced today that it is going to tweak its platform such that links, photos, and other media no longer count against the 140 character limit. That's a great idea, and really they ought to go further and make it possible for tweets of arbitrary length to appear — even if the main feed only displays a short introduction.
This right here is why:

Extended tweets are a great idea pic.twitter.com/ldnTO0F9tp
Speaking as someone who loves Twitter and who worries about the fact that it is failing in stock market terms, I think this is a sign of why bringing back Jack Dorsey as CEO was ultimately a good idea. Simply put, a founder has the standing and clout to make this kind of fundamental change, whereas Dick Costolo never did.
My main fear is simply that it's too little, too late at this point. The Twitter product has been very slow to evolve over the years. To this day, the company seems to be having trouble rolling out new features like polls to the full suite of Twitter apps — TweetDeck doesn't have polls yet, for example — and really making Twitter a home to natively supported longer-form essays is something they should have done a year ago or more.
Update: Twitter CEO Jack Dorsey made a similar argument in his own tweet:
pic.twitter.com/bc5RwqPcAX

One way in which Amazon differs from a conventional supermarket or a place like Walmart or Target is that it offers relatively little in terms of "store-brand" products. There's the Amazon Basics line of electronics accessories and there are Amazon Elements baby wipes, but not much else. But Greg Bensinger reports in the Wall Street Journal that's about to change, with Amazon prepared to roll out the Elements diapers that have long been rumored, plus a much larger array of products that will "include nuts, spices, tea, coffee, baby food and vitamins, as well as household items such as diapers and laundry detergents."
Why? Bensinger cites Bill Bishop, who runs a consulting company called Brick Meets Click, suggesting that "private-label goods boast higher profit margins than name brands because companies save costs on marketing and brand development."
Seeking higher margins would be a somewhat bizarre strategy for Amazon, which has historically had no profits whatsoever but recently stumbled into a high-margin web services business. My guess is that if Amazon goes big into store-label products they'll be priced aggressively to gain market share at razor-thin margins. The goal isn't really going to be making money, it'll be filling more trucks.
Right now, Amazon is much more than a retailer of physical goods. But the retail of physical goods is still at the core of its corporate identity. And at the moment, the company is involved in a massive multifaceted push to get better at the delivery element of that.
For years, the company has offered free two-day shipping to Amazon Prime members. But these days, a wider and wider array of products is available for Prime one-day shipping or even prime same-day shipping.
This is an important strategic initiative for Amazon. If it can make one-day shipping the new normal, it'll make life that much more difficult for hypothetical future competitors. And to the extent that it can make same-day shipping a reality, it will be able to intensify the competition against brick-and-mortar retail and possibly dominate the buzzy but unproven on-demand delivery sector.
The key thing here is that routinized one-day delivery is going to require a ton of infrastructure. You need warehouses near all the major population centers, the warehouses need to be staffed with people and/or robots, and you need to be putting tons of trucks in the field actually doing the door drops.
Amazon has lots of initiatives in the field ranging from drones to physical stores to try to support this ambition, but the ideas all have something in common — they are capital-intensive and involve high fixed costs.
That means that to make it work, you need to spread the cost across as many deliveries as possible. Making generic versions of household staples and selling them cheaply seems like an excellent way to do that. The fact that competitors are counting on these to work as high-margin items only means that the opportunity to steal a price advantage is real.
In most cases, obviously, the idea of earning nothing on each item sold and then making it up in volume is a joke. But for Amazon it's no joke. Each zero-margin item it sells helps create the infrastructure to meet more and more customer needs faster and faster.
For most of the past five years, Apple has been the world's most valuable company, with oil giant ExxonMobil a close second and other companies far behind. But recently, Apple's earnings growth has slowed, while Alphabet — the company most of us know as Google — has seen its profits continue to grow. The result: Alphabet briefly passed Apple on Thursday to become the world's most valuable company — though it ended the day worth $488.7 billion, slightly less than Apple's $489.9 billion.
The remarkable thing about this is that Apple's 2015 operating income (that's profits, basically) of $71 billion was more than three times Google's operating income of $20 billion. So you might expect Apple's market value would be a lot higher than Google's. The fact that Wall Street is valuing them about the same is a signal that the market is a lot more optimistic about Google's growth prospects. Investors expect Google's profits to continue going up, whereas Wall Street thinks Apple's massive iPhone profits have nowhere to go but down.
Google does a lot of different things. It has a browser called Chrome, a smartphone OS called Android, and a wide variety of online services such as Google Maps, Gmail, and Google Docs. Google's parent company, Alphabet, is working on self-driving cars, residential broadband networks in several cities, and a lot more.
But Google's revenues overwhelmingly come from one thing: advertising.
In 2015, ads accounted for about 90 percent of Google's overall revenues, and of this ad revenue three-quarters came from ads on Google's own websites — including a large share for Google's market-leading search engine. The remaining quarter came from Google's ad networks, which sell ads that appear on other people's websites.
Some high-profile Google products aren't directly ad-supported, but most of them indirectly support Google's ads business — and especially its flagship search engine. For example, creating Android and giving it away to smartphone companies helps ensure that Google's search engine and other online services remain popular with mobile users. Similarly, owning the leading web browser, Chrome, helps Google steer users toward its search engine.
This is worth a lot of money: Google paid Apple $1 billion in 2014 to ensure that Google was the default search engine on iPhones. And until 2014, Google paid hundreds of millions of dollars every year to ensure Google is the default search engine for the Firefox web browser (more recently, Yahoo has outbid Google to be the default).
The ad business keeps getting more lucrative for Google:

<!--
 (function() { var l = function() { new pym.Parent( 'vox-google-advertising-revenue__graphic', '//apps.voxmedia.com/at/vox-google-advertising-revenue/'); }; if(typeof(pym) === 'undefined') { var h = document.getElementsByTagName('head')[0], s = document.createElement('script'); s.type = 'text/javascript'; s.src = 'https://cdnjs.cloudflare.com/ajax/libs/pym/0.4.5/pym.js'; s.onload = l; h.appendChild(s); } else { l(); } })();
// -->

While Google makes most of its money from ads, Apple makes most of its money from selling iPhones. The iPhone is a lot more lucrative than any of Apple's other products. Apple sold 231 million iPhones in 2015, generating $154 billion in revenue. In its most recent quarter, Apple generated almost twice as much revenue from the iPhone as all of its other products — iPads, Macs, Apple Watches, and so forth — put together.
Like Google, Apple has seen its revenue soar over the past few years as the iPhone has gotten more popular. But unlike Google, it looks like Apple is seeing a slowdown in its previously rapid growth. In April, Apple reported its first down quarter in over a decade, with revenues falling 13 percent from a year earlier.
The issue seems to be that the iPhone is close to saturating its market. Apple dominates the market for high-end smartphones so completely that most of the people around the world who can afford to buy an iPhone already have one. Apple will be able to continue selling tens of millions of iPhones every quarter as their existing users upgrade, of course. But there doesn't seem to be much room for further growth in iPhone sales.
To continue growing, then, Apple needs to come up with another massive hit. And it hasn't been able to do that. The iPad is pretty popular, but it's nowhere near as popular as the iPhone, and its sales are actually declining. The Apple Watch seems to be a pretty successful product by conventional measures, but, again, it's nothing like the iPhone.
Of course, Apple could always surprise us. The company has a talented staff and tens of billions of dollars to invest in new products.
But Apple's stock price suggests that Wall Street, at least, isn't optimistic about Apple's chances of coming up with anything new that will match the iPhone's success. A key statistic to watch here is the price-to-earnings ratio — that is, the company's stock price divided by its annual profits.
If the P/E ratio is high, that means Wall Street is paying a premium in hopes that profits will rise over time. A low P/E ratio signals that Wall Street expects profits to stagnate or even decline in the future.
Fast-growing technology companies have share prices that are 20, 50, or even 100 times their earnings. Alphabet's P/E ratio, for example, is about 30.
In contrast, Apple's P/E ratio is about 10. That means Wall Street is valuing Apple like a sleepy utility company — still highly profitable, but with little prospect for future growth.
There are lots of technology companies that have one big hit and then stop growing once that initial product matures. Yahoo, Twitter, and eBay are all examples of companies that seem to have hit a wall.
What makes Apple and Google remarkable is that they were able to follow up an initial hit — early PCs in Apple's case, a search engine in Google's — with many other successful products. Apple had the iPod, iPad, and iPhone. Google has had Gmail, Google Maps, Android, Chrome, and so forth.
It's impossible to say exactly why some companies continue to thrive while others turn out to be one-hit wonders, but one common theme seems to be that the most successful companies still have their charismatic founders at the helm. Apple struggled during Steve Jobs's absence between 1985 and 1997, then enjoyed an amazing resurgence between 1997 and Jobs's death in 2011. Google has been under the control of its founders, Larry Page and Sergey Brin, since the beginning.
Founders have an unmatched level of respect among rank-and-file employees. Because they've been at the company since the beginning, founders have relationships with people all across the country.
This is particularly important when a company needs to make a big change. Employees at once-great but now-struggling companies have a tendency to romanticize a company's early days and resist necessary changes. In these moments, no one has more credibility than a company's founders to put these concerns into perspective and make the case that the company needs to change if it wants to survive.
Founders' greater credibility also allows them more leeway to take big risks. Ordinary CEOs serve at the pleasure of the board, so they constantly have to worry that they'll lose their jobs if they go too far out on a limb. Founders tend to be more secure in their jobs, which makes them more able to take big risks and push through necessary changes.
Apple, of course, lost its visionary founder to cancer in 2011. It's now run by Tim Cook, a man who is by all accounts an able manager but doesn't seem to have Jobs's vision. Prior to Jobs's death, Cook's focus was on optimizing Apple's operations, not creating new products. Alphabet, on the other hand, is still run by co-founders Larry Page and Sergey Brin. They've made big bets on everything from Android to self-driving cars. Some of those bets have failed, but others have been big hits.
That might be one reason Wall Street is bullish on Alphabet but bearish on Apple. The iPhone is a great product, but there's little reason to think Cook will be able to create more products like it. On the other hand, the market seems to be hoping that Page and Brin are just getting started.
Disclosure: My brother is an executive at Google.
Correction: I stated that Google pays Firefox to be the default search engine, but Firefox switched to Yahoo in 2014.
On Tuesday, Walmart sued Visa. The claim? That Visa is trying to force Walmart to use a less secure payment system that happens to generate more revenue for Visa.
The conflict highlights the dismal state of American payment technology. When the United States switched to chip-based credit and debit cards last year, it became one of the last developed countries in the world to do so.
America is even further behind in the switch from signatures — which are almost useless for preventing fraud — to the four-digit personal identification numbers (PINs) that customers in many developed countries use to approve credit card transactions.
In the United States, Visa makes more money when customers use this older, less secure technology, and so Visa has insisted that retailers must continue to allow customers to make signature debit payments. Walmart cites 2009 data from the Federal Reserve showing that signature debit transactions had an average transaction fee of 1.53 percent, compared with 0.56 percent for PIN debit transactions.
Walmart is right on this one: The poor security of "signature debit" helps no one other than credit card fraudsters. Requiring customers to enter a PIN — which most debit card customers use to get money from an ATM anyway — is a sensible step. Indeed, it's so sensible that most of the world adopted it many years ago, and it's past time for America to catch up.
When you take money out of an ATM, you probably enter a four-digit PIN. On the other hand, if you use the same debit card to buy something in a store, you may be asked to use a signature to verify the transaction instead.
Unfortunately, signatures are practically worthless as a security measure. If you don't believe me, try scribbling randomly next time you're asked to sign a credit or debit card receipt. I've been doing this for years and I've never had a store clerk decline the transaction because my signature didn't look authentic.
The rest of the world is way ahead of us on this. Over the past decade, the United Kingdom, Canada, and Australia — just to name a few — have switched to PIN-based authentication, in which customers identify themselves with a four- or six-digit code.
In its lawsuit, Walmart points out that Visa has been an advocate for making PIN-based authentication mandatory — in other countries. But here in the United States, Visa has resisted the change, insisting that retailers like Walmart let consumers decide whether to authenticate their purchases with a signature or a PIN.
Why? Walmart's lawsuit suggests one possible reason: When customers make a signature debit transaction with a Visa, it has to be processed by a signature debit network that's owned by Visa. On the other hand, PIN-based purchases are handled using the same financial networks the nation's ATMs use. And this is a more competitive market. Several different networks exist, and some of them are independent of the big credit card networks.
So Visa has been pressuring retailers to use a less secure payment method that happens to earn Visa a lot more in transaction fees. Walmart has been resisting this pressure. And on Monday, that conflict burst out into the open with a Walmart lawsuit.
Walmart has long been obsessed with keeping costs and prices low, so it's not surprising that the retailer has been a leading advocate for switching to PIN-based debit transactions. In April 2015 — a few months before the switch to chip cards — a Walmart executive argued that it was a "joke" that the nation was switching to chips without also introducing a PIN-based system.
Walmart contrasts America with the United Kingdom, where credit card networks worked with the government on a coordinated "I ♥ PIN" campaign that launched in 2002 to promote the switch to PIN-based transactions. By 2006, "99.8 percent of chip transactions were PIN-verified," according to the Atlanta Fed.
In its lawsuit, Walmart points to the 2010 Dodd-Frank Act, which included an amendment from Sen. Dick Durbin (D-IL) guaranteeing retailers the right to route payments over the network of its choice. Walmart argues that this legislation gives it the right to require consumers to make payments with a PIN rather than a signature.
Unfortunately, the lawsuit is heavily redacted, so we don't know the details of Walmart's dispute with Visa or its precise legal argument. But it seems clear that Walmart believes Visa's efforts to promote signature debit run afoul of the Durbin amendment's guarantee of retailer autonomy.
Visa hasn't responded to my email seeking comment — and has declined to comment on the lawsuit to other media organizations — so we don't what Visa's counterarguments will be. But it looks an awful lot like Visa is pushing a less secure payment method because doing so allows it to charge merchants higher fees. In doing so, Visa is not just costing merchants — and ultimately consumers — more money, it's also making it easier for criminals to commit credit card fraud.
If Walmart wins its lawsuit, it could provide momentum for making PINs the default for debit card transactions. That's a big deal because people make more payments with debit cards than credit cards.
Still, to fully bring the US financial system into the 21st century will require using PINs for credit cards as well. This is going to be trickier because people aren't used to remembering a PIN for their credit card (in contrast to debit cards, where people know they need a PIN to use an ATM). Banks worry that if they start pushing customers to use PINs for their credit card, customer will get annoyed and switch to another credit card.
But this is where the kind of coordinated persuasion campaign employed in Britain can be hugely valuable. If everyone starts requiring credit card PINs at the same time — especially in concert with a public campaign explaining why the switch is worthwhile — banks won't have to worry that moving first will cost them customers.
In the long run, having a PIN to make credit card and debit payments will seem as natural as using a PIN to withdraw from your ATM. The only question is how to get there.
If you've used Facebook on a desktop or laptop computer, you might have noticed the "trending topics" box in the right rail. While the title gives the impression that the list is automated, a Gizmodo piece last week reported that a group of 20-something journalists help algorithms choose which stories appear in this box and write headlines and brief summaries for them:

hey. look what’s trending on Facebook. pic.twitter.com/8rWNavwq4p


And on Monday, Gizmodo dropped a bombshell: A former member of this team alleged that the trending topics team was systematically skewing the results to favor liberal viewpoints. According to Gizmodo's source (who declined to be named, so it's hard to verify his claims), Facebook's trending topics team tended to be dismissive of stories that came from right-leaning news outlets such as Breitbart, Washington Examiner, and Newsmax — waiting instead until more mainstream news organizations like the New York Times or the BBC covered them.
"I’d come on shift and I’d discover that CPAC or Mitt Romney or Glenn Beck or popular conservative topics wouldn’t be trending because either the curator didn’t recognize the news topic or it was like they had a bias against Ted Cruz," the former Facebook contractor, who identified himself as a conservative, told Gizmodo.
This has triggered predictable — and justified — consternation among online conservatives. "It is beyond disturbing to learn that this power is being used to silence viewpoints and stories that don't fit someone else's agenda," argued a press release from the Republican Party.
Facebook insists that the allegations are untrue. "There are rigorous guidelines in place for the review team to ensure consistency and neutrality," wrote Facebook's Tom Stocky late on Monday.
Behind this story is a deeper question that unnerves everyone — including established, mainstream outlets — in a media ecosystem that's increasingly dependent on Facebook's whims: The company's power is vast, and that power is not always deployed in ways that are transparent and accountable.
Mark Zuckerberg has always said he wants to build Facebook into "a utility," and he's arguably succeeded. But utilities, because they're so important, are highly regulated. Facebook is approaching utility-level importance, but it answers to no one — not even, given Zuckerberg's control of the company, its shareholders.
The irony here is that the government used to more actively regulate large media companies to prevent them from abusing their power. Conservatives were skeptical of these policies, and they have largely gotten their wish online. As a result, we now have an unregulated free market for internet content. And it has put a lot of power in the hands of left-leaning CEOs like Zuckerberg.
During the second half of the 20th century, broadcast media and daily newspapers played a dominant role in the information diets of ordinary Americans. A typical American city might have one or two daily newspapers and three or four local television stations. There might also be a couple dozen radio stations, only a few of which carried significant news programming.
Strictly speaking, these weren't the only sources of news. But they had enough influence that  the Federal Communications Commission established a complex set of regulations designed to ensure that influence wasn't abused.
For example, a 1975 regulation made it illegal for a company to own a major newspaper and a television station in the same market. Also, in the late 20th century, no company could own television channels reaching more than 35 percent of the country — a cap that was bumped up to 45 percent in 2003.
In 1949 the FCC instituted the Fairness Doctrine, a controversial rule requiring broadcasters to give "equal time" to opposing points of view on controversial issues. The repeal of this rule in 1987 paved the way for talk radio hosts like Rush Limbaugh, who are known for offering a strongly one-sided point of view to listeners.
These rules existed because regulators believed it was dangerous for any single company to exercise too much influence over the national political conversation. By carefully limiting media consolidation, the FCC hoped to provide room for a diversity of voices to be heard.
But in the past couple of decades, this approach has fallen out of favor. Conservative policy experts have argued that the proliferation of media organizations has made it unnecessary for the government to micromanage the structure of the media sector.
"Americans are in no danger of seeing their news and information monopolized, least of all by newspapers," wrote the Heritage Foundation's James Gattuso in 2008, arguing to liberalize the broadcast-newspaper cross-ownership rule. "Rather than increased concentration, recent decades have brought an historic expansion of information sources and their diversity."
And conservatives have largely won this argument. Today, cable television networks and the internet are much more lightly regulated than the broadcast media giants of yesteryear.
In the 20th century, power came from owning the means of distributing content — like a printing press or a broadcasting tower. If your town only had two daily newspapers and four television channels, the companies that controlled those six outlets had outsize influence over public debates.
Not anymore. Thanks to platforms like Medium and YouTube, anyone can distribute text, audio, and video content worldwide for free. But being able to publish something globally isn't the same as getting a lot of people to read it. Instead, power has shifted to companies like Google, Twitter, and especially Facebook that help their massive audiences filter online content.
In some ways, these new media platforms are more powerful than old-fashioned media companies have ever been. Facebook, for example, has a billion daily active users — a far larger loyal audience than any television network or newspaper has ever had.
And these companies' role as the internet's gatekeepers gives them a lot of power over other media companies. Facebook and Google each account for double-digit percentages of the traffic of many online news organizations. Most news sites spend a lot of time thinking about how to maximize the traffic they receive from Google and Facebook. This leads to articles like the Huffington Post's infamous 2011 article, "What Time Does the Superbowl Start?" (and its many imitators), whose entire purpose was to get a good ranking on Google's search results for people wanting to answer that question.
Similarly, the curiosity gap headlines innovated by Facebook-first publishers like Upworthy and now emulated all across the internet ("You'll never believe what happened when...") are an effort to generate high click-through rates and thus win favor from Facebook's content algorithms.
But in other ways, Facebook and Google are not as powerful as the media giants of the past. While many people use Facebook, there are many, many other sites that help you find interesting content. All of them are available with just a couple of clicks. And while Facebook and Google can drive traffic to content they think is worthwhile, they have very little power to stop the spread of content they don't like; people can always share using other platforms like email or Reddit.
Gizmodo's report that a small group of Facebook contractors may have been manipulating users into reading more left-leaning content highlights just how powerful Facebook has become. There's no evidence that Mark Zuckerberg or anyone else in Facebook's leadership made a conscious decision to skew the trending topics box in a left-wing direction. Yet so many people spend so much time on Facebook that even a small shift in the platform's approach could have a big impact on what people read online.
And in principle, Facebook could do a lot more. People spend most of their time interacting not with the trending topics box at the right of the screen but with the news feed in the center. If Zuckerberg wanted to really shape people's media diets, he would have his engineers tweak how the newsfeed works to steer people toward favored content.
A particularly chilling example, suggested by the Atlantic's Robinson Meyer, would be for Facebook to turn itself into a turnout operation for Zuckerberg's favorite political candidates. Facebook's own experiments have shown that telling people their friends have voted increases the odds that they'll vote too. If Facebook showed those buttons only to Democrats — and it would be easy for Facebook to figure out who was likely to be a Democrat — it could swing a close election.
But the reaction to Gizmodo's latest story also illustrates that Facebook's power could prove relatively fragile. The news that Facebook may have been manipulating the trending topics box has rocketed around the conservative internet, generating a volume of bad press that has to hurt even for a company of Facebook's size.
And the current furor is tiny compared with the backlash that would occur if it were revealed that Facebook management was deliberately trying to manipulate the political system. That could easily trigger a broad conservative boycott of Facebook and could even create an opening for one of its rivals to gain market share at Facebook's expense.
Precisely because the danger of backlash is so high, it's unlikely that Zuckerberg will ever be so ham-handed as to explicitly censor or promote content on an ideological basis — or to try to directly manipulate an election. But even subtle tweaks to Facebook's algorithm can have profound effects. For example, Facebook's current model has contributed to the internet's "filter bubble" effect, in which people disproportionately read content they agree with, giving a boost to candidates with extreme views.
It wouldn't make sense to try to directly regulate the behavior of major internet platforms. Not only would good regulations be fiendishly difficult to write, but there's a good chance they'd get struck down on First Amendment grounds.
Nevertheless, it's worth taking seriously the dangers that can come from excessive concentrations of power and thinking about ways to limit that power. One obvious way to do this is by scrutinizing mergers more carefully. Back in 2012, for example, the Federal Trade Commission quickly approved Facebook's proposal to acquire Instagram, which quickly became one of the largest social media sites on the internet.
It's probably not fair to blame the FTC for missing the significance of this merger, since Instagram has grown fast over the past four years. But federal regulators should think harder the next time Facebook (or a large rival such as Google) wants to acquire a fast-growing online platform like Instagram.
There's also room for users to engage in self-help here. If you find it creepy that a secret Facebook algorithm has so much influence over your reading habits, there are a lot of other ways to find news stories that are less prone to manipulation. You can subscribe to your favorite sites using an RSS reader. You can spend more time on Twitter, which shows posts in a more chronological order, leaving less room for manipulation. Or you can browse the web the old-school way: bookmarking the homepages of your favorite news sites and visiting them directly.
Amazon's new streaming video service, Amazon Video Direct, is being widely reported as an effort to compete with YouTube, but it's probably better to think of it as an extension of Jeff Bezos's ongoing war with Netflix.
Netflix, of course, lets you stream unlimited video for a monthly fee. For a long time, Amazon made a streaming video library available to Amazon Prime subscribers — a broader, annual service whose main selling point was free two-day shipping. More recently, though, Amazon has created a video-only tier of Prime membership that competes directly with Netflix. And while Netflix has blazed the trail of creating streaming-native premium content like House of Cards and Unbreakable Kimmy Schmidt, Amazon is in the game, too, with shows like The Man in the High Castle and Transparent.
That's probably the right strategic context in which to understand Video Direct, which does have a YouTube-like element but also does important work to supplement their Prime offerings.
Video Direct is fundamentally a creator-facing platform, a set of infrastructure whereby people who make videos can upload them to Amazon's video service. Having done so, they have four options for how to make the videos available to customers:
The first of these options genuinely competes with YouTube, but it's not very compelling. YouTube has an enormous head start, and Amazon isn't trying to compete with it on price.
Options two and three are kind of interesting, but seem like they'd only be applicable to really big media brands.
It's option four that seems potentially disruptive, because it's giving people and organizations the ability to do something they genuinely can't do now — get into the premium video content game. Right now you can earn a living making ad-free television shows, but to do it you need to talk executives at Netflix or HBO or Showtime into paying you. What Amazon is doing is saying anyone who wants to can make a show with an absolute guarantee that if the show proves popular they will get paid.
A good hint that the pay-television market is Amazon's real target is offered by the company's Video Direct marketing material, which emphasizes the idea of watching Amazon video on your television or perhaps a tablet rather than watching casually on a web browser.
As with any new idea, the risk of course is that it will be a giant flop.
Existing premium television shows are created with plenty of upfront investment and marketing hype, and it's not clear that any of that would work on Amazon's pure royalty model.
But the company has likely gained some confidence from the Kindle Direct Publishing Select program, which produces e-books on a fundamentally similar model. KDP Select paid out a total of $14.9 million in March, up from $14 million in February.
And authors are in some ways more wedded to traditional distribution models than are video producers, many of whom have already embraced YouTube in the recent past and may be open to taking their ideas in a direction that isn't ad-supported.
"Sharing economy" services like Airbnb are thought of as revolutionary and democratizing. They let ordinary people make extra money using something they already have, like an apartment, and they offer consumers a wider variety of affordable choices than more traditional institutions, like hotels.
But despite its upstart nature, Airbnb still suffers from an old, institutional problem: racism.
The hashtag #AirbnbWhileBlack recently went viral, as black Airbnb users discussed their experiences with discrimination while using the service.
Research backs up their experiences. A working paper by three Harvard researchers found that Airbnb hosts were 16 percent more likely to reject black guests than white guests.
That's not nearly as frequent as, say, the rate at which people of color are denied home loans, a subject fraught with deeply embedded institutional discrimination that has denied equal housing access to people of color for generations. But it shows that even when you try to democratize things and subvert the old institutions like Airbnb does, there's still a core of implicit racial bias that just won't go away.
In a field experiment, the Harvard researchers created Airbnb user profiles that were the same except for the names — some sounded distinctly African American, and some sounded white. The researchers then used these profiles to ask about the availability of 6,400 Airbnb listings in five different cities. Profiles with white-sounding names got a positive response 50 percent of the time, but African-American names only got a 42 percent positive response rate.
As our online lives start to look more like our offline ones, baggage like racial bias comes with it
The results were incredibly consistent. The host's race, gender, and age didn't matter. The type and size of the property, or the type of neighborhood it was in, didn't matter. It didn't matter whether the host was a casual Airbnb user or a seasoned professional: All hosts largely discriminated against black guests at about the same rate. The only mitigating factor was whether a host had already had at least one black guest in the past.
People discriminated in this way even though it ended up costing them: Hosts only found a replacement guest 35 percent of the time, and they passed up an estimated $65 to $100 in revenue by rejecting a black guest.
It's unlikely that hosts did this consciously. Implicit bias is a powerful phenomenon that constantly informs our daily decisions and reinforces discrimination against marginalized groups — yet most people don't realize they have these biases. And an institution can never be truly egalitarian unless it finds ways to work against implicit bias.
Airbnb could work against racial discrimination in several ways, the paper's authors say. It could conceal guest names, or have people use pseudonyms like eBay does. It could also expand its "Instant Book" option, which works more like booking for traditional hotels or bed and breakfasts, where guests aren't screened before they're accepted.
In a statement following the release of the Harvard working paper, Airbnb seemed open to considering options to fix this problem. "We recognize that bias and discrimination are significant challenges, and we welcome the opportunity to work with anyone that can help us reduce potential discrimination in the Airbnb community," the company said.
The internet has the potential to increase equality. After all, the paper's authors argue, there's almost no way for platforms like Amazon or Expedia to discriminate based on race or any other personal category. And they point out that some inequities, like black people being charged more than white people when they buy cars, go away when the transaction happens online.
But as our online lives start to look more like our offline ones, baggage like racial bias comes with it. And as it turns out, even Amazon can still find ways to discriminate.
Facebook chief operating officer Sheryl Sandberg is both famous and infamous for her book Lean In: Women, Work, and the Will to Lead. She has been praised for frankly discussing the deep gender inequities in the corporate world and for giving women sound advice on how to navigate them. She has also been harshly criticized for presenting a narrow, corporate version of feminism that ignores, or even actively harms, disadvantaged women.
But on the Friday before Mother's Day, Sandberg wrote a long, touching Facebook post that gives both her fans and her detractors something to think about.
Sandberg, who lost her husband just over a year ago, writes about how she never truly understood the difficulties of being a single mother until she became one herself.
She writes about how lucky she is compared with many others: She is financially stable after losing her husband, whereas one in five US widows live in poverty by age 65. Sandberg was in a heterosexual marriage, so she was unquestionably entitled to the things that cohabiting or same-sex couples might not be if their partner dies.
And she writes about how the experience has made her rethink the perspective with which she wrote Lean In:
In Lean In, I emphasized how critical a loving and supportive partner can be for women both professionally and personally—and how important Dave was to my career and to our children’s development. I still believe this. Some people felt that I did not spend enough time writing about the difficulties women face when they have an unsupportive partner or no partner at all. They were right.
I will never experience and understand all of the challenges most single moms face, but I understand a lot more than I did a year ago. Our widespread cultural assumption that every child lives with a two-parent heterosexual married couple is out of date. Since the early 1970s, the number of single mothers in the United States has nearly doubled. Today, almost 30 percent of families with children are headed by a single parent, and 84 percent of those are led by a single mother. And yet our attitudes and our policies do not reflect this shift.
Single moms have been leaning in for a long time—out of necessity and a desire to provide the best possible opportunities for their children.
Some critics argue that the backlash against Sandberg and Lean In was overblown and unfair — that she was always writing from her own experiences, that she wasn't trying to speak for all women, and that her self-described "sort of" feminist manifesto shouldn't be read as any sort of full-blown treatise.
But it's also telling and important to see how such a dramatic shift in Sandberg's personal experiences might have colored her advice to other women.
Last month, Uber announced that it was settling two big driver lawsuits that could have forced the company to recognize its drivers as employees rather than independent contractors. In a post titled "Growing and growing up," Uber CEO Travis Kalanick argued that it was "time to change" Uber's relationship with drivers, offering drivers more transparency and due process.
Uber should make these the first steps toward a broader rethinking of the company's public image and the way it does business. Uber began its life as a scrappy startup trying to break up the taxi cartels that dominated most of America's big cities. When Uber was a clear underdog, many people appreciated the company's rebellious streak. Without it, the company probably wouldn't have survived.
But Uber is no longer an underdog. It's a huge company, and it's likely to become more dominant in the coming years. And when a company with real power behaves like Uber circa 2013, it doesn't seem scrappy. It seems menacing.
And that's a problem because Uber has ambitions to become much more than just another taxi service. Uber wants to become a kind of transportation utility — the default way that people and goods move around a city. That would make Uber one of the most powerful institutions in our cities.
But if Uber continues to be seen as a bull in the china shop, its growing authority will inevitably become a source of concern from voters and public officials. If Uber wants people to be comfortable with it wielding that kind of influence, it's going to have to become a company that people trust and admire. Yet Uber still seems focused on maximizing short-term profits rather than the public interest — and ironically, that approach is likely to make Uber less successful in the long run.
New companies need to think about growth and achieving profitability. But often, successful companies reach a point where they generate profits reliably enough that they can relax and think about larger strategic issues.
One of the most important things big companies have to think about is their public image. And different companies have chosen to handle this in different ways. Some companies — think about technology companies like Amazon or Apple, for example — are beloved by customers for their well-designed products and excellent customer service. Others — think especially about telecommunications providers like Comcast (whose NBC Universal subsidiary is an investor in Vox Media) or Verizon — are disliked by many customers who have little choice but to use them anyway.
Right now, Uber's reputation is in an awkward limbo between these two extremes. On the one hand, many people love Uber's service, and admire the company for its role in opening up the taxi market around the country.
On the other hand, Uber has had more than its share of bad publicity over the years — allegedly spying on customers, threatening to dig up dirt on journalists, and downplaying sexual assault concerns. Uber's surge pricing — which can lead to customers paying up to nine times the normal fare — is also a source of continued frustration among some customers.
The public's ambivalence means that Uber has more opportunity than most companies to reshape its public image. If Uber makes a concerted effort to improve its public image, it could cultivate a reputation that's more like its Silicon Valley peers. On the other hand, if it ignores the issue, it could be one or two scandals away from a more toxic public image.
And Uber's public reputation also matters more than it would for most companies because Uber is a lightly regulated company in an industry — transportation — that has traditionally been heavily regulated. If Uber succeeds in its goal of becoming a more and more important part of America's transportation system, it is going to face greater scrutiny from regulators. A good reputation for the public will be invaluable as Uber tries to shape the laws to its own advantage.
Uber's relationship with its drivers has emerged as a key point of controversy. Many drivers, of course, love the flexibility and independence provided by Uber's just-in-time model. But others — especially those allied with the labor movement — have grown dissatisfied. They fault Uber for its arbitrary and opaque process for removing drivers from the platform. And more broadly, they fault Uber for failing to provide its drivers — even those who effectively work for Uber full time — with the job stability and benefits they would enjoy if they were legally considered to be Uber employees.
Uber has flatly rejected calls to make its drivers employees, arguing persuasively that switching to a formal employer-employee relationship would be bad for both Uber and its drivers. A fundamental aspect of an employer-employee relationship is that the employer sets the employee's schedule — yet for many drivers, the ability to decide when and where to work is a big selling point for the Uber platform.
At the same time, Uber could be doing more for its drivers. Uber tacitly acknowledged this when it announced its settlement with California and Massachusetts drivers. Some of the company's key concessions — including an official policy on driver deactivation and an appeals process for unjustified terminations — are taking effect nationally, not just in California and Massachusetts. That's because they weren't really "concessions" — they were ways to improve driver satisfaction, which benefits Uber in the long run.
But there's more Uber could be doing here. As part of the settlement, Uber agreed to fund drivers' associations in Massachusetts and California that could serve as a forum for drivers to raise grievances with Uber management. But there's no reason to do this only in those two states — forming such organizations in all 50 states would be a good way to make sure drivers nationwide have an effective channel for raising concerns, promoting driver satisfaction and benefitting Uber in the long run.
And while it doesn't make sense to make Uber drivers formal employees, there's more Uber could do to reduce the volatility of driver earnings. When I drove for Lyft, the company had a promotion where they guaranteed that drivers would earn a minimum amount if they drove at least 50 hours, including 10 hours during peak times. Uber could adopt a similar policy, ensuring that its most loyal drivers don't have to worry that a light week will make it hard for them to pay the rent. (Uber does offer its riders some earning guarantees but they're much more limited.)
Improving the driver experience isn't just important because it will help Uber recruit and retain drivers — so long as the labor market remains weak, recruitment isn't a big challenge. The bigger issue is that hundreds of thousands of satisfied, loyal drivers could be a powerful political weapon. Happy drivers are going to be more willing to mobilize on Uber's behalf in cases where the basic ride-hailing business model is threatened by regulators.
This is something that major telecommunications companies like Verizon understand.
Verizon and the labor unions representing its workers have their share of conflict over pay, benefits, and working conditions. But at other times — like the recent fight over network neutrality regulations — the Communications Workers of America have been a key ally of major broadband providers. After all, a labor union of telecommunications workers can only prosper if telecommunications companies are economically healthy.
Uber and Uber drivers, similarly, have a shared interest in seeing the ride-hailing business succeed. And Uber drivers are much more sympathetic advocates for the Uber business model than Uber management. So ensuring that Uber drivers aren't just satisfied but enthusiastic about Uber will pay political as well as economic dividends.
Another major Uber flashpoint is over surge pricing. Many riders have a visceral negative reaction to the idea that they could be forced to pay three, five, or even nine times the standard rate during periods of peak demand.
Once again, Uber has refused to abandon variable prices. And once again, Uber has a valid point: If Uber charged the same rate at all times, the service would suffer from massive driver shortages during periods of peak demand.
Yet there's a straightforward way that Uber could preserve the benefits of variable pricing while blunting the backlash: Use discounts rather than surcharges. Instead of setting a low standard rate and then charging multiples of that amount during periods of high demand, it should set a high standard rate and then offer generous discounts at times when demand is low.
The actual prices charged under this system might be identical (except during periods of very high demand). But customers get less angry about a company cutting prices unexpectedly than raising them. This is why restaurants and bars offer half-price happy hour specials instead of doubling prices on Friday and Saturday nights.
If Uber isn't ready to go that far, an even simpler step would be to shift its pricing so that 100 percent of surge pricing revenue goes to drivers. That would make Uber's argument that surge pricing is needed to get drivers on the road more plausible.
Uber's goal should be to become a universal public utility. And one thing public utilities do is provide service to everyone.
One way Uber can make this point while generating positive publicity for itself and developing better relationships with public officials would be to expand its service to disabled riders. Last year, Uber launched a pilot program for disabled riders in Austin, Texas. But the company continues to face criticism from disability advocates for doing too little to ensure that its service is accessible to disabled customers.
But there's room for Uber to go a lot further. The Americans with Disabilities Act requires transit agencies to provide disabled customers with paratransit services to help them get to and from bus and subway stops. These services are very expensive for transit agencies to provide, and they rarely provide the kind of on-demand service that Uber riders now take for granted.
Uber has flirted with becoming a paratransit provider, but the company should do more than flirt: It should start lobbying transit officials across the country for contracts to provide paratransit services. With the infrastructure Uber already has, it should be able to offer services that are a lot more convenient than conventional paratransit, while saving local governments money.
This probably wouldn't earn Uber big profits, but it would have benefits that could be far more important. It would get Uber a lot of positive press for improving the lives of people with disabilities. It would allow them to deepen their ties with local officials whose help they may need in the future. And it could convert disabled people — and the organizations that advocate on their behalf — into key Uber allies.
The current economic recovery has been under way since 2009, making it one of the longer periods of continuous economic growth in American history. But it has also been one of the most sluggish recoveries on record. The economy just isn't creating as many jobs — or pushing wages up as quickly — as it did in previous decades.
On Friday, the Labor Department released new data showing the performance of the labor market in April. And it continued the pattern of the past couple of years. The economy added 160,000 jobs, a bit below the 200,000-per-month average of the past couple of years:
Wages have grown 2.5 percent over the last year — a respectable figure given that the inflation rate was only about 1 percent during the same period.
The unemployment rate was unchanged at 5 percent.
But the most disappointing statistic in this month's numbers is the labor force participation rate. This figure shows the fraction of the workforce that is either working or looking for work. Normally, this figure falls during recessions and then goes back up during economic recoveries. But it fell from 2008 until 2015 — a sign that the economy wasn't growing robustly enough to lure back workers who had left the workforce. Over the past six months, the labor force participation rate had started to rise, a hopeful reversal of that trend.
But in April, the LFPR declined by 0.2 percent. That obviously could prove to be a blip if the LFPR sees big gains in future months. Still, it seems like another sign that the economy has yet to deliver the kind of rapid growth the country has been hoping for.
Most of us take it for granted that we have a right to quit our current job and find a new one. But a growing number of workers are seeing this freedom curtailed by noncompete contracts that bar employees from taking jobs with a competitor of their previous employer.
A new report from the White House portrays this trend as a threat to both worker rights and economic growth. Limits on worker mobility can slow the spread of knowledge and, therefore, the rate of technological progress. These agreements also reduce worker bargaining power, which can lead to lower wages and make it harder for workers to find jobs they enjoy.
The report is the latest sign of growing interest in this issue from policymakers. Last year Hawaii banned noncompete agreements for workers in the technology sector, while Oregon banned them for doctors and Oregon and Utah placed new time limits on the deals.
But in recent years, no state has gone as far as outlawing these agreements outright. And that's true even though one of the few states where noncompete agreements are totally unenforceable, California, is also one of the nation's most innovative.
Noncompete agreements have traditionally been used against highly skilled workers to prevent them from taking company secrets to competitors. In theory, the enforcement of these deals gives workers a greater incentive to provide worker training and invest in research and development programs.
However, it's not obvious that stopping the spread of knowledge in this way is actually good for the economy as a whole. Critics point to a famous 1999 paper that attributes Silicon Valley's success to the state's refusal to enforce noncompete agreements. With California courts refusing to enforce these contracts, Silicon Valley developed a job-hopping culture that promoted the rapid spread of new ideas.
It's impossible to know for sure, but critics of noncompetes argue that this freewheeling culture was a key factor that allowed the San Francisco area to outpace other regions — like Boston's Route 128 corridor — as the nation's premier technology center.
There's a lively debate about whether it's a good idea to enforce noncompete agreements against highly skilled employees. But it's harder to defend the use of noncompete agreement against lower-skilled workers. The White House cites one study finding that 14 percent of workers making less than $40,000 per year and 15 percent of workers without college degrees are subject to noncompete agreements.
These workers are unlikely to receive much training, and they rarely possess valuable trade secrets. In one infamous case, for example, the Jimmy John's sandwich chain has been asking its employees to sign agreements promising not to take their sandwich-making skills to competing sandwich shops. It's hard to imagine that this restriction increases the incentive Jimmy John's has to invest in better sandwich-making techniques.
What it can do, however, is limit workers' bargaining power and thereby push down wages. The White House points to empirical research finding a connection between stronger enforcement of noncompete agreements and lower wages.
One way to address this problem would be to ban noncompete agreement for low-wage workers. A proposal from Sen. Al Franken (D-MN) and Sen. Chris Murphy (D-CT) would do just that, prohibiting the contracts among workers making less than $15 per hour.
But there are also other, less dramatic actions policymakers could take. For example, employers often ask employees to sign noncompete agreements after they've already accepted the job, limiting their bargaining power. The White House argues that employers could be required to notify employees of the noncompete agreement at the time they make a job offer, giving employees an opportunity to look for a different job if they want to.
The White House also suggests that noncompetes should be unenforceable in cases where a company lays off workers. The White House also points to states where the courts automatically strike down overly broad noncompete language, giving employers a stronger incentive to write narrower, less onerous noncompete rules.
The White House is a naturally conservative institution, so it's not surprising that it's sticking to these relatively modest reform ideas. But it's worth asking whether states shouldn't go even further.
Noncompetes have been unenforceable in California for more than a century. Not only does this not seem to have hurt the state's economy, it may have helped the state attract the talent that made Silicon Valley what it is today.
More fundamentally, noncompete agreements impose a major restriction on the freedom of employees to decide where they want to work. We're a nation that values freedom, and where you work is one of the most important decisions any working adult makes.
In recent years, no state has gone the full California route and banned the enforcement of noncompete agreement outright. But some of them should try it. Absent compelling evidence that noncompetes are economically beneficial — and if anything,  the evidence suggests the opposite — states might want to err on the side of protecting worker autonomy.
Update (May 5, 2016): In a new post on his website, Wright has now tacitly admitted that he can't prove his identity as Bitcoin's creator. But rather than admitting the obvious — that he isn't actually Satoshi Nakamoto — Wright claims that "As the events of this week unfolded and I prepared to publish the proof of access to the earliest keys, I broke. I do not have the courage. I cannot."


For years, people have been trying to unmask Bitcoin's enigmatic creator, known only by the pseudonym Satoshi Nakamoto. Previous efforts have not panned out. But this morning three media organizations — the BBC, the Economist, and GQ — reported that an Australian man named Craig Wright was claiming to be Bitcoin's creator.
And this story is different from previous efforts to unmask Nakamoto in a crucial way: Wright claims he can offer cryptographic proof of his identity. As the BBC puts it, "Wright has provided technical proof to back up his claim using coins known to be owned by Bitcoin's creator."
Most convincing of all, a prominent Bitcoin developer named Gavin Andresen says he believes that Wright is Nakamoto. Andresen is the man Nakamoto chose to lead the Bitcoin project when he abruptly left the Bitcoin community in 2011, and he's still one of the most prominent figures in the Bitcoin world.
Yet something doesn't add up about Wright's claims. The real Nakamoto would be able to settle all doubt about his identity by publishing a mathematical proof called a digital signature. Instead, Wright seems to have orchestrated an elaborate smoke-and-mirrors campaign, offering private demonstrations to a handful of people — most of whom weren't in a position to fully verify the evidence he provided.
Security researcher Dan Kaminsky is particularly harsh. "This is a scam," he wrote in a Monday blog post. "Not maybe. Not possibly. Wright’s done classic misdirection by generating different scams for different audiences."
The idea that Wright is Nakamoto isn't new. Wired and Gizmodo first reported the possible Wright-Nakamoto connection back in December. These publications were contacted by a man posing as a hacker with a grudge against Wright. He provided what appeared to be incontrovertible proof that Wright was, in fact, Satoshi Nakamoto.
But this evidence proved hard to authenticate. The documents included email discussions with computer forensics expert Dave Kleiman from 2008 — before Bitcoin was released to the public. Unfortunately, Kleiman died in 2013, so he can't confirm their authenticity. Other, more recent, documents merely proved that Wright had been telling various associates that he was Nakamoto — but of course that doesn't rule out the possibility that Wright could have been lying.
But the biggest red flag in these December stories was identified by Wired reporter Andy Greenberg. Early Wright blog posts appeared to link him to Bitcoin at a time when the cryptocurrency was still in its infancy. The problem is that these posts were modified in 2013 or later to add key references to Bitcoin.
Similarly, forensic examination of a cryptographic key purportedly belonging to Nakamoto — and linked to Wright — showed that it was likely created by a version of cryptographic software that didn't yet exist when the key was created in 2008.
In short, most of the evidence purportedly showing that Wright was connected to Bitcoin during its creation in 2008 and 2009 appears to have been manufactured years after the fact. We don't know who was perpetrating this apparent hoax, but some in the Bitcoin community started to suspect that the anonymous "hacker" was actually Wright himself.
Wright still insists that the December revelations occurred against his will. He says that those reports led to a swirl of rumors that have negatively affected his friends, family, and employees. And so, he claims, he decided to set the record straight by finally acknowledging that he is Bitcoin's creator.
This ought to be easy to do. Bitcoin is based on a cryptographic technology called digital signatures. Bitcoin users "sign" transactions before submitting them to the Bitcoin network, ensuring that only the owner of a particular Bitcoin account can spend money from it.
Some of the earliest Bitcoin transactions were signed with a private key belonging to Satoshi Nakamoto. So the easiest and most convincing way to show that you're Nakamoto is to sign something with this private key. Assuming Nakamoto has practiced good security, no one else should be able to do this. And once a signature is published, anyone in the world can use standard software tools to mathematically verify that it was signed with the same private key as Nakamoto's earliest Bitcoin transactions.
On Monday, Wright published a long, rambling blog post purporting to do just that. But security experts say it does nothing to establish Wright's identity. What Wright appears to have done is to find an old digital signature generated by Nakamoto years ago, reformatted it, and then presented it as a new signature generated by Wright.
So the post doesn't just fall short of proving that Wright is Nakamoto. It suggests that Wright is willing to go to elaborate lengths to trick people into believing that he is Bitcoin's creator.
Wright's strongest bit of evidence is the endorsement of Gavin Andresen. When Nakamoto stopped contributing to the Bitcoin project in 2011, he turned effective control over the project to Gavin Andresen, who was then a software developer in his 40s. Today, Andresen is the chief scientist for the Bitcoin Foundation and a member of Bitcoin's core development team.
So when Andresen wrote this morning that he believed Wright was the creator of Bitcoin, people paid attention.
"During our meeting, I saw the brilliant, opinionated, focused, generous – and privacy-seeking – person that matches the Satoshi I worked with six years ago," Andresen wrote. "And he cleared up a lot of mysteries, including why he disappeared when he did and what he's been busy with since 2011."
However, Andresen had never met Nakamoto face to face before, so this didn't mean a whole lot. The key question was whether Wright had Nakamoto's encryption keys. And Andresen claimed Wright did just that.
Andresen described the procedure he used to verify Wright's identity in a Reddit post. Wright cryptographically signed a message chosen by Andresen, transferred it to a new laptop, and then used software to verify that the signature was valid.
If taken at face value, this appears to show that Wright has Nakamoto's private keys. But this verification process leaves lots of room for a hoaxster to trick a gullible observer. The key question is whether Wright tampered with the software used to verify the digital signature — if he did, then obviously this verification is meaningless.
And crucially, Wright didn't allow Andresen to verify the signature on his own laptop, keep a copy of the signature, or (best of all) publish it so it could be verified by anyone in the world. So if there was something fishy about the software Wright used for his demonstration, Andresen didn't have any opportunity to confirm that.
The demonstration Wright provided to the Economist was similarly limited. The newspaper wrote that "information that allows us to go through the verification process independently was provided too late for us to do so fully." The Economist concluded that "as far as we can tell," Wright had control of Nakamoto's private key. But under the circumstances, that doesn't mean a whole lot.
So were Andresen, the Economist, and other observers tricked by the digital equivalent of a magic trick? No one other than Wright knows for sure. But given the elaborate lengths someone has gone to manufacture other evidence linking Wright to Nakamoto, it's worth being very skeptical.
But one thing we do know for sure is this: If Wright were really Bitcoin's creator, he could put all these doubts to rest very quickly. All it would take is for him to publish the digital signature he claimed to have generated for Gavin Andresen. In a matter of minutes, independent experts would be able to check the signature and verify that it was created using the same key as the earliest Bitcoin transactions.
But Wright hasn't done this. And it's hard to think of any plausible explanation other than the obvious one: that he hasn't done it because he can't do it.
Indeed, the way Wright has stage-managed the latest revelations about himself seem inconsistent with what we know about Nakamoto. Wright chose to give his scoop to the BBC, the Economist, and GQ. These are all excellent publications, but none of them are known for their in-depth coverage of computer security. The real Satoshi Nakamoto should have anticipated that no one would give much weight to a GQ scoop about his identity.
Bitcoin was Nakamoto's attempt to create a financial system that didn't require trusting the fallible human beings that run the banking system. Yet when Wright decided to reveal his identity as Nakamoto, he chose to do it via face-to-face meetings with a handful of journalists and Bitcoin insiders instead of providing mathematically rigorous proof that anyone could verify. It's hard to believe that's what Nakamoto would have done.
A class action lawsuit against Starbucks is seeking $5 million in damages over the key difference between hot drinks and cold drinks: ice.
When you order a 24-ounce "venti" coffee at Starbucks, you're getting 24 ounces of coffee. But when you order a 24-ounce iced coffee, you're getting 14 ounces of coffee, plus a whole bunch of ice.
And if customers knew that, a lawsuit filed in federal court alleges, they wouldn't have been willing to pay nearly as much. The lawsuit is seeking $5 million in damages on behalf of everyone who's bought a Starbucks cold drink since 2006.
This is a silly lawsuit; it implies, among other things, that customers don't realize that ice takes up space in drinks. But the fact that Starbucks, which got its start with hot coffee and blended cold drinks, is facing a lawsuit over how much ice it dumps into customers' cups actually is an interesting insight into how its business is changing.
Selling coffee in the morning is a lot more competitive than it used to be, and Starbucks is getting crunched at both ends of the market. Dunkin' Donuts has expanded nationally. Krispy Kreme is trying to make its coffee seem more upscale. The Canadian chain Tim Hortons has merged with Burger King and is increasing its presence in the United States. And at the higher end of the market, super-upscale coffee — pourovers, single-origin beans, and so on — is growing so much that Starbucks opened a fancy tasting room in New York in 2014.
So Starbucks' future growth doesn't rely entirely on hot coffee at all. Instead, according to the company's five-year plan, the overall goal is to keep people coming into stores in the afternoon and evening, long after they've finished their morning coffee.
That means selling beer and wine, food, and yes, iced drinks:
And iced drinks are a moneymaker in part because people are willing to pay more for them. Americans really want their cold beverages, ice and all.
On Monday, Puerto Rico is expected to skip payment on $389 million in debt owed by the island's Government Development Bank to bondholders. Gov. Garcia Padilla of Puerto Rico has been warning for over a year that this government will be unable to fully pay what it owes, and has asked Congress to provide for a structured path to bankruptcy. He didn't get it, largely due to opposition from congressional Republicans, so he is now being forced to resort to unilateral repudiation of debt.
"Faced with the inability to meet the demands of our creditors and the needs of our people, I had to make a choice," he said "I decided that essential services for the 3.5 million American citizens in Puerto Rico came first."
The Obama administration and many members of Congress had been pushing to create a bankruptcy process for Puerto Rico that would allow bondholders to recoup some of what they are owed while allowing the island's government to continue functioning. Since Congress has, so far, not acted we are now on the precipice of a much more uncertain and chaotic situation in which Puerto Rico will attempt to selectively cancel debts and bondholders will seek to use the federal courts to block the Puerto Rican government from operating until it pays up.
Puerto Rico is an island in the Caribbean Sea that is also a largely self-governing territory of the United States.
For years, a quirk of US law created a tax subsidy for Puerto Rican debt that encouraged middle class Americans to binge on loaning money to Puerto Rico without really realizing that's what they were doing. The Puerto Rican government took advantage of this situation by borrowing a lot of money, but didn't manage to spend the money that they borrowed to accomplish much that was useful in the long term.
Then starting in 2006, Puerto Rico was hit with a series of economic misfortunes. At that point, Puerto Rico's strong ties to the United States became a liability because Puerto Rico could not adjust to bad economic times with currency depreciation, but Puerto Rican people could adjust to bad times by moving to the mainland United States.
That has left Puerto Rico in a 10-year downward spiral of tax hikes, spending cuts, emigration, and higher interest rates. About a year ago, Padilla announced that Puerto Rico is in a "death spiral" that he needs to halt, and he began saying that bondholders will not be fully paid. He asked for the creation of a legal bankruptcy process but warned that even absent one the money would not all be paid.
The bad news is that Puerto Rico is really facing two separate death spirals.
One is the basic death spiral of self-fulfilling default risk. The more money you owe, the more likely it is that you won't be able to pay back all the money that you owe. That means that when your debts come due and you need new loans to pay off the old ones, investors start demanding that you compensate them for their risks in the form of higher interest rates. Those higher interests rates increase the financial burden on your country, and that in turn makes default more likely.
But the death spiral Garcia was referring to is a second one.
People generally don't like paying taxes but do enjoy receiving high quality government services. Consequently, a given territory's ability to turn tax revenue into useful services is an important driver of whether people will want to live and do business there. To the extent that your tax revenue is going to pay off old debts, it is not going to provide current services. Thus the more of your budget that you dedicate to debt repayment, the worse the value proposition that you are delivering to your territory's residents and businesses.
The harder Puerto Rico squeezes, in other words, the more its economy suffers. But the more the Puerto Rican economy suffers, the harder it is for Puerto Rico to pay back its debts. In other words: death spiral.
Puerto Rico's total debt outstanding is $72 billion, which is small relative to the overall United States economy but big pretty much any other way you slice it.
Two US states have more debt than that — California and New York — but Puerto Rico is much smaller, with approximately the population of San Diego County. New York and California are also richer than the average US state whereas Puerto Rico is poorer. Almost all US states have growing populations, but Puerto Rico's is shrinking. In October of 2013, the Economist reported that "in America’s 50 states the average ratio of state debt to personal income is 3.4%" whereas the ratings agency Moody's says the comparable figure for Puerto Rico is 89 percent.
Hawaii, the most indebted US state by this measure, has a 10 percent ratio.
In other words, Puerto Rico's debts really are way out of line with what any state is financing, and there's no real precedent for paying down debts of this magnitude. There's no real precedent for refusing to pay them either, but default is by no means a crazy option.
A large share of the money was initially lent by people not so different from you or me — middle class Americans, especially those living in higher tax states. As for what they were thinking, they probably weren't thinking much of anything in particular.
They were just putting money away for retirement in municipal bond funds to diversify their portfolios.
Those funds, in turn, were invested in a diverse array of US public sector bonds. Since Puerto Rican bonds feature some unusual tax advantages, there was an unusually robust level of demand for Puerto Rican debt. Successive Puerto Rican governments responded to demand for their debt in the economically rational way — they borrowed an unusually large amount of money. But none of this lending was driven by particular scrutiny of the details of Puerto Rico's economic situation, and when Puerto Rico's economic fortunes began to change about 10 years ago the dynamics became untenable.
The flip side of this mindless lending is that Puerto Rico failed to take real advantage of the financial windfall it provided. In theory, loads of cheap debt could have been used to finance incredibly useful public works projects and other social services that laid the foundations for enduring prosperity. But it didn't happen. Instead, Puerto Rico seems to have mostly taken advantage of the opportunity to run a somewhat more generous welfare state than the island could really afford over the long term. Thus when the easy money went away, the country was left with a huge pile of debts rather than a huge pile of enduringly useful infrastructure.
Not exactly, though "America" from the 1957 musical West Side Story does deal with many of the relevant issues — debt, Puerto Rico's relative impoverishment vis-a-vis the United States, the possibility of mass emigration, and the island's oft-misunderstood political relationship with the mainland United States. The recent Glee version tones down the minstrelry relative to the original:

But problematic though it may be, Rita Moreno's classic 1961 film performance is still worth your time and provides clearer context. A crucial eight-bar musical phrase from the song is replicated in Metallica's "Don't Tread on Me," if heavy metal is more your thing.
All municipal bonds are exempt from federal income taxes. In addition, if you buy municipal bonds issued by the place where you live, those bonds are exempt from state and local income taxes as well. Such bonds are known as triple tax exempt, and they're a big deal for municipal finance and high tax places like New York and California.
But Puerto Rico's bonds are triple tax exempt regardless of where you live.
This is not a huge deal for most Americans, but for a high-income person living in a high-tax state it can be a very big deal. And it helped fuel a lot of lending to Puerto Rico that wasn't necessarily thought through in a very serious way.
Starting in 2006, the island has been hit by a series of negative shocks that have undermined its economy and its creditworthiness.
That was the year that Puerto Rico lost its longstanding federal tax advantages as a location for US companies to do business in. From 1986 to 1996, these took the form of special tax credits (pre-1986 the tax advantage worked differently but had a similar impact) that were rationalized as a way to help Puerto Rico be competitive with developing countries as a manufacturing location, given that Puerto Rico-based firms need to comply with basic US labor rights and safety standards. But starting in 1996 these advantages were placed on a 10-year phase-out schedule and, despite the hopes of Puerto Rican politicians (and tax break hungry business), they were never extended or replaced. That prompted an exodus of businesses from the island from which it has never really recovered.
After that:
A related ongoing development is that in response to Puerto Rico's economic woes, Puerto Rican people have increasingly chosen to leave the island.
Pew
For any given individual, migrating to the mainland makes a lot of sense given the economic conditions on the island. But each person who departs leaves the people who remain with a higher share of old debts to repay. That makes the economic situation even worse and the debt even harder to pay.
No. People throw the word bankrupt around a lot, but it actually has a specific technical meaning laid out in the US Bankruptcy Code and other laws. There are a lot of different kinds of bankruptcy, and they all lay out one way or another for a person or organization that cannot pay back its debts to restructure its payments and move forward. The key is that bankruptcy is an organized, rule-governed process designed to bring some clarity to the situation and ideally to resolve it sooner rather than later.
But US bankruptcy law makes no provision for Puerto Rico (or a US state) to declare bankruptcy. Indeed, what's really special about Puerto Rico is that Puerto Rico's municipalities and municipal corporations — unlike towns, utilities, and school districts in the US mainland — can't declare bankruptcy either.
Puerto Rico's supporters in the White House, in Congress, and the Treasury Department have been trying to create a bankruptcy process for Puerto Rico, but bondholder organizations have characterized this as a "bailout" and blocked action in Congress. So now we get a situation that is going to be a lot more chaotic and generate a lot more revenue for lawyers.
First, the Puerto Rican government will try to unilaterally decide which bond payments it needs to skip in order to keep the lights running. Then there will be lawsuits — lots of lawsuits — in which various creditors try to force Puerto Rico to pay them ahead of paying Puerto Rico's civil servants, pensioners, social assistance recipients, and other creditors.
It is relatively unlikely that a federal court based in New York will actually try to dispatch cops to Puerto Rico to physically haul money off. But it's easy to imagine a scenario in which banks based in the mainland are told it's illegal to participate in processing payments of salaries for Puerto Rico's police officers because Puerto Rico's bondholders have not yet been paid.
Puerto Rico should be an independent country.

To many residents of the mainland United States, separation between the USA and Puerto Rico seems like a natural solution to the island's financial woes as well as the most logical resolution of an anomalous constitutional situation. After all, the empire-building and thirst for military bases that led the United States to take Puerto Rico away from Spain in 1898 are long since obsolete, and Puerto Rico is linguistically, culturally, and economically distinct from the United States.
What's more, sovereignty could help Puerto Rico in a number of ways. For starters, an independent Puerto Rico would have its own currency and could set monetary policy that is appropriate to Puerto Rican conditions.
Right now the Federal Reserve does things with little regard for their impact on Puerto Rico, and the value of Puerto Rico's currency (the US dollar) is driven by factors that have nothing to do with Puerto Rico's situation. An independent Puerto Rico could also establish a tax and regulatory framework that is suitable to its status as a middle-income country, rather than subjecting businesses to policies designed for the much richer United States.
Wikipedia graphic / Puerto Rico government data
The big problem with this idea is that Puerto Ricans don't want to be independent. In a 2012 referendum, a large minority of the population said Puerto Rico should continue with the status quo. Among the 54 percent who desired change in Puerto Rico's constitutional status, 60 percent said Puerto Rico should seek to become a US state. Only 5.5 percent of the 54 percent favored independence.
There are some practical reasons for this, but the main reason is that Puerto Ricans have been Americans for a long time and just like other Americans feel a strong connection to their country. Most Puerto Ricans have friends and family members living on the US mainland, and many people go back and forth. Consequently, the idea of independence is just a total non-starter. Statehood has more appeal to Puerto Ricans, but would not address any of the factors leading to Puerto Rico's debt problems, and securing a reputation for the island as a deadbeat is unlikely to inspire the mainland United States to become excited about statehood.
Things are looking up for Mark Zuckerberg. While a lot of other major tech companies — including Apple, Google, and Microsoft — have posted disappointing financial results for the first quarter of 2016, Facebook announced yet another quarter of spectacular growth on Wednesday. The company's quarterly revenues have grown by more than 50 percent over the last year — an impressive achievement for a company of Facebook's size.
To some extent, Zuckerberg is simply riding a wave of popularity that started when he created the social network 12 years ago. But Zuckerberg has also made a series of savvy decisions that have allowed the company to maintain momentum as others have stumbled. And Facebook stock price is about 90 times its annual earnings (the stock market's overall average is about 24), suggesting that Wall Street expects the company to continue outperforming other companies of its size.
Zuckerberg believes Facebook's success has been enabled by Facebook's unusual corporate structure, which gives him permanent and near-total control over the company he founded — despite owning fewer than 18 percent of Facebook shares. On Wednesday, Zuckerberg announced a new plan that would allow him to sell most of his shares — or donate them to charity — further reducing his stake in the company without losing his majority of the firm's voting rights.
You might think Facebook shareholders would get nervous about the prospect of Zuckerberg having total control of Facebook — with no accountability to other shareholders  — even as his financial stake in the company dwindles. So far there's been little sign of opposition, but there's a good chance Facebook will face a lawsuit before the new plan can go into effect.
Initially, Facebook was a website, and a less savvy CEO might have missed the significance of smartphones and tablets — as some other web companies did. Flickr, for example, was a popular web-based photo sharing service in the late 2000s, but its owner, Yahoo, never figured out how to turn it into a popular smartphone platform.
But Zuckerberg quickly grasped the importance of smartphones and ensured that Facebook would have a full-featured mobile app.
Zuckerberg further shored up Facebook's position in the mobile marketplace by buying other companies. When Facebook bought Instagram for $1 billion in 2012, the move was mocked by observers like the Daily Show's John Stewart. Now, of course, Instagram has more than 400 million users, and there's little doubt that it would be worth a lot more than $1 billion if it were an independent company.
Facebook also paid $21 billion in 2014 for WhatsApp, a mobile messaging company that had more than 400 million users at the time.
Facebook's focus on mobile platforms has paid off. In its most recent quarter, mobile ads accounted for a whopping 82 percent of the company's overall revenue.
Most companies are run on a principle of one share, one vote. That means that as the company grows and raises money from outside investors, the initial founders wind up with a minority of the shares, making it possible for them to be fired if other shareholders become convinced that someone else would run the company better.
But some companies — notably Facebook and Google — are structured to avoid this situation. These companies have two different classes of shares, with the shares held by insiders like Zuckerberg (and Google co-founders Larry Page and Sergey Brin) having a lot more voting power than the shares controlled by the general public. The result: Zuckerberg owns just 18 percent of Facebook shares but controls 56 percent of the company's voting rights, giving him the right to hand-pick the board of directors that, in turn, selects the CEO.
That's a pretty sweet deal for Zuckerberg, because it means he can't be fired no matter how dissatisfied the other shareholders — who collectively own more than 80 percent of the company's value — get with his leadership. But even this isn't enough for Zuckerberg.
Zuck has vowed to give 99 percent of his wealth to charity during his lifetime, and he wants to get started on this now instead of waiting until after he leaves Facebook. But if he just sold a bunch of shares, his voting power would drop below 50 percent and he could lose control of the company.
So now Facebook is proposing to create a third class of shares, and give every existing shareholder — both insiders like Zuckerberg who have extra voting rights and members of the general public who don't — two extra shares for each share they already have. After this stock split, shareholders would have three times as many shares and each share would be worth one-third as much.
And crucially, these new shares would have no voting rights at all. That means Zuckerberg could sell them, liquidating two-thirds of his economic stake in Facebook, without diluting his voting power. In other words, he could go from owning 18 percent of Facebook to owning 6 percent, while maintaining total control of the company.
You might expect this to trigger a backlash from shareholders upset at the idea of somebody with a shrinking share of their company keeping total control over it. And indeed, when Google proposed a similar move back in 2012, a large majority of non-management shareholders opposed it. But founders Page and Brin already controlled a majority of the voting rights, and they used their power to approve the plan to give themselves even more power. Shareholders filed a lawsuit, but the lawsuit was settled, clearing the way for the plan to go forward.
The Facebook proposal for a new class of stock is even more aggressive than the Google proposal was. The Google proposal issued one new share for each share outstanding. Facebook's proposal issues two shares for every existing share — allowing Zuckerberg to sell two thirds of his shares and still maintain a majority of voting power.
There hasn't been much sign of a backlash yet, but it's a safe bet that the proposal will lead to shareholder objections and a lawsuit. Facebook's lawyers argue that the proposal benefits public shareholders because it gives Zuckerberg a stronger incentive to remain as CEO for the long run. Because the Google lawsuit was settled, we never got a ruling on the merits, so it's not clear if the courts will buy this kind of argument.
The clear signal, however, is that Zuckerberg intends to maintain control of Facebook even as he diverts most of his Facebook wealth to charitable causes. Zuck could have followed the lead of Bill Gates, devoting his 20s, 30s, and 40s to running Facebook and then devoting the later years of his career to giving his wealth away.
But Zuckerberg is evidently in a hurry to get started on the philanthropic phase of his career while he's still the boss at Facebook. Last year, he created an organization called the Chan Zuckerberg Initiative that will serve a similar function to the Bill and Melinda Gates Foundation, allowing Zuckerberg and his wife Priscilla Chan to begin donating his billions to worthy causes. If he's able to donate two-thirds of his Facebook stake to the Chan Zuckerberg Initiative, the organization will have a $30 billion war chest that it can begin dispensing to worthy charitable organizations immediately.
Correction: This article originally mis-stated how Google's stock split worked.
A bunch of companies in Silicon Valley, Detroit, and around the world are racing to build cars that drive themselves. And they have a big, important disagreement about what these vehicles will look like.
The disagreement centers around the steering wheel — and specifically whether cars will have one or not. On one side of the debate are conventional car companies who largely view self-driving capabilities as a new feature to add to their existing fleet of self-driving cars. On the other side of the debate is Google, which has already built a self-driving car prototype that's designed to operate in a fully autonomous mode.
This is partly a debate about safety; each side claims its own approach will save more lives. But it's also a clash of business models. If human beings can take over in situations the computer can't handle, it will be easier for car companies to gradually introduce self-driving capabilities to their existing vehicle fleets. On the other hand, companies like Google and Uber are starting from scratch anyway, and they can more easily adopt on-demand business models that are more compatible with fully autonomous operation.
The debate matters because regulators are currently drafting safety standards for autonomous vehicles. Reuters reports that California's standards may require cars to have a steering wheel, while federal regulations may allow fully autonomous operation.
If you're worried about the safety of self-driving vehicles, you might expect it to be safer to allow human drivers to take over in an emergency. It's easy to imagine nightmare scenarios where a self-driving vehicle suddenly malfunctions — or is hacked — and a helpless passenger is hurtled to his death.
Including an option for human-driven operation also allows self-driving technology to be conservative about when it takes control. In situations where the software isn't sure about the right thing to do — say, a construction site or a blizzard — it can hand over control to a human driver.
But some experts say that cars capable of switching between automatic and self-driving can actually be more dangerous than purely automated driving. That's because the most dangerous moment is the instant a vehicle switches between an autonomous and human-driven state.
If a driver wasn't paying attention just before the switchover, he's more likely to make a misjudgment about how fast the car is moving, which vehicles are around, and so forth. Human drivers might also get confused and assume the car is driving itself when it isn't. And over time, as cars become more and more automated, human drivers might get out of practice, making them less safe drivers if they're forced to take over in unusual situations.
This isn't just a theoretical problem — it's something that has cropped up with the autopilot feature on airplanes. As a 2014 New Yorker article pointed out, a number of crashes have occurred because pilots simply weren't paying close enough attention as the plan largely flew itself. That caused them to make crucial mistakes when they were forced to take over control.
One study found that with higher levels of automation, "pilots' ability to make complex cognitive decisions suffered a palpable hit. They were less able to visualize their plane's position, to decide what navigational step should come next, and to diagnose abnormal situations."
With the plane doing most of the driving, pilots had more trouble concentrating on the task in front of them. Their minds tended to wander That made them less well-prepared when an emergency required them to exercise good judgment and quick thinking.
Car companies are just starting to introduce partially self-driving cars onto the market, so we don't yet know if the same kind of problem will crop up on our roads. But it provides a powerful argument for advocates of allowing fully autonomous driving.
It's not a coincidence that Google has been leading the fight to allow fully self-driving vehicles, while many car companies prefer the gradual route. These technological approaches dovetail with the business strategies each company is likely to pursue.
Car companies are mostly in the business of selling finished automobiles directly to customers. And if you're buying a car, you naturally expect it to work in all circumstances. Yet building a car that can work in all circumstances — in rural as well as urban areas, in rain and snow, on mountain passes and in construction zones — is a difficult technical and logistical challenge that might take many years to fully solve.
There are two big issues here. One is that certain environments are just inherently challenging for an autonomous vehicle to navigate. A big snowfall, for example, will render most of a self-driving car's landmark-detection capabilities useless. Driving through a construction zone is another case where fully automated driving could be challenging, since lanes aren't as clearly marked as on a normal road.
The other issue is that self-driving software may need detailed maps to navigate safely. And mapping the entire country will take a lot more effort than mapping major populated areas.
A mixed-mode vehicle provides a nice solution to this dilemma. The car can drive in situations where it's safe to do so — when it's not snowing, not in a construction zone, and in an area where maps are available. The rest of the time, the human driver can take control.
Fully autonomous vehicles are going to have to take a different approach. If the vehicle isn't confident it can drive safely in a particular situation — in snow, in remote areas, on dirt roads, and so forth — it's going to have to refuse to drive altogether. And that means cars like Google's prototype that have no steering wheel are going to have some major limitations, especially in the early years.
Of course, that's going to be a hard sell if Google is trying to sell its vehicles directly to customers. Who wants to own a car that can only drive to certain parts of the country or certain weather conditions? But this wouldn't be such a big problem for an Uber-style on-demand service, since people who take taxis typically rely on a mix of transportation modes to get around anyway.
Over the long run, this is likely to emerge as the biggest cleavage in the self-driving car market. Uber is working on its own self-driving car technology, and we can assume they'll focus on building an on-demand service like the one they already have. GM and Lyft have a partnership to work on self-driving technology, suggesting that GM may be  interested in shifting toward a more on-demand model.
We can expect these on-demand vehicles to come without steering wheels. And without the need for a driver's seat, they may wind up looking a lot different than a conventional car. They might be smaller, have rear-facing seats, and offer less storage space. With their ability to go back and recharge after a few trips, they may have smaller batteries and a shorter range — and as a result, be more affordable.
On the other hand, we can expect some car companies to focus on an incremental strategy, gradually adding self-driving capabilities to conventional vehicles.
My guess is that in the long run, the fully automated, on-demand model will come to dominate, especially in urban areas. But for a while, we're likely to have a mix of partially and fully automated vehicles, with fierce competition between them — both in the consumer market and in the halls of government.
Disclosure: My brother works at Google.
Apple posted its worst quarterly financial results in more than a decade on Tuesday. Sales of iPhones, iPads, and Macs all fell by double digits, leading to a 13 percent drop in total revenue. The markets have reacted harshly, with the company's stock losing more than 7 percent of its value in after-hours trading.
Apple is still an enormously profitable company — it pulled in more than $10 billion in net income last quarter. But the latest figures represent the end of an era in which CEO Tim Cook — and before him Steve Jobs — could seemingly do no wrong.
However, the disappointing results don't necessarily mean that Cook has made any major management blunders. The issue is simply that the iPhone has been one of the most successful consumer products in world history. It's an almost impossible act to follow.
To get a sense for the magnitude of the iPhone's success, it's helpful to look back at Apple's financial picture nine years ago. In April 2007, a few months before the iPhone first appeared in stores, the company reported that it had sold 1.5 million Macs and 10.5 million iPods between January and March 2007, generating $2.3 billion and $1.7 billion in revenue, respectively. That was considered a big success and an impressive turnaround for a company that was close to bankruptcy when Jobs took over in 1997.
Today, of course, those figures look puny. Between January and March 2016, Apple sold 51 million iPhones, generating $33 billion in revenues — more than 10 times as much revenue as the iPod generated in its heyday. In addition, Apple sold 10 million iPads and 4 million Macs, for another $10 billion in revenue.
The markets are reacting negatively because the 51 million iPhones Apple sold in the first three months of 2016 is smaller than the 61 million iPhones Apple sold during the same quarter a year earlier. But 51 million is still a massive number. For that matter, most companies would consider selling 10 million iPads to be a big hit. Apple's financial results are only disappointing compared to the very high expectations set by previous quarters' results.
A good way to tell if Wall Street is optimistic or pessimistic about a company is to look at the ratio of its stock price to its earnings. When this number is high, it's a sign that investors are optimistic about the company's growth. Google, for example, has a price/earnings ratio of 30, while Facebook's is 84. As impressive as these companies' profits have been in the past, Wall Street expects them to make even more money in the future.
Apple is in the opposite situation. Its price/earnings ratio is around 10 — on par with stodgy companies like Ford and Verizon. That's a sign that investors aren't optimistic that Apple will be able to come up with another product that's anywhere close to the success of the iPhone.
So far, that skepticism has proven justified. Apple has sold millions of iPads, but iPad sales seem to have peaked in 2013. Apple hasn't provided sales figures for the Apple Watch, but estimates suggest that it's only a modest hit so far.
Presumably, Apple is working on other products that it hopes will be big hits. Maybe the rumored Apple Car will generate iPhone-level revenues and profits. But if Apple fails to find a successor to the iPhone, that won't be a sign that they've done anything wrong. iPhone-level hits are just very, very rare.

Apple's second quarter earnings report showed a company that is still enormous and still enormously profitable, but whose sales and profits are declining across the board — revenue fell 10 percent year-on-year in the Americas, 5 percent in Europe, 26 percent in China, and 25 percent in the rest of Asia, way too much to be offset by a 24 percent increase in Japan.
What's particularly striking about this, as Benjamin Mayo of 9to5Mac noted, is that Apple simply hasn't had a down quarter in so long that proclaiming each quarter to be a "record" has become a dull routine.

A word is missing from Apple's press release title today. pic.twitter.com/fv2Niabgd0
Proclamations that this means we've reached "peak Apple" are probably premature. It's not rare for companies as a whole to have down stretches and up stretches, and the fact that Apple is falling now doesn't mean they can't rise to new heights in the future.
But this quarter's earnings do show that the endless ascent the company's been on since the introduction of the iPhone has come to an end. People still love their iPhones, but Apple's already sold enough of them that it's going to take something more than business as usual to push them to new heights.
This week, the Federal Reserve is meeting to decide whether to raise interest rates. Arguments about Fed decisions tend to get pretty deep pretty fast. What tends to get lost in the shuffle are the most fundamental and important issues: that a somewhat obscure government agency exercises enormous control over the economy by changing the price of money at regularly scheduled meetings.
Since the state of the economy ends up influencing everything from your ability to get a new job to the outcomes of presidential elections, that makes these meetings one of the most important events on the calendar. Yet they're rarely discussed outside specialist circles except by the occasional crank, leaving ordinary people in the dark.
An interest rate is the price lenders charge to borrowers to use their money. An interest rate of 5 percent means that someone borrowing $1,000 will have to make interest payments of $50 per year — in addition to eventually paying back the amount that was originally borrowed.
There are different interest rates for different types of lending — home mortgages, business loans, credit cards, and so forth.
But when economists talk about the Fed "raising interest rates," they're referring to a specific rate called the federal funds rate. That's the rate big banks charge one another for short-term loans.
The way the Fed manipulates the federal funds rate has broad economic effects
People often talk about the Fed "setting" this interest rate, but that's not quite accurate. What happens is that the Fed announces a target for the federal funds rate and then uses its ability to create or destroy money to reach its target.
Of course, these actions don't only affect the federal funds rate. When the Fed pushes the rate up or down, it tends to push other interest rates in the same direction as the federal funds rate. So ultimately, the Fed's interest rate decision will have an impact on the rates you pay the next time you borrow money — whether it's with a mortgage, an auto loan, or a credit card purchase.
By itself, the federal funds rate isn't especially important to anyone but bankers. However, when the Fed manipulates the federal funds rate, it can have broad economic effects.
Money is an essential fuel for economic activity
This is often described mechanically, as a question of the interest rates spurring or strangling economic activity. For example, if mortgage rates rise, it becomes harder for people to buy new houses, which can hurt employment in the construction industry. If interest rates for business loans go up, it becomes harder for companies to finance the construction of a new factory. And so forth.
That's all true, but it can also introduce confusion because causation can move in the other direction. When economic activity is robust there's a lot of demand for loans, which can pull interest rates up. And focusing too much on specific lending markets can obscure a more fundamental point about why the Fed's decisions matter: Money is an essential fuel for economic activity. Recessions happen when people spend less than they did before. Booms happen when people spend more. So all else being equal, putting more money into people's pockets is going to produce more demand for companies' products, more economic activity, and more jobs.
From 2008 until 2015, the Fed kept interest rates below 0.25 percent, in an effort to help the economy recover from the Great Recession. But in December 2015, the Fed announced that it would raise its target for the federal funds rate to between 0.25 and 0.5 percent. That was the first interest rate hike since 2006.
At the time, many people expected this would be the first of several interest rate hikes that would occur over the course of 2016. But with the economy continuing its slow but not spectacular growth over the last few months, the Fed chose not to raise rates further at its January or March meetings. And most Fed observers aren't expecting an interest rate hike at this week's meeting either.
If low interest rates are so good for the economy, you might be wondering why they should ever be increased. The reason is that pumping more money into the economy only works up to a certain point.
During a recession, there are a lot of idle resources. People are unemployed, factories are producing below their maximum capacity, trucks and ships sit empty a lot of the time, and so forth. In that situation — the kind of situation we had in 2001 and 2009 — getting people to spend more will mobilize idle resources and boost the real output of the economy.
The traumatic inflation of the 1970s looms large in the minds of senior Fed policymakers
But during an economic boom, things look different. With few idle resources sitting around, there's no way for more consumer spending to translate to more output. If the Fed cuts rates during a boom, the result is likely to just be that prices go up — inflation — without generating much economic growth.
That's what happened in the late 1970s. The Fed kept interest rates too low for too long because it feared that higher interest rates would be economically harmful. That produced double-digit inflation that created chaos for many Americans.
The traumatic inflation of the 1970s looms large in the minds of senior Fed policymakers, most of whom are old enough to remember it firsthand. They're determined not to repeat the mistakes of their predecessors and let inflation get out of control.
The theoretical case for raising rates to ward off inflation is strong. But the case for raising rates right now runs into a huge problem: Inflation is really low right now. It's been low since 2008, and market forecasts suggest that it will continue to be low over the next decade.
Like many countries around the world, the Fed has set an inflation goal of 2 percent. Yet over the last year, prices — as measured by the Fed's preferred inflation measure, known as the personal consumption expenditures index — have increased by just 1 percent. That's partly because oil prices have been falling; if you exclude volatile food and energy prices, the inflation rate is 1.7 percent. Moreover, markets are projecting that the average inflation rate will be below 2 percent over the next decade.
If inflation shows signs of picking up, the Fed can always raise interest rates later
And while the economy has been doing pretty well, there's reason to think it could be doing better. True, the unemployment rate is down to 5 percent, not too far from what economists regard as the full-employment level. But the labor force participation rate — the fraction of all adults participating in the labor force — is close to a 30-year low. After falling for several years, it has only ticked up slightly in the last few months, suggesting that there's still room for an economic boom to draw more people into the labor market.
The economy has been growing at a respectable but not spectacular rate, and wages have barely been growing faster than inflation.
We don't know if keeping interest rates low will boost economic growth. But given that the inflation rate is actually a bit below the Fed's target, it seems there's not much risk in giving it a try. If inflation shows signs of picking up, the Fed can always raise interest rates later.
People have made a number of arguments in favor of raising interest rates, but on some level they all boil down to the view that seven years of ultra-low rates is unnatural.
Prior to 2008, it had been many decades since the federal funds rate was zero, and a lot of people find the current interest rate environment deeply unnerving. As Vox's Matt Yglesias has written, there's a widespread view that zero percent interest rates are a kind of life-support measure for the economy. Now that the patient is recovering, people think, we should remove the breathing tube so he can get back to breathing normally.
What happens if we keep the patient on zero-percent-interest life support too long? As we've seen, people normally worry that low interest rates will generate high inflation. And in the first few years after the Fed slashed rates in 2008, a lot of people warned that inflation was just around the corner. But after seven years of low interest rates and low inflation, those fears have started looking a bit silly.
So today, advocates of higher rates mostly focus on bubbles. A good example is Sen. Rand Paul (R-KY), son of longtime Federal Reserve critic, gold standard advocate, and former Rep. Ron Paul (R-TX). The younger Paul co-authored an op-ed for the Wall Street Journal in September 2015 blaming low interest rate policies over the past 20 years for the stock market bubble of the late 1990s and the real estate bubble that popped in 2007.
In Paul's view, prolonged periods of low interest rates encourage people to make risky, unsustainable investments. Recessions, in his view, are a painful but necessary process that purges the economy of bad investments. When the Fed keeps rates "artificially" low, it merely prolongs the day of reckoning and allows these bubbles to get bigger than they otherwise would have gotten. Hence, because the Fed tried to cushion the 2000 stock market crash with low interest rates, we got an even bigger crash in 2008. Paul predicted we'll have a third crash — perhaps even bigger than the previous two — as a result of recent Fed policies.
But this argument doesn't explain how to tell whether rates are "too low." The federal funds rate was around 5 percent in the late 1990s — that was low relative to the previous couple of decades, but it was actually higher than rates for most of the 1950s and 1960s. There's widespread agreement among monetary hawks that monetary policy should be more "normal" — i.e., not zero — but little clarity about how high rates need to be to avoid bubbles or other financial calamities.
Sure thing. Listen to the classic Dire Straits song "Money for Nothing."

The song is written from the perspective of ordinary workers who envy rock stars on MTV who get "money for nothing and the chicks for free." Meanwhile, regular guys have to "install microwave ovens," do "custom kitchen deliveries," and move refrigerators and color TVs.
Obviously, monetary policy is never going to remedy this kind of inequality. Someone has to install microwave ovens and do custom kitchen deliveries, so we're never going to live in a world where everyone gets to enjoy the perks of being a rock star full time.
But there's still a lot monetary policy can do to help those guys wrangling refrigerators and color TVs. For most of the past eight years, it was hard for regular guys (and girls) to earn a living even if they were willing to do unglamorous work like installing microwave ovens. Pumping money into the economy couldn't turn those guys into rock stars, but it did generate economic activity and make it easier for them to find jobs.
And while the labor market is a lot better than it was a few years ago, there's still room for improvement. Wages for low-end workers have been stagnant for more than a decade. If we had a few years of tight labor markets — like we had in the late 1990s — ordinary workers would have more bargaining power. Many would get raises. That's why the guys who do custom kitchen deliveries might want to root for the Fed to keep interest rates low.
It's certainly true that seven years of near-zero percent interest rates was historically unusual. But whether recent Fed policies have been too tight, too easy, or just about right is open to debate.
There's a lot monetary policy can do to help those guys wrangling refrigerators and color TVs
It's helpful to think about a time when the Fed was in a very different situation. The late 1970s was a period of high interest rates. By the start of 1979, the federal funds rate had risen above 10 percent.
Yet inflation soared, reaching a high of 14.8 percent in March 1980, and it stayed above 10 percent until well into 1981. That's a sign that even the historically high rates of early 1979 weren't enough to keep inflation under control. With interest rates above 10 percent, monetary policy might have seemed tight, but it was actually too loose. As it turned out, the Fed had to let rates go as high as 19 percent in 1981 in order to get inflation under control.
Interest rates were high because the market was factoring high expected inflation into interest rates. If you lend money at 10 percent but the inflation rate is 12 percent, you're actually losing money! So the "natural" interest rate — the rate that struck the best balance between inflation and recession — was abnormally high.
Today we're in the opposite situation. Inflation expectations are low. The US population and economy are growing slowly, which limits demand for credit. And that means the natural rate of interest may be a lot lower than it was three or four decades ago.
The US isn't alone here. Interest rates are low across the developed world. Japan and the eurozone have actually adopted negative interest rates in recent months. The United Kingdom, Canada, and Australia all have interest rates at their lowest levels in decades.
And the experience of the eurozone suggests this isn't really the fault of central banks. As economist Scott Sumner has pointed out, the European Central Bank tried raising rates in 2011, believing the worst of the recession was over. The result was a double-dip recession that quickly forced the ECB to bring rates back down.
The US economy is now stronger than the eurozone was in 2011, so this week's rate hike probably won't trigger a recession. But the low rates of the past few years aren't really the doing of central banks. Central banks are just reacting to market signals — cutting rates when unemployment rises, raising them when inflation becomes a problem — and the result has been historically low interest rates.
The Fed and other central banks have been setting interest rate targets for so long that a lot of people think of monetary policy and interest rate changes as synonymous. But there's actually no law requiring the Fed to do monetary policy this way. Fundamentally, the Fed conducts monetary policy by creating money and buying stuff with it. There's no reason the amount of money they create needs to be determined by an interest rate target.
One example of this was between 2008 and 2014, when the Fed engaged in a technique called quantitative easing. The federal funds rate had already reached zero, so the Fed couldn't drive it any lower. But the Fed still wanted to do more to support an economy that was in a major recession. So the Fed just announced that it was going to create a certain amount of money every month. It worked fine, and many economists believe it helped speed the economic recovery over the last seven years.
Still, quantitative easing has two big disadvantages. One is that it's pretty ad hoc. It's hard for the Fed to know how much money to create or how long the process should go on.
The even larger problem, though, is political. Because the Fed's "normal" monetary policy approach is to target interest rates, quantitative easing generally gets labeled "unconventional" or "extraordinary" — even though the actual mechanism of creating money and buying government securities is very similar in both cases. This tends to create a political backlash and make the Fed reluctant to use QE as forcefully as might be appropriate.
The Fed twice halted its bond-buying programs — once in 2010 and again in 2012 — before bad economic news forced them to restart them. This tentative approach may have hampered the economic recovery.
A different approach would be to stop targeting interest rates and instead directly target a variable the public cares about, such as the growth of total spending in the economy. In an approach known as nominal GDP targeting, the Fed would commit to creating enough money so that total spending in the economy grows at 5 percent per year.
The Fed's interest rate decisions might seem pretty remote, but they can actually have a big impact on every American. When the Fed keeps interest rates low, it means there will be more money flowing through the economy, which is likely to mean more economic activity and more jobs.
This week's meeting, in which the Fed is widely expected to leave the rate unchanged, is likely to be a bit of a snoozer. But the Fed's broader policy approach — whether to steadily raise rates, keep them near 0.25 percent, or even push them back down toward 0 — will have a big effect on the economy.
If you'd like to see the economy grow more quickly, unemployment fall, and wages rise, then you should be rooting for the Fed to keep rates low — and maybe even reverse December's rate hike. In contrast, if you're most worried about inflation or another big economic bubble, you might want to cheer the Fed's decision to raise rates in December and hope the Fed raises rates further in the coming months.
Late yesterday, Uber announcement settlement of two lawsuits that posed a significant threat to its on-demand business model. Drivers will get more clarity about when they can be terminated, as well as a new appeals process if drivers feel they've been terminated unfairly. They'll also get some cash. In return, Uber has neutralized two big threats to its existing model for managing drivers.
This probably isn't the end of the story, though. The settlements only affect drivers in two states, and they don't actually settle the legal question at the heart of the lawsuit. So litigation in one of the other 48 states could eventually force Uber to change how it handles its relationship with drivers.
Drivers in California and Massachusetts had sued Uber arguing that they should have been legally classified as employees rather than independent contractors. If they'd won their lawsuit, they could have been entitled to a variety of legal rights, from overtime pay to reimbursement for expenses.
If the drivers had won the lawsuit, it could have forced Uber to dramatically change its business model. Under the current model, drivers are free to work when and where they want, and they get paid based on the number of rides they actually complete. That freedom could have been curtailed in a world where drivers are legally employees and are guaranteed a minimum wage and other legal benefits.
Instead, Uber has reached a settlement that features clear benefits for drivers but lets the company retain its core business model.
Labor law in California (and other states) draws a fundamental distinction between employees and independent contractors. Employees have a direct, long-lasting relationship with their employers, and as a consequence they are eligible for a number of benefits and legal protections.
Independent contractors, on the other hand, are service providers with an arms-length relationship to their customers. For example, if you hire a plumber or electrician to do work on your house, that person might be classified as an independent contractor. It wouldn't make sense for the law to treat everyone who pays for outside help on their house as an employer.
Whether a worker is an employee or an independent contractor is an issue that's decided by regulators and the courts. Employers can't opt out of the legal requirements of labor law merely by getting employees to agree to call themselves independent contractors.
Labor laws were written in an era when nothing quite like an on-demand car service existed. So Uber drivers don't fit comfortably on either side of the divide between employees and independent contractors.
There are a number of ways that Uber drivers seem a lot like conventional employees. Uber drivers must undergo a lengthy application and background checking process before they can begin work. Many drivers treat Uber as a full-time job, working 40 or more hours per week for months at a time.
Uber sets a wide variety of rules governing how drivers should provide services to Uber passengers. Drivers' fees are fixed by Uber, and Uber sometimes provides drivers with bonuses, minimum earning guarantees, and other forms of compensation that don't come directly from customers.
But Uber pointed to important ways that drivers seemed more like independent contractors. Normally, employers set their employees' schedules, requiring them to work a minimum number of hours and often dictating when and where to report for work. By contrast, Uber drivers set their own schedules. They can work as much or as little as they want. They also have total freedom to decide where to work.
Employees generally use equipment supplied by their employers, while independent contractors usually supply their own tools. Uber has cited the fact that drivers supplied their own vehicles as evidence that they are independent contractors. Uber argued that it merely provided a kind of online marketplace — like an eBay for transportation services — connecting independent ride providers with customers who wanted to purchase their services.
Some of Uber's critics — especially those connected to the labor movement — believe Uber is making things unnecessarily complicated. In their view, Uber is a rich company that could afford to provide workers with the benefits of conventional employment if they wanted to.
But it's not clear shifting to an employee-employer model would be good either for Uber or for its drivers. The key problem here is about scheduling.
In a normal employment relationship, the employer exercises control over the employee's schedule. If the employee works long or inconvenient hours, it's often because the employer requested it. Labor law's scheduling rules are built on this assumption. Workers must receive time-and-a-half compensation if they work more than 40 hours in a week. Some states, including California and Massachusetts, also mandate that workers be provided with breaks and meal times.
But these rules don't make much sense on a platform like Uber where work hours are entirely under the control of the driver. Drivers can take breaks whenever they want, and they're never forced to work more than 40 hours per week. If Uber were subject to a time-and-a-half rule, it might simply prohibit drivers from working more than 40 hours per week, which would be bad for drivers.
A similar point applies to the minimum wage. If Uber drivers were classified as employees in California, they'd be entitled to make at least $10 per hour — and $15 per hour by 2022.
More money is obviously nice for workers, but the tricky thing here is that it would force Uber to exert more control over where and when workers put in their hours. Right now, drivers have a natural incentive to work at times and places where demand is high — like near bars on Friday and Saturday nights. If drivers were guaranteed $10 per hour, they'd no longer have to worry about that so much. They'd be more inclined to work at times and in places that are convenient for the drivers, even if those are not times when many customers needed rides.
So a minimum wage would effectively force Uber to start telling drivers when and where they can work. That would mean drivers could lose one of the best things about being an Uber driver: the freedom to set their own hours and decide which parts of town to drive in.
By itself, settling with Uber drivers in California and Massachusetts doesn't accomplish that much for Uber. The company operates in dozens of other states, and drivers there are free to sue. The key to the settlement is the compromises Uber is making to try to address drivers' concerns and make them less interested in seeking the status of employees.
The key demand focuses on transparency and due process for worker terminations. Uber has finally published a formal policy on driver deactivation, spelling out the circumstances in which a driver would be terminated from Uber. These include drug and alcohol use, persistently low ratings, and a high rate of ride cancellations.
And while Uber drivers will not be represented by a union or subject to collective bargaining, Uber has agreed to create a driver representative organization — in effect a trade association rather than a union — and give drivers a process for appealing termination decisions.
It's not obvious that either of these changes strengthens Uber's argument that drivers are not employees in a narrow legal sense. Nevertheless, Uber's willingness to work with its drivers may make a favorable impression on judges who oversee similar lawsuits in other states. If Uber can convince judges (and legislators) that it is addressing key driver grievances under the existing legal framework, they might be less likely to force Uber to treat drivers as employees instead.
Are fully functional self-driving cars right around the corner? After years of optimism, we're starting to see people wonder if they might be further away than people thought. And skeptics point to mapping as a key obstacle.
Writing at the Marginal Revolution blog, for example, economist Tyler Cowen argues that "mapping the territory, reliably, will remain the key problem. Until that is solved, driverless cars will be a form of mass transit — except without the mass — along predesignated routes."
Creating detailed and comprehensive maps is difficult in the sense that it takes a lot of work, but it's not a hard technical problem. Google has already done it for roads around their corporate headquarters in Mountain View and some of its competitors likely already have the same capabilities. Expanding these maps nationally doesn't require a conceptual breakthrough, it just takes money — and Google has a lot of money.
We can expect Google and its rivals to start their mapping projects in major cities where the bulk of Americans live. That means that most of us are likely to get access to door-to-door self-driving car service long before the last mile of rural American roads has been mapped.
Computers have been able to beat human beings at chess since 1997, when the IBM's Deep Blue beat human champ Garry Kasparov. But in his 2013 book Average Is Over, economist Tyler Cowen pointed out that (at least at the time he was writing) mixed teams of humans and computers — known as freestyle chess teams — were even better at chess than computer software alone. Humans provided valuable strategic insights to complement the massive computing power of the machines.
Google's self-driving car technology works on the same principle. A computer inside the car is responsible for making second-by-second driving decisions. But the car is in constant contact with Google headquarters, where a large team of human analysts — backed up by the vast computing power of Google's data centers — maintains an extremely accurate, detailed, and up-to-date map of the streets where Google's cars are driving.
Google described its effort to build this map in its most recent monthly update on the self-driving car program.
"Before we drive in a new city or new part of town, we build a detailed picture of what’s around us using the sensors on our self-driving car," Google writes. "Our mapping team then turns this into useful information for our cars by categorizing interesting features on the road, such as driveways, fire hydrants, and intersections."
Google's self-driving cars are able to navigate city streets pretty well even without this kind of detailed map. But when people's lives are at stake, "pretty well" isn't good enough.
The human-annotated map provides an extra margin of safety, allowing a car to know its location within about 4 inches. And identifying permanent, immovable road features ahead of time, the map allows a car's onboard software to quickly focus in on objects that aren't labeled in the map. These new objects tend to be people, animals, or vehicles that are likely to move, requiring the car to be extra cautious.
There's a lot that software can do to speed up the process of identifying objects like street signs and fire hydrants, but Google still employs human analysts to do much of this work. When a single mistake could lead to an accident, it's better to be safe than sorry.
Right now, Google only has this kind of detailed maps for a small fraction of the country's roads — primarily in the area around Silicon Valley and Austin, Texas. Taking these maps national will be expensive. Only Google knows exactly how expensive, but we can make some educated guesses by looking at how much online mapping companies are spending to maintain their maps today.
A rough 2012 estimate found that maintaining the data for a global mapping service costs $1 billion to $2 billion per year, a figure that's in line with industry rumors.
We should expect the maps used for self-driving cars to be even more expensive because they're going to have to be a lot more detailed. The maps that power Google's self-driving cars are going to have to mark a lot of features — fire hydrants, driveways, street signs, and bushes — that aren't relevant for merely providing turn-by-turn directions.
Ironically, then, the effort to automate driving may actually create a lot of jobs, especially in the early years as self-driving technology is being rolled out. As Google and its competitors expand their self-driving vehicle programs nationwide, they're going to have to hire thousands of human analysts to produce the detailed maps that enable cars to drive safely.
And this won't just be a one-off development, either. Landscapes are changing constantly, with changing speed limits, new construction, and trees growing and being cut down. So while maintaining maps may require less manpower than creating them initially, self-driving car technology is likely to employ a lot of people for the foreseeable future.
If a company had to build a nationwide map before it could bring its self-driving technology to market, that could be a major obstacle. But companies don't have to do that.
The alternative is to introduce the vehicles as an on-demand service rather than a product customers can buy. For example, Google might just map the city of San Francisco and then offer a self-driving car service that competes with taxis, Uber, and Lyft within the city limits. As the service grows in popularity, Google could expand its service territory, first to other parts of the San Francisco Bay Area, then to other major metropolitan areas.
It might take many years before Google manages to offer services in outlying rural areas. But as Uber has demonstrated, there's a ton of demand for on-demand rides restricted to major metropolitan areas. And without the need to pay a human driver, we can expect Google's self-driving cars to be dramatically cheaper than Uber's, which will mean even greater demand for the services.
Google seems to believe that detailed maps are an essential resource for allowing cars to drive themselves safely. Of course, it's possible that some of the other companies working on self-driving car technology — Uber, Tesla, Apple, and several major car companies are all rumored to be working to develop self-driving technology of their own — will find ways to build fully self-driving cars that aren't reliant on maps. But it's also possible that maps will be an essential resource for self-driving systems for the foreseeable future.
If that happens, it will provide a big strategic advantage for companies that have experience managing map data. That includes Google, of course. It also includes Apple, which has a mapping app for the iPhone. It may include BMW, Daimler and Audi, which jointly paid $3 billion for Nokia's mapping division last year. And it may also include Uber, which has been buying up mapping assets.
The expense of managing maps may also be a major reason why GM teamed up with Lyft earlier this year. Right now, GM's business model is to sell cars to people who expect to be able to drive them anywhere they want nationwide. But if self-driving cars need detailed maps of everywhere they go, then this business model would force GM to build a detailed nationwide map before selling its first self-driving car, an extremely daunting prospect.
Instead, the Lyft partnership gives GM the opportunity to build self-driving cars that, like Lyft's service, only operate in major metropolitan areas. Collecting the mapping data required to operate in these limited areas is a much more manageable problem.
Still, the importance of maps to the self-driving market is another reason that car companies may struggle to remain market leaders as the industry shifts to fully autonomous technologies. Google, Apple, and Uber have a lot of experience collecting, analyzing, and distributing vast quantities of fast-changing geographic data. Ford, GM, and Toyota don't.
This also may explain why car companies have been focusing on developing partially self-driving technologies like adaptive cruise control, emergency braking, and self-parking. These relatively simple self-driving capabilities don't rely on maps, and they're compatible with car companies' existing business models. Car companies hope that these will provide customers with enough of the benefits of self-driving technology to provide a competitive alternative to fully self-driving products from Google and others. But in the long run, this approach seems unlikely to work that well, as the benefits of fully self-driving cars will be massive.
Disclosure: My brother is an executive at Google.
"The most important article you write on your blog is the second article someone reads ... If that next article is also really good, then you've established something meaningful with that reader. You have the inkling of a relationship." — Ben Thompson
Since launching Stratechery in 2013 from his home in Taiwan, Ben Thompson has established himself as one of the smartest and most thoughtful analysts at the intersection of media, business, and technology.
Just as impressive: Thompson has also figured out a way to turn Stratechery into a viable business; his one-man operation operation were earning more than $200,000 in annual revenue by January 2015. Thompson is coy about the number now, but it's safe to assume it's considerably higher.
So getting to geek out with Thompson on the state of the media business is a lot of fun. In the latest edition of my podcast, (which you can listen to by subscribing to my podcast or streaming it on SoundCloud), we talked about a number of topics close to my heart, including:
And much, much more.
This is a particularly great episode if you're in new media, or thinking of getting into it, or just want to understand the business dynamics behind the content you consume. There's a lot of advice here that I wish I had known when I started as a journalist.
A big thanks again to Thompson for taking so much time for this conversation. And for more podcast conversations — including episodes with Rachel Maddow, Bill Gates, political scientist Theda Skocpol, and conservative activist Michael Needham — subscribe to The Ezra Klein Show. For write-ups of past episodes, head here.
The news that Harriet Tubman will be replacing Andrew Jackson on the front of the $20 bill is significant for all sorts of reasons. Slave owner Jackson is being pushed to the back of the bill by a former slave; Tubman, who led more than 300 slaves to freedom on the Underground Railroad, is displacing a president who drove 16,000 Cherokees (and thousands more from other native tribes) out of their homelands on the Trail of Tears.
But even if Tubman weren't displacing Jackson, the $20 would be the perfect bill to honor her, because the sum of $20 played a significant role in her life on two separate occasions.
For one thing, $20 was the amount she earned as a monthly pension after the Civil War, for which she helped the Union as a scout and spy. It was still less than the $25 a month paid to full soldiers, but it was the result of a long legal fight to earn a soldier's pension at all. (Vox's Phil Edwards wrote about this last year, when the social media campaign to put Tubman or another woman on the $20 was at its height.)
But even before that — as Yoni Appelbaum of the Atlantic pointed out on Twitter — the sum of $20 played a huge role in Tubman's efforts to rescue her own father from slavery.
In Tubman's first biography, the 1869 book Scenes in the Life of Harriet Tubman, author Sarah Hopkins Bradford told the story of Tubman's efforts to save her parents as an example of just how rare it was for Tubman to ask for anything from others. "But though so timid for herself," Bradford wrote, "she is bold enough when the wants of her race are concerned" — and unafraid to embarrass powerful people, if necessary.
In this case, Bradford writes, Tubman believed she'd gotten "directed" by God to ask for funds to rescue her parents from "a certain gentleman in New York," whom Appelbaum identifies as prominent abolitionist Oliver Johnson:
When she left the house of her friends to go there, she said, "I'm gwine to Mr.--'s office, an' I ain't gwine to lebe there, an' I ain't gwine to eat or drink till I git enough money to take me down after the ole people."
She went into this gentleman's office.
"What do you want, Harriet?" was the first greeting.
"I want some money, sir."
"You do? How much do you want?"
"I want twenty dollars, sir."
"Twenty dollars? Who told you to come here for twenty dollars?"
"De Lord tole me, sir."
"Well, I guess the Lord's mistaken this time."
"I guess he isn't, sir. Anyhow I'm gwine to sit here till I git it."
So she sat down and went to sleep. All the morning and all the afternoon she sat there still, sleeping and rousing up--sometimes finding the office full of gentlemen--sometimes finding herself alone. Many fugitives were passing through Now York at that time, and those who came in supposed that she was one of them, tired out and resting. Sometimes she would be roused up with the words, "Come, Harriet, you had better go. There's no money for you here." "No, sir. I'm not gwine till I git my twenty dollars."
Ultimately, Tubman got her twenty dollars — and then some. Bradford writes that Tubman eventually fell asleep in the office, and woke up to find $60 in her pocket. But they hadn't come from Johnson; they'd come from the other "fugitive" ex-slaves passing through the office, who managed to raise a tremendous amount of money to help Tubman bring one more to their ranks.
Tubman used the money to rescue her father — who was on trial for helping slaves escape — and bring him all the way up to Canada, where he couldn't be recaptured into slavery.
Admittedly, $20 doesn't go as far as it used to. But once Tubman's face is being minted onto new $20 bills, she'll be part of every exchange in the amount of cash even a prominent abolitionist wouldn't give her to save her own father. And to people who know that story, it might even serve as a reminder of how much more valuable $20 is to those who have less.
June 6, 2005, seemed to be a triumphant moment for Intel. The chipmaker was already dominating the market for processors that powered Windows-based PCs. Then Steve Jobs took the stage at Apple's World Wide Developers Conference to announce that he was switching the main Windows alternative, Macintosh computers, to Intel chips as well. The announcement cemented Intel's status as the leading company of the PC era.
There was just one problem: The PC era was about to end. Apple was already working on the iPhone, which would usher in the modern smartphone era. Intel turned down an opportunity to provide the processor for the iPhone, believing that Apple was unlikely to sell enough of them to justify the development costs.
Oops.
On Tuesday, Intel announced that it was laying off 12,000 employees, 11 percent of its workforce, the latest sign of the company's struggle to adapt to the post-PC world. Intel still isn't a significant player in the mobile market — iPhones, iPads, and Android-based phones and tablets mostly use chips based on a competing standard called ARM.
The company is still making solid profits — it just announced a $2 billion profit for the first quarter of 2016. But the company's growth has stalled, and Wall Street is getting worried about its future.
Obviously, Intel made a mistake by missing out on the iPhone business. Intel's error in judgment is a classic example of what business guru Clay Christensen calls "disruptive innovation." The term disruption has become so overused in the technology world that it's sometimes treated as a joke. But Christensen gave it a more precise meaning that fits Intel's situation perfectly: a cheap, simple, and less profitable technology that gradually erodes the market for a more established technology.
Intel is just the latest in long line of companies that have failed to effectively deal with  this kind of disruptive threat.
Intel invented a chip standard called x86 that was chosen for the IBM PC in 1981 and became the standard for Windows-based PCs generally. As the PC market soared in the 1980s and 1990s, Intel grew with it.
The key to success in the PC business was performance. Chips with more computing power could run more complex applications, complete tasks more quickly, and run more applications at the same time. During the 1990s, Intel and its rivals raced to increase their chips' megahertz ratings — a measure of how many steps the chips could perform in a second.
One thing these early chipmakers didn't care about was power consumption. Higher-performance chips often consumed more energy, but this didn't matter because most PCs were desktop models plugged into the wall. Even laptops had large batteries and could be plugged in most of the time.
But this became a problem in the late 2000s, when the market began to shift to smartphones and tablets. These devices had smaller batteries (to keep the weight down), and users wanted to use them all day on a single charge. Existing x86 chips were a poor fit for these new applications.
Instead, these companies turned to a standard called ARM. Created by a once-obscure British company, it was designed from the ground up for low-power mobile uses. In the mid-2000s, ARM chips weren't nearly as powerful as high-end chips from Intel, but they consumed a lot less power, which was important for smartphones from Apple and BlackBerry.
Even better, the ARM architecture is designed for customization. ARM licenses its design to other companies such as Qualcomm and Samsung, which make the actual chips. That provides flexibility that allows smartphone makers to combine a number of different functions on a single chip. And packing a bunch of functions — like data storage and image processing — onto one chip helps to keep power consumption down.
Today, ARM chips totally dominate the mobile device business. iPhones and iPads run on a chip called the A9 (and predecessors such as the A8 and A7) that are based on the ARM platform, designed by Apple, and manufactured by chipmakers like Samsung and TSMC. Most Android-based phones run on ARM-based chips from Samsung, Qualcomm, and other ARM chipmakers.
Intel had not just one but two opportunities to become a major player in the mobile chip market. One was the opportunity to bid on Apple's iPhone business. The other was its ownership of XScale, an ARM-based chipmaker Intel owned until it sold it for $600 million in 2006.
Intel sold XScale because it wanted to double down on the x86 architecture that had made it so successful. Intel was working on a low-power version of x86 chips called Atom, and it believed that selling ARM chips would signal a lack of commitment to the Atom platform.
But Atom chips didn't gain much traction. Intel has made a lot of progress improving the power efficiency of its Atom chips. But ARM-based chipmakers are experts at building low-power chips, having focused on that task for more than a decade. So they had the early advantage. And at this point, ARM has a huge share of the market. That gives them all of the advantages — more engineers, better software — that come with being a dominant platform.
On one level, you can say that Intel just got unlucky and backed the wrong horse. The chipmaker could have tried harder to win Apple's iPhone contract, and it could have bet on its XScale ARM subsidiary instead of trying to create Atom processors. But it chose not to.
But on a deeper level it's not surprising that Intel took the path it did, again because of Christensen's theory of disruptive innovation.
Intel's basic problem was that the mobile chip market didn't seem profitable enough to be worth the trouble. Intel had built a sophisticated business around the PC chip. Its employees were experts at building, selling, distributing, and supporting PC chips. This was a lucrative business — often Intel could charge several hundred dollars for its high-end chips — and the company was organized around the assumption that each chip sale would generate significant revenue and profits.
Mobile chips were different. In some cases, an entire mobile device could cost less than the price of a high-end Intel processor. With many companies selling ARM chips, prices were low and profit margins were slim. It would have been a struggle for Intel to slim down enough to turn a profit in this market.
And in any event, Intel was making plenty of money selling high-end PC chips. There didn't seem to be much reason to fight for a market where the opportunity just didn't seem that big.
What this analysis missed, of course, was that the mobile market would eventually become vastly larger than the PC market. ARM-based chipmakers might make a much smaller profit per chip, but the market was destined to grow to many billions of chips per year. Even a small profit per chip multiplied by billions of chips could add up to a big opportunity.
Meanwhile, Intel had to worry that jumping wholeheartedly into low-power mobile chips would undermine demand for its more lucrative desktop chips. What if companies started buying Intel's cheap mobile chips and putting them in laptops? That could hurt Intel's bottom line more than the added mobile revenue would help it.
Obviously, Intel's leadership now recognizes that they made a mistake. They're now so far behind that it's going to be a struggle to gain a foothold in the new market. And as cheap mobile chips get more and more powerful, we can expect more and more companies to put them into low-end laptop and desktop computers, eroding demand for Intel's more expensive and power-hungry chips.
Ironically, Intel is now suffering the same fate that it inflicted on an earlier generation of computing innovators three decades ago. In the 1980s, there was a thriving community of "minicomputer" makers led by a company called the Digital Equipment Corporation.
These washing machine–size minicomputers were only "mini" compared to the room-size mainframe computers that preceded them, and they cost tens of thousands of dollars.
Early PCs based on Intel chips were referred to as microcomputers, and companies like DEC dismissed them as toys. They did this for exactly the same reasons Intel dismissed the mobile market — selling a $2,000 PC was a lot less profitable than selling a $50,000 minicomputer, and DEC didn't expect PCs to be a big enough market to be worth the effort.
Of course, that turned out to be totally wrong. The PC market turned out to be vastly larger than the minicomputer market, just as the mobile market is now much larger than the PC market. But by the time this became clear, it was too late. DEC and most of its peers were forced out of business by the end of the 1990s.
When we think about productivity in an economy, we are normally referring to the output of human workers. But some segments of the economy also feature a nonhuman labor force.
Dairy cows, for example, are a key part of the milk industry. And according to this striking chart from the US Department of Agriculture, their productivity has surged over the past generation:
Cow wages, presumably, have not increased commensurately during this period.
These days, if you want to get full-featured cable or satellite television, you typically need to pay not just for the television service itself but for a rented set-top box from your television provider. This is an easy and lucrative stream of revenue for cable and telecom companies, with consumers paying an average of $230 a year in rental fees for relatively unsophisticated boxes.

The Obama administration wants to change that, and will at 9 am release a formal request that the Federal Communications Commission require pay television providers to open up that market to competition. They're not asking for any particular technical solution, but they want an enforceable guarantee that there will be some way for third parties to make and sell cable boxes.
They anticipate that this will save consumers money. But more importantly, if it happens it will turn a stagnant element of the electronics landscape into an innovative one. Future iterations of the Xbox, Playstation, Roku, Apple TV, or other integrated media streamers could serve as complete substitutes for cable boxes. Or maybe ultra-cheap low-feature boxes will emerge to serve customers who really just want a traditional linear cable experience.
At the same time, President Obama will unveil an executive order that tries to ensure more regulatory actions in this spirit — giving every executive agency a 60-day deadline to do a top-to-bottom review of the areas it supervises and report back on what it can do to break down barriers to competition in the American economy.
Set-top boxes are one micro-scale example of a problem that has increasingly become a macro-scale concern for Obama's economic team: evidence that the American economy has become less competitive and more ridden with monopoly market power.
The big-picture concern is that corporate profits have risen to an unusually high level as a share of total national income, and then stayed high. Profits are, of course, an integral part of a capitalist economy. But in a healthy capitalist economy the idea is that high profits inspire businesses to invest more in order to capture a share of the profits for themselves. That investment creates jobs and innovation, and leads to competition that whittles away the profits.
In recent years, we've seen the profits but not the investment.
Some analysts blame activist investors on Wall Street for the investment drought but a dearth of competition is another plausible suspect. There's evidence that fewer new companies are being founded and many industries are becoming more concentrated — both signs of declining concentration.
When the conversation turns to competition policy, it's natural to think of anti-trust enforcement as practiced by the Department of Justice and the Federal Trade Commission.
The White House is interested in that, but it also thinks that reviews of merger and acquisition activity only get you so far in terms of genuinely driving competition.
FCC activism around set-top boxes is a case in point. Breaking Verizon or Comcast into multiple smaller companies wouldn't do anything to change the fact that most consumers only have access to one or two pay-television providers, all of whom require set-top box leasing. Introducing competition into that market requires direct regulatory intervention — just as the administration earlier acted to mandate that wireless carriers allow consumers to "unlock" their smartphones.
Air travel is another example where the Transportation Department may have to look not just at the scale of airlines as a whole, but the allocation of slots at particular airports.
But there are also cases where too much regulation may be standing in the way of competition. Obama's economic team has previously taken aim at occupational licensing rules that set up de facto cartels in the provision of certain kinds of services. There's also increasing concern that even when several companies operate in the same industry they may have so many common shareholders that they are subtly pressured to avoid competing.
The internet also appears to have spawned several opportunities for companies to obtain market power via network effects — everyone uses Facebook in part because everyone else uses Facebook, making them very hard to dislodge — with implications that policymakers have not yet fully understood.
Set-top boxes are a small thing, and completely reinvigorating competition in the American economy is probably too big a thing to be achieved with an executive order.
But like the administration's springtime crackdown on the banking industry, the competition initiative is a sign of a White House that is fiercely resisting the lame-duck label and trying to put its stamp on national policy. The order says, in effect, that the president wants his appointees to hurry up and see what they can still get done before they have to leave office.
Over at the Upshot, Margot Sanger-Katz and Reed Abelson have an interesting discussion of the difficulties some insurers are having adjusting to Obamacare's insurance exchanges.
On Friday, UnitedHealth announced its intentions to pull out of Georgia and Arkansas, and the week before the Blue Cross and Blue Shield Association released a research paper arguing that new enrollees had been sicker — and thus less profitable — than expected. We're entering the season when insurers submit next year's pricing proposals to regulators, and pretty much everyone expects substantial rate hikes.
And that's where things get interesting — or, depending on your point of view, troubling. An early question with the Obamacare exchanges was whether enrollees would respond to rate hikes by shopping around each year to get a better price. The fear was that having chosen a plan once, they would stick with it, even if premiums rose sharply, and so insurers wouldn't be forced to cut costs. For competition to revolutionize the insurance market, enrollees have to actually force insurers to compete for their business.
Happily, that's exactly what enrollees did. Only a third of Obamacare enrollees in 2016 had been on the same plan in 2015. About 25 percent of exchange users switched their plans in 2016. This is precisely what health wonks hoped would happen. In response, insurers have fought to keep costs down, narrowing networks and hiking deductibles.
The result is that Obamacare is proving much cheaper than the Congressional Budget Office originally expected. But many of the participating insurers aren't much enjoying the experience — some priced their plans too low and are losing money, and others simply don't see how to make enough money to justify the effort of participating in these state markets.
"I’m not sure I know what the business model is for an insurer, if the expectation is that you’re going to keep your customers for only a year," writes Abelson. "It makes achieving long-term goals like keeping people healthier and focusing on preventive measures much harder because there may be no payoff for the insurer."
Sanger-Katz agrees, and draws out the underlying tension a bit more. "The fact that people are actually switching seems like a sign that this market is functioning as it was designed. But … all that churn sure makes it hard for an insurer to make money by investing in its customers' long-term health."
I'm a bit skeptical that an inability to invest in customers' long-term health is really the problem insurers are facing. For all their rhetoric to the contrary, I haven't seen much evidence that insurers — particularly individual-market insurers — are any good at improving the health of enrollees. In most cases, I don't think they even try particularly hard to affect enrollee health beyond paying for medical claims.
But there's no doubt that in an idealized insurance system, insurers would try to invest in the long-term health of their customers. The problem is that it doesn't make much sense for them to make those investments if they're just going to lose their enrollees to a competitor a few years later. This is one of the underdiscussed downsides of the push for competitive insurance markets: The easier you make it for enrollees to switch insurers, the harder you make it for insurers to invest in the future health of their enrollees.
And perhaps that's fine. Maybe the right model for insurers is something like Southwest Airlines: low prices, narrow networks, exceptional customer service, and not much else. I lean toward that view myself, in part because I don't think insurers have the tools or the trust to effectively change behaviors among their enrollees. Probably the most effective ways for insurers to invest in enrollee health would be to lobby state and local governments to pass smoking bans or tax alcohol.
But if you think the people who pay for hospital stays should also be responsible for keeping the number of hospital stays to a bare minimum, competitive insurance markets probably won't get you there. The model that makes sense for that purpose is something more like single-payer, where the insurer knows that if it makes costly investments in enrollee health now, it will be the one to reap the benefits later.
For more discussion of Obamacare — including some big wins the law has recently scored in the Medicaid and employer markets — listen to the April 8 episode of Vox's policy podcast The Weeds, which you can subscribe to on iTunes, stream on SoundCloud, or download wherever fine podcasts are, well, downloaded.
Tesla is a very exciting car company, and lots of people like to use the word "disruptive" when talking about it, so it's natural that headlines proclaiming Tesla to be disrupting something or other are rampant on the internet.
But describing Tesla in this way stretches the concept of "disruption" beyond the point of usefulness and misunderstands the nature of the company's success. The real message of Tesla is that not everything needs to be disruptive to be innovative and successful. Sometimes making something great really is good enough.
Here are a few reactions to the release of Tesla's Model 3:
And, of course, it's true that Tesla's cars are well-reviewed and popular, and if the company can really deliver the Model 3 on the scale that it's promising, that will be a significant challenge over the medium term for other car companies.
But "disruption" theory, introduced by Harvard Business School's Clay Christensen, actually refers to something more specific than the generic idea of new competition. His coinage is a useful one and worth preserving — while also recognizing that it simply doesn't apply to every successful new business.
The core idea of disruptive innovation is that successful companies tend to become obsessed with getting better and better at serving their existing high-margin customers.
Those customers provide the profits, so they get studied closely and provided with more and more services and features to ensure their continued loyalty. Eventually a new competing product comes into the marketplace that is generally cheaper, simpler, and, in an abstract sense, inferior. This is the disruptor. What makes it disruptive is that even though the incumbent company could, technically, copy the disruptive new product, it can't bring itself to actually do so, because that would involve undercutting its existing profit margins.
Instead, the tendency is for the incumbent to reassure itself, accurately, that the new product simply does not meet the needs of the most valuable customers and to continue focusing on them.
The problem for incumbents is that over time the new disruptive product tends to get better and better, eating away at a bigger and bigger share of the incumbent's market share. At the same time, because the disruptive new product was designed from the beginning to be cheaper, simpler, and lower-margin it manages to enlarge the market far beyond its previous size.
In this sense, smartphone cameras have disrupted the traditional camera industry. Even a very good smartphone camera takes photos that are lower quality than what you could get with a dedicated camera. But these days, the marginal price of owning a phone that's also a camera as opposed to just a phone is essentially $0. That has devastated the market for dedicated cameras, even as it's created a world in which people buy more cameras (called "phones") and take more photos than ever before.
Tesla's products do not have any of these hallmarks.
Even the new Model 3 — the "affordable" Tesla — is very expensive. It's affordable in the sense that unlike the Model S or the Model X, a middle-class family could decide to buy one if they wanted to stretch their budget. But it's unquestionably an indulgence, and not an affordable alternative to anything.
More importantly, in terms of sequencing Tesla followed the exact opposite strategy.
It first introduced the Roadster, a high-end electric sports car that was both expensive and impractical for most generic automotive applications. It was a car aimed at an extremely narrow target audience of rich weirdos. But it served the purpose of demonstrating that Tesla could, in fact, make an all-electric car that was safe and fun to drive.
Next Tesla made the Model S, a very expensive luxury sedan aimed at the wider audience of rich people who enjoy fancy cars. This and its successor, the larger and more expensive quasi-SUV Model X, served to establish the idea that Tesla was a luxury brand and a maker of cool, high-quality cars.
Now the company is moving further down market with the more accessible Model 3. It's a car that benefits from the technical innovations that went into the earlier cars, but that also benefits from the brand halo effect. As Stratechery's Ben Thompson writes, "It's a Tesla," which everyone now knows is a good thing to be.
A disruptive approach to the electric vehicle market would have involved a vehicle that looked more like a Smart car: cheap, small, and with a limited range that limited its appeal to conventional car buyers but that was extremely reliable due to the extreme simplicity of an all-electric drivetrain.
Such a car could, along the lines of classical disruption, appeal primarily to buyers who aren't well-served by the existing auto manufacturers. Smart cars might have sold primarily as fleet vehicles for new on-demand, app-based ride-hailing services that rarely need to take passengers on long trips. Disruption would have emerged as the batteries and range improved and, more importantly, as automation eventually made on-demand fleets into a larger and larger share of the overall transportation marketplace.
A Tesla, by contrast, essentially competes head to head with a BMW or an Audi as a product.
It's true that the underlying technology is different, but the basic value proposition is the same — it's intended to be an awesome car by the standards of the people who buy expensive cars today, and to appeal to them for similar reasons.
Thompson's view is that Tesla's success — and the larger-scale success of Apple's high-end gadgets — is that disruption theory doesn't apply to consumer markets. That's an overstatement. Companies like Ikea, Walmart, Aldi, and Warby Parker have all applied disruption-style ideas to consumer markets.
But Thompson is right to say that at least some segments of some consumer markets persistently resist disruption.
That's because for many classes of consumer goods, products never become truly "good enough." Nobody needs a Lexus to get to work and run errands. For that matter, nobody needs a brand new Toyota when a used one would be cheaper. And nobody needs features like power steering, anti-lock breaks, Bluetooth connectivity for smartphones, or dozens of other features that were once high-end options and have now become standard.
It just happens to be the case that most people spend a lot of time in their car, and consequently, to the extent that they can afford to do so they always prefer a nicer car to a less-nice one.
Value still counts in this kind of consumer market, but it's not the all-consuming priority in the way it is for some other markets. And it means that entering on the high end to build your capabilities and your brand makes at least as much sense as starting at the bottom.
Over the next decade, Detroit's big car companies are likely to face existential threats as Silicon Valley companies like Google, Tesla, Apple, and Uber invade the auto market. Ford CEO Mark Fields plans to meet this threat with a preemptive strike — but even his bold idea probably isn't bold enough to meet the scale of the challenge, a problem that underscores how genuinely hard it is for business leaders to deal with the threat of massive technological change.
"Our approach is to first disrupt ourselves," Fields said in a recent interview with The Verge (which, like Vox.com, is owned by Vox Media). His plan is to create a new subsidiary called Ford Smart Mobility LLC. Based in Tesla's hometown of Palo Alto, the new company will house Ford's work on ride-sharing and self-driving cars.
By creating an independent subsidiary to deal with a disruptive threat, Fields is taking a page from The Innovator's Dilemma, the 1997 Clayton Christensen book that introduced the concept of disruptive innovation. Locating the new organization in Silicon Valley will give it some insulation from the bureaucratic culture of its corporate parent and an opportunity to absorb the culture of the technology sector.
Unfortunately, Fields does not seem prepared to give the new subsidiary the degree of independence it will likely need to succeed. When The Verge's Chris Ziegler asked if Ford Smart Mobility could work with other automakers, Fields said no, arguing that "we want it to be dedicated to Ford."
"It’s not moving from an old business to a new business, just a bigger business," Fields said. "They’re interconnected."
Unfortunately for Ford, the reason incumbents struggle to adapt to disruptive innovations isn't that they're bureaucratic or dumb — it's that establish companies rarely have the stomach to introduce new products that undercut the market of their existing ones. The more interconnected a subsidiary is to its corporate parent, the more vulnerable it is to this problem and the less likely it is to be truly disruptive.
Over the next decade, we're likely to see three major automotive innovations that could threaten established auto companies like Ford:
These three trends reinforce one another. Automation will make on-demand vehicles more affordable, dramatically expanding their use and causing more people to opt out of car ownership. If more riding shifts to on demand, there will be a bigger market for electric vehicles designed specifically for on-demand use in urban areas. These may be significantly lighter, smaller, and therefore cheaper than conventional cars. Self-driving cars will be able to automatically drive themselves to a charging station when they run low on power, so they won't need the heavy, expensive batteries that make electric cars uneconomical for most consumers today.
Put all these trends together, and the result is likely to be cars that look dramatically different from the cars Ford and its competitors are selling today.
And the problem, as Christensen explained, is that it's extremely hard for a mature organization like Ford to adapt to this kind of change. The problem isn't just that individual employees would have to learn new skills. It's that successful companies have cultures focused on serving their existing customers. And by definition, Ford's customers mostly want to buy Ford's existing gasoline-powered, customer-owned, non-self-driving cars. As an institution, Ford isn't well positioned to produce the kind of cars that are likely to succeed in a self-driving, ride-sharing future.
So Fields has exactly the right instinct: By creating a subsidiary in Silicon Valley, he starts building a team that is steeped in the culture of the technology sector and unencumbered by a need to serve Ford's existing customer base.
But the project will only succeed if Fields is personally committed to giving the company the autonomy to be truly disruptive. "In our studies of this challenge, we have never seen a company succeed in addressing a change that disrupts its mainstream values absent the personal, attentive oversight of the CEO," Christensen wrote in The Innovator's Dilemma.
In particular, there's a good chance that the next generation of automotive technologies will eventually cannibalize the market for conventional, customer-owned, gasoline-powered cars. If Ford is serious about having its new subsidiary succeed, it needs to be prepared for it to participate in that process — creating products that undermine the profitability of its parent company.
But saying things like, "It’s not moving from an old business to a new business, just a bigger business," suggests that Fields doesn't fully grasp what it could mean for Ford to "disrupt ourselves." When a disruptive technology enters the market, the result is often that most of the established companies go bankrupt.
If Ford's plan succeeds and Ford Smart Mobility really does start to disrupt its parent company, Fields is going to face a lot of pressure from within Ford's Detroit headquarters to rein it in. For the plan to work, Fields needs to not only resist this pressure, he needs to give the subsidiary's leaders confidence that he'll continue doing so no matter how strong it gets.
Instead, Fields is already sending the opposite signal, telling the media that the new subsidiary is going to be "dedicated to Ford" and will be limited to working with Ford's own vehicles. That suggests he's not actually prepared to stand up for Ford Smart Mobility's leadership if it winds up truly disrupting its parent company.
CEOs of large American companies saw their compensation fall in 2015, according to a data analysis by Theo Francis and Joann Lublin of the Wall Street Journal.
Not every S&P 500 company has yet released information on its 2015 pay, but about 300 members of that index of big publicly traded companies have. (The rest will do so over the next couple of months.) Of the companies in their sample, they found that median pay fell from $11.2 million to "only" $10.8 million — a decline of nearly 4 percent — largely because growth in cash bonuses slowed and pension contributions got less generous.
Nobody is going to cry for these CEOs, of course, but it is one measure in which inequality fell last year. Compensation growth for normal workers was not particularly robust by historical standards, but it did go up rather than down.
Alongside the aggregate data, the Journal put together a fun interactive comparing CEO pay to companies' stock performance. It shows that there's not a ton of rhyme or reason to who gets paid what at these lofty heights of the corporate world.
Google Inc. CEO Sundar Pichai had the highest pay of anyone by far, earning $100.5 million by taking over one of America's largest and most dynamic companies and delivering 45 percent shareholder return. But at No. 2 we have Philippe Dauman of Viacom, who earned $54.2 million while watching his company's stock slide 42 percent.
Steve Ells and Montgomery Moran of Chipotle earned $13.8 million and $13.6 million, respectively, while their company was plagued with food safety problems and lost 30 percent of its stock market value.
The bottom of the pay rankings is dominated by founder-owners, like Whole Foods' John Mackey and Google's Larry Page, who both earned just $1 in 2015.
Of course for founders, share price accumulation is its own reward. That 45 percent increase in the value of Google stock made Page a lot richer than he was at the start of the year, even though it technically wasn't salary. Mark Zuckerberg paid himself $610,455, and Warren Buffett earned $470,244 — again, with both men making their real money through share price accumulation.
That's a reminder that as lavishly paid as CEOs are, for the truly rich, getting paid isn't the name of the game. The top 20 richest people in America all founded a company (most of them), inherited a fortune (Jim, Rob, and Alice Walton; Jacqueline, John, and Forrest Mars), or did a little of both (Charles and David Koch). No pay package, no matter how splendid, can compete with the possible rewards of owning things — either things you created yourself or things you inherited from your parents.
On Sunday the world became familiar with the Panama Papers: a massive 2.6-terabyte leak of confidential documents revealing a deep web of international corruption and tax evasion from the world's political elite.
Panamanian law firm Mossack Fonseca — which specializes in helping foreigners set up international shell companies to protect their financial assets –  leaked the papers to the International Consortium of Investigative Journalists to expose the offshore holdings and hidden financial dealings of some of the world's most familiar names.
Vox's Matt Yglesias explains:
The documents provide details on some shocking acts of corruption in Russia, hint at scandalous goings-on in a range of developing nations, and may prompt a political crisis in Iceland.
But they also offer the most granular look ever at a banal reality that's long been hiding in plain sight. Even as the world's wealthiest and most powerful nations have engaged in increasingly complex and intensive efforts at international cooperation to smooth the wheels of global commerce, they have willfully chosen to allow the wealthiest members of Western society to shield their financial assets from taxation (and in many cases divorce or bankruptcy settlement) by taking advantage of shell companies and tax havens.
More than 100 media organizations spent a year poring over 11.5 million leaked files with 40 years' worth of data connecting more than 214,000 offshore companies to people in 200-plus countries. Here are some key resources to help you catch up on the unfolding scandals.

1) The Russian government has already said it was "obvious" President Vladimir Putin was the main target of the Panama Papers leak. Whether or not the objective of the leak was to smear the Russian president, the findings showed a $2 billion trail of secret offshore deals and loans all pointing toward Putin.
The Guardian explains the "fabulous fortunes of the Russian president's inner circle":
Though the president’s name does not appear in any of the records, the data reveals a pattern – his friends have earned millions from deals that seemingly could not have been secured without his patronage.
The documents suggest Putin’s family has benefited from this money – his friends’ fortunes appear his to spend.
[...]
Cash was also handed over directly to the Putin circle, this time in the form of very cheap loans, made with no security and with interest rates as low as 1%. It is not clear whether any loans have been repaid.
2) Icelandic Prime Minister Sigmundur Gunnlaugsson walked out of an interview after a Swedish reporter asked him about investments exposed in the Panama Papers.
.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
Gunnlaugsson and his wife, Anna Sigurlaug Pálsdóttir, bought the offshore company Wintris in 2007 to invest millions in Icelandic banks — a line of questioning the prime minister found "totally inappropriate."
The BBC explains Gunnlaugsson's questionable investments:
The leaked documents show that Mr Gunnlaugsson was granted a general power of attorney over Wintris - which gave him the power to manage the company "without any limitation". Ms Palsdottir had a similar power of attorney.
Court records show that Wintris had significant investments in the bonds of three major Icelandic banks that collapsed during the financial crisis which began in 2008. Wintris is listed as a creditor with millions of dollars in claims in the banks' bankruptcies.
Mr Gunnlaugsson became prime minister in 2013 and has been involved in negotiations about the banks which could affect the value of the bonds held by Wintris.
3) While China’s top leader, Xi Jinping says he is ready to take on the "armies of corruption," the Panama Papers revealed that, like many of the world leaders exposed in this data dump, members of Xi and other top Chinese officials' families are tied to multiple offshore companies.
The papers named Xi's brother-in-law Deng Jiagui and the daughter of former China Premier Li Peng, Li Xiaolin — both names that were previously exposed in a 2014 ICIJ report that the Chinese government denied.
The Washington Post explains why this can create an uncomfortable tension in a country that has tried to wage an aggressive — albeit selective — anti-corruption campaign:
Although there are legal uses for shell companies, the charges are sure to rile Beijing.
China’s ruling Communist Party does not like to discuss the wealth of its leaders, or their families, especially as it wages an aggressive, if selective, anti-corruption campaign.
[...]
In 2014, a report jointly published by the ICIJ and the Center for Public Integrity found 22,000 alleged tax haven clients from Hong Kong and China. That investigation found offshore accounts linked to more than a dozen of China’s richest people, including members of the National People’s Congress and executives from state-owned firms caught up in corruption probes.
[...]
Asked about the story at a Foreign Ministry press conference that year, a Chinese government spokesperson called the investigation "hardly convincing."  The report was subsequently blocked. The Chinese press did not play up the story.
4) It's not only political elites. Top names in the entertainment and athletics industries also made the long list of Mossack Fonseca's clientele. Notably, the list included names closely tied with the already corruption-mired FIFA.
The records showed that four of the 16 FIFA officials indicted in the United States used offshore companies. And then there is famed Argentine player Lionel Messi, who, already under indictment for using offshore companies to skirt taxes, was found to have owned yet another offshore company in Panama: Mega Star Enterprises.
Messi has already said he is ready to sue the Spanish newspaper that outed his record of tax evasion for defamation.
You can read ICIJ's full report on the financial underbelly of international soccer and other athletics here.
5) The Panama Papers made one thing very clear: Tax havens, meaning countries or independent areas where taxes are levied at a low rate, are ubiquitous. So much so that avoiding them is nearly impossible, Nicholas Shaxson explained in his exposé on the world's tax havens for the Guardian.
"See if you can dodge all my bear traps, and declare yourself untainted by tax havens. If you succeed, you win my Hermit of the Year prize," Shaxson writes of the pervasiveness of these loopholes:
Do you celebrate Christmas? If you do (or even if you do not), did you buy any gifts on Amazon last December? If so, then your goods were quite likely to have been routed through a byzantine world hosted – only on paper, you understand – by the Grand Duchy of Luxembourg, where Amazon has located its European headquarters, slashing its tax bills around the world. In 2011, Amazon revealed that the US Internal Revenue Service was chasing it for $1.5bn in back taxes. More recently, Amazon has said it will stop routing its UK sales through Luxembourg.
[...]
Let’s cut this challenge short. Did you at any point consume the services of any of these: AIG, Aviva, Barclays, Black & Decker, British American Tobacco, Burberry, Citigroup, Deutsche Bank, Facebook, FedEx, GlaxoSmithKline, Ikea, HSBC, JP Morgan, Microsoft, Pepsi, Skype, Starbucks, Vodafone or Walt Disney? This is just my quirky personal selection from a list of more than 350 multinationals whose convoluted tax schemes were revealed last November by a whistleblower, working for one accountancy firm, PricewaterhouseCoopers (PwC), in one European tax haven, Luxembourg.
6) Tax havens aren't only in Panama and the Cayman Islands. For some, states like Delaware and Wyoming in the United States are tax havens as well.
Bloomberg published "The World’s Favorite New Tax Haven Is the United States." Why? Because even American law firms dedicated to protecting the financial assets of the world's elite say the US is a perfectly effective tax haven:
You can help your clients move their fortunes to the United States, free of taxes and hidden from their governments.
Some are calling it the new Switzerland.
After years of lambasting other countries for helping rich Americans hide their money offshore, the U.S. is emerging as a leading tax and secrecy haven for rich foreigners. By resisting new global disclosure standards, the U.S. is creating a hot new market, becoming the go-to place to stash foreign wealth. Everyone from London lawyers to Swiss trust companies is getting in on the act, helping the world’s rich move accounts from places like the Bahamas and the British Virgin Islands to Nevada, Wyoming, and South Dakota.
"How ironic—no, how perverse—that the USA, which has been so sanctimonious in its condemnation of Swiss banks, has become the banking secrecy jurisdiction du jour," wrote Peter A. Cotorceanu, a lawyer at Anaford AG, a Zurich law firm, in a recent legal journal. "That ‘giant sucking sound’ you hear? It is the sound of money rushing to the USA."
7) But while everyone has heard of the existence of tax havens, the actual practices that go into wealth management are more secretive.
The Atlantic explains how a select few legally "enable their clients to sidestep many laws policies" in its piece "Inside the Secretive World of Tax-Avoidance Experts":
Wealth management is a profession on the defensive. Although many people have never heard of it, it is well known to both state revenue authorities and international agencies seeking to impose the rule of law on high-net-worth individuals. Those individuals—including the 103,000 people classified as "ultra-high-net-worth" based on having $30 million or more in investable assets—pay wealth-management professionals hefty fees to help them avoid taxes, debts, legal judgments, and other obligations the rest of the world considers part of everyday life. The general public doesn’t hear much about these professionals, since there are only a few of them worldwide (just under 20,000 belong to the main professional society) and they strive to keep a low profile, both for themselves and their clients.
8) Somewhat surprisingly, it is really easy to set up a shell company. In fact, NPR's podcast Planet Money set up its own shell companies just to test this out: Unbelizeable, Inc., in Belize, and Delawho? in Delaware.
Listen to Planet Money's discoveries on the ins and outs of owning a shell company, and why they are easy to set up and a hassle to deal with.
(The Planet Money team even drafted a resolution that would allow them to go to Belize to meet the "director" and "shareholder" of the company.)
At 2.6 terabytes, the massive leak of confidential documents now known as the Panama Papers offers a deep, complicated look at an international web of corporate finance, corruption, and tax avoidance.
But the heart of the story — a bunch of individuals and organizations storing their money in secret offshore locations like Panama — isn't that complicated. Over at Reddit, user DanGliesack gave one of the best explanations I've read yet:
When you get a quarter you put it in the piggy bank. The piggy bank is on a shelf in your closet. Your mom knows this and she checks on it every once in a while, so she knows when you put more money in or spend it.
Now one day, you might decide "I don't want mom to look at my money." So you go over to Johnny's house with an extra piggy bank that you're going to keep in his room. You write your name on it and put it in his closet. Johnny's mom is always very busy, so she never has time to check on his piggy bank. So you can keep yours there and it will stay a secret.
Now all the kids in the neighborhood think this is a good idea, and everyone goes to Johnny's house with extra piggy banks. Now Johnny's closet is full of piggy banks from everyone in the neighborhood.
One day, Johnny's mom comes home and sees all the piggy banks. She gets very mad and calls everyone's parents to let them know.
Now not everyone did this for a bad reason. Eric's older brother always steals from his piggy bank, so he just wanted a better hiding spot. Timmy wanted to save up to buy his mom a birthday present without her knowing. Sammy just did it because he thought it was fun. But many kids did do it for a bad reason. Jacob was stealing people's lunch money and didn't want his parents to figure it out. Michael was stealing money from his mom's purse. Fat Bobby's parents put him on a diet, and didn't want them to figure out when he was buying candy.
Now in real life, many very important people were just caught hiding their piggy banks at Johnny's house in Panama. Today their moms all found out. Pretty soon, we'll know more about which of these important people were doing it for bad reasons and which were doing it for good reasons. But almost everyone is in trouble regardless, because it's against the rules to keep secrets no matter what.
As Vox's Matt Yglesias explained, chances are most of the people involved hid their money in a way that's technically legal in order to avoid taxes. And it's something that's been going on for decades due to bad policy, allowing big businesses to dodge taxes in a shady but legally permissible manner.
Still, this isn't the kind of behavior that Americans want giant corporations engaging in. After all, this is money that should be going to US coffers but just isn't. So even those who did everything by the book are in trouble — and the big controversy may convince lawmakers to finally do something about the corporate tax system.
Richard Branson, Virgin's billionaire founder, is sad that Virgin America airlines is being sold to Alaska Airlines for $2.6 billion: "I would be lying if I didn’t admit sadness that our wonderful airline is merging with another," he wrote on his blog. "There was sadly nothing I could do to stop it."
And Branson isn't the only one.
whaaaaaaaplease dont crapify virgin b/c i love it https://t.co/c1MKTrioNO
Virgin America is a tiny minnow in the US airline market, but it's a beloved one. Customers are besotted by the mood lighting, leather seats, oddly catchy safety instruction videos, and snack selection. It wins international awards.
JetBlue, one of the few US airlines approaching Virgin America in popularity, bid for the airline but lost. Still, it could be worse: Most rankings agree that Alaska Airlines is one of the better carriers. And some evaluations say it actually does a better job, even if its planes don't have quite as much mood lighting.
Virgin Airlines ranked first in the latest Airline Quality Rating study, which evaluates American airlines based on objective factors like on-time arrival and lost bags; Alaska came in fifth, behind Virgin, JetBlue, Southwest, and Delta.
Planes are more likely to be on time with Alaska than with Virgin, according to the study: 87 percent of Alaska Airlines' flights landed on time, compared with 82 percent of Virgin's. And Alaska Airlines has the lowest rate of passengers who file official complaints about problems with their trip. Only about four out of every 1 million passengers complains, less than half of Virgin's rate.
Compared with Virgin, Alaska was about three times as likely to mishandle baggage and nearly five times as likely to bump passengers off flights because they're overbooked.
But Alaska placed first, just ahead of Virgin, on the Wall Street Journal's most recent airline rankings, a spot it's held every year since 2013. As well as involuntary bumping and on-time arrivals, the WSJ's evaluation took into account delays of at least 45 minutes and two-hour delays on the tarmac — both things Alaska was very good at avoiding — along with canceled flights.
And studies of customer satisfaction have found that people are generally pretty happy with Alaska Airlines. Alaska Airlines was the top-scoring traditional carrier in rankings from JD Power and Associates and came in third, behind JetBlue and Southwest, in the American Customer Satisfaction Index's airline survey. Virgin America was too small to be included in either survey.
If there's one consistent trend in customer satisfaction surveys, it's that airlines that started or expanded after industry was deregulated in 1978, such as JetBlue, Southwest, and Virgin, are consistently more popular than the older carriers, such as Alaska, Delta, or American.
The problem is that it's very hard to succeed in the airline business. Since 1978, more than 250 new airlines have been started in the US, and nearly all of them failed. It took Virgin America seven years to turn a profit. And in the meantime the airline industry has consolidated, with big players getting bigger.
Since 2007, when Virgin America started flying, there have been four major airline mergers. Four carriers — American, United, Southwest, and Delta — now control 80 percent of the US market. The merger with Virgin will make Alaska the fifth-largest airline, smaller than the big four but bigger than JetBlue.
Two big stories about Russian corruption have broken in the past week. A leak of papers from a Panamanian law firm appears to show perhaps $2 billion, presumably owned by President Vladimir Putin, stashed away in offshore companies under the name of a close friend and the godfather of his oldest daughter, the cellist Sergei Roldugin. Meanwhile, the brave Organized Crime and Corruption Reporting Project hit on a story about the women in Putin's life being given posh apartments.
Together, these stories tell us something important about how corruption works in Russia. Whereas in many countries corruption is the means by which elites turn their power into money, in Russia it is the other way around — corruption is a way to get and keep the political power that is so much more important than mere wealth.
Even before these stories broke, the Kremlin spin machine was briefing against what it was calling an "information attack" in a global media war. But corruption in Russia is, sadly, hardly news, which goes to show why these stories speak to something much more significant than, say, tax avoidance.
It is too easy simply to see Russia as a kleptocracy or, more misleading yet, a "mafia state." Yes, corruption is endemic to the system, not a byproduct but a central feature of Putin's methodology of power. But this doesn't fully explain why there is such corruption in Russia today.
Assuming those $2 billion are Putin's, how did he get them? Did people hand him suitcases of cash? Highly unlikely. Rather, he takes or is given stakes in assets, rights to shares in profits. This is not so much for the money itself — anything he could want, he can get the state or the oligarchs to buy, from a palace on the Black Sea to a $35 million yacht — but rather for the political power they give him.
The real currency in Russia is not money but power — and the latter can buy the former, but not necessarily the other way around. You can be rich today, but the state can impoverish you tomorrow. Conversely, if you have power, you can always get money, as we are likely seeing with the Panama Papers, or else simply don't even need it.
While the Panama Papers involve far more cash, and are likely to draw far more attention, it's the other story that is the more meaningful, for demonstrating that Russia's real currency isn't money — it's power and connections.
It alleges that Grigory Baevsky, a little-known Russian businessman who formerly ran a state property agency and now works for Arkady Rotenberg — one of Putin's oldest friends and, coincidentally, one of the richest billionaires in Russia — has been involved in transferring apartments in Moscow for a string of women connected with Putin. They include his youngest daughter, Katerina Tikhonova; the sister and, it is thought, grandmother of his current alleged girlfriend, rhythmic gymnast Alina Kabaeva; and Alisa Kharcheva, a woman whose main claim to fame is her near-naked appearance in an infamous "We Love You" pinup calendar dedicated to Putin.
In today's Russia, official corruption is so normal that it scarcely even merits much mention. Ministers and officials routinely turn out to have massive mansions, such as Defense Minister Sergei Shoigu's $18 million pagoda-themed estate.
In part, the Kremlin's prickly response may be precisely because Putin is notoriously secretive about his private life. But given that the preemptive spin from Kremlin spokesperson Dmitry Peskov (who himself apparently lives in a $7 million house on an income of less than $140,000) made it even more of a high-profile story, it is likely more than that.
The answer may be that the case illustrates the way corruption really works in Russia. For sure, the driver pulled over by a traffic cop, the contractor looking to speed up approval of building plans, or the store owner being shaken down by a fire inspector all have to pay cash on the nail. But this kind of corruption is pretty small-scale and, something most Russians never have to face.
The real corruption that is sucking the blood out of today's Russia is the industrial-scale profiteering taking place at the top of the system. According to INDEM, one of the last independent liberal think tanks left in Russia, corruption costs the country between a quarter and a third of its total GDP.
Put it another way: Corruption by the Russian elite could be costing the country up to six times as much as all the sanctions imposed by the West since Russia invaded Crimea.
The way this corruption works is through access and favors rather than actual transfers of money. When Putin wants to reward his friends, he allocates them contracts and monopolies they can milk for all their worth.
But in return, they know that likewise they are rich only so long as they have political power and Putin's goodwill. Part of the price is to understand that at times they will be called on for favors, and they better deliver.
There is, after all, no evidence that Putin actually paid for any of the properties Baevsky doled out. Rather, it is more likely that Putin made his wishes known, maybe through his friend Rotenberg — who incidentally received more state contracts than anyone else last year — and everything was arranged to keep the boss happy. These valuable assets and sums of money are often something that is much more valuable in Russia than mere cash: They are tools used to express, deliver, or exert political power.
Money can be moved, hidden, willed to your kids. Power, though, is something active, ephemeral, needing constantly to be refreshed and reasserted. It is something you either have or you don't. Back in Soviet times, one reason so many leaders died in office was because they knew the day they retired everything they had — the cars, the mansions, the summer dachas — could be taken away from them. The tragedy of modern Russia is that the same is true.
Putin and other senior Russian figures are like sharks: They have to keep swimming or they drown. To an extent this worked in the 2000s and early 2010s, when the economy was growing and there was always more sea in which to swim. Now, though, as the waters drain, the competitions and collisions are getting more common.
But these conflicts are not always or only about cash and contracts. Sometimes they are about other manifestations of power. Chechen strongman Ramzan Kadyrov already has a private zoo with a tiger and a $1.25 million Lamborghini supercar, for example, so for him the Kremlin offers more medals and honors than he could fit on his chest.
Or for Investigations Committee Chief Alexander Bastrykin, one of the Kremlin's main political enforcers, the really valuable thing is not money (he seems to be of relatively moderate means) but rather success in his regular political struggles with his rivals, especially Prosecutor General Yuri Chaika.
Either way, the property story actually illustrates how corruption really works in Russia, and the Panama Papers tell us how power really works in Russia. It's not about following the money, but following the power.
Mark Galeotti is a professor of global affairs at New York University and a visiting fellow with the European Council on Foreign Relations. He blogs at In Moscow's Shadows and is on Twitter as @MarkGaleotti.
On Thursday, Elon Musk unveiled a prototype of Tesla's new Model 3, the much-hyped vehicle that, he hopes, will finally help electric cars go mainstream when it hits the market in December 2017.
The news has induced the sort of feeding frenzy usually associated with shark chum and Apple products. More than 180,000 people have already plunked down a (refundable) $1,000 deposit to reserve their Model 3 a year in advance. In California, Colorado, even Australia, hundreds of fans were lining up to preorder a vehicle they hadn't even laid eyes on yet:

Tesla fans stand in line inside Park Meadows Mall March 31, 2016 to preorder the new Tesla due to be unveiled Thursday night. (Photo By John Leyba/The Denver Post via Getty Images)
Partly that's because the car seems pretty neat. Musk says the all-electric Model 3 will start at just $35,000, considerably cheaper than Tesla's flashy $75,000+ high-end models. The base version is expected to get a range of 215 miles on a single charge, though the company is hoping to bump up that number eventually. We'll see if Tesla can actually follow through on these grand promises: it's banking on the massive battery-making GigaFactory outside Reno, Nevada, to churn out cheap batteries and keep the car's price down.
But there may be another curious policy reason for this week's Tesla stampede. Right now, the federal government offers a tax credit worth up to $7,500 for anyone who buys an electric car. Except it comes with a catch: The credit starts phasing out for any manufacturer that sells a cumulative total of 200,000 electric vehicles and plug-in hybrids in the US.
Tesla is on track to do just that. It has already sold roughly 65,000 of its high-end Model S vehicles over the past three years and is hoping to sell another 90,000 or so cars this year as its Model X hits the showroom. Some analysts think the company could reach 200,000 cumulative sales sometime in 2017. Once that happens, the federal tax credit for Tesla vehicles would fall by 50 percent for the next two quarters, and then by 75 percent for the two quarters after that1. And then it's gone — unless Congress decided to expand the program.
Note: Separately, California also offers a $4,000 electric vehicle tax credit for anyone whose income is less than 300 percent of the poverty line. It phases out for higher incomes and isn't available for anyone making more than $250,000.
Which means only a fraction of buyers may end up actually qualifying for the tax credit after the Model 3 comes out in Christmas 2017. It's unclear how many of the people standing in line yesterday were aware of this, but they certainly have incentive to try to reserve while it's hot.

The "Fight for 15" movement got its biggest win yet on Thursday as the California legislature passed a bill to phase in a statewide $15-per-hour minimum wage over the next six years. Gov. Jerry Brown is expected to sign the legislation.
There's a lively debate among economists about the economic impact of minimum wage hikes. Higher minimum wages provide raises to some workers, but some economists argue that they also prompt substantial job losses. Other economists dispute this, saying there's little or no effect on employment and that businesses compensate for higher costs through reduced turnover, improved productivity at work, lower compensation for better-paid workers, and price increases.
So who is right? When I set out to interview economists about the effects of California's minimum wage hike, I was expecting some strong disagreements. Instead, I found a broad consensus: California's hike is so large — and would result in a minimum wage so high — that no one really knows what will happen. None of the three economists I interviewed was willing to make a prediction about how the new law would affect employment in California.
"It would be foolhardy to believe you could project what's going to happen with any degree of confidence," said Jeff Clemens, an economist at the University of California San Diego whose research has found that higher minimum wages have caused job losses in the past. That sentiment was echoed by Arindrajit Dube, whose research has suggested that minimum wage hikes do not cause significant job losses.
Of course, that in itself is a reason to be concerned, since California lawmakers are taking a risk with the livelihood of millions of low-wage California workers. But advocates of the California proposal argue that it's a risk worth taking.
Companies employ workers if the value they get from the workers' labor exceeds the costs of employing them. The higher the minimum wage is, the harder it will be for employers to afford to pay workers. So if the minimum wage gets too high, job losses are inevitable.
But economic theory doesn't tell us how high a minimum wage has to get before significant job losses occur. And over the past quarter-century, this has become one of the most hotly debated questions in economics. A famous 1993 study examined the effects of a minimum wage hike in New Jersey by comparing employment in nearby counties in New Jersey and neighboring Pennsylvania. Surprisingly, the authors of that study, David Card and Alan B. Krueger, found that employment at New Jersey restaurants affected by the wage hike actually increased faster than employment at nearby restaurants in Pennsylvania, where the minimum wage did not increase.
Of course, that was only one study. Over the next two decades, many other economists have performed similar studies, with varying results. For example, a recent study by Clemens found that the most recent hike in the federal minimum wage — from $5.15 in 2006 to $7.25 in 2009 —  "reduced employment among individuals ages 16 to 30 with less than a high school education by 5.6 percentage points." On the other side, a comprehensive study of state-level minimum wage hikes between 1990 and 2006 by Dube and two co-authors found "no detectable employment losses from the kind of minimum wage increases we have seen in the United States."
Unfortunately, little if any of that past research is directly applicable to California's proposal, which would take the state's minimum wage to unprecedented highs. California's current $10-per-hour minimum wage is already among the highest in the country — only Washington, DC, has a higher minimum wage at $10.50 per hour. California is planning to boost its minimum wage by another 50 percent over six years. Even after adjusting for inflation, the new rate of $15 per hour could be the highest minimum wage ever adopted by a US state.
Raising the minimum wage to $15 an hour by 2022 "will likely mean that 30 to 40 percent of the California workforce will get a raise," Dube said in a phone interview. "This will be a big experiment. It's far outside of our evidence base."
I asked Dube — generally seen as a supporter of a higher minimum wage — if it was a mistake for a state as large as California to try such a big increase. Would it be better to let $15-an-hour experiments in San Francisco and Los Angeles play out?
"If you're risk-averse, this would not be the scale at which to try things," Dube told me. "On the other hand, if you think that wages are really low and they've been low for a really long time and we can afford to take some risks, doing things at this scale will get us more evidence."
"A $15-an-hour national minimum wage would put us in uncharted waters, and risk undesirable and unintended consequences," wrote Alan Krueger, who has served as an economic adviser in the Obama administration, last October. Krueger supports raising the national minimum to $12 per hour, and he acknowledged that some cities and states might be able to absorb a $15-per-hour minimum wage. But he argued that a $15 minimum is "beyond international experience, and could well be counterproductive."
Clemens said one reason it's hard to predict the effects of California's wage hike is that it will affect different types of workers than previous hikes. In his previous work, Clemens studied the federal wage hike from $5.15 to $7.25 between 2006 and 2009. This increase affected a relatively small number of workers at the very bottom of the wage scale.
In contrast, the California wage hike will affect workers making between $10 and $15 per hour. Clemens said that "the types of workers, the amount of experience they have, the length of time they've been in their particular employment relationship" are all different in this higher income bracket. So a $15-per-hour minimum wage might have significantly different economic impacts than a $10 minimum wage.
It's also significant that the new minimum would take effect statewide, not just in wealthy cities like San Francisco and Los Angeles. Dube points out that — for better or worse — the law will have the biggest effect in less affluent areas like Fresno, where average wages are lower. More workers in those areas will get raises, but there's also a greater danger that businesses will be forced to lay off workers.
Experts told me there's no direct analogue to California's wage hike, but one of the closest parallels is Puerto Rico in the early 1980s. The standard of living in Puerto Rico is significantly lower than on the US mainland, and so until the 1970s Congress allowed the island to set its own, lower minimum wage on an industry-by-industry basis. But in 1974, Congress changed that, phasing in the higher US minimum over a decade. By 1983, Puerto Rico had the same $3.35 minimum wage that applied throughout the continental US. And because Puerto Rico is poorer than the mainland, the higher minimum affected a lot of workers.
"Puerto Rico experienced massive job losses as a result of the application of the U.S. minimum to the island," wrote Alida J. Castillo-Freeman and Richard B. Freeman in a widely cited 1992 study of the minimum wage hike. "Imposing the U.S.-level minimum reduced total island employment by 8 to 10 percent compared to the level that would have prevailed had the minimum been the same proportion of average wages as in the United States."
The researchers found that the higher minimum wage forced many low-skilled workers to flee to the United States in search of work — something they could easily do because there are no restrictions on migration between the island and the mainland. Before the higher minimum wage took effect, people leaving Puerto Rico tended to be more educated than those who stayed. Afterward, migrants became predominantly less well-educated, suggesting that the higher minimum may have forced the least skilled workers to leave the island in search of work.
Yet some economists question whether the Puerto Rico experience is really the cautionary tale that conservatives portray. A follow-up study by Alan Krueger examined the same data with different statistical tools and found no sign that the higher minimum wage had reduced employment in Puerto Rico.
Moreover, Puerto Rico was in a very different economic condition in 1980 than California is today. Puerto Rico was one of the poorest parts of the United States and saw its minimum wage increased from a very low level to a level typical of the United States as a whole. In contrast, California is one of the wealthier parts of the US and already has one of the nation's highest minimum wages. So the economic consequences of its new, even higher minimum wage could be very different.
Surprisingly, Richard Freeman, the co-author of the original Puerto Rico study, doesn't see the island's experience as a cautionary tale for California. "A big jump in the minimum wage did cost some jobs" in Puerto Rico, he told me,  "but it was not a giant disaster at all."
Freeman argues that California's higher minimum wage might be worth it even if it costs some people their jobs.
"If the minimum wage goes up 50 percent and you lose 5 percent of work, there are huge benefits flowing to lots of people," he says.
Freeman likes a provision of the California proposal that would allow the governor to halt the increases in the event of an economic downturn. "You want to raise the minimum as much as possible to benefit people and obviously stop when we're causing some serious harm," Freeman says.
The tricky thing, however, is that it may not be easy to tell if California's higher minimum wage is harming employment.
"A lot of people were saying that if some of these increases are implemented, we'll finally 'get an answer' to the question" of how big minimum wage increases affect employment, Clemens told me. But he's skeptical about this. Because the new minimum is going to be phased in over six years — and possibly longer — it could be hard to draw any firm conclusions about the law's effects, even after the data is in.
After all, people are still arguing about the effects of minimum wage hikes that occurred in the 1980s, 1990s, and 2000s. We can expect that California's experience will be studied intensively over the next decade. But there's no guarantee a consensus will be reached on its economic effects.
Charlie Stross wrote a blog post arguing that Apple's interest in strong encryption is linked to its interest in secure payments, which in turn is linked to its long-term plan to leverage the company's enormous stockpile of cash into becoming a bank and disrupting the entire consumer banking industry.
It's a fun idea to think about. And when you start thinking about it, you quickly realize that not only do Apple's consumer relationships suggest a possible banking opportunity but so do Amazon's and Google's and Facebook's. Yet there's a pretty good reason none of these companies have taken this step yet: It's generally illegal for non-bank companies like Apple to go into the banking business.
Theoretically, Apple could try to convince regulators to let it get involved in some bank-like activities. But if it wanted to do that, it would be bending over backward to show it was willing to cooperate with regulators on other issues. Instead, Apple has done just the opposite, staging a high-profile fight with the FBI over iPhone privacy. That's not the behavior of a company that's preparing to get into a new, highly regulated industry.
We talk a fair amount in US politics about an old law called Glass-Steagall, its repeal in 1999, and proposals to reinstate some version of it. What that law said was that a bank (in the sense of the kind of place where you might have a bank account or go to get a mortgage) couldn't be part of the same company as other kinds of financial services companies, like investment banks or insurance companies.
But it's important to understand that the commercial bank/investment bank combination wasn't something that was uniquely banned during the New Deal; it's something that was uniquely legalized during the financial deregulation of the 1980s and '90s.
Which is to say that even though a bank can be part of the same company as an investment bank or an insurance company or a stock brokerage firm, a bank can't sell pizza or cars or also do HVAC repair. To be a company that owns banks you need to be a bank holding company, and then you can't be owning businesses that aren't financial services companies.
The line here can get a little bit fuzzy at times since non-bank companies that sell durable goods sometimes run financing subsidiaries that make loans, which seems pretty bank-like. But regulators do try to police the lines. One example is that General Motors' financing arm, GMAC, used to be a big moneymaker for the company. But it was only after GMAC was spun out as a separate company called Ally Bank in the wake of the 2008 financial crisis that it started taking deposits. GMAC was owned by a car company, so it couldn't do banking. Ally Bank isn't, so it could.
Just because an Apple Bank would normally be illegal (and not just because that's already the name of a bank) doesn't mean it couldn't happen. Walmart fought and failed to get a banking license, but then eight years later succeeded in securing permission to do some banking-like stuff. Apple is a big company, and it could hire lawyers and lobbyists to try to get favorable regulatory rulings and new legislation passed.
But here's where Stross's theory of the linkage between banking aspirations and taking on the FBI really goes south.
If you need big regulatory favors from the US government, the last thing you want to do is go and make a huge public stink about your disinclination to cooperate with the government on matters the FBI regards as urgent national security questions.
Most likely, Apple's willingness to take a strong stand on behalf of its users' privacy against government requests for help indicates the opposite: Apple is not planning on making any kind of big new regulatory asks in the foreseeable future. Apple Pay works by partnering with stakeholders in the existing bank and credit card industries. That's partly to secure widespread acceptance, but it also helps to avoid regulatory issues. The company's willingness to take a hard line against the Feds suggests that Apple has no plans to change this partnership-based strategy.
Walk into almost any grocery store in the continental United States, and you'll be able to buy bananas for 79 cents a pound or less.
To most of us, this seems utterly normal. The banana is so cheap and widely available that, decades ago, it surpassed the apple to become the most widely consumed fruit in the country.
But the fact that bananas have become so commonplace is fairly astounding when you think about it. The banana is a delicate tropical fruit: It must be picked and packed by hand, then shipped and refrigerated for thousands of miles before reaching your door. Until the early 20th century, the banana was an exotic, expensive delicacy, unknown to most Americans. Nowadays, there's growing concern that Panama disease, a parasitic fungus, could wipe out the most popular banana variety altogether.
And yet, says Dan Koeppel, the author of Banana: The Fruit That Changed the World, "bananas remain incredibly cheap. When you adjust for inflation, they're nearly as cheap and in some cases even cheaper than they were decades ago, when we first started importing them widely."
How is this possible? Part of the answer is a fascinating biological trait unique to the banana plant — and part simply has to do with how we mass-produce commodities in today's globalized food system.
Virtually all of the cheap foods we find in the supermarket today — think potatoes, eggs, or ground beef — are the products of finely tuned, highly industrialized agricultural systems geared toward mass production. And, as Koeppel details in his excellent book, bananas were among the first foods to be turned into a commodity.
In the 1880s and '90s, American businessmen Andrew Preston and Minor Cooper Keith began importing Gros Michel bananas (a different variety from the Cavendish bananas widely eaten today) under the auspices of the Boston Fruit Company, which would eventually become the United Fruit Company and then Chiquita. Betting that American consumers could be taught to develop a taste for the exotic fruit, they cleared tracts of land in Jamaica for plantations and began running their own steamships to bring the bananas to US markets along the East coast.
"No one had ever shipped fruits over the ocean before," Koeppel says. "It was unheard of." To get them to port without rotting, the company built a network of ice-cooled warehouses, boxcars, and ships, vertically integrating the whole operation in a way that paralleled the oil and steel monopolies developing during the same era.
Preston had predicted that bananas could become "more popular than apples" — and he was right. Decades of aggressive ad campaigns — including tactics such as distributing manuals to schoolchildren that extolled the nutritional benefits of bananas — gradually enshrined the fruit as a wholesome, fundamental part of the American diet.
As demand in the US grew, banana executives colluded with authoritarian regimes in the so-called "banana republics" of Costa Rica, Honduras, and Guatemala in order to expand production. The companies would offer concessions — or in some cases, bribes — in exchange for cheap or free land and other favorable policies that would enable them to grow more bananas at low cost.
"They were able to say, 'We'll build you a railroad in return for land and some tax breaks,'" says John Soluri, a Carnegie Mellon historian and banana expert. "They also got the controversial right to import labor: black workers from the West Indies." These workers were severely underpaid, a huge factor in driving down the cost of the product, given that banana harvesting is a labor-intensive process.
Today's banana laborers are somewhat less heavily exploited, but the cost of labor in the developing world is still low. That, along with the still intact political influence of the banana multinationals and the infrastructure networks they began building a century ago, are all core reasons why bananas are so inexpensive compared with homegrown crops.
Around the world, there are hundreds of banana varieties grown by small-scale farmers. But in the United States, you're only likely to find one type for sale — the yellow Cavendish banana. That's by design. It's also a big reason why bananas remain so cheap.
"When the Gros Michel variety was wiped out [by the Panama disease fungus] in the 1950s and '60s, the banana companies were looking for another variety that was easy to handle, pack, and ship," says Rony Swennen, a Belgian biologist who studies the diversity of banana varieties.
Enter the Cavendish. "The Cavendish has bunches that grow three meters above the soil, with a shape that makes them easy to pack, and a beautiful color to boot," he says. The fact that it's significantly less flavorful than other varieties wasn't considered a major problem.
All those Cavendish bananas also look and taste identical. And that's largely due to the fact that banana plants reproduce asexually.
When a farmer wants a new banana plant, he or she removes a part of an existing plant (either a side shoot, called a "sucker," or an underground root-like structure called a "corm") and puts it in the ground. In time, it will develop into its own genetically identical plant. Without sexual reproduction — a grain of pollen fertilizing an egg, as occurs with most other fruit species — there's no random variation among plants that growers need to worry about. Every banana you've ever eaten is a clone.
This is how virtually all commercially grown bananas are produced worldwide, and it means that every banana plant behaves in the same perfectly predictable manner. Their fruits grow at the same rate, in the same abundance, and ripen at precisely the same time.
"It's almost wrong to think of the banana as a fruit, as a product of a what we traditionally think of as farm," explains Koeppel. "The Cavendish banana is a factory product in every bit the same way that a potato chip or a BMW is."
Today we have a high-tech system honed to growing this standardized product on a massive scale. Engineers can remotely monitor refrigerated shipping containers at sea at the precise temperature (ideally between 54.5 and 55 degrees Fahrenheit) needed to preserve them as long as possible. Upon arrival in the US, bananas can be kept in airtight warehouses and exposed to just the right amount of ethylene gas to cause artificial ripening before they're stocked in supermarkets, in a uniform pale yellow-green color.
"When you have just one thing to manufacture, it's a lot cheaper to do it," says Koeppel. "That's economies of scale at work."
The standardization of the Cavendish has allowed agribusinesses to grow bananas for low cost and for shoppers to become accustomed to cheap bananas. We even expect it. If prices ever do go up, retailers just take the hit and keep selling them for 79 cents a pound. "Supermarkets view bananas as a loss leader. They use their price to get you in the store," says Soluri.
But there are downsides to our current system of cheap bananas, too. "These companies can keep bananas so cheap only because they don’t count the cost to the environment," says Swennen. This, he notes, includes the damage caused by excess fertilizer dumped on banana plantations that seeps into surrounding groundwater, and the fossil fuel emissions produced to carry the fruit thousands of miles from plantations to our houses.
The cheap price of bananas also doesn't take into account how current growing techniques have allowed for the spread of a new form of Panama disease (known as Tropical Race 4), which could wipe out the Cavendish in coming years — just as a previous strain of the pathogen eradicated the Gros Michel back in the 1950s.
When growers replaced the Gros Michel with the Cavendish, they believed the latter was impervious to Panama disease. But because all their bananas are clones, they're easy targets for a slightly altered version of the disease that has since evolved and can exploit just one vulnerability to attack every single banana. Meanwhile, today's densely cultivated plantations and interconnected shipping networks, it's believed, have allowed the fungus to spread more efficiently. Since 1990, Tropical Race 4 has jumped from Malaysia to Pakistan to Africa, and many fear it could hit Latin America at any time.
All this has led some observers to claim that the Cavendish is on the verge of going extinct — which isn't exactly true. Tropical Race 4 is very unlikely to wipe out the Cavendish entirely. However, it — along with other threats such as the fungal disease black sigatoka — could certainly devastate banana crops and drive up retail prices of the fruit in coming years. The era of the cheap banana, more than a century long, might not last forever.
After six years of strong returns, the market suddenly lost about 10 percent of its value in mid-August 2015. In September, after the market had regained some of August’s losses, Yale economist Robert Shiller, a Nobel laureate, told CNBC that the stock market might be in a bubble. "I think the market might do what it did in 2000," he said.
Six months later, the market is roughly where it was the day Shiller made his comments. With plunging oil prices, China’s serious economic troubles, and the ever-present possibility of a security crisis, one can hardly rule out the possibility of a big further drop.
If you remember the past two stock market meltdowns, in 2000 and 2008, you might be tempted to dump your stock investments so you can avoid big losses when the current bubble — if it is in fact a bubble — ultimately pops.
I asked several experts what they thought about this question. They told me that trying to predict market bubbles is generally a fool’s errand. However, there are some steps ordinary investors can take to protect themselves that work whether there’s a bubble or not.
The lessons are a bit different regarding a housing market bubble. Because these are more immediately dangerous to regular people, you should be more restrained in your decisions about housing, especially if local real estate prices race ahead of local rents, or if your life situation would makes it hard to ride things out if housing prices really dropped.
The first thing to remember is that we don’t know if we’re in a bubble right now. Shiller suggested we’re in a bubble, and he’s pretty smart. But there are plenty of smart people who think current prices are sustainable.
"Bubbles are only ‘predictable’ after the fact," writes Princeton’s Burton Malkiel, author of a famous investment book called A Random Walk Down Wall Street, in an email.
We all know about the 2000 dot-com bubble and the 2008 real estate bubble. We like to think that if we’d been there we would have seen them coming. But bubbles are more deceptive than that. Genuinely smart investors lose serious money when bubbles burst. After all, that’s how they become bubbles in the first place: If they were truly obvious, so many people wouldn’t have gotten fooled.
During a bubble, there’s always a plausible argument that higher prices are justified by more favorable market fundamentals. After the dot-com bubble burst, for example, it seemed obviously stupid to bet the farm on Pets.com. But during the 1990s boom, it sure looked like Amazon, Microsoft, and other innovative companies were changing the nature of American business.
The same point applies today. Maybe the possibility of Indian and Chinese growth has spawned unrealistic expectations about the companies that sell goods and services there. Maybe those hopes will actually be realized. Either way, it will seem more obvious afterward than it does right now.
And it’s important to remember that the stock market has experienced solid periods of strong growth that were not bubbles at all. For example, after the stock market boom of the mid-1980s, a lot of people thought the market was due for a fall. Pessimists predicted that the 22 percent, single-day stock market crash on October 19, 1987, would be the start of a big recession and a bear market. Instead, the market shrugged it off, delivering spectacular stock market returns for another 12 years. People who panic-sold in October 1987 expecting further declines missed out on big gains instead.
Even if some financial experts might be able to recognize stock market bubbles, you and your financial adviser probably aren’t in this group. If you’re saving for retirement, what you care most about is stock market returns over the long run. Neither excessive alarmism nor undue optimism is helpful.
The key to investment success is to save 10 to 20 percent of your gross income over the course of your career — regardless of what the stock market is doing. You’ll ride some serious upswings, and you’ll experience some stomach-churning declines. But in the long run, you’re likely to do fine, or at least as well as you would do following any other available strategy that doesn’t involve a time machine.
Don’t panic-sell when the market plummets. Don’t get overconfident when the market soars, either.
Avoiding the cacophony of financial media can help you stay on course. As my University of Chicago colleague Richard Thaler told me: "Never watch a financial news network.  ESPN is much better for your financial health."
If you live below your means during your working years, you’ll build up a nice cushion against a major stock market downturn. If you get lucky, you might enter your golden years with greater wealth than you expected. As worst-case scenarios go, that one isn't so bad.
As you age, you can also reduce your risk by somewhat reducing your exposure to stocks — which offer higher returns but are more volatile. A "target date" fund set to your date of likely retirement can do this automatically for you. There are more details on how to do this in my new book (with Helaine Olen), The Index Card.
Today’s high stock prices don’t necessarily mean that stocks are about to crash. But they do mean you should expect stock market returns to be a bit lower in the future than they have been in the past.
"If someone gives you a rule of thumb that you can expect 7 percent real returns in the stock market over a long-term, this is wrong," writes Dean Baker, an economist at the Center for Economic and Policy Research. That’s the average rate of return over the past century, but these generous returns occurred at a time when stock prices were often less than 15 times corporate earnings.
Today, by contrast, stocks are worth more than 20 times earnings. And that means we should expect the rate of return on stocks to be correspondingly lower. Baker says current stock values imply that the inflation-adjusted rate of return is likely to be below 5 percent over the long run.
That doesn’t mean you should run away from stocks. Other options, like bonds and money market funds, are also offering lower returns than they used to. But it is a reason to save a little more and spend a little less in the expectation that the stock market won’t be going like gangbusters as it did in the late 1980s, the late 1990s, or between 2009 and 2015.
Shutterstock
I don't believe ordinary investors should spend much time wondering if the stock market is overvalued. I’m more cautious when it comes to housing, because a fall in your local housing market can do you greater and more immediate harm.
The money you put down on your house is different from the money you put down on an index fund for your retirement. Your house is the most leveraged, illiquid, and undiversified investment you will ever make. So a 10 to 20 percent swing in your local housing market can have an outsize impact on your wealth.
Housing runups and bubbles are distinctive risks for a second reason, too. Most people don’t need to draw on much of their stock portfolio until they’re at or near retirement. Even then, people draw down their wealth gradually in their 70s, 80s, and hopefully beyond.
In contrast, buying a house is an all-or-nothing proposition. And depending on what happens in your life, you might need to sell unexpectedly. You or your partner might lose a job. You might have a child or get a divorce. You might have to move to a new city to find work. If the local housing market drops just as you need to sell your house, that can be financially devastating.
How vulnerable you are depends a lot on your own life situation. If you’re confident you’ll be able to stay in the same house for a decade or more, you can ride out a bursting housing bubble in the same way you can ride out a bursting stock bubble. You’re less vulnerable if you are a tenured professor than if you work in a more volatile profession. Employment is not the only variable in play, either. If your marriage is troubled, that’s harder to talk about, but it also increases the risk that a separation will force you to sell earlier than you expected.
The best defense against these dangers is to be patient — especially if there has recently been a runup in the local housing market. The more you feel yourself stretching to buy a house, the more it makes sense to rent longer or to buy a more modest home. A vanilla fixed-rate mortgage with a 20 percent down payment is your best bet. These monthly payments, plus your property taxes, plus a few percent annually for repairs and maintenance, shouldn’t exceed 30 percent of your income.
Pay attention to the ratio of home prices to annual rents for similar properties. Dean Baker suggests that when this ratio exceeds 15 to 20, "caution is in order." Readily available data isn't perfect. Typical data compares median home prices to average annual rent. In areas that include a preponderance of hugely expensive homes, this can be misleading. But if this ratio creeps well above an area’s historic average, think twice before buying.
One final risk arises when your house rapidly appreciates. That risk is you. It’s tempting to spend too much by drawing on your home equity. During the Great Recession, millions of Americans learned that home equity can fall as quickly as it rises. I’m leery of home equity loans for a luxurious kitchen upgrade, a vacation, or a costlier car than you would otherwise drive. In this, as in so many things, living below your means is the best way to achieve financial security.
Correction: This article originally misidentified Dean Baker's affiliation.
When someone wins the lottery, it can be bad news for his neighbor's finances. A new study from the Federal Reserve Bank of Philadelphia examines the relationship between lottery winners in a particular Canadian province and bankruptcies in the same province — it found that neighbors of lottery winners are unusually likely to go bankrupt, and the larger the lottery prize, the more likely bankruptcy becomes.
Specifically, every $1,000 in lottery winnings translates to a 2.4 percent higher probability of a nearby neighbor declaring bankruptcy.
The researchers have an explanation for why this happens, too. When people declare bankruptcy in Canada, they have to disclose all their major assets — things like houses, cars, boats, and motorcycles — to the courts. The researchers found that the larger the lottery prize, the more money bankrupt neighbors spent on big-ticket vanity purchases — and the more likely they were to run out of money.
The clever study is one of the first to provide statistically rigorous evidence for a claim that seems plausible but is hard to prove: that rising inequality causes people to spend beyond their means in an effort to "keep up with the Joneses." This is the idea that when someone's wealth suddenly increases, her neighbors — and probably her friends and relatives — feel pressure to spend more to avoid being upstaged. Ultimately, this kind of competition can leave everyone worse off.
And while big lottery winnings are rare, the study could have much broader implications. Critics of income inequality have long argued that large income disparities make people unhappy. The Philly Fed study provides further evidence for this point of view. While it focuses on lottery winners, the same basic problem is likely to arise anytime some people enjoy rapid income growth at the same time that others' incomes are not rising.
The federal government is blocking the sale of hoverboards in the US until the self-balancing scooters can be proven to meet newly created safety standards.
Anyone who "imports, manufactures, delivers, or sells" hoverboards that don't meet the new standards could be sued or charged with a crime, according to a letter the US Consumer Product Safety Commission sent to the hoverboard industry Thursday.
The letter will probably lead to recalls of hoverboards that have already been sold as well. The safety standards, from UL, a company that certifies the safety of consumer products, have only existed for about two weeks, so there are no hoverboards currently on the market that meet them.

The commission's letter is the culmination of the rise and fall of one of 2015's hottest toys — one that literally began catching on fire. Major airlines banned hoverboards from their aircraft. Amazon in the UK told customers who bought hoverboards before Christmas that, actually, they should probably throw them away.
Hoverboards have a very weird, very 2015 backstory. They're the plastic-and-battery equivalent of a viral Instagram joke. The story of the hoverboard is the story of how a product itself can go viral, and the corners that can get cut along the way.
If you've somehow managed to avoid the hoverboard phenomenon so far, the most important thing to know is this: hoverboards do not actually hover.
The idea of a personal transportation device that allows you to float a few inches off the ground is still a mostly futuristic idea. Instead, what everyone is calling "hoverboards" are technically self-balancing electric scooters — basically, it's a much cooler name for a hands-free Segway.
Hoverboards run on battery power. You direct them by leaning forward or back, or by putting your weight on one foot to turn. They're usually stabilized by gyroscopes that keep you upright.
The scooters aren't particularly practical: their top speed is around 6 miles per hour, not too much faster than a brisk walk.
It's surprisingly hard to say where the nickname came from. One of the earliest self-balancing scooters, which started as a Kickstarter project in 2013, was called the Hovertrax; the name might have come from there.
But it's also possible that 2015 was simply fated to be the Year of the Hoverboard. Hoverboards were making news this year before self-balancing scooters were, inspired by all of us reaching the year Marty McFly traveled to in Back to the Future Part II and finding it depressingly devoid of actual hoverboards.
The first recorded use of "hoverboard" to refer to the hands-free scooters seems to come from the Luxury Technology Show, where visitors reference Back to the Future but don't directly call them hoverboards (although the video title does):
Calling it a hoverboard seems to have originated on YouTube. Casey Neistat, a filmmaker who posts vlogs on YouTube and has more than 2 million subscribers, was talked into buying a self-balancing scooter on Amazon in early June and quickly started referring to it as a hoverboard.
In July, TmarTn, a YouTube personality, bought one and described it in a video viewed more than 6 million times as a "Hoverboard, Segway-type thing":
Hoverboard manufacturers were incredibly successful at getting their product into the hands of celebrities, and the boards rolled their way into the national consciousness via Instagram, YouTube, and Vine.
Kendall Jenner glided around on one gracefully (until she fell off) on Instagram back in March. Justin Bieber wheeled around on a hoverboard a few weeks later. Jamie Foxx rode a hoverboard onto the Tonight Show with Jimmy Fallon in May. Rapper Wiz Khalifa was tackled and handcuffed at Los Angeles International Airport in August because he wouldn't stop riding a hoverboard. Even Mike Tyson got in the mix.
But then, a few weeks before Christmas, they started going viral for another reason: they were catching on fire. The hoverboards' batteries were exploding, leading to fires while hoverboards were plugged in and charging, being ridden, or simply sitting on the floor at a shopping mall.
The fires caused a quick hoverboard backlash. In the week leading up to Christmas, Amazon and Overstock stopped selling most hoverboards; the US Postal Service refused to ship them by air mail; and at least six airlines, including all the major carriers, said they weren't allowed on board.
The Consumer Product Safety Commission eventually investigated 52 fires in 24 states. In one case, a 13-year-old boy was riding his hoverboard inside when it started to smoke; after he took it outside, it burst into flames and the boy had to use a fire extinguisher to put it out.
The fires are the result of the lithium ion batteries that power the hoverboards. When a lithium ion battery is punctured, it explodes, a battery expert told Wired. Batteries can also explode if they short-circuit or overheat.
Lithium ion batteries aren't inherently dangerous. They're in everything — powering smartphones and laptops, cars and airplanes. But the way hoverboards rose from nowhere to everywhere, with few dominant or well-known manufacturers making a type of gadget that didn't exist a few years ago, has created particular safety headaches.
The CSPC wasn't able to get any boards to catch on fire during the testing process. But they said they suspected the fires could have been prevented if board manufacturers had to meet safety standards.
With hoverboards, it's the general idea, not a specific manufacturer, that's become popular.
The original two-wheeled, hands-free, self-balancing scooter was (probably — it's disputed) the Hovertrax, which got its start as a Kickstarter in 2013. Inventor Shane Chen, whose company Inventist has come up with other wacky, futuristic ideas for moving people around — easy-to-ride unicycles, something billed as "a cross between a skateboard and in-line skates" — promised the device would be the "future of powerful and portable transportation."
Chen more than met his $40,000 Kickstarter goal, and the first Hovertrax were shipped to the US in December 2014. But before they arrived, other hoverboards were being promoted in the US, including the Chic Smart S1. Chen, who patented his design, is now in a patent fight with IO Hawk, the leading American distributor of hoverboards, who buys from manufacturers like Chic.
The shifting manufacturing market for hoverboards has a direct bearing on their safety problems. That's partly because, as Wired reported this summer, underneath different labels and packaging, hoverboards are pretty similar.
Hoverboards almost universally come from Chinese manufacturers who can quickly replicate each other's designs. And not just one or two factories, but thousands of them, all of which got into the hoverboard business more or less overnight. Buzzfeed's Joseph Bernstein wrote in a fantastic exploration of the hoverboard supply chain:
The hoverboard industry that has unfurled in the concrete of Bao An and other similar districts is on-demand IRL content production, a super-flexible churn that hands us the playthings of social-media-driven seasonal diversion. It is the funhouse mirror reflection of the viral internet, the metal-and-cement consequence of our equally flexible commercial hype machine… Call it memeufacturing. It starts when a (typically) Western company, eager to cash in on a product made popular by the social internet, contracts a Chinese factory to make it. From here, the idea spreads throughout the elaborate social networks of Chinese electronics manufacturing until the item in question is being produced by hundreds and hundreds of competitors, who subcontract and sell components to each other, even as they all make the same thing.
Social media virality makes everything move faster — a local news story goes national or international within a few hours; a hoverboard goes from a Justin Bieber Instagram to a neighborhood dad in a matter of weeks or months. And the same process happens with products that happens with gossip or news: sometimes, corners are cut.
If you want to understand how weird the hoverboard industry is, look at the pricing, which is all over the place: an IO Hawk goes for nearly $1,800; a PhunkeeDuck is $1,500; a Swagway is $500, and you can get a no-name hoverboard on Chinese retailer Alibaba for $300.
It would be one thing if the IO Hawk or PhunkeeDuck came with additional bells and whistles. But the truth is that all hoverboards are fundamentally similar. This isn't necessarily the difference between a brand name and a knockoff; none of these brands existed before the hoverboard craze started.
The viral internet hasn't just outpaced the ability for individual brands to get a foothold in the market — it moved too fast for regulators, too. UL didn't develop safety standards for hoverboards until recently, meaning there was no independently certified way to know the products were safe.
The safety warnings before Christmas didn't stop a lot of kids from unwrapping hoverboards. But the hoverboard crackdown from airlines and Amazon led to a manufacturing dropoff in China, Quartz reported in December.
Now hoverboard manufacturers are going to have to be able to prove their products are safe, fast, or risk losing access to the American market. Hoverboards that don't meet standards will be seized when they get to the US, the CPSC said in its letter.
A Wall Street Journal story sent alarmed ripples through the internet on Wednesday, with tweets flying about how bosses could be sent "alerts" that their employees have stopped using birth control and might be planning an expensive pregnancy.
Turns out, not so much. A more careful read of Rachel Emma Silverman's piece doesn't actually support these claims. And one of the third-party data companies Silverman wrote about told Vox that employers definitely can't get information about individual employees through their service.
If anybody is getting "alerts," it's the employees, and if the bosses are being sent data about employee health, it's not about identifiable individuals.
That said, the piece still raises some serious privacy concerns about the way employers are using "big data" to try to curb health care costs.
Silverman reported that some companies, including Walmart, are hiring third-party firms like Castlight Healthcare Inc. to help them reduce their health care costs.
The outside firms do this by collecting data about employees, using it to calculate people's risks of certain health conditions, and sending messages that "nudge" individual employees into making healthier choices that could lower their (and their employer's) health care costs in the long run.
Here's the passage from Silverman's Wall Street Journal article that set off the alarm bells about birth control "alerts":
To determine which employees might soon get pregnant, Castlight recently launched a new product that scans insurance claims to find women who have stopped filling birth-control prescriptions, as well as women who have made fertility-related searches on Castlight’s health app.
That data is matched with the woman’s age, and if applicable, the ages of her children to compute the likelihood of an impending pregnancy, says Jonathan Rende, Castlight’s chief research and development officer. She would then start receiving emails or in-app messages with tips for choosing an obstetrician or other prenatal care. If the algorithm guessed wrong, she could opt out of receiving similar messages.
Out of context, this definitely sounds like some kind of dystopian fertility monitoring system with troubling implications for a woman's job security. Pregnancy discrimination still happens all the time, after all, despite laws against it.
But in context, Silverman notes that employers only see aggregated data, that federal health privacy laws generally prohibit employers from viewing their workers' health data anyway, and that workers can opt out of the health messaging service. And representatives from Castlight told Vox there's no way that data could be traced back to individual employees.
"Employers that use our system never, under any circumstance, see individual employee data from Castlight Action," said Jim Rivas, senior director of corporate communications for Castlight. The data is anonymized and aggregated, he said, and the employer only sees the number of people who are at risk for certain conditions.
Castlight also limits the size of the group that can be displayed — since in a small enough group, it could be easy to guess which employee is at risk for which condition (such as pregnancy). Castlight senior product manager Alka Tandon said bosses won't receive any data for groups smaller than 40 people. That's almost four times as high as the privacy threshold that the Center for Medicare and Medicaid Services recommends, which is 11 people.
So unless a company had more than 40 soon-to-be-pregnant employees and was prepared to cut paid family leave or institute mass layoffs in response (which is still not an inconceivable scenario), the privacy of pregnant women workers who use Castlight is probably pretty safe.
Tandon added that the company uses a "robust" development process that includes testing whether users find the health messages creepy or invasive, or helpful and empowering. Employees also have to actively create an account to use the service in the first place.
Frankly, there's something appealing about these "big data" health services. They can help people who don't have a primary care provider find a good in-network doctor, or they can refer employees with back problems to physical therapy before they turn to expensive, possibly unnecessary spinal surgery. Prenatal care is also essential for good maternal and infant health, so alerting pregnant women to their care options actually seems like a great idea.
These services could legitimately help people stay healthier, which would also end up saving companies money. Everybody wins, right?
But there's also something disturbing about how much these third-party firms can know about you, based on not just your health records but also things like your spending habits.
"I bet I could better predict your risk of a heart attack by where you shop and where you eat than by your genome," one consultant told Silverman.
Castlight doesn't use that kind of outside data, Tandon said. But other companies, as Silverman reported, buy information from data brokers that helps connect people's consumer spending habits with their health care usage.
Indiana University law professor Nicolas Terry told Fortune that this space is completely unregulated, and that insurance claims and search queries aren't necessarily protected in the same way as other private health information under federal law.
The whole thing brings to mind how Target creeped out its customers a few years ago by using data mining to send ads for baby products to women who didn't even know they were pregnant yet, or who hadn't yet told their families and had to have an awkward conversation after the mail arrived. But of course the stakes are higher when it's your employer.
Privacy experts also told Silverman that these data-mining efforts carry other huge risks. Sensitive health data could be vulnerable to hacks or breaches, for instance, which could lead to privacy concerns even worse than your boss knowing you're trying to get pregnant.
Read the Wall Street Journal article for more on the subject.
Neel Kashkari was an assistant secretary in George W. Bush's Treasury Department who wound up running TARP (a.k.a. the bank bailout) and then launching a comically inept Republican campaign for governor of California. More recently, he became president of the Federal Reserve Bank of Minneapolis; he just gave his first major speech in that capacity, and it's a real shot across the bow.
He says the current approach to regulating the biggest banks in America is conceptually flawed, and that while policymakers should finish dotting the i's and crossing the t's on Dodd-Frank, they also need to start considering "transformational measures" that would create "fundamental change."
This is a particularly surprising view from a guy who ran for office as a Republican just two years ago and who's described himself repeatedly as a "free market" and "pro-growth" Republican. National Republicans have, of course, been critical of the Obama administration's approach to bank regulation but generally by arguing that the White House has put too much red tape in the way of industry. Kashkari, by contrast, says that what President Obama has done has been helpful but doesn't go nearly far enough. It's the kind of speech you could imagine Bernie Sanders or Elizabeth Warren giving, except in some respects he ends up embracing ideas that are more radical than theirs.
The whole speech is worth a read, but Kashkari's key idea is really contained in this paragraph. His point is that it's one thing to look at a financial institution and ask yourself what would happen if it went bankrupt due to a random act of massive incompetence, and another thing entirely to ask what would happen if banks were going bankrupt as part of a larger meltdown of the American economy:
I learned in the crisis that determining which firms are systemically important—which are [Too Big To Fail]—depends on economic and financial conditions. In a strong, stable economy, the failure of a given bank might not be systemic. The economy and financial firms and markets might be able to withstand a shock from such a failure without much harm to other institutions or to families and businesses. But in a weak economy with skittish markets, policymakers will be very worried about such a bank failure. After all, that failure might trigger contagion to other banks and cause a widespread downturn. Thus, although the size of a financial institution, its connections to other institutions and its importance to the plumbing of the financial system are all relevant in determining whether it is TBTF, there is no simple formula that defines what is systemic. I wish there were. It requires judgment from policymakers to assess conditions at the time.
Kashkari says he's reasonably confident that the regulatory tools put in place after the crisis can do a good job of dealing with systemically significance financial institutions in a non-crisis situation. The problem, he says, is that in a crisis, that calculation would become a lot less certain and policymakers would become a lot more risk-averse. The exact problem that faced the Bush administration in 2007 and 2008 would recur:
Given the massive externalities on Main Street of large bank failures in terms of lost jobs, lost income and lost wealth, no rational policymaker would risk restructuring large firms and forcing losses on creditors and counterparties using the new tools in a risky environment, let alone in a crisis environment like we experienced in 2008. They will be forced to bail out failing institutions—as we were. We were even forced to support large bank mergers, which helped stabilize the immediate crisis, but that we knew would make TBTF worse in the long term. The risks to the U.S. economy and the American people were simply too great not to do whatever we could to prevent a financial collapse.
So what does he think should be done about it?
Kashkari says we should "give serious consideration to a range of options" and that bank breakups ought to be on the menu. His other two ideas are less politically sexy but, if anything, more radical.
One is that large banks should be regulated like public utilities, "by forcing them to hold so much capital that they virtually can’t fail (with regulation akin to that of a nuclear power plant)." The other is "taxing leverage throughout the financial system to reduce systemic risks wherever they lie."
Both these proposals are, essentially, extreme curbs on banks' ability to finance their operations with borrowed money, which would make them a lot less profitable. Breaking up banks is something that would be really bad for the executives of the existing big banks and probably a little bad for their shareholders, but would still leave the banking industry as a whole in a prosperous condition. Curbing risk across the board would be more severe.
Saudi Arabia and Russia, the world's two largest oil producers, joined Qatar and Venezuela at a big OPEC meeting to announce a plan to cap oil production and bring a halt to the slide in crude oil prices that's rocked global markets over the past couple of years.
But don't expect it to work.
The key problem is that even though Saudi Arabia and Russia are huge producers of crude oil, they haven't been responsible for much of the recent increase in oil supply. So capping production at January levels, which is what they are talking about, won't necessarily do much to prevent new supply from coming online. The real sources of new crude are Iran and Iraq, and they're not party to the deal.
Iran, as you have probably heard, recently signed a major diplomatic agreement with the United States and other world powers, whose terms involve verifiable nuclear disarmament in exchange for sanctions relief. The main points of this from an Iranian point of view are to make it easier to export oil and to make it easier to import the foreign capital, equipment, and expertise needed to increase domestic oil production.
Under the circumstances, agreeing to a production cap would amount to giving up the lion's share of the gains from the deal with no real upside.
Somewhat similarly, Iraq has been steadily increasing its oil production as part of the postwar rebuilding process but continues to see output hampered by security problems. The Iraqi government may or may not manage to make further progress in securing oil facilities from the Islamic State, but if it does succeed, the Iraqis are going to do everything they can to bring that oil to market and give it the revenue it needs to fight the insurgency.
Last but by no means least, the United States — the world's No. 3 producer of oil — isn't party to any such deal and doesn't even attend these kinds of meetings, because we are net importers of crude oil.
American production is down a bit from its highs in the summer of 2015. But that's not a policy decision to cut production, it's not security problems, and it's not a lack of exploitable oil resources. What's stymied US production is that the price of oil fell steeply enough that the pace of new drilling collapsed.
That's been the one ray of good news for Persian Gulf oil producers in 2016. But it also in effect puts a cap on oil prices. Even if the Saudis and the Russians could get Iran and Iraq on board for production cuts to raise prices, if prices rise too much, US production will come roaring back.
Fear of this scenario is precisely why Saudi Arabia has thus far been reluctant to agree to meaningful production cuts. Today's agreement reflects less a change of heart on that score than a desire to create the appearance of progress by reaching a diplomatic deal that isn't so meaningful.
Around the world, markets are in chaos. Japan's stock market plunged 5 percent on Friday, while markets in France, Germany, and the UK all saw big losses on Thursday. The US stock market is doing better than most, but it is also down since the start of the year. Oil hit a new low on Thursday of $26 per barrel.
These declines reflect growing concerns that the world economy is headed for another recession. Before 2007 we’d say, "If things get bad, the Fed will cut interest rates." But with the Fed’s benchmark rate below 0.5 percent already, a substantial cut would mean rates that are below zero. That's an unorthodox strategy, and it might not even be legal, according to testimony by Fed Chair Janet Yellen before congressional committees this week.
The Fed needs a new strategy: Stop targeting interest rates and instead target the growth of the overall economy. Moving away from interest rate targeting would give markets confidence that the Fed has the tools to deal with the next economic downturn, which would reduce the danger of another 2008-style meltdown.
Unfortunately, there's little sign that the Fed is laying the groundwork for a shift in strategy. Instead, Yellen seemed to be in denial about the magnitude of the challenge she is facing.
"Let’s remember that the labor market is continuing to perform well," she said to the Senate Banking Committee on Thursday. "We want to be careful not to jump to a conclusion about what is in store for the economy." Maybe not — but the Fed needs to be prepared for the worst.
"The Fed needs to change their fundamental approach," argues Scott Sumner, a monetary policy expert at the Mercatus Center. Right now the Fed's policy discussions are all about where to set short-term interest rates. But not only does that approach stop working when interest rates fall to zero — as they did in 2008 — but interest rates aren't even what people actually care about.
Instead, Sumner argues, the Fed should start directly targeting a variable people do care about: either the inflation rate or (even better) the total amount of spending in the economy. He argues that the Fed should focus on setting long-run goals for these variables and then doing whatever it takes to meet those goals.
The Fed currently has an official target of 2 percent inflation. But the central bank's actions make it clear that it's not serious about this target. Last December, for example, the Fed's own forecast showed that inflation would be around 1.6 percent in 2016 — and the forecast inflation rate had actually been falling. Yet the Fed raised interest rates anyway. That was a pretty clear signal to the markets that the Fed cared more about returning to "normal" interest rates than it did about achieving its inflation target.
The problem isn't just that the economy will grow a little bit slower in early 2016 than it could have otherwise. By ignoring its own targets, the Fed sent a message that it wasn't really committed to robust growth over the long run, which undermines businesses' confidence in the recovery and discourages investment.
The solution, Sumner argues, is for the Fed to use a strategy called level targeting to make its own targets more credible. Under a level targeting regime, the Fed would compensate for missing its target in one year by overshooting the following year. For example, in 2015, the Fed's preferred measure of inflation came in at 1.4 percent — 0.6 percent below the Fed's 2 percent target. Under level targeting, the Fed would aim to achieve 2.6 percent inflation in 2016, delivering 2 percent inflation on average in 2015 to 2016. That would not only support faster economic growth in 2016, it would also give the markets more confidence in the Fed's forecasts for 2017, 2018, and beyond.
Abandoning interest rate targeting might seem radical, but the Fed has actually done it once before, in the late 1970s. Back then, it seemed that no matter how high the Fed raised interest rates, it couldn't get inflation under control. So in 1979, the Fed stopped targeting interest rates altogether.
Instead, it simply set a target for the total amount of money in the economy. Fed Chair Paul Volcker knew that if the amount of money in circulation stopped rising, the inflation rate would eventually have to stop rising too. It took a couple of years (and helped induce a major recession in 1980), but it worked.
A big reason the strategy worked is that markets believed Volcker was serious about the target. Targeting the money supply directly signaled he was willing to let interest rates go as high as they had to in order to get inflation under control. Once markets believed he was serious, they started doing a lot of his work for him — and businesses began to curtail price increases in the expectation that the overall inflation rate was going to decline.
Today we're facing the reverse situation. A big reason the economy has been recovering so slowly is that businesses are worried about sluggish growth — or, worse, another 2008-style meltdown — in the coming years. So they've been reluctant to invest, making slow growth a self-fulfilling prophecy.
If the Fed can convince businesses that it's serious about delivering consistent growth, businesses will start investing more in the expectation that demand for their products will grow — and that investment will itself produce growth.
Level targeting is a strategy for giving the market more confidence in the Fed's long-term targets. And while inflation-based level targeting would work better than what we're doing now, Sumner argues that the best strategy would be to target the total amount of spending in the economy. This approach, known as nominal GDP targeting, has been endorsed by prominent economists such as Christina Romer.
There are two big problems with the Fed's current strategy of focusing on interest rates. The obvious one is that once rates hit zero, the conventional approach to monetary policy becomes ineffective. After rates hit zero in 2008, the Fed was forced to use an ad hoc strategy known as "quantitative easing" to pump more money into the economy. Lacking experience with this new strategy, the Fed twice made the mistake of ending easing too early, slowing the economic recovery between 2010 and 2012.
The larger problem with zero interest rates, however, is politics. People are used to thinking of low interest rates as a sign of easy money and vice versa, so the zero interest rate struck many as a sign of recklessly easy monetary policy. In the years after the financial crisis, critics warned that Fed policies would create runaway inflation.
In retrospect, it's clear that these concerns were unfounded. The average inflation rate since 2008 has been well below the Fed's 2 percent target, while the economy has suffered from persistently slow job and wage growth. But fear of a political backlash for doing "too much" discouraged Yellen's predecessor, Ben Bernanke, from acting decisively to promote economic growth.
More recently, the Fed has come under a lot of pressure to "normalize" — that is, raise — rates above zero percent. After resisting these pressures for most of 2015, the central bank finally pulled the trigger in December, boosting its target rate from zero percent to 0.25 percent. It did this despite the fact that — as Vox's Matt Yglesias pointed out at the time — most economic indicators suggested that a rate hike would do more harm than good.
This is the flip side of the situation the Fed faced in the 1970s. Because interest rates were high, many people thought monetary policy was too tight, and the Fed faced a lot of pressure to cut rates. But cutting rates triggered another wave of inflation, forcing the Fed to raise rates once again. Interest rate targets had become a distraction, and abandoning them helped Volcker focus on the variable he really cared about: inflation.
Negative interest rates are one way the Fed could try to salvage the current regime of focusing on interest rates. But it's not a very good one.
Just as you might have a savings account with your bank, so a nation's banks all have accounts with their nation's central bank. The money deposited in these accounts is called reserves, and in recent years a lot of banks around the world have chosen to build up huge reserve war chests. That's frustrating to central bankers who have been trying to encourage banks to stimulate economic activity by lending out the money.
So recently Japan's central bank and some central banks in Europe have been experimenting with negative interest rates on reserves. Last month, the Japanese central bank announced that banks would be assessed a 0.1 percent penalty on their reserves — an interest rate of -0.1 percent. A bank with a billion yen deposited with the Bank of Japan will now have to pay 1 million yen per year for the privilege.
Obviously, 0.1 percent is not a very big number, so the direct effects of Japan's new policy won't be very large. But going negative breaks through an important psychological barrier — once a central bank has instituted a slightly negative interest rate, it's more likely to cut rates further in the future.
In her testimony before Congress this week, Yellen was pressed on whether the Fed would follow its European and Japanese counterparts and impose a penalty on reserves. Yellen demurred, saying that the Fed's experts were still studying whether negative interest rates would be legal and technically feasible.
But even if the Fed ultimately decides to adopt negative rates, there are real limits on how far they can go. If negative interest rates get too steep, banks have an obvious alternative: They can get physical cash and store it in a big warehouse. By definition, cash is worth as many dollars a year from now as it is today.
There are a couple of ways central banks could try to make negative interest rates more feasible. University of Michigan economist Miles Kimball, for example, advocates a shift to a new form of electronic money that would allow central banks to impose economy-wide negative interest rates. Others argue that the Fed should raise its inflation target so that real, inflation-adjusted interest rates can go lower. But not only do both of these approaches have technical challenges, they're also likely to be intensely unpopular with voters.
So even if the Fed adopted negative rates, it wouldn't improve the effectiveness of the current interest rate targeting regime very much. Just as the Fed got stuck at zero percent interest rates in 2008, it could get stuck at -1 percent interest rates in 2017 or 2018. So the Fed is going to need a new framework that's less dependent on interest rates regardless. It might as well get started.
Twitter is at a crisis point in the wake of an earnings report that showed its number of users has stopped growing. At the same time, depending on how you count Twitter employees' stock options, the company is either still continuing to lose money or only modestly profitable. The thin ray of good news is that revenue grew — if that continues, the company's profits could improve steadily over time. But investors who bought Twitter shares back in 2013 were expecting explosive, Facebook-style growth, not modest profitability.
This brings Twitter to a key decision point. Does CEO Jack Dorsey push for fundamental changes in how the service works in hopes of dramatically increasing Twitter's user base, even though big changes might alienate current users and completely destroy the company? Or does he decide to try to make do with what he has, keeping current customers pleased and focusing on optimizing revenue and trimming costs in pursuit of a decent near-term profit?
That's why a small change Twitter rolled out this week is attracting so much interest in financial markets and so much anxiety among hardcore Twitter lovers.
If you walk by the desks of software developers here at Vox — or at any other company — there's a good chance you'll see them using a Unix command-line interface that dates back to the 1970s. Geeks continue to use the Unix command line because once you know how to use it, it's a powerful way to perform complex computing tasks.
But most users don't need the power, complexity, or hassles of using a Unix command line, which is why it never caught on with ordinary users. Until recently, most people used Windows PCs or Macs with a more user-friendly graphical user interface. Lately people have been shifting toward even simpler computing technologies: smartphones and tablets. These mobile platforms provide fewer capabilities than a conventional PC — it's hard to write a blog post or manage a complex spreadsheet on an iPhone — but they're easy to learn and demand little of users.
The older, more complex computing platforms didn't die. Certain kinds of professionals still use them. But most people use the simplest, most user-friendly platform available: smartphones.
A similar principle applies to social media technologies: The most popular services tend to be the ones that demand the least from their users. And Twitter demands a lot more of users than Facebook does.
To make Twitter manageable, you have to carefully curate the list of people you follow to avoid being overwhelmed. The rules for Twitter conversations — for example, the fact that starting a tweet with someone's username will hide it from anyone not already following that user — are not intuitive to someone dropping by the site for the first time, or even the 10th. And many users find it intimidating to write tweets that anyone in the world could read.
Twitter helps users sift through a lot of information efficiently, which makes it invaluable for a media professional like me. But most people aren't interested in sifting through large volumes of information. They just want to look at pictures of their friends' weddings, vacations, and babies with a minimum of hassle. And Facebook makes this really easy.
The result: Twitter's growth has stalled at the same time other social networks such as Facebook and Instagram are continuing to grow. And that has created a lot of friction between Twitter's management and Wall Street.
Many investors bought Twitter stock hoping that it would grow to become a Facebook-size behemoth. But it now looks like Twitter will wind up being much smaller than Facebook, which will mean it generates a lot less ad revenue — and ultimately profit — than Facebook.
Last week, BuzzFeed reported that Twitter was about to change the order in which it showed tweets to the user. This might seem innocuous, but it could have profound consequences for Twitter's user experience.
When you log in to Twitter, the service has traditionally shown tweets in strict chronological order, with the most recent tweets at the top. This means you only see tweets that occur at times when you happen to be paying attention. If a friend announces an engagement or pregnancy at a time when you're not online, for example, you might never scroll back far enough to see it.
Facebook takes a different approach: It shows the posts that a special Facebook algorithm thinks you will find most interesting. Facebook hasn't explained how its algorithm works, but we know it uses a wide variety of factors to gauge how interesting a post is. Posts about weddings, pregnancies, and other major life announcements tend to show up at the top of the Facebook news feed, as do posts with a lot of likes and those from your closest friends.
Facebook's approach is better for casual users. To get started on Facebook, you just have to identify your real-life friends and "like" posts that interest you. Facebook takes it from there, sifting through thousands of things your friends post to identify content you're likely to find interesting. You don't have to worry that friending too many people — or the wrong people — will turn your timeline into an unusable mess.
Twitter has been taking small steps toward a more Facebook-like service. Last year, the company introduced a feature called "While you were away." If you log in to Twitter after being away from the service for several hours, Twitter will show you older tweets that its software thinks you'll be interested in. However, it only shows a handful of older tweets — if you scroll down further, you get back to Twitter's standard reverse-chronological tweet order.
Then on Wednesday, Twitter announced a new feature called "Show me the best Tweets first" that seems to be very similar to "While you were away." The post doesn't explain how the two features differ, but it seems like the main difference may simply be that the new feature shows more "best tweets" than the old one did.
This might seem pretty innocuous — and it is. But when rumors of this feature first started circulating, it was pretty controversial among Twitter users.
The reason is that Twitter's current approach of showing tweets in chronological order means that most of the people who see a given tweet will see it within a few minutes of posting. This makes Twitter a real-time platform in a way that no other social media platform really is.
Twitter is the perfect place to banter about the Super Bowl, the Oscars, or a presidential debate. You can tweet about what just happened and assume that many of your followers will immediately understand the context. This real-time character makes the service especially useful to journalists, who want to always be up to date on the latest developments in their beats.
This kind of thing simply doesn't work on Facebook, because you never know if your Facebook post is going to be read an hour, a day, or a week from now. That means you can't assume that most readers of a particular Facebook post just saw the same thing you did. The real-time nature of Twitter also enables a type of sprawling real-time conversation among many users that's not really possible on any other platform.
Facebook's approach also gives more power to Facebook, since Facebook ultimately decides what users see. On Twitter, by contrast, what you see is entirely determined by whom you follow and when you're logged in. Naturally, power users who have put a lot of effort into curating whom they follow don't like the idea of ceding more power to Twitter over which tweets they see.
The big fear of Twitter users, then, was that Twitter would go full Facebook and totally replace its real-time feed with a Facebook-style news feed that shows the best tweets rather than the newest tweets. Or, at a minimum, that a Facebook-style feed would become the default, eroding Twitter's distinctive real-time culture.
But so far, that seems to have been a false alarm. Twitter is trying to help out infrequent users by showing a few high-quality tweets while staying firmly committed to reverse-chronological order as the main way people read tweets.
Still, if the "best tweets" experiment goes well, Twitter could gradually shift to Facebook's model over time. All they'd have to do is expand the number of "best tweets" they show, to the point where most people don't bother scrolling back to see the live tweets.
Underlying recent debates over Twitter's future has been a basic assumption that Twitter needs to resume the growth of its user base to be considered a success. That assumption is driven by Wall Street investors, who bought shares in the company's initial public offering in the hopes that the company will continue to grow.
Instead, Twitter's user growth has ground to a halt. And while Twitter will undoubtedly experiment with new ways to expand its audience, the company might ultimately have to admit that it's never going to be anywhere close to Facebook's size.
Twitter has more than 300 million users, and many of those are passionate daily users. That should be a large enough user base for a highly profitable business. Probably not profitable enough to justify the $30 billion valuation the company had a year ago, but perhaps profitable enough to justify today's company value of around $10 billion.
And Twitter may be able to find ways to play to the unique strengths of its user base. It doesn't have as many users as Facebook, but it can count among its users a large number of prominent investors, entertainers, academics, journalists, and other influential people.
These are people that some advertisers may be more keen to reach than the much broader audience reachable using Facebook ads. So if Twitter can figure out how to position itself as a premium advertising platform for precisely targeting its highly influential user base, it could earn a lot of money.
At the same time, it's not obvious that making Twitter more like Facebook would allow Twitter to grow to Facebook's size. People who like the Facebook experience can already get it on Facebook. Aping Facebook could easily alienate core Twitter users without attracting many new ones.
A new study says hiring more women in leadership roles literally pays off — big time.
The study, released Monday by the Peterson Institute for International Economics, finds that companies with more women executives tend to be more profitable.
This study isn't the first to find that better gender balance in leadership can be good for business. But it is the most extensive, sampling 21,980 firms with headquarters in 91 countries. Most other studies looking at this issue have been more limited or have just focused on one country.
Researchers found that companies with at least 30 percent of women in their most senior "C-suite" management positions are about 15 percent more profitable than firms with no top women executives.
This huge difference is probably because gender diversity is also correlated with skill diversity, which improves corporate performance on average. It's not that individual women will always outperform individual men in leadership. It's that women often bring different skills to the table — and firms that discriminate against women won't benefit from those skills.
Despite the profit-boosting power of women leaders, the report found a relative lack of women in upper management worldwide. Sixty percent of the companies studied had no women board members. Just over 50 percent had no women in C-suite executive positions, and 57 percent of the remaining half had just one woman executive. Fewer than 5 percent had a woman CEO. (Women CEOs also lead fewer than 5 percent of US companies on the S&P 500 index.)
But it's important to note: Having a woman CEO didn't actually have a measurable effect on a firm's performance one way or another. Having other women senior executives did, though — so much that the authors wonder if the same effect would apply to women in leadership below the C-suite level. Having women board members helps too, but not as much as having women executives.
"This pattern underscores the importance of creating a pipeline of female managers and not simply getting lone women to the top," the report reads.
Some countries, like Norway, have gender quotas for corporate boards. But, the report notes, these quotas don't seem to do much to help companies' performances.
One reason for this is the so-called "golden skirt effect," where a small number of women sit on the boards of several different companies and perform worse because they're overcommitted.
There could still be a role for quotas — especially ones that companies impose on themselves — in helping fight gender discrimination, the authors note. But it depends on a lot of different factors, including how far down the corporate ladder the glass ceiling reaches. If women struggle even just to reach upper management, it's more helpful to pursue policies to help mid-career women before tackling corporate board representation.
What definitely does help? Being located in countries that are really good at gender equity overall.
There's a positive correlation between companies with more women executives (and thus better profit potential) and countries where girls do better at math and where the public has less discriminatory attitudes toward women executives.
The researchers said that when women get a better education and have a better chance to get work experience free of discrimination, it fills the pipeline with lots of women who are qualified to serve in executive-level positions.
Paid paternity leave also makes a huge difference — but paternity leave specifically, not maternity leave.
This makes sense because, as other research has found, paid leave for dads boosts gender equality overall. It helps shift social norms away from the expectation that women are always going to be the primary caregivers for children, which helps remove a big stumbling block that keeps women from participating as fully as men in work and society.
This is another reason why boardroom quotas may not work — they can easily operate at a surface level. They can help companies look more diverse without solving the broader, deeper problems that hold down women's workplace advancement in the first place.
Every Chipotle restaurant will close for several hours today, February 8, so that the company can hold an unprecedented all-hands meeting to discuss issues related to the chain's food safety crisis. Multiple outbreaks of food contamination of varying levels of severity have pummeled the chain in recent months.

Here's the announcement notice on my local Chiptole, explaining vaguely that "we're closed for lunch today to attend a meeting with all other Chipotle employees" without mentioning the bacteria that have caused the meeting.

Sales have been plummeting as the chain, which used to market itself to health-conscious consumers with bogus arguments about the virtues of avoiding GMO foods, is learning that local and organic produce is actually harder to manage safely than conventional food.
A recent Bloomberg cover story makes clear that to an extent, Chipotle has been a victim of its own success. The chain has been wildly popular for years, and has been opening stores — and hiring staff — at a rapid pace. This large-scale hiring combined with an obsessive focus on serving customers at a more rapid clip seems to have made it challenging to maintain best practices on a staffing level. At the same time, relentless expansion of the Chipotle supply chain has made it harder and harder to track the sources of contamination.
In the short term, the question for Chipotle is whether things like the the shutdown can succeed in stemming the problems. But in the longer term, the big question is whether Chipotle can ever regain its brand as a "better" sort of fast food.
When I went to Chipotle last week for the first time since the crisis started, for example, they had no lettuce. It wasn't the biggest deal in the world, and I think it reflects a welcome newfound commitment to food safety. But it also reflects the fact that the restaurant seemingly can't fully deliver on its vision of quick service dining featuring fresh ingredients in a way that is both consistent and safe.
The Super Bowl is the purest distillation of America there is. It's brutal, lucrative, tawdry, spectacular, amazing, and full of delicious snacks. It's the one moment when we as a nation truly come together to reflect on our greatest achievements as a society — television, innovative chicken and cheese products, and over-the-top marketing. This year, there's also going to be a football game on.
But as the social pressure to watch a football game — or at least be in the presence of others who are watching — mounts, you may find yourself with some nagging questions. This is particularly true if you're not a football fan but are bowing to social pressure and pretending to be one for the day. We have the answers.
The most important question about any Super Bowl is what time is the Super Bowl? The answer is that this year’s big game will take place at 6:30 pm Eastern time on February 5, at NRG Stadium in Houston, Texas.
It’s on Fox, so if you’re interested in how to watch the Super Bowl, the answer is to tune in to Fox. If you want to know how to stream the Super Bowl, the answer is that you can stream the Super Bowl on the FoxSportsGo.com website or with the Fox Sports Go app.
If you are a Verizon customer who is wondering how to stream the Super Bowl to your phone, the answer is that you can stream the Super Bowl on your phone using the NFL app.
If you’re wondering why this section is written awkwardly, it’s because we are trying to load it with commonly searched keywords in hopes of improving its showing in Google and other search engines. This is called “search engine optimization,” and it’s an important part of contemporary digital content strategy.
Super Bowl 51 will be played at NRG stadium in Houston, Texas. This stadium is the home of the Houston Texans, and is part of a larger complex of sports facilities known as NRG Park that also includes the Astrodome (where the Houston Astros used to play), and which houses the Houston Livestock Show and Rodeo.
Most American sports leagues play their championship games at the home venues of the teams competing, but that’s not the case for the Super Bowl, which is such a big event that it’s invariably played at a neutral site selected long in advance.
Each year, the Super Bowl pits the champion of the National Football Conference against the winner of the American Football Conference. Super Bowl 51 features the Atlanta Falcons and the New England Patriots.
The NFL playoffs' single-elimination tournament structure sometimes allows real underdog teams into the Super Bowl, but that’s not really the case this year. The Patriots had the best record in the AFC and the best overall record in the NFL. The Falcons didn’t quite have the best record in the NFC, but they were close, and they had the second seed in the NFC playoff bracket.
Super Bowl ads are a big deal because they're extraordinarily expensive — $5 million for a 30-second spot this year — and Super Bowl ads are extraordinarily expensive because of the intersection of two trends.
One is the tremendous popularity of professional football. Lots of people watch the game.
The other is the declining popularity of everything that isn't live sports. The highest-rated non–Super Bowl broadcast of all time was the 1983 M.A.S.H. finale, which 60 percent of households watched. After that is a 1980 Dallas episode and the 1977 Roots finale. In the modern world, with audiences fragmented by cable television, distracted by the internet, and time shifting with DVR and on-demand services, it simply isn't possible for anything other than live events to reach very large segments of the population. This makes the Super Bowl a unique marketing opportunity that commands a uniquely high price.
Because Super Bowl ads are so expensive, companies that buy them tend to take the opportunity to roll out signature ads and new campaigns, which heightens the attention paid to the advertisements.
Are the ads worth the money? A team of researchers from the University of Wisconsin's Eau Claire campus has found some evidence that they may be. Films that are advertised during the Super Bowl see a 40 percent boost in ticket sales, and publicly traded companies that advertise during the game see their stock overperform the S&P 500 in the short term.
No. The winner gets the Vince Lombardi Trophy, named for the legendary coach of the Green Bay Packers in the 1960s. The origin of the Super Bowl name is somewhat tangled, but in brief:
Yale University's football team has long played in a bowl-shaped arena known as the Yale Bowl (not to be confused with Yale Bowls, which sells actual bowls). In 1923, a similarly shaped arena was constructed in Pasadena, California, and dubbed the "Rose Bowl." Pasadena had been the site of an important postseason college football match for about 20 years before the construction of the Rose Bowl, and once the new arena was complete, the match became known by the same name as the arena. From there, the tradition of referring to postseason college football games as "bowls" spread.
Meanwhile, in 1920 a number of professional football teams banded together to form the National Football League. In 1960, a rival professional football league — the American Football League — was established. In 1966, the two leagues agreed to merge. The merger was not complete until 1970, but starting in 1967 the winner of the NFL championship tournament played the winner of the AFL championship tournament in a championship game.
Once the merger was finalized, pro football was reorganized so that the old NFL became the National Football Conference and the old AFL became the American Football Conference, and the whole thing combined was the National Football League. The Super Bowl is played between the AFC champion and the NFC champion, and determines the overall league champion.
Like so many other things these days, this is basically a matter of partisan politics.
Donald Trump is a big fan of New England Patriots quarterback Tom Brady, whom he says “is a friend of mine, we play golf together.”
Conversely, while feuding with Rep. John Lewis (D-GA), Trump referred to his district — which includes the vast majority of the city of Atlanta — as “crime infested,” “in horrible shape,” and “burning.”
Some people like Trump, and they will enjoy rooting for Trump’s team, the Patriots. Other people do not like Trump, and they will enjoy rooting for Lewis’s team, the Falcons.
Of course, to make things somewhat problematic, there are serious Falcons fans throughout the state of Georgia, which Trump won, and Patriots fans throughout New England states, all of which Trump lost. So actual residents of these areas may feel significantly cross-pressured. But if you don’t live in Georgia or New England, your choice is clear.
Football has a lot of rules. But here are the basics:
The complete rulebook is here if you happen to be very bored. Note that even very serious football fans often don't fully understand all the different aspects of the rules, whose details change a bit from year to year within the basic framework.
I don't know. That's why they play the games!
I can't. Please watch the great video below, which Joseph Stromberg did on this subject, and read his article.
Yahoo is one of the best-known brands on the internet, but its core internet business is in a grim situation. How grim? There's a debate over whether the company itself — what most of us think of when we think of Yahoo — is actually worth less than zero dollars.
Back in 2005, Yahoo invested $1 billion in one of China's hottest technology startups, Alibaba, getting a roughly 40 percent stake. The bet has paid off handsomely. In 2012, Yahoo sold part of its stake back to Alibaba for $7.6 billion. Since then, Alibaba has continued to grow rapidly, and Yahoo's remaining stake is now worth around $25 billion.
That number is remarkable because Yahoo as a whole isn't worth much more than that. Indeed, if you subtract the value of all of Yahoo's major assets — including a multibillion-dollar stake in Yahoo Japan (an independent subsidiary in which Yahoo is a minority shareholder) and a few billion dollars in cash — from its market value, you get a big negative number. "If you just solve for the missing number, you are forced to conclude that Yahoo's actual core business of being Yahoo (and Tumblr and whatever) is worth negative $13 billion," as Bloomberg's Matt Levine put it in December.
I don't think that's true, for reasons I'll get into shortly. But it's created a secondary crisis for the company — and a deep distraction for its CEO, Marissa Mayer.
In 2012, Yahoo's board hired Mayer, then one of Google's best-known executives, to turn the company around. Nearly four years later, it's becoming clear that her turnaround effort is failing. Mayer has invested lavishly in both engineering and media talent, but there's no sign that these investments are paying off in the form of higher revenue.
And over the past year, Mayer's management of Yahoo the business has been overshadowed by an argument over whether Yahoo can distribute its Alibaba holdings to shareholders without paying billions of dollars in taxes on them.
Things came to a head on Tuesday, when Yahoo released its quarterly financial results along with a new turnaround plan. Yahoo announced that it was laying off 1,700 workers and focusing on its most successful products — including its search engine and popular email service. But in the same press release, the chairman of Yahoo's board announced that the board is going to "engage on qualified strategic proposals" — that is, consider offers to sell the company.
It's a humiliating announcement for Mayer, because it clearly signals that the board is losing patience with her turnaround efforts. And the looming possibility of a sale is going to make it all the more difficult for her to motivate Yahoo's remaining staff to work hard on her latest turnaround plan.
The most successful companies in Silicon Valley — including Google, Facebook, and Apple — have an intensely technology-focused culture. These companies are obsessive about hiring the most talented engineers (and in Apple's case, designers) so they can build the best technology products. And this culture tends to be self-perpetuating — very skilled, highly motivated people like to work with other very skilled, highly motivated people. Once you have a critical mass of such people it becomes easy to recruit more of them.
Yahoo has never had the same kind of obsessive focus on recruiting technical talent. Paul Graham, a well-known Silicon Valley investor who sold his company to Yahoo in 1998, has written that even in the late 1990s, Yahoo was ambivalent about its status as a technology company.
"One of the weirdest things about Yahoo when I went to work there was the way they insisted on calling themselves a 'media company,'" Graham wrote. Yahoo employed a lot of programmers and produced a lot of software, of course — and still does. But it never made software as core to its identity as some of its major competitors.
That's probably because at the time Yahoo was founded, in 1994, no one had ever heard of an ad-supported software company. Back then, software companies sold their products in shrink-wrapped boxes at Best Buy. Yahoo had the same business model as CNN and the New York Times — build up a large audience and then make money by selling ads — so it was natural for Yahoo to think of itself as being in the same industry. But one consequence of this was that Yahoo didn't focus as much as it could have on recruiting the best programmers.
Marissa Mayer's roots are as an engineer at Google, and she has made an effort to beef up Yahoo's technical talent. She instituted a more rigorous hiring process, and the company has worked hard to hire more computer scientists, especially from top universities.
But there's little sign that these moves have changed the culture or improved morale among Yahoo's programmers. "I just try to ship products that I’m not ashamed of," a Yahoo executive told the New York Times in December. This is not an attitude that tends to produce excellent products.
At the same time, Mayer has doubled down on the "media company" side of Yahoo's personality. In 2013, she hired television news anchor Katie Couric for Yahoo's news site. Couric's contract was renewed last year in a deal reportedly worth $10 million. Mayer also recruited gadget reviewer David Pogue from the New York Times to anchor Yahoo's relaunched technology news section.
But despite these investments, Yahoo doesn't have nearly the prestige of a New York Times or a CBS. The company is seen as something of an also-ran both in Silicon Valley and in the media world. Yahoo creates technology products that people use and media properties that have an audience, but its attempt to be a technology company and a media company simultaneously has resulted in an organization that's less than the sum of its parts.
In the past few years, Yahoo's media and tech businesses have been overshadowed by a third line of business: venture capital. At the same time Yahoo's core business has been in decline, its Alibaba investment has been soaring in value. Indeed, when you subtract the value of Yahoo's major assets from the total market value of the company itself, you get a large negative number.
The uncharitable way to interpret this is that the core Yahoo business is actually destroying value. It's possible that Marissa Mayer could increase her stock price by simply announcing that she was shutting down all of Yahoo's websites and laying off all of its employees.
But there's another major factor in Yahoo's depressed share price: taxes. On paper, Yahoo's Alibaba share is worth around $25 billion. However, if Yahoo ever tried to sell its stake and pay out the proceeds to shareholders, it would owe billions of dollars in taxes to the IRS.
After adjusting for these tax liabilities, it's possible to get a positive number for the value of Yahoo's core business. But it's still a small number. When Levine crunched the numbers in December, he concluded that Yahoo's core businesses were worth just $1.7 billion, less than 10 percent of Yahoo's overall market value.
So Yahoo's search engine, email service, news site, and other properties might not literally be worth less than nothing. But right now the stock market doesn't seem very optimistic about their chances.
It's not hard to see why Wall Street would value Yahoo's core business as close to worthless. Yahoo has several different ways to measure its profits, but all of them have been getting worse over the past two years:
At a time when other internet companies have enjoyed healthy growth, Yahoo's numbers are moving in the opposite direction. Analysts who have looked at Yahoo's cash flow think Yahoo's internet business would be worth around $4 billion as a separate company, a small fraction of its value a few years ago. In short, there's no sign that Mayer's turnaround efforts have been working. She has invested heavily in both engineering and media talent. But those investments haven't yet improved Yahoo's bottom line.
The big fear of Yahoo's Wall Street critics isn't just that Yahoo management will fail to turn a profit; it's that they'll burn up billions of dollars in a futile effort to turn Yahoo around. Yahoo has enough cash in the bank to continue its current losses for several more years, and after that it could sell its Alibaba and Yahoo Japan stakes to buy itself many more years of money-losing operation.
But while Yahoo's management and employees obviously like to have a big cash cushion, shareholders aren't interested in endlessly subsidizing a money-losing business. And so over the past year, Wall Street has been steadily ratcheting up the pressure on Mayer to separate Yahoo's core internet business from its stakes in Alibaba and Yahoo Japan.
To mollify Wall Street, Mayer announced a plan last summer to spin off Yahoo's Alibaba shares into a new holding company. Under tax law, a company can spin off part of its business tax-free if it's doing so for a legitimate business purpose, but it can't do so merely as a tax dodge. In the past, the IRS hasn't enforced this rule very strictly, but when Yahoo asked the IRS to bless its spinoff proposal, the IRS demurred. That meant Yahoo could face a multibillion-dollar tax bill. So in December, Yahoo announced that it was canceling the spinoff.
In the goofy world of tax law, another option is a "reverse spinoff." In this plan, Yahoo would essentially spin off the entire company into a new legal entity, leaving the existing corporation as a holding company for Alibaba shares (and possibly Yahoo Japan shares) and a few other assets.
You might think spinning off everything except Alibaba shares would have the same tax implications as spinning off Alibaba shares, but that's not necessarily the case. This could allow shareholders to get their Alibaba shares without the baggage of Yahoo the business, and without paying any taxes on Alibaba's increased value.
In a January letter, the hedge fund Starboard Value was scathing about Mayer's performance. "The management team that was hired to turn around the Core Business has failed to produce acceptable results," the firm wrote.
So Starboard urged Yahoo's board to choose a third option: selling Yahoo's core business to another company.
A spinoff would leave Mayer in control of Yahoo the business, which Starboard views as a disadvantage. The hedge fund believes a new owner could do more with the company than the current management, and would therefore pay more for the company than the current market value.
And Starboard isn't just making an idle suggestion. Starboard is an activist investment firm. Its strategy is to buy a stake in a company and then use it as leverage to force management to make changes. In 2014, for example, Starboard successfully ousted the management of the Olive Garden after writing an epic 300-page slide deck criticizing the company's management. The slide deck faulted the restaurant chain for stale breadsticks and mushy pasta, along with weightier criticisms of its real estate portfolio and business strategy.
Starboard is threatening to take that same approach at Yahoo. "If the Board is unwilling to accept the need for significant change," the company wrote on January 6, "then an election contest may very well be needed so that shareholders can replace a majority of the Board with directors who will represent their best interests."
It's easy to get bogged down in tax and accounting details, but the big-picture lesson here is that Yahoo is failing under Mayer.
If Apple had made a prescient billion-dollar investment in Alibaba 10 years ago, Wall Street wouldn't be pressuring CEO Tim Cook to spin off the shares. And that's not just because Apple's success gives Cook leverage over Wall Street in general. It's also because so long as Apple continued to be profitable, there'd be no reason to worry about Cook raiding profits from one part of the business to cover losses in another part.
But there's a real danger that Mayer — or one of her successors — will dip into those Alibaba profits to help pay for Yahoo's continued losses. And because those Alibaba shares are worth a lot more than the rest of Yahoo put together, Wall Street's top priority is to make sure that a continued meltdown of Yahoo the company won't drain value from Yahoo's investments. The easiest way to do that is to put them into separate companies.
Reasonable people can debate whether the failure of Yahoo's core business is Mayer's fault or whether Yahoo was beyond saving when she arrived. Given the long line of failed CEOs that preceded her, I'm more inclined to go with option two. But either way, it's becoming clear that Mayer's turnaround plan isn't working.
In November, Amazon opened its first bookstore, and reports from the CEO of one of America's largest shopping mall operators Tuesday afternoon suggest that the company is prepared to open several hundred new ones across the country. This prompted many to ask why the company that destroyed the physical bookstore industry would possibly want to operate a physical bookstore.
Part of the answer is that, as the announcement of the original store location said, "At Amazon Books, you can also test drive Amazon’s devices," meaning Kindles, Echos, Fire TVs, and Fire Tablets "are available for you to explore, and Amazon device experts will be on hand to answer questions and to show the products in action." Apple has physical retail stores for its digital devices, as do (albeit less successfully) Microsoft, Sony, and Samsung. Since Amazon makes Amazon-branded devices, why shouldn't it have a store too?
But the bookstore framing is no coincidence, and the reality is that something bigger and more profound is happening than a simple desire to let people window shop for Fire TV sticks. Amazon is interested in bookstores for two big reasons:
For years now, Amazon has been the most terrifying competitor on the planet. And a possible move into physical retail should be taken as a reminder that no business of any kind should view itself as protected from Jeff Bezos's plan for global domination.
Large American technology companies like Apple, Google, Facebook, and Microsoft are ridiculously profitable and, indeed, infamous for the lengths to which they go to avoid paying corporate income tax on their gargantuan profits. Since Amazon is also a large American technology company, it is easy to assume that it, too, must be ridiculously profitable. But this is not the case. The retail industry has traditionally been a very low-margin matter, and Amazon has outcompeted traditional retailers in part by offering even lower margins.
But that's recently changed. In the most recent two quarters, Amazon has earned meaningful profits — profits driven by the success of Amazon Web Services, an enormously popular technology infrastructure company that enjoys tech-like economics rather than retail-like ones. That means 25 percent profit margins on a business that does $2 billion in revenue a quarter and is growing at a 70 percent annual rate.
As the technology industry analyst Ben Thompson put it, Amazon became profitable because "AWS is simply spinning off more cash than Amazon knows what to do with."
The key to understanding Amazon as a business is that earning a profit is antithetical to its corporate culture and mission. Rather than increasing the value of Amazon stock by pushing out cash to shareholders, Bezos's strategy is to increase the value of Amazon by literally making the company bigger. Each year, Amazon owns more warehouses, more customer data, more intellectual property, wider distribution channels, etc., and therefore becomes a more valuable enterprise than it was before.
On occasion, Amazon will turn a profit either to prove to Wall Street that it can, or else because (as with AWS recently) a particular venture simply proves more lucrative than expected.
But that AWS revenue was never going to sit around in the corporate treasury or be paid out as dividends. A surge in revenue needs to be met by a surge in new expenses. Recently prestige video content (Bezos says he wants to win an Oscar) and an effort to create a two-hour delivery service called Amazon Now have been soaking up the extra money. Brick-and-mortar retail is both another potential money sink and also a possible launching pad for Amazon Now services, which are obviously going to require some kind of logistical infrastructure.
So why brick-and-mortar retail? Most likely because Amazon's long-term strategy is simple: It wants everyone, everywhere to buy everything from Amazon.
And it's clear that whatever the struggles of some major big-box retail chains lately, people do in fact continue to buy things in stores. For some people, some of the time, a physical store is where they want to shop. These days you probably could buy everything you need online, but almost nobody actually does. Which means nobody buys everything from Amazon. Which is unacceptable.
So why bookstores? For the same reason Amazon.com was originally an online bookstore. You've got to start somewhere, and the book industry is a relatively soft target. Since Amazon's already basically crushed the national bookstore chains, nobody can really stop the company from getting a foot in the door of this niche.
Ultimately, it might be a total dead end. But even if the effort to establish stores fails, it will be a potentially valuable learning experience. Amazon prides itself on a value it calls "customer obsession," but lacking a physical presence means the company ends up with a somewhat limited view of what its customers look like and how they behave. A retail presence can help change that.
The bigger, less irony-laden thing that Amazon is working on right now is same-day delivery for Amazon Prime members. Currently, same-day delivery is sporadically available — for some products, in some cities, some of the time. It feels kind of like magic when it works, but it's not nearly predictable enough right now to be a real driver of business rather than an impressive occasional delight for customers.
Amazon's long-term aspirations in this field appear to involve fleets of driverless trucks and even flying delivery drones.
But in the human-powered present (and perhaps even in the drone-full future) same-day delivery requires stockpiles of merchandise that are more numerous and located more directly adjacent to population and transportation hubs than the company's existing warehouses. The geography of same-day delivery depots, in other words, looks a lot like the geography of classic big-box stores. You wouldn't have just one Borders serve an entire region. Instead, a given metro area would feature one or more downtown locations plus a bunch of mall spots in the surrounding suburbs. The goal was to ensure that nobody who bought books regularly was ever all that far from a Borders.
Essentially replicating this structure but combining it with Amazon's logistics infrastructure, immense supply-chain bargaining power, vast stockpile of consumer knowledge, and the Prime subscription revenue model is at least a plausible vision of the future. And if the depots can serve as showrooms for Amazon hardware and help get traditional brick-and-mortar shoppers into the Amazon lifestyle, then why not?
Amazon shares plummeted late last week as the company's quarterly earnings report revealed profits that were well below Wall Street's expectations. Notably, it's not as if people stopped buying things through Amazon. Sales grew 22 percent. It's just that analysts had gotten it into their heads that profit margins were going to rise as well. Loyal Vox readers, of course, were warned that this wouldn't happen, but some people don't listen.
I would say that if you want to understand Amazon, you should just look at this chart:
This, to me, does not look like a company that is trying and failing to increase its profits. Nor does it look like a brand new startup that is eschewing short-term profits in order to establish its business. Amazon is a pretty old company, and its profits have never meaningfully differed from zero even as the company gets bigger and bigger.
That's because — drumroll, please — Amazon's leadership, from CEO Jeff Bezos on down, are deliberately redeploying every dollar of revenue Amazon earns into making the company bigger and bigger.
One can debate the wisdom or sustainability of this strategy (I think it's awesome, personally) but it's clearly the strategy. Nothing in life lasts forever, and this will presumably change at some point due to some drastic change of circumstances. But the expectations around Amazon this quarter were much more banal. People decided that because Amazon Web Services is profitable and growing fast, Amazon would start exhibiting fast-growing profits.
The mistake here is in understating Amazon's ambitions. Profits stayed meager because Amazon amped up its spending by 20.5 percent. Company leaders explained that they are spending more on original video content (Bezos wants to win an Oscar) and are trying to create something called Prime Now that will deliver you stuff in two hours rather than two days, which is totally ridiculous. There's no limit to how much you can spend chasing these kind of goals, and absent some kind of fundamental change in the company's structure or legal status, that's where all the money will go.
For years, pundits have speculated that online instruction could begin to overtake traditional higher education, but too often have offered few details about how this would happen. Already, however, you can see a path through which tech companies could gain a foothold in the higher ed market.
Here's one scenario — told through the vantage point of Amazon's Jeff Bezos in 2030. I don't know if it's going to happen, but as you'll see in the footnotes, Amazon is already making moves that could suggest it would be a potent competitor to existing colleges and universities.
To Our Shareowners:
After the spectacular and occasionally criminal failure of several for-profit college companies in the years following the Great Recession1, some critics argued that the pursuit of profit was fundamentally at odds with the mission of high-quality education. Amazon University, now in its 15th year and serving more than a million customers, has proven those critics wrong and delivers higher-quality, lower-cost educational offerings than the once-vaunted nonprofits that continue to charge high tuition in pursuit of a short-term revenue boost.2
A dreamy business offering has at least four characteristics. Customers love it, it can grow to very large size, it has strong returns on capital, and it’s durable in time — with the potential to endure for decades.3 Amazon University meets this standard, and then some.
Like some of our other ventures in the past, Amazon University was started out to fill an internal need.4 We needed our employees to have certain skills. So we found a way to give them just that.
We started out with Career Choice, a benefit offered to employees through which we paid 95 percent of tuition for classes in in-demand fields to help our employees progress in their careers. Within a few years, we started offering classrooms on site.5 From the beginning, it was about filling needs not just at Amazon but in the larger community: The first graduate of the program earned a nursing degree.6
Separately, in 2013, we launched a certification program for various Amazon Web Services engineers, letting companies using AWS easily train or hire workers who could manage AWS infrastructure.7
But we also found that many of our employees, even those with advanced degrees from prestigious universities, were incompetent at core aspects of their jobs here at Amazon. Due to our obsession with rewarding competency, hard work, and results,8 we searched for a solution. Luckily, it was right there in front of us.
In 2013, our subsidiary Zappos became a trailblazer in the use of "badges" to  let employees demonstrate mastery of a skill and earn raises.9 Leaning heavily on that expertise, Amazon, in 2018, decided to revamp Career Choice and build an internal competency-based education system.10 Employees would earn a badge for a discrete skill, and earning a number of related badges awarded mastery of a "track."11 Over time, we created tracks for supply-chain logistics, factory equipment operation, and, eventually, management, accounting, and more.
We then began offering these courses at cost online, and created an official policy within Amazon that allowed for hiring talent at all levels who had Amazon badges in place of, or in addition to, more traditional education credentials.12 We called it Amazon University.
Over time, we found badges to be nearly a prerequisite for hiring in many divisions of the company, and internal surveys demonstrated less and less interest in where or if the potential hire went to college, and more interest in completion of (and scores in) certain tracks.
Again, we offered these products at low prices because we were attempting to improve the pool of potential talent, and we succeeded. Over time, we also learned that other Silicon Valley businesses were using our badge system as a proxy for hiring and promotion, and that over the course of a few years more traditional firms, like General Electric, were doing so as well.13
While we considered lucrative licensing deals for these products, we were, as always, focused on creating lifelong loyal Amazon customers, and therefore continued to offer our educational services at cost and introduced many as free to Prime members.14 Over time, some schools and new nonprofits created wraparound services that included encouragement and a physical sense of community, which helped certain types of students who may not have otherwise completed badges to do exactly that, and we began expanding our physical classroom presence within or near our warehouses.15 We also decided early on to not participate in the federal aid system. A study of the system found the process cumbersome, confusing, and dissatisfying to customers; it also had tended to create bad incentives among institutions participating.16
We continue to be obsessed with the quality of our educational offerings, which is reflected in our students' enthusiasm and persistence. Of those students who completed one badge, 90 percent go on to complete a second, and 75 percent go on to complete a "track.".17 Of those who complete one track, 40 percent go on to complete a second.18 In surveys of customers, 95 percent believe that their badges helped them secure a job or salary increase and were worth the cost,19 while market research suggests that as many as half of major US employers now consider Amazon badges to be one of their top five criteria when determining whom to hire.
Over time we have heard from many customers — or, as we like to call them, alumni — who have told us how important their Amazon education has been to them, and asking how to give back. We tell them the single best thing they can do is to purchase shares in Amazon. Not only does this give the company more capital for us to invest in educational services and continue to offer them at cost, but it also broadens our pool of investors who share our core value of doing everything we can for the customer, thus helping prevent takeover attempts from those seeking short-term profits.20 We also suggest they volunteer their time to nonprofits that assist students and keep them on track in completing their Amazon badges.
Recently, due to customer demand, we have begun to explore offering some courses in the liberal arts and are already offering these courses at a subsidy to select Prime members. We are also investing a significant amount of money into artificial intelligence that could help reduce the need for human evaluators.
The future of Amazon University is strong as we continue to become the first truly global university. As our alumni network and reputation with customers and employers grow, we predict increasing demand for our services. We are excited about the future of a more educated, less indebted citizenry.
Jeffrey P. Bezos
Founder and Chief Executive Officer
Amazon.com, Inc.
April 2030
Alexander Holt is a policy analyst with the Education Policy Program at New America, where he conducts research on the economics of higher education.

Be sure to subscribe to Vox on YouTube for more explainer videos
A new study finds that sexism is rampant in the tech industry, with almost two-thirds of women reporting sexual harassment and nearly 90 percent reporting demeaning comments from male colleagues.
The study, called "Elephant in the Valley," surveyed 200 women who work at tech companies, including large companies like Google and Apple as well as startups. The study focused on women who had 10 years of experience in the industry, and most worked in Silicon Valley.
The project was inspired by former Reddit CEO Ellen Pao's failed gender discrimination suit against her former venture capital firm. Two co-authors of the study, former Yahoo executive Michele Madansky and Pao's former co-worker Trae Vassallo, said that after Pao's suit they started hearing an outpouring of stories from their peers about harassment and other problems.
"What we realized is that while many women shared similar workplace stories, most men were simply shocked and unaware of the issues facing women in the workplace," the report said. So the authors decided to go out and get some data. They asked women about their experiences in five main areas: feedback and promotion, inclusion, unconscious biases, motherhood, and harassment and safety.
The results were startling. Sixty percent of the women surveyed had experienced sexual harassment. (That's about twice as often as women report harassment overall.) The vast majority of the women surveyed said they'd had demeaning comments made to them by male colleagues, or that they'd witnessed sexist behavior at company offsites or industry conferences. Significant numbers of women also felt pressured based on their actual or perceived family choices, or even felt physically unsafe at work.

<!--
new pym.Parent('vox-women-tech-discrimination__graphic', '//apps.voxmedia.com/at/vox-women-tech-discrimination/', {xdomain: '.*\.voxmedia\.com'});
// -->

Some of the sexist incidents were subtle but still infuriating. "At Company X we had a joke that there were only two reviews for women — you are either too reticent or you are too bossy — no middle ground," said one respondent. Another woman, a venture capitalist, described a pitch meeting with her two male colleagues and a male founder: "Despite my background/skill set being clearly the most relevant, the founder didn't make eye contact, and didn't really listen to the questions I asked before answering." Another had male colleagues tell her that once women get pregnant they become "irrelevant."
Other examples were more egregious. One woman was groped by her boss at a company event, reported it, and had to leave the company after being retaliated against. Another had a client ask her to sit on his lap in exchange for buying her products.
Women in science, math, engineering, or technology have a hard time at just about every level of hiring for academic positions, due to the unconscious bias of those who do the hiring. There's overt sexism, like that awful peer reviewer who said women researchers should get help from men, and subtler forms, like how male researchers tend to choose fewer female trainees to work in their labs. And the STEM bias starts as early as grade school.
This usually isn't because people intentionally discriminate against women and girls. Harvard has a fascinating research project that tries to measure unconscious biases. You may believe with all your heart that women and men are equally capable at science or math, Harvard's researchers say, but your automatic associations may show otherwise. This explains how even a feminist science teacher who knows she is being observed can still give a disproportionate amount of talking time to the white male students in her classroom.
Pao argued in November that the low numbers of women in technology fields isn't just a "pipeline problem" caused by lack of interest among women. The problem is that women are treated badly at every level of entry to these fields. One study found that an uncivil workplace culture systematically pushes women out of engineering fields. While 20 percent of engineering graduates are women, just 11 percent of all engineers are women.
Pao also said that sexism in Silicon Valley is getting better — not really in the sense that men are doing less of it, but more that women and other marginalized groups are banding together to speak out and fight back against it. The culture of silence around these issues is starting to crack, and people are bringing consciousness to unconscious bias.
Conventional maps, by their nature, emphasize sheer spaciousness even though many large areas can be relatively devoid of human beings or other forms of activity. This cool diagram from HowMuch.net gives us a different way to visualize the entire US economy, depicting the whole thing as a big circle and then slicing it up by state, with each state's area representing its share of total economic output:
The basic news that California and Texas are really big shouldn't come as a huge shock. But you also see that Florida punches a bit below its weight in terms of population, in part because a large share of the state's residents are retired.
There are also disparities related to wealth. New Jersey has fewer people than North Carolina, Michigan, or Georgia, but it contributes more to the national economy since the productivity per worker in New Jersey is much higher.
At 10:59 pm Eastern time, the winning numbers in the Powerball lottery will be announced, with the current jackpot up to a record high of $1.5 billion after the past several drawings have failed to produce a winner.
Lottery jackpots have grown in recent years, with all 10 of the biggest nominal hauls coming since 2012 and inflation adjustments making little difference to the overall rankings.
Perhaps the most important thing to know about lotteries in the United States is that the winner of a $1.5 billion jackpot doesn't get $1.5 billion. Instead, what he or she gets is the choice between an annuity that pays out a total of $1.5 billion over the course of 30 years or a cash prize of $930 million right away. And that's before taxes. Depending on where the winner lives, he or she will actually end up getting around half of that.
Most winners choose the lump sum of cash, but most people who do so are making a poor financial decision. (In general, playing the lottery is a poor financial decision, so this is perhaps unsurprising.) As Josh Barro argues, the annuity benefits from what amounts to favorable tax treatment of investment income and will likely come out ahead of any reasonable conservative strategy you could take with your lump sum. A risky investment strategy might work well, but risky investment strategies are, well, risky, and lottery players do not have a great track record of managing risky investments.
Total spending on lotteries amounted to a shocking $70 billion in 2014, which amounts to about $300 per adult. As Derek Thompson wrote last year for the Atlantic, there is tremendous state-by-state variation in lottery spending, with Rhode Island and South Dakota spending huge sums on a per capita basis while North Dakota and Oklahoma spend relatively little.
The lottery is a famously regressive source of state government revenue, with the poor spending  a much larger share of their income on lottery tickets. But a 2003 study by economist Emily Oster suggests that massive lottery jackpots may be more egalitarian in their distributive impact. Oster found that the regressive nature of the lottery as a revenue source is driven by the downscale demographics of very frequent lottery players. When jackpots get bigger, more people are induced to play, and the regressivity diminishes — though it doesn't vanish.
Oster found that, hypothetically, a jackpot of about $806 million would likely be large enough to make the lottery progressive. At the time of her study, no jackpot of that level had ever been recorded, so the analysis was purely speculative. But now that we are actually well above the threshold she posited, future researchers could and should do follow-up analysis to see if rich jackpots really do lead to a more equal outcome.
On January 11, staffers of the New Republic learned via a note to the staff and a post on Medium that their beleaguered owner Chris Hughes had decided to sell the publication.
That announcement came a bit more than a year after a massive shake-up at the magazine, in which Hughes tried to replace top editors Franklin Foer and Leon Wieseltier with more digitally minded recruits, only to provoke mass resignations from then-current senior staffers and an immense backlash from the magazine's extensive network of alumni.
The general theme of these alumni takes was that Hughes had not only made a decision they disagreed with, but had also literally destroyed the publication. Jonathan Chait called his appreciation of the magazine's legacy a "eulogy," which was actually restrained compared with novelist Cynthia Ozick, who commemorated the change with an original poem alleging that "Thought and Word lay dead and cold" in the wake of Hughes's management.
This in turn provoked a counter-backlash from left-wing critics of TNR and its former owner Martin Peretz. "A publication that buoyed anti-black, anti-Latino, anti-Arab, Islamophobic racism was tolerable; a publication that fired two beloved white men was not," as Vox's Max Fisher put it, not so much in defense of Hughes as in incredulity over the scale of the anti-Hughes rhetoric.
SNORT RT @shani_o: So, is TNR going to become more diverse now or…?
The resulting fray was deeply confusing to many readers who are not professional journalists — and even to many journalists under the age of 30 — who couldn't quite understand why management turmoil at a single low-circulation publication could possibly be worthy of so many pixels and takes.
At a basic level, the sheer scale and clout of the TNR alumni network explains the level of attention it got. The magazine long served as an important incubator of talent, a place whose staffers would leave to become writers and editors at higher-circulation publications but who retained enormous affection for each other and the publication.
But at a larger level, "TNRmageddon" has attracted the intense interest of 30-something to 60-something politically minded journalists because the magazine and its woes stood — usually self-consciously so — at the intersection of a number of ideological and demographic trends that are profoundly shaping the broader political culture.
TNR stood for a certain model of publishing, but also for a certain model of liberalism whose viability is diminishing under strain from partisan polarization and increasing demands that an ideological movement whose political power comes mostly from women and minorities be represented in public by figures other than white men.
The world of Washington, DC-based magazines and websites is incredibly incestuous, so I have no way of writing about this without stepping all over too many conflicts of interest to count.
But some noteworthy ones include the fact that I applied for a job with the Peter Beinart–era TNR and didn't get it after a disastrous job interview. I was recruited for jobs in both the first and second Foer eras. I used to work closely with Richard Just (who was editor between Foer stints) before he worked at TNR. I dated a TNR staffer for a while, was roommates with Spencer Ackerman at the time Foer fired him from TNR, and am very close friends with a current staffer at TNR. I also lived in the same dorm with Hughes for a year in college.
All of which is to say that while my coverage of this can hardly be objective, it's also pretty well-informed.
The small-minded literal answer is that both Foer and Wieseltier are very well-liked and well-connected in the journalistic and literary worlds, and when they got fired they deployed their connections to torch Hughes.
The broader, more important, reason is that the New Republic has long been at the center of profound arguments over the direction of American liberalism. It was founded in 1914 by Herbert Croly, Walter Lippmann, and Walter Weyl with financing from Willard Straight and Dorothy Payne Whitney, and it's really only a slight exaggeration to say that the magazine's ideological program laid the foundation for what we now know as the ideology of modern liberalism.
Croly sought a synthesis of the political traditions of Thomas Jefferson and Alexander Hamilton, promoting the view that Hamiltonian means (an active state and a strong central government) were necessary to promote Jeffersonian ends (small-d democracy and an egalitarian economy) under the conditions of modern industrial life. Many of the specific policy views of the Croly-era New Republic would be unrecognizable to the liberalism of a century later, but those broad themes are very evident today and even the subject of a hit musical.
In the 1940s, '50s, and '60s TNR was involved in the struggle to define liberalism's relationship to the Cold War. In the mid-1970s, the magazine was bought by Martin Peretz, who used it to once again try to chart an ideological agenda for liberalism. Under Peretz, the magazine stood for a hawkish, fervently pro-Israel form of liberalism that, while fairly conventional in its domestic politics, was always on the lookout for excessive left-wing deviationism. It sought controversy and made enemies — though it also left a broad network of friends scattered throughout prestige media in the United States.
But by the mid-aughts, Peretz and the magazine were in a state of financial distress; the magazine suffered a series of rounds of budget cuts and was taken over by an unstable set of investors backing Peretz. In 2012, Chris Hughes bought the magazine, provided a much-needed infusion of cash, brought back beloved former editor Frank Foer, and invested in some marquee journalists and new office space.
He was, briefly, hailed as a savior of the magazine. And then it all went wrong.
TNRmageddon has come to be at the nexus of a wide range of ideological conflicts, but on the most literal level it was about something else entirely. Simply put, from day one Hughes had always wanted to own a version of the New Republic that would be a relevant digital brand in the contemporary world, and Foer was always an editor with a print-first mentality and a deep loyalty to a core group of writers who felt they did their best work at a considerably more leisurely pace than you find at most websites.
This was not primarily a disagreement about ideology, or even one about commercial versus noncommercial values. A number of noncommercial publications — including Mother Jones on the left and National Review on the right — have successfully built large and influential digital operations on the backs of old-time print brands. Commercial publications like the Atlantic and New York magazine have done the same.
Conversely, there are both commercial (the New Yorker) and noncommercial (N+1) publications that have deliberately chosen to march into 2016 still offering a distinctly analog mentality.
The original sin of Foer and Hughes's relationship was that they simply didn't see eye to eye on this.
Hughes is a millennial, a digital native who made his fortune in Facebook stock. To him it is natural that to be a force in the media world means to be a digital force. Foer is older, but more importantly he is a proud neo-traditionalist who thinks Amazon is destroying literary culture, and during both of his editorships he treated digital work as less important than the job of editing the print magazine.
There's nothing wrong with either of these approaches, but the Hughes-Foer TNR renaissance was fundamentally an exercise in mutual deception and self-deception. Hughes brought back Foer in order to gain the prestige and cachet that would come with the acclamation of the TNR alumni network, even though he had no real affection for the kind of journalism Foer values; Foer told Hughes what he wanted to hear in order to get the funding for the magazine of his dreams, even though he had no real affection for the kind of digital publication that Hughes wanted.
When the deception became untenable, Hughes massively mishandled the aftermath. Rather than arranging an amicable parting of ways, he brought in a new CEO, Guy Vidra, with experience at Yahoo who, as Ryan Lizza recounts, "spoke in a Silicon Valley-inflected jargon that many of T.N.R.’s journalists found grating and bewildering."
Foer himself discovered that Hughes wanted to replace him with a new editor through leaks rather than a face-to-face conversation. (This method of firing, while appallingly rude, is actually itself a bit of a TNR tradition, as former editor Charles Lane apparently learned he'd been replaced by Beinart from a Washington Post column rather than from Peretz.)
In large part as a result of his own mishandling of the situation, Hughes wound up losing more than a couple of top editors: An enormous fraction of the magazine's staff — including relatively new Hughes-era hires like Julia Ioffe — resigned en masse.
Rather than break up politely citing irreconcilable differences over digital-first versus print-first editorial strategies, the TNR quitters and their allies in the old guard developed a curious alternate history of the New Republic over the past generation.
In this view, TNR was not a perennially money-losing ego project through which Peretz subsidized a prestigious journalism operation in order to lend a sheen of respectability and influence to his own crank view. It was, instead, a "public trust" that had been owned by wise stewards who, in the words of former TNR senior editor John Judis, had "devoted themselves to philanthropy and to what they understood as the public interest." In contrast, Judis wrote, Hughes's "commitment to social responsibility turned out to be skin-deep."
In this retconning of New Republic history, both Peretz's rancid political views and his mercurial hiring and firing of not-always-obviously-qualified editors vanished down the memory hole. After all, if one acknowledges that Peretz had treated the magazine as his personal property (which, after all, it was), then one would have to acknowledge that Hughes was just as entitled to be fickle as his predecessor.
In fact, the owner who fit Judis's description was not Peretz but Hughes, who, unlike Peretz, is deeply involved in philanthropic pursuits (for example, giving cash grants to desperately poor people in rural East Africa) and does not fancy himself a writer or crave his own byline.
What neither side of the dispute really wants to forthrightly acknowledge is the likely connection between Hughes's shifting view of his investment in the New Republic and his husband's failure to win a congressional seat in the 2014 midterms. Hughes was willing to spend generously on Eldridge's political career, outspending Eldridge's opponent 3 to 1 in a district Barack Obama carried in 2012 and contributing ancillary spending on real estate and local charitable endeavors to grease the wheels for Eldridge's run.
In a world where Hughes and Eldridge were a young political power couple, making an open-ended financial commitment to a Washington-based prestige journalism operation made a lot of sense. It was something Hughes could do with his time and money that wouldn't enmesh him in ethical conflicts of interest, and it would allow Eldridge to punch greatly above his weight as a backbench member of the minority party.
With Eldridge's political career in shambles and the couple reevaluating their priorities, the calculus obviously looks different. For Peretz, one major virtue of owning TNR was that it afforded him an opportunity to grind his favored ideological axes. In 2016, any rich guy who wants to gain attention with ideological ax grinding can do it for free on Twitter or Medium. And Hughes doesn't even appear to have any particularly interesting axes to grind. So what's the point?
The result of this, it seems, was that Hughes's willingness to absorb the losses necessary to run the New Republic dimmed. In his announcement that he was putting the magazine up for sale, he said he's invested $20 million in the institution just in the short time he's owned it, and the implication is he's no longer willing to lose that kind of money indefinitely. To many of his critics, that is the core of his betrayal — by purchasing the magazine in the first place, he was committing himself to bearing its attendant losses, perhaps not indefinitely, but certainly for longer than a few years.
Once the anti-Hughes takes started flying from the TNR old guard, the magazine's owner was clearly in need of allies and swiftly found himself making an alliance of convenience with a group of longtime TNR critics who didn't appreciate the magazine's approach to foreign policy and, especially, race.
Arguments about Peretz-era TNR's content have raged for years and will continue to do so. But one fact that seems essentially indisputable is that Peretz-era TNR was well-known as an incubator of journalistic talent, and the talent that was incubated there was essentially all white and very largely male — unapologetically so, as one of the magazine's main ideological heterodoxies was opposition to affirmative action.
Consequently, as Ta-Nehisi Coates put it during the December 2014 meltdown, "the family rows at TNR's virtual funeral look like the 'Whites Only' section of a Jim Crow-era movie-house."
This critique of TNR and race dovetailed nicely with liberals' longstanding critique of the New Republic's hawkish foreign policy, which was ostensibly animated by high-minded idealism but often seemed grounded in Peretz's crude anti-Arab racism.
If Hughes had been genuinely bothered by these longstanding concerns, he presumably wouldn't have bought the magazine to begin with. But once on the offensive, he and new editor Gabriel Snyder decided to go to war with the allies they had and join the pile-on. Version 2.0 of the Hughes-era TNR featured a much more diverse set of hires, and kicked off with a Jeet Heer feature criticizing TNR's historical record on race.
Foer's allies then mounted a backlash to the backlash, which mostly went to show how real the ideological differences between the magazine's new hires and its ex-staffers had become:
Am excited to see if the new @tnr can write about anything other than identity politics. Like, you know, the rest of the world.
Perhaps the central irony of TNRmageddon is that the scorched earth tactics Foer's allies in the old guard have deployed have fundamentally imperiled the viability of the magazine and its legacy.
After all, the one thing TNR has going for it is the idea of cultural prestige — a bank of influence and importance that long predates the Peretz era and that managed to survive several ownership transitions and many firings of many editors. The mass campaign of op-eds, interviews, and takes proclaiming the death of the New Republic served to massively undermine that prestige.
This succeeded in hurting Hughes's personal standing in society as well as his financial interests, but fundamentally Hughes is still going to be a rich guy living a decent life.
What it also did was massively undermine Hughes's interest in indefinitely subsidizing a prestige journalism play that was no longer bringing him prestige. Worse, it probably undermined anyone else's interest in taking on the burdens of owning TNR.
This is in part a question of money, but in a larger sense it's about risks to reputation. Virtually any other monetary investment in journalism would be less likely to invite loud public second-guessing. The Peretz-era alumni network went after Hughes so viciously that they've made it much less likely anything vibrant will ever thrive under the TNR brand.
The good news for people who enjoy small-circulation, ideas-focused magazines is that, TNR's struggles aside, this genre of publication is thriving perhaps as never before. It's true that niche publishing is an awkward fit for the commercial logic of the internet, where scale rules all. But it's also true that this sort of publication has never been a truly commercial endeavor, whether formally organized as a nonprofit or not. Digital technology, by drastically reducing the cost of publishing and distributing articles, has served to drastically increase the bang for your buck involved in financing such publications.
Consequently, there's been a blossoming of new ideas-focused small publications like New Inquiry, N+1, and Jacobin, joined by a revived version of the Baffler often espousing left-wing ideas well out of the mainstream of the commercial press. The right has its own high-quality journals — of which National Affairs is probably the best — while Democracy holds the torch for a more conventional form of liberalism.
When I entered journalism there were three places I badly wanted to work: The American Prospect, the Washington Monthly, and the New Republic. The decision turned out to be easy: TNR never called me back. The Washington Monthly didn't have entry-level positions. But I got lucky: The Prospect took me on as a writing fellow, and it turned out to be a dream job.
Ten years later, the Prospect, the Monthly, and TNR are all in crisis. The Prospect laid off much of its staff and is retrenching to its roots as a policy journal. The Washington Monthly has downsized to a bimonthly. The New Republic was bought by Facebook-founder Chris Hughes only to become a cautionary tale when Hughes ineptly fired its editor Frank Foer — a move that caused massive staff resignations and a devastating backlash from the TNR-veterans laced throughout the rest of the media.
Now Hughes is putting the magazine back up for sale.
"I will be the first to admit that when I took on this challenge nearly four years ago, I underestimated the difficulty of transitioning an old and traditional institution into a digital media company in today's quickly evolving climate," Hughes wrote in an article that, oddly, was published on Medium rather than the New Republic's web site.
TNR's problems have been largely being laid at Hughes's doorstep. And, to some degree, that's fair. Transitioning an old and traditional institution into a digital media company is hard, but it's not as hard as Hughes made it look.
Marty Peretz, who owned the New Republic from 1974 to 2002, fired a slew of editors without causing mass resignations among the staff (though, as my colleague Max Fisher has written, the contrast between the indulgence of Peretz's racism and the backlash to Hughes does not reflect well on TNR, or journalism more broadly.). And plenty of other venerable institutions — the Atlantic, the Washington Post, the New York Times, National Geographic, etc — have made the leap to digital without TNR-ian tumult.
What happened at the New Republic was a colossal management failure compounded by cultural tensions between the journalism and technology worlds, and it was the job of Hughes, and those he hired, to make sure that didn't happen.
But, to reprise an argument I made amidst TNR's 2014 crisis, there's a deeper story here too. The New Republic was sold to Hughes in the first place because the institution was bleeding so much money that Peretz, its previous owner, couldn't sustain it. And Hughes's alarm over the magazine's future — the alarm that led him to bring in Guy Vidra, an ex-Yahoo executive, to lead the institution, and that convinced him he needed to fire Foer — was based on watching the magazine's influence wane, its traffic lag behind competitors, and its business prospects dim.
Behind the crisis caused by Hughes's management, in other words, was the crisis that led to Hughes's management.

The American Prospect.
TNR.com might flourish under its next owner. But it won't be what the New Republic was. And that's because the thing the New Republic was has already died. The eulogy that needs to be written isn't for the New Republic. It's for the New Republic and The American Prospect and the Washington Monthly and their peers. It's for the role once played by Washington's small fleet of ambitious policy magazines.
This sprawling conversation over Washington policymaking used to be centered in a handful of elite-focused policy magazines, of which the New Republic was perhaps the best known and most ambitious. There was policy reporting in the newspapers, of course, but it didn't go as deep, and it was crippled by the faux-evenhandedness that is death to any serious conversation over solutions. There were the journals, like The Public Interest, but they came out more rarely, and their tone was often staid and impenetrable.
The policy magazines had a number of unique characteristics, but two were central. The first was what they covered — which was, for the most part, politics through the lens of policy (though the New Republic, in particular, had an amazing culture section).
Policy — wrongly, in my view — was broadly considered a boring topic in journalism, and so if you wanted to keep large masses of readers engaged, you couldn't do too much of it, too often. But these magazines could, because they weren't trying to keep large masses of readers engaged. They were niche products comfortable with small, enthusiastic audiences. They were by people who loved writing about policy and for people who loved reading about policy, and that allowed them to serve their audience in a way mass-market publications couldn't touch.
The second was the angle that animated their coverage. The American Prospect was labor-liberalism. The Washington Monthly was technocratic neoliberalism. The New Republic oscillated from editor to editor, but tended towards a hawkish, contrarian neoliberalism (hence the "Even the liberal New Republic" meme). The Nation, which is based in New York, and Mother Jones, which is based in San Francisco, were a bit less policy-oriented, but a lot more liberal.
On the right, you had (and still have) the National Review, which tended towards conservative fusionism. The Public Interest was the birthplace of neoconservatism, and that mantle was later taken on by the Weekly Standard. (The most interesting policy publication on the right at the moment is Yuval Levin's reformist-inclined journal National Affairs.)
These magazines, in other words, stood for something. That set them apart from newspapers and general-interest magazines, which were carefully neutral in ways that made their coverage both less vibrant and less clear. It's very, very hard to cover policy topics well if you can't, at the end, say which solutions you think most promising.
People often talk about the problems of the transition to digital in broad terms, but for policy magazines, the transition to digital created specific problems: namely, the qualities that once set organizations like the New Republic apart were adopted by their bigger, richer competitors.

Wha'cha reading? (JEWEL SAMAD/AFP/Getty Images)
To the wonk in the 1970s, '80s, and '90s, these magazines were the thrumming center of the policy conversation in Washington. That's why it was believable that the New Republic was the "in-flight reading on Air Force One." President Bill Clinton was a policy wonk. What else was he going to read?
But they're no longer the center of the policy conversation in Washington. That conversation has spilled online, beyond their pages, outside their borders. The in-flight reading on Air Force One is probably saved to President Obama's iPad.
And he has much to choose from. The internet is now thick with outlets that pride themselves on covering Washington's vast policymaking apparatus in much the way the policy magazines once did, and often with staff culled from those same policy magazines.
Vox is one of those outlets, as is the New Republic, but so are the Washington Post's Wonkblog, the New York Times' Upshot, Politico, Bloomberg View, and FiveThirtyEight, to name just a few. Many of these publications are attached to bigger institutions that would never have published so much policy, or allowed such conclusions-driven coverage, in their print products.
And that doesn't even include the individual bloggers who are must-reads if you're following policy: Kevin Drum, and Tyler Cowen, and Brad DeLong, and Paul Krugman, and Ross Douthat, and Ramesh Ponnuru, and Jonathan Chait, and Scott Sumner, and Megan McArdle, and Jonathan Bernstein, and, again, the list goes on. At another time, most of these names would be published inside policy magazines. Now they're either employed by bigger institutions or forging ahead on their own blogs, supported by foundations, advertising, and speaking fees.
The other problem is on the business side. Hughes believed his charge was to make TNR a viable web publication, in a world where viability — and, arguably, influence — requires web traffic. That meant publishing more, publishing faster, and publishing the kinds of quick hits and aggregations that help build audience on the cheap.
In a strange sentence on his Medium post, Hughes writes, "Even though our search for a workable business model has come up short, we have shown that digital journalism isn't at odds with quality and depth." But if digital journalism of quality and depth is at odds with a workable business model, then digital journalism of quality and depth won't survive.
This was, according to many accounts, the central tension between Hughes and Foer: Hughes wanted to solve TNR's business problems in part by increasing the size of its audience, which meant it had to to become more like its audience-hungry competitors. But many at TNR felt Hughes had promised to preserve the TNR of yore, even if it lost money indefinitely — as it had in the past. To them, forcing TNR into a fight for audience was forcing it into a fight that would destroy what made it unique even as it failed to create a model on which TNR could thrive.
The New Republic, for better and for worse, has stood for less in recent years. So too do its competitors, who sound a bit more like everyone else and a bit less like themselves.
This isn't a criticism of Foer, who led TNR to publish great journalism. And nor is it a criticism of Snyder, who pushed the magazine in new and interesting directions. But the TNR that stood for so much routinely saw subscriber numbers of 100,000 or less. It would never fulfill its publisher's hopes of acquiring tens of millions of monthly digital readers.
Behind this fight is a deeper tension in digital journalism: The pressure for convergence is strong
Behind this fight is a deeper tension in digital journalism: The pressure for convergence is strong. We feel it at Vox, and sometimes give into it. It's easy to see which stories are resonating with readers. It's obvious that John Oliver videos do big numbers. And that's fine. Right now, almost all successful digital publications are partially built on internet best practices and partially built on that publication's particular obsessions, ideas, and attitude. Digital publications need to be smart about their mix of what everyone else does and what no one else does.
But what made the New Republic and its peer policy magazines so great was how restlessly, relentlessly idiosyncratic they were — that's how they drove new ideologies and new ideas to the fore. They were worse at covering policy than their digital successors because they were slower and more distant from the news cycle, but they were probably better at thinking.
Part of this was because they simply cared less what the audience thought — they saw their role as telling their audience what to think, and they expected a readership in the low six or high five figures, not the mid-eight figures. That gave them a freedom to truly be themselves that more mass-market publications don't have.
As someone who really loathed a number of TNR's previous eras (see the Bell Curve, or No Exit, or A Fighting Faith, or much of what Hughes's predecessor Marty Peretz wrote, for examples), I'm probably a bit less nostalgic for its past. But something is being lost in the transition from policy magazines to policy web sites, and it's still an open question how much of it can be regained.
For TNR, however, the problem is more specific. There's so much expectation and history attached to the publication that its room for strategic movement is limited — as Chris Hughes found out. But an owner who wants to buy and support the TNR of yesteryear is buying into a market that makes it much harder for the TNR of yesteryear to thrive.
Related: How the American Prospect changed policy journalism.
Correction: This article initially said Marty Peretz was Hughes's predecessor as owner of the New Republic. Peretz owned the magazine from 1974 to 2002, when he sold majority control to Michael Steinhardt and Roger Hertog. Peretz bought back the magazine later in the decade, and stepped down as editor-in-chief in 2011.
Inequality is perhaps my favorite interview topic in Silicon Valley: It's fascinating to watch ordinarily confident titans of industry squirm in their seats before offering a conspicuously measured response. But occasionally a leader in the community breaks an unspoken rule by being brutally honest in public.
The tech world encountered one of these deliciously informative moments earlier this week, when a well-known startup investor and mentor, Paul Graham, admitted that he was personally (and unabashedly) responsible for rising inequality.
"I've become an expert on how to increase economic inequality, and I've spent the past decade working hard to do it," Graham wrote. "Eliminating great variations in wealth would mean eliminating startups."
In response, friends carefully avoided denouncing Graham or his core beliefs, but disagreed with his approach.
"Yes, income inequality exists and yes it’s a natural consequence of capitalism and other forms of government are decidedly worse than capitalism because they inefficiently create and allocate resources," wrote fellow investor Mark Suster. "But the celebratory nature of today’s conversation felt tone deaf."
Of course, it’s hard to know whether a handful of blog posts really represent the views of Graham's fellow technology moguls. The plural of anecdote is not data. But for the past five years, I've been systematically collecting data on what Silicon Valley believes through interviews with CEOs, including Graham's colleagues in the startup world.
After dozens of interviews with new and big-name tech startup founders, I designed a structured battery of political and philosophical questions and randomly selected people from an exhaustive database of funded companies (more details on the methods here).
What emerged from my interviews and survey results was a set of views that are somewhat more nuanced than Graham’s, but also in agreement with his fundamental view of the world. Founders believe that equality of opportunity is crucial to a fair and healthy economy, while equality of outcome is economically paralyzing.
They believe that a relatively small slice of geniuses advance humanity more than the combined efforts of everyone else, and that economic growth is better at improving the overall quality of life than burdensome redistribution schemes.
And many believe that the best long-term solution to inequality may be a guaranteed basic minimum income, which minimizes regulation on innovation but ensures that the masses are well-off.
It’s little surprise that a group of people who grew wealthy building successful businesses have a positive view of the economic system that made that success possible. And they see more growth as the solution to broader social problems.
"If we have 4 percent a year of GDP growth, all these problems would get solved," PayPal billionaire Peter Thiel told me when I quizzed him about inequality.
A plurality of founders agree: Among 33 founders I surveyed, 48 percent said that mediocre growth was more problematic than financial inequality, while 42 percent believed the opposite. Among the general population (as represented by 595 people polled on SurveyMonkey), 59 percent of people believe inequality is more important.
Silicon Valley is an optimistic crowd. In my survey, 80 percent of the 129 startup founders I surveyed told me "almost all change is good over the long run," compared with just 48 percent of the general public.
And it’s not as though Valley folks are tone deaf to the problems of inequality. I asked tech founders and members of the public to tell me which of four goals is the best way to improve the world: reducing inequality, addressing threats to national security, reducing government intervention, or getting citizens more active.
Interestingly, founders were more likely than the general public to choose inequality as their top issue (37 percent to 32 percent). They were less likely to say that cutting government (47 percent to 38 percent) or beefing up national security (17 percent to 9 percent) was of paramount importance.
But the biggest difference was on citizen involvement. Twenty-four percent of startup founders saw that as the most important issue, compared with just 11 percent of the general public. Founders have a unique optimism that having an active and informed citizenry can make the world a better place.
So far, this might give you the impression that startup founders have garden-variety liberal politics. And it’s true that many Silicon Valley moguls lean to the left. But there’s one big way that Silicon Valley’s elite see the world differently than a lot of others on the political left.
For tech CEOs, the most comfortable response to the growing economic gap is to support "equality of opportunity, not equality of outcome." At some point in my research process, I got tired of hearing this response. Who isn’t in favor of equal opportunity? But over time I came to realize that Silicon Valley elites view issues of opportunity and accomplishment differently than most people.
Toward the end of my research, I asked tech CEOs to tell me how equal or unequal an economy would be in a perfectly meritocratic society where everyone's income was precisely proportional to their productivity. I asked this question of 14 tech founders (including one billionaire), and all predicted that a meritocracy would lead to a very unequal economy. Most said that the top 10 percent of talent would naturally earn more than 50 percent of the nation's wealth.
"An uninspired population is a stagnant population. Inequality breeds creativity, and fosters motivation to change one's situation," wrote Byron Morgan, founder of the music startup Vinylmint. "Mass change starts with one person inspiring another."
This is perhaps a more artful way to articulate the point Graham was trying to make when he wrote, "Most people who get rich tend to be fairly driven. Whatever their other flaws, laziness is usually not one of them."
The idea that workers have radically different levels of productivity is so commonplace in the Bay Area that Red Bull even referenced it in an ad, cheekily suggesting that drinking its product would transform a 10Xer — someone who was 10 times as productive as the average programmer — into a hyperproductive 100Xer.
This also helps explain Silicon Valley's continued obsession with Massive Open Online Courses, which have been repeatedly shown to be much worse for low-income students. In a moment of rare honesty, MIT's Andrew McAfee told a crowd in San Francisco that MOOCs' actual promise is to be "diamond finders" — large nets that give opportunity to the rare geniuses born into poor circumstances.
"Very few are contributing enormous amounts to the greater good, be it by starting important companies or leading important causes," one of my survey respondents wrote.
During a Twitter discussion of Graham's essay, one billionaire pointed me toward an essay that Graham's colleague, Sam Altman, had penned on the same subject. It's a more compassionate version of the same arguments, and Altman floats an idea that is increasingly popular among his elite friends: a basic minimum income, paid for by heavily taxing the rich.
If not everyone can contribute to the economy, the best-case scenario is to just subsidize the entire world with a respectable quality of life (what is lovingly known as "automated luxury communism"). In the kind of healthy, fast-growing economy Thiel and others envision, the economic pie would be growing quickly and there would be plenty of wealth to go around.
But fundamentally, Paul Graham is not much of an outlier among Silicon Valley’s elites when it comes to the relationship between ability and financial rewards. Most successful technology moguls know better than to be as blunt as Graham, but deep down a lot of them believe that a small minority — like them — create a hugely disproportionate share of the world’s wealth.
December's job growth numbers are in, and they make it official: 2015 was the second-strongest year for job growth since the 1990s, and only slightly behind the big gains of 2014. Unemployment fell in 2015 from an already low 5.6 percent at the end of 2014 to 5 percent in December 2015. Wages grew 2.5 percent during 2015, which isn't a huge number but looks more impressive when you remember that inflation was close to zero for the year.
So what accounts for the second straight year of strong economic results? The US economy is a complex system, so it would be a mistake to point to any single factor as driving economic growth and job creation. No one fully understands how and why economies grow. And to some extent, you could look at 2015's solid but not spectacular performance as the kind of thing that happens when there's nothing holding the economy back.
But we can also identify several specific factors that positively influenced economic growth in 2015.
Chung Sung-Jun / Getty Images News
Short-term interest rates fell to zero percent in 2008, and the Federal Reserve kept them there until December 2015. Lower interest rates tend to promote economic growth and job creation. Some people believe the Fed should have done even more — earlier in the recession the Fed ran a series of "quantitative easing" programs to pump even more money into the economy, which it phased out in 2014 — but there's little doubt that the Fed's decision to keep interest rates near zero percent for most of the year promoted faster job growth than an earlier interest rate hike would have done.
In December, the Federal Reserve raised its target interest rate by 0.25 percent, and signaled that it may increase rates further in 2016. That may create a drag on the economy this year.
Oil prices were high — around $100 per barrel from 2011 until mid-2014. But then prices started to fall, and they haven't stopped since. They were around $50 per barrel when 2015 began, and they've now fallen below $35 per barrel.
Energy is an important input to lots of different products and services, so cheaper oil (and other fossil fuels like natural gas) meant that everyone not associated with the oil industry had a bit of extra cash in their pockets in 2015.
It's hard to say exactly where that extra cash went — at least some of it went to boost people's savings and pay down debt — but consumers also spent some of it on other stuff. That provided a nice economic tailwind throughout 2015.
Since the Great Recession, state and local governments have been tightening their belts. Early in the recession, this added to the magnitude of job losses; later, it partially offset job gains in the private sector.
But as this data from the Brookings Institution shows, things started to change in mid-2014. After years of shedding employees, state and local governments started hiring again.
Overall, Brookings estimates that federal, state, and local government spending and tax policies exerted a modestly positive effect on the growth of gross domestic product — that's after four years of spending cuts and tax hikes that Brookings argues imposed a net fiscal drag on economic growth.
At 10:59 pm Eastern on Saturday, January 9, there will be a Powerball lottery drawing for an estimated $800 million jackpot.
That's the biggest jackpot in history, even when adjusted for inflation.
Lottery jackpots have grown in recent years, with all 10 of the biggest nominal hauls coming since 2012 and inflation adjustments making little difference to the overall rankings.
But by design these jackpots are small in comparison to the amount of cash Americans spend on lottery tickets. Total spending on lotteries amounted to a shocking $70 billion in 2014, which amounts to about $300 per adult.
As Derek Thompson wrote last year for the Atlantic, there is a tremendous quantity of state-by-state variation in lottery spending, with Rhode Island and South Dakota spending tremendous sums on a per capita basis while North Dakota and Oklahoma spend relatively little:
About 40 percent of lottery revenue is sent to states (often nominally earmarked for schools, but in practice money is fungible), and then winnings are subject to a hefty 45 percent windfall income tax, so the lottery is a major moneymaker for the government. In terms of revenue sources it's one of the most regressive out there, with the poor buying a vastly disproportionate share of lottery tickets.
But a 2003 study by economist Emily Oster suggests that massive lottery jackpots may be more egalitarian in their distributive impact. Oster found that the regressive nature of the lottery as a revenue source is driven by the downscale demographics of very frequent lottery players. When jackpots get bigger, more people are induced to play, and the regressivity diminishes — though it doesn't vanish.
Oster found that, hypothetically, a jackpot of about $806 million would likely be large enough to make the lottery progressive. Even this weekend's record jackpot won't quite reach that level, but it's extremely close. And if there is no winner on Saturday, it's possible we'll have America's first distributionally progressive lottery.
Apple is currently the world's largest company by market capitalization. But the Kingdom of Saudi Arabia is seriously considering creating a much larger company — by staging an initial public offering (IPO) for shares in its state-owned oil company, Saudi Aramco.
Rumors of a potential IPO flew on Thursday following a statement by the kingdom's deputy crown prince, Mohammed bin Salman, and confirmed by a terse statement from Aramco headquarters Friday morning.
It's impossible to know how much Aramco would be worth on the private market if sold, especially without details regarding the terms under which it might be privatized. But based on the scope of Aramco's operations and the values of other oil companies, it seems likely that it would achieve a market capitalization of more than $1 trillion — far ahead of any American company.
The company currently known as Saudi Aramco has its roots in an exclusive concession to explore for oil in Saudi Arabia that the kingdom granted to Standard Oil of California (now Chevron) way back in 1933.
This concession was operated by a subsidiary called the California-Arabian Standard Oil Company, and it became a joint venture with Texaco in 1936. In 1944, both Standard Oil of New Jersey (which later became Exxon) and Socony-Vacuum (which later became Mobil and then merged with Exxon) joined the consortium — which was named Arabian-American Oil Company, or Aramco.
In essence, all of America's major oil companies were working together to exploit a monopoly on Saudi oil.
In 1950, Saudi King Abdullah threatened to nationalize the oil company — a way to get Aramco to agree to a deal in which 50 percent of profits would be handed over to the Saudi government. In response, the US Congress instituted a tax credit known as the "golden gimmick" that ensured all of Abdullah's money would come out of Uncle Sam's tax haul rather than out of the pockets of Aramco shareholders.
This arrangement didn't last long. By the 1970s, with anti-Western sentiment and Arab nationalism running high in the Middle East, the Saudis decided to nationalize anyway. Except instead of doing a full expropriation, the Saudis did a gentler takeover, using oil revenue to buy Aramco from its parent companies.
As recounted by Charles McPherson in his comparative study of oil nationalization schemes, "The Saudi approach to nationalization was very different than that of other countries" — not only in the financial terms under which it was done but in how the company was operated after nationalization.
By 1980, McPherson writes, Saudi Arabia was the sole owner of Aramco, but "under strict instructions from the King, the new Aramco [was] left very much to itself on operational matters" and "many of the Aramco companies continued as advisors to Saudi Aramco ensuring continuity of management." So the company was nationalized, but US-based oil companies got all its money and were still running the company operationally.
That deal came more than a generation ago. In the subsequent 35 years, the Saudi government has been able to use its control of Aramco to move the corporate headquarters from New York to Saudi Arabia and to fill more and more jobs with Saudi natives. As of 2015, it really operates like a state-run company, seeking revenue but more broadly pursuing the Saudi government's policy objectives.
Having gone through the literally decades-long slog of nationalizing the world's most valuable oil company in a non-disruptive way that preserved the country's positive relationship with the United States and major private oil companies, why would Saudi Arabia consider turning around and re-privatizing?
The starting point for understanding is that Prince Salman told the Economist he wants to list a minority stake in Aramco — perhaps 5 percent — while leaving control firmly in government hands.
It is not entirely clear what this would accomplish. In follow-up reporting, the Economist suggested that the issue may involve concerns about Aramco's current management practices:
Questions surround the company, though. Mr DeLucia says 87% of its output is oil; it needs to develop more gas to satisfy the country’s needs for cleaner, cheaper power. Some argue that its reserves, which have barely budged since the late 1980s, are overstated. Internal documents about them are "phenomenally closely guarded secrets" says a local observer.
The company does not report its revenues. Its fleet of eight jets, including four Boeing 737s, and a string of football stadiums suggest that it is not run on purely commercial lines. It is the government’s project manager of choice even for non-oil developments, and runs a hospital system for 360,000 people. A listing would require it to become more transparent.
The Economist analogized the situation to concerns about state-owned oil companies in Mexico and Brazil that have been accused of corruption and mismanagement, in response to which the Mexican government has begun to open things up to foreign investors — an idea that conservative politicians in Brazil have also proposed.
But Mexico and Brazil are democracies with free media and judicial systems where the transparency induced by a listing would operate as a lever for change. Saudi Arabia is a closed autocracy with a controlled media, so it's not clear through what mechanism transparency per se could shift management. Aramco presumably operates football stadiums and a hospital system because that's what the Saudi government wants it to do — selling a minority stake that leaves all control in the hands of the Saudi government wouldn't really change anything.
One way to understand the Aramco IPO talk is probably through the same lens that has to be used to understand all of the Saudi government's other recent decision-making: fear.
The Saudis are beset by problems ranging from the low price of oil to Iran's regional activism to the rise of ISIS. A successful flotation of a minority stake in ARAMCO would generate a good news story about Saudi Arabia. Aramco would be the world's largest company by market capitalization, and the Saudi stock exchange would suddenly be a big deal.
Partial privatization would serve as a token of change and reform in a country that is often seen in the West as excessively hostile to change and reform. It would also give a new generation of Saudi leadership a chance to put their personal stamp on things — not the best reason for taking dramatic action but at least a reason.
Perhaps most fundamentally, as Jennifer Williams has explained, one thing the Saudis fear is "abandonment by the United States in favor of Iran, or even just US disengagement from the region in general, thus depriving Saudi Arabia of its great power protector."
Giving Western investors a concrete financial stake in the Saudi national oil company would serve as a way to deepen and broaden the coalition of stakeholders in the kingdom's stability. The US-Saudi alliance is about much more than oil, but oil was its ground floor, and bringing foreign investors back into the Saudi oil business could be a way to strengthen its foundation.
The US economy created new jobs at an unexpectedly strong pace in December. There was a net increase of 292,000 jobs in the month, according to figures released today by the Bureau of Labor Statistics. Economists were expecting the economy to add about 200,000, in line with the average pace during 2015.
Even better, BLS says that last month's jobs report had undercounted the number of jobs created in October and November by a total of 50,000. That means the economy was creating jobs at an unexpectedly strong pace throughout the last quarter of 2015. The economy created 2.7 million jobs in all of 2015, a strong result but a bit weaker than the 3.1 million jobs created in 2014.

These results confirm that the economy has finally entered the kind of robust economic growth that seemed so elusive for the first few years after the 2008 financial crisis. The unemployment rate stayed at 5 percent, where it has been for the past couple of months:
Yet there are also signs in the report that the economy still has some room to grow. One is the labor force participation rate:
The fraction of the population that is employed has been declining since the last recession began in 2007. That's largely due to long-term demographic forces — people are living longer, staying in school longer, and so forth — but we should still expect a strong economic boom to pull some people back into the labor force. That hasn't happened yet.
The other sign that the economy is strong but could still be stronger is earnings. The average worker's hourly earnings rose by 2.5 percent — just slightly faster than the (currently quite low) rate of inflation. In a really strong economic boom — the kind we enjoyed in the 1990s, for example — we should be seeing workers' wages growing much faster than the inflation rate, producing real increases in people's standard of living.
It's a safe bet that President Obama will tout the economy's strong 2015 performance in his State of the Union speech next week. And if the strong results continue over the next year, it will give a boost to Hillary Clinton, who can be expected to run on Obama's economic record.
Silicon Valley philosopher king Paul Graham's essay on inequality has set tech Twitter on fire for the past few days. It's about as intensely loved and hated as any piece on the topic I can remember. Which makes sense, because it manages to jam some very good points together with some very bad ones.
Graham, a famed adviser to technology startups, appears to have experienced the inequality conversation as an attack on his life's work. His essay is thus more a defense of startups and their worth than it is an analysis of the trends driving inequality. More than anything, Graham seems terrified of policies that, in trying to combat inequality, would end up targeting the founders of tech companies.
This is a slightly bizarre interpretation of the debate. The inequality argument has emerged at a moment when Silicon Valley startups are lionized but protesters take to the streets to demand the dissolution of Goldman Sachs. If inequality were driven by technology startups, there would be much less concern over it.
But Graham's focus on startups as a cause and consequence of inequality is also empirically wrong. "Startups are almost entirely a product of this period [of inequality]," he writes, which is simply not true. For all the Silicon Valley hype, the startup rate has actually been declining as inequality has been rising.
In a separate (and, I think, more interesting and nuanced) essay, Graham argues that in the mid-20th century, there were startups, but they were very different in composition. "Educated people," he writes, worked for large corporations, because "there was practically zero concept of starting what we now call a startup: a business that starts small and grows big."
So perhaps that falling startup rate obscures a rise in the kind of startups that interest Graham. Even if that's true — Graham doesn't present data to prove it, but it certainly seems correct as a description of Silicon Valley trends  — it doesn't change the fact that there is no observable relationship nationally in recent decades between the rate of startup formation and inequality. I wonder whether Graham's perch in Silicon Valley isn't warping his analysis of what's going on in the rest of the economy.
When you dig into the occupations of the top 0.1 percent, you find that "the incomes of executives, managers, supervisors, and financial professionals can account for 60 percent of the increase in the share of national income going to the top percentile of the income distribution between 1979 and 2005."
Some of that is certainly Silicon Valley executives. But it's the financial professionals that this conversation is really about.
You can see that in the timing. The debate over inequality doesn't coincide with either the rise of Silicon Valley (late '90s, and then again in the early 2000s) or even the rise of income inequality (1980s). It coincides with the aftermath of the Great Recession — a time when finance professionals crashed the global economy, immiserated millions of people, and managed to remain incredibly, infuriatingly rich. There's a reason it was called Occupy Wall Street rather than Occupy Google.
By the time of the 2007 crash, financial sector profits accounted for about 35 percent of all corporate profits. These weren't startups. Indeed, the fear in the financial sector was over firms so ridiculously large that the government wouldn't permit them to fail.
"I know the rich aren't all getting richer simply from some sinister new system for transferring wealth to them from everyone else," Graham writes. In Silicon Valley, that's largely true. But if you lost your construction job because of the financial crisis even as a trader who bet on subprime bonds kept both his career and his bonuses, you've got good reason to think the rich are getting richer from a rigged system.
Graham tries to acknowledge this in a footnote. "Others will say I'm clueless or being misleading by focusing on people who get rich by creating wealth that startups aren't the problem, but corrupt practices in finance, healthcare, and so on. Once again, that is exactly my point. The problem is not economic inequality, but those specific abuses."
But this gets almost tautological. The inequality debate is driven by the belief that those kinds of abuses are disparate and widespread. People need a way to talk about the idea that economic gains are being shared unfairly and inequality is the word they've chosen to do it. Dismissing the source of their anger only leads you to miss the point of their critique.
An important point Graham makes is that while people are angry about income inequality, they usually prioritize fixing other problems. When it comes down to it, they really care about poverty, or social mobility, or median wages, or political power.
Consider two worlds. In one, the Gini coefficient — the standard measure of inequality — remains the same, but median wages are double their current level. In another, the Gini coefficient falls, but median wages are 10 percent lower and poverty is 3 percentage points higher.
Would anyone choose the second world? Bueller?
But having made that point, Graham spends much of his essay grappling with strawmen. Statements like "Ending economic inequality would mean ending startups" confuse the conversation. No one is talking about ending startups. No one is even talking about ending inequality. And you can certainly ameliorate inequality without destroying the ability to found new companies. Sweden, for instance, has a higher startup rate than America, and less income inequality — as do a number of other countries.
Graham's belief that you can't ease inequality without declaring war on technology runs deep. "I think rising economic inequality is the inevitable fate of countries that don't choose something worse," he writes.
He argues that the long fall in inequality in the 20th century was an anomaly driven by wars and government-backed oligopolies. He goes on to write:
The acceleration of productivity we see in Silicon Valley has been happening for thousands of years. If you look at the history of stone tools, technology was already accelerating in the Mesolithic. The acceleration would have been too slow to perceive in one lifetime. Such is the nature of the leftmost part of an exponential curve. But it was the same curve.
You do not want to design your society in a way that’s incompatible with this curve. The evolution of technology is one of the most powerful forces in history.
This is far too fatalistic. Modern societies have long figured out how to manage this curve. Technology makes individuals grow more productive, in part because they stand atop the knowledge and industrial base of their societies, and societies redistribute part of that wealth, in part because that's necessary to sustain the political stability and economic freedom required to protect those individuals.
There are difficulties and trade-offs inside this system, but they're manageable, and all in all, it actually works pretty well. The taxes the Silicon Valley elite pay in the 21st century are much, much higher than anything their predecessors paid in the 18th century, but somehow people still like inventing new things and getting rich.
There's no particular level of inequality that is inevitable, and it's both pessimistic and ahistorical — two qualities I don't tend to associate with Graham, who tends towards optimism and a strong grasp of history — to believe the drive towards technological progress is so flimsy that modest changes to the tax code or social programs will derail it.
What is all the land in Manhattan worth? Economists Jason Barr, Fred Smith, and Sayali Kulkarni think they know the answer based on a data set of vacant parcel sales in Manhattan. By recording all the vacant sales and doing a little math, you can interpolate the value of all the land and conclude that in 2014 the island's land was worth about $1.4 trillion — almost 10 percent of the annual income of the entire United States.
You can also see how the price of Manhattan has changed over time:
These numbers are adjusted for inflation and are on a logarithmic scale, so that 21st-century increase is truly enormous. They say that land prices have risen 15.8 percent per year since 1993 and that if you go all the way back to Dutch settlement in 1626, there's been a 6.4 percent annual rate of return over the past 388 years.
It's a fascinating paper, but one thing that's striking to me is the mere fact that it has to be written at all. The government collects, creates, and records tons of economic data. Using government websites, you can look up how many new homebuilding permits were issued last year or what the average retail price of a dozen eggs was or what the wholesale price of a pig was. But there's no authoritative tracking of land prices, even though the price of land is of fundamental economic importance.
Most of the country's top economists are gathered this week in San Francisco for the annual American Economic Association conference. And from what I'm hearing, the buzz is all about Robert Gordon, a Northwestern professor who's been arguing for some time that American economic growth is over. His book The Rise and Fall of American Growth: The US Standard of Living Since the Civil War will be out on January 12 and is largely dedicated to putting that claim into historical context.
The way Gordon sees it, rather than view the US's slowdown in economic growth since the mid-1970s as an anomaly, we should understand the rapid growth from 1870 to 1970 as exceptional. Around most of the world, for most of history, growth has been slow.
And he expects growth in average people's living standards in the US to continue to be slow for four big reasons: Educational attainment is slowing down, there's a big overhang of debt, the population is aging, and the rich are gobbling up more and more of the diminished economic pie.
Normally these kinds of big-think books end with a whimper, as the author totally fails to identify solutions to the problem he is writing about. But Gordon's conclusion offers some admirably definitive policy advice.
Specifically, he thinks we should:
To me, what's striking about this is that for such a big and ambitious book that is attracting so much debate, the policy prescriptions aren't especially far out.
Items 1, 2, 3, 5, 7, and 8 are all things the Obama White House has come out for, and 9 and 10 are things they've definitely signaled openness to. Items 3, 7, 8, 9, and 10 are all things I've heard leading Republicans endorse, along with some openness to 5. Total drug legalization isn't something that's very mainstream politically, but the overall political consensus is clearly shifting in that broad direction. Only 6 really seems like a nonstarter politically, even though it's absolutely a reasonable idea.
The overall tone of the end of the book is very much on the pessimistic side, but these seem like  policy solutions that one could be realistically optimistic about.
The self-driving car wars are heating up. A few weeks after we learned that Ford and Google are creating a joint venture to develop self-driving cars, General Motors and Lyft have announced a self-driving joint venture of their own.
Lyft is raising $500 million in investment capital from GM along with another $500 million from other investors. Those other investors include two Chinese companies that are huge in Asia, albeit obscure in the United States — Alibaba in e-commerce and Didi Kuaidi in ride-hailing. Together, it amounts to a global alliance to battle Uber, a direct Lyft competitor that is working on its own self-driving technology.
The odds of this new alliance triumphing seem slim, as it doesn't have either the resources or the artificial intelligence expertise of Google, Tesla, Uber, and some of the other companies working in this space. But the deal does tell us a lot about how the global ride-hailing market is evolving — and why competition in the ride-hailing market is really just the prelude to a much bigger fight over dominance of the self-driving car market over the next couple of decades.
Here are four big lessons from GM's deal with Lyft.
We're used to thinking about cars as personal property that people own. Taxis and rental cars exist, of course, but they're niche products used in unusual situations or in a handful of central cities. Most households do most of their trips in cars the household owns.
I've argued before that self-driving cars will flip this around. Without the need to pay a driver, self-driving taxis will be so cheap that ordinary middle-class consumers, even in the suburbs and smaller towns, will find them cost-effective for most trips. Indeed, because rental allows several people to effectively share a single vehicle, getting around via self-driving taxi will likely become more affordable — not to mention more convenient and versatile — than owning a dedicated vehicle.
If on-demand rentals are the future of self-driving car technology, then teaming up with an on-demand rental service is a smart strategic move for a carmaker like GM. By the time self-driving cars start showing up in the marketplace — likely sometime in the 2020s — many customers will have grown accustomed to hailing cars using a smartphone-based service like Uber or Lyft. That will give them a lot of influence over consumers' use of self-driving technology, and so it makes sense that GM is acting now to make sure it has an ally in the ride-hailing market.
New car technologies come along all the time, and it would be easy for car companies to assume that self-driving capabilities will be just another feature to add to their existing vehicles. But there's reason to believe self-driving technology is a much bigger deal, and that car companies that don't adapt quickly won't survive the transition.
Putting software in control of cars is likely to be a lot more than a cosmetic change. Just as the internet is fundamentally transforming industries from music to retail — and threatening incumbents in those industries — so self-driving cars are likely to prompt a fundamental rethink of how cars work. If cars are primarily rented, rather than owned, then they can be optimized for shorter trips and more heavily specialized for different use cases. Short-range, high-efficiency electric vehicles will become more practical. Companies may make cars in a wider variety of sizes and shapes, from hyper-efficient one-seaters to luxury minivans to support family vacations.
And car companies will also face new reliability and security challenges they've never faced before. When cars are controlled by software, they become vulnerable to hacking, and car companies' current manufacturing techniques — which involve delegating most of the work to hundreds of subcontractors — make car software almost impossible to audit. If car companies don't change their software development techniques, companies like Uber, Tesla, Google, and Apple are going to run circles around them.
Forming a joint venture with a prominent software company like Lyft gives GM a chance to start with a fresh slate. It could even be a sign that GM management recognizes that truly radical innovations will only take place if they're insulated from GM's bureaucratic culture.
GM is Lyft's biggest new investor, but the latest round of funding also includes money from Alibaba (China's answer to Amazon.com) and Didi Kuaidi (Uber's biggest rival in China).
These investments represent a growing recognition that self-driving cars are likely to be a global market. Developing self-driving technology won't be cheap, and so companies that can spread those development costs across multiple big markets will have a distinct advantage. The United States and China are the world's two biggest markets, so it makes sense that companies in these markets would team up. Once GM and Lyft have developed self-driving car technology, they'll be able to turn to Alibaba and Didi Kuaidi to help sell it to Chinese consumers.
Lyft is seeking new allies because it's a huge underdog, as reflected by the terms of this new deal. Lyft sold shares to its new investors on terms that valued the company as a whole at $5.5 billion. A few years ago, that would have been considered a high valuation for a ride-hailing company, but it's tiny compared with the more than $60 billion valuation of Lyft's biggest rival, Uber. Lyft raised $1 billion in its latest fundraising round and $680 million total in 2015. By contrast, Uber has raised nearly $5 billion in the last year.
Uber has been spending all of that cash not only consolidating its lead in US markets but also extending its reach internationally. Its global reach means that if and when Uber's own self-driving car project — which it has been working on for a year — comes to fruition, Uber will be able to deploy the cars in dozens of countries around the world.
The Lyft-GM alliance will also have to play catch-up with other companies that have big head starts in self-driving technology:
Starting with the March issue, due to hit newsstands this weekend, Playboy magazine will no longer feature explicit nudity. It sounds like an April Fools' joke, but it's not: The New York Times was given a copy of the latest issue, and what used to be an NC-17 publication is now more like PG-13.
This isn't about prudishness so much as it is about money: Playboy CEO Scott Flanders believes the Playboy brand can transcend its salacious origins and become a lucrative vehicle for selling mainstream products. There's already a wide variety of Playboy-branded clothing and jewelry out there, and the Playboy brand is particularly popular in China, where pornography is officially illegal.
Playboy tested this strategy with the Playboy.com website, which has been free of explicit nudity since 2014. The company says it's been a big success, attracting a much bigger and younger audience. Now it's hoping to expand on that success with what used to be the country's most popular pornographic magazine.
Beginning with next month's issue, there won't be any explicit nude images of women in the US edition of Playboy magazine. The Times reports that there are still some naked women in the issue but that the images are "shot in ways intended for strategic concealment" — much like men's magazines such as Maxim and Stuff.
In 1953, Playboy made its mark by being one of the first mainstream magazines to feature pictures of nude women. In the pre-internet era, porn was a lot harder to obtain, so there was a big market for pornographic magazines. The magazine grew to more than 5 million subscribers by the 1970s and attracted a bunch of competitors.
But the internet has totally transformed the pornography industry. Today, any kind of porn you can imagine is just a Google search away and in most cases is available for free. So over the past couple of decades, the value proposition of paying $19.95 a year to have a few dozen nude images delivered in dead-tree format each month has become less and less compelling. By last year, the magazine only had around 800,000 subscribers.
The internet has totally transformed the pornography industry
On the other hand, Playboy has always aspired to be more than just a pornographic magazine. Over the decades, those 5 million subscribers allowed Playboy to do interviews with a wide variety of famous people, including Martin Luther King Jr., Jimmy Carter, and Steve Jobs.
There's a long-running joke about people "reading Playboy for the articles," but Playboy's non-pornographic content really has been pretty good over the years. Now it won't be such a joke anymore. Playboy will tone down the nudity while beefing up its coverage of other topics, including a new sex column and expanded coverage of the liquor business.
Playboy used to look like a conventional media company with a stable of magazines, websites, television stations, and so forth. But that business model hasn't done well in the internet age, and it reached its nadir in the wake of the 2008 financial crisis.
So the company began downplaying its media properties and focusing instead on promoting and licensing its iconic brand. And Flanders started to wonder whether distributing pictures of naked women was becoming a business liability. "You could argue that nudity is a distraction for us and actually shrinks our audience rather than expands it," he argued in 2014.
Dropping the naked women dramatically expanded the potential audience for Playboy.com
Lots of people are attracted to the risqué vibe of the Playboy brand, but there are situations in which outright pornography isn't allowed. Apple's App Store, for example, doesn't allow apps to have sexually explicit imagery, for example, nor do Facebook and Instagram.
So last year, Playboy overhauled its primary website, Playboy.com, and took out all the explicit nudity (there are still plenty of racy near-nude shots of the type you'll find in other men's magazines). Playboy executives told the New York Times that this was a huge success: Traffic quadrupled, and the average age of readers fell from 47 to 30.
In other words, young people who grew up in the porn-saturated world of the internet aren't that interested in Playboy.com as a place to get porn. And the existence of naked women on the site made it awkward to read Playboy articles at work — where many people spend time goofing off online — or share Playboy content on social media sites. Dropping the naked women dramatically expanded the potential audience for Playboy.com without significantly reducing its appeal.
More traffic and a younger audience are big successes in their own right, but even more importantly, the shift helps make the Playboy brand more mainstream. There's already a large demand for Playboy-branded merchandise, and Flanders is betting that that demand will grow even more if Playboy becomes less associated with explicit pornography in the minds of the public.
The decision to drop nudity from the magazine is best seen in this light. The goal isn't so much to make the magazine itself more successful — though presumably its owners would like to do that — but to make the magazine a more effective sales tool for the Playboy brand more generally.
Playboy's magazine hasn't been a big moneymaker in years. Flanders told the New York Times last year that the US edition of the magazine lost around $3 million last year. But Playboy's efforts to cash in on its brand — and particularly its famous bunny logo — are paying big dividends.
The goal is to make the magazine a more effective sales tool for the Playboy brand more generally
Playboy's brand is not only widely known in the West, it's also surprisingly popular in China. In 2014, Playboy-branded products generated $1.5 billion in revenues in China, about a third of the worldwide total. Playboy merchandise is available in 3,500 retail outlets in China — which is particularly remarkable because pornography is officially illegal there.
Flanders hopes that making the magazine less porny and more mainstream will help make the Playboy-branded products more mainstream as well — and dramatically expand the market for them.
There will no longer be naked ladies in Playboy magazine or at Playboy.com, but that doesn't mean we'll stop seeing explicit imagery distributed under the Playboy brand.
In 2011, Playboy signed a deal with the internet porn company Manwin, since renamed MindGeek, to manage many of the company's online properties and television channels. Playboy later regained control over the Playboy.com site, but the rest of Playboy's pornographic empire, including the Playboy Plus subscription service and Playboy TV, continues to be operated by MindGeek.
This might mean that Playboy can have the best of both worlds: It could enjoy the commercial benefits of a more mainstream image while continuing to profit indirectly from its pornography business.
On the other hand, if dropping pornography from the website pays big dividends for Playboy's licensing business, it's possible the company will seek to shut down its other pornographic properties as well. That might be tricky, since Playboy's licensing agreement with MindGeek runs for 15 years (meaning Playboy might not get control back until 2026). But if Playboy becomes determined to separate itself fully from the pornography business, it might be able to cut a deal with MindGeek to end the deal early, or to choose a new brand name for its pornographic content.
Via Fred Wilson, here's a look at the 25 most popular mobile apps as of mid-2015, a list that you'll see is utterly dominated by Google, Facebook, and Apple:
As Wilson notes, "There isn’t a single 'startup' on that list and the youngest company on that list is Snapchat which is now over four years old." In other words, we've experienced a closing of the app frontier and entered a phase of consolidation.
But another theme I would note is that this chart calls into question two bits of conventional wisdom that currently exist in the technology press. One is that the strength of Apple's iPhone franchise fundamentally rests on the strength of the app ecosystem — developers develop for iOS because iOS has the best customers, and high-end buyers flock to iOS because it has the richest app ecosystem. The second bit of CW is that this means Apple needs to cultivate a similar virtuous circle between users and developers to succeed with products like iPads, Apple TV, and Apple Watch. In other words, for its new products to succeed, Apple needs to do more to improve its strained relationship with independent developers.
From this chart, though, it seems maybe Apple's relationship with independent developers is strained because Apple can see that those developers aren't as important as they think they are. The main thing people want to do with their mobile devices is access services from Facebook and Google, meaning that the important thing for Apple to manage is the delicate relationship between giant companies that compete with each other while also being codependent.
The Big Short has earned acclaim from critics and financial journalists alike for the skillful way in which it dramatizes and humanizes financial products and concepts that are complicated, and at times deliberately obscure. But like many other financial crisis narratives, it fundamentally misses the part of the story that turned the 2008 financial crisis into the sort of epochal event that people would make movies about in 2015 — the Great Recession that sent the unemployment rate soaring to 10 percent and kept it above 8 percent for two more years.
The thing about this recession is that it's a lot simpler than the financial machinations that blew up and then deflated the housing bubble. So simple that it would make a terrible movie. But despite its simplicity, it's a story that is oddly missing from American political dialogue.
Excavations of the plumbing behind the financial crisis often seem to be implicitly written from an alternate universe in which the events of the fall of 2008 played out entirely differently. In this universe, the Federal Reserve wasn't able to organize a rescue for Bear Stearns, or allow Goldman Sachs to hastily convert to bank holding company status, Congress didn't approve the Troubled Asset Relief Program, AIG wasn't nationalized so the claims it had underwritten didn't get paid off, and the Bush-Obama lame duck period was characterized by a series of epic bankruptcies of large, diverse financial institutions.
If all that had happened, then we would be sitting around saying that economic devastation visited upon American working people in the subsequent years was caused by a massive banking crisis. We would note that there's a certain irony in the fact that Fed Chairman Ben Bernanke was a leading academic proponent of the view that an uncontrolled series of bank failures caused the Great Depression, and yet an uncontrolled series of bank failures rolled out under his watch, followed by a second Great Depression.
Except none of that happened.
The unsound bets on mortgage-backed securities that are detailed and explicated in the Big Short nearly brought the American banking sector to its knees, but with the exception of poor Lehman Brothers none of the major banks actually did fail. Everyone got access to the Fed's discount window. AIG's bills were paid even though it had no money. New capital was injected by the federal government on a generous basis, and an implicit guarantee halted runs. There was a scary near-miss on the "all the banks fail" thing, but it didn't happen. Before the crisis, Citigroup, Wells Fargo, JP Morgan Chase, Bank of America, and Goldman Sachs were the biggest and most important financial companies in America, and that's still the case today.
So why did we have such a gigantic recession? This is an ultimately more important question, albeit one that wouldn't make a great movie. And the answer is pretty simple — the collapse in house prices led to a sharp slowdown in residential construction spending (because building new houses wasn't lucrative any more) and it also led to a sharp slowdown in consumer spending (because people became poorer) and those slowdowns led to a slowdown in business investment spending (because nobody was buying anything).
You can call this a big drop in demand, a big drop in total economy-wide spending, a big drop in nominal gross domestic product, or any number of other things. But that's what happened.
But there's supposed to be a fix for this kind of thing. The government — through a mix of money-printing by the Federal Reserve and tax cuts and deficit spending by congress — is supposed to plug the gap. The tax cuts finance consumer spending, the deficit spending directly employs many people, and the Fed action boosts net exports all while business investment continues apace to keep up with these streams of demand.
In that scenario, we wouldn't remember 2009-2010 as painless times. Construction workers still would have lost their jobs and had to go find new work, perhaps work that didn't take advantage of their specialized skills and didn't pay as well. Affluent people would find that foreign travel and imported German cars had become less affordable, while the poor and middle class would have worried more about import prices for things like clothing and children's toys. But after a modest bump of bad times we'd have moved on to the enduring issues of public controversy — the appropriate size of the welfare state, the balance between environmental regulation and short-term economic growth, and whatever Donald Trump said yesterday.
But that didn't happen. We had a significant fiscal stimulus bill from the Obama administration, but it was scaled to a smaller recession than the one that was actually happening. The Federal Reserve cut interest rates to zero, but then got timid about additional money-printing. Unemployment never got as bad as it did during the Great Depression, but it got pretty bad and only recovered slowly.
That's why we remember the financial crisis as such a big deal. But financial crises don't cause years-long spells of mass unemployment unless the political system lets them. The country's governing elite mobilized during the fall and winter of 2008 to prevent a banking crisis from destroying the economy, but then during the spring and summer of 2009 didn't take the kind of decisive action that could have led to a quick employment recovery. That's the real tragedy of the era, and you won't see it in any movie theater.
Star Wars: The Force Awakens has crushed the competition at the box office, making the $4 billion price Disney paid for ownership of the Star Wars franchise look like an enormous bargain — especially when you consider that even more money will come pouring in from ancillary licensing deals. Disney also owns Marvel Studios, which has become an increasingly reliable engine of hit content, spawning not only an endless parade of movies but also critically acclaimed television shows like Jessica Jones that could be an even better home for Marvel properties than the cinema. Combine those two franchises with Disney's effective long-term stewardship of Pixar, and the company is clearly positioned as the dominant content franchise of the future.
Yet Disney stock is down a bit over 1 percent on the year, with almost $2 billion in market value having been eliminated. And it really all comes down to one thing: ESPN.
Live sports has been an important part of the television ecosystem for decades, and ESPN has been one of the most successful and important networks throughout the cable television era. But in the 21st century, live sports has truly emerged as the killer app for linear cable television.
The first factor was the rise of the DVR, which has made it cheaper and easier than ever before for people to record their favorite shows and watch them at their leisure. This has been great for television artistically, since it means creators can now more readily assume that every single episode of their show will be consumed in sequence. But in business terms, it's devalued the audience, since marketers know that DVR-watchers are skipping ads. But people don't normally like to record sports and watch them later — they watch live, meaning a sports viewer has increasingly become more valuable than a non-sports viewer.
Streaming television services then came along and made live sports even more valuable. Suddenly the vast majority of basic cable networks became a fundamentally dispensable commodity. A Netflix or Hulu Plus subscription would give anyone a vast array of programming to watch without the need for a cable subscription. But for sports fans, cable remained vital.
Which meant that sports became even more vital to cable companies. Cable companies are blessed to face little to no competition in most circumstances, but they do need to worry about non-consumption of pay television. Ensuring that ESPN is in your bundle of channels was the key to avoiding non-consumption, so ESPN could demand increasingly high fees from cable companies that wanted to carry it.
But this is the year it all started to fall apart. As of the fiscal year that ended on October 3, ESPN had 92 million subscribers — down from 95 million in 2014 and 99 million in 2013. Every pay television operator under the sun still subscribes to ESPN, but fewer and fewer people are subscribing to cable.
The overall cable bundle in which you pay a high price for a ton of content works out to be a pretty good deal for most consumers. And it's been a great deal for live sports, since it means they collect high fees not just off the large number of sports fans in America but also off the large minority of Americans who don't watch sports. But it's not a good deal for everyone, and more and more of the people for whom it's not a good deal are opting out and relying on streaming services or à-la-carte purchases for their entertainment needs.
And the problem with the bundle is that the more people who opt out of it, the worse a deal it becomes. More and more content owners will want to try to reach the cord-cutting audience, which means that subscribing to the bundle will be necessary for a smaller group of people, which means that even more people will opt out. The move to a purely over-the-top world in which everything is consumed via the internet will happen in fits and starts, but once the process is underway it's unstoppable.
And that's very scary for ESPN. In theory, the channel could thrive in a post-bundle world by becoming its own sports-specific bundle. As the incumbent worldwide leader in sports, the network is better positioned than any other particular provider to assemble the ultimate omni-sport package that every sports fan in America would buy. But the chance of someone else — Fox Sports, NBC Sports, or even a brand new upstart — doing this isn't zero. And the chance that sports itself will completely unbundle with each team selling its own games to its own fans isn't zero either.
So while ESPN is hardly doomed, it's gone from a situation in which its dominance was guaranteed to a situation in which its dominance is not guaranteed. And as goes ESPN, so go Disney's other cable channels — they are all plunging into a very uncertain world.
Uber’s devastating effect on the New York cab industry is plain to see in this chart, produced by Goldman Sachs, showing the change in the price of New York City taxi medallions since 2004.
New York’s yellow taxicabs are the only vehicles in the city allowed to pick up passengers who hail them from the street. The medallion system, in place since 1937, sets an upper limit on the number of those cabs. As demand grew, medallions became more and more valuable.
This chart shows how medallion prices rose from about $250,000 in January 2004 to a peak of just over $1 million for an individual medallion — and about $1.3 million for a corporate one — in March 2013.
But starting in 2010, Uber’s drivers — who aren’t allowed to accept street hails — started filling this government-created vacuum. As Uber added more and more drivers, medallion priced stagnated, then started to fall precipitously. The more people hail cars through Uber, the less money cab drivers make, and the worse taxi medallions look as an investment.
One of the city’s largest taxi companies, White & Blue Group, saw its monthly medallion-leasing income drop as much as 50 percent in the past year, according to a lawsuit it filed against the city last month.
Discussions of "gentrification" are commonplace in contemporary urban America, with complaints usually focusing on two main themes. One is change in the built environment — people often liked neighborhoods the way they were when they moved there, and resent the construction of new structures that differ in scale and style from what was there previously. The other is economic impact — people often worry that an influx of affluent newcomers will raise housing costs in a way that disadvantages less privileged people.
The good news is that this latter problem can be fixed. The bad news is that the best way to do it is to increase the pace at which a city's built environment changes.
The experience of expensive, politically liberal coastal cities tends to dominate media discussions of urbanism, so it's important to note that these cities are the exception rather than the rule. Most American central cities are relatively affordable, and many of them — especially in the Midwest — are still suffering from the population loss and disinvestment associated with white flight. A Detroit, Cleveland, or St. Louis could greatly benefit from an influx of affluent newcomers whose presence would create new job opportunities and bolster local tax bases.
At the same time, in any city it does seem to be true that an influx of newcomers will tend to raise prices. Research by Veronica Guerrieri, Daniel Hartley, and Erik Hurst shows empirically how this works. Price increases tend to concentrate in specific neighborhoods rather than spreading across a city as a whole. They model this as a question of spillovers. More and less affluent people place systematically different values on different kinds of retail opportunities. So affluent young people might be drawn to proximity to a Whole Foods and an array of independent coffee shops and yoga studios, while working-class families might prefer a cheaper supermarket and proximity to some home-based day care providers. When affluent people start moving to a neighborhood, the retail mix shifts in favor of things affluent people like, which draws more affluent people to that specific neighborhood but not necessarily to other places in the city.
But whether this is good or bad for older residents of the city depends on other factors. Janna Matlack and Jacob L. Vigdor examined market data from 1970 to 2000 and found that the net economic impact of gentrification varies according to local housing conditions.
"In tight housing markets," they write, "the poor do worse when the rich get richer," whereas in slack markets, "some evidence suggests that increases in others' income, holding own income constant, may be beneficial."
When houses are plentiful, in other words, gentrification can be a win-win — increases in other people's incomes create new opportunities for the poor. But when houses are scarce, increases in other people's incomes merely exacerbate scarcity and leave the poor worse off than ever.
So what creates a "slack" housing market where gentrification can be a win-win? Data from the real estate website Trulia shows it can basically happen one of two ways.
Markets like Detroit, Cleveland, or Rochester are cheap essentially because they are economically depressed. There are plenty of empty houses, so if affluent newcomers show up and fix some of them up it doesn't generate any real scarcity.
Tight markets like New York and the Bay Area can't replicate that approach to affordability. But they could learn a lesson from the other kind of slack housing market — Sunbelt markets like Raleigh and Atlanta where new houses are being built at a very rapid clip.
Those fast-growing metros are mostly adding houses by spreading their geographical footprint deeper into the suburbs. That's not necessarily an appealing option for cities whose sprawl is limited by oceans or already-gargantuan commuting times. But fortunately, technology exists that allows house builders to pack large quantities of dwellings into limited land. Rather than detached houses each perched in their own yard, rowhouses or townhouses can be built. Where land is even scarcer, American builders have the capacity to erect apartment buildings — some of them two dozen stories high or more — whose floors are connected by elevators. The big problem is that in the most expensive metropolitan areas it is illegal to deploy these technologies on large swaths of land. Zoning codes and historic preservation rules generally prevent even the priciest neighborhoods from becoming denser.
Relaxing these zoning rules would transform gentrification of neighborhoods in generally affluent cities into a win-win that benefits the poor. But it would mean accelerating the pace at which gentrification reshapes the built environment of those neighborhoods. Those worried about gentrification, in other words, likely need to choose what it is they are primarily worried about — the aesthetic or economic dimensions of the issue — and recognize that addressing one will likely exacerbate the other.
Seattle and the San Francisco Bay Area have a lot in common — coastal locations, high-tech economies, and relatively high wages. But as California's Legislative Analysis Office wrote in a recent report, it's much easier to get permission to build new houses in the Seattle area. Consequently, the Seattle area's housing stock has grown twice as quickly as the Bay Area's. The CLAO writes that in recent years, Seattle's total number of housing units "grew at an average annual rate of 1.4 percent per year while San Francisco and San Jose’s housing stock grew by only 0.7 percent per year." The main reason for this is that Washington state centralizing more planning functions at the state level, which gives hyperlocalized Not in My Backyard sentiments less when determining what people are going to be allowed to build.
So what happened? While prices in the Bay Area have been skyrocketing, some Seattle landlords have actually seen the rents they can charge start to fall. Mark Stiles of the Puget Sound Business Journal writes that landlords are finding the trend "alarming" — though if you're a tenant in Seattle you probably feel differently:
The big warning sign for landlords is what the report says is "price resistance" in the most expensive submarkets: the downtowns of Bellevue and Seattle, including Belltown and South Lake Union, and Sammamish/Issaquah. After increasing during the first three quarters, rents dropped this quarter in all but South Lake Union, with the average decline hitting $59 a month. Further, when all of these submarkets are considered, the average vacancy rate increase was nearly a full percentage point.
Meanwhile, across all markets, more landlords are offering tenants sweeter incentives, such as free rent. The average value of incentives is $15 a month this quarter, which is nearly double what it was last quarter, when 16 percent of landlords were offering incentives. Now 20 percent are.
Skeptics often note that new construction tends to target the high end of the market, rather than creating affordable dwellings for the working class. And that's true here. Stiles reports that the weakness in the market is at the high end, "where 5.4 percent of the units are vacant," while cheaper rentals feature a lower vacancy rate.
But these markets are all logically linked. As proprietors of luxury buildings begin to lower rents in response to high vacancy rates, some people currently in mid-market housing will take advantage of the opportunity to upgrade. That puts downward price pressure on the middle of the market and draws more people further up the chain. None of this exactly makes Seattle a cheap place to live — land is still more expensive there than it is in Atlanta, and multi-family apartment buildings are often more expensive to build than sprawling single-family homes. But a high level of construction ensures that the homeland of Microsoft and Amazon remains substantially cheaper than the Bay Area homeland of Apple and Google.
Chipotle likes to emphasize the quality of its food, a goal summed up in the company's slogan, "Food with integrity." So it might seem paradoxical that Chipotle, of all companies, has gotten hit by a string of food safety problems.
Yet it turns out that it's not so paradoxical. This paragraph from a regulatory disclosure Chipotle filed in February — before the current food safety crisis began this summer — explains why (emphasis added):
We have made a significant commitment to serving local or organic produce when seasonally available, and a small portion of our restaurants also serves produce purchased from farmers markets seasonally as well. These produce initiatives may make it more difficult to keep quality consistent, and present additional risk of food-borne illnesses given the greater number of suppliers involved in such a system and the difficulty of imposing our quality assurance programs on all such suppliers. Quality variations and food-borne illness concerns could adversely impact public perceptions of Food With Integrity or our brand generally.
There's plenty to dislike about factory farms, but one big advantage of large-scale conventional agriculture is that it allows sophisticated quality control measures. By aggressively embracing local and organic food, Chipotle put itself — and its customers — at greater risk of doing business with suppliers with substandard safety and quality control procedures.
And as we've noted before, the benefits of organic food are scientifically dubious to start with.
Thanks to Andrew Lang for pointing out Chipotle's filing.
The news about Chipotle's food safety record keeps getting worse. In recent months, people in California, Washington state, Minnesota, Boston, and elsewhere have gotten sick after eating at Chipotle. On Monday, the Centers for Disease Control and Prevention reported another round of infections — five Chipotle customers in Kansas, North Dakota, and Oklahoma.
The run of bad news is ironic because Chipotle has actually spent a lot of time this year thinking about where its ingredients come from. Back in April, Chipotle became the first major restaurant chain to announce that all of its food was free of genetically modified organisms. Many customers saw that as a sign of progress — though others complained that some of its "GMO-free" meat came from animals fed GMO grains.
Yet study after study has found that GMO foods are perfectly safe. While genetically modified food sounds scary to a lot of people, it's been widely available in the United States for about two decades with no apparent ill effects.
So rather than pandering to groundless fears about GMO safety, Chipotle would have served its customers better by focusing on the very real dangers of food tainted with E. coli, norovirus, or salmonella. Theoretically, it should be able to do both, of course, but like any organization Chipotle has limited resources. A dollar it spends guarding against the overblown threat of GMOs is a dollar it can't devote to preventing actual health problems.
Chipotle's stock took a beating on Friday after the Centers for Disease Control and Prevention reported on another outbreak of E. coli infections linked to the fast-casual restaurant chain. According to the CDC, five people in Kansas, North Dakota, and Oklahoma contracted E. coli infections between November 18 and November 26. All five had previously eaten at Chipotle.
It's the latest in a long string of revelations about food safety problems at Chipotle restaurants. This newly reported outbreak actually occurred a few days before an outbreak that sickened 120 students in Boston. In late October, the company closed 43 restaurants in Oregon and Washington in an effort to get the problem under control, and has also faced outbreaks in Minnesota and California. Thankfully, no deaths have been reported.
The string of food safety problems has battered Chipotle financially. In a regulatory filing last Friday, Chipotle predicted that sales at a typical restaurant would fall by about 10 percent as a result of the outbreak, and that the company would have to spend $6 million to $8 million to address the crisis — not counting possible legal costs if customers sue. The company's stock has fallen by about 30 percent since August.
With $600 million in cash on hand, Chipotle shouldn't have any trouble weathering this storm financially. But the larger question is whether the string of outbreaks — which may or may not be over — will damage the restaurant's reputation for "food with integrity." Chipotle's commitment to using fresh ingredients from local farms makes it more vulnerable to foodborne illnesses. Chipotle is going to have to work hard to improve its food handling procedures to stamp out foodborne illnesses and win back customers' trust.
The string of outbreaks stretches across the country. In early December, the Centers for Disease Control and Prevention created this map showing the location of E. coli outbreaks in recent weeks — this map does not include the most recent revelations of illnesses in Kansas, North Dakota, and Oklahoma.
The CDC says that 52 people had been infected with E. coli, and that 47 of them reported eating at Chipotle in the preceding week — strong circumstantial evidence linking Chipotle to the outbreak.
And that's not all. In August, dozens of California Chipotle customers and employees were sickened with a different infection called norovirus — one of the most common foodborne pathogens. The same month, at least 45 people in Minnesota became ill with a third pathogen, salmonella, a problem that was eventually traced to tainted tomatoes at area Chipotles.
In early December, we learned that more than 120 people had become ill with norovirus after eating at a Chipotle near Boston College.
As each outbreak has come up, Chipotle has moved aggressively to contain the problem. As I already noted, Chipotle closed restaurants across Washington state and some parts of Oregon in late October and early November to try to contain the E. coli outbreak there.
In early December, Chipotle announced further steps to beef up its food safety protections. It brought in independent food safety expert Mansour Samadpour to improve its food safety practices and implemented their recommendations. "I am happy to report that our proposed program was adopted in its entirety, without any modification," Samadpour said on December 4. "While it is never possible to completely eliminate all risk, this program eliminates or mitigates risk to a level near zero, and will establish Chipotle as the industry leader in this area."
The improvements included "high-resolution testing of all fresh produce," testing ingredients as they reach the end of their shelf life, continual monitoring of the supply chain to identify suppliers with quality problems, and better employee training.
Then Chipotle faced another big outbreak in Boston. (The just-announced illnesses in Kansas, North Dakota, and Oklahoma all began in November, before this announcement.)
One reason the company may be struggling is its commitment to fresh ingredients. Big restaurant chains that serve canned or frozen foods can centralize their food distribution systems, allowing them to more easily monitor their supply chains and implement stringent procedures to eliminate foodborne illnesses. But Chipotle uses fresh ingredients sourced from a wide variety of local suppliers that may not have the capacity for stringent quality controls. That makes the company more vulnerable to outbreaks, and puts more of the onus for food safety on the managers of the company's 1,700 restaurants.
For years, Chipotle has touted the superior quality of its ingredients, emphasizing that its meat is organic, humanely raised, and GMO-free. These are all strong selling points with Chipotle's upscale customers, but of course they won't mean much if the chain develops a reputation for getting its customers sick.
Concern about long-term damage to Chipotle's brand may explain why the company's stock has lost a quarter of its value since the current string of outbreaks began in August.
Chipotle's situation could be worse. In 1993, for example, hundreds of people were sickened — and four children died — as a result of a massive E. coli outbreak caused by undercooked hamburgers at the fast-food restaurant Jack in the Box. Jack in the Box survived the crisis, instituting innovative new food safety procedures and running ads showing it dynamiting the company's corporate headquarters.
Chipotle is going to have the pursue the same two-pronged strategy: First make sure it's identified and fixed the problems that allowed the outbreaks in the first place, and then make sure the public knows that Chipotle has turned over a new leaf when it comes to food safety.
You know setting aside money for retirement is smart, but you don’t know anything about how it works. You need advice. Where do you turn?
Maybe you have a financially savvy friend or family member. But a lot of people turn to professional advisers.
Until now there have been two different kinds of investment advisers: those who are required to work in your best interests, and those who — amazingly — are not.
But a new rule from the Department of Labor, which becomes final today, aims to change that. Under the new rule, savers will gain the right to sue or initiate arbitration against advisers who don’t meet high ethical standards or who fail to disclose conflicts.
The effect, say both experts and many industry advocates, will be to drive many advisers to change their business models, while pushing others entirely out of the business.
And that’s probably a good thing.
The Department of Labor developed the new standards over the past few years, as part of a larger regulatory effort to reduce risk for middle-class savers after the 2008 financial crisis.
The two kinds of retirement savings pros are called "registered investment advisers" and "broker-dealers." Registered advisers — who often work with wealthier, more sophisticated clients — are required to uphold fiduciary standards, a special legal arrangement most often associated with lawyers and doctors. They are required to work in the best interests of their clients and can be punished for doing otherwise. Registered advisers are paid directly by their clients, and generally charge based on the size of the fund they manage.
"Broker-dealers," on the other hand, are often more like salespeople (a dealer is a broker who works independently). They’re often paid commissions, increasing their incentive to suggest products with higher fees. Many also receive "revenue-sharing" payments from the banks and mutual funds that generate the investments the brokers sell, again potentially influencing them to steer savers toward products that charge more.
The suggestions broker-dealers make to clients are held to a "suitability standard." That is, brokers are required to only propose products that are appropriate for the saver given his or her age, retirement goals, etc.
"I've never met anyone who's going to go to a dealership to ask advice about whether to buy a new car"
What brokers dole out is "advice" in the conventional sense, but the current rules don’t require it to be particularly good, or even fully well-meaning.
"A sales pitch where they're going to get a huge commission isn't ‘advice,’" says Betsey Stevenson, a professor of economics and public policy at the University of Michigan and a former member of the White House Council of Economic Advisers (CEA) who co-authored its report on the rule.
"Car salesmen get commissions, and everyone’s fine with that," she adds. "But I've never met anyone who's going to go to a dealership to ask advice about whether to buy a new car or take the bus."
A decades-long shift from traditional pensions to 401(k) savings plans means more people than ever are responsible for deciding where to invest their own retirement savings.
The CEA’s report, published in February 2015, found that bad advice from conflicted broker-dealers reduced savers’ returns by about 1 percent a year — as much as $17 billion a year nationwide.
The greatest losses occur when workers roll their 401(k) balance into a higher-fee individual retirement account when leaving a job, rather than keeping it with their former employers.
"A typical worker who receives conflicted advice when rolling over a 401(k) balance to an IRA at age 45 will lose an estimated 17 percent from her account by age 65," the CEA’s report said. The report adds that if there is $100,000 in that account, it could grow to $216,000 in 20 years without the bad advice, as opposed to $179,000 with the conflict of interest.
Opponents of the new rules argue that most brokers already act the way regulators want them to.
"If you don’t help someone, they’re not going to continue with you as a client," said Lisa Bleier, managing director at the Securities Industry and Financial Markets Association, an industry group, in a December interview.
Bleier said the Labor Department’s proposed rules were haphazard, applying only to retirement advisers and not to investment advisers generally. They’d require savers to sign extra contracts, including one the moment they walk in the door, she said, and would expose brokers to frivolous lawsuits.
Stevenson argues that most savers would be fine with so-called "robo advice" from online services
I pressed Bleier on the ethical issues involved in advisers receiving commissions or revenue-sharing arrangements. "I don’t see those compensation structures as a problem, no," Bleier responded. "The SEC has approved them."
Both Stevenson, the professor and former Obama administration economist, and Bleier agree on one likely effect of the rules: A lot of brokers will stop serving middle-class clients.
Broker-dealers will have three options:
In late 2012, the UK passed a set of regulations that were similar to the Obama proposal — but stronger. The regulations not only imposed a fiduciary standard on retirement brokers, but also banned nearly all commissions, while also strengthening disclosure and professional training requirements.
The result: The number of advisers in the UK fell from about 27,080 in 2009 to 23,640 in 2014, a reduction of about 13 percent, according to the Association of Professional Financial Advisers.
<!--
new pym.Parent('vox-number-of-advising-staff-working-in-financial-adviser-firms-__graphic', '//apps.voxmedia.com/at/vox-number-of-advising-staff-working-in-financial-adviser-firms-/', {xdomain: '.*\.voxmedia\.com'});
// -->
The revenue generated by advisers was impacted as well. Advisers’ total income never fell, but it stopped growing for three years, from 2011 to 2013. But growth resumed in 2014 with a surge of fee-based income replacing a very large drop in commissions. (Outside factors like the eurozone debt crisis likely influenced advisers’ revenue, as well.)
In the years since the new rules went into effect, both government and industry have expressed concern about a growing "advice gap" for middle- and lower-income retirement savers. While regulators have said it's difficult to measure the gap — measuring something customers aren’t doing — a research firm called Fundscape found, based on survey data, that many advisers were turning away investors who had less than about $148,000 in total assets. The average British investor has a portfolio of about $30,000.
Bleier and Stevenson both believe something similar will happen here in the United States — less wealthy clients simply can’t afford the upfront fees charged by non-conflicted investment advisers. But while Bleier sees that as a big problem, Stevenson disagrees.
Stevenson argues that most savers would be fine with so-called robo advice from online services that use data and algorithms to offer advice based on savers' specifications. Another option: They can read the Vox guide to retirement savings.
"It’s not about good guys and bad guys," said Stevenson. "These guys are just trying to feed their families. And if they can offer a product where they get a $500 commission versus one where they get an $800 commission — they don’t want to give bad advice, but what if it’s hard to tell?"
With the fiduciary rule, the government aims to resolve that tension and legally obligate advisers to put aside their self-interest. The result for savers, though, won’t necessarily be better advice. It could be less advice, at least of the kind you get from human beings.
But that’s okay. Most people don’t need much advice, because the principles of saving for retirement aren’t complicated: Save 20 percent of your income, invest in low-cost index funds, and don’t touch the money until you reach your retirement age.
Cigarette packs in Australia look different from anywhere else in the world. There are no brand logos, no bright colors. Every pack is the same shade of dull brown, plastered with graphic images showing the health impacts of smoking. There’s the gangrenous foot, mouth cancer, and everyone’s favorite, the creepy sickly eye.
Tobacco companies don’t do this by choice. In 2011, Australia became the first country in the world to pass plain packaging laws that severely restrict what can appear on cigarette packs.
Naturally, Big Tobacco hates these laws and has done everything it can think of to get rid of them. On Friday, Australia defeated a challenge by cigarette giant Philip Morris after a four-year international trade dispute in Singapore.
Big Tobacco is clearly running scared — and it should be. The latest ruling is likely to open the door for plain packaging laws around the world. Already, 11 other countries — including England, New Zealand, France, Brazil, India, and South Africa — have plans to implement their own plain packaging rules.
Other countries, including the United States, should follow Australia’s lead. Plain packaging laws are a simple, cost-effective way to cut smoking rates. That’s why tobacco companies hate them.
Philip Morris exploited an obscure clause in Australia’s free trade agreement with Hong Kong known as investor-state dispute settlement. President Obama’s controversial Trans-Pacific Partnership trade agreement includes an ISDS provision, and it has caused a lot of controversy. Critics worried that big companies — like Philip Morris — could use the ISDS process to overturn countries’ democratically enacted laws.
Australia may have won this round, but its government now faces an estimated $50 million legal bill. And Philip Morris is not the only company to push back against plain packaging laws. In 2012, British American Tobacco (BAT) challenged the laws in Australia’s high court, alleging they infringed the company’s intellectual property. The court ruled in favor of the government.
Eyebrows were raised at the World Trade Organization when Ukraine — a country that doesn’t actually export tobacco to Australia — challenged plain packaging as anti-trade. Later, it was discovered BAT had footed the country’s legal bill.
It’s not clear whether similar challenges from Cuba, the Dominican Republic, and Honduras are also funded by Big Tobacco.
While in public the tobacco giants insist plain packaging laws won’t work, behind closed doors they have spent millions of dollars trying to discredit the laws.
In 2010, a newly formed group called the Alliance of Australian Retailers launched a media blitz criticizing plain packaging. It was a case of "astroturfing" — an attempt to give the impression of a widespread grassroots backlash against the laws that just didn’t exist
Australian investigative journalists unearthed that Philip Morris, BAT, and Imperial funneled more than $5 million into forming the Alliance of Australian Retailers. The group’s argument against plain packaging was distilled into a simple message: "It won’t work, so why do it."

Of course, the obvious response is: If it won’t work, why are you spending millions of dollars to fight it? The alliance wasn’t effective. In fact, one study found for some people the ads increased their support for plain packaging.
The goal of the plain packaging laws is to make cigarettes less attractive and reduce the glamour of smoking. In lab studies, researchers have found they achieve this. More than 20 studies, undertaken over two decades in five countries, strongly suggest that plain packaging increases the impact of health warnings and reduces the appeal of cigarettes.
The laws aren’t a silver bullet to make people stop smoking. Instead, they work alongside higher taxes, public health campaigns, and education to reduce smoking rates over time.
As Australia is the only country to have implemented the laws, real-world evidence on plain packaging is limited. However, there is a growing body of research gathered since the laws were enacted three years ago. While we don’t yet have long-term evidence pointing to changes in smoking rates, short-term shifts seem positive.
A large study in the Australian state of Victoria found that in just 12 months plain packaging both reduced the appeal of smoking and increased desire to quit for adult smokers. Another study found calls to Quitline, an Australian government service to help people quit smoking, rose by 78 percent after the plain packaging laws came into effect. Smoking in outdoor areas, where the graphic packaging is visible to more people, also declined.
British American Tobacco hit back with its own study by Deloitte, which argued health warnings haven’t been effective in reducing consumption of cigarettes. But this study wasn’t independent — it was commissioned and funded by BAT. The study itself admits the researchers were highly selective about what brands they included.
If cigarettes were like any other product, high taxes would be enough to make people stop buying them. But cigarettes are highly addictive, so rising prices don’t have too much impact on a smoker’s decision to buy cigarettes.
It’s estimated that in rich countries, a 10 percent increase in the price of cigarettes will only bring about a 4 percent drop in demand. In poor to middle-income countries, the figures vary quite a bit because of a host of cultural and economic factors. For some though this sizable price bump would reduce demand by just 2 percent.
Of course, smokers could just take their cigarettes out of the packs. They could smoke rollies and put their tobacco in a tin. However, the evidence suggests very few people do. So the plain packs are always there, a graphic reminder of the harms of smoking. It’s a behavioral nudge that smokers carry around with them.
Globally, tobacco kills around 6 million people every year. Smoking costs the US more than $300 billion a year through both direct medical bills and lost productivity. Taxes, education, and public health campaigns are all important in reducing harm. However, Australia has shown that plain packaging needs to be in the mix too. It’s a simple and effective tool in the fight against a deadly habit.
On Wednesday night I went to the London Star Wars premiere. Or, if you want to get technical, I was a very lost tourist caught up in the mass of people trying to catch a glimpse of Carrie Fisher’s dog, Gary.
London’s Odeon Theatre was transformed into a sprawling red carpet, running the length of a city block. A line of luxury cars, each more impressive than the last, stretched as far as you could see towards Piccadilly Circus. Paparazzi swarmed around the entrance of the W Hotel, craning to snap the stars milling around the official preparty.
The scale of the whole thing was overwhelming, but it shouldn’t come as a surprise given the numbers around this release.
The Star Wars franchise has generated more than $32 billion in revenue over the past 38 years. The Force Awakens is expected to be its biggest earner yet, but the film’s fortune won’t be made in the cinema. It will be in the mall, where shoppers are expected to pick up $5 billion worth of merchandise over the next 12 months.
Branded bags of oranges, a $3999 Millennium Falcon kid’s bed and toy lightsabers — these are the real force behind Star Wars.
Back in 2012, Disney bought Lucasfilm — the studio that created Star Wars — for $4.02 billion. The pair’s first foray together, Strange Magic, was released in January this year. It was a total flop, one of the worst ever opening weekends for a widely released film.
But Disney wasn’t worried. Buying Lucasfilm had one purpose: to acquire the rights to Star Wars. It’s the world’s most lucrative franchise, and it has been sitting on the shelf for 10 years since Star Wars Episode III: Return of the Sith.
Star Wars: The Force Awakens is widely expected to be a huge hit for Disney, easily making back its $200 million budget. It’s on track to become the third highest-grossing film of all time, behind James Cameron’s blockbusters Avatar ($2.8 billion) and Titanic ($2.2 billion).
When the Star Wars franchise launched in 1977, it transformed the movie industry. Creator George Lucas suspected that people actually going to see a film in the cinema would represent only a tiny fraction of its potential revenue; the real money would be in merchandise. It was an insight that made Lucas a billionaire.
Back in the early 1970s, Lucas was a young director with just two films on his résumé and a curious idea for an epic space opera. When 20th Century Fox decided to pick up Star Wars, Lucas came back with a deal: He was willing to accept a $350,000 pay cut as director in order to keep the film’s merchandise rights, along with the rights to any sequels.
Not anticipating how popular the film would be, Fox accepted. Lucas is now worth more than $5 billion, having made one of the most profitable bets in history. In the 38 years since Episode IV: A New Hope, Star Wars has grossed $28 billion in revenue. And less than a sixth of this has come from ticket sales.
In buying Lucasfilm, Disney has secured both Star Wars’ film and merchandise rights. Already, the studio has laid out extensive plans to profit from the deal between now and 2020.
There will be two more "saga" films in 2017 and 2019, plus the "anthology" series — three standalone films within the Star Wars universe. The first, Rogue One: A Star Wars Story, is set between Episode III: Revenge of the Sith (2005) and Episode IV: A New Hope (1977) and will be released in December 2016.
Then, of course, there are the collector’s items. Disney has always been good at merchandising, pioneering the practice with Mickey Mouse toys in the 1930s. For the release of 101 Dalmatians in 1996, the studio made deals with more than 130 companies, including McDonald’s and Dr. Pepper.
Disney is already the world’s biggest licensor, selling more than $45.2 billion in 2014. Merchandise is particularly important for the studio in this age of illegal downloading. It’s much easier to torrent a film than a to-scale toy replica of the Death Star.
Disney has made deals with scores of companies to create Star Wars branded products, from CoverGirl to Lego. Hasbro released more than 100 new toys in the lead-up to the release of The Force Awakens. Walmart announced it would carry more than 500 products in store and thousands more online.
How much does the studio stand to make? It’s estimated that for every branded item sold, Disney takes a cut between 10 and 15 percent. Star Wars merch is expected to bring in $5 billion in sales over the coming 12 months, rising to as much as $20 billion in the next five years.
While the typical image of a Star Wars collector is a fanboy, women are a big focus of The Force Awakens’ merchandise campaign. This is likely the effect of two forces — the popularity of the new film’s heroine Rey and a growing awareness of the female market.
CoverGirl has released a Star Wars–branded makeup collection, Hot Topic has a clothing line. In one Walmart ad, a young girl plays with Star Wars toys as her mom asks why the princess doesn’t let boys rescue her. "Because she’s a modern, empowered women," the girl replies, "unfettered by the antiquated gender roles of a bygone era." It has been viewed nearly 21 million times.

China’s maturing market also offers big opportunities for Disney. This month, the studio’s chair, Andy Bird, pitched Star Wars: The Force Awakens–branded merchandise to more than 800 Chinese cinema owners, opening the door to millions of potential collectors.
At the moment, box office takings still account for around 80 to 90 percent of film revenue in China. Over the next few years, though, it’s expected the country will come to account for a huge chunk of the $241.5 billion in global annual licensed merchandise retail sales.
While there’s been a lot of focus on Star Wars products, building excitement around the film and actually getting people into cinemas is still vitally important. If you’ve stepped outside your house in the past few weeks, you would’ve seen Star Wars everywhere — on billboards as you walk to work, TV ads, radio spots, endless articles analyzing the teaser trailers as you scroll through Facebook. Disney didn’t get all that hype for free.
The average global marketing budget for a "tentpole" film (a release whose profits fund smaller productions) is around $100 million. Building hype overseas is increasingly important for blockbusters. Since 1999’s Phantom Menace, the franchise has been making more money overseas than at the US box office.

Long before Star Wars was on every billboard, though, Disney started building hype for the merchandise. In September, the film’s YouTube channel hosted a worldwide "unboxing," where fans in 12 countries unveiled the new toys via live stream. This came just ahead of Force Friday, the first release of official Force Awakens merch.
Much like the film’s plot, the tie-in merchandise was shrouded in secrecy, protected by nondisclosure agreements between Disney and its retail partners. What we do know is that companies making Star War–branded merchandise have already smashed the previous advertising record of $26.5 million spent to promote Minions.
Subway and Dodge have both released ads. Duracell’s "Fight for Christmas Morning" has been viewed 15 million times on YouTube. The ubiquitous Star Wars ad even earned itself a spoof on Saturday Night Live.

Star Wars merchandise occupies a unique position in the film world. Don’t get me wrong — there are certainly some ghastly offerings. Suggestive C-3PO tape dispenser, anyone?

But on the whole, the Star Wars merchandise isn’t foisted on fans; they covet it. It’s this love that Disney will be riding all the way to the bank. It’s just a bonus the film is pretty great as well.
Martin Shkreli became one of the most hated men on the internet back in September when he raised the price of an essential drug, Daraprim, more than 5,000 percent. Shkreli seemed to revel in his notoriety, firing taunts right back at people who attacked him on social media.
This morning, federal officials arrested the entrepreneur at his apartment in Manhattan. And it appears the charges have nothing to do with the Daraprim price hike that made him infamous online.
Instead, Shkreli is charged with defrauding his investors. According to the federal indictment, Shkreli moved funds between companies he co-founded under false pretenses, effectively stealing millions from the investors of one company in order to settle legal disputes involving another company.
It’s a sudden and shocking downfall. And he’s not likely to get much sympathy from his legions of online haters.
Rich Howells" data-chorus-optimize-field="main_image">

Rich Howells">
Martin Shkreli. (Rich Howells)
Toxoplasmosis is a parasitic disease. It’s harmless in healthy people, but in those with weakened immune systems it can cause headaches, fever, fatigue, and seizures. Expectant mothers are particularly at risk, as toxoplasmosis can cause miscarriage.
Back in 1953, Nobel Prize–winning American scientist Gertrude Elion developed a drug called Daraprim, which can treat both toxoplasmosis and malaria. It’s included in the World Health Organization’s List of Essential Medicines — the basics required for any health system.
Until recently, Daraprim wasn’t very expensive. In 2014, a single pill cost $13.50 in the United States. Then a Shkreli company, Turing Pharmaceuticals, came onto the scene. Shkreli bought up the rights to Daraprim and immediately jacked up the price to $750 per pill.
The extortionate move caused national uproar. Unlike in the UK and Europe, US law allows drug companies to set their prices with little regulation. But that didn’t mean people had to like it.
Bernie Sanders publicly refused a $2,700 campaign donation from Shkreli. Donald Trump called him a "spoiled brat." People began to label him the "pharma bro." He’s become so toxic even PhRMA, the biotech industry group, has distanced itself from him.

.@TuringPharma does not represent the values of @PhRMA member companies.


Shkreli seemed to revel in this hatred. After Hillary Clinton criticized Daraprim’s pricing, he simply tweeted back, "lol."
He’s bragged about being the world’s most eligible bachelor and taunted DC lawmakers.

50-100 date solicitations a day for me, the world's most eligible bachelor. Sorry, but you have to be a shareholder to meet me.



In DC. If any politicians want to start, come at me. pic.twitter.com/YrxWoSPQ1H



(Isaiah Trickey/FilmMagic)
Earlier this year, the seminal rap group Wu-Tang Clan finished their seventh album, Once Upon a Time in Shaolin. A single copy of the recording was made, 31 new songs presented in a hand-carved wooden box with a price tag of $2 million.
"We’re about to put out a piece of art like nobody else has done in the history of music," RZA told Forbes. "We’re making a single-sale collector’s item. This is like someone having the scepter of an Egyptian king."
The album was sold through Paddle8, an online bidding agency, which organized private listening parties for prospective buyers in New York. When the buyer’s name was kept anonymous, fans speculated it might have been Quentin Tarantino.
No one was excited when it was revealed the buyer was Shkreli. It’s reported his favorite Wu-Tang song is "C.R.E.A.M," which stands for "Cash Rules Everything Around Me."

Private album just for me. Who's next?


Shkreli is supposedly yet to listen to the album, saving it "for a rainy day." RZA has given away most of his proceeds from the sale in protest of Shkreli’s business practices.

Within 10 years, more than half of all rap/hip-hop music will be made exclusively for me. Don't worry--I will share some of it.


While the public hatred was mostly focused on Shkreli’s arrogance and greed, it’s his creative accounting that may prove his real downfall.
Early Thursday he was led from his apartment in handcuffs, charged with misusing $11 million in company funds from Retrophin, a biopharmaceutical company he founded in 2011.
In September 2014, Retrophin dumped Shkreli as chief executive
Before he became a notorious pharmaceutical executive, Shkreli was something of a Wall Street wunderkind. Starting as an intern at Mad Money host Jim Cramer’s hedge fund at age 17, he worked his way up to found three companies in his mid-20s — Elea Capital Management, MSMB Capital Management, and MSMB Healthcare. Then at just 28 years old, he shifted to pharmaceuticals, launching Retrophin.
In September 2014, Retrophin dumped Shkreli as chief executive and launched an investigation into his actions at the helm. Shkreli then founded Turing, the firm whose extortionate pricing for Daraprim made him famous. Meanwhile, Retrophin’s board found that Shkreli had used company funds to settle the debts of MSMB, which he’d left in financial ruin.
According to the federal indictment unsealed on Thursday, Shkreli and his outside counsel Evan Greebel orchestrated "three interrelated fraudulent schemes" between September 2009 and September 2014. The pair allegedly defrauded investors in MSMB Capital and MSMB Healthcare, before using funds from Retrophin to pay off both companies' debts.
In a filing with the Securities and Exchange Commission, Retrophin reported that Shkreli had used Retrophin funds to pay off former MSMB investors, as well as to settle personal lawsuits. According to the company, Shkreli fraudulently reclassified a $900,000 investment MSMB made in Retrophin as a loan. Shkreli then allegedly had Retrophin pay this "loan" back to MSMB — enabling the hedge fund to use the money to settle one of its many legal disputes. And while Shkreli founded both companies, that doesn’t give him the right to shift money between them without consent from the companies’ boards.
Between September 2013 and March 2014, 612,500 company shares were issued to former MSMB investors. While Shkreli described them as "consulting agreements," Retrophin now says that was a ruse. Rather, their purpose "appears to have been to settle and release claims against the MSMB Entities or Mr. Shkreli personally, and not to provide meaningful and sustained consulting services to the Company."
In August this year, Retrophin sued Shkreli for $65 million. The former chief quickly shot back, demanding $70 million from the firm and citing damage to his image as a businessman.
Even before Retrophin announced the findings of its internal investigation of Shkreli, there had been a criminal investigation underway by the US Attorney for the Eastern District of New York.
In January, Retrophin received a subpoena requesting "information regarding, among other things, the Company’s relationship with the MSMB Entities and Mr. Shkreli." In its SEC filings Retrophin made it clear that Shkreli, not the company itself, was the focus of the criminal investigation.
Share prices of KaloBios Pharmaceuticals, a company Shkreli recently acquired a majority stake in, fell 50 percent today before Nasdaq halted its trading indefinitely. Shkreli and Greebel, who was also arrested, are yet to comment or tweet about the charges.
On the internet, people have been having fun with Shkreli's arrest:

Martin Shkreli's bail was going to be set at $500,000 but they raised it to $27,500,000 just for him.

The basic dilemma facing the Federal Reserve is this: Low interest rates promote economic growth but create the risk that the economy will "overheat" with too many dollars chasing too few actual goods and services — causing inflation. Today, the Fed announced it was raising rates for the first time since 2006, signaling that it is starting to worry more about inflation and less about jobs and growth.
The weird thing about this is that the Fed's own forecasts show inflation getting lower, not higher.
Today, as it does every quarter, the Fed released a document showing how the people on the Fed's Open Market Committee — which makes the Fed's interest rate decisions — predict various economic variables will change in the next few years. And the latest projections show something surprising: The Fed's decision-makers have revised their projection for 2016 inflation down. In September, the Fed thought inflation would be 1.7 percent in 2016. Now the central bank thinks it will be just 1.6 percent.
Obviously that's a small difference, but it's also a telling one. The Fed is raising rates because it's worried that keeping rates low for too long will cause inflation to "overshoot," rising significantly above 2 percent and forcing the Fed to raise rates rapidly to keep inflation under control.
Yet the Fed's own actions tell a different story. In September, Fed officials projected that inflation would be only 1.7 percent in 2016, so it kept rates low. Now the Fed thinks that inflation will be even lower — 1.6 percent — in 2016, yet it's raising rates anyway.
This doesn't make sense.
Suppose you're riding a bus from Washington, DC, to New York, and you want to know if the bus will stop in Philadelphia. If the passenger next to you says the bus is going to stop in Philadelphia, that's a projection. But if the driver of the bus tells you the bus is going to stop in Philadelphia, it doesn't make sense to call that a projection — the driver is just announcing a decision he's made.
The same point applies to the Fed. The Fed has a ton of influence over future inflation rates, so its "projections" aren't really projections at all; they're statements about the Fed's own priorities. If the Fed raises rates at the same time it "projects" that it's going to miss its inflation target by even more than previously expected, that's a signal that the Fed isn't actually serious about hitting the target.
The Fed has been consistently overestimating inflation rates for several years. At the final meeting of 2012, Fed decision-makers projected that "core" inflation — excluding volatile food and energy prices — would be at least 1.8 percent in 2015. That was revised downward to 1.6 percent in 2013 and 1.5 percent in 2014. Now it looks like core inflation will be 1.3 percent in 2015.
Scott Sumner, an economist at the Mercatus Center, argues that if the Fed is serious about reaching a 2 percent inflation target, it needs to act like it's serious.
"If they could craft a clear statement of what they're trying to do, I think that would help," he says. He argues that if the Fed announced that it won't raise rates again until policymakers are confident that they'll actually hit the 2 percent goal, that would actually boost the economy and help the Fed hit its own target.
It might seem like this doesn't matter very much — 1.3 percent isn't that different from 2 percent, and no one likes to see prices go up anyway.
But low rates don't just produce more inflation; they also produce more job and wage growth. Low rates encourage businesses and consumers to borrow and invest, generating more demand for products and services. Companies respond to that demand by hiring more people. As the labor market tightens, employers are forced to offer the employees raises.
That kind of economic boom would be good for almost everyone. The main downside is that it could produce too much inflation. But right now, inflation is at its lowest level in decades, suggesting that the Fed has an opportunity to boost the economy without creating dangerous inflation. And the Fed is blowing it.
At 2pm, the Federal Reserve made it official: it is raising a key interest rate for the first time since 2006. The move was widely expected, but it also remains somewhat controversial, because critics say it could hamper a still-anemic recovery.
Arguments about Fed decisions tend to get pretty deep pretty fast. What tends to get lost in the shuffle are the most fundamental and important issues: that a somewhat obscure government agency exercises enormous control over the economy by changing the price of money at regularly scheduled meetings.
Since the state of the economy ends up influencing everything from your ability to get a new job to the outcomes of presidential elections, that makes these meetings one of the most important events on the calendar. Yet they're rarely discussed outside specialist circles except by the occasional crank, leaving ordinary people in the dark.
An interest rate is the price lenders charge to borrowers to use their money. An interest rate of 5 percent means that someone borrowing $1,000 will have to make interest payments of $50 per year — in addition to eventually paying back the amount that was originally borrowed.
There are different interest rates for different types of lending — home mortgages, business loans, credit cards, and so forth.
But when economists talk about the Fed "raising interest rates," they're referring to a specific rate called the federal funds rate. That's the rate big banks charge one another for short-term loans.
The way the Fed manipulates the federal funds rate has broad economic effects
People often talk about the Fed "setting" this interest rate, but that's not quite accurate. What happens is that the Fed announces a target for the federal funds rate and then uses its ability to create or destroy money to reach its target.
Of course, these actions don't only affect the federal funds rate. When the Fed pushes the rate up or down, it tends to push other interest rates in the same direction as the federal funds rate. So ultimately, the Fed's interest rate decision will have an impact on the rates you pay the next time you borrow money — whether it's with a mortgage, an auto loan, or a credit card purchase.
By itself, the federal funds rate isn't especially important to anyone but bankers. However, when the Fed manipulates the federal funds rate, it can have broad economic effects.
Money is an essential fuel for economic activity
This is often described mechanically, as a question of the interest rates spurring or strangling economic activity. For example, if mortgage rates rise, it becomes harder for people to buy new houses, which can hurt employment in the construction industry. If interest rates for business loans go up, it becomes harder for companies to finance the construction of a new factory. And so forth.
That's all true, but it can also introduce confusion because causation can move in the other direction. When economic activity is robust there's a lot of demand for loans, which can pull interest rates up. And focusing too much on specific lending markets can obscure a more fundamental point about why the Fed's decisions matter: Money is an essential fuel for economic activity. Recessions happen when people spend less than they did before. Booms happen when people spend more. So all else being equal, putting more money into people's pockets is going to produce more demand for companies' products, more economic activity, and more jobs.
At every meeting since 2008, the Fed has decided to keep interest rates near 0 percent.
But this time, the Fed announced that it would raise its target for the federal funds rate to 0.25 percent. That's the first interest rate hike since 2006.
At the same time, it issued a statement signaling that it won't do further rate hikes too quickly, giving the economy more room to grow.
If low interest rates are so good for the economy, you might be wondering why they should ever be increased. The reason is that pumping more money into the economy only works up to a certain point.
During a recession, there are a lot of idle resources. People are unemployed, factories are producing below their maximum capacity, trucks and ships sit empty a lot of the time, and so forth. In that situation — the kind of situation we had in 2001 and 2009 — getting people to spend more will mobilize idle resources and boost the real output of the economy.
The traumatic inflation of the 1970s looms large in the minds of senior Fed policymakers
But during an economic boom, things look different. With few idle resources sitting around, there's no way for more consumer spending to translate to more output. If the Fed cuts rates during a boom, the result is likely to just be that prices go up — inflation — without generating much economic growth.
That's what happened in the late 1970s. The Fed kept interest rates too low for too long because it feared that higher interest rates would be economically harmful. That produced double-digit inflation that created chaos for many Americans.
The traumatic inflation of the 1970s looms large in the minds of senior Fed policymakers, most of whom are old enough to remember it firsthand. They're determined not to repeat the mistakes of their predecessors and let inflation get out of control.
The theoretical case for raising rates to ward off inflation is strong. But the case for raising rates right now runs into a huge problem: Inflation is really low right now. It's been low since 2008, and market forecasts suggest that it will continue to be low over the next decade.
Like many countries around the world, the Fed has set an inflation goal of 2 percent. Yet over the last year, prices — as measured by the consumer price index — have increased by just 0.5 percent. That's mostly because oil prices have been falling; if you exclude volatile food and energy prices, the inflation rate is 2 percent — exactly in line with the Fed's target. Another inflation measure that's a favorite of the Fed's, called the core personal consumption expenditure index, currently stands at 1.3 percent — below the 2 percent target. Moreover, markets are projecting that the average inflation rate will be below 2 percent over the next decade.
If inflation shows signs of picking up, the Fed can always raise interest rates later
And while the economy has been doing pretty well, there's reason to think it could be doing better. True, the unemployment rate is down to 5 percent, not too far from what economists regard as the full-employment level. But the labor force participation rate — the fraction of all adults participating in the labor force — is close to a 30-year low, suggesting that an economic boom might draw more people into the labor market. The economy has been growing at a respectable but not spectacular rate, and wages have barely been growing faster than inflation.
We don't know if keeping interest rates low will boost economic growth. But given that the inflation rate is actually below the Fed's target, it seems there's not much risk in giving it a try. If inflation shows signs of picking up, the Fed can always raise interest rates later.
People have made a number of arguments in favor of raising interest rates, but on some level they all boil down to the view that seven years of ultra-low rates is unnatural.
Prior to 2008, it had been many decades since the federal funds rate was zero, and a lot of people find the current interest rate environment deeply unnerving. As Vox's Matt Yglesias has written, there's a widespread view that zero percent interest rates are a kind of life-support measure for the economy. Now that the patient is recovering, people think, we should remove the breathing tube so he can get back to breathing normally.
What happens if we keep the patient on zero-percent-interest life support? As we've seen, people normally worry that low interest rates will generate high inflation. And in the first few years after the Fed slashed rates in 2008, a lot of people warned that inflation was just around the corner. But after seven years of low interest rates and low inflation, those fears have started looking a bit silly.
So today, advocates of higher rates mostly focus on bubbles. A good example is Sen. Rand Paul (R-KY), son of longtime Federal Reserve critic, gold standard advocate, and former Rep. Ron Paul (R-TX). The younger Paul co-authored an op-ed for the Wall Street Journal in September blaming low interest rate policies over the past 20 years for the stock market bubble of the late 1990s and the real estate bubble that popped in 2007.
In Paul's view, prolonged periods of low interest rates encourage people to make risky, unsustainable investments. Recessions, in his view, are a painful but necessary process that purges the economy of bad investments. When the Fed keeps rates "artificially" low, it merely prolongs the day of reckoning and allows these bubbles to get bigger than they otherwise would have gotten. Hence, because the Fed tried to cushion the 2000 stock market crash with low interest rates, we got an even bigger crash in 2008. Paul predicts we'll have a third crash — perhaps even bigger than the previous two — as a result of current Fed policies.
But this argument doesn't explain how to tell whether rates are "too low." The federal funds rate was around 5 percent in the late 1990s — that was low relative to the previous couple of decades, but it was actually higher than rates for most of the 1950s and 1960s. There's widespread agreement among monetary hawks that monetary policy should be more "normal" — i.e., not zero — but little clarity about how high rates need to be to avoid bubbles or other financial calamities.
Sure thing. Listen to the classic Dire Straits song "Money for Nothing."

The song is written from the perspective of ordinary workers who envy rock stars on MTV who get "money for nothing and the chicks for free." Meanwhile, regular guys have to "install microwave ovens," do "custom kitchen deliveries," and move refrigerators and color TVs.
Obviously, monetary policy is never going to remedy this kind of inequality. Someone has to install microwave ovens and do custom kitchen deliveries, so we're never going to live in a world where everyone gets to enjoy the perks of being a rock star full-time.
But there's still a lot monetary policy can do to help those guys wrangling refrigerators and color TVs. For most of the past seven years, it was hard for regular guys (and girls) to earn a living even if they were willing to do unglamorous work like installing microwave ovens. Pumping money into the economy couldn't turn those guys into rock stars, but it did generate economic activity and make it easier for them to find jobs.
And while the labor market is a lot better than it was a few years ago, there's still room for improvement. Wages for low-end workers have been stagnant for more than a decade. If we had a few years of tight labor markets — like we had in the late 1990s — ordinary workers would have more bargaining power. Many would get raises. That's why the guys who do custom kitchen deliveries might want to root for the Fed to keep interest rates low.
It's certainly true that seven years of zero percent interest rates was historically unusual. But whether recent Fed policies have been too tight, too easy, or just about right is open to debate.
There's a lot monetary policy can do to help those guys wrangling refrigerators and color TVs
It's helpful to think about a time when the Fed was in a very different situation. The late 1970s was a period of high interest rates. By the start of 1979, the federal funds rate had risen above 10 percent.
Yet inflation soared, reaching a high of 14.8 percent in March 1980, and it stayed above 10 percent until well into 1981. That's a sign that even the historically high rates of early 1979 weren't enough to keep inflation under control. With interest rates above 10 percent, monetary policy might have seemed tight, but it was actually too loose. As it turned out, the Fed had to let rates go as high as 19 percent in 1981 in order to get inflation under control.
Interest rates were high because the market was factoring high expected inflation into interest rates. If you lend money at 10 percent but the inflation rate is 12 percent, you're actually losing money! So the "natural" interest rate — the rate that struck the best balance between inflation and recession — was abnormally high.
Today we're in the opposite situation. Inflation expectations are low. The US population and economy are growing slowly, which limits demand for credit. And that means the natural rate of interest may be a lot lower than it was three or four decades ago.
The US isn't alone here. Interest rates are low across the developed world. Japan has had short-term interest rates near zero for two decades. The eurozone, the United Kingdom, Canada, and Australia all have interest rates at their lowest levels in decades.
And the experience of the eurozone suggests this isn't really the fault of central banks. As economist Scott Sumner has pointed out, the European Central Bank tried raising rates in 2011, believing the worst of the recession was over. The result was a double-dip recession that quickly forced the ECB to bring rates back down.
The US economy is now stronger than the Eurozone was in 2011, so this week's rate hike probably won't trigger a recession. But the low rates of the past few years aren't really the doing of central banks. Central banks are just reacting to market signals — cutting rates when unemployment rises, raising them when inflation becomes a problem — and the result has been historically low interest rates.
The Fed and other central banks have been setting interest rate targets for so long that a lot of people think of monetary policy and interest rate changes as synonymous. But there's actually no law requiring the Fed to do monetary policy this way. Fundamentally, the Fed conducts monetary policy by creating money and buying stuff with it. There's no reason the amount of money they create needs to be determined by an interest rate target.
One example of this was between 2008 and 2014, when the Fed engaged in a technique called quantitative easing. The federal funds rate had already reached zero, so the Fed couldn't drive it any lower. But the Fed still wanted to do more to support an economy that was in a major recession. So the Fed just announced that it was going to create a certain amount of money every month. It worked fine, and many economists believe it helped speed the economic recovery over the last seven years.
Still, quantitative easing has two big disadvantages. One is that it's pretty ad hoc. It's hard for the Fed to know how much money to print or how long the money-printing process should go on.
The even larger problem, though, is political. Because the Fed's "normal" monetary policy approach is to target interest rates, quantitative easing generally gets labeled "unconventional" or "extraordinary" — even though the actual mechanism of printing money and buying government securities is very similar in both cases. This tends to create a political backlash and make the Fed reluctant to use QE as forcefully as might be appropriate.
The Fed twice halted its bond-buying programs — once in 2010 and again in 2012 — before bad economic news forced them to restart them. This tentative approach may have hampered the economic recovery.
A different approach would be to stop targeting interest rates and instead directly target a variable the public cares about, such as the growth of total spending in the economy. In an approach known as nominal GDP targeting, the Fed would commit to printing enough money so that total spending in the economy grows at 5 percent per year.
The Fed's interest rate decisions might seem pretty remote, but they can actually have a big impact on every American. When the Fed keeps interest rates low, it means there will be more money flowing through the economy, which is likely to mean more economic activity and more jobs.
By itself, this week's 0.25 percent rate hike isn't going to have a big impact on the US economy. But it's significant because it could signal the start of a sequence of interest rate hikes that could have significant effects on the economy. The Fed has tried to mollify those fears with a statement signaling that it won't raise rates too quickly in the future.
Of course, if the Fed keeps rates low for too long, the economy could overheat, producing inflation. But right now there just isn't much evidence that the economy is overheating. The inflation rate is well below the Fed's 2 percent target, and the economy has been adding jobs more slowly than in previous economic expansions.
So if you'd like to see the economy grow more quickly, unemployment fall, and wages rise, then you might see this week's decision to raise rates as premature. In contrast, if you're most worried about inflation, you should be happy that the Fed has started to raise rates — just to be on the safe side.
After seven years of keeping a key interest rate near zero percent, the Federal Reserve has voted for a rate increase. The decision signals the central bank's growing confidence in the economy.
The Fed is raising its target for the federal funds rate — the rate banks charge when they lend money to one another — from 0 percent to 0.25 percent. By itself, that modest increase isn't going to have a big impact on the American economy. But the move is significant because it's widely seen as the first step in a longer sequence of rate increases over the next couple of years.

In a statement accompanying the rate increase, the Fed tried to signal that it would not move too quickly on further rate increases. "The stance of monetary policy remains accommodative after this increase, thereby supporting further improvement in labor market conditions and a return to 2 percent inflation." In plain English, the Fed is worried that moving too quickly could strangle the still-fragile economic recovery.
An obscure federal agency raising an obscure interest rate might not seem like big news. But Fed decisions have broad impacts on the US economy.
What really matters here isn't the fact that a particular interest rate is going up — it's the way the Fed is going to accomplish the interest rate hike. The Fed has the power to create or destroy money at will, which allows it to make cash more scarce (pushing up the amount of money people will pay to borrow it) or more plentiful (pushing interest rates down). For the past seven years, the Fed has been flooding the market with cash in the hope that this will boost the economy. Now the Fed is starting to reverse course.
So when the Fed raises its target rate, what it's really doing is signaling that it's going to make cash scarcer across the entire economy. That is likely to push up the interest rates on other loans — mortgages, car loans, credit cards, and so forth. It's also expected to have broad economic effects, slowing the rate at which the economy grows and creates jobs.
Indeed, in a sense this is the point of the rate hike: The Fed is worried that keeping rates too low for too long will trigger inflation, or possibly another bubble like the real estate bubble of 2007 and the technology bubble of 1999. By starting to tap on the brakes now, the Fed hopes to head off an overheated economy before it happens.
The weird thing about this is that inflation is actually below the Fed's 2 percent target. It's been below target for most of the past seven years, and markets expect the rate to  continue to be below target, on average, over the next decade. So arguably, the Fed is exacerbating a real problem — sluggish job and wage growth — to deal with a problem that has yet to materialize.
While most of the media coverage so far has focused on whether the Fed would raise rates at this week's meeting, the more important question is what the Fed does in the future — and what it says about its plans in the statement it releases with the announcement.
When businesses, venture capitalists, and others make investment decisions, a big factor they consider is the likely rate of future economic growth. If they expect a big boom over the next couple of years, they're more likely to make investments now to capitalize on the healthy economy. And one big factor shaping the economy's future growth is the Fed's interest rate decisions.
And that means that the Fed's statements about future interest rate hikes can have a significant impact on the economy now. The Fed's relatively dovish statement — signaling that its policy "remains accommodative" — is a signal to investors that they shouldn't be too spooked by a quarter-point rate increase. The Fed might have raised rates this week, but it's not going to do further increases too quickly.
When I bought a house back in June, my lender encouraged me to lock in our interest rate quickly because mortgage rates couldn't stay so low — they were around 3.85 percent at the time — for much longer. Six months later, the average mortgage rate in the Washington DC area is still 3.85 percent.
People have been predicting imminent rate hikes for years: Rates were said to be about to go up in 2013, in 2011, and in 2009. In 2010, a New York Times columnist predicted that "interest rates have nowhere to go but up." Mortgage rates are now lower than they were at the time any of those articles was written.
It's not too surprising that people were fooled. If you compare today's rates with those that prevailed in the 1970s, 1980s, or 1990s, they look freakishly low. But the New York Times's Neil Irwin points out that if you take a longer-term perspective, today's low rates don't look so anomalous:
The interest rate on 10-year government bonds is currently 2.2 percent, about the same as it was in the 1930s, 1940s, and 1950s. If you take this longer perspective, the high interest rates of the past few decades look like the anomaly, and today's 2.2 percent rate looks like a return to normal.
Irwin argues that this is mostly about inflation. When inflation is high, people demand higher interest rates to compensate for the declining value of the principal. So when inflation skyrocketed in the '70s, interest rates skyrocketed too — and fears that inflation would return kept rates high throughout the '80s and '90s, even as inflation fell. Only recently have interest rates returned to a more historically normal level.
Irwin is clearly right that low inflation is an important reason for interest rates to be low. But another big factor is the changing demographics of the American economy.
Many factors contribute to interest rates, but on the most fundamental level they reflect a market judgment about how much opportunity there is to generate future wealth from present-day investments.
When the economy is growing quickly, there are lots of ways to turn dollars into productive assets — factories, roads, houses — which can then generate wealth in the future. So the competition for investment dollars is strong, and interest rates rise.
On the other hand, if tomorrow's economy won't be much bigger than today's, then we'll be able to serve most of our needs with the factories, roads, and houses we already have. So few people will want to borrow and invest, pushing interest rates down.
Japan's population has actually been falling the past few years
We can't say exactly how fast the economy is going to grow over the next few decades, but one thing we can be pretty sure about is that the US population is going to be growing more slowly. In the 1960s, investors could look forward to a future with many more people — and many more potential consumers — than there are now. Today, that's not as true. The US population is still growing, but thanks largely to falling birthrates, it's growing at about half the rate it did in the mid-20th century.
And the population growth rate has fallen even more in other rich countries. Japan has 127 million people, barely more than the 124 million it had in 1990, and its population has actually been falling the past few years. Italy has 61 million people, just 7 percent more than the 57 million who lived there in 1981.
If your country's population has stopped growing, there's little point in building a bunch of new houses, stores, or office buildings. There's less need for new roads, schools, or other infrastructure. Of course, you'll still need to spend some money repairing or replacing facilities that become obsolete or worn out, but the total amount of investment spending is going to be a lot lower.
It's not a coincidence that Japan — the rich country with the biggest population slowdown — has also been stuck in a low-inflation, low-interest rate, low-growth rut for longer than other rich countries. It's hard for a country with a shrinking workforce to have a growing economy, and without economic growth there's little demand for borrowing.
On the other hand, Australia is one of the world's fastest-growing rich countries. Over the past 20 years, Australia's population has grown 33 percent — about the same as the US growth rate between 1950 and 1970. And it's probably not a coincidence that Australia (blue line) has higher interest rates than the United States (green), while Japan's (red) interest rates are lower.
The United States still has a growing population and a growing economy. But both are growing more slowly than in decades past, and as a result we're experiencing a milder version of Japan's doldrums. One symptom of that is lower interest rates. And since America's low population growth isn't likely to change any time soon, its low interest rates may not either.
A lot of people have pointed to the Federal Reserve as the cause of today's low interest rates, but the Fed has less power than people think. It's true that the Fed controls short-term interest rates, and is expected to raise those rates this week for the first time in nine years.
But long-term interest rates are controlled by the market, not directly by the Fed. And in practice, the Fed's ability to raise even short-term rates are constrained by market conditions. If the Fed raises rates too high or too quickly, it will trigger a recession, forcing the Fed to cut rates once again. So in practice, broad economic trends, not the whims of Fed Chair Janet Yellen, are the main reason interest rates are so low.
Everybody hates Comcast. The cable giant consistently ranks last or near last among all companies on consumer satisfaction surveys. Hurling insults at Comcast — its prices, its speeds, its customer service — has risen nearly to the level of a national pastime.
But what if there's nothing the company can do to change its customers' minds? What if most of what people hate about Comcast has its roots in the structure of America's cable market?
That's what the company's CEO, Brian Roberts, suggested last weekend when asked about the company's poor record in an interview with Business Insider founder Henry Blodget.
Roberts argues that people might hate Comcast, but they hate other cable companies too:
We're with all the other cable companies, within spitting distance of each other. As a group, that is what the results show.
Like... "Well, your people didn’t show up on time" and therefore let’s fix that and will that actually change the score and suddenly we’re the best company in America? Google’s free. Facebook is free. We charge, and we collect for every piece of content rights. Every movie star. Every athlete. Every possible piece of content we pay.
We’re up to well in excess of $13 [billion] to $14 billion a year at this one company to procure that content on behalf of the consumer, and it’s grown on average as an industry about 8% to 12% a year compounded for a decade. If you drop a channel, you’re incredibly unpopular, and if you pass along a rate increase, you’re incredibly unpopular.
The problem isn’t Comcast’s service, Roberts is saying; it’s that people have to pay for it. Comcast operates by striking deals with content creators and publishers — ABC, CBS, FOX, ESPN, HBO, and the rest — for the right to broadcast their shows, movies, football, baseball, and basketball games. And as Roberts said, it doesn’t come cheap.
And there’s not much the company, or other cable companies, can do about that, in Roberts's view, because content companies have too much leverage.
One problem with Robert’s argument is that Comcast makes money too — a lot of it.
In 2014, it brought in nearly $69 billion in revenue, with $14.9 billion of that being operating income, a.k.a. profits.
So, yes, Comcast has to charge its customers, but it could charge them less if it wanted to. It could also invest more heavily in more and better-trained customer service workers. It could boost those data caps that customers are always complaining about.
To be fair, elsewhere in the interview Roberts described some of the company’s plans to improve its customer service, including an Uber-like tracking system for Comcast’s technicians.
But he seems to believe that it may just never be enough. No matter how hard Comcast tries to make its customers happy, they still wind up disgruntled. Customers just can’t stand paying for things, and the only way Comcast could really earn their love is by giving away its product, as Google and Facebook do.
The problem with this argument is that most companies do charge for their products, and few if any are as hated as Comcast. Indeed, the cable TV industry’s upstart rivals — Netflix, Hulu, Amazon Prime — charge their customers as well.
And customers don't hate Netflix the way they hate Comcast. In 2014, Comcast scored a 54 out of 100 on the American Customer Satisfaction survey — down from 64 in 2001. On the same survey, Netflix came in at 81. In eight years of measurement, it's never dropped below a 74.
One reason for this: Online streaming services charge a lot less. Netflix’s basic service costs $7.99 a month, as does Hulu’s. Comcast’s "digital starter" TV package, which doesn’t include premium channels like HBO, costs $49.99.
On the other hand, some companies charge a premium while still earning high marks, because their products are great. For instance, iPhones are way more expensive than a lot of Android-based smartphones, yet they’ve earned fanatical customer loyalty.
So maybe Comcast can’t please its customers. Maybe it’s doomed to its abysmal Yelp reviews and a rock-bottom reputation. But it could probably try a bit harder too. Who knows?
Disclosure: Comcast is an investor in Vox Media, the parent company of Vox.com.
Serial, one of the most popular podcasts of all time, returned last week with an episode chronicling the capture of Bowe Bergdahl, a US service member imprisoned for five years by the Taliban.
The show’s first season — a deeply researched reinvestigation of the 1999 murder of Hae Min Lee, a Baltimore teenager, and the subsequent trial and conviction of her ex-boyfriend, Adnan Syed — put podcasting on the map. Host Sarah Koenig, long of This American Life, narrated lengthy, penetrating interviews with Syed himself, speaking from prison, as well as painstaking recapitulations of every detail of evidence and testimony.
It made for gripping storytelling, and listeners ate it up. As of March of this year, the show’s first season’s 12 episodes had been downloaded a total of 75 million times. And that was part of a broader trend: Podcasting is becoming a mainstream phenomenon.
About 17 percent of Americans 12 or older, about 46 million people, listened to a podcast in the past month, up from 12 percent in 2013.

The medium is taking off now because of the happy convergence of three big trends. The technology has finally improved enough that listening to podcasts is easy and convenient for ordinary listeners. Talented professionals — many of them veterans of NPR or other radio outlets — have begun to focus on the medium. And a new generation of podcast-focused businesses are figuring out how to convert these professionally produced, popular podcasts into serious money.

raneko" data-chorus-optimize-field="main_image">

raneko">
The old and busted way to listen to podcasts. (raneko)
Podcasting has been around for about a decade — the term is a reference to the iPod, which older readers will remember as an iPhone that only played music. But while the idea of listening to music on an iPod quickly became popular, it’s taken a lot longer for the concept of listening to podcasts to catch on.
A big reason for this is that downloading podcasts to an iPod or other MP3 player was cumbersome. Typically, you had to subscribe to podcasts on your computer, download episodes, transfer the episodes over to your iPod player using a USB cable, and then listen to the episodes on your iPod.
And you’d have to repeat this ritual every time new episodes came out, which might happen every day, week, or longer. Most users simply didn’t have the patience for this. Some people listened on their computer; many didn’t listen at all.

The wide adoption of smartphones with mobile internet capabilities, beginning around 2010, removed these hurdles. Only 10 percent of Americans owned smartphones in 2009. This year, that number has jumped to 71 percent. Fans gained the power to tune in to podcasts much like they tuned in to radio shows, instantly, wherever they happened to be.

New software platforms like Stitcher, Overcast, and Castro, along with Apple's own undeletable Podcasts app, have emerged in recent years, making the process of aggregating, downloading, and streaming podcasts even easier.

Podcast listeners have migrated to mobile in droves. In just one year, from 2013 to 2014, the percentage of listeners who said they primarily listen on smartphones, tablets, and portable audio players rather than on a computer jumped from 34 percent to 51 percent.


Charles Wiriawan" data-chorus-optimize-field="main_image">

Charles Wiriawan">
(Charles Wiriawan)
The thing that’s really driven the widespread adoption, though, has been new technologies that make it easier to listen to podcasts in your car.
The market for in-car audio programming is huge. A disproportionate share of radio listening — about 44 percent — takes place in cars, compared with about 29 percent at home and 15 percent at work. More than 50 million Americans each week tune in to news-talk radio stations, which offer programming that sounds a lot like what you can find on many podcasts. Programs like The Rush Limbaugh Show and NPR's Morning Edition draw millions of listeners every day, and have done so for decades.
So you might have expected podcasts to disrupt the talk radio market the way digital music disrupted the record labels. But until recently, that wasn’t happening because — again — the technology was too cumbersome.
Driving with headphones is a bad idea no matter how smart your phone is. Would-be listeners could use tape-deck adaptors or digital transmitters, but both cost extra, were a hassle to use, and could mangle the audio quality.
But in recent years, carmakers have made it a lot easier to pipe audio from customers’ smartphones to their stereo systems. Carmakers added auxiliary audio inputs, then USB ports (which had the added benefit of charging your device). More recently, they’ve begun adding support for Bluetooth, which allows you to play podcasts from your smartphone without even taking it out of your pocket or purse.

Tech giants such as Google and Apple are investing heavily in the development of "connected car" platforms, which allow smartphones to totally take over the interface of cars’ in-dash entertainment consoles. One consequence of this is that listening to podcasts in your car is becoming as easy as listening to AM or FM radio.

Many early podcasts were amateur efforts; others were simply on-demand versions of radio programs produced by major outlets such as National Public Radio or BBC Radio. But recently, there’s been a new wave of professional, dedicated podcasters making shows with the same high production values you hear on the radio.
Serial’s Koenig is only the most famous example. Another This American Life vet, Alex Blumberg, co-founded NPR’s Planet Money podcast, and, more recently, created StartUp, a podcast chronicling the rise of a podcast network, Gimlet Media, that he co-founded with another former NPR producer, Matt Lieber.
Carmakers have made it a lot easier to pipe audio from customers’ smartphones to their stereo systems
The host of Gimlet's Mystery Show, Starlee Kine, is also a This American Life alum. The hosts of its Reply All, Alex Goldman and P.J. Vogt, were once producers at On the Media, and were hosts of its short-lived spinoff podcast TLDR. Roman Mars, host of 99% Invisible and founder of the PRX's Radiotopia podcast network, is also a public radio vet.

Other successful podcasters — such as Marc Maron, host of WTF, and Joe Rogan of The Joe Rogan Experience ­­— got their start in standup comedy, TV, commercial radio, or all the above.

Major media outlets have also jumped in with more conviction than before. Slate recently brought its various podcasts together under an umbrella organization called Panoply, whose owners recently bought a stake in Gimlet as well. Public Radio International and American Public Media have both recently launched networks as well, called SoundWorks and Infinite Guest, respectively.


Alex Blumberg and Matt Lieber, co-founders of Gimlet Media. (Yana Paskova/the Washington Post via Getty Images)
One reason the medium has been able to recruit so much talent recently is that podcasts are making money. Many podcast hosts, like some radio hosts, read or even write their own ads. Listeners connect with a host's voice and personality in a deeper and more intimate way than, say, the readers of newspapers or magazines or their web equivalents.
And talented podcasters are often talented admakers. A Mailchimp spot that aired during Serial — which featured a tourist mispronouncing the company's name ("Mail ... kimp?") — became a bona fide web phenomenon in its own right.
Podcast ads are lucrative. As of late last year, podcasters reported CPMs — cost per a thousand ad impressions, the standard industry metric — of between $20 and $45. Network TV programs, for comparison, earned about $5 to $20 per thousand impressions, radio ads made between $1 and $18 per thousand, and regular web ads between $1 and $20.
Those kinds of numbers have attracted a bit of a gold rush to the podcasting business.
Slate’s Panoply network produces podcasts, but it also offers distribution, sales, and audience development services.
Many shows on its 58-podcast roster are long-running Slate staples —such as the Political Gabfest and Culture Gabfest. Others are made in partnership with outside news organizations, such as the New York Times, New York Magazine, and Popular Science, which are choosing to take advantage of the platform Panoply offers rather than develop their own podcasting operations from scratch. (Vox’s own The Weeds podcast debuted on the network in September).
Gimlet Media — the startup featured in season one of StartUp — is, at least for now, a smaller operation, with just four shows in production. But its founder’s reputation and his idea of the company as an "HBO for podcasts" have attracted keen interest from investors.
Chris Sacca, an early backer of Twitter and Uber, was one of the first investors in the company. Just this month, Gimlet raised $6 million in Series A financing round that valued it at $30 million. Of that, $5 million came from Panoply’s parent company, Graham Holdings, former owner of the Washington Post.

The latest investment — discussed at length in a recent StartUp episode — will allow the company to add eight new shows and triple its headcount from 25 to 75 employees.
Podcasts may not replace radio talk any time soon. Live radio, live TV, and their streaming equivalents seem likely to dominate key niches like breaking news and sports into the future.
But smartphones and car integration mean podcasts will finally exist right beside radio, giving many more listeners a chance to choose between them. Some of radio’s top producers — along with some savvy investors — are betting they’ll choose podcasts more often.
Correction: This story originally misidentified This American Life as a National Public Radio program. It's actually produced by WBEZ and distributed by the Public Radio Exchange.
Imagine President Barack Obama announced a plan for a new tax that he said would raise the price of borrowing money in America. Every new mortgage would become more expensive. So would every auto loan and small-business loan. Towns and school districts would find the cost of new bonds elevated, as would large corporations. All across the land, credit availability would diminish.
Republicans would, of course, denounce him. Why would the president impose a new job-killing tax at a time when the American people have been suffering from an agonizingly slow labor market recovery and years of flat wages?
And then imagine the Democratic reaction when Obama explained that it wasn't his aim to spend the money on some new social program, or even use it to reduce the deficit. His only goal with the new tax was precisely to reduce the pace of job growth. To make sure that unemployment didn't get too low. That workers' bargaining power didn't become excessive.
After all, it's been a long, difficult recession, but the economy is a lot stronger now than it used to be. Let growth continue and wages might rise, forcing corporate profit margins to shrink until companies had no choice but to start raising prices.
"When it comes to inflation," the president might say, "it's better safe than sorry. So here's your new job-killing tax!"
It's unimaginable, of course. Congress, the press, and the public would all throw a fit. Yet at this point it is considered all but certain that the Federal Reserve is going to do exactly this by raising interest rates at its meeting next week. There's broad agreement among economists that this kind of tight-money policy leads to slower economic growth and fewer jobs being created. Yet it's happening with barely a word of public concern.
It's natural to wonder why any government official would ever decide that it makes sense to increase borrowing costs across the board and slow job growth. But the reason is inflation. At times, a central bank can boost growth with easy money, but there are fundamental limits to this strategy. A country that is out of workers, or out of natural resources, or out of machines and equipment or new ideas isn't going to be able to produce more stuff just because the central bank has made it cheap to borrow and spend. All that's going to happen is prices are going to rise.
The Federal Reserve is structured as an independent agency precisely on the theory that for the long-term good of the economy we sometimes want the central bank to slow the pace of job creation in order to avoid inflation, even though standing in front of a podium and saying, "I want to slow the pace of job creation" sounds terrible.
But the weird thing about this week's push for higher interest rates is that there's no inflation problem to solve.
Thanks to the global collapse in oil prices, there has been literally no inflation at all throughout 2015. If you ignore food and energy prices — which people often do, since they shift rapidly for non-monetary reasons — then inflation looks quite a bit higher. But it has still been below the Fed's 2 percent target for all of 2015. And it was below the Fed's 2 percent target for all of 2014. And it was below the Fed's 2 percent target for all of 2013. And it was below the Fed's 2 percent target for about half of 2012.
It's true that if you ignore food and energy prices, inflation is currently close to the Fed's 2 percent target. That's why the Fed is now eager to raise rates. It doesn't want to be caught "behind the curve" and facing a period in which inflation lingers above target as it enacts several rounds of rate increase. But given that we've survived three and a half years of consistently below-target inflation, it doesn't seem like being a little behind the curve would be the worst thing in the world.
The reason the Fed is now comfortable with the idea of a rate hike is that the labor market has improved considerably from where it was a few years ago. The unemployment rate is down to 5 percent and seems to be falling. That means the economy clearly can tolerate somewhat higher interest rates, and it's making the Fed eager to implement them.
But even though the labor market is in much better shape than it was a year or two ago, it's honestly still not in such great shape. A broad gauge of the labor market — the share of 25- to 54-year-olds who have a job — shows that something between 2 and 5 percent of the prime age population has vanished from the workforce:
It's not clear how many of these people could be tempted back into work — or would be considered hirable by employers — if we let the economy keep growing. But the number almost certainly isn't zero. The risk that keeping interest rates low a little too long could lead to a little bit of inflation needs to be balanced against the risk that slowing the pace of job creation could keep hundreds of thousands of people permanently trapped out of the labor force.
At a congressional hearing earlier this year, Fed Chair Janet Yellen was asked about the black-white unemployment gap and said basically that there's nothing she can do about it. If you delve into the data, it's easy enough to see what she means — the African-American unemployment rate and the white unemployment rate move in tandem, at a 2-to-1 ratio that seems to be fixed by factors that are out of control of monetary policy.
But as Jared Bernstein points out, this semi-fixed ratio actually means that monetary policy matters a great deal for the racial gap. If white unemployment goes from 10 percent to 5 percent, the Fed has achieved a 5 percentage point reduction. At the same time, we would expect black unemployment to fall from 20 percent to 10 percent — a much larger 10 percentage point reduction.
With the United States currently enjoying a lowish 5 percent unemployment rate, it's easy for relatively privileged people to neglect the benefits of further small reductions. But for an African-American population that will enjoy a double-scale version of any drop in the unemployment rate, the stakes remain quite high.
The same is true of other kinds of vulnerable populations. The college-educated cohort that dominates discussion of economic policy already has a very low unemployment rate. But working-class Americans could see considerable benefit from a stronger labor market.
Most economists think I am wrong and the Fed should raise rates. But the thinking behind this, as measured in things like the IGM Survey of prominent economists, is awfully fuzzy.
Anil Kashyap of the University of Chicago says he strongly agrees with a rate hike because, "As Mike Mussa once famously said, 'If not now, when?'"
Darrell Duffie of Standard says "the macro vital signs look healthy enough now."
The need for a rate hike has become so much part of the conventional wisdom that many supporters haven't articulated a rationale at all. But among those who are speaking — both in academia and on Wall Street — the predominant sentiment is one of impatience. Like Kashyap, many are simply sick and tired of waiting for a liftoff from the zero rates that have been in effect ever since 2008. And like Duffie, many feel that since the patient is now well enough to survive a rate hike, we may as well end life support.
But though this kind of impatience is understandable (I'm bored of having this argument too), it is ultimately not the point. The relevant question is whether, under the circumstances, the risks of a little bit of inflation are really worse than the risks of sluggish job growth. This is a subject that deserves to be debated squarely. Instead, it's been largely ignored by political authorities and even evaded by economists. But when rates go up, and six months from now politicians and voters alike are complaining that job growth has been too weak, they'll have the Federal Reserve — and their own inattention to it — to blame.
The Seattle City Council has unanimously passed groundbreaking and controversial legislation that effectively allows drivers to bargain collectively with Uber, Lyft, and big taxi companies that treat drivers as independent contractors. Seattle Mayor Ed Murray has refused to sign the legislation, but it is expected to become law anyway.
The measure's supporters hope that it will raise drivers' take-home income, perhaps providing them with a "living wage." But the way the ride-sharing market is structured means this isn't likely to work very well. Even assuming that drivers for Uber, Lyft, or other companies negotiate higher compensation for themselves, these gains are likely to be fleeting.
Supporters of the Seattle legislation envision a future in which drivers join "exclusive driver representative" organizations that represent drivers in collective bargaining with a company such as Uber. The EDR might ask Uber to charge customers higher fares, take a smaller cut of passengers' payments, or compensate drivers for common expenses such as gas or wear and tear on vehicles.
Suppose Uber agrees, and drivers see their take-home pay jump. What will happen next? Well, these drivers will tell their friends about the great living they're making on Uber. Some of those friends will sign up and will tell their friends about the opportunity. As a result, there will be more drivers on the street competing for the same pool of customers. Each driver will have to wait longer between fares. And so even if drivers are making more per fare, the income per hour will fall.
How far will hourly incomes fall? This depends on what economists call the elasticity of supply for driver labor. If there were a driver shortage in the Seattle area, the incomes of existing drivers might stay high. But in this case it seems more likely that there's a large pool of low- and moderate-income people who would be attracted by the higher compensation. So any deal that increases the average amount drivers make per passenger is likely to just mean there's more competition for passengers.
There are a couple of ways drivers' representatives could try to avoid this downward spiral. One would be to push for a deal that compensates drivers by the hour instead of by the ride. In that case, Uber would have an incentive to limit the influx of new drivers to make sure its hourly drivers weren't sitting around idle. That might be good for existing drivers, but it would come with some significant downsides: As hourly workers, they'd probably lose the flexibility to decide when, where, and how much to drive.
The other option would be to explicitly limit the number of drivers on the road. Not coincidentally, this is the technique regulators in cities like New York used to boost the incomes of taxi drivers before Uber entered the market.
But we can expect Uber to strongly resist this kind of proposal, since it would limit the company's potential growth.
In practice, then, the kind of collective bargaining envisioned in the Seattle legislation is unlikely to boost drivers' wages very much. It might have some other positive effects — like helping drivers get more reliable insurance or more predictable rules and regulations. But it will take a fundamental change in the ride-sharing business model — or a significant improvement in the economy-wide labor market — to boost the wages of Uber, Lyft, and taxi drivers.
The massive gender gap among CEOs of major US companies hasn't gotten any better in the past decade, according to two new reports. There are still very few women CEOs, and they don't make nearly as much as men do.
"Despite all of the attention placed on increasing the number of female executives at American companies, the needle on the gender gap has hardly moved," says one report by S&P Capital IQ. That report focused on the 500 companies that comprise the Standard & Poor's Index, which is widely considered to be one of the most accurate indicators of the broader American corporate landscape. These companies account for about 75 percent of the US equity market by capitalization.
Between 2006 and 2015, there was an average of just one new woman CEO at S&P 500 companies every two years. Of the 500 companies on the index, only 21 — a paltry 4.2 percent — are currently headed by a woman CEO. That's actually a decrease since 2014, when there were 25. These women also serve shorter median tenures, four years, compared with six years for male CEOs.
The S&P study is accompanied by two really depressing charts. There's this one, which shows that you can count on one hand the number of women CEOs in each major S&P 500 industry sector — and three of those industries have no women CEOs at all:
The second depressing chart is this one, which shows that there are so few women CEOs at major US companies, you don't even really need a chart. You can very easily just list them all.
The third depressing chart comes to us courtesy of SNL Financial, which studied the gender pay gap among C-level employees in the banking industry from 2007 to 2014. In the banking industry, too, roughly 4 percent of CEOs are women. And while the gender wage gap fluctuates a lot more among CEOs and COOs, since fewer of them are women, it's pretty constant among CFOs — the C-level position occupied by the most women.
The SNL Financial study also found that compensation for male bank CEOs climbed more than 60 percent cumulatively from 2007 to 2014, while female bank CEOs saw their compensation rise just 33 percent. In 2014, median total compensation for male CEOs was $646,803; for women, it was $499,738. That means the women CEOs made about 77 percent of what the men did, which is slightly less than the wage ratio for women overall in America.
Wage gap critics often say that statements like "women make 79 cents on the dollar" are misleading because they don't account for women's different career choices, among other things. But here we have men and women in the same field and the same position, and the wage gap still persists.
There are some specific reasons for this gap, not the least of which is that women tend to head smaller banks that have less capital. But that, too, has a significant gender component:
"[Clients] say, 'We want someone that's run a $10 billion bank through this kind of environment and here's our criteria. How do we find someone who fits the 10 check boxes?'" In a situation like this, [CEO of global executive search firm ZRG Partners Larry] Hartmann estimates that 95% of candidates would be male. "When you look at VP/director level, the mid-management level … you have a lot bigger labor pool to pick from that has more diversity of choice. But when you get to the top spots of big organizations the funnel gets small," he said.
Women CEOs interviewed by SNL Financial talked about persistence of the "good ol' boy network" in banking, which helps create what Hartmann called a "glass ceiling of middle management." Jon Terry, global financial services HR consulting leader at PricewaterhouseCoopers, said that "unconscious bias" factors in because so many of the managers in charge of promotion are men, who tend to instinctively understand other men better. "And so if you've got a bunch of men making the promotion decisions, you are absolutely going to get more men promoted than women," Terry said.
After the housing bubble pushed up homeownership rates to historic highs, we've crashed to a new historic low in homeownership — at least for non-retired Americans. That's according to the latest State of the Nation's Housing report from Harvard's Joint Center for Housing Studies, which shows that aggregate numbers mislead.
First up, the report shows a chart illustrating a trend that gets circulated a lot — homeownership spiked because of the mortgage lending boom, and now has reverted to its normal level:
But a big underlying trend in America these days is the growing number of senior citizens. The report shows that if you break out homeownership by age bracket, the "return to normal" is really an illusion. Old people are more likely than ever to own a home — and more numerous in the population — but younger cohorts are all owning homes at abnormally low levels.
One upshot of this is that the 55-to-64 cohort, in particular, is even worse prepared for retirement than a conventional scan of financial assets held in 401(k) and IRA plans would reveal. Older homeowners have typically paid down a large share of their mortgage and have successfully turned their house into a savings vehicle, but the unusually low level of homeownership among Americans of this approximate age means that won't be available to them.
Two popular fantasy sports sites suffered a major blow on Friday as a New York judge ordered that they be shut down in the state pending the outcome of a legal fight with New York Attorney General Eric Schneiderman.
The two companies, FanDuel and DraftKings, have pioneered a relatively new type of sports contest known as daily fantasy sports. Founded in 2009 and 2012, respectively, the companies have paid out hundreds of millions of dollars in prizes this year alone.
But in the past few months, the companies have faced a growing crisis that could threaten their continued existence. In the wake of an employee betting controversy that began in September, federal and state officials have been giving the site more scrutiny. Those officials started investigating whether the companies ran afoul of state and federal laws against online gambling.
The companies argue they've done nothing wrong, that daily fantasy sports isn't a form of online gambling. They insist that it's a game of skill, and that it qualifies for a fantasy sports exemption that was included in the 2006 law that banned online gambling. And they've vowed to fight the judge's ruling. "We are disappointed with the Court’s decision, and will immediately file an emergency notice of appeal in order to preserve the status quo," DraftKings said in an emailed statement.
The stakes are high. If the companies lose in New York, it could set a precedent for legal action in other states and at the federal level, jeopardizing the sites' very existence.
Fantasy sports have been around for decades; the concept first became popular for baseball before spreading to other sports. And in the early days, fantasy baseball wasn't such a big business.
The concept caught on first in baseball thanks to the wealth of statistics available about baseball games
It worked like this: At the beginning of the season, you would assemble an imaginary team — a pitcher, catcher, shortstop, and so forth — using the names of real, active players. Then, over the course of the season, your fantasy team would rack up points based on the real-world performance of the players you've chosen. You might also be able to trade players in your lineup with others in your fantasy league midway through the season. At the end of the season, the contestant whose imaginary team earns the most points wins the league.
The concept caught on first in baseball thanks to the wealth of statistics available about baseball games. As the internet made it easier to find information about other sports, the concept spread beyond baseball — especially to football.
In the past five years, a variant called daily fantasy sports has become popular. The basic concept — choosing fantasy teams and racking up points based on players' real-world performance — is the same. But whereas conventional fantasy sports provided fun, low-stakes entertainment for a group of friends (albeit often with some money at stake), daily fantasy leagues look a lot more like conventional sports gambling.
The daily fantasy market is dominated by two relatively new companies: FanDuel (which has a partnership with Vox Media's sports site SB Nation) and DraftKings. Players might pay $5, $25, or $100 to enter a contest, and they can win prizes as large as $1 million. Rather than just competing against a few friends, people compete with thousands of strangers from across the country. Both companies have raised millions of dollars in venture capital, and they've said they would pay out more than a billion dollars in prizes in 2015.
Major sports leagues lobbied for the ban on internet gambling Congress passed in 2006 that shut down internet poker and other online gaming. But they also convinced Congress to carve out an exception for fantasy sports leagues because they boost fan interest in watching sports. As a result, fantasy leagues are the only form of sports betting that's legally available to most Americans.
Companies like FanDuel and DraftKings have taken full advantage of the loophole. Today's daily fantasy sites feel more like professional gambling operations than a friendly office pool. And there's growing concerns that they've bumped up against the legal limit under federal law.
In the process, these companies have created an awkward situation for the NFL. In the past, it was easy for the NFL to argue that it should be in a different legal category from conventional sports betting. But daily fantasy leagues are blurring this line.
In October, we learned that DraftKings employee Ethan Haskell won second place in a fantasy contest hosted by DraftKings competitor FanDuel, winning $350,000. This caused people to wonder whether Haskell had used access to private DraftKings data to give him a leg up in the FanDuel contest.
Here's how that might have worked: Because the payouts in daily fantasy games go disproportionately to the top players, data about which athletes are most and least popular among other fantasy players can help a contestant boost the odds of winning. And while Haskell didn't have access to any data about FanDuel users, the DraftKings and FanDuel contests are similar enough that data about DraftKings players' bets should have provided a lot of insight about both sites.
However, DraftKings insists that nothing improper occurred. The company says Haskell didn't get access to DraftKings data until after the deadline for choosing his FanDuel team, making it impossible to use the data from one contest to influence his choices in the other.
In a brief joint statement released in early October, DraftKings and FanDuel insisted that they have strict policies in place to prevent employees from cheating on fantasy games. They also temporarily banned employees from playing on competing sites (employees were already banned from playing on their own sites).
While there's no proof Haskell did anything wrong, the controversy seems to have inspired government regulators to ask larger questions about the FanDuel and DraftKings business models. Daily fantasy sports sites seem a lot like gambling operations, and with only narrow exceptions online gambling is illegal.
Eric Schneiderman, New York's latest crusading attorney general, has taken this ball and run with it the furthest. He has sought to shut down the sites under New York's anti-gambling law. On Friday, a judge granted his request to halt the sites' operations in New York while the courts consider Schneiderman's case for shutting them down permanently.
If Schneiderman succeeds, FanDuel and DraftKings would still be able to operate in most other states. But losing in New York could also set a bad precedent for the companies and inspire public officials in other states to take a more aggressive approach. There's also a risk that federal officials could seek to shut down the sites nationally. In October, the Wall Street Journal reported that federal prosecutor Preet Bharara is probing the sites' legality and could decide that they don't qualify for the fantasy sports exemption in federal law.
With a new baby in the house, I've been ordering a lot of stuff using Amazon Prime. And recently, Amazon has been trying really hard to get me to try a service called Amazon Pantry, offering me $5.99 in credit to try the service if I agree to take slower delivery of items. I didn't know anything about Prime Pantry, but $5.99 in free "pantry" items sounded like a good deal, so I took the offer.
But once I read up on Prime Pantry, I wasn't so excited anymore. Amazon Prime Pantry may be Amazon's worst service — indeed, it's almost an anti-service, taking all the customer-friendly policies Amazon customers are used to and making them worse.
Here are some of the key features of Amazon Prime Pantry:
So what's going on here? Before Prime Pantry, Amazon wasn't always a good place to buy the kind of bulky, nonperishable items people normally buy at the grocery store. In some cases, you could only buy items like cereal or toilet paper in large quantities. In other cases, Amazon would charge a significant premium for everyday household items.
Prime Pantry is Amazon's attempt to fix this. By bundling a bunch of items together and sticking them in one big box, Amazon keeps per-item shipping costs down. That allows Amazon to offer a wider selection and smaller package sizes. And adding an explicit $5.99 shipping charge helps the company keep the prices on individual items more competitive with what you pay at the grocery store.
This all probably sounded good in the Amazon conference room where Prime Pantry was dreamed up. But the service the company actually created just isn't very useful.
The slow shipping time means that Prime Pantry can't offer perishable goods like produce, meat, and dairy products, so customers are still going to have to go to the grocery store on a regular basis. Once you're already doing that, throwing paper towels and breakfast cereal into the cart isn't too difficult.
Prime Pantry's deficiencies are particularly baffling because another Amazon product, Subscribe and Save, does a better job of serving a similar type of consumer. Subscribe and Save allows busy and cost-conscious customers to get everyday household items delivered to their door on a regular schedule and enjoy discounts and free shipping in the process. Prime Pantry is also distinct from Amazon Fresh, a full-service grocery delivery service that Vox's David Roberts tells me is great.
Slow shipping and limited selection might be forgivable if Prime Pantry offered excellent bargains. But it doesn't. For example, with Prime Pantry, you can buy this 17-ounce box of Honey Nut Cheerios for $3.52. Or you can go to Walmart's website, which has an identical box of cereal for an identical price — and if you buy $50 worth of groceries from Walmart, shipping is free.
Even better, you can go over to Target's website, where that same 17-ounce box is currently on sale for $3 with free shipping (Target's regular price is $3.52, like Amazon). Or you can buy it from Jet.com, a relatively new Amazon competitor, for $3.14. Jet offers free two-day shipping on orders over $35.
Even worse, colleagues who have used Prime Pantry say that Amazon doesn't even pack the boxes very well. In an effort to pack as many items into a box as possible, Vox's Matt Yglesias told me, Amazon skimps on Styrofoam or other padding. And that can lead to damaged items or other disasters.
"They sent me a thing of Ajax powder that exploded on everything else I ordered," Vox's Dylan Matthews said.
The most positive reaction I got from Vox staffers who have used the service came from Jen Trolio. "My general opinion of the service is a shrug," she told me. She liked the fact that she can get normal-size items delivered to her door. However, she said, "If I need two things soon but am putting off buying them until I can fill a Prime Pantry box, it’s not really worth the mental energy when I can just pick them up on a Target run in between."
Pantry isn't cheap enough to appeal to bargain hunters. It's too slow and complicated to appeal to impulse buyers. It's not comprehensive enough to serve customers who want to skip going to the grocery store. All it's accomplishing is annoying loyal Prime subscribers like me who have grown accustomed to the more customer-friendly policies of Amazon's core service.
One of the biggest mysteries in the technology world is who invented Bitcoin, the cryptocurrency (and payment network) that's now worth billions of dollars and could — according to supporters, at least — revolutionize the financial industry. Until now, the technology's creator was known only as Satoshi Nakamoto, an online pseudonym whose offline persona was a tightly guarded secret.
Many people have tried and failed to unmask Bitcoin's inventor. One list compiled this summer counted 10 people or organizations that might be the real Satoshi Nakamoto, ranging from cryptographer Nick Szabo to the National Security Agency. The most notorious case came last year, when Newsweek reported that Nakamoto was an elderly Japanese model train enthusiast living in California — only to have its reporting decisively debunked.
On Tuesday, independent reporting by Wired and Gizmodo both pointed to a new candidate: an Australian technologist named Craig Steven Wright. Wright fits the basic Nakamoto profile — he's a brilliant and secretive technologist — and leaked documents appear to provide overwhelming evidence that Wright is Nakamoto's real-life alter ego.
The scoops are based on documents that were — purportedly — taken from Wright by a hacker. The question, then, is whether the documents are authentic. Gizmodo talked to several people — including Wright's ex-wife — who seemed to believe that Wright was Nakamoto. And Wright himself seemed to tacitly acknowledge the documents' authenticity in a phone call.
However, it's also possible that the documents are part of an elaborate hoax perpetrated by Wright himself. A key piece of evidence in the Wired story is a series of blog posts by Wright from 2008 and early 2009 — before and immediately after Bitcoin's launch — that suggest that Wright had close ties to Bitcoin and Nakamoto. However, sleuthing by Wired indicates that these details were added to the posts sometime after 2013, suggesting someone — and that someone would almost certainly be Wright himself — was trying to manufacture evidence of a Wright-Nakamoto link.
So there are two possibilities here. One is that Craig Wright is Satoshi Nakamoto. The other is that Wright has been conducting an elaborate, year-long con to convince the world that he is Satoshi Nakamoto. When I originally wrote this story on Tuesday evening, I was pretty sure that Nakamoto had been found. But after sleeping on it and looking through the evidence again, I'm more skeptical.
The leaked documents include emails dating back to 2008 — before Bitcoin's creation — in which Wright discusses his work on Bitcoin and acknowledges his alter ego as Satoshi Nakamoto (GMX and vistomail are services that hosted Nakamoto's email accounts):
A legal document suggests that Wright had 1.1 million bitcoins. This sum, worth about $400 million, is the same amount that Nakamoto is believed to own.
Gizmodo says it reached Wright by telephone and he seemed to tacitly confirm the documents' authenticity: "On a subsequent call, in which lines from his purported emails were read back to him, an audibly unsettled Wright asked 'how did you get that?' and stated 'you shouldn’t have that.'"
While in Australia, Gizmodo also talked to several other people who knew Wright. Gizmodo writes, "Wright’s ex-wife Lynn recalled her husband working on Bitcoin 'many years ago,' but noted that he 'didn’t call it Bitcoin' at first, but rather 'digital money.'"
The last time a major media organization — Newsweek — claimed to have unmasked Satoshi Nakamoto, it turned out to be a massive journalistic blunder. Leah McGrath Goodman's case that an elderly Japanese train collector in California was the true inventor of the cryptocurrency didn't stand up to close scrutiny, and in retrospect it appears that Goodman read way too much into circumstantial evidence that simply didn't prove what she thought it did.
The Wired and Gizmodo stories are different. If the leaked documents are authentic, they conclusively demonstrate that Wright — or someone closely associated with him — is Bitcoin's creator and the man behind the Satoshi Nakamoto persona. And Wright himself tacitly acknowledged the authenticity of the documents to Gizmodo, making it unlikely that a third party created the documents to frame Wright. The only real question is whether the documents themselves might be part of an elaborate hoax.
A key bit of evidence in the Wired story are two blog posts by Wright from 2008 — before Bitcoin's creation — that appear to provide strong circumstantial evidence that Wright is Nakamoto. These posts reference an unreleased  cryptocurrency project, and they include an encryption key that's linked to the email address satoshin@vistomail.com. That's similar — but not identical — to the satoshi@vistomail.com address Nakamoto has used himself. Another blog post from January 10, 2009 — right around the time of Bitcoin's release — says that "The Beta of Bitcoin is live tomorrow." Again, if these posts were genuine, they would pretty conclusively demonstrate that Wright was Nakamoto.
The problem is that these "smoking gun" details appear to have been added to the posts long after 2009, as Wired's Andy Greenberg reported:
Comparisons of different archived versions of the three smoking gun posts from Wright’s blog show that he did edit all three—to insert evidence of his bitcoin history. The PGP key associated with Nakamoto’s email address and references to an upcoming "cryptocurrency paper" and "triple entry accounting" were added sometime after 2013. Even the post noting bitcoin’s beta launch is questionable. While it was ostensibly posted in January 2009, it later seems to have been deleted and then undeleted—or possibly even written for the first time—sometime between October 2013 and June of 2014.
This seems like evidence that someone was trying to fool people into believing there's a link between Wright and Nakamoto. And of course the person in the best position to tamper with Wright's blog is Wright himself.
Could Wright have also created a bunch of fake emails and sent them to reporters at Wired and Gizmodo? The oldest, most significant documents could prove difficult to authenticate because most of them — including the two I reproduced above — were emails sent to Dave Kleiman, a computer forensics expert who died in 2013.
The document dump also included emails, transcripts, and other documents that involved other people, but (at least among the documents Gizmodo has released) these are of more recent vintage and demonstrate only that Wright has been claiming to be Satoshi in private correspondence in the last couple of years. If Wright were conducting a long-running hoax to convince the world that he is Satoshi Nakamoto, the fact that he recently convinced his wife and a few business associates that he was Nakamoto doesn't prove much.
The intense public interest in Nakamoto's identity occurred primarily because it makes a great story. But unmasking Bitcoin's founder could also have practical significance. After actively contributing to Bitcoin's development during the project's first two years, Nakamoto handed his role off to a successor — Gavin Andreessen — in 2011. He has maintained near-total radio silence ever since.
Nakamoto's absence has helped to burnish one of the system's key selling points: that it's a decentralized system not under the control of any specific person or organization. Andreessen inherited Nakamoto's technical role in the Bitcoin development process, but he didn't inherit his predecessor's prestige within the Bitcoin community. As a result, the Bitcoin community has had to make decisions by consensus, with no one wielding a veto over technical decisions.
One beneficial side effect — in the eyes of many Bitcoin supporters — is that Bitcoin has been hard for regulators to control. With no single person or organization having the authority to unilaterally modify how the Bitcoin network worked, there was no one government officials could approach to demand changes. And because the technology spanned national borders, it wasn't easy to shut down. As a result, governments were forced to accept the network as it was.
If Wright is Satoshi Nakamoto, he will instantly become the most prominent person in the Bitcoin world. The community could look to him as the final authority in long-running disputes, for example its debate over how to expand the network's capacity. And if he once again becomes active in the Bitcoin community, he may become the target of unwanted attention from government regulators.
Yet Nakamoto's four-year absence from the Bitcoin community has made a big difference. His years of radio silence have transformed him from a day-to-day manager of the Bitcoin community into a mythical figure. Other powerful individuals and institutions have stepped forward to fill the power vacuum he left. And while they may have a lot of respect for Nakamoto's accomplishment in inventing Bitcoin, they're unlikely to automatically defer to his judgments.
Wall Street is starting to get excited about a technology idea that's tantalized the business world for more than a decade now — Amazon, but profitable. After all, in the most recent two quarters, Amazon has earned meaningful profits — profits driven by the success of Amazon Web Services, an enormously popular technology infrastructure company that enjoys tech-like economics rather than retail-like ones. That means 25 percent profit margins on a business that does $2 billion in revenue a quarter and is growing at a 70 percent rate.
That's led Citigroup's Mark May to issue a bullish forecast, calling for Amazon to demonstrate rapidly growing profits over the next few years with stock price growth that matches. May's note sees that breakout as driven by two factors. One is a shift within the retail business toward higher-margin items. The other is a shift away from the retail business and toward Amazon's fast-growing and high-margin Amazon Web Services business.
May thinks these two factors will lead to steady profit growth, which will drive the price up of Amazon stock. It's an intriguing theory, but it reflects a fundamental misunderstanding of Amazon's nature. Amazon may become consistently profitable someday, but if it happens it's likely to be the result of a financial, legal, or political battle that reshapes its nature. The company as we know it today will never be a profit engine, because it doesn't want to be.
May's note is packed with jargon but worth reading. The key points are that "GAAP Net Income" and "EPS" — earnings per share — are both measures of profitability:
The profit potential of Amazon's business has dominated dialogue around the stock nearly since its inception. Concerns over margins were far from ill-founded, with Amazon converting a 1,200% increase in revenue from 2004 to 2014 into a 141% decline in GAAP Net Income. The primary symptom of this penchant for long-term investing has been confusion around how to value the company, with many investors opting for an EV/Revenue approach — not dissimilar to our current EV/GMP SOTP model. The dramatic transformation of Amazon's business should change this, and potentially sooner than expected. An ongoing mix-shift in the Retail business and stellar growth in its high-margin [Amazon Web Services] segment are expected to drive adjusted EPS growth of 50% annually over the next three years, bringing [Calendar Year 2018] EPS to as much as $20. Considering Amazon's projected earnings growth, the S&P 500's historical PEG ratio of 1.2-1.5, and a 10% discount rate, AMZN is currently trading at a discount to fair value on an EPS (not revenue) basis. We believe there is an opportunity to attract a new class of investors as the company proves the sustainability of its recent margin expansion and produces more meaningful EPS.
The basic model here is that even though Amazon is an old company, we should think of it as a startup like Uber or Snapchat: a company that has a lot of customers and a successful product but that has struggled to demonstrate profitability, and whose share price will take off like a rocket if it can convert its user base into earnings. Investors can reap a fortune if they can buy in right before this happens.
There is considerable evidence that this model of Amazon's decision-making is mistaken. Amazon has not, historically, been a profitable company because Amazon's leaders don't want it to be a profitable company. In the future it will continue to not be profitable for the exact same reason. In the past, Amazon has managed to turn a profit when it's forced to by skepticism from Wall Street, which suggests that non-profitability is a choice.
Indeed, it's a choice that CEO Jeff Bezos has explained to the public in response to a joke I once made about the company's unprofitability:
Our heavy investments in Prime, AWS, Kindle, digital media, and customer experience in general strike some as too generous, shareholder indifferent, or even at odds with being a for-profit company. "Amazon, as far as I can tell, is a charitable organization being run by elements of the investment community for the benefit of consumers," writes one outside observer. But I don’t think so. To me, trying to dole out improvements in a just-in-time fashion would be too clever by half. It would be risky in a world as fast-moving as the one we all live in. More fundamentally, I think long-term thinking squares the circle. Proactively delighting customers earns trust, which earns more business from those customers, even in new business arenas. Take a long-term view, and the interests of customers and shareholders align.
As I write this, our recent stock performance has been positive, but we constantly remind ourselves of an important point – as I frequently quote famed investor Benjamin Graham in our employee all-hands meetings – "In the short run, the market is a voting machine but in the long run, it is a weighing machine." We don’t celebrate a 10% increase in the stock price like we celebrate excellent customer experience. We aren’t 10% smarter when that happens and conversely aren’t 10% dumber when the stock goes the other way. We want to be weighed, and we’re always working to build a heavier company.
Bezos is interesting in weighing, not voting, as a plan for long-term stock price appreciation. And the way the company builds mass is by investing revenue in new endeavors, not by increasing profit margin.
Recent talk of a new, profitable Amazon is driven by several successive quarters in which the company — driven by Amazon Web Services' growth — has reported earnings that, while modest, were ahead of the company's own forecasts.
"I think you could absolutely argue that AWS is simply spinning off more cash than Amazon knows what to do with," writes technology industry analyst Ben Thompson. "To be sure, Amazon is projecting a likely loss next quarter (-$480 million~$70 million), but then again, their prediction for this quarter was even more negative (-$500 million~$50 million). It will be fascinating to see if they unexpectedly beat their projections again."
One could interpret this as a sign of a covert plan to grow AWS into a financial engine that finally turns Amazon into a consistently profitable company.
But one could also take it at face value. AWS has simply grown faster than Amazon planned for, meaning the company invested less money than it realized it was going to have available, thus creating surprise profits. But if AWS's success continues, Amazon will likely respond by ramping up its level of investment, not by booking profits.
One reason May thinks profits will boost Amazon's share price is that he believes consistent profitability would "attract a new class of investors."
This is likely not something that Amazon management would welcome. What profits do is attract the kind of investors who try to mount activist campaigns to force companies to push their profits out to shareholders in the form of dividends and share buybacks.
Whether those kinds of campaigns are good for individual companies or the economy as a whole is controversial. But they're clearly not good for engaged, megalomaniacal founders who are still running the companies they created. Bezos obviously is not hard up for cash, personally, at this point in his life. If he wanted money, he would sell shares and retire. The reason he bothers to show up for work every day is that he wants Amazon to be the biggest and most important company in the world — the Everything Store where everyone buys everything all the time.
You don't build the Everything Store by paying dividends, and if you don't have profits, there are no dividends to pay. Far better to keep building and investing, disappointing as it may be to Wall Street analysts.
Fundamentally, Amazon will only start booking large consistent profits when the company's leaders run out of new ideas to invest in. Right now they are not out of ideas, as you can easily tell from the wide range of businesses they are halfway into.
A few examples:
Those are just areas where Amazon could ramp up spending on things it's already spending money on. Amazon also employs a lot of bright and hard-working people, some of whom can no doubt think up some brand new ideas all on their own. And of course there are always super-boring ways for a profit-averse company to reduce profits. Amazon could make AWS or Prime membership cheaper. It could start paying its warehouse workers more. A company can accidentally turn a profit for a quarter or three, but fundamentally this is not that difficult a problem to solve.
When you go grocery shopping, you can often save money by buying cheaper, generic alternatives to popular name-brand foods. One name-brand manufacturer, the cookie company Pepperidge Farm, thinks that Trader Joe's has taken this practice too far. It's suing the grocery chain for selling "crispy cookies filled with Belgian chocolate," which Pepperidge Farm claims is too similar to its own Milano cookies.
"The Infringing Product contains a chocolate filling sandwiched between two rounded rectangular cookies, mimicking an overall oval shape," Pepperidge Farm complains in its lawsuit. Also, the TJ's cookies come in a bag that's somewhat similar to the Milano bag, and, like the Milano cookie package, it shows cookies resting on "fluted paper trays."
Trader Joe's says it doesn't comment on pending litigation, but we can expect the company to fight this lawsuit. If it lost, it'd have to rethink other Trader Joe's products like Joe's O's (generic Cheerios) and Joe Joe's (generic Oreos).
It would be a big deal for the rest of the grocery business too. Target sells Market Pantry chocolate sandwich cookies. Walmart sells Twist and Shout chocolate sandwich cookies. Safeway makes Tuxedo's chocolate sandwich cookies.
These generic products exist because trademark law doesn't prohibit companies from copying each other's food concepts. It simply requires that companies not mislead customers about what they're really buying. It's fine to make a chocolate sandwich cookie — you just can't package it in a way that makes customers think they're buying Oreos if they're not.
Pepperidge Farm claims that Trader Joe's cross the line with its "crispy cookies filled with Belgian chocolate," arguing that the company's actions are "malicious and calculated to injure Pepperidge Farm." But that argument seems like a bit of a long shot. Pepperidge Farm owns the "Milano" name and the specific design of its packaging, but its lawsuit seems to go beyond that, essentially claiming that it owns the concept of putting a chocolate filling between two oval cookies and selling them in a tall bag.
Employers added 211,000 jobs in November, and the unemployment rate held steady at 5 percent, according to data released by the US Department of Labor Friday morning. Consensus expectations had been for 190,000 new jobs, so the report was a bit better than expected. That means the pace of job creation was good enough to make it all but certain that Janet Yellen and the Federal Reserve are done delaying and will raise interest rates at their December 17 meeting.
The Fed appears to have been eyeballing 100,000 new jobs as the minimum needed to make them comfortable proceeding with the rate hike, and this report easily clears that bar.
A small interest rate increase later this month should not, on its own, represent a dramatic change in economic circumstances. But the Fed hasn't raised interest rates since its June 2006 meeting, so there is plenty of curiosity as to how both financial markets and the real economy will react. The European Central Bank and the central bank of Sweden were both quicker than the Fed to enact their first post-recession rate hikes only to see themselves reverse course after their economies proved to be less robust than they hoped.
The improving economy over the past two years has turned the once dramatic monthly jobs-day ritual into a lower-profile affair.
But this month's report is being closely watched, because the Fed has been hinting that this jobs report is the last decisive piece of data it was looking at before deciding to pull the trigger. In a speech delivered Wednesday at the Economic Club of Washington, Yellen laid out the case for a rate hike provided that evidence of "continued improvement in the labor market" continues to come in.
Then, in testimony to Congress's Joint Economic Committee, Yellen stated her view that given existing demographics the United States needs to create about 100,000 jobs per month to absorb the natural growth of the labor force.
Any job creation above that would be consistent with continued improvement in the labor market — either further cutting the unemployment rate or else drawing new people into the labor force out of the ranks of the discouraged. Yellen hasn't quite come out and said explicitly that 100,000 new jobs is the green light for a December rate hike, but she's dropped about as many hints as the Fed ever does about the future course of economic policy.
Despite the improvement in the state of the labor market, there is little specific reason for the Federal Reserve to be shifting toward tighter money. Inflation is well below the Fed's 2 percent target, and has been for more than two years. The Fed simply seems impatient to abandon the zero interest rate policy that has prevailed since 2008 and wants to do so because the economy is now healthy enough to survive it.
Low interest rates offer a range of benefits to the economy, and until very recently it was the conventional wisdom that policymakers should keep rates low as long as possible.
Internet giant/business basket case Yahoo is embroiled in a new round of controversy, with activist investors at Starboard Value demanding big changes and the board debating proposals to essentially liquidate the company. A majority of board members appear to still be backing CEO Marissa Mayer, but the swirling controversy may nonetheless force her to pause some of her current plans.
Yahoo is a big company with a lot of moving parts, but the reason it's so contentious can be summed up in one chart of data borrowed from Bloomberg's Matt Levine.
<!--
new pym.Parent('vox-yahoo-value__graphic', '//apps.voxmedia.com/at/vox-yahoo-value/', {xdomain: '.*\.voxmedia\.com'});
// -->
Here, I've taken the total value the stock market places on Yahoo. I've also listed the total value the stock market places on the shares in the Chinese internet company Alibaba that Yahoo owns. And the total value the stock market places on the shares in the Japanese internet company Yahoo Japan that Yahoo owns. And the value of the cash that Yahoo owns in the bank. Subtract all that, and you reach the conclusion that the rest of Yahoo is worth less than nothing.
<!--
new pym.Parent('vox-yahoo-value__graphic', '//apps.voxmedia.com/at/vox-yahoo-value/', {xdomain: '.*\.voxmedia\.com'});
// -->
Now, is Yahoo worth less than nothing? Obviously not. If you actually put the core Yahoo business up for sale as some people are talking about, someone would buy it for a greater-than-zero sum of money.

At a minimum, you could shut down everything except the fantasy football app, fire everyone, and you'd have a company that's worth something.
And plenty of other bits and pieces of Yahoo seem to clearly have some value too.
The issue is that tying these various businesses together and then linking them with the Asian stock assets and considering potential tax liability on selling those assets appears to be destroying billions of dollars in potential value. The result is a company that is worth considerably less than the pre-tax sum of its parts. So investors are fighting over how to best break up or reengineer the company in order to maximize the flow of money into their own pockets.
Mark Zuckerberg and his wife Priscilla Chan's announcement of plans to give away 99 percent of their Facebook stock comes with an unusual twist. According to paperwork filed with the SEC by Facebook, the money will go to a new limited liability corporation (LLC) rather than to a charitable foundation or other traditional nonprofit structure.
That has naturally raised a lot of eyebrows from people looking to expose the whole thing as a scam, but that's almost certainly not what's going on. When Steve Jobs's widow, Laurene Powell, created a charitable LLC back in 2013, Laura Arrillaga-Andreessen told the New York Times the reason was that Powell wanted to be able to spend some of the money on political lobbying and investing in for-profit businesses, both things that a charitable foundation can't do:
"The beauty of having an LLC in today’s world is No. 1, you have the ability to act and react as nimbly as need be to create change, and you have the ability to invest politically, in the for-profit sector and the nonprofit sector simultaneously," she said.
"And the reality is," she added, "we are now seeing a blurring of the lines between the sectors in a way that was not even discussed 10 years ago. The way that we are going to solve social problems is by working with multiple different types of investing."
An LLC, for example, can spend money on political ads. A tax-exempt nonprofit can't. And an LLC could make angel investments in clean energy startups in a way that a tax-exempt nonprofit can't. But an LLC also can make donations to tax-exempt nonprofits, and thus reap the tax benefits of charitable giving.
One reason very wealthy philanthropists have traditionally set up charitable trusts is that they've been motivated in part by the desire to create enduring institutions that long outlive them. Things like the Ford Foundation, the Rockefeller Foundation, and the Carnegie Foundation are still alive and well generations after their creation. The recent trend, however, has been toward trying to spend all the money within a finite span of time rather than creating an infinitely lived grantmaking institution. Under those circumstances, the LLC structure has a lot of advantages, and it's not surprising to see Silicon Valley donors starting to opt for it.
Of course, one reason a traditional nonprofit can't invest in for-profit businesses is that when you invest in for-profit businesses that succeed, you end up earning a profit. Zuckerberg says the Chan Zuckerberg Initiative will simply reinvest any profits the LLC earns back into the larger enterprise. If he goes back on his word about that, then of course it will turn out that he didn't establish a nonprofit at all — he established an angel investing fund. It's not quite a legally binding divestment of funds in the same way a traditional charitable donation would be. But if Zuckerberg were harboring a secret desire to give away less than 99 percent of his Facebook wealth, he could easily have just made a pledge to give away 50 percent of it. That would still have been a lot of money and a big deal.
China this week received official status from the International Monetary Fund as the issuer of one of just five globally influential currencies that are used to peg the value of the IMF's Special Drawing Rights (SDR). If this sounds boring to you, Neil Irwin at the New York Times spices things up by suggesting that this "akin to what happened about a century ago, when the United States dollar was gradually supplanting the British pound as the predominant currency for global trade and finance," a move that "was a crucial piece of the nation’s rise to superpower status." Similarly, Matt O'Brien at Wonkblog raises the prospect that China "might be like the U.S. 100 years ago": poised to displace us as the world's financial hub, just as we were poised to displace Britain at the dawn of World War I.
The good news for those of you who don't know what any of this is about is that it's honestly not nearly as important as these stories are making it sound. I personally think the mechanics are interesting, but in terms of global economic conditions Paul Krugman rightly says, "This is not much more than a minor change in accounting, with trivial economic implications." Ben Bernanke compares it to an elementary school teacher putting a gold star on a piece of properly completed homework. He says it's a move that "confers no meaningful additional powers or privileges on China."
So honestly feel free to stop reading this article right now (though I would appreciate you sharing it on social media), unless you happen to be in the market for a detailed exploration of the nuances of something that isn't that important.
Here are the key bullet points about this story:
At the heart of this unimportant story is a deservedly obscure economic instrument known as a Special Drawing Right.
IMF member states (which these days is basically all countries) hold SDRs that are allocated (i.e., created out of thin air) to member states in a manner proportionate to their payments to the IMF. The value of an SDR is determined in terms of a basket of currencies. Back in the early 1990s, for example, an SDR was 40 percent dollars, 21 percent German marks, 11 percent French francs, 17 percent Japanese yen, and 11 percent British pounds. More recently, SDRs have been 41.9 percent dollars, 37.4 percent euros, 9.4 percent yen, and 11.3 percent pounds. Now China is joining the club, and future SDRs will be 10.92 percent yuan, with the weight accorded to other currencies diminished accordingly.
You can't actually do anything with an SDR other than swap it for one of its component currencies. Consequently, countries generally don't do anything with their SDRs, and SDRs play no significant functional role in the economy.
The IMF does, however, use the SDR as its unit of account when scoring its own books. And a number of other international organizations — ranging from the Economic Community of West African States to the Islamic Development Bank — follow their lead in this regard. Actual business is conducted in local currencies, in dollars, or maybe in euros or yen or whatever else is convenient. But for accounting purposes, the SDR is a nice neutral choice.
If this doesn't sound important to you, then you are correct. As Berkeley economist Maurice Obstfeld recounts in his excellent overview of the SDR, they were created to solve a problem peculiar to the economic conditions of 1969. At the time, only gold or dollars — which were convertible to gold — could be used for international economic transfers. But there wasn't enough gold and dollars to go around. The idea was that "even though SDRs are not money, they could be used, like demonetized gold, to settle international claims between central banks." Could this have worked? Maybe. But the world will never know, because just a few years later Richard Nixon ended the convertibility of dollars into gold, and the entire gold-based system and the gold-related problem the SDR was supposed to solve went away.
Countries sometimes want to stockpile foreign currency — or financial assets that are denominated in foreign currency — for a variety of reasons.
One, as Obstfeld recounts, is as a form of "self-insurance" against financial crisis. The IMF itself is supposed to be able to help crisis-stricken countries with loans, but getting an IMF loan requires agreeing to an IMF-written structural adjustment program. Keeping a few billion dollars under the pillowcase is a small price to pay for national sovereignty.
Another is genuinely as a savings device. Intelligently managed oil exporting countries, for example, know that spending 100 percent of any given year's oil revenue would be a mistake. The global price of oil goes up and down from year to year, and the reserves generally don't last forever. So oil-rich countries generally stockpile a bunch of foreign currency during good times to have something to help ride out the lean years.
Last, a country can amass foreign currency reserves as a kind of accident. For years, Americans were buying tons of stuff that was made in China, and the Chinese government didn't want this to drive up the price of Chinese currency. Consequently, China needed to buy and hold some dollar-denominated financial assets. That's how it wound up buying so many US government bonds, leading to a lot of misinformed commentary about the existence of some kind of Chinese debt bomb.
When it comes to foreign currency reserves, in principle any currency would work. In practice, you want a currency that is widely used so that if you need to sell your currency in the middle of a panic you will find customers. You would also like the currency to be tied to a credible legal system, a transparent political system, and open financial markets. Basically you want American dollars, and then you might want to hedge a bit with euros and yen and British pounds especially if you happen to do a lot of business with those countries. The main thing, though, is that you want a currency that other people will want — it's a basic coordination game. So for a long time the currency that everyone wanted was the British pound. Then after Britain's financial resources were exhausted by two gigantic global military conflicts, the main default global reserve currency became the US dollar.
In theory, the dollar could be supplanted by Chinese money someday. But not only would a lot of institutional, legal, economic, and political changes need to happen in China for this to make sense but you would also need some equivalent of the world wars to erode the United States from its current position.
Nothing. There is literally no causal relationship between inclusion in the SDR basket and emergence as a dominant global reserve currency. The SDRs themselves are counted as a form of foreign currency reserve, but that's an unrelated issue to whether anyone really uses the SDR's component currencies as a reserve asset. The euro has been in the SDR basket since its inception, and it's not all that widely used as a reserve currency because there's just no reason for anyone to switch.
You often hear this, generally from Europeans, who sometimes complain that the United States enjoys an "exorbitant privilege" from the dollar's reserve currency status that allows us to get away with running large trade deficits.
But this is not true. Australia has run bigger trade deficits for longer than the United States, nobody holds Australian dollars as a reserve currency, and Australian governments are not wasting their time trying to convince anyone to do it.
The reason Australia can always run trade deficits is ultimately not that mysterious. Australia is a rich country with a credible legal system and a stable political order that also — thanks to immigration — has a substantially higher population growth rate than other advanced economies. That makes Australia well-suited to receive a net inflow of private investment money from the rest of the world. All this also applies to the United States, though to a lesser extent, and so we also can sustain large trade deficits.
Meanwhile, even if it really were true that being a global reserve currency made it easier for you to run a trade deficit, it's clear that the Chinese government doesn't want to run a trade deficit. On the contrary, it rather infamously intervenes in foreign exchange markets to try to ensure it runs a trade surplus to bolster its exporting industries.
China has an ongoing and active program to send people to the moon.
Once upon a time, the United States and the Soviet Union were engaged in a high-profile "space race" to accomplish precisely this. It is not entirely clear to me why the superpowers became fixated on this moon goal, since there was never any indication that anything of value was on the moon. But it happened. And the US won. And then we sent a few more astronauts to the moon. And then having proved our point (whatever the point was), we stopped bothering. China is a large and important country whose large population and middling income combine to make it a major power on the world stage.
Consequently, the Chinese government is doing a bunch of "major power on the world stage" type of things. One of those is trying to send people to the moon. Lobbying the IMF to get into the SDR basket is a lot cheaper than sending people to the moon.
A recent Paul Krugman column on America's dysfunctional urban housing situation briefly mentions an article from a 1955 issue of Forbes magazine that is genuinely worth your time if you're interested in understanding what that era of greater economic equality looked like. Of course, you can see this "Great Compression" on various kinds of charts if you like. But the Forbes piece really tells a story of how the successive events of the Great Depression, the New Deal, World War II, and then the new postwar consensus served to flatten out the American elite:
Twenty-five years have altered the executive way of life noticeably; in 1930 the average businessman had been buffeted by the economic storms but he had not yet been battered by the income tax. The executive still led a life ornamented by expensive adjuncts that other men could not begin to afford, a life attended by a formality that other men did not have time for. In Boston, which set the highest tone if not the fastest pace, the archetype of the high-salaried executive of 1930 arrived at his office in his chauffeur-driven Pierce-Arrow, uncompromisingly attired in dark suit and detachable stiff collar. For weekend lounging white flannels were de rigueur.
By contrast, in 1955 top executives generally led lives that resembled the lives of the middle class. They drove their own cars and lived in modestly sized suburban homes that did not accommodate lavish parties:
The executive’s home today is likely to be unpretentious and relatively small–perhaps seven rooms and two and a half baths. (Servants are hard to come by and many a vice president’s wife gets along with part-time help. So many have done so for so long, in fact, that they no longer complain much about it.) The executive who feels, as apparently Robert R. Young does, that to be completely happy he needs a forty-room "cottage" in Newport and a thirty-one-room oceanside villa in Palm Beach is a rare bird these days. The fact that Young paid only $38,000 for his Newport place, Fairholme, which cost Philadelphia banker John R. Drexel nearly a quarter of a million dollars to build in 1905, demonstrates the decline in the market for such outsize mansions.
As executives’ homes have dwindled in size, so have their parties. Frederick J. Thibold, catering manager at Sherry’s in New York, can remember dances for 2,000 with a "sumptuous supper" twenty-five years ago. A big dance today is one for 400, and at some of these, Thibold confides in a whisper, Sherry’s has served hot dogs and hamburgers. Today’s executive entertains at his country club, or at small dinner parties at home. The New York executive who entertains at smart restaurants, where a dinner party for six may cost $125, usually does so on an expense account.
For context, the $38,000 paid for that Newport mansion would be about $340,000 in today's money. That's about twice the price of the median house in the USA today, and a bit less than the median price of a house in California. By contrast, a quarter of a million of 1905 dollars would be almost $6.5 million in today's terms.
This illustrates something important about the economics of luxuries, like vacation homes in beach communities. Under any set of economic arrangements, these are going to be expensive in the sense that the typical family probably wouldn't want to pay for them. But under egalitarian economic conditions, there is a de facto ceiling on their price. If nobody has the money to spend $6.5 million on a Newport getaway, then Newport getaways will have to be a lot cheaper. Consequently, while high levels of inequality clearly benefit the people at the top of the economic food chain, they benefit them a lot less than it might superficially appear.
Even under a much flatter distribution of income, all those beaches would still be there, and someone would own the beach houses — they'd just be cheaper.
But equality had been bad news for the yacht industry:
The large yacht has also foundered in the sea of progressive taxation. In 1930, Fred Fisher (Bodies), Walter Briggs, and Alfred P. Sloan cruised around in vessels 235 feet long; J. P. Morgan had just built his fourth Corsair (343 feet). Today, seventy-five feet is considered a lot of yacht. One of the biggest yachts launched in the past five years is the ninety-six-foot Rhonda III, built and owned by Ingalls Shipbuilding Corp., of Birmingham, Alabama. The Rhonda III cost half a million dollars to build, and the annual bill for keeping a crew aboard her, stocking her, and fueling her runs to around $130,000. As Chairman Robert I. Ingalls Jr. says, only corporations today can own even so comparatively modest a craft. The specifications of the boat that interests the great majority of seagoing executives today are "forty feet, four people, $40,000." In this tidy vessel the businessman of 1955 is quite happily sea-borne.
These days, of course, the business press is full of articles about the booming superyacht industry — a seaborne manifestation of our return to 1920s-style economics.
The whole story is worth a read, so I won't excerpt any more of it. I will, however, note something that doesn't appear in the story — much talk about fundamental economic trends. There's no thesis that equality suddenly appeared because of a surge of new inventions or a dearth of new inventions. There's not much interest in whether trade was freer in the 1950s or in the 1920s. The take is very simple — back in 1955 the top marginal income tax rate was 91 percent, so there simply weren't any people with monstrous pay packages.
The media had a field day last year when the investment firm Starboard Value wrote what amounted to an epic one-star Yelp review of the Olive Garden.
In a 300-page slide deck, Starboard investor Jeff Smith argued that the middlebrow Italian chain served too many of its famous unlimited breadsticks at a time, allowing the leftovers to grow cold and contributing to food waste.
Starboard had other gripes, too. It complained that the Olive Garden wasn't salting its pasta water, producing a "mushy, unappealing product." It declared that the restaurant's combination of vegetarian lasagna with grilled chicken not only "doesn't make any sense" (if you want meat, you'll get the meat lasagna), but was also poorly prepared. And it said that the "crispy parmesan asparagus" was "anything but."
The stakes were higher than cold breadsticks and mushy pasta, though. The presentation, which also delved into the company's financial performance and business strategy, was part of an ambitious campaign to oust the management of the Olive Garden's parent company, Darden Restaurants. Starboard succeeded a few weeks later, when shareholders elected a new board of directors that went on to implement many of Starboard's ideas. Since then, Darden's stock price has soared. That has earned Starboard — which owned a 5 percent stake in the company — millions in profits.
Starboard's strategy — known as activist investing — has been getting more popular in recent years. And some people see that as an ominous trend.
"Activists have become toxic to the tech community," says Peter Levine, a partner at the prominent venture capital firm Andreessen Horowitz. Levine argues that activists pressure companies to focus on short-term financial results at the expense of long-term investments in company growth. In his view, that's a disaster for Silicon Valley firms that need to keep their products on the cutting edge.
But defenders point out that when activists target a new company, its stock price usually rises — and it generally stays high even after the activists leave the scene. They see activist investors as a benign force in corporate America, helping to ensure companies are run well.
The debate makes more sense when you reframe the argument. The larger question is: run well for whom? The goal of activists is to enrich shareholders, but pro-shareholder moves won't necessarily be good for a company's creditors, employees, and customers. Pressure from activists can discourage companies from making long-term investments that can produce broad social benefits. The big shareholder payouts activists often seek can drain companies of financial reserves, making layoffs or bankruptcies more likely in the event of an economic downturn.
In short, activists' laser-like focus on economic efficiency might — ironically — be making the economy as a whole less productive.
If some of your retirement savings are invested in stocks (and they should be!), then you have a personal financial stake in how America's public companies are run. Better corporate performance means higher profits, which will ultimately mean a larger nest egg when you reach retirement age.
In most companies, shareholders elect a board of directors to represent their interests. The board, in turn, hires the CEO and then tries to make sure he or she runs the company well.
That can be harder than it sounds, according to Ronald Gilson, a legal scholar at Columbia University. Modern companies have become so large and complex that even sophisticated board members struggle to understand what they're up to.
"The bulk of the information that the board gets comes through management," Gilson says. CEOs have staffs of people who can prepare briefing materials reflecting the CEO's point of view. Board members generally don't have the time or staff to do much independent research.
For ordinary shareholders, this is a problem; for activist investors, it's an opportunity. Activist firms have enough money to buy a big stake in a company — usually between 5 and 10 percent. And they have the resources to do their own research and develop proposals for improving performance and boosting returns. If they succeed, it pushes up the stock price and makes the activist — and all the company's other shareholders — more money.
This was Starboard's strategy in the Olive Garden fight. "In effect," Gilson argues, "the activists provide a parade of McKinseys" — that is business consultants like the ones you can hire at McKinsey & Company — "who come into the board saying, 'We've got a better idea.'"
A "parade of McKinseys" might sound great if you're a shareholder concerned that the company's CEO might be doing a bad job. But if you're the CEO, activists can be pretty disruptive.
"When you have an activist come on your board, you can't run the company anymore because all you're doing is dealing with the activist," Levine says. "It's crippling until these campaigns are over with."
Levine argues that the demands of the activists — who often launch their campaigns after only owning shares for a few months — may not be good for shareholders who are investing for the long term. Activists, Levine says, are "very interested in returning money to shareholders, changing management teams, selling the company." But they're often not interested in making acquisitions or investing in research and development — activities that help the company grow and prosper over the long term.
If it's true that activist investors are forcing CEOs to think short term and forgo promising investment opportunities, stocks ought drop after activist campaigns start.
But the data shows the opposite. An influential study by Harvard legal scholar Lucian Bebchuk, Duke's Alon Brav, and Columbia's Wei Jiang found that when an activist firm announces it has taken a position in a company, the company's stock price usually rises — suggesting that other shareholders view the news positively. And increases aren't transitory, either. Five years after the start of an activist campaign, companies targeted in activist campaigns still tend to outperform similar companies that have not been targeted.
The increases observed in their study were not statistically significant, so it's possible that they were the result of random chance. But the data certainly doesn't support the fears that having an activist target a particular company is bad for that company's shareholders.
This makes sense because the activist strategy depends on support from other shareholders. As Gilson stressed to me, activists only succeed if other shareholders buy into their proposals. The activists themselves typically buy just 5 or 10 percent of a company's shares. They need other shareholders to agree with them to achieve a majority and force a change in strategy or management. An activist firm that mostly pushed ideas that were bad for shareholders wouldn't stay in business very long.
The fact that activists seem to be good for shareholders doesn't necessarily mean that their campaigns are good for companies, to say nothing of the economy as a whole.
Take McDonald's, for example. Earlier this year, activist investors began a campaign to pressure McDonald's to pay out larger dividends to shareholders. McDonald's recently capitulated to their demands, announcing that it would borrow $10 billion to help finance $30 billion in payments to shareholders. The whole company is only worth about $100 billion, so that represents a large fraction of the company's value.
The move might enrich shareholders, but it's going to make McDonald's as a company a lot weaker. Major credit ratings agencies immediately downgraded the company's debt, and it's not hard to see why. In recent years, McDonald's has struggled to find its footing as consumer tastes have shifted to healthier and more upscale options. Sending $30 billion out the door will greatly reduce the company's margin for error. In the coming years, McDonald's will have less money on hand to invest in expansion and a smaller cash cushion to help it ride out future economic downturns.
This is bad for everyone associated with McDonald's other than the shareholders. It's bad for lenders, who face a slightly lower likelihood of getting their loans paid back. It's bad for McDonald's workers, who are more likely to lose their jobs in the next recession. And it's bad for customers who may see the quality of McDonald's products decline — or may even see their local McDonald's forced to close.
The McDonald's case is not an isolated incident. A Wall Street Journal analysis of 71 recent activist campaigns found that more than 20 of them successfully pressured target companies to buy back shares, boosting share prices and weakening companies' balance sheets.
Companies forced to disgorge money to shareholders in recent years include Apple, Safeway, Dow Chemical, Yahoo, McGraw-Hill, and State Street bank. And, of course, worries about unwanted attention from activists have likely motivated other companies to proactively return cash to shareholders.
Ideally, shareholders would reinvest the cash they receive from established companies in ways that help newer, smaller companies grow. But in recent years, that mostly hasn't been happening.
A recent paper from the Roosevelt Institute found that in 2014, companies paid out $1.2 trillion in dividends and buybacks. Yet the paper's author, J.W. Mason, estimates that less than $200 billion of those payouts were ultimately reinvested at other companies in Silicon Valley or elsewhere. The other $1 trillion was either used to buy existing stocks (which drives up share prices but doesn't increase investment spending) or simply went into the pockets of mostly wealthy shareholders.
So what's going on here? Mason's interpretation is that pressure from shareholders — and activists in particular — is forcing companies to take a myopically short-term point of view. In his view, companies would be more profitable in the long run if they spent more to build factories and infrastructure, buy equipment, and develop new products and services. But instead, shareholders are forcing CEOs to devote most of their profits to paying dividends and buying back shares.
Another possibility, however, is that there just aren't that many opportunities for investment. The most innovative sector of the economy — high tech — is notable for not requiring vast quantities of capital investment (Facebook, after all, was launched from a college dorm room), and $1.2 trillion is a lot of money.
Mason readily admits that this might be part of the explanation for the recent decline in investment spending. But he still argues that aggressive shareholder demands have had a detrimental impact.
"A lot of technological innovation happens as a spillover from investment," he says.  When a company invests in growth, it doesn't just benefit its own bottom line; it makes the broader society richer. For example, inventing the iPhone has obviously made Apple a lot of money, but it's made lots of other people better off, too. Thousands of people have gotten jobs selling iPhone apps, iPhone accessories, iPhone cases, and so forth. Apple's innovations were quickly copied by rivals such as Google and Microsoft, making smartphones better for everyone. And so forth.
So even if — perhaps especially if — activists are effectively advancing the interests of shareholders, that doesn't necessarily mean that their efforts are good for the economy as a whole. The economy as a whole might be better off if companies invested more aggressively — even if many of the investments don't quite pay off for the company making them. Ironically, activists' efforts to boost the returns companies pay to shareholders may be making the economy as a whole less innovative.
This might explain a recent trend in Silicon Valley. Some of the most successful Silicon Valley founders have become convinced that pressure from Wall Street is so toxic that they're better off avoiding public markets altogether. Companies like Uber and Airbnb have stayed private despite being much larger than previous generations of technology companies were at the time they first offered their shares to the public. Others, including Google and Facebook, have adopted structures that give their founders control even though they only own a minority of the shares.
"I think there's really an overvaluation of people who work on Wall Street — an exaggeration of their talents relative to everyone else," Mason says. In his view, Wall Street's obsession with boosting shareholder returns is myopic. In the long run, we might all be better off if companies faced less pressure to generate returns for shareholders — and more incentive to invest in the next generation of great products.
The Federal Reserve has been attacked for years by critics, most of them conservative, who insist that its low interest rates are bad for savers. But those attacks recently got more attention when Ralph Nader joined the fray, penning a remarkably sexist open letter suggesting both that Fed Chair Janet Yellen's policies were hurting savers and also that she would know this if she would only "sit down with your Nobel Prize winning husband, economist George Akerlof"  and talk the matter over.
Akerlof is, indeed, a very distinguished academic economist, but unlike, say, Janet Yellen he's not actually known for work on monetary issues. He also, unlike Yellen, doesn't have more than a decade of experience in central banking. But it's not unusual for even the most well-known and well-regard women in economics to have trouble gaining recognition.
Yellen took the unusual step of responding with a letter of her own. It ignores the bizarre reference to her husband, but does include one of the best short summaries of why this widespread criticism is totally mistaken:
Would savers have been better off if the Federal Reserve had not acted as forcefully as it did and had maintained a higher level of short-term interest rates, including rates paid to savers? I don't believe so. Unemployment would have risen to even higher levels, home prices would have collapsed further, even more businesses and individuals would have faced bankruptcy and foreclosure, and the stock market would not have recovered. True, savers could have seen higher returns on their federally-insured deposits, but these returns would hardly have offset the more dramatic declines they would have experienced in the value of their homes and retirement accounts. Many of these savers would have lost their jobs or pensions (or faced increased burdens from supporting unemployed children and grandchildren).
What Nader (or Ben Carson or dozens of congressional Republicans and others offering this line of attack) is missing, and what Yellen is highlighting, is that "savers" who put money in bank accounts aren't a special class of people who live on Mars isolated from the experience of the rest of the economy. Savers generally also have jobs and own homes. Smart savers don't just have money in a bank account but are also putting money in a 401(k) or other tax subsidized retirement account where they own shares of stock. Moves that are beneficial to the labor market, beneficial to share prices, and beneficial to house prices aren't bad for savers, even if they happen to be bad for one particular kind of asset a saver might have.
Pfizer, the large American pharmaceutical company, formally announced on Monday that it will buy Allergan, an Irish company with about one-tenth Pfizer's revenue. Except legally speaking, Allergan is going to be buying Pfizer. And legally speaking, the new company's headquarters is going to be in Dublin even though its "operational" headquarters will be in New York — right where Pfizer is located today.
The reason? Tax avoidance. Having Pfizer become an Irish company will reduce its tax bill a decent amount in practice and a huge amount in accounting terms, making it easier for money to flow out of the corporate treasury and into the pockets of shareholders.
Hillary Clinton denounced the deal as a rip-off for US taxpayers, and in a statement Bernie Sanders went even further and said, "The Obama administration has the authority to stop this merger, and it should exercise this authority."

Hillary Clinton blasts Pfizer-Allergan Merger: These kind of deals "will leave U.S. taxpayers holding the bag."

Welcome to the exciting world of what are known as "tax inversions" — an increasingly common practice whereby American companies become foreign ones in order to evade the grasp of the IRS.
One key motivation for tax inversions is that the United States, unlike other developed countries, attempts to tax US-based corporations on all their profits regardless of where in the world the profits were earned. Companies get to deduct the corporate income tax they pay to foreign governments for their foreign profits, but since the US has a higher corporate income tax rate than most foreign countries, that generally leaves a residual tax bill.
So if a US-based company can become a subsidiary of a company headquartered in a low-tax jurisdiction like Ireland, then it can avoid paying a bunch of taxes on sales made in foreign countries.
For some companies, the inversion story is a pretty basic case of taxes paid on foreign sales. But for companies in a handful of industries — most notably pharmaceuticals and high tech — there are additional gains.
That's because a huge share of the value of a pharmaceutical company is tied up with its drug patents. By assigning ownership of the patent to a subsidiary located in a low-tax jurisdiction and then having subsidiaries in higher-tax jurisdictions license the patent from it, a pharmaceutical company can ensure that profits accumulate in low-tax countries even if sales happen in high-tax countries.
In theory, the US taxes all profits, whether they are earned at home or abroad. But there's a catch: The tax is only due to the US Treasury Department when the money is actually "brought home" from the foreign subsidiary back into the US-based parent company. Before that, the cash is considered to be offshore (note that the money may well actually be in a US bank account or other financial institution — it's a question of ownership, not location), and the taxes owed may be deferred.
Companies generally hold money offshore because they are hoping some future Congress will cut corporate income tax rates or pass some kind of repatriation amnesty that will let them bring the money back onshore at a low tax rate.
But as long as the taxes are being deferred, for accounting purposes the company has to act as if it eventually plans to pay the full taxes due on its foreign profits. By becoming an Irish company, Allergan can dispense with that pretext and fully make its paper earnings look vastly larger. But it also makes a difference in a practical sense. Before Pfizer can hand cash to its shareholders in the form of dividends, it needs to bring it onshore and pay taxes. An inversion will cut taxes on money used for that purpose, as well as improve the company's paper profits in accounting terms.
The White House actually wrote an inversion proposal into the budget it released in March 2014. The original proposal would have made inversions more or less impossible and would have retroactively penalized inversions completed earlier in the year. But those proposals would have required legislation to pass Congress, and the Republicans who run Congress have no interest in raising taxes on American businesses.
Last fall, Treasury instead released a broad suite of new rules and interpretations of rules that make inversions more difficult. These rules generally would make it harder for an inverting entity to shift funds around various subsidiaries for tax purposes, and would also strengthen enforcement of anti-inversion rules adopted in previous decades.
But as the Pfizer-Allergan deal makes clear, absent new legislation this sort of thing is going to keep happening.
The United States has more or less the highest official corporate income tax rate in the world, but it's so full of loopholes that very few companies pay anything close to the official rate. This is widely regarded as a lamentable situation, and there is overwhelming political consensus around the idea that the corporate income tax code should be reformed. The broad idea is that the rate should be brought down but loopholes should be closed. The resulting system would treat different companies more similarly and should help US-based firms compete in global markets.
Corporate tax reform keeps not happening, however, for two reasons.
One is that there's big-picture ideological disagreement between Republicans and Democrats over whether the goal of reform should be to raise more tax revenue or less. Everyone agrees that the current code is bad. But absent consensus about revenue targets, it's hard to build a coalition for reform. The other is that while it's easy for everyone to agree on the idea of "closing loopholes," it's very difficult to agree on exactly which loopholes should be closed.
Were broad corporate tax reform to pass, it would likely reduce the incentive for inversions somewhat. On the other hand, depending on exactly which loopholes were closed, it might create more incentive for inversions in certain sectors. Either way, inversions themselves are a huge loophole that companies will almost certainly continue to exploit unless they are specifically restrained from doing so.
The hotel giant Marriott is buying the smaller hotel group Starwood (whose brands include Sheraton, Westin, W, St. Regis, and Le Méridien) to form what will be the largest hotel group on the planet. The main aim of the merger is to obtain scale that's large enough to drive a hard bargain with Expedia and other giant players in the online hotel brokerage game, but another factor that makes Starwood an attractive pickup is the fierce loyalty its Starwood Preferred Guest loyalty program inspires in the company's most devoted customers.
At the same time, this very fierce loyalty has many SPG devotees panicked that the new, less classy management from Marriott will somehow mess things up. "I’m livid," Hugo Espinoza told Josh Barro of the New York Times. "I dread to think what the merger will do to my platinum-for-life status."
But Fusion's Felix Salmon and Stratechery's Ben Thompson both have reassuring takes, arguing that there are real complementarities between the Marriott and Starwood portfolios and that it would be hugely against Marriott's interests to ruin this beloved aspect of its new acquisition. The truth, however, is more complicated. Even if the program itself remains high-quality, the merger's impact on many existing Starwood customers can still be strongly negative. At the same time, some SPG members — including Espinoza himself — will likely benefit from the deal. Like the concurrent trend toward consolidation in the airline industry, hotel consolidation will ultimately drive a form of reward-points inequality where the rich get richer and the middle class lose out.
The fundamental logic of a hotel rewards program goes like this: A room in a nice hotel is expensive, so if someone gets one for free she is receiving something of value. At the same time, the cost difference to a hotel of leaving a given room empty versus filling it with a guest is negligible, and if that guest buys a meal or two or some drinks at the bar it may even be profitable to let her stay in the otherwise empty room for free.
A loyalty program takes advantage of the fact that the empty room is worthless to the hotel but valuable to a potential occupant to generate some arbitrage. By giving away the empty room — whether in the form of a free stay or a free upgrade — to a frequent customer, you generate value out of nothing and encourage a set of frequent travelers to deliberately seek out your hotel. Tie-ups with credit card companies (in Starwood's case, American Express) generate a further opportunity to monetize these empty rooms.
The issue this creates for loyalists is that you are inextricably in competition with your fellow loyalty program members. Except in the depths of a severe recession, there is only so much excess capacity to go around. To get the best goodies, it's not good enough for you to be loyal — you have to be more loyal than other potential points redeemers.
All the major hotel groups operate brands at different points on the fanciness spectrum, and Starwood and Marriott are no exception. But broadly speaking, their portfolios are weighted differently. Marriott is much larger, with 4,300 hotels to Starwood's 1,270, and a larger share of Marriott's hotels are utilitarian spots (think the Courtyard, Residence Inn, and Fairfield Inn brands), while Starwood's portfolio is more weighted toward fancy hotels.
Marriott is basically a convenience option. If you have to travel frequently for work, often to miscellaneous locations, Marriott will serve your needs more effectively simply because it is much more likely that Marriott has a hotel near where you want to go.
Starwood is more of a choice for travel enthusiasts. Its rewards program is more generous and features better customer service, and its portfolio contains lots of places where it would be fun to cash in rewards stays. And if your necessary travel is overwhelmingly tilted toward major cities, then their smaller footprint won't bother you. It's a smaller chain, but it's not small per se.
A tie-up will create a company that is just bigger and able to do more. It'll be more ubiquitous than Marriott ever was by adding the Aloft, Four Points, and Sheraton brands to its already large stable of properties and offer more fancy destination getaways than Starwood ever could by aligning the Ritz Carlton and JW Marriott brands with Starwood's existing high-end portfolio.
But here's where the limited amount of excess capacity comes into play. Even if the merger goes off perfectly smoothly and lives up to its full business potential, it's not possible for everyone to win in the rewards game. The merged company will have more hotels, and therefore more excess capacity to go around. But it will also have more loyalty program members looking to soak up that excess capacity.
And since Starwood's portfolio is disproportionately tilted toward destination properties while Marriott's client base is disproportionately tilted toward utilitarian frequent travelers, you'll see more Marriott loyalists cashing in at Starwood properties than Starwood loyalists wanting to cash in at Marriott properties. For the very top-end Starwood elites, that's no problem. They'll still be at the front of the line for goodies, and they'll have an expanded portfolio of hotels to take advantage of. But for the middle class in the Starwood program, it's going to be a huge problem — they'll be pushed down in the pecking order and find it harder and harder to gain access to the hotels they want to stay in.
This is essentially what we've seen happen in repeated rounds of airline loyalty program revaluations (most recently American Airlines) in the wake of industry consolidation. Building a larger network means more convenience for fliers with the highest tiers of frequent flier status, but it's also meant there's less excess capacity to share with lower-tier elites. Airline after airline has responded to this by devaluing the lesser tiers of its loyalty programs in order to focus on the newly enlarged bloc of superloyalists. It's just another way in which broad economic trends toward bigger and bigger scale support winner-take-all markets and create unequal distribution of gains.
The New York Taxi & Limousine Commission has released an amazing data set containing information about every public taxi trip taken from 2009 to 2015. Software developer Todd W. Schneider crunched the numbers and produced a fascinating set of gorgeous maps that provide insight into the rhythms of America's biggest city.
On the map above (see a high-res version here), dots represent taxi drop-offs, with brighter dots reflecting locations where more drop-offs occurred. Unsurprisingly, the map is brightest in Midtown and Downtown Manhattan. There's also significant action in the innermost parts of Brooklyn and Queens (just to the right of Manhattan on the map). And New York's two airports, LaGuardia and JFK, shine particularly brightly.
There are separate white and green areas because New York distinguishes between yellow taxis — which mostly serve Manhattan — and green taxis that serve the outer boroughs.
Schneider explores many aspects of New York life, from the times employees arrive at major Wall Street banks to the average time it takes to drive to the airport from various locations on various days.
For example, here's a fun map showing where to go for New York City nightlife:
Schneider generated this map by looking at the areas where a disproportionate share of taxi pickups occur late at night — defined as 10 pm to 5 am. He assumes this means people have been out partying. As you'd expect, Williamsburg, Greenpoint, and Bushwick in Brooklyn, Jackson Heights and Astoria in Queens, and the Lower East Side in Manhattan, are hot spots.
There are a lot more interesting maps and charts where these came from. Check them out.
Japan is back in recession. The country's GDP shrank 0.8 percent in the third quarter of 2015 after shrinking in the second quarter, so it meets the technical definition. On its surface, this looks like a damning indictment of "Abenomics" — a program of aggressive money printing that Prime Minister Shinzo Abe ordered upon taking office a few years back in order to jolt the Japanese economy out of its doldrums. But look closer and you'll see that the opposite is the case.
The Japanese economy is shrinking because Abe already succeeded in fixing Japan's unemployment problem. Japan is simply in an odd situation where low and falling levels of unemployment aren't good enough to ensure economic growth.
First things first — Japan's unemployment rate has tumbled, reaching a low point it never achieved during the previous global expansion phase:

(Tradingeconomics.com)
And unlike in the United States, the labor force participation rate of working-age adults has soared to a record level:
Abenomics, in other words, has accomplished exactly what macroeconomic stabilization policy is supposed to accomplish — while millions of able-bodied Americans and Europeans sit idly, Japan has achieved something close to full employment.
So why is the Japanese economy shrinking? Well, it's pretty simple. The country is running out of people:
In the context of a working-age population that's shrinking 1.5 percent a year, an economy that is "only" shrinking at 0.8 percent per year is actually doing okay. If you define a recession as two consecutive quarters of negative GDP growth, then a country like Japan, where the population is shrinking, is going to tumble into recession basically every time anything even slightly bad happens.
You might or might not think this is a problem, but either way it's clearly not something monetary policy could solve. For a while, monetary policy was effective at solving the problem of unemployment, which helped make up for the declining working-age population. But now that Japan has achieved full employment, only a surge of people or a sustained increase in the productivity growth rate can generate consistent positive GDP numbers.
Can we be sure that Abenomics is responsible for the recovery in the Japanese labor force? It's hard to prove anything conclusively in macroeconomics. But we can see that the Japanese price level has stopped falling ever since Abe came to office determined to make it stop falling:

In three years, Abenomics has restored prices to their mid-2010 level pic.twitter.com/aLGCW6ZCwU


In tandem with the return of inflation, nominal GDP growth — which is key to ensuring full employment — has set in:

Japan's nominal GDP crossed ¥500T for the 1st time since the financial crisis (seasonally-adjusted, annualised data) pic.twitter.com/Ip6bjmUSdY


Critics of monetary stimulus in the United States and Europe often note that it's not a panacea for every economic problem that exists. Japan is a living, breathing example of what that slogan gets right and what it gets wrong. By deploying monetary stimulus Japan was able to boost inflation and nominal GDP, increasing demand for labor, reducing the unemployment rate, and increasing the labor force participation rate. Relative to a years-long spell of mass unemployment, that's pretty good! But other aspects of the fundamental economic situation matter, too. In Japan's case, demographics is now destiny.


(Gallup)
Christmas spending is a pretty good barometer for the health of the economy. When families are doing well financially and feeling optimistic about the future, they're more likely to splurge on gifts for their loved ones. And by that metric, families are feeling better about their finances than in any year since the 2008 financial crisis.
Every November since 1999, Gallup has been asking families how much they plan to spend on Christmas presents. On average, families this year say they'll spend $830, up from the $720 they spent in 2014 and just shy of the $866 they planned to spend in November 2007.
Thirty percent of respondents said they were going to spend $1,000 or more this year, up from 25 percent last year. On the other hand, 8 percent of Americans said they didn't planned to spend anything — perhaps because they don't celebrate Christmas.
Consumers revised their spending estimates upward in the past month. In October, they told Gallup that they would spend $812, before raising the estimate to $830 in November. In most previous years, shoppers have gotten more conservative between October and November.
All of this is significant because consumers' attitudes about the economy can be a bit of a self-fulfilling prophecy. If people expect the economy to do well, they will spend more money and boost demand for goods and services. That, in turn, will allow businesses to earn bigger profits and hire more workers.
Of course, things can also turn around dramatically. A few months after that strong Christmas shopping season in 2007, the US economy suffered the worst financial crisis in decades, resulting in sharply lower Christmas spending in 2008.
The "fight for $15" campaign has helped turn a $15-per-hour minimum wage into a litmus test on the political left. Two of the three Democratic candidates for president, Martin O'Malley and Bernie Sanders, want to institute a national $15-per-hour minimum wage.
"It is not a radical idea to say that if somebody works 40 hours a week, that person should not be living in poverty," Sanders said in Saturday's Democratic presidential debate.
But as moderator Kathie Obradovich pointed out, raising the minimum wage that high could price a lot of low-wage people out of their jobs altogether. Neither Sanders nor O'Malley had a convincing response to this concern.
There's a lively debate among economists about whether higher minimum wages cause unemployment. Conservatives argue that forcing employers to pay more will force them to reduce the number of workers they hire. For two decades, liberals have been citing a famous study by David Card and Alan Krueger showing that a 1992 increase in New Jersey's minimum wage didn't cost jobs in the fast food industry — a result that ran contrary to conservative orthodoxy.
That finding has hardened into a liberal orthodoxy that higher minimum wage hikes never cost jobs. When confronted with concerns that a $15-per-hour minimum wage will reduce employment, activists brush them off, as Sanders did on Saturday, by arguing that the higher minimum will put cash in people's pockets and actually raise employment.
But Alan Krueger, the co-author of that famous fast food employment study and a former adviser to the Obama administration, isn't so sure. He supports Hillary Clinton's plan to raise the minimum wage to $12 per hour. But in a New York Times op-ed last month, he argued that "a $15-an-hour national minimum wage would put us in uncharted waters, and risk undesirable and unintended consequences."
There's extensive research on how small increases in the minimum wage affect employment — Vox's Matt Yglesias summarized some of it here. But we simply don't have experience with the kind of large increase Sanders and O'Malley are proposing. And there's good reason to think that large minimum wage increases could cause a lot more job losses than small ones.
This is particularly important because O'Malley and Sanders are proposing a national $15-per-hour minimum wage. Setting a $15 minimum wage in San Francisco or New York is a different proposition than doing the same thing in Arkansas or West Virginia. In rich cities, most wages are already above the minimum, companies can probably pass on the extra costs to their affluent customers, and some of the burden of adjustment simply takes the form of lower commercial real estate prices. In poorer areas, it's going to be a lot harder for employers to accommodate the increase without laying off workers.
An extreme example of this comes from Puerto Rico, a US territory that became subject to the US minimum wage in 1983. Reihan Salam describes what happened next:
In the early 1990s, the labor economists Alida J. Castillo-Freeman and Richard B. Freeman found that the "U.S.-level minimum altered the distribution of earnings in Puerto Rico to an extraordinary extent," and that "imposing a U.S.-level minimum reduced total island employment by 8–10 percent compared to the level that would have prevailed had the minimum been the same proportion of average wages as in the United States." The result of this massive shock to employment levels was, according to Castillo-Freeman and Freeman, a massive wave of migration from Puerto Rico to the mainland that drew largely on "persons jobless on the island, with characteristics that make them liable to have been disemployed by the minimum wage."
This 8 to 10 percent decline in employment occurred because Puerto Rico was significantly poorer than the rest of the United States; a minimum wage that made sense on the mainland was way too high for the island.
Something similar seems to be happening in the debate over a $15-per-hour minimum wage. A $15-per-hour minimum wage may make sense for the handful of wealthy cities that have adopted it in the past couple of years. But that doesn't mean it's a good idea for the rest of the country, where average productivity is a lot lower. And while Puerto Ricans who lost their jobs were able to look for work in the much larger mainland US economy, given the scarcity of housing in rich coastal cities it's not so obvious that unemployed workers in Kentucky or New Mexico would be able to move to Boston or Seattle in search of work.
A lot of conservative voters — especially those old enough to have lived through the high inflation of the 1970s — are convinced that America is currently suffering from an inflation problem. Sen. Ted Cruz (R-TX) pandered to those voters in a recent Republican presidential debate, blaming the "loose money" policies of the Federal Reserve for raising the prices of various consumer products.
But new data released Friday by the Bureau of Labor Statistics shows that overall, prices aren't going up. At all.
Between September and October, prices actually fell slightly. And over the past year, the inflation rate was exactly 0.0 percent.
To be fair, this is mostly because energy prices have fallen dramatically over the past year. If you ignore volatile food and energy prices, then prices rose 1.9 percent, just shy of the Federal Reserve's 2 percent inflation target. Ironically, inflation hawks have long complained that this measure, known as the "core CPI," understates inflation by ignoring rising food and energy costs. But right now, with energy prices falling, the opposite is true. Another measure favored by the Fed, known as the core personal consumption expenditures index, also shows inflation below the 2 percent target.
But either way, concerns that the Federal Reserve's zero interest rate policy will produce high levels of inflation have proven misplaced. No matter how you look at it, the inflation rate is below the Fed's 2 percent target. And that's been true for a while. Since 2008, when the Fed cut interest rates to near zero, the average inflation rate during that period has been about 1.4 percent. It's been the least inflationary period in 50 years.
The moderators at Tuesday night's Republican debate spent a surprising amount of time talking about one of the least exciting but most important economic issues: monetary policy. During the course of the debate, Ben Carson, Ted Cruz, Rand Paul, and Chris Christie all commented on the policies of the Federal Reserve. And all agreed that the Fed was doing too much to try to support the economy. None spoke in defense of recent Fed policies to boost the economy by pumping money into the financial system.
Their economic arguments of these candidates were dubious, as we've argued here, here, and here. But the Republican Party's growing hawkishness on monetary issues also carries a huge political risk.
Low interest rates and loose money boost the economy, making it easy for incumbents to win reelection. Tight money has the opposite effect. So if Republicans turn monetary policy into a partisan issue — with Republican administrations adopting tight money policies and Democrats favoring looser money — they will be handing Democrats a huge electoral advantage.
History is full of examples of Federal Reserve decisions shaping the fortunes of presidents:
Reasonable people can disagree about the economic merits of the Fed's policies in some of these cases. But it's clear that politically speaking, looser money is better for the incumbent party. Loose money promotes a short-term economic boom that boosts incumbents' chances of reelection.
Of course, lower interest rates aren't always a good idea. When inflation is high, cutting rates can make the problem worse. President Carter understood perfectly well that tight monetary policy could be bad for his political career, but he appointed an inflation hawk like Volcker anyway because he thought tough medicine was needed to combat the nation's inflation problem.
If today's economy looked like the economy of the 1970s, the Republicans' hawkish views would have a lot of merit. But today's economy is dramatically different from the economy of the Carter and Reagan years. Since the 2008 financial crisis, the inflation rate has averaged about 1.4 percent. That makes it the least inflationary period in a half century. And market forecasts suggest there's very little inflation on the horizon.
In that economic environment, pushing for tighter money isn't just bad politics, it's bad economics too. For example, in 2011 the European Central Bank believed that the worst of the eurozone recession had passed, so it raised interest rates. That proved to be a huge mistake that tipped the eurozone economy into a double-dip recession. Countries like Greece and Spain are still feeling the pain today.
Fortunately, the economy seems to be healthy enough that a modest interest rate hike probably wouldn't tip us back into recession. Indeed, the Fed is expected to begin raising interest rates soon — perhaps as early as next month and almost certainly before Janet Yellen's term expires in 2018.
The larger danger is that tight money orthodoxy could prevent the Fed from responding effectively the next time a recession occurs under a Republican president. In the wake of the 2008 recession, Ben Bernanke aggressively eased monetary policy, cutting short-term interest rates to zero. Critics have derided these low rates as "artificial" and "extraordinary," but many economists believe Bernanke's decisive action saved the US from a much worse calamity.
And there's a lot of reason to think today's environment of low interest rates and low inflation will be with us for a long time to come. Japan has had near-zero interest rates and very low inflation for two decades. Interest rates and inflation are low in the eurozone, the United Kingdom, Canada, and other rich countries.
This means the next recession is likely to once again require the Fed to quickly cut interest rates to zero. If the chair of the Fed is a Republican who shares the monetary policy views of Rand Paul, Ben Carson, or Ted Cruz, there's a real risk the Fed won't respond quickly enough, leading to a more severe recession and a slower recovery.
First and foremost, that would be a disaster for the country. But it would also be a political disaster for the party that controls the White House, because the performance of the economy is one of the biggest factors driving presidential elections. When the economy is doing well, the incumbent's party tends to win reelection. When the economy is doing poorly, voters like to throw out the incumbents and elect the other party.
So if monetary policy becomes a partisan issue — with Republicans favoring tight money and Democrats facing looser money — that will be bad for the reelection prospects of Republican presidents. Democratic presidents will enjoy the tailwinds that come from a favorable interest rate environment, while Republican presidents are forced to fight against the headwinds created by unnecessarily tight money.
And there's no reason monetary policy should be a partisan issue. We've already seen that Presidents Richard Nixon and George H.W. Bush lobbied the Fed for looser money during their presidencies. Ben Bernanke has become a villain for much of the right, but he was appointed to lead the Fed by a Republican president, George W. Bush, just 10 years ago.
Indeed, the 20th century's most prominent free market economist, Milton Friedman, famously argued that tight money had worsened the Great Depression. In 2000, he urged Japanese monetary authorities to undertake a program of quantitative easing that sounds a lot like the expansionary monetary policy the Bernanke Fed undertook a decade later.
Yet Friedman's intellectual heirs on the right, including National Review's Ramesh Ponnuru, the American Enterprise Institute's James Pethokoukis, and the Mercatus Center's Scott Sumner, seemed totally unrepresented on Tuesday's debate stage. It seems that tight money is becoming a Republican orthodoxy, and that would be not only an economic disaster for the country but a political disaster for the GOP.
In Tuesday night's Republican debate, Rand Paul argued that a root cause of growing inequality in America is the Federal Reserve and its policy of low interest rates.
"By artificially keeping interest rates below the market rate, average ordinary citizens have a tough time earning interest," Paul said. "As the Federal Reserve destroys the value of the currency, what you're finding is that if you're poor, if you make $20,000 a year and you have three or four kids and you're trying to get by, as your prices rise, these are the people hurt the worst."
This line of argument has some intuitive appeal, as evidenced by the many Republicans in Tuesday's debate who blamed the Fed for America's economic problems. But it actually makes very little sense.
The most obvious problem with Paul's argument is that Fed policies have actually produced below-average inflation. Data from the Bureau of Labor Statistics show that the average inflation rate since the fall of 2008 has been about 1.4 percent per year. That's below the Fed's longstanding target of 2 percent annual growth. And it's the least inflationary period in the past half-century.
Markets are also projecting that the average inflation rate will be 1.74 percent over the next decade. So there's zero evidence that the Fed is driving up the cost of living for poor people or anyone else.
Paul ignores the fact that ordinary people don't just save money, they borrow it too. If you've bought a house in the past few years, you probably benefited from today's exceptionally low interest rates. If you bought a house 10 or 20 years ago, you probably benefited from being able to refinance your mortgage at a lower interest rate. That's thousands of dollars in lost income for big banks.
People used to understand that low interest rates are good for ordinary people. Back in the 1990s, politicians would frequently argue that we needed to cut the deficit in order to bring interest rates down. Low interest rates make it easier for people to buy houses and cars, borrow money to start a business, pay for their student loans, and so forth.
People used to understand that low interest rates are good for ordinary people
At the same time, anyone who's saving for retirement by putting cash in a savings account is making a big mistake — whether interest rates are currently high or low. Experts advise people to put their retirement savings into a diversified portfolio of stocks and bonds. History suggests that this kind of portfolio is likely to outperform a conventional savings account over the long run — and it's not as tied to short-term interest rate moves by the Fed.
The broader problem with Paul's arguments is that the Fed doesn't actually have that much control over interest rates.
Think of a guy driving along a winding mountain road. In one sense, he has total control over where the car goes. If he turns the steering wheel to the right, the car goes right. But that doesn't mean he can drive the car wherever he wants. If he steers too far to the right, he'll go through the guardrail and off the cliff. If he steers too far to the left, he'll run into the mountain on the other side of the road.
The Fed doesn't have that much leeway to raise rates if it wants to avoid hurtling over the cliff and into a big recession
The Fed is in a similar situation. It's trying to steer a course between the twin evils of inflation and recession. If it keeps rates too low for too long, the economy will start to overheat, and inflation will get out of control. If the Fed raises rates too quickly, it'll tip the economy back into recession. So it's true that at any particular instant, the Fed can make interest rates go up and down. But the Fed doesn't have that much leeway to raise rates if it wants to avoid hurtling over the cliff and into a big recession.
The European Central Bank did exactly that when it raised interest rates prematurely in 2011. That proved to be a huge mistake, because it tipped the eurozone economy into a double-dip recession. Countries like Greece and Spain are still feeling the pain today.
A key thing to notice here is that the ECB didn't just damage Europe's economy with its interest rate hike, it wasn't even able to keep interest rates up for very long. Before the end of the year, it became obvious that the higher rates were hurting the economy. The ECB was forced to reverse itself and return interest rates to their previous level. Today rates are even lower than they were in 2011, and that year's premature interest rate hike is part of the reason.
So if you want higher interest rates in the long term, you should be rooting for the Fed not to make the ECB's mistake. Low rates accelerate the economy, getting us more quickly to a point where the economy is healthy enough that private demand for capital pushes rates upward.
If you follow sports, you've likely seen dozens of advertisements for DraftKings and FanDuel, two companies that have pioneered a relatively new type of online gambling known as daily fantasy sports. A few weeks ago, the sports world was rocked by revelations that a DraftKings employee with access to proprietary DraftKings data had won $350,000 in a FanDuel contest. That naturally led to speculation that his access to DraftKings data had given him an edge at FanDuel.
Since then, federal and state regulators have been subjecting the two companies to greater scrutiny.
In October, the Wall Street Journal reported that DraftKings received a subpoena from US prosecutor Preet Bharara, who was probing whether a DraftKing employee misused proprietary information and whether the business models of DraftKings and its major competitor, FanDuel, are running afoul of federal gambling laws.
Now the companies are facing unwanted attention from New York's powerful attorney general too. According to the New York Times, Attorney General Eric Schneiderman has ordered DraftKings and FanDuel to stop taking bets in the state of New York, where DraftKings has 500,000 users.
The companies deny their services are illegal gambling, and they could still fight the order in court. But the fact that multiple public officials are raising concerns about the legality of daily fantasy sites is an ominous sign for both companies.
Fantasy sports have been around for decades; the concept first became popular for baseball before spreading to other sports. And in the early days, fantasy baseball wasn't such a big business.
The concept caught on first in baseball thanks to the wealth of statistics available about baseball games
It worked like this: At the beginning of the season, you would assemble an imaginary team — a pitcher, catcher, shortstop, and so forth — using the names of real, active players. Then, over the course of the season, your fantasy team would rack up points based on the real-world performance of the players you've chosen. You might also be able to trade players in your lineup with others in your fantasy league midway through the season. At the end of the season, the contestant whose imaginary team earns the most points wins the league.
The concept caught on first in baseball thanks to the wealth of statistics available about baseball games. As the internet made it easier to find information about other sports, the concept spread beyond baseball — especially to football.
In the past five years, a variant called daily fantasy sports has become popular. The basic concept — choosing fantasy teams and racking up points based on players' real-world performance — is the same. But whereas conventional fantasy sports provided fun, low-stakes entertainment for a group of friends (albeit often with some money at stake), daily fantasy leagues look a lot more like conventional sports gambling.
The daily fantasy market is dominated by two relatively new companies: FanDuel (which has a partnership with Vox Media's sports site SB Nation) and DraftKings. Players might pay $5, $25, or $100 to enter a contest, and they can win prizes as large as $1 million. Rather than just competing against a few friends, people compete with thousands of strangers from across the country. Both companies have raised millions of dollars in venture capital, and they say they'll pay out more than a billion dollars in prizes in 2015.
Major sports leagues lobbied for the ban on internet gambling Congress passed in 2006 that shut down internet poker and other online gaming. But they also convinced Congress to carve out an exception for fantasy sports leagues because they boost fan interest in watching sports. As a result, fantasy leagues are the only form of sports betting that's legally available to most Americans.
Companies like FanDuel and DraftKings have taken full advantage of the loophole. Today's daily fantasy sites feel more like professional gambling operations than a friendly office pool. And at least one legal expert believes these sites are bumping up against the legal limit under federal law.
In the process, these companies have created an awkward situation for the NFL. In the past, it was easy for the NFL to argue that it should be in a different legal category from conventional sports betting. But daily fantasy leagues are blurring this line.
A few weeks ago, we learned that DraftKings employee Ethan Haskell did two things on Sunday, September 27:
Naturally, a lot of people wondered if these events were connected. Because the payouts in daily fantasy games go disproportionately to the top players, data about which athletes are most and least popular among other fantasy players can help a contestant boost the odds of winning. And while Haskell didn't have access to any data about FanDuel users, the DraftKings and FanDuel contests are similar enough that data about DraftKings players' bets should have provided a lot of insight about both sites.
However, DraftKings insists that nothing of the sort happened. The company says FanDuel's deadline for choosing players was 1 pm, while Haskell didn't get access to the DraftKings data until 1:40 pm — so data from DraftKings couldn't have helped him assemble his winning FanDuel roster.
Knowing how other users have bet can help a user stand out from the crowd
And to be clear, the data Haskell released was not sufficient, on its own, to win money. Far from it. Winning requires choosing a roster of players who perform well in a particular set of games. No one can know that in advance. So even someone who has data about other players' rosters will only be able to win a small percentage of the time.
But daily fantasy sports, like most betting, is a game of averages. Knowing how other users have bet can help a user stand out from the crowd. And even modest improvements in the odds of winning can add up over the course of many bets.
In a brief joint statement released in early October, DraftKings and FanDuel insisted that they have strict policies in place to prevent employees from cheating on fantasy games. They also temporarily banned employees from playing on competing sites (employees were already banned from playing on their own sites).
The big worry for DraftKings and FanDuel is that the controversy over Haskell's winnings — whether or not they were based on inside informaiton — will cause policymakers to reconsider whether daily fantasy sports sites are, or should be, legal under federal law. Bharara might conclude that critics of DraftKings and FanDuel are right, and the sites don't actually qualify for the fantasy sports exemption. If he does, that could lead to a big legal battle that could force the sites to radically change their services or shut down altogether.
It's also possible that Congress could become involved. Congress exempted fantasy sports from its online gambling ban at a time when fantasy leagues looked very different from conventional online gambling. But Congress could revisit that decision and impose new restrictions — restrictions that could make these fantasy sites much less profitable. At least one member of Congress has questioned whether the line drawn between fantasy sports and other forms of sports betting makes any sense.
Of course, that line of reasoning could lead in one of two directions. One option would be to narrow the fantasy sports exemption and more strictly regulate — or ban altogether — sites like DraftKings and FanDuel. Or Congress could decide that online gambling really doesn't pose a threat to the republic and opt to open up the market to other forms of internet betting.
Amazon opened a physical bookstore this week (it is called Amazon Books), prompting many to ask why the company that destroyed the physical bookstore industry would possibly want to operate a physical bookstore. You can make it sound a bit less odd by noting, "At Amazon Books, you can also test drive Amazon’s devices," meaning Kindles, Echos, Fire TVs, and Fire Tablets "are available for you to explore, and Amazon device experts will be on hand to answer questions and to show the products in action." Apple has physical retail stores for its digital devices, as do (albeit less successfully) Microsoft, Sony, and Samsung. Since Amazon makes Amazon-branded devices, why shouldn't it have a store too?
But the bookstore framing is no coincidence, and the reality is that something bigger and more profound is happening than a simple desire to let people window shop for Fire TV sticks. Amazon is opening a bookstore for two big reasons:
For years now, Amazon has been the most terrifying competitor on the planet. And though a single bookstore in a single mall in Seattle is hardly a game changer, its existence should be taken as a powerful reminder that no business of any kind should view itself as protected from Bezos's plan for global domination.
Large American technology companies like Apple, Google, Facebook, and Microsoft are ridiculously profitable and, indeed, infamous for the lengths to which they go to avoid paying corporate income tax on their gargantuan profits. Since Amazon is also a large American technology company, it is easy to assume that it, too, must be ridiculously profitable. But this is not the case. The retail industry has traditionally been a very low-margin matter, and Amazon has outcompeted traditional retailers in part by offering even lower margins.
But that's changed recently. In the most recent two quarters, Amazon has earned meaningful profits — profits driven by the success of Amazon Web Services, an enormously popular technology infrastructure company that enjoys tech-like economics rather than retail-like ones. That means 25 percent profit margins on a business that does $2 billion in revenue a quarter and is growing at a 70 percent rate.
As the technology industry analyst Ben Thompson put it, Amazon became profitable because "AWS is simply spinning off more cash than Amazon knows what to do with."
The key to understanding Amazon as a business is that earning a profit is antithetical to its corporate culture and mission. Rather than increasing the value of Amazon stock by pushing out cash to shareholders, Bezos's strategy is to increase the value of Amazon by literally making the company bigger. Each year, Amazon owns more warehouses, more customer data, more intellectual property, wider distribution channels, etc., and therefore becomes a more valuable enterprise than it was before.
On occasion, Amazon will turn a profit either to prove to Wall Street that it can or else because (as with AWS recently) a particular venture simply proves more lucrative than expected.
But that AWS revenue was never going to sit around in the corporate treasury or be paid out as dividends. A surge in revenue needs to be met by a surge in new expenses.
So why brick-and-mortar retail? Most likely because Amazon's long-term strategy is simple: It wants everyone, everywhere to buy everything from Amazon.
And it's clear that whatever the struggles of some major big-box retail chains lately, people do in fact continue to buy things in stores. For some people, some of the time, a physical store is where they want to shop. These days you probably could buy everything you need online, but almost nobody actually does. Which means nobody buys everything from Amazon. Which is unacceptable.
So why is it a bookstore? For the same reason Amazon.com was originally an online bookstore. You've got to start somewhere, and the book industry is a relatively soft target. Since Amazon's already basically crushed the national bookstore chains, nobody can really stop the company from getting a foot in the door of this niche.
Ultimately, it might be a total dead end. But even if the effort to establish stores fails, it will be a potentially valuable learning experience. Amazon prides itself on a value it calls "customer obsession," but lacking a physical presence the company ends up with a somewhat limited view of what its customers look like and how they behave. A retail presence can help change that.
The bigger, less irony-laden thing that Amazon is working on right now is same-day delivery for Amazon Prime members. Currently, same-day delivery is sporadically available — for some products, in some cities, some of the time. It feels kind of like magic when it works, but it's not nearly predictable enough right now to be a real driver of business rather than an impressive occasional delight for customers.
Amazon's long-term aspirations in this field appear to involve fleets of driverless trucks and even flying delivery drones.
But in the human-powered present (and perhaps even in the drone-full future) same-day delivery requires stockpiles of merchandise that are more numerous and located more directly adjacent to population and transportation hubs than the company's existing warehouses. The geography of same-day delivery depots, in other words, looks a lot like the geography of classic big-box stores. You wouldn't have just one Borders serve an entire region. Instead, a given metro area would feature one or more downtown locations plus a bunch of mall spots in the surrounding suburbs. The goal was to ensure that nobody who bought books regularly was ever all that far from a Borders.
Essentially replicating this structure but combining it with Amazon's logistics infrastructure, immense supply chain bargaining power, vast stockpile of consumer knowledge, and the Prime subscription revenue model is at least a plausible vision of the future. And if the depots can also serve as showrooms for Amazon hardware and also help get traditional brick-and-mortar shoppers into the Amazon lifestyle, then why not?
Bitcoin hasn't received the kind of hype in 2015 that it has in previous years. But outside the spotlight, the Bitcoin economy has continued to grow slowly but steadily. And in the last few weeks, the value of Bitcoin has soared. One bitcoin cost $236 at the beginning of October. Now, five weeks later, it costs $426.
No one is sure why the currency has had such a dramatic surge. But it's at least partly a sign of growing investor confidence in the growth of the underlying Bitcoin economy. Here are five charts that show Bitcoin's progress.

(Bitcoincharts.com)
One bitcoin was worth around $320 at the start of 2015, and it was below that level for most of the year. But last Friday, it rose above $320, and then shot up to more than $420 in the last couple of days.
To be sure, this is far from the currency's all-time record: One bitcoin was worth more than $1,000 in late 2013, and it lost 60 percent of its value in 2014. But the past few weeks' boom suggests that after months of growing pessimism, Bitcoin speculators are becoming more optimistic again.
The best way to estimate Bitcoin's long-term growth isn't by its price — which is hugely affected by speculation and media hype — but by the volume of transactions on the Bitcoin network. Over the long run, a growing volume of Bitcoin transactions is a strong signal that people are finding the network more and more useful. And this year we've seen steady — though not spectacular — growth in the number of bitcoin transactions.
This growing transaction volume is a healthy sign for Bitcoin, but it's also a potential problem, because right now the network has an artificial limit on the total number of transactions it can handle. The network will hit this limit in a couple of years if changes aren't made to the Bitcoin software — and the Bitcoin community has yet to reach an agreement about what to do about this.

<!--
new pym.Parent('vox-bitcoin-investments__graphic', '//apps.voxmedia.com/at/vox-bitcoin-investments/', {xdomain: '.*\.voxmedia\.com'});
// -->

Bitcoin hasn't received nearly as much attention from the media this year as it did in 2013, but Bitcoin-based startups continue to be of great interest to venture capitalists. With two months remaining in the year, there has already been $468 million invested in Bitcoin startups — more investment than in any previous year. Bitcoin has yet to break into the mainstream, but a lot of investors are betting it will do so soon.
This chart from the Bitcoin startup Bitpay shows how its business has grown in various parts of the world. Bitpay helps merchants accept Bitcoin payments. Like most Bitcoin startups, Bitpay is based in the United States, so its business was originally skewed toward the US. But recently that's been changing. Europe zoomed ahead of the United States in the first half of 2015, and Latin America has seen rapid growth.
This might be because in many ways the US is the least promising market for Bitcoin. One of the big promises of the technology is that Bitcoin could serve as a global standard, allowing people in different countries to interact. That's not a very strong selling proposition in the United States, which is a single integrated market where people tend to all use the same payment methods.
But Bitpay says that despite the euro, "traditional payments systems in Europe are still very localized and disjointed throughout the continent." The same is true in Latin America. In areas where people are used to juggling many different payment methods, adding Bitcoin to the list is an easier sell.
A Bitcoin ATM looks much like a conventional ATM. It allows people to insert dollars (or other local currencies) and get bitcoins in exchange. Some machines also allow the opposite: Customers can send bitcoins to the machine and get cash.
This provides a key bit of infrastructure for the Bitcoin ecosystem, because it means that anyone who wants some bitcoins can get them easily. Among other applications, these machines provide an alternative to conventional money-transfer services like Western Union: Someone can put cash into an ATM in New York and send bitcoins to a family member in Argentina or Thailand, who can then use another machine to get out the local currency.
However, right now Bitcoin ATMs are too expensive for this to be practical. Average fees are around 5 percent on each end of the transaction, so using them as a Bitcoin-based money transfer service costs about 10 percent — more than a conventional money transfer service. Bitcoin ATM owners will need to bring these fees down if they want the machines to be more widely used.
For years, if you liked a tweet you could click a little star icon to "favorite" it. But Twitter has decided that this concept is too confusing, so it's rebranding it as a "like" button (that sounds familiar) and replacing the star with a heart:

You can say a lot with a heart. Introducing a new way to show how you feel on Twitter: https://t.co/WKBEmORXNW pic.twitter.com/G4ZGe0rDTP

This is part of a larger campaign by Twitter to expand the appeal of its social network. Twitter is extremely popular among journalists and the tech elite, but it has fallen far behind Facebook among ordinary users. Twitter has about 320 million users, compared with 1.5 billion Facebook users. That's upsetting to Wall Street, which wants to see Twitter earn Facebook-like profits instead of the losses it's been suffering quarter after quarter.
Twitter has been trying a variety of things to make itself more accessible, including a "moments" tab that displays curated collections of tweets about news stories and a "while you were away" feature that shows occasional users the most interesting tweets that appeared since they last logged in.
Unsurprisingly, lots of people on Twitter had opinions, and made jokes, about the change:

Pretty happy everyone else on Twitter is talking about the star wars as well


I've learned 3 things from Twitter: 1) People hate change. 2) People accept change. 3) We'll all be dead in 100 years and no one will care.


Personally, I think we should have the option of using *all* of the Lucky Charms.


ironically, twitter didn’t use its OWN NEW FEATURE — polls — to learn that no one wants hearts


Retweets to be renamed pokes



what's ❤️ got 2 do, got 2 do w/ it what's ❤️ but a 2️⃣✋emotion  what's ❤️ got 2 do, got 2 do w/it who needs a ❤️ when a ⭐️ can't be broken⁉️


This is your daily reminder that there are other things happening in the world, and people who don't use Twitter exist!

.@Twitter we’re glad you had a change of heart. We like you even more!
People on both the left and the right are arguing that the Federal Reserve is hurting savers by keeping interest rates low.
On the left, there's Ralph Nader, who recently wrote a polemic from "Savers of America" arguing that Fed policies constituted a massive transfer of wealth from ordinary Americans to big banks.
From the right, Ben Carson argues that low interest rates hurt "poor people and the middle class," who used to be able to accumulate wealth with a savings account.
This line of argument clearly has intuitive appeal since it is popping up in diverse situations, but it actually makes very little sense. For one thing, a lot of "poor people and the middle class" borrow more than they save, so low interest rates are actually good for them. But more fundamentally, if the Fed were to raise interest rates aggressively and prematurely, it would be a disaster for everyone.
The most obvious problem with the Nader and Carson arguments is that they ignore the fact that ordinary people don't just save money, they borrow it too. If you've bought a house in the past few years, you probably benefited from today's exceptionally low interest rates. If you bought a house 10 or 20 years ago, you probably benefited from being able to refinance your mortgage in the past few years. That's thousands of dollars in lost income for the big banks Nader loathes so much.
People used to understand that low interest rates are good for ordinary people. Back in the 1990s, politicians would frequently argue that we needed to cut the deficit in order to bring interest rates down. Low interest rates make it easier for people to buy houses and cars, borrow money to start a business, pay for their student loans, and so forth.
People used to understand that low interest rates are good for ordinary people
At the same time, anyone who's saving for retirement by putting cash in a savings account is making a big mistake — whether interest rates are currently high or low. Experts advise people to put their retirement savings into a diversified portfolio of stocks and bonds. History suggests that this kind of portfolio is likely to outperform a conventional savings account over the long run — and it's not as tied to short-term interest rate moves by the Fed.
The broader problem with Nader and Carson's arguments is that the Fed doesn't actually have that much control over interest rates.
Think of a guy driving along a winding mountain road. In one sense, he has total control over where the car goes. If he turns the steering wheel to the right, the car goes right. But that doesn't mean he can drive the car wherever he wants. If he steers too far to the right, he'll go through the guardrail and off the cliff. If he steers too far to the left, he'll run into the mountain on the other side of the road.
The Fed doesn't have that much leeway to raise rates if it wants to avoid hurtling over the cliff and into a big recession
The Fed is in a similar situation. It's trying to steer a course between the twin evils of inflation and recession. If it keeps rates too low for too long, the economy will start to overheat, and inflation will get out of control. If the Fed raises rates too quickly, it'll tip the economy back into recession. So it's true that at any particular instant, the Fed can make interest rates go up and down. But the Fed doesn't have that much leeway to raise rates if it wants to avoid hurtling over the cliff and into a big recession.
The European Central Bank did exactly that when it raised interest rates prematurely in 2011. That proved to be a huge mistake, because it tipped the eurozone economy into a double-dip recession. Countries like Greece and Spain are still feeling the pain today.
A key thing to notice here is that the ECB didn't just damage Europe's economy with its interest rate hike, it wasn't even able to keep interest rates up for very long. Before the end of the year, it became obvious that the higher rates were hurting the economy. The ECB was forced to reverse itself and return interest rates to their previous level. Today rates are even lower than they were in 2011, and that year's premature interest rate hike is part of the reason.
So if you want higher interest rates in the long term, you should be rooting for the Fed not to make the ECB's mistake. Low rates accelerate the economy, getting us more quickly to a point where the economy is healthy enough that private demand for capital pushes rates upward.
From all the hype and trend pieces around Airbnb and other online room-rental platforms, you might have the impression that the hotel industry is in some kind of severe slump. But as this great chart from Bill McBride and Calculated Risk shows, exactly the opposite is the case.
America has never had so few vacant hotel rooms:
So what's behind this?
Well, first and foremost it's the ongoing recovery from the Great Recession. There are more people alive today than there were in 2007 or 2000, so even though the labor market isn't as tight as it was in those peak years, there are more total employed people.
But the second factor is that we've had very little new hotel construction in the past few years. That largely speaks to both the severity of the recession and its specific nature arising in the construction and construction-finance sectors. And that's why the hotel room shortage ultimately should turn out to be good news for the broader economy. It's clear at this point that there are markets in the United States where it would be profitable to build more hotels, which would mean more construction jobs in the short term and more hospitality employment in the longer term.
Apple is the world's most valuable company by a wide margin, and on Tuesday it released financial results that demonstrated why its stock is valued so highly by investors. Apple reported profits of $11 billion for the quarter that ended in September on revenue of $51.5 billion. That's more than the combined profits of Google ($4.7 billion) and Microsoft ($5.8 billion) — two companies that are, by any normal standard, huge engines of profit. And the year's biggest profits are yet to come, as Apple always posts the best financial results over the holiday shopping season.
What has allowed Apple to deliver such spectacular financial results quarter after quarter is the staggering success of the iPhone, arguably the single most commercially successful product of all time. The iPhone allows Apple to stand in a class of its own in the smartphone world. Android-powered phones are, collectively, very popular, but companies making them have struggled to make a profit in the face of fierce competition and falling prices. Apple has actually seen average iPhone prices rise, allowing Cupertino to enjoy 39.9 percent profit margins — an unheard-of sum for a product in a competitive market.
And Apple expects to have many more quarters of strong economic performance. Not only will loyal customers in rich countries want to upgrade to the latest model every two or three years, but Apple sees big opportunities in China and other developing countries. Right now most Chinese consumers simply can't afford the high price of an iPhone. But Apple's Chinese sales have been growing rapidly — nearly doubling over the past year — and as China's economy develops, Apple is expecting the flood of new customers to continue.
To understand why Apple is such a huge and profitable company, you really only have to look at a single product: the iPhone. The iPhone accounted for 62 percent of all Apple revenue last quarter, and as Apple has become more successful, the phone has become more and more important to Apple's bottom line.
As iPhones get more expensive, they're getting more lucrative too
Apple sold 48 million iPhones in the quarter that ended in September, generating $32 billion in revenue. That's up from 39 million iPhones and $24 billion in revenue in the same quarter of 2014.
Not only is Apple selling more iPhone than ever, but it's making more money on them too. Apple has managed to raise the average price of the iPhones it sells — likely because customers are opting for models with bigger screens or more storage space. The average sale price of an iPhone during the last quarter was $670, up $67 from the same quarter a year ago.
Apple hasn't disclosed its profit margins on iPhones specifically, but teardowns have suggested that a $749 iPhone 6s Plus may cost as little as $236 to assemble. Andthe company disclosed that its overall gross margin — how much revenue is left after subtracting manufacturing costs for all Apple products — is 39.9 percent. That compares with 38 percent a year ago and 37 percent two years ago.
For any other company, Apple's other offerings — Macs, iPads, iTunes, Apple Watches, and so forth — would be considered big and successful products. Apple sold 9.8 million iPads and 5.7 million Macs. But this is a sideshow compared with the 48 million iPhones.
The rising price and profitability of iPhones is particularly impressive because the price of Android phones has been moving in the opposite direction.
At the high end of the market, Android companies have been struggling
The smartphone market is increasingly becoming two distinct submarkets. At the low end of the market — phones that cost $300 or less — Android phones are totally dominant. Indeed, because cheaper phones account for most smartphones sold, Android controls 82 percent of the overall smartphone market.
But at the high end of the market, Android companies have been struggling. While Apple has been selling more iPhones at higher prices, the sales and profits of high-end Android phones from companies like Samsung and HTC have been disappointing. Customers in the market for a luxury phone are increasingly opting for the most glamorous smartphone brand of all: Apple.
And there are signs that this bifurcation of the market — between iPhones for affluent customers and Android phones for everyone else — could become self-perpetuating. For example, I've owned Android phones for the past couple of years, and I've noticed that new apps are often developed for the iPhone first. On paper, there are a lot more Android users than iPhone users. But iPhone users are disproportionately wealthy, educated, and technologically sophisticated, so app developers have an incentive to cater to them first.
Apple also enjoys economies of scale that few of its Android competitors can match. Because Apple sells tens of millions of iPhones every quarter, it can commit to buying components at a massive scale, allowing it to negotiate big volume discounts.
You might expect that the impressive profitability of the iPhone would attract imitators, but creating a luxury smartphone platform is a lot harder than creating a luxury handbag or watch. Android-based vendors have trouble setting themselves apart when they're all based on the same software platform. And creating a new smartphone platform from scratch — and attracting the thousands of developers who would make it useful — is extremely difficult.

(ChinaFotoPress/ChinaFotoPress via Getty Images)
North America continues to be Apple's biggest market, but most of Apple's growth has come from "Greater China" — which includes Taiwan and Hong Kong. Apple's sales in China last quarter were $12.5 billion, nearly double what the company made in China a year earlier.
Apple's status as a luxury brand is even more pronounced in China than it is in the United States. For an ordinary American, $670 is a lot to pay for a smartphone. It's an even bigger outlay for the average person in China, where the per capita income is only about $7,000. In China, an iPhone is a luxury item like a Gucci handbag or a Cartier watch.
In a call following Tuesday's earnings report, Apple CEO Tim Cook argued that Apple was well-positioned for further growth in China. He expects China's middle class to grow by a factor of 10 in the coming years, and as new customers enter the middle class, Apple will be able to sell them iPhones, iPads, and other Apple products.
Apple has generated billions of dollars in profits every quarter for many years now. As a result, the company has accumulated a mountain of cash — $206 billion in total, largely held by Apple's foreign subsidiaries to minimize the corporate income tax bill. This is by far the largest cash stockpile in the world. For context, there are only 15 companies in the entire world whose total value exceeds $206 billion.
An obvious thing to do with that money is to give it back to Apple's shareholders. Earlier this year, Apple vowed to spend $200 billion on dividends and share buybacks, and it has already returned $143 billion in cash to shareholders. The more than $206 billion Apple has now is on top of money it has already pushed out to shareholders.
There is an inherent limit to the number of innovative ideas Cook and his team can conceive and execute on
The other thing Apple could do with its cash reserves is to invest them in new products and services. And the company is doing some of that too. The rumored Apple Car is one such project. We don't know how far Apple has gotten in its development process, but if it does decide to bring a car to market, it could cost many billions of dollars to do so.
Still, there is an inherent limit to the number of innovative ideas Cook and his team can conceive and execute on. So as Apple's cash pile continues to grow, Cook will face pressure to give even more back to shareholders and to lobby for changes to tax law that will allow this to be done without giving Uncle Sam an enormous cut.
Twitter stock plunged 11 percent in after-hours trading after the company released disappointing third-quarter results on Tuesday. While Twitter met its revenue target for the quarter, user growth has slowed to a crawl, and the company revised its fourth-quarter financial results downward. The news comes a couple of weeks after CEO Jack Dorsey announced layoffs of 8 percent of the company's workforce.
Dorsey is trying to turn Twitter around after a year of poor performance. "We do not expect to see sustained, meaningful growth in monthly active users until we start to reach the mass market," chief financial officer Anthony Noto said at the last earnings call in July. "We expect that will take a considerable period of time."
Twitter's dismal performance prompted one of the company's biggest investors, venture capitalist Chris Sacca, to pen a widely read memo earlier this year discussing Twitter's problems and suggesting some solutions. "Twitter has failed to meet its own stated user growth expectations and has not been able to take advantage of the massive number of users who have signed up for accounts and then not come back," Sacca wrote.

Twitter's basic problem is that it doesn't enjoy the same mass-market appeal of Facebook, which has more than four times as many users. But there's no obvious reason — save maybe the company's valuation — that that should be a problem. Twitter could arguably build a strong business by focusing on its current user base. What it's failing to do is show Facebook-like numbers, which is what Wall Street really wants from Twitter. So Twitter faces pressure to change the core service in ways that could drive off its most loyal fans.
Twitter is one of the internet's most popular sites, with more than 320 million users. But the company has fallen far behind Facebook, and user growth has been stalling recently. Twitter said that it gained just 4 million users, growing from 316 million to 320 million users. For comparison, Facebook has around 1.5 billion users.
And despite large and growing revenues, the company has struggled to turn a profit. Twitter lost $578 million in 2014. In the first six months of 2015, Twitter's revenues were an impressive $938 million, but the company lost $299 million.
On Tuesday, Twitter revealed that the third quarter has brought more of the same. Revenues were $569 million — a significant increase from last year's third-quarter revenues. But the company lost $132 million dollars for the quarter — less than they lost in Q3 2014, but still troubling for a company whose user growth has nearly stopped.

(DAMIEN MEYER/AFP/Getty Images)
Many of Twitter's strengths — and also its weaknesses — come from the fact that tweets in a user's timeline are displayed in strictly chronological order. Any time you log in to Twitter, you see the most recent tweets from people you follow.
This focus on recency makes Twitter indispensable for certain kinds of users. If you're a journalist following a breaking news story, for example, Twitter is by far the best source of information. And for people who sit in front of a computer all day, Twitter is a great way to always stay on top of the latest conversations.
But presenting tweets in a strict reverse chronological order can make the service less useful to casual users. People whose jobs don't involve sitting in front of a computer might only check in once or twice a day. They care more about seeing the most important information than the most recent. Facebook's newsfeed is designed for these users. It uses a proprietary algorithm to predict which posts users are most likely to care about, ensuring that you see your friends' wedding and pregnancy announcements.
Until recently, Twitter didn't do this. Because Twitter made little effort to prioritize tweets, users have had to do more work to make it useful. Power users carefully curated the list of people they follow to optimize their Twitter experience. A lot of casual users didn't have time for this, and as a result Twitter felt chaotic and overwhelming to them.
These different schemes for ordering posts have led the two sites to be used in different ways. Facebook has become the most popular way for ordinary users to share personal content with friends and family. Twitter, by contrast, is used in more impersonal ways. People use Twitter to see tweets from their favorite celebrities, journalists, and other public figures, to stay up to date on the news, and to share snarky insights into the news of the day.
This difference has had huge business consequences because the number of people who want to stay in touch with friends and family is vastly larger than the number of people who want to keep up with current events. Facebook had 1.49 billion monthly active users in June 2015 — more than four times Twitter's 320 million active users.
And while Facebook's audience is about four and a half times the size of Twitter's, Facebook's revenues are nearly eight times as large.
Twitter recognizes that this is an issue and has begun experimenting with new features to help casual users get value from the service. Earlier this year, the company added a "while you were away" feature to show a handful of popular tweets that were posted since your last login. A few weeks ago, Twitter introduced Twitter Moments, which presents curated collections of tweets about breaking news stories. Twitter is hoping features like this will jump-start the company's growth, but it's too soon to say if the strategy is working.
By most standards, a company with 320 million users and more than a billion dollars in annual revenue is a big success. But Twitter became a publicly traded company in 2013, and so it faces pressure from Wall Street for continued growth.
Twitter hasn't delivered:
(Statista)
In 2012, Twitter added 66 million users for a growth rate of nearly 50 percent. In 2013, the company added 51 million users for a growth rate of 25 percent. In 2014, the company added 47 million users for a growth rate of 18 percent. Between March and June 2015, the company added a paltry 2 million users. Between June and September, Twitter only added 3 million additional users. (All of these figures ignore SMS-only users, which have been growing faster in recent quarters — but not that fast.)
Meanwhile, other social networks are passing Twitter in audience size. Instagram (which was acquired by Facebook in 2012)  became larger than Twitter in late 2014. Snapchat is growing quickly and could surpass Twitter this year.
This is particularly problematic for Twitter because there are economies of scale in the advertising business. The largest internet companies — currently Google in search and Facebook in social media — can offer advertisers one-stop shopping and extremely accurate ad targeting, generating more revenue per user than a smaller service. Right now, 320 million users might seem like a lot, but in a few years it might not be enough to reach the top tier of social media sites.


Twitter's stock price is below the level of its 2013 IPO. (MSN Money)

The pressure on Twitter to accelerate growth helps to explain an otherwise puzzling fact about the company: It's losing a lot of money. In 2014, Twitter lost $578 million, only a little less than the $645 million the company lost in 2013.
It shouldn't be difficult for a company with 320 million users to turn a profit. And indeed, Twitter took in $1.4 billion revenues in 2014, more than double 2013 revenues of $665 million. But the company's costs grew almost as fast. Twitter spent $692 million on research and development and $614 million on sales and marketing in 2014.
Twitter lost another $430 million in the first nine months of 2015 — almost as much as the $452 million the company lost in the same period in 2014.
Losses aren't necessarily a cause for concern if they reflect investments that will produce more rapid growth in the future. Twitter's problem is that it appears to be spending a lot of money on engineering and marketing initiatives that don't seem to be producing much growth.
One of Twitter's strengths in its early years was a vibrant ecosystem of third-party developers. For example, when the iPhone ushered in the modern smartphone era in 2007, Twitter was relatively slow to introduce a mobile Twitter app. But luckily, Twitter was an open platform, and third parties stepped in to provide the mobile app customers demanded.
It shouldn't be difficult for a company with 320 million users to turn a profit
But everything changed in 2012, when Twitter effectively killed off third-party Twitter apps. It did this because the fragmentation of Twitter users across multiple apps made it harder for Twitter to provide a consistent user experience. Also, the popularity of third-party apps made it harder for Twitter to generate ad revenue.
But killing third-party clients had long-run costs. By souring third-party developers on the platform, Twitter deprived itself of an important source of new ideas for expanding the Twitter ecosystem. Now ideas for expanding Twitter have to come from Twitter itself. And in the past couple of years, these ideas have been few and far between.
Twitter's new CEO, Jack Dorsey, recognizes that this is a problem, and he's been working hard to win back developers' support. Last week, he publicly apologized for Twitter's previous behavior and asked developers to give him another chance.
As Twitter has posted quarter after quarter of poor financial results, a wide variety of people have weighed in with ideas for how the social media company can pull out of its current slump.
Focus on becoming more accessible. This is probably the most common suggestion, and it's the direction Twitter appears to be headed in. The basic idea is that ordinary users find today's Twitter confusing and overwhelming, and Twitter should work on ways to make the wealth of information it presents more accessible to casual users. For example, earlier this year investor Chris Sacca wrote a memo suggesting  that Twitter build a series of channels that allow people to quickly find information about particular topics, like a sports team, TV show, or election. Dorsey appears to have taken this suggestion to heart, as the recently introduced Moments feature does this.
Sacca also encourages Twitter to relax the assumption that tweets should appear in strictly reverse chronological order. Instead, when a user logs in, the platform should show a selection of the most interesting and insightful tweets that would have appeared on the user's timeline since the last check-in. Twitter took a small step in this direction earlier this year with its "while you were away" feature, but Twitter's interface is still fundamentally based on showing the most recent tweets.
The counterargument, which I made here, is that a more accessible version of Twitter already exists. It's called Facebook, and it's wildly popular. The danger is that aping Facebook might alienate existing users more quickly than it attracts new ones.
Refocus on third-party apps. Another option, promoted by analyst Ben Thompson, would be to build lots of different apps that allow people to interact with the Twitter platform in different ways. Different apps could target different types of users, with some offering advanced features to power users, while others provide casual users with simplified ways to extract value from Twitter's firehose of information.
The best way to do this would be to encourage third parties to build Twitter apps. But that's tricky because Twitter has burned a lot of bridges with developers since 2012. Dorsey's recent public apology to developers is an effort to repair these relationships and encourage more people to build for Twitter's platform.
Sell to Google. One of Twitter's most valuable assets is an unrivaled view into what's happening at this very instant. That knowledge could prove very useful to Google, whose mission is to "organize the world's information." Earlier this year Google and Twitter signed a deal to make it easier for Google to index tweets in real time. But if Twitter were a Google subsidiary, the search giant might find even more ways to extract value from this data — without requiring significant changes to the primary Twitter app.
The big problem here is that Twitter is probably too expensive. Twitter is currently worth about $20 billion, which is a lot of money even for a behemoth like Google. And Google may be able to accomplish many of the same goals at a small fraction of the price with the kind of strategic partnership the company signed earlier this year.
Just focus on power users. A final option, advocated by Vox's Matt Yglesias, is to simply accept that Twitter is never going to be a mass-market product on the scale of Facebook, and focus on serving the 320 million passionate users it has now as well as possible. This option would entail cutting back dramatically on research and marketing spending so that Twitter could earn a profit with limited revenue. The company might also focus more on selling premium ads targeted at its highly influential user base.
The problem with this option is that Wall Street would hate it. The company's current valuation of $20 billion is based on an assumption that the company will continue growing. Dorsey will face a lot of pressure to deliver on that expectation.
Worries about a financial bubble in Silicon Valley are growing. In a Monday piece for the Wall Street Journal, Christopher Mims compares the current crop of dozens of "unicorns" — tech companies worth more than a billion dollars but not traded on any stock market — to the subprime mortgage market a decade ago.
He argues that the same kind of complex, opaque financial engineering that caused people to overestimate the value of mortgage-backed securities a decade ago may be inflating the value of technology startups today. And he worries it will lead to the same kind of financial meltdown.
If the pessimists are right, the technology implosion of 2016 won't look like the one that started in 2000. That's because the market has changed a lot since the 1990s. Back then, companies tried to offer their shares to the public as quickly as possible. That meant people could watch the stocks of duds like Pets.com, Webvan, and eToys crater in realtime.
But today's hottest startups aren't traded on any public stock market. With more rich people around, it's easier than it used to be to raise money in a few big chunks from private investors. So the bubble — if there is a bubble — is mostly in companies whose stock is closely held.
The good news here is that this means ordinary investors are less likely to be burned. Joe Investor can't lose money on overvalued tech stocks because he never had a chance to buy them in the first place. The bad news, though, is that the proliferation of gigantic, privately held companies could make Silicon Valley as a whole more brittle.
When I visited the San Francisco Bay Area in May, everyone was talking about whether there was a tech bubble (and also, not coincidentally, about how expensive San Francisco real estate was). Since then, bubble talk has only gotten more common.
Last week the Wall Street Journal reported there was a "chill" among private companies trying to offer their stocks to the public for the first time. Some privately held companies have been finding that they can't get investors in the public market to pay as much for their stock as the companies were expecting. That could be a sign that the private market is getting out of whack.
The tightly knit and closed-door venture capital market can be prone to mood swings
But the Journal's evidence was highly anecdotal, focusing on a handful of startups with disappointing fundraising efforts. That might signal that technology stocks are overvalued, generally. But it might just reflect that those specific companies aren't doing well.
The respected venture capitalist Fred Wilson argues that one big problem is that companies are spending one another into huge losses in an effort to capture new markets. He points particularly to a new wave of new smartphone-based delivery apps (he didn't mention any specific companies, but Instacart and Blue Apron are two well-known examples) that seem to be offering their services at below-market rates. This obviously can't last, and Wilson predicts that some will run out of money in the next year or two.
Taking a company public has some real downsides. Last year investor Marc Andreessen told me that when you run a public company, speculators can "bat your stock around like it's a chew toy" and that volatile stock prices can be bad for the morale of employees who are compensated with stock options.
Also, public companies face more regulation now, thanks to the 2002 Sarbanes-Oxley Act, than they did in the 1990s. And public companies are increasingly targeted by activist investors who buy up a company's stock and then try to force its management to change how they do business.
But it also has a huge upside: You always know exactly where you stand, and you can easily raise more capital if you need it. Anytime a public company needs more cash, it can sell stock on the open market, getting the current market price.
By contrast, private companies raise cash in huge fundraising rounds that usually happen every year or two. If the company is doing well, each round will fetch a higher price than the one before, allowing earlier investors to make a healthy return and boosting employee morale. But if the opposite happens — known as a "down round" — it can be devastating. Not only is a declining value bad for previous investors, but it can shake the confidence of employees (who are often compensated with stock options) and customers, who might wonder if the company will still be around in a couple of years.
Because a down round can be so devastating, companies work hard to avoid them. That might mean delaying a much-needed round of fundraising in hopes of getting a better price later. And Mims says that some companies have been offering investors ever more favorable terms in an effort to inflate their paper stock values and keep up the illusion of upward momentum.
All of this means that the private venture capital market may be brittle. Public stock markets, of course, are prone to irrational swings due to investor psychology. But the tightly knit and closed-door venture capital market can be even more prone to mood swings. It could just take a few failures by overvalued "unicorns" for the venture capital world to reevaluate their entire portfolios and decide that many are overvalued.
In the past, it was rare for a venture-backed tech company to stay private for more than a few years. Either it would grow rapidly and become a publicly traded company (or be acquired by one), or it would flame out and go out of business. Silicon Valley has never had so many companies that are as large as conventional public companies but still privately held. We don't know how Silicon Valley will cope if there's a broad downturn in the value of these big, privately held technology stocks.
The optimistic view is that a downturn among private technology stocks will just mean a bunch of rich people (as well as some pension funds and university endowments) will lose money. Ordinary investors aren't allowed to invest in venture capital markets, so they won't be directly harmed the way many investors were harmed by the bursting of the dot-com bubble at the turn of the century.
Also, while some companies are struggling, others may still be doing well — so perhaps we'll see a wave of failing companies alongside others that continue to thrive.
But the pessimistic view holds that an imploding technology bubble could bring down technology companies in general — and perhaps other parts of the US economy as well. This is where the analogy to the housing markets gets scary. In theory, there was no reason falling housing prices in 2007 should have triggered a global financial crisis in 2008. But the economy is interconnected, and if venture capital firms start losing boatloads of money, it could cause a broader financial retrenchment.
And unfortunately, we don't really know when — or even if — a technology downturn will happen. Private companies only get valued when they raise money, and most companies only do that every year or two. So there's no index of private company technology stocks we can watch to see if it's falling. We just have to wait and see.
Yesterday I made the case that Uber could wind up being a bigger deal than many people think — that Uber could not only come to dominate the taxi business, but could expand the market for taxi services as well. But evaluating Uber as a player in the taxi market could underestimate the company's growth potential.
To see why, imagine it's 2000 and you're trying to predict how big Google can get. Well, you might have tried to estimate this by looking at the size of existing services that help people find information: the Yellow Pages, encyclopedias, library card catalogs, and so forth. But of course, Google wasn't just a new kind of card catalog or a better Yellow Pages. Rather, it became the default way that people found all kinds of information online.
The bullish case for Uber assumes that (as I've argued before) self-driving cars will render consumer car ownership obsolete. In a world where renting cars is the norm and buying them is the exception, the services people use to find cars for rent are going to have a lot of power. And Uber has a good shot at dominating this market in much the same way it dominates the smartphone-based taxi market today.
(Google Self-Driving Car Project)
(Google Self-Driving Car Project)
Even if self-driving car rentals will be a big market, that doesn't necessarily prove that Uber in particular will dominate that market. But Uber has some advantages that no other companies can really match.
There are two different types of companies that might compete with Uber to build apps to hail self-driving cars: tech companies like Google and Apple and car companies like Ford and Toyota. But neither type of company is as well-positioned as Uber to build a popular app for hailing self-driving cars.
The car companies' weaknesses are obvious: They are not in the software business, and non-software companies often struggle when Silicon Valley invades their turf. There's a reason that Apple, not the recording industry, popularized digital music. There's a reason YouTube and Netflix, not Hollywood studios, dominate the online streaming business. It'll be hard enough for car companies to make their cars full self-driving; creating a user-friendly car-hailing app and building all the digital and physical infrastructure required to support such a service will be an even bigger struggle.
Google will be a bigger threat, since it obviously does know how to build user-friendly apps and large-scale network services. But Google is likely to struggle with other aspects of operating a self-driving car service.
Running a transportation network requires a lot of communications with both regulators and customers. Google has generally avoided products with customer service needs — when's the last time you called Google for help with your Gmail account? And while the company has a large lobbying presence in Washington, it doesn't have nearly as much experience as Uber at dealing with officials in dozens of cities around the globe.
And while Uber has a reputation for flouting local regulations, its relationship with cities is gradually improving as cities become more accommodating. By the time self-driving cars arrive sometime in the 2020s, we can expect Uber to have deep and generally friendly relationships with local officials around the world. Those relationships will be extremely valuable as Uber tries to convince those same officials to allow self-driving cars on their roads.
Meanwhile, Google's most ambitious foray into a labor-intensive transportation service — Google Express — hasn't been doing very well. Managing people and physical infrastructure is a different skill than tackling hard technical problems, and Google just isn't very good at it.
A similar point applies to Apple, which is working on its own automotive products. Apple has struggled to produce reliable network services like Apple Maps, it's never shown much interest in the lobbying game, and it's never even tried to build large-scale physical infrastructure. Apple may be able to build a great self-driving car, but it probably wouldn't be good at managing a huge fleet of them.
All of which means that both Google and Apple might be happy to partner with a company like Uber to handle the boring logistical details of building a ride-hailing app, managing a network of vehicles, and handling complaints from regulators and customers. And if not, Uber's deep experience in these areas gives it a good shot at out-competing the tech companies — perhaps in partnership with carmakers.
So if you want to figure out how big Uber could get, looking at the taxi market is way too narrow. Uber is vying to become the standard app that everyone — not just urban elites, but ordinary people in suburbs and small towns too — uses when they want to move around town.
To figure out how big that could be, you want to look at the automotive industry as a whole. Consumers currently spend hundreds of billions of dollars with these companies, and they'll likely continue spending hundreds of billions of dollars on in-town transportation in the future. If Uber plays its cards right, it could be come an indispensable middleman that can take a cut of every transaction.
And the service might not stop with moving people around. There are likely to be self-driving alternatives to FedEx, Domino's, and other delivery services. The company that manages the dominant network of self-driving cars for people would be well-positioned to manage self-driving delivery vehicles too.
If Uber does succeed in building the dominant self-driving ride-hailing app, it will make the company's rumored $70 billion valuation look downright puny.
Disclosure: My brother is an executive at Google.
About a year ago this month, I bought a new car for the first time in my life, and it was an entirely crazy-making process.
Shopping for furniture or appliances or other consumer durables is pretty straightforward. You look up what items are for sale and what they cost, you decide what you're interested in, and then you can pay. Sometimes the item you're looking for isn't in stock locally (this happened to me with a couch recently), so you're told you'll have to wait a few weeks for delivery.
With cars, though, everything is nuts. You need to go from dealer to dealer, each of whom has his own inventory. One guy only has blue paint. The other guy doesn't have the blue paint, and also only has dark gray seats. And each has his own fake sticker prices and complicated cash-back offers. It's no wonder 83 percent consumers say they would rather skip the haggling, and a third of people say doing taxes is less annoying than working with a car dealer.
But it's not just the hassle. State bans on direct sales turn out to cost consumers an enormous amount of cash. It's an enormous problem, and it warrants a federal solution.

Stacks and stacks of expensive inventory. (Shutterstock)
Cars are the most expensive consumer product that the typical consumer buys. And while it may seem obvious that cars are expensive due to the material and labor required to build them, the logistics of distributing cars is actually a very expensive part of the process. Research by Eric Marti, Garth Saloner, and Michael Spence has concluded that as much as 30 percent of the cost of a car is the cost of distribution.
Along most aspects of the automobile value chain, manufacturers work hard to find less costly ways of producing automobiles. Initially these savings accrue to manufacturers in the form of higher profits. But as competition leads to the dissemination of new techniques, consumers win by getting cheaper or more advanced cars.
And yet there is little innovation in the distribution process, largely because distribution needs to be run through a dispersed network of dealerships. What's visible about this to consumers is the limited choice and anachronistic haggling involved in the dealership model. The more economically savvy will note that for the dealerships to be profitable, consumers must be paying an extra, unnecessary markup.
But as Gerald Bodish wrote in a 2009 analysis from the US Department of Justice, the most expensive part of the whole process is hiding in plain sight — it's the stockpiles of unsold vehicles sitting around on dealers' lots. He observes that in late 2008, there was a staggering $100 billion worth of unsold dealer inventory, with an annual carrying cost of $890 million.
In other words, it's a huge pile of waste. At any given time there is a vast quantity of newly built cars sitting around unsold, and the price of the cars that are sold needs to be high enough to cover the costs of building and storing the unsold ones. Bodish cites a Goldman Sachs analysis indicating that replacing the current inventory-heavy method with a more efficient build-to-order method could reduce costs by 8.6 percent. Real-world experience from Brazil, where Chevrolet sells Celtas direct to consumers, shows a somewhat more modest savings of 6 percent relative to what's paid at traditional dealerships. Either way, for a product that costs tens of thousands of dollars it's a meaningful saving — over and above the large increase in convenience.

Cool car, but a little pricey. (Tesla)
The issue of direct auto sales is frequently in the public eye these days because of Tesla. Tesla does not work with car dealerships. Instead, the company owns its own showrooms and sells cars directly to consumers. Every once in a while a state acts to ban these direct sales (it was Michigan most recently), and stories get written about it. But the real story here is much more general than Tesla. As Federal Trade Commission economists have written, protectionist laws that defend the interests of car dealerships over the broader public exist all across America.
The only reason Tesla is able to sell directly at all is these laws are frequently written so as to protect existing dealership networks. Since Tesla is brand new, it has no existing dealer networks to circumvent, and it is able to operate legally in many states until new laws are passed to block it.
These fights that are playing out sporadically around the country are important. Most people aren't in the market for an $85,000 electric luxury car and won't be for the foreseeable future. But buyers of F-150s and Accords and Camrys and Fusions deserve the benefits of direct sales as well. That means not just fighting back against efforts to add new anti-Tesla provisions to existing state laws, but actually rolling back the tangled web of anti-competitive rules currently in place.
Legal restrictions on direct car sales are typically a matter for state law. But the problem of excessively expensive, time-consuming, and choice-restricting auto purchases is a national one. It deserves a federal solution. What's more, it likely needs a federal solution.
One reason dealers are so effective in lobbying state legislatures is that typically a car dealership company is local, while the manufacturer is out of state. What's more, citizens simply don't pay much attention to state politics, making it even more of a plaything for special interest lobbies. It's striking that dealer-coddling protectionist measures are just as likely to be supported by theoretically market-loving Republicans like Michigan Gov. Rick Snyder as anyone else.
At the national level, a coalition for reform could be built on legislators from car-manufacturing regions, principled free marketeers, and reform-oriented liberals. The fact that the Obama administration's economic team has already weighed in against direct sale bans gestures toward the possibility of bipartisan cooperation.
What the FTC doesn't have is an actual proposal. But while the federal government can't directly step in and repeal state-level bans on direct auto sales, it can take advantage of the large federal role in transportation finance. A quarter of all transportation funding flows from Washington through various grant programs. Some of that money should be set aside in a "best practices" pool and made available to states that allow for open entry into the car-selling market, while states that refuse to reform will lose out.
American consumers spend more than $60 billion at new car dealerships each month. A change in legal regime that might reduce prices by 6 to 8 percent of that total while also reducing hassles would be a huge win. And while like any useful reform it would face special interest opposition, car dealership reform doesn't force anyone to cross any ideological red lines in gridlocked Washington.
In a piece for today's New York Times Magazine, Planet Money's Adam Davidson tells the story of Rick Stern, a farmer who is worried that higher interest rates will hurt him financially. Higher interest rates will mean a stronger dollar, which will make US crops less competitive on world markets. It will also make it more expensive for the farmer to borrow money to invest in his farm. So, Davidson concludes, Stern "just wishes the Fed would leave rates alone, and he can’t understand why they would even consider raising them."
"It’s politics," Stern tells Davidson. "Most politicians forget who they are and why they went to Washington."
But Davidson says our system is designed to ensure that people like Stern can't influence the Fed's decisions. "If the Fed added up all the ways a rate increase helped people in the short term and subtracted all the ways it hurt them, they would never raise rates," he argues. Yet if the Fed never raised rates, the result would be high rates of inflation. So Davidson argues that even though low interest rates would be better for Stern — and millions of other Americans — in the short run, it's a good thing that the Fed is empowered to raise rates anyway.
I think this actually gets things backward. In recent years, the political dynamic has generally cut in the opposite direction: The Fed has faced far more criticism from monetary hawks on the political right — who believed the Fed was keeping rates too low — than from doves pushing for more expansionary policies.
Right now, in fact, the Fed is under significant political pressure to raise rates. That's despite the fact that the inflation rate is currently below the Fed's 2 percent target — which would normally be considered a sign that interest rates are too high.
One reason for that, however, is that many mainstream pundits have adopted Davidson's view that monetary policy is too complicated for ordinary people to understand. The result of this isn't to free the Fed's technocrats to make decisions without political pressure. Instead, it amplifies the influence of people on the political fringes, most of whom currently believe the Fed has done too much to support the economy.
But the hawks are wrong, and the commonsense perspective of that farmer is right. Higher interest rates slow the economy, and with inflation at very low levels, there's no good reason to do that. And if ordinary people want to see the economy continue to boom, they might want to make their views known to policymakers.
In June 2014, Uber made headlines by raising an eye-popping $1.2 billion, in a deal that valued the company at $17 billion. Now, a bit more than a year later, the company has had seven more rounds of fundraising, raising $6.7 billion in additional venture capital. And now the New York Times is reporting that the company is trying to raise yet another billion dollar round — and that the company now believes itself to be worth $60 to $70 billion.
When last years's $17 billion valuation was announced, it generated howls of skepticism. Aswath Damodaran, for example, estimated that the global taxi industry is worth $100 billion and Uber might get 10 percent of it, which would value the company at around $6 billion. Another estimate used a much smaller figure for the global taxi industry — $22 billion — but a much higher Uber market share — 50 percent — to arrive at a valuation just under $17 billion.
Now, investors seem to think the company is worth three to four times as much. Has the world gone mad? Not really. There are a couple of factors that could actually justify Uber's skyrocketing valuation.
One is if this turns out to be a winner-take-all market. There are some industries — like search engines and social media — where the biggest firm winds up dwarfing all the others.
The smartphone-powered taxi market has the right characteristics for this: passengers are going to prefer the network with the most drivers, because that keeps down the average wait time. Drivers will want to drive for the network with the most passengers for the same reason. This factor gives the market leader a systematic advantage that will be hard for Lyft — to say nothing of smaller rivals or not-yet-founded startups — to overcome.
Chris Mims of the Wall Street Journal has predicted that Uber's profit margins would be destroyed by competition. But if Uber emerges as the undisputed king of the ride-sharing market, that won't happen. Uber will have the lion's share of passengers, and so drivers will have little choice but to give Uber its 20 percent cut.
A big question here is whether this market will have a global leader — like Facebook or Google — or whether each country will have its own dominant ride-sharing firm. Uber is facing growing competition from home-grown ride-sharing companies in China, India, and other countries. A big reason Uber is raising money so aggressively is that it hopes to expand quickly into these other countries, eventually achieving a dominant market share around the world — not just in the United States.
The convenience of Uber — and innovations like its UberPOOL carpooling service — could dramatically expand the size of the market. A lot of people take fewer taxi rides than they'd like to because of high costs or limited availability. Uber and Lyft have already pushed down fares and expanded availability, and Uber may achieve further improvements on both fronts in the coming years. In the process, they may significantly expand the overall market.
And there could be a lot of room for expansion. The current size of the US taxi market — $11 billion, according to one estimate — represents just $35 per American. That's largely because only a handful of large cities are dense enough to support a large-scale taxi market based on taxis being hailed from the street.
Uber makes it possible to offer taxi services in low-density cities and even suburbs where cabs are rare today. In the traditional model, you'd call a cab company and ask them to send you a taxi. But because each company controls only a small fraction of cars in the city, they might not have anyone nearby, and you might be forced to wait a long time. Uber drastically improves the customer experience here: the company is likely to find a car that's relatively nearby, and because you can follow its progress in realtime, you know exactly how long you'll have to wait.
And as Vox's Matt Yglesias has noted, the market could expand even further with the emergence of self-driving vehicles. If users around the world become accustomed to hailing cars using Uber, it will be easy to convince them to use Uber to hail self-driving cars once those become available. And because self-driving taxis have no driver, they could be dramatically cheaper than the traditional kind.
People tend to systematically under-estimate the growth potential of the most successful technology startups because they fail to appreciate how much new technologies can change peoples behaviors. The high quality of Google's search engine made the web dramatically more useful, causing people to use Google far more than they used previous search engines. Facebook didn't just become another website people visit, it has become the default way many people interact with the web.
By the same token, Uber has the potential to dominate and reshape the taxi market in a way that no traditional taxi company could have hoped to do. Models that assume Uber will gain a modest slice of a static market are going to systematically underestimate its potential.
Investors valued the medical testing startup Theranos at $9 billion last year. But a bombshell Wall Street Journal investigation published last week has thrown the company into crisis by raising questions about whether its technology works as advertised.
Theranos was founded by a Stanford dropout and is based in Silicon Valley, so people have naturally drawn comparisons to tech industry legends — especially Apple co-founder Steve Jobs. But founder Elizabeth Holmes ignored a crucial piece of Silicon Valley conventional wisdom, and it may prove her undoing.
The idea is that young startups should create a product and get it in front of customers as quickly as possible. Sure, the first product will have flaws and limitations, the argument goes, but there's nothing like real-world feedback to help drive improvement. Mark Zuckerberg, for example, began working on Facebook in January 2004, and had a working website operating across multiple campuses by March. The site's rapid growth helped him raise $500,000 from investor Peter Thiel a few months later.
Theranos was started around the same time as Facebook — indeed, Holmes and Zuckerberg are the same age. But Theranos stayed in "stealth mode" —  not talking to the media or the public about what it was doing, to say nothing of releasing a working product — for a decade.
That meant that by the time customers began using its blood test services in 2013, it had already raised more than $100 million from investors. The danger with this strategy is that if your original innovation has unexpected problems — and most innovations have unexpected problems — you don't find out about it until after you've wasted tens of millions of dollars. That seems to be the problem Theranos is facing today. And at this point, it may prove to be a really hard problem to solve.

Theranos customers have to endure conventional veinous blood draws after all. (Tappasan Phurisamrit/Shutterstock)
When Theranos first emerged from stealth mode in 2013, it made some ambitious claim for its product. As a glowing 2013 profile put it, Theranos was supposed to have "devices that automate and miniaturize more than 1,000 laboratory tests, from routine blood work to advanced genetic analyses. Theranos's processes are faster, cheaper and more accurate than the conventional methods and require only microscopic blood volumes, not vial after vial of the stuff."
But in the past couple of weeks, many of these claims have been called into question. The company has admitted that right now only one Theranos test actually works with just a few drops of blood (others are currently being evaluated by regulators); dozens of others are conducted using the same "vials after vial of the stuff" that others labs use.
The Journal notes that while it was reporting its big scoop on Theranos's technology, the company deleted a claim on its website that "many of our tests require only a few drops of blood," replacing it with the much less impressive boast that it collects less blood from patients than competitors.
According to the Journal, Theranos was using its proprietary testing technology for only 15 tests at the end of 2014. The other 60 tests the company offered at the time were done using conventional laboratory equipment. (Theranos disputes these specific numbers, but it doesn't deny that it's been using conventional laboratory equipment for many of its tests, and has refused to say how many.)
The company's culture of secrecy has likely cost its investors dearly
The Journal's recent reporting also calls into question the accuracy of the Theranos tests. A big reason competing labs draw so much blood is that the machines they use often require it. But if Theranos is using the same conventional machines, it should need the same volume of blood as other testing companies — and one of Theranos's selling points is that its tests collect less blood than competitors. The Journal alleges that Theranos has dealt with this problem by diluting its samples, a process that can degrade the accuracy of the tests.
Others have raised similar concerns. Jean-Louis Gassée, a prominent former Apple executive, says he tried Theranos for a test he has to take regularly. He found that the results from the Theranos tests fluctuated a lot more than tests from a conventional lab.
Theranos has refused to provide details on how its testing regime works, so we can't be sure what's going on here. It's possible that the problems identified in recent reporting can be fixed, and that Theranos's new technology will eventually disrupt the medical testing industry.
But the company's culture of secrecy has likely cost its investors dearly. If Theranos had taken a more open approach, it might have been able to start testing its technology — and opening it up to scientific peer review — years ago. That might have allowed the company to identify and fix problems while it was much smaller and less well-known, avoiding the massive public relations crisis it's suffering right now.
On the other hand, if Theranos's technology can't be made to work as advertised, everyone involved would have benefited from discovering that a lot earlier. Holmes might have been able to "pivot" to a new technology or business model. And if not, investors could have avoided sinking tens of millions of dollars into a flawed technology.


Former Secretaries of State Henry Kissinger (left) and George Shultz are among the elderly former government officials on the Theranos board. (JIM WATSON/AFP/Getty Images)

The fact that Holmes was producing a medical product rather than a software one likely gave her extra leeway to keep her technology under wraps for a decade. Medical technology has life-or-death implications, so it requires more rigorous testing than a social media website. Of course, that's exactly why the medical profession has a culture of rigorous, open peer review of new medical technology — a process Theranos has largely refused to participate in.
Also, the Theranos board is conspicuously light on people who have experience with either biotechnology or startups. It contains a who's who of the military-industrial complex. Theranos's independent board members include former Secretaries of State George Shultz and Henry Kissinger, former Sens. Bill Frist and Sam Nunn, former Defense Secretary William Perry, retired Gen. James N. Mattis, and retired Adm. Gary Roughead.
This is obviously a distinguished group, but it's not necessarily a great board for a biotechnology startup. In the world of defense contracting, it's not unusual to have secretive projects that cost tens of millions of dollars and take a decade to complete. But there was apparently no one on the board to point out that this approach doesn't work very well for technology startups.
Most technology startups — and especially most technology startups that grow to be worth billions of dollars — do not stay in stealth mode for very long. We don't have to speculate on whether Uber, Airbnb, or other big, venture-funded technology companies have products that work. Their products have been in the market, and subject to intense scrutiny, for many years.
There are some exceptions. For example, a company called Magic Leap has raised more than $500 million from investors for its virtual reality technology, which has yet to be publicly unveiled. Its leading competitor, Oculus VR, was acquired by Facebook for $2 billion in 2014 — it also has yet to release its product to the public. Creating a new category of consumer products is harder than creating a new website, so it's not surprising that it's taken these companies more than a few months to bring their products to market.
But neither company has been in stealth mode for nearly as long as Theranos was — Magic Leap was founded in 2010, and Oculus VR has only been around since 2012. If these companies are still struggling to get their technology to work in 2020, their investors should be worried.
For the past few months, a guy named Brandon has been living in a truck in Google's parking lot and documenting the experience on his blog. He's a software engineer at Google, a company famous for its generous amenities. Brandon is able to eat meals, take showers, and work out on Google's campus, which he says makes it practical for him to live in the back of a box truck — with no kitchen, running water, or other amenities.
He says he's doing this to save money. Rent for a studio apartment costs around $2,000 per month, he says. The truck cost just $10,000, and his only recurring expense is $121 per month for truck insurance — so just a few months into the experiment, he's already saved more money than he spent on the truck, and he expects to save tens of thousands of dollars over the next few years.
Obviously, living in the back of a truck is an unorthodox solution to the problem of high housing costs. But the really crazy thing here is a set of housing policies that have made it impossible for workers like Brandon to find cheap housing.
Brandon" data-chorus-optimize-field="main_image">

Brandon">

The inside of Brandon's truck. (Brandon)

The majority of the residential areas in Mountain View, where Google's headquarters is located, are zoned for single-family houses. That includes plenty of land that's a short walking distance from shops and even the commuter rail station. Building small, cheap apartments — or even connected rows of adjacent townhouses — in these neighborhoods is illegal.
There are some areas where apartment buildings are allowed, but even here there are strict limits. They can't be taller than 45 feet — about four stories — and an apartment building can't occupy more than 40 percent of the lot on which it's located. And each housing unit needs to include a storage locker and parking.
All of these restrictions limit the number of small, cheap housing units developers can supply. That's why studio apartments in the area cost $2,000 per month — far more than the national median of slightly below $800.
Google has noticed that its younger workers are struggling to find affordable and convenient housing, and has been lobbying the Mountain View city council for permission to build more high-density housing in the northernmost part of Mountain View. But city council members have been hostile to the very idea of providing small, affordable apartments for young workers.
"One thousand units of single-occupancy rooms, that's not a community, that's dorms," council member Ronit Bryant said at a 2012 meeting where Google's proposal was considered. "It's done a lot in China. Huge factories, huge apartment blocks, I don't think everyone lives happily ever after."
No one dreams of living in a tiny apartment forever, of course. But there's nothing wrong with people choosing spartan accommodations when they're young, single, and working long hours at a demanding job — allowing them to save up money they can use to buy a house later on.
More importantly, refusing to accommodate Google's growing workforce won't lead to everyone living "happily ever after," either (there's a guy living in a truck, after all). Quite the contrary: By reserving most of its residential land for single-family homes, Mountain View guarantees that there won't be enough housing for everyone who wants to live there. Instead, Google workers have been forced to seek housing further and further afield. Many now have hour-long commutes on Google shuttles that bring them in from San Francisco.
In the process, they've displaced less affluent people in surrounding communities, contributing to a region-wide affordable housing crisis. Indeed, less affluent people are the biggest victims of excessive housing regulations in Mountain View — and other nearby communities that also limit housing development.
Ultimately, engineers at Google will always be able to find housing they can afford — even if they have to take an hour-long trip in a Google shuttle to get to work. By contrast, the people who serve lunch in the Google cafeteria probably can't afford to pay $2,000 per month for a studio apartment — and the authorities probably wouldn't be so forgiving if they tried to sleep in their vehicles in nearby parking lots. So less affluent workers are going to be forced to move even further out to find affordable housing, live in cramped conditions, and endure multiple hours of commuting every day, on buses that are a lot less comfortable than a Google shuttle.
Disclosure: My brother is an executive at Google.
Legendary investor Carl Icahn today pledged $150 million to launch a new Super PAC designed to advocate for what he calls "desperately needed legislation" to address "the pernicious effects that are occurring and will continue to occur as a result of Congress’s failure to immediately stop so many of our great companies from leaving our country." This is the problem of so-called tax inversions, in which companies that are primarily based in the US shift their nominal headquarters overseas to reduce their tax burden. It's an interesting issue, a somewhat important one, and something that Congress should address.
1/2 I am starting a Super PAC with my initial commitment of $150 million to help end the crippling dysfunction in Congress
2/2 I have therefore sent the following letter to the relevant committees and leaders of Congress: https://t.co/EGcuHvzou4

But peer into the details, and what Icahn is actually doing is pledging $150 million to the cause of helping Carl Icahn get even richer. As large a sum of money as $150 million is, Icahn's personal stake in the legislation at hand is even bigger.
The specific bill Icahn is advocating for isn't a narrow effort to address tax inversions; it's a broad effort to cut corporate income tax rates while generating a one-time windfall for people who currently own large blocks of shares in cash-rich companies. That's what Icahn is talking about when he refers to "passing legislation for international tax reform as outlined in the framework put forth by Senators Charles Schumer and Robert Portman, and supported by Chairman Paul Ryan, to fund the Highway Bill."
Here's how it works:
Proponents of this plan hope that it would increase federal tax revenue. They also hope that by making it cheaper for companies to "repatriate" cash from their foreign subsidiaries that it would increase their incentive to invest money in the United States. But another thing that it would do is make it cheaper for companies to pay dividends to shareholders. Right now, if you are a company with profits stashed abroad you need to pay corporate income tax on those profits before you "bring them home" to pay dividends.
The single company with the most overseas cash is Apple. Icahn is one of Apple's largest shareholders. His big idea for Apple as a business is that it should pay more dividends.
So let's do the math:
At an 8 percent rate, Icahn would save about $243 million in potential taxes on his Apple dividends. That — or even a slightly higher rate — would easily generate a healthy ROI for a $150 million investment in a Super PAC. And that's just from the one-time levy, just from Apple. Icahn presumably has other investments, and Icahn also would be able to take advantage of continued lower taxes on Apple's foreign profits.
One of the really big and disturbing economic trends of the past 15 years has been a steep decline in the share of national income going to workers, in the form of wages and benefits, as opposed to going to owners of capital. A new report from the White House focused on a larger question about "economic rents" sheds some interesting light on the specific mechanics of how this shift is happening.
This phenomenon — a decline in the labor share of income —  hadn't really happened before. In fact, economists had kind of convinced themselves that it couldn't happen, and that the labor share was something like a fixed property of the economy.
But obviously that was wrong. And the most natural interpretation of why it's wrong is that the bosses are getting one over on the rest of us. Maybe it's globalization, maybe it's automation, maybe it's the decline of labor unions, maybe it's neoliberal hegemony (why not), or maybe it's something to do with workplace skills. But whatever it is, it means that the American worker's power to bargain for wages and benefits has declined, hence the declining share of income going to workers' wages and benefits.
Except that's wrong, too. Check out this chart — it shows that the rise in the share of national income going to the owners of businesses has only nudged up very slightly. The rise is in the share of income going to the owners of houses.
That's something people definitely used to think couldn't happen. After all, if owning houses becomes more lucrative, then people should respond to market incentives by building more houses. There's no way houses could just get more and more and more valuable. Except, of course, a house isn't just a house. It's also a place. Location, location, location, as the realtors say. A house that's within a decent commuting distance of Google or JP Morgan is worth a lot more than a similarly sized house in San Antonio or Memphis or Cleveland. You can always make more houses, but you can't make more land.
The pioneering 18th-century economist David Ricardo thought this scarce supply of land spelled long-term immiseration for working people. Over time, as the population grew, it was landlords — the people who owned the most useful land — who were going to reap all the gains.
But what Ricardo had in mind was agricultural land. He was writing before the Industrial Revolution (to say nothing of the internet), so what he meant by useful land was good land to grow crops or raise sheep. After all, even way back in Ricardo's day it was technologically possible to fit a whole bunch of people on a parcel of land by constructing adjoining houses rather than separate ones each on their own lot. And with modern technology, we can even stack homes vertically and use elevators to access dwellings hundreds of feet in the air.
Except across the vast majority of America's valuable land we've made it illegal to build rowhouses or apartment buildings. And so the land's value only increases, the rents going to its owners accumulate, and workers lose out.
The first big commercial deployment of driverless car technology is coming not in the streets of Silicon Valley but in the arid and sparsely populated Pilbara region of Australia. That's where the large mining conglomerate Rio Tinto has rolled out fleets of all-driverless trucks at two iron ore mines, according to a report by Jamie Smyth at the Financial Times.
Rio Tinto tells Smyth that the driverless transition has improved performance by 12 percent, mainly by "eliminating required breaks, absenteeism and shift changes."
GPS guides the trucks and allows them to deliver iron ore 24/7, 365 days a year, without the kinds of breaks and handover periods that human drivers would need. The GPS navigation system is backstopped by a team of human operators working remotely from Perth, hundreds of miles away. Not only does this reduce the total number of humans who are needed to run the trucking operation, but it eliminates the need to employ those humans in the remote and desolate mining country. A mine needs to be located where the ore is, and you often end up needing to pay a premium to recruit workers to ore-adjacent locations. Remote workers, by contrast, can live in a nice suburb of a midsize city.
But of course mining operations are hardly the only companies that could save money by replacing human drivers with robots. The big difference is that the mine setting offers a huge advantage that most companies can't match — there are no human drivers on the road.
As David Roberts has written, one of the biggest technical challenges in making a general-purpose autonomous vehicle is that it would have to deal with all those crazy human beings. If all the cars were autonomous and networked, they would interact and communicate in predictable ways. But for that to happen in a normal transportation context, you would first need a transition phase in which autonomous cars co-exist with human-piloted ones long enough for them to gain trust and traction.
Rio Tinto doesn't have that problem. It controls the entire site, and can make the transition to an all-autonomous fleet all at once. There's no "transition period"; there's just a transition.
To most people, the current face of driverless car technology is a pretty normal-looking Google car cruising the streets of the Bay Area. But most of the concrete progress over the next few years is likely to happen in areas that are more conceptually and geographically distant from the core functions of the modern automobile.
Rio Tinto is only doing this at two mines so far, and it has a lot more mines. There are also other mining companies, and other companies in fields like lumber harvesting that involve a similar need to haul lots of heavy stuff around privately owned land. You probably won't hear them called "driverless cars," but warehouse robots that move things around a confined space while interacting with a limited set of other robots are also starting to come into use. Automation of light trucks and specialized vehicles on farms and ranches would be an interesting next step. These are in some ways closer to the generic "driverless car" case, but they also involve private land and not many people.
After that, who knows — zoos and amusement parks? Airports? Transit buses with dedicated lanes? The point is that rather than seeing a slow trickle of autonomous cars start to appear on busy streets (the way we have seen with electric cars, for example), you are likely to see mass adoption of driverless vehicles in settings that are somewhat marginal to the core market for light vehicles. Then if the technology succeeds, it will gobble up more and more slices, along the way establishing the kind of clear track record and public understanding that would be necessary to move into the core area.
Angus Deaton, born in Scotland but a longtime professor at Princeton, has won the 2015 Nobel Prize for Economics "for his analysis of consumption, poverty, and welfare." Deaton is well-known for a broad body of work rather than for a handful of breakthrough papers. But it is possible to understand his output as falling along a couple of themes. Methodologically, Deaton is about both empiricism and individualism, arguing for a close look at data on how specific human beings and households behave, rather than stylized models or big national-level aggregate data.
Substantively, this is because he's trying to look behind the easiest summary statistics and understand what is actually happening in people's lives — who is better off than whom, and why. That's a subject that has very broad application. We might wonder if the average person in Oslo is better off than the average person in Orlando, and by how much. But it's of particular interest when we're thinking about questions of poverty. If we want to improve the lot of the worst-off people, we need to know who they are and how to measure improvements in their well-being.
Deaton originally rose to prominence for work on two technical issues. The first of these was the creation of the Almost Ideal Demand System, AIDS, which was first published in 1980 just before that acronym came to be known for something else entirely.
A very simple demand system says that if the price of apples falls, people will buy more apples. A natural complicating observation is that if the price of apples falls but the price of oranges falls even more, people actually might buy fewer apples because they are gorging on oranges. Comparing apples to oranges is a legendarily difficult problem, but to understand what products people will want to consume, you more or less need to compare everything to everything. AIDS was a promising effort to show how we can do all the aggregations necessary to understand these dynamics, and it's been the subject of a lot of subsequent refinement by various economists.
Deaton also worked on a problem known as the Deaton Paradox, which is a kind of puzzle internal to the widespread economic assumption that people have a more or less rational, forward-looking behavioral pattern.
This kind of work propelled Deaton's career forward but isn't really what he's best known for.
Money is a really convenient way of comparing how people are faring economically. Saying Jose has $1,000 more than Joe but $2,000 less than Giuseppe is very simple and relatively easy to verify.
But whenever you try to take these kind of simple cash comparisons into the real world, immediate problems resolve. If Jose lives in Texas but Joe lives in Toronto, then one of them has US dollars and the other has Canadian dollars. You can convert between the currencies using market exchange rates, but exchange rates bounce up and down at the speed of financial markets, and it's not plausible that living standards shift that quickly. We need to start looking at what people are actually consuming — the food, cars, medicine, etc. that make up economic life.
Yet the further afield you go, the harder this kind of problem becomes. The price of an iPhone is very similar around the world, with the difference largely accounted for by taxes and short-term currency fluctuations. But a haircut is cheaper in Hanoi than in Harrisburg, and cheaper in Harrisburg than in Helsinki. So the cost of living varies from place to place. But it also varies according to what you mean by "living" — the extent of the variation depends on what it is you are buying. If people in Hanoi don't get haircuts as often as people in Helsinki, the fact that haircuts are cheaper isn't as big of a benefit.
Deaton does not have one giant paper that solves this problem. The whole point of his work, rather, is that it's a problem that requires both theoretical sophistication and a lot of piecemeal work. Here are his papers on poverty in India, for example. It is not a small number of papers.
In a big-picture sense, Deaton is urging both empiricism and individualism. The easiest thing to do in economics is to choose one or the other. The most widely available empirical data is data about big aggregates — how much did Americans as a whole spend on this or that — and there's a long tradition of work grounded in observing the movements of these big aggregates. There is also a counter-tradition that insists on building up our model of how the big picture works from economists' standard model of how rational individual humans behave. This generates elegant but highly stylized takes on what is going on.
Deaton's approach emphasizes the use of household surveys and other finer-grained sources of empirical data. And it does so due to an appreciation, on a theoretical level, of the importance of diversity. Economic conditions vary enormously from place to place and from person to person. Poor people consume different sorts of things than do rich people, and these patterns vary across place and time.
This is crucially important when it comes to measuring poverty — you can read a nontechnical account of Deaton's approach here — because it implies that governments and nonprofits interested in combating poverty need a fine-grained understanding of how it varies as a phenomenon from place to place. It's not enough to set the poverty line at $1.90 a day and the see how it's changing around the world. You need to see what $1.90 a day actually means in Nigeria versus Nepal, versus Nanjing.
Deaton's interest in consumption, and peering behind the veil of money, eventually led him into the arenas of health and well-being. For many people, health-care services constitute a large share of their spending and consumption. But while people buy movie tickets because they want to watch a movie, people don't really pay for doctors' visits because they like sitting in doctors' offices. The idea is to get healthier. And yet it's well-known that health is impacted by lots of things (diet, exercise, stress) that aren't health-care services, and also that lots of health-care services don't do much to improve health.

Angus Deaton is the Obi-Wan Kenobi of Economics.   Breathtaking range of work in poverty, health, healthcare, wellbeing, methods…
This is a big deal in rich countries where health-care costs are so important, but it's also a big deal in poor countries. Many foreign donors are very interested in improving public health, possibly as a tool for fostering economic growth. At the same time, one of the best things about economic growth is that it might foster better public health. Deaton's inquiries into poverty and consumption fed into this area, and his work is well-known among public health and development specialists.
Deaton is very much an economists' economist, but he's also a clear writer who dabbled in more popular fare. His book The Great Escape paints an optimistic picture of modernity and the benefits of economic development.
For a while now he's written a biannual "Letter From America" for the Royal Economic Society offering views on the need for regional price indexes, the benefits of a single-payer health-care system but the unlikeliness of adopting one, the impact of unemployment and health and happiness, and budget cuts to state university systems.
Deaton is a very widely admired economist but does stake out two controversial positions in development economics that ruffle some feathers. One is that he is sharply critical of foreign aid, seeing improved state capacity as the key to sustainable economic development in poor countries, and aid as useless to counterproductive in achieving it. Other development economists note that aid can and has built state capacity, and that Deaton's argument that it's net useless or counterproductive doesn't match the empirical reality.
Deaton sees direct cash grants as superior to conventional foreign aid, but even so deems it "no solution" because "poor people need government to lead better lives; taking government out of the loop might improve things in the short run, but it would leave unsolved the underlying problem."
This is linked to Deaton's criticism of the recently popular trend toward Randomized Controlled Experiments (RCTs) as a key tool of development economics. His 2012 debate with Abhijit Banerjee on this subject is fascinating if you're interested in a deep dive, but broadly speaking Deaton thinks RCTs tell us too little about interventions that are too small in scale. A study of the deployment of antimalarial bednets in one village in Kenya tells us a lot about the effect of one specific policy in one specific region of one specific country — but it doesn't tell us much about the overall task of eradicating developing world poverty.
Per the title of his popular book, he is interested in understanding what poor people in poor countries need to achieve a "great escape" from a world of widespread immiseration — changes in political economy and economic development that are far too big to be studied as piecemeal RCTs.
There's been a lot of turmoil in the cellphone industry recently. Industry maverick T-Mobile has been cutting prices and rethinking longstanding industry practices, forcing other carriers to follow suit. The result: Consumers can get better deals than ever before, but they also face more — and more complicated — options than ever before.
We're here to help. Read on to learn how the market has changed, the best options for getting a new smartphone, and how the nation's four major wireless networks compare on network quality.
(David A.Grogan/CNBC/NBCU Photo Bank via Getty Images)
T-Mobile CEO John Legere has been shaking up the wireless industry. (David A.Grogan/CNBC/NBCU Photo Bank via Getty Images)
Two-year contracts used to be standard across the cellphone industry. In exchange for a two-year commitment, customers got a heavily discounted — sometimes even free — phone.
Rolling the costs of a new cellphone into a customer's monthly bill avoided sticker shock and helped boost the growth of wireless service. But this arrangement also had some downsides. It encouraged customers to buy a new phone every two years, whether they needed one or not. And a lot of customers hated being locked into long-term contracts — and facing steep early termination fees if they broke them.
So in 2013, T-Mobile declared war on two-year contracts. Under T-Mobile's new pricing structure, customers could cancel their service anytime they wanted, without paying an early termination fee. The flip side was that T-Mobile stopped subsidizing customers' handsets. Customers had to either bring their own phones, pay the full retail price for a new one, or pay for a phone in monthly installments.
Because it was no longer subsidizing customers' handsets, T-Mobile could offer monthly rates dramatically lower than what its major competitors were charging.
T-Mobile's strategy has proven so successful — this summer it passed Sprint as the No. 3 wireless carrier — that other companies have been forced to follow suit. Verizon announced it was phasing out contracts in August of this year, and Sprint announced it was following suit a few days later. AT&T is still offering two-year contracts, but its CEO has predicted that they are "going to go away slowly."
T-Mobile's moves also touched off an industrywide price war. The result is that you can get more service — and, especially, bigger data plans — for less money.
This has all been good for consumers, who can get more bang for their buck. If you've had the same cellphone plan for more than two years, you're probably getting a bad deal; it's worth checking out today's packages to see if you can get a better one.

( efa Karacan/Anadolu Agency/Getty Images)
Wireless companies used to sell voice, data, and a cellphone in one bundle for a single monthly fee. T-Mobile forced the rest of the industry to unbundle these things from one another, making things more complicated. There are more options, and you can mix and match them in more ways.
If you're in the market for wireless service, you have three basic options, in order from least to most convenient:
The most frugal option — and the one that involves the most hassle — is to buy a used phone and then bring it with you when you sign up for wireless service. If you buy a phone that's a year or two old, you can get a significant discount compared with a new phone. And you may also be able to sell your old phone, saving still more money. There are a number of sites, including Amazon, Craigslist, and Glyde, that help people buy and sell used devices.
But this approach has one big potential pitfall: You have to make sure the phone you choose will work with the network of the wireless network you choose. The details here are beyond the scope of this article, but if you buy a relatively new phone that was previously used on the same network you want to use, you should generally be okay.
At the opposite end of the cost and convenience spectrum are the leasing and early-upgrade plans. These allow you to pay a somewhat higher monthly rate in exchange for being able to upgrade your phone more quickly than the standard two-year cycle. They generally require you to trade in your old phone to get a new one, saving you the hassle of disposing of old phones.
However, for most people the best option will be to buy a phone using a two-year financing option and then hold on to it for more than two years. After two years, your phone will be paid off, so your monthly bill will drop. If you can hold on to your phone for more than two years, you can save a significant amount of money.

(Roberto Machado Noa/LightRocket via Getty Images)
Which carrier should you choose? The national wireless market is divided into two tiers. AT&T and Verizon are the two largest carriers in the country, with more than two-thirds of the market between them. T-Mobile and Sprint are each about half as large.
Generally speaking, the larger carriers tend to have better network coverage. Verizon is widely viewed as having the most extensive network, followed by AT&T, Sprint, and T-Mobile. On the other hand, Verizon and AT&T tend to charge more than their smaller rivals.
However, you don't care how these companies' networks perform in general — you only care how they work in the cities and neighborhoods where you're going to spend time. If Sprint or T-Mobile's network works well near your home and office, you might be totally satisfied with them even if they offer poor coverage in other areas.
The Verizon and AT&T networks are superior in two specific ways. One is service in rural areas. The larger networks can afford to spend more on cellphone towers, so they're able to cover more remote areas than the smaller carriers can. So if you live in a small town, you'll probably want to go with one of them. However, if you spend all your time in urban areas, this might not matter.
The larger carriers' other big advantage is that they have more low-frequency spectrum. This kind of spectrum is a lot better at passing through thick walls and other obstructions. That means that if you happen to live in a huge apartment complex, or you work in a big office tower surrounded by other office towers, you might find T-Mobile and Sprint's coverage frustratingly spotty.
In urban areas where T-Mobile and Sprint do have coverage, on the other hand, the smaller carriers have an advantage of their own. Because they have fewer customers, wireless connections are often faster.
If you're not sure which carrier is best for you, you might want to take advantage of carriers' return policies. All four wireless providers allow customers to return their phones and cancel their wireless plans within 14 days — though note that some charge restocking fees of around $50. So you can sign up with the cheapest provider that seems to meet your needs and see how it performs. If connectivity is disappointing, you can return the device and sign up with someone else.
Trade negotiators in Atlanta reached an agreement Monday that could affect everything from American exports of pharmaceuticals to New Zealand milk, Japanese rice, and Vietnamese textiles.
The deal, known at the Trans-Pacific Partnership, would more closely link the economies of 12 Pacific Rim nations and have sweeping global implications. President Obama has portrayed it as essential to cementing America's relationships in Asia, but critics such as Sen. Elizabeth Warren (D-MA) have portrayed it as a giveaway to corporate interests and a threat to US sovereignty.
Of all the issues under negotiation, the most contentious was legal protections for the pharmaceutical industry. American drug companies and their allies in the Obama administration have been pushing for new rules that would limit competition and boost drug prices. Other countries, with the support of public health groups, have pushed back, arguing that the measures would cost thousands of lives.
Ultimately, the negotiators split the difference. They agreed to language that would require some countries to expand the legal protections afforded to drug companies (and raise prices in those countries), but big drug companies got less than they wanted.
Now the action will move to Congress, which must approve the deal before it can take effect. We can expect the TPP to attract criticism from both ends of the political spectrum. Already, Vermont Sen. and presidential candidate Bernie Sanders (D-VT) has blasted the deal as a victory for "Wall Street and other big corporations," while Sen. Orrin Hatch (R-UT) has complained that the drug protections in the bill "fall woefully short" of what the industry had requested. Obama faces a big challenge convincing critics on both sides that while the deal might not be perfect, it's still better than no deal at all.
The TPP is usually described as a trade deal, and it certainly will have important provisions related to trade. Negotiators have been considering liberalizing trade in cars and trucks, rice, dairy products, textiles, and a lot more.
But the agreement is also a lot more than a trade deal. It has more than two dozen chapters that cover everything from tariffs to the handling of international investment disputes. The reason these deals have gotten so complex is that people realized that they were a good vehicle for creating binding international agreements.
American negotiators — and, therefore, US interest groups — have had the most power in these negotiations
Modern trade deals include a dispute settlement process that helps ensure countries keep the commitments they make under trade deals. If one country fails to keep its commitment, another country can file a complaint that's heard by an impartial tribunal. If the complaining country prevails, it can impose retaliatory tariffs on the loser.
Interest groups have realized that this same mechanism can be used to enforce agreements on topics that have little to do with trade. And so a wide variety of interest groups — from Hollywood and the pharmaceutical industry to labor and environmental groups — have lobbied to include rules they favored in trade agreements. And because the US is the world's largest economy, American negotiators — and, therefore, US interest groups — have had the most power in these negotiations.
For example, at the behest of Hollywood and other US copyright holders, American negotiators have been pushing other countries to adopt our long copyright terms: the life of the author plus 70 years. International investors have pushed for an investor-state dispute settlement process that allows private investors to challenge foreign government policies before an impartial arbitration panel — a process critics such as Sen. Warren describe as a threat to American sovereignty. Drug companies want other countries to provide the same robust legal protections for new drugs they enjoy in the United States.
At the same time, labor and environment groups have pushed the Obama administration to incorporate their priorities into the agreement. The Obama administration insists the president has done just that, but so far these changes haven't gone far enough to convince these groups to endorse the agreement.
Previous trade deals already required TPP member countries to provide a minimum level of patent protection for pharmaceuticals, but most countries didn't provide protections as generous as those in the United States. Obama's trade negotiators wanted to include language in the TPP requiring other countries to make their laws more like those in the United States.
The most controversial provision of all concerns a type of drugs called biologics. These drugs are produced by biological processes rather than being synthesized in a chemistry lab. Drug companies say that patents, which protect a specific chemical formula, do not always provide adequate protection for biologic drugs, because it's often possible to find another compound that's biologically equivalent even though it has a different chemical structure.
Even the Obama administration's own budget wonks believe 12 years of protection is excessive
To prevent generic drug manufacturers from copying biologics and driving down their prices, big drug companies have used the regulatory process to limit competition. The Food and Drug Administration — and other regulatory agencies overseas — require drugmakers to prove that a drug is safe and effective before it can be introduced to the market. US law gives the creators of a drug exclusive rights to this data for a period of 12 years. Because clinical trials are expensive to perform, this effectively prevents generic drugmakers from creating competing drugs until the exclusivity period has expired.
Even the Obama administration's own budget wonks believe 12 years of protection is excessive. They've proposed reducing the protection period to seven years, and estimated that increased generic drug competition would save Medicare and other federal health-care programs billions of dollars. At the same time, Obama's trade negotiators have been pushing for language that would lock in 12 years of protection in the United States and require other countries — most of which offer shorter terms of five or eight years — to adopt the same 12 years of protection as the United States.
The full details of the compromise haven't been released — and might not be for another month — but media reports indicate that the US dropped its demand for 12 years of protection and settled for requiring five to eight years of protection instead. That's a significant concession for the United States, but it's still a victory of sorts for the pharmaceutical industry, since it will bar countries that currently offer five to eight years of protection from reducing it later. It also sets a floor, but not a ceiling — the United States will continue to offer 12 years of protection, and US negotiators may push for more lavish protections in future trade deals.
While the TPP member countries have reached the outline of a deal, media reports suggest that not every detail of the agreement has been fully fleshed out. The New York Times predicts that it will take about a month for these details to be worked out and for the final text of the deal to be made publicly available.
After that, it will take another three to four months for Congress to enact a deal. Under the "fast-track" legislation authorizing Obama to negotiate the deal, the president must give Congress 90 days' notice before signing the trade deal, and then another wait another 30 days before introducing legislation implementing it. This means that even in the best-case scenario, Congress won't be able to vote on the controversial deal until early 2016. And it could be delayed by further wrangling, either among TPP member countries or within Congress.
Obama's big challenge will be that the deal has something for everyone to hate. Drug company allies like Orrin Hatch are disappointed that US negotiators didn't get the generous drug protections they'd sought — that will make them less excited about the deal. Meanwhile, public health groups believe eight years of protection is too long.
Nothing has happened in the past few months to mollify the TPP's many critics — most of whom come from the political left. We can expect many labor unions, environmental groups, and other left-leaning advocacy groups to lobby against the agreement.
However, Obama also has a huge advantage: The Republican leadership has firmly supported Obama's trade agenda, and was able to assemble majorities for fast-track legislation earlier this year. To pass the final deal, he simply needs to convince those same members of Congress — some of whom took a substantial political risk to back the fast-track bill — to vote with him again.
You might think I'm pretty lucky. I've managed to score tickets to festivals, local shows, and six-course dinners. And I've even won not one but two bicycles in my life.
My biggest contest-winning asset isn't luck — it's my experience advising companies that run contests. As a digital strategist, I've worked with clients that depended on contests to boost likes, comments, and follows on their social media accounts. And that has given me a road map for how contests work.

Running contests is one of the many ways companies boost engagement with their brands. A book giveaway can translate to a couple thousands signups on an email list or more supporters using an event-specific hashtag. Tickets for a show, easy to come by and ship out to a fan, can net companies hard-earned social currency.
Contest results aren't necessarily random — and if you understand how they work, you can boost your chances of winning.
Here are six rules I follow:
Say you have a brand to promote and a big pile of something — like concert tickets or band merchandise — to give away. Your goal is to use the giveaway to get the brand in front of as many people as possible, generating the maximum number of entrants.
For brands that are still building a social media following, that's not easy. The number of initial followers who hear about the contest might be pretty low, and the number of entrants even lower.
That's a big problem for the social media manager. But it's an opportunity for fans, because it means that you have a pretty good chance of winning the prize — if you play your cards right.
Your first step is to identify businesses, venues, or tourism boards to follow. Ideally, these will be in your local area, because who wants to win a prize you can't redeem?
You might be following some promising accounts, but there's still a chance you'll miss opportunities amid all the online noise. To avoid this, you can set up pings for keywords that will help filter your tweets and emails. When running a search in Tweetdeck, I generally include terms such as "giveaway," "RT to win," or "win tickets" that are most likely to be included in a social media manager's promotion message. You could also specify a target item, whether it's a newly released book, travel, or electronics.
For example, in Tweetdeck you could search for "RT to win" OR "win tickets" OR "win tix." You can also run this a search for these keywords in the "any of these words" row of the advanced Twitter search.
Some contest enthusiasts have taken automating their entries to the next level, with bots that automatically retweet or enter anything with a contest ask, but I like to keep my criteria simple.
Once I've grown a significant pool of contests to choose from, I can get pretty selective about which ones to enter, focusing on my favorite musical acts or prizes I might actually use. I usually don't spend more than five minutes checking in on any of my given lists, and once I'm done I can just wait for a friendly social media ping or mention to inform me if anything has come of it.
Take advantage of filtering technologies, such as Google's promotions tab or Tweetdeck's filters
At this point, you're probably wondering if this means you're going to wind up getting a lot of spam or, even worse, wind up forcing contest spam on your social media contacts. If that prospect makes you queasy, there are several options.
One is to create separate accounts that you use only for contests. You might only check these once or twice a day — often enough to see new announcements but not so often that it drives you crazy.
You can also take advantage of filtering technologies, such as Google's promotions tab or Tweetdeck's filters, to filter out contest-related content from your primary account.
For email promotions, you can also add +promotions to your email address (example+promotions@gmail.com) as you type it into a signup form; then you can run a filter on all incoming emails with the appended keyword.
In some cases, you might also decide to use your "real" accounts. This might be annoying for you and your friends, but in some cases it might be worth it, because (as we'll see) contest promoters are more likely to choose winners with an active social media presence and more online followers.
While some contest managers will pick a randomly selected winner, all too often the winner will be preselected and (as in the case of those "Dinners With Barack") heavily vetted.
Contest managers want a winner who promotes the brand, is excited, and will spread the word to his or her followers after winning. For social media contests especially, there's a big benefit to choosing a winner who has a decent personal following. Often the rules favor those who best represent the brand by meeting some arbitrary criteria for the "best" comment or entry.
This is one reason using your real accounts might give you a better chance of winning than using a secondary account. And at the end of the day, actually sounding excited about a contest will probably help you get picked, or at the very least make you a much more appealing prospect for a contest down the line.
Music is an area where savvy contest entrants can really shine. Following local venues, artists coming to town, or first-time festivals reaps the easiest rewards. Promoters are eager to fill up shows, and throwing a contest is an easy way to get buzz for the band or venue. Plus, a contest winner might be likely to get a few more friends to tag along or spend money at the venue on alcohol or promotional items, a win-win for everyone involved.
Bands and authors will also likely count on the types of swag that are easiest for them to distribute, from digital downloads of books or music to signed hard copies and merchandise. Just make sure it's something you'd actually want to own.
Tesla Motors is following up its well-reviewed, ridiculously expensive Model S by releasing the Model X, an all-electric SUV that is … even more expensive, with vehicles starting at a mind-blowing $132,000. This isn't an unprecedentedly high price for a car, but even luxury automakers like BMW and Mercedes offer entry-level products for a quarter the price of a Model X.
Musk is, of course, aware that his vehicles are far too expensive to be mass-market successes. He has signaled that cheaper versions of the Model X will be "coming later," and promises that by 2017 there will be a car — the Model 3 — in the $35,000 range. But Tesla has missed deadlines before, so there is some reason to doubt that it will be able to deliver on that target.
But even more, the whole idea of starting with an incredibly expensive, incredibly high-end product flies in the face of a lot of emerging conventional wisdom about the process of technological disruption and the desirability of shipping "minimum viable products" that improve iteratively over time.
Yet there's a method to the madness. In some ways, the actual car is the least of the obstacles to creating a mass-market electric car. Under the circumstances, the focus on high-end products as a support system for the infrastructure Tesla needs to make a mass-market product makes perfect sense. And so far, the strategy is working. But it does have one potentially fatal flaw — it's slow, and leaves Tesla potentially vulnerable to having its legs swept by another new entrant.
If electric cars were widely owned and nobody had a gasoline-fueled car, nobody would buy one. Getting regulatory approval to cruise past people's houses with such a noisy and toxic device would be a nightmare, of course, but it would also be really inconvenient. Where would you refuel?
In the real world, of course, the shoe is on the other foot: People with conventional cars can easily find a gas station, while electric car charging stations are few and far between.
Regardless of the price of gas, the volume of subsidy, or one's personal commitment to the environment, it just makes an awful lot of practical sense to buy a car that uses the same fuel as everyone else's car. Tesla is aware of this and has a solution in the form of a growing network of "Supercharger" stations that, when complete, would make electric cars a reasonable thing for a typical family to consider.
The Model S (and Model X) is priced to appeal to people who don't need to worry too much about the practical aspects of car ownership. And they offer gross margins high enough to subsidize the buildout of the charger network.
Similar logic applies to the costly batteries that are the heart of an electric car. Tesla is building a "Gigafactory" that it says will reduce unit costs of its batteries by 30 percent. This is the kind of breakthrough you need in order to make an affordable electric car. The early expensive cars provide the funds necessary to build the factory, as well as practical experience with integrating batteries into cars that would be necessary to actually take advantage of it.
Like any good disruptive business strategy, Tesla's has the virtue of being essentially impossible for incumbent automakers to compete with. Companies that are already making money selling internal combustion engines aren't going to invest in a broad infrastructure that would make gasoline obsolete. Nor are they going to attempt to engineer a manufacturing breakthrough that would have the same impact.
The incumbents aren't dumb. They can (and do) make electric cars. But they make EVs that are designed to live in a world dominated by conventional cars — semi-affordable small cars useful for daily local driving by people with an eccentric interest in green living.
By contrast, Tesla, by simply accepting the reality that its early cars will be too expensive for the vast majority of people to even consider, has achieved something really impressive: near-universal acclaim for the quality of its products, including a determination from Consumer Reports that the P85 D variant of the Model S is so good that it broke the quality scale.* This is a kind of free marketing campaign for the eventual Model 3 that money can't buy.
The strategy of starting from the top and then working down, though alien to the software-heavy business models that dominate the startup sector these days, makes perfect sense for the infrastructure-intense car industry. The real risk for Tesla is that its roadmap may be unfolding too slowly. The Model X was originally supposed to have shipped in 2013, and even with delivery of preordered vehicles beginning this week it doesn't think new orders will be fulfilled until the back half of 2016. In other words, Tesla is evidently facing significant production bottlenecks that make it difficult for the company to make cars in large quantities.
That's another good reason for the company to charge high prices, but it adds up to significant reason to doubt that it will really have a mass-market Model 3 ready in 2017. Tesla would need to develop the car, obviously, which is difficult. But it would also need to develop a process by which the cars can actually roll off assembly lines at mass scale. There's no point in selling a car that normal people would consider buying if you can't actually get them built.
This isn't a huge problem if you view the competitive set as legacy carmakers. A year or three, more or less, doesn't really change anything.
The problem is that other new entrants could attempt a similar strategy, and despite Tesla's years-long lead, the company's slow pace of execution means they're not un-catchable. Companies like Google and Apple that are known to be interested in the car market have much more free cash flow available from their existing businesses than Tesla can obtain by selling high-end cars. If they can manage to build a good car (admittedly a big if), then these companies have the ability to leapfrog Tesla in terms of capital investments in manufacturing and vehicle charging facilities with ease. To stave off that kind of competition, Tesla needs to rely on its actual expertise in building cars. And so far even though the cars it's built have been extremely well-regarded, it hasn't actually demonstrated the ability to make them at the kind of scale that a successful car company needs.
Correction: An earlier version of this article said it was the Model X, rather than the P85D, that broke Consumer Reports' quality ratings scale.
The Washington Post calls it "terrifying." Dubbed "Yelp for people," Peeple is a new app that lets people rate their friends, professional contacts, and even romantic partners. And everyone is freaking out.
But there's not actually much reason to be terrified of Peeple. Yes, the app is a bad idea. But it's not really a new bad idea. It's an idea that entrepreneurs have repeatedly tried and failed to make work. It turns out that people aren't as interested in publicly burning their ex-lovers and friends as Peeple thinks they are. And even if some people do want to publicly trash their acquaintances, Peeple has promised safeguards that will make that hard to do.
You're only hearing about Peeple because it sounds like such an outrageously bad idea that people love denouncing it. But that's not the foundation of a successful business. In a few days, the internet will move on to being outraged about something else, and Peeple — which won't even become available until November — is likely to sink back into obscurity.
Peeple is a forthcoming smartphone app that will allow people to rate anyone they know, whether or not the subjects want to be reviewed. Founded by Canadian entrepreneurs Julia Cordray and Nicole McCullough, the company behind Peeple says it has already raised $250,000 in funding.
You're only hearing about Peeple because it sounds like such an outrageously bad idea
The service is designed to cover all aspects of people's lives. You can use it to rate professional contacts, friends, and romantic relationships.
Peeple says it will take a number of precautions to prevent the service from becoming a cesspool of nasty reviews. Reviewers will be required to use their real identities as verified by Facebook, and new Facebook profiles won't be allowed to participate.
Positive reviews of another person — those rated three or more stars on a five-star scale — will be posted immediately, but negative reviews will be held until the subject has time to review them. If someone refuses to register for the site, those negative reviews will be kept private indefinitely.
So the emerging caricature of Peeple as an app for stalkers and disgruntled exes may turn out to be wrong. It may actually be harder to harass people on Peeple than on existing social media platforms.
The reaction has been swift and overwhelmingly negative. Across the internet, people have condemned the app as an invasion of privacy and an invitation to online harassment. So many people are angry about Peeple that the app recently became a trending topic on social media sites.
The backlash has been so intense that Peeple has been trying to play damage control. "We hear you loud and clear," the company said in a Thursday Facebook post. "You want the option to opt in or opt out."
But no one seemed to be mollified. "This is not Yelp for people. This is a harassment tool for abusers," one commenter said.
"This app is a vicious and disgusting idea that can only cause harm," another added, describing the app as "the ugliest Pandora's box in internet history."

(g-stockstudio/Shutterstock)
The idea behind Peeple isn't really new, says Eric Goldman, a legal scholar who focuses on online privacy issues.
"For the grizzled internet veterans like me, I'm confused about why people are freaking about this idea," he says. "People reviewing other people for their personal behavior is a perennial topic."
The reaction has been swift and overwhelmingly negative
He pointed to PlayerBlock and Don't Date Him Girl as examples. Both are sites that allow women to rate the men they date, with an eye to filtering out "players" who cheat on their partners.
When PlayerBlock was released in 2007, it got a reception much like the one Peeple is getting now. "I for one think that such a service is a disgusting invasion of privacy," one reviewer wrote. "The potential for abuse of such a system is enormous."
Lulu is another app with the same premise: helping users — mostly women — review people they've dated. The app got a writeup from the New York Times in 2013.
Perhaps the closest analogy is Unvarnished, an app that was released in 2010. An LA Times writeup even used the same "Yelp for people" framing that's been used for Peeple. Unlike Peeple, Unvarnished allowed reviews to be posted anonymously.
A number of armchair attorneys have warned Peeple's founders that they're opening themselves up to liability. But Goldman says that — at least under US law — the company has nothing to worry about.
The reason, ironically, is the Communications Decency Act. Most of this controversial 1996 internet censorship law was struck down by the Supreme Court, but the courts left in place Section 230, which gives broad immunity to website operators hosting user-submitted information. "This is clearly governed by Section 230," Goldman says.
If someone posts defamatory information about another person online, the poster could face liability under libel laws. But Section 230 shields an online service like Peeple from any liability, even if the posts are ultimately found to be defamatory.
No, and the other company is pretty frustrated about it.
There's reason to be skeptical that Peeple will get very far
Peeple is a small camera that can be mounted to the keyhole in your front door. It has a built-in wifi chip, allowing you to check out who is standing at your front door with your smartphone, no matter where you are.
There's no connection between the two companies, but the tsunami of outrage surrounding the Yelp-for-people app has engulfed the gadget company too.
"This was supposed to be our moment in the sun," the gadget company's founder told Wired. "We just won a major competition … then this happened yesterday and completely swallowed up our press. Our branding is in tatters."
We won't know how popular Peeple will be until the app's launch, which is scheduled for November. But there's reason to be skeptical that it will get very far.
For one thing, you probably hadn't heard of the other people-rating services I mentioned earlier in this article. This is an idea that has been tried before, and it's never really worked.
And the furious reaction helps explain why. People find Peeple, and other apps like it, creepy. They have a strong intuition that rating friends and romantic partners is different from rating businesses. Given that Peeple will require users to attach their real names to reviews, most people will be reluctant to participate.
Yelp works because customers and businesses have an arms-length relationship. Most people aren't friends with the owners of businesses they patronize; they don't have to worry that leaving a negative review will later lead to awkward encounters at social events. So while Yelp has caught on, there's no reason to think that many people want to use a "Yelp for people."
<!--
new pym.Parent('vox-labor-force-participation-rate__graphic', '//apps.voxmedia.com/at/vox-labor-force-participation-rate/', {xdomain: '.*\.voxmedia\.com'});
// -->
If you judge by the unemployment rate, America's labor market seems pretty healthy. Today the Labor Department released new statistics showing that just 5.1 percent of Americans are unemployed. That's unchanged from the previous month and down from more than 10 percent in the depths of the last recession.
But the unemployment rate tells an incomplete story about the state of the labor market. It counts the number of people who are out actively looking for work and not finding it. But it does not include people who — for whatever reason — are not looking for work at all.
But another statistic, the labor force participation rate, gives a comprehensive sense for how many people are working. It shows the fraction of the population over age 16 that is working. And today we learned that this statistic fell to 62.4 percent — the lowest level since 1977.
One big factor driving this trend is that the American population is getting older, and older workers are less likely to be in the workforce. At the same time, the share of "prime age" adults — those between 25 and 54 — in the workforce has also been falling since the late 1990s.
The declining labor force participation represents a long-term trend that goes beyond the most recent recession. The LFPR rose in the 1970s and '80s because a lot of women were entering the workforce. But that trend has run its course, and as the US becomes a wealthier and older society, fewer and fewer of us are employed.
For decades, Americans have been paying for things by swiping the magnetic strip on their credit cards through an electronic card reader. But that's about to change. Today, October 1, is the official deadline to switch to a new, more sophisticated payment technology that replaces that magnetic strip on the back of your credit card with a tiny computer chip. If you have one or more credit or debit cards, you probably got replacements recently that looked like this:
Ti_ser / Shutterstock
On the left-hand side of the picture, you can see metal contacts that allow a card reader to communicate with a tiny computer chip embedded in the card. This chip is capable of authenticating financial transactions in a way that's much more fraud-resistant than the old-fashioned magnetic strip.
From the user's perspective, the change will be a fairly minor one: Instead of swiping the card through a reader, you'll slide it into a slot and leave it there for several seconds. But behind the scenes, the switch could produce a dramatic reduction in credit card fraud.
In the past few years, US retailers have suffered from a seemingly endless series of security breaches that led to the loss of customers' credit card information. A big reason for this is that our technology for processing credit card transactions — specifically, the magnetic strip on the back of the card — is decades out of date.
That magnetic strip contains a machine-readable version of the same information that's printed on the card itself: the account number, account holder's name, and the card expiration date. The credit card terminal uses this information to contact the bank that issued the credit card and verify that the card is valid.
The key thing to notice about this scheme is that it effectively works on the honor system. Your account number and expiration date work as a de facto password for your account, and you share that "password" every time you buy something.
This works surprisingly well because the overwhelming majority of merchants have no interest in defrauding their customers. But if the information falls into the wrong hands — say, because hackers infiltrate a major retailer like Target or Home Depot — then exploiting it is easy. Criminals simply have to copy the information onto a new credit card, then hire people to go on shopping sprees with the new cards, buying valuable items like iPads and designer handbags that can be unloaded at a profit later.
This might be why the United States suffers disproportionately from credit card fraud. In 2013, the US accounted for 23 percent of all credit card transactions but 47 percent of credit card fraud.
This problem has been obvious for decades, and indeed the financial industry figured out how to solve it decades ago. The solution: Replace that magnetic strip with a tiny computer chip that is capable of authenticating itself in a more sophisticated way. The chip card can prove it's legitimate without supplying enough information for a criminal to clone the card.
EMVCo
The global standard for doing this is called EMV, after the Europay, MasterCard, and Visa networks that developed it. The EMV standard was developed in the early 1990s, and most of the developed world has been using the technology for years. In Europe, chip-based credit card transactions accounted for 96 percent of transactions in late 2014, compared with less than 1 percent in the United States. Latin America, Asia, and even Africa are ahead of the US in adopting the technology.
The transition has been so slow because switching to a new payment system requires simultaneous upgrades by many different parties. Banks have to send out new credit cards. Retailers have to upgrade to new equipment. If banks upgrade and merchants don't — or vice versa — the investments will be wasted.
And these upgrades are expensive. New chip cards cost as much as $4, compared with less than 50 cents for old-fashioned magnetic strip cards. New card readers can cost hundreds of dollars, compared with less than $100 for the old ones.
To prevent companies from dragging their feet, major American payment networks set a hard deadline — October 1, 2015 — for switching to chip card technology. Starting today, they're going to change credit card liability rules to give merchants and card-issuing banks an incentive to switch. Right now, merchants and card-issuing banks split liability for credit card fraud. But if a fraudulent transaction occurs after October 1, liability will fall more heavily on companies that haven't upgraded to the new technology.
This is why you may have gotten a bunch of replacement credit cards in the mail in recent weeks. By upgrading promptly to the new technology, major banks can not only reduce fraud, but can also shift liability for fraud that does occur onto merchants.
Retailers — especially smaller ones — have been slower to make the switch. But starting today, they'll have powerful incentives to do so.
The switch to chip-based credit cards will dramatically reduce one specific type of credit card — the kind where criminals steal the data off the magnetic strip and use it to make a new, fraudulent card.
The fact that the United States is the last major economy to switch to chip-based cards means that we're likely to see the benefits more quickly than other countries did. When other countries switched to EMV cards, criminals responded by cloning cards and using them in countries, including the United States, that hadn't yet made the switch. But once the US transition is complete, criminals won't have anywhere else to turn.
However, two other major avenues for credit card fraud will remain open.
One is to steal the cards themselves. A purse snatcher will still be able to take a stolen credit card and go on a shopping spree. Some other countries have adopted an approach called chip-and-PIN, which requires customers to enter a four-digit PIN to authenticate transactions. But most US credit card companies have adopted a less secure chip-and-signature approach that provides no real protection for stolen credit cards (debit cards are more likely to require a PIN to make payments).
The even harder problem is remote transactions. A chip only helps with face-to-face transactions. Online orders will still work by typing in a customer's credit card number and other details, which means it will still be possible for bad guys to steal a customer's credit card information and then make fraudulent transactions online.
Credit card companies have tried a wide variety of ways to beef up the security of online transactions. All three credit card networks have experimented with systems where users are redirected to a third-party website to prove their identity before a transaction is approved. But the process is glitchy, and users hate the extra hassle, so it hasn't caught on.
Tesla CEO Elon Musk introduced the company's latest supercar on Tuesday: the Model X. It's an all-electric SUV that accelerates like a sports car.
Musk spent a lot of time touting the safety features of the Model X, arguing that it has dramatically better crash safety than competing SUVs. Advanced sensors and software can detect an impending crash and automatically apply the brakes. And Musk says the car has the industry's best air filters, including a "bioweapon defense mode" to prevent bacteria, viruses, pollen, and other pollutants from entering the vehicle.
The most visible innovation in the Model X is the falcon-wing doors. Instead of swinging outward as they do on most SUVs, the rear passenger doors on the Model X swing upward.
But before you get too excited, the Model X has sports car pricing to go with its sports car acceleration. On Tuesday, Musk unveiled a 90D model for $132,000, a P90D model with a "Ludicrous Speed" acceleration mode for $142,000. A tweet from Musk indicates that "lower cost versions" are "coming later."
Tesla will be targeting the same class of wealthy customers that bought the company's previous models, the Roadster and the Model S. If you want to own a Tesla car and you're not rich, you'll likely need to wait until 2017. That's when Tesla claims it will release the Model 3, an electric car that normal people will be able to afford.



(The Verge)

Major car companies like Ford, GM, and Toyota build their vehicles around gasoline-powered engines. Tesla cars are built around batteries and electric motors. And that gives Tesla unique advantages — and a few big disadvantages.
The biggest downside is that batteries are expensive, and you need a lot of them to get reasonable range and performance. The Model X can go an impressive 250 miles on a single charge. But the batteries required to deliver that kind of range are a big reason the car is so expensive. Tesla is investing billions of dollars in a Nevada battery factory in hopes of bringing these costs down.
Driving an electric-only vehicle also means you need a network of electric charging stations to enable people to make long trips — a network Tesla is slowly building. Tesla claims its superchargers can provide the Model S enough charge for 170 miles of driving in as little as 30 minutes — a figure that should be similar for the Model X.
The electric motors in the Model X are so small that they leave room for a trunk in the front
But all-electric design also has some huge advantages. Gasoline engines are complex and heavy, and they take up a lot of space. Using smaller and lighter electric motors has allowed Tesla to rethink how to use the space inside a car.
For example, the electric motors in the Model X are so small that they leave room for a trunk in the front of the vehicle where the engine would be in a conventional car. That not only provides more room for groceries, Musk says, it's also a safety feature.
In a head-on collision involving a conventional car, the engine gets pushed back toward the passenger compartment, increasing the risk that the driver's legs get crushed. The trunk space at the front of the Model X provides a larger crumple zone to absorb the impact of a front-end collision, increasing the chances that a passenger will avoid injury.
The batteries that power the vehicle are mounted under the floor of the vehicle. This gives the vehicle a low center of mass, reducing the risk of rollovers.
Finally, the electric motors provide great performance. Gas-powered engines have to shift gears to maintain maximum acceleration, but Tesla says the electric motors in the Model X can smoothly and rapidly accelerate from 0 to 60 miles per hour in 3.2 to 3.8 seconds, depending on the specific model.

(The Verge)
Unlike normal car doors that swing out to the side, the rear passenger doors on the Model X swing up. In the past, this kind of door has had a big problem: If there's an obstacle next to the car — like another car — it can block the door from opening.
Tesla solved this problem by adding an extra set of hinges to the middle of the doors. That allows the doors to swing upward without swinging out very far:

Of course, this approach could lead to another problem: the doors hitting the ceiling if the car is parked in a garage. To avoid that, the car is equipped with sensors that measure the distance to surrounding objects. It automatically adjusts the path of the doors to avoid hitting objects either beside or above the vehicle.
The front driver's door also has a convenient innovation: It detects the driver's approach and opens automatically. Then when the driver steps on the brake, the driver's side door starts to close.
Musk made a big deal about the air filters in the Model X. He says that standard cars have relatively small conventional filters — around a foot square — for taking in air from outside. The Model X has a more advanced HEPA air filter that can catch particles conventional air filters can't catch. However, HEPA filters work best when air flows through them slowly, so the air filters in the Model X are dramatically bigger than those in other cars.
Musk claims that the larger filter, along with advanced filtering materials, allows the interior of the car to be as sterile as a hospital operating room. The car even has a "bioweapon defense mode" that creates a slightly higher air pressure inside the car, ensuring that no outside air can seep into the vehicle.
The Model X also has one of the industry's biggest windshields, stretching up over the head of the driver and front-seat passenger, allowing them to look up at the sky as the car drives down the road. Musk claims this more expansive view can help people who are prone to carsickness.

(The Verge)
Overall, the Model X sounds like a great product. But don't expect to see a lot of them on the roads any time soon.
Tesla's stated business strategy is to start at the high end of the market and work its way down. Its first two cars were the Roadster, an electric sports car that cost more than $100,000, and the Model S, a luxury sedan that could easily cost more than $100,000 with all the bells and whistles.
The Model X has a more family-friendly design, but the $132,000 price tag on the first model makes it no more accessible to ordinary families than other Tesla cars.
Musk has signaled that later versions of the Model X will be more affordable. In a tweet, he pointed out that Model X versions cost $5,000 more than corresponding Model S versions. The cheapest Model S versions cost $70,000, suggesting that Tesla could eventually offer a version of the Model X for $75,000.
Of course, that's still a lot of money. Tesla has only sold around 80,000 Model S vehicles in the life of the product. And that's a problem because economies of scale are crucial to making profits in the car business. Musk has said that Tesla needs to sell 500,000 vehicles a year by 2020 to turn a profit, and right now the company is nowhere near that goal.
Supposedly, that will change in 2017, when Tesla plans to release the Model 3 with a much more accessible price tag of around $35,000. (Musk wanted to call it the Model E, so his three car models spelled S-E-X, but that plan ran into trademark problems). But given Musk's a reputation for missing deadlines, ordinary consumers might have to wait even longer to join the electric vehicle party.
A new McKinsey report done in partnership with Sheryl Sandberg's group Lean In sheds light on a number of obstacles women face when trying to advance up the corporate ladder. Much of it is about what you might expect, but a particularly insidious obstacle is arguably a form of self-deception in which companies say that gender diversity is a priority but don't act like it.
McKinsey
This chart shows that nearly three-quarters of companies officially state that their CEO prioritizes gender diversity in his (or her, but really it's almost always his) decision-making. About half of men say they think this is true, but only about a third of women (who would be in a position to know) agree. And of course real priorities filter down to middle managers, who know they need to adopt the CEO's priorities in order to get ahead. And when it comes to their direct supervisors, men and women both overwhelmingly agree that gender diversity isn't a priority.
The result is a dynamic that's incredibly resistant to change. Companies aren't going to do things differently unless CEOs make it a priority, but you can't even get a discussion going about making something a priority when the CEO is invested in saying it already is.
As podcasts have become a staple of our commutes, some of their quirks have become more ... noticeable. And annoying.
Of course, we have undying gratitude for podcasters' hard work — but do they have to mention Squarespace 17 times in a row? And why do they act like iTunes reviews are the most important currency in the world?
But as it turns out, many of the most aggravating podcast tics have perfectly logical explanations, and understanding those tics can tell us a lot about the future of the medium. These aren't problems with artists, but an immature form that's on the cusp of change.
The USPS is every podcaster's obsession.
Lisa J. Goodman/Getty Images
Podcasts obviously need to air ads to make money. But why do those ads have to be for the same companies all the time? If you listen to a lot of podcasts, you'll hear enough Stamps.com ads to think that philately is a national obsession.
The ad repetition isn't an illusion. In May of this year, Marketplace and FiveThirtyEight tasked an intern with listening to the ads that played during the top 100 podcasts, and the list was dominated by five companies: Squarespace, Stamps.com, Audible, MailChimp, and Dollar Shave Club (there's a lot more data in the article).
So why do these particular companies dominate? One reason is technological. As the Atlantic notes, podcast ads often offer promo codes for some product or service (i.e., they mention a code that you can use to get a 10 percent discount). That's partly because podcast listenership is disaggregated among a bunch of different services (iTunes, Stitcher, YouTube, SoundCloud, etc.) and different times (people might listen a whole week after a podcast airs). Both of those factors make it harder — or at least more complicated — to sell advertisers on listenership alone. By contrast, a promo code verifies a "conversion" on an advertisement in a concrete fashion, since advertisers knows exactly where their sale comes from. That model works well for stamps, but less well for glossy brand-building campaigns.
The other reason is business-related. Many bigger companies prefer to move the needle on big buys that newer podcasts often can't offer. (Though some podcast companies have made dents in the market — for example, startup Gimlet Media snagged a Ford sponsorship for one of its signature shows.)
It's possible this will change in the future, however. Podcast networks and podcast ad networks (like Midroll, which sells ads for famous WTF podcaster Marc Maron) could someday make podcasts more appealing to major advertisers. Less popular podcasts, though, will likely continue to have no ads at all or scrape the bottom of the barrel.
But, of course, ads aren't the only annoying podcast tic.
"Rate us," the podcaster begs incessantly.
Shutterstock
It might seem obvious why podcasts want good ratings and reviews: They can convince curious listeners to take a leap and spend 20 minutes trying out a new show. But that's only part of the reason podcast hosts are constantly pleading for ratings.
The real prize is taking advantage of iTunes' algorithm, as Nick Loper at Side Hustle Nation details. If podcasts can gain more visibility in Apple's podcast app and store, they can gain more listeners. And the best ways to appeal to Apple include:
The reason all those podcasters are obsessed with iTunes is that it provides the best algorithm to pick up new listeners. On the web, a host of media companies have swarmed to big players like Facebook, and the same dynamic is visible in podcasting. Some companies will have the resources to post on every podcast platform, but the biggest ones will get the most attention — and right now, that's still iTunes. That could push further consolidation as well as iTunes' own possible monetization efforts — after all, Apple is already selling ads against its new Apple News app, and it could conceivably do the same for podcasts.
"Subscribe, or we will never release your family."
Shuttestock
The dynamic is similar for subscriptions: Of course podcasters want you to subscribe, because it means you're likely to listen to their show. But they also want you to help them impress the iTunes algorithm.
My Wife Quit Her Job podcaster Steve Chou is, like Nick Loper, another savvy online marketer who realizes the algorithm might be his most important audience member. Subscribers are another key piece of landing in the iTunes New & Noteworthy section, and without it, a podcast might fall off the radar.
Dan Lyons, guest-blogging at Propodder, sees it as beneficial to iTunes, as well — subscribers come back to the app and don't use alternatives like SoundCloud. So a subscriber is a valuable user to iTunes, which, in turn, makes subscribed shows worth promoting. Other networks have the same incentives, which means the subscription war is on (this should be familiar to YouTube video viewers, as well).
The only way around the mighty algorithm are guest spots, cross-promotion, and an internal network with the muscle to help break a show out of obscurity. That's yet another incentive for consolidation through a content network, like Gimlet, Earwolf, Nerdist, or a host of others that might include a public radio audience.
So podcasting's biggest annoyances are, at heart, business problems that are quickly being remedied. Are these changes good or bad for the future of podcasts? It depends on your preferences. At the very least, you may hear fewer repetitive ads for MailChimp as podcasting continues its march toward the mainstream. But what's annoying or not will depend on what you can tolerate during your commute and — most likely — how bad the traffic is.
The 21 Bitcoin Computer, which was unveiled this week, is one of the most highly anticipated products in the Bitcoin world. The company behind it, 21 Inc., has raised $120 million from prominent investors like PayPal co-founder Peter Thiel and the well-known firm of Andreessen Horowitz. According to this list of Bitcoin investments, that makes it the most lavishly funded Bitcoin startup ever.
So this week's announcement left a lot of people confused. For $399, you can get a tiny computer with a customized chip that allows you to generate bitcoins. An incredibly small quantity of bitcoins, in fact — according to one back-of-the-envelope calculation, it will generate around 10 cents' worth of bitcoin per day if run constantly. And depending on where you live, the electricity required to power the device could cost more than the value of the bitcoins generated.

The backers of 21 believe that the ability to generate small quantities of bitcoins is going to become a standard component in digital devices — just as a wifi chip is today.  They envision a future where digital currency serves as a lubricant for a wide variety of electronic transactions that aren't possible with today's computers. If 21's technology works, it could deliver something technologists have dreamed about for decades: a practical system for paying for content and online services with tiny payments. For example, 21's technology could be used to power a jukebox that plays ad-free music, or a camera that automatically rents its own online storage.
And 21 has built some impressive technology to help realize this vision. But the vision itself seems to have some gaping holes in it — holes so big that I'm skeptical 21's technology will take off.
You've probably heard advertisements telling you to text to a certain number in order to make a $10 contribution to a particular charity. In this transaction, the phone company acts as the middleman, putting the $10 charge on your next monthly phone bill. That makes things more convenient for customers, who don't have to pull out a credit card at the time of donation — or worry that the credit card might get misused.
The technical details of how the 21 Bitcoin Computer works is complicated, but at a basic level, you can think of it as a clever hack for putting charges onto your electricity bill. Inside the 21 Bitcoin Computer is a chip that can efficiently engage in "mining": performing difficult mathematical operations that can generate new bitcoins. These bitcoins have real financial value, but the process isn't free — the chip consumes a lot of power.
The 21 Bitcoin Computer isn't designed for people who want to become professional Bitcoin miners — there are more sophisticated products for that already. Rather, 21 believes that the ability to generate a few pennies' worth of bitcoins per day will open up totally new types of markets that don't exist right now.
The device 21 is selling right now isn't the version of its technology that will eventually be offered to the general public. Instead, it's a proof of concept aimed at developers who — 21 hopes — will begin creating applications that use the 21 chip's capabilities. Over the next few years, they expect the chip will get smaller and dramatically cheaper, to the point where it can be built into a wide variety of third-party devices, much as chips from Intel are today.
You can think of the 21 computer as a clever hack for putting charges onto your electricity bill
Imagine, for example, buying a small speaker that acts as an ad-free jukebox system. You plug it in, name any song, and the device starts playing it. And you never have to pull out a credit card. Instead, the jukebox is generating a fraction of a penny for each song it plays and sending it to the relevant copyright owner. Average consumers never have to think about it — or even understand how it works.
Other 21-enabled products could work in a similar way. There could be a camera that automatically purchases enough online storage for the pictures and videos you take. There might be a tablet that automatically detects wifi networks that are willing to rent out anonymous access for a few pennies' worth of bitcoins. And maybe entrepreneurs can think of other clever ways to use small amounts of digital cash to make our lives more convenient.
As the number of connected devices in our homes and offices grows, 21's technology could help avoid an orphan device problem. That's a situation where companies stop supporting these connected devices, leaving them in a broken or — even worse — insecure state. If each device is able to generate a small Bitcoin maintenance fee each month, it could provide manufacturers the funds they need to continue supporting devices long after they were created.
At this point, you might be wondering why anyone would want to buy a weird money-printing chip instead of making payments through the regular financial system. There are two basic reasons.
One is that for many applications it will be a hassle to input credit card information into a special-purpose device. The Bitcoin jukebox I mentioned in the previous section might not have a keyboard or screen, for example, and it would be convenient if you could just plug it in and have it start playing music.
The more fundamental issue, though, is that the transaction fees of traditional financial networks make very small financial transactions impractical. The overhead of credit card networks means that the smaller transactions get, the larger the fraction that gets eaten up by fees. This is why you rarely see online goods that are cheaper than the 99-cent songs in the iTunes store. Below a dollar, the economics of credit card payments don't work very well.
This is the real magic of 21's platform: The standard Bitcoin network isn't a great platform for micro payments either, but it's an open software platform. And 21 has apparently developed technology to use the Bitcoin network to make very small payments more efficiently than is possible with other payment technologies.
Technologists have been dreaming of building practical micropayments for a very long time. There have been a number of attempts to build micropayment systems, and so far, none of these systems have really taken off. The investors behind 21 are making a big bet that Bitcoin is the technology that will finally make the concept work.
People have been trying to make micropayments work for so long that the internet theorist Clay Shirky wrote an article way back in 2000 explaining why the micropayment experiments of the dot-com boom hadn't taken off. More recently, as others have tackled the concept, he's written multiple follow-up articles on the topic since then.
In a nutshell, Shirky's argument is that micropayment systems fail because users find them annoying. "There is a certain amount of anxiety involved in any decision to buy, no matter how small, and it derives not from the interface used or the time required, but from the very act of deciding," he wrote. "Micropayments, like all payments, require a comparison: 'Is this much of X worth that much of Y?' There is a minimum mental transaction cost created by this fact that cannot be optimized away."
On the surface, it might seem like 21's micropayment technology actually could optimize away these transaction costs. After all, when consumers buy new household appliances, they don't spend much time worrying about how much power they'll consume. Why should customers worry about a new generation of devices that take a bit of extra power and convert it into money?
But if you think about how this would work in practice, it becomes clear that there would be some serious difficulties. Imagine a future where you have a dozen devices in your house with 21's bitcoin mining chip in them. One month, your electricity bill is suddenly $20 higher than you expected.
Maybe it was just a hot month and your air conditioning was running on overtime. Maybe some of your 21-based devices got hacked, and bad guys are stealing your electricity to generate bitcoins for themselves. Maybe your teenage son recently bought a new off-brand device that generates a lot more bitcoins (and wastes a lot more power) than it promised on the box — and sends the extra cash back to its sketchy manufacturer.
Devices with built-in bitcoin mining chips would have to be replaced every couple of years
The problem is that you wouldn't know, and there would be no easy way to find out. It's not like your power bill will have an itemized list showing how much electricity each device is consuming. You'd be forced to start measuring the power consumption of the devices around your house — exactly the kind of accounting hassle 21's technology was supposed to eliminate.
In practice, few people are going to want to worry about this kind of issue. It's only going to take a few stories of devices being hacked — or unscrupulous manufacturers overcharging customers — for customers to decide they want to steer clear of devices with built-in bitcoin mining chips.
The 21 approach has another big problem, too: Bitcoin mining hardware tends to become obsolete quickly. All of the Bitcoin mining chips in the world compete to win a fixed pool of bitcoins. As new, more efficient chips come on the market, the number of bitcoins won by older, slower chips will go down over time.
When you buy a shiny new 21-powered device, it might only cost 70 cents' worth of power to generate $1 worth of bitcoins. After a year, it might take $1.20 worth of power to generate $1 worth of bit coins. A year after that it might cost $2 to generate the same $1.
So devices with built-in bitcoin mining chips would have to be replaced every couple of years to avoid having them waste more and more electricity.
Of course, a device that only works for a couple of years could still be useful. But in that case, it might be more efficient to just load it with pre-generated bitcoins — or even better, just have the manufacturer provide the necessary services for free and charge an extra $10 or $20 for the device. Customers like clear and transparent pricing; effectively billing costs to your electricity bill is just the opposite.
Bloomberg has a fantastic feature story on the internet's epidemic of click fraud. Over the past decade, the internet's infrastructure for selling and displaying ads has become increasingly complex and increasingly automated. That, in turn, has created growing opportunities for scammy behavior.
For example, companies create websites that humans hardly ever visit, at least on purpose, and then pay other companies to generate cheap, low-quality traffic to them. Sometimes traffic brokers use shady techniques like pop-under windows to trick users into opening a page. In other cases, the traffic is purely automated. The upshot is that advertisers wind up paying for ads that will never be seen by any human being.
This kind of scammy behavior is made possible by ad networks that automate the process of buying and selling ad space. Advertisers use ad networks because they want to reach large numbers of people and don't have time to negotiate deals with individual websites. But that also means they don't have time to carefully vet the websites that are showing their ads, leaving room for fraud.
Of course, advertisers aren't stupid. They want their ads shown to human beings, not botnets, and over time they're going to be looking for better ways to combat ad fraud.
One consequence of this is that larger websites — and media companies whose sites collectively reach a lot of people — are going to have a growing advantage over smaller, independent sites. Advertisers can be pretty sure that a well-known brand like the New York Times or BuzzFeed won't sell them fake traffic. So buying directly from publishers makes them less vulnerable to click fraud than buying through ad networks.
But the people buying the ads only have so many hours in the day. So given a choice between buying from a few big publishers or a lot of smaller ones, they'd much rather deal with large publishers. Indeed, the convenience of one-stop shopping will likely allow larger publishers to charge a bit more per reader than smaller publishers can. This is a big reason why media organizations — including my employer, Vox Media — are rushing to get bigger.
And as Vox's Matt Yglesias wrote last week, the growing popularity of ad blockers is likely to push in the same direction. Ad blockers do the most damage to sites that rely on automated ad networks to sell ads for them. The largest media companies will be able to adapt by selling ads themselves and making them look more like legitimate content. Indeed, the largest publishers might even benefit from the reduced competition for ad dollars.
This is likely to be a mixed blessing for readers. Obviously, it wouldn't be great for readers if a bunch of small, independent websites were forced out of business. On the other hand, consolidation in the media industry could ultimately raise the average quality of online journalism.
Many readers complain about the internet's "clickbait" problem, where publications seem more focused on generating clicks than on delivering quality content to readers who do click. Larger media companies that sell directly to advertisers have more reason to worry about the quality of the audience they're building, because they want repeat business and know advertisers hate clickbait as much as readers do. So if the advertising market drives consolidation in the media world, it could ultimately raise the average quality of online journalism.
For the first time ever, Boeing is locating an aircraft production facility abroad — in China — as part of a bundled deal to sell 300 new planes to Chinese airlines and leasing companies. Companies moving production to China is an old story, of course, but Boeing isn't just new to the Chinese market — this is the first time it's ever built a factory abroad. That makes it a huge deal in the deeply politicized aviation industry, and many smell a link to the demise of the Export-Import Bank, since Boeing was the biggest beneficiary of its largesse.
But this is also a story about Chinese public policy, and it highlights at least one respect in which the country's state-dominated economic growth model (whatever its other flaws) works better than freer markets — the country can coherently pursue multi-pronged efforts to develop new domestic industries by leveraging the scale of its domestic consumer market. The Chinese want to develop a domestic airplane manufacturing industry. But building large airplanes is difficult. So they've been playing Boeing and its major competitor off each other to get both companies to help teach a Chinese company how to do it. Lenin famously said that "the capitalists will sell us the rope we use to hang them," and while neither company really wants to help create a new rival, neither is willing to cede control over the Chinese market to the other.
In total, the planes Boeing has agreed to sell are worth about $38 billion — an enormous sum of money. That's spread across three separate airlines and an aircraft leasing company, but all three airlines are state-owned enterprises, and the leasing company is a subsidiary of a bank that's also state-owned.
The deal, in other words, is entirely controlled by the Chinese government, which, of course, wants a good deal on quality airplanes but also has a larger set of policy objectives.
In the United States, privately owned airlines choose to buy large aircraft from either Boeing or Airbus, Boeing's European rival, based on a relatively narrow set of business considerations. But while the Chinese government isn't indifferent to the quality of a plane purchasing deal qua deal, it also looks at other political factors.
In recent years the bulk of Chinese aircraft purchases have come from Airbus. Not coincidentally, Airbus has a production facility in Tianjin and is opening a second Chinese factory. Boeing is now opening its own Chinese factory in part to play catch-up — and the announcement is deliberately paired with the announcement of the new sales. The message from the Chinese government to both companies is clear: Your ability to make sales in China is going to be based in part on your willingness to locate factories in China.
Labor unions representing Boeing's workforce are, naturally, concerned about the impact of the new facility on jobs for their members. But China's leaders are really after something much bigger than a factory full of jobs. They are trying to develop a domestic aviation industry. And to do that, they need workers and managers who know how to build airplanes.
That's why the Chinese government's state-owned aerospace company has launched a subsidiary called the Commercial Aviation Company of China (Comec) with a mandate to build first the C919, a narrow-body aircraft intended to compete with Boeing's 737 and Airbus's 320, and then with a longer-term ambition to build wide-body airplanes.
The plant Boeing is going to build in China will be used to put the finishing touches on 737s and will handle the delivery and servicing of the aircraft. It's also going to be a joint venture between Boeing and Comec. In other words, Boeing is going to be training Comec personnel in the skills they need to complete the C919 — an airplane that is designed to put Boeing out of business.
How could Boeing be so careless about its own long-term business interests? Well, in part it's because Boeing's executives need to care about the company's short-term revenue and profits, and the quarterly earnings reports don't care about Comec's long-term vision.
But in part it's because Boeing believes that Comec is going to master this craft one way or the other. After all, remember that Airbus plant in Tianjin? It's also a joint venture with Comec. So from Boeing's perspective the die has already been cast, and it would be foolish to let Airbus gobble up the entire Chinese market for itself.
Meanwhile, Airbus is probably telling itself that helping the Chinese learn how to do final assembly for the A320 probably isn't that big of a deal because there are a lot of other steps in the aircraft value chain and a lot of bigger, more complicated planes out there. But that's why getting Boeing into the China game is important. Boeing's new Chinese plant is going to be doing basically the same things as Airbus's existing one. So if Airbus wants to regain the upper hand in competition for sales to the giant Chinese market, it will likely have to step up its future Chinese production.
Lurking in the background of this story is the Export-Import Bank, a longstanding scheme to provide discounted loans to American manufacturers that vanished early this summer after sustained attacks from Tea Party Republicans. As the American economy has shifted away from manufacturing over the decades, airplanes have become a very large share of American manufacturing exports, and Boeing became the single biggest recipient of Export-Import Bank loans. On an elite level, the main source of lobbying against the bank was Delta, an airline that didn't like the idea of the US government subsidizing airline purchases for its foreign competitors.*
The bank's disappearance will somewhat disadvantage Boeing in competition with Airbus for future contracts, because Europe retains its export financing subsidies. It also moderately reduces financial incentives for Boeing to keep its production in the United States.
But the main relevance is political. The aerospace industry is highly politicized, due to both the heavy government role in regulating the airline industry and the linkages between commercial aircraft production and military aircraft production. Boeing's main competitor, Airbus, is partly owned by European governments, and its Chinese frenemy Comec is owned by the Chinese government. Government ownership isn't really done in America, but the Export-Import Bank — along with defense contracts — was one of the US government's main tools for supporting and influencing Boeing. With it gone, Boeing is more cut loose and more inclined to cut deals that advance China's long-term industrial aspirations rather than America's.
* Correction: An earlier version of this article stated that Delta mostly flies Airbus planes. Delta does have a fleet of Airbus equipment inherited from its takeover of the former Northwest Airlines but a majority of its planes are made by Boeing.
People use the phrase "Silicon Valley" as a shorthand for the technology industry, much as they use "Wall Street" to describe the financial industry.
But much like "Wall Street," the term has become increasingly inaccurate. It's still true that the San Francisco Bay Area is the center of the technology sector. But within the Bay Area, the industry's center of mass has been shifting steadily northward, away from towns like Palo Alto and Mountain View toward San Francisco itself. Yelp, Dropbox, Airbnb, Slack, and Twitter all have their corporate headquarters in or near San Francisco's Soma neighborhood:
(Timothy B. Lee / Vox Media / Google)
On Wednesday, a major tech company announced plans to move some of its workers even farther from Silicon Valley. Uber is opening new offices in Oakland, on the other side of the San Francisco Bay — while simultaneously keeping offices in San Francisco.
Uber is hardly the first technology company to locate in Oakland — Ask.com has had a major presence there for a while — but Uber is the most prominent technology company to establish a major presence on the east side of the bay. And there's good reason to think it won't be the last.
Two big forces have been pushing technology companies up the San Francisco peninsula. One is a serious space shortage. Strict building regulations in all the major Silicon Valley municipalities has made it impossible for the high-tech economy to continue expanding in Silicon Valley proper. As Google, Facebook, Apple, and other companies have grabbed every available square foot of office space they could find, it became unaffordable for new companies to continue taking root there.
Second, San Francisco has been enjoying the same kind of urban revival we've seen in other cities across the United States. So over the past decade, founders looking for alternatives to Silicon Valley proper have generally looked toward San Francisco. The city's Soma neighborhood happens to be the terminus of the CalTrain that connects Silicon Valley to San Francisco.
The problem is that San Francisco isn't very friendly to the development of office space, either. You might think the city could make room for a lot of additional companies by building more skyscrapers downtown, but a 1986 law caps the number of square feet of office space that gets built in the city each year. So now that San Francisco has become a thriving center of the technology sector, companies there are once again facing space shortages.
So companies are looking to move to Oakland, repeating the cycle.
Yet despite San Francisco's business-hostile climate, the city is likely to remain the center of region's (and probably the world's) technology sector in the long run. The region's transportation infrastructure is oriented around carrying people to and from the city — not Oakland or Cupertino — so companies located downtown are always going to have some inherent advantages. And while Oakland real estate is comparatively cheap now, that advantage is likely to dissipate if more technology companies move to the East Bay.
Still, San Francisco is leaving a lot of money on the table by making it so difficult for technology companies to bring jobs and tax dollars into the city.
The Federal Reserve's key interest rates have been very low for a long time now, and the labor market is in at least okay shape, so calls for tighter money are getting louder from almost every corner. One huge problem for these calls, though, is that the point of tight money is supposed to be to control inflation. And right now inflation is way below the Federal Reserve's 2 percent target, and it's been below that target for years.
But a lot of people want to raise rates anyway, and they're making two somewhat dubious arguments to bolster their case. One is to say that we should ignore the inflation rate the Fed has set as its target, and use another one instead. The other is to make misguided assertions about the ways interest rates influence the economy, in order to gin up non-inflation rationales for tighter money.
On inflation metric funny business, Rich Miller has a piece in Bloomberg titled "The Fed Is a Lot Closer to Its Target Using This Inflation Measure."
The measure in question is the Dallas Fed's "trimmed mean" PCE deflator. This is part of a family of alternate inflation measures that attempt to improve on the instability of overall price indexes. The oldest and best-known of these are so-called "core" inflation measurements that simply throw food and energy prices out of the basket on the grounds that food and energy prices are very unstable. Trimmed mean is a more sophisticated way of doing the same thing — each month you throw out the fastest-growing and fastest-falling prices, "trimming" the inflation index to ignore the impact of weird outliers.
Of the different approaches along these lines, I'm most a fan of the Cleveland Fed's median CPI.
But whatever you think of these alternate indexes, here are two key points:
Bloomberg
This last one is important. It's true that using Trimmed PCE shows we are undershooting 2 percent by only a modest amount, while Median CPI and Core PCE both show undershooting by a slightly larger amount, and pure PCE shows massive undershooting. But directionally, all these measurements show the same thing — inflation is not too high, so if the point of higher interest rates is to control inflation, there is no case for higher interest rates.
Meanwhile, over in the Financial Times, Danielle DiMartino Booth offers an even more bizarre argument for higher interest rates. She accuses the Fed of "ignoring rising inflation" even though inflation is not, in fact, rising.
And then she argues that low interest rates are causing companies to not invest:
In the meantime, Fed policy has facilitated bad behaviour. Corporate chieftains, a breed long plagued with short-termitis, have been encouraged to trespass further by the siren call of cheap money. Why bother investing in the long term when it is so much more fun, to say nothing of more lucrative, to buy back shares, reduce share count and puff up profits?
The trend toward executives using borrowing to finance share buybacks rather than investment appears to be real (see JW Mason's research for more on this), but it has nothing to do with the current state of interest rates. An executive has to make the calculation, "Is it better for the value of my stock options to invest this borrowed money or to spend it on share buybacks?" Interest rates plausibly influence the quantity of borrowing that companies do, since lower rates make borrowing cheaper. But there's no reason for them to influence the split between buybacks and investment.
Economic commentators seem to have a great deal of difficulty with this, but it's time to admit that at the moment the United States simply isn't facing a serious business cycle problem. Unemployment is on the low side, but so is inflation. Cheap commodity prices are giving everyone a boost, there are a lot of able-bodied adults who may or may not rejoin the workforce in the near future, and after a long stretch of weak wage growth there's room for people to get some raises without corporate profits being squeezed to an untenable level.
Things are basically fine, and while a small increase in interest rates almost certainly wouldn't be ruinous, there's also no reason to do it.
Revelations that as many as 11 million Volkswagen cars have been cheating on their emissions tests have become big news this week. But the research that demonstrated that VW's diesel vehicles were generating excessive pollution has been publicly available for more than a year — ever since a team at West Virginia University published their findings in the spring of 2014.
Volkswagen reportedly programmed its vehicles to behave differently during emissions testing than in real-world driving conditions. To detect this, the West Virginia researchers developed a method for measuring a vehicle's emissions performance as it drove down the highway. Here's what it looked like:
(University of West Virginia)
This equipment rode around in the back of the vehicles they were testing, collecting gas from the exhaust pipe and analyzing it. The gear included an onboard generator, to make sure that the power demands of the testing equipment didn't change the performance of the engine.
Then they drove the vehicles up and down the West Coast, testing their performance in a variety of real-world driving conditions, from city streets to mountain roads. They found that one of the vehicles they tested (we now know it was a VW Jetta) was emitting 15 to 35 times the legal limit of nitrogen oxides, while another (a VW Passat) was emitting five to 20 times the limit.
At this point, the researchers didn't know why the cars were emitting so much pollution. But when they presented their results at a 2014 conference in San Diego, there were EPA officials in the audience. They picked up the investigation from there and eventually forced Volkswagen to admit that they had programmed the vehicles to cheat on emissions tests.
A CNN poll released on Sunday found that Carly Fiorina had rocketed to the number two spot in the Republican primary field, second only to longtime front-runner Donald Trump. She attracted 15 percent support from Republican-leaning voters, edging out Ben Carson at 14 percent.
Her strong performances in the first two Republican primary debates have caused a lot of Americans to take a second look at Fiorina, who is best known from her time as CEO of technology giant Hewlett Packard from 1999 to 2005. Here are nine things you should know about her business career — and what that career tells us about her qualifications for the presidency.
Hewlett Packard was a Fortune 20 company in 1999, so when Fiorina was selected as its CEO in 1999 she instantly became one of the most prominent women in business.
People are still debating how well Fiorina did running HP
Her most consequential decision at HP was to propose a merger with one of its rivals, the PC company Compaq. Fiorina's proposal attracted opposition from the families founders Bill Hewlett and David Packard, leading to a bitter proxy fight that Fiorina ultimately won in 2002 with just 51 percent of the vote. She ran the company for another three years before the board fired her in 2005.
A decade later, people are still debating how well Fiorina did running HP. The conventional wisdom holds that she did poorly. Critics note that HP's stock price plummeted during her tenure, and that the combined firm never achieved the financial targets Fiorina had touted when making the case for the merger.
Yet HP's poor financial performance was mostly due to factors beyond Fiorina's control. She managed HP during the popping of the dot-com bubble of the late 1990s; almost every technology company suffered dramatic stock price declines during the period she was running the company. Fiorina was clearly not a great CEO, but there's also little evidence she was the failure her critics claim.
Before she joined HP, Fiorina was a senior executive at Lucent, a company that had been formed by spinning off the equipment division of the old AT&T telephone monopoly.
Lucent could have been seen as a stodgy old telephone manufacturer; Fiorina played a key role in re-branding it as the company whose equipment powers the internet revolution. Fiorina dazzled would-be investors on a nationwide road show to promote the stock to investors ahead of the 1996 initial public offering.
Two years later, she dazzled the editors of Fortune magazine, who were looking for someone to put on the cover of their "most powerful women in business" issue. Her high profile and obvious media savvy were some of the factors that attracted attention from HP's board in 1999.
Carly Fiorina began her career in the late 1970s, a time when sexist attitudes were still prevalent in corporate America. So she dealt with more than her share of double standards and misogyny as she climbed the corporate ladder at AT&T.
In one early incident, one of Fiorina's colleagues agreed to meet a client at a strip club. Determined not to be intimidated, she went to the meeting anyway and tried to ignore the unconventional setting. Dancers had pity on her and refused to come to the table while she was there. And her stubbornness paid off — her embarrassed colleagues stopped scheduling meetings at strip clubs.
Carly Fiorina married a fellow AT&T executive, Frank Fiorina, in 1985
When Fiorina became the first woman to lead a Fortune 20 company, reporters naturally asked if she had broken the glass ceiling. Fiorina was dismissive. "I hope that we are at a point that everyone has figured out that there is not a glass ceiling," she said. "My gender is interesting, but really not the subject of the story here."
She has continued to resist conventional feminist rhetoric in her presidential campaign, declaring in last week's debate that "women are not a special interest group."  She bristles at liberals' contention that Republicans are waging a "war on women," arguing that many women — including her — agree with conservatives not only on abortion but also on issues like taxes and health care.
Fiorina's rise wasn't just driven by her charisma, it was also driven by Lucent's impressive financial results. Quarter after quarter, Lucent would sell more telecommunications equipment than Wall Street expected, driving the company's stock price ever higher.
This was largely because the dot-com boom was driving interest in expensive networking gear, of course. But critics say it was also due to a risky and misleading sales strategy. During Fiorina's tenure, Lucent would extend credit to their own customers to help them buy Lucent equipment.
During the dot-com boom, these loans made Lucent's financial results look better than they really were because Lucent could put sales on its books before the customer had actually paid. When the technology bubble popped, some customers went bankrupt, forcing Lucent to write down hundreds of millions of dollars worth of bad loans.
One of the most important things a president does is negotiating with foreign leaders. And while Fiorina has never conducted the kind of high-stakes negotiations a president has to — hardly anyone has — her business career has given her significant experience in talking to foreigners.
In the early 1990s, Fiorina was working in AT&T's equipment division. She was responsible for finding ways to boost AT&T's sales of telecommunications equipment to overseas customers. That involved a lot of foreign travel, navigating foreign bureaucracies, and building relationships with people from different cultures.
Boxer highlighted the fact that Fiorina owned two yachts
For example, in her memoir, she describes her efforts to close a deal with Italtel, Italy's telecommunications giant. Fiorina had lived in Italy in her 20s, so she spoke fluent Italian and understood the culture. She spent several days with her Italian counterparts, developing a relationship with them as they hashed out the terms of the deal.
When negotiations were close to completion, AT&T flew in a more senior executive, who had a terse one-hour meeting with the Italians and rebuffed their suggestion to retire to the terrace for a glass of wine. The Italians, she writes, were insulted by the way he treated them, and negotiations broke down.
"If you want to conduct effective negotiations, know whom you're dealing with," Fiorina writes. "Pay them respect by respecting what's important to them, and take the time to build trust" — which is the "emotional glue that binds people together during disagreements."
Carly Fiorina married a fellow AT&T executive, Frank Fiorina, in 1985. Their marriage never produced children, but Carly became a stepmother to Frank's two children from his first marriage.
Tragically, their younger daughter Lori died of a prescription drug overdose in 2010 at the age of 34. Fiorina begins her 2015 campaign book, Rising to the Challenge, by describing the anguished moment when police informed her and Frank that Lori had died.
"Only faith, family, and friends got me through those first terrible days after Lori's death," Fiorina writes. "Without my complete conviction that a loving God had been with Lori, and was with our family as we buried her, I'm not sure how I would have coped."
In 2010, Fiorina ran for the United States Senate against incumbent Sen. Barbara Boxer (D-CA). Boxer sought to portray Fiorina as wealthy and out of touch with ordinary Californians.
Fiorina's tenure at HP gave Boxer some ammunition for this line of attack. Fiorina ran the company during the 2001 recession, which was particularly severe in Silicon Valley, and plunging revenues forced her to lay off 30,000 workers, many of them in California.
Boxer also highlighted the fact that Fiorina owned two yachts. When asked about this, a Fiorina campaign spokeswoman told the San Francisco Chronicle that it made sense for her to own a yacht on each coast because the couple liked to spend time in the Washington, DC, area where their grandchildren live.
Fiorina lost to Boxer by a 52 percent to 42 percent margin. That's actually pretty good for a Republican candidate — it's 5 percent more than either John McCain or Mitt Romney got in the state in their presidential races.
While Fiorina lost her 2010 race for US Senate, she won another important campaign: the 2002 shareholder vote on whether to approve the merger of HP and Compaq.
The race was as expensive and grueling as a conventional political campaign. Both HP management and opponents of the merger spent millions of dollars promoting their respective sides of the debate. And Fiorina spent weeks flying across the country meeting with major shareholders in an effort to win their votes.
By the end of the campaign, according to biographer George Anders, Fiorina was visibly exhausted from the grueling travel schedule and late nights. But she was successful; the merger was endorsed by 51 percent of HP shareholders.
While Fiorina has never served in elected office, she has extensive experience dealing with the government as a service provider. During the 1980s, much of her time was spent selling telecommunications products to the federal government, and HP sold products to the federal government as well.
So Fiorina probably has a more sophisticated understanding of how the federal government makes major technology purchases than any other candidate for president. And that could be particularly valuable because in recent years the federal government has struggled to adapt to a changing technology landscape. Technological innovation is rapidly reducing the cost of web technology in the private sector, but too many federal agencies are still soliciting multimillion-dollar bids to overhaul their IT systems. Fiorina may be the ideal person to change that.
Like several other Republican candidates, Carly Fiorina has made President Barack Obama's nuclear deal with Iran a key part of her presidential campaign. Fiorina has described the agreement as a "very dangerous deal," because it opens up the Iranian economy without getting US inspectors sufficient access to Iranian nuclear facilities.
Yet in recent days, Fiorina has faced criticism for her own past dealings with Iran. Specifically, when she ran Hewlett-Packard, the company indirectly sold hundreds of millions of dollars worth of equipment — mostly printers — in Iran. She claims that she didn't know about the sales and didn't violate sanctions laws. But the reports, which have been circulating at least since her 2010 Senate campaign, makes it awkward for her to strike a hawkish pose on the Iran issue today.
Since 1995, the US has had a sanctions regime that imposes strict limits on US companies selling their products in Iran. The sanctions are intended to pressure the Iranian regime to improve its human rights record and abandon its efforts to get a nuclear weapon, among other objectives.
HP didn't sell its products in Iran directly, but a lot of HP products wound up being sold there anyway. A 2008 Boston Globe investigation explained why:
In 1997, two years after President Clinton banned trade with Iran, HP struck a partnership with a newly formed company in Dubai to sell its products in the Middle East. At the time, the company, called Redington Gulf, had only three employees and its sole purpose was to "sell HP supplies to the Iran market," says a history on Redington Gulf's website and Rajesh Chandragiri, the administrative manager in Redington Gulf's Dubai office.
Redington Gulf maintained offices and a service center in Tehran, and licensed Iranian retailers to sell HP printers in their stores. The result: one poll found HP was the leading printer brand in Iran, with a 41 percent market share.
There's also evidence that HP personnel — thought not necessarily Fiorina personally — were aware of the extent of HP product sales inside Iran. The San Jose Mercury News has reported that in 1999, "the company's Middle East general manager was quoted in a United Arab Emirates English-language newspaper calling Iran 'a big market for Hewlett-Packard printers.'"
The Globe investigation prompted an SEC investigation into HP's dealings with Iran, leading HP to sever ties with Redington Gulf in early 2009. At the time, HP estimated that sales of HP products in Iran were around $120 million in 2008, a tiny fraction of HP's $118 billion in worldwide revenues that year.
Fiorina ran HP from 1999 to 2005, so HP was allowing Redington Gulf to distribute its products before, during, and after her tenure. A spokeswoman for Fiorina's 2010 Senate campaign said that "to her knowledge, during her tenure, HP never did business in Iran and fully complied with all U.S. sanctions and laws."
Experts say that HP was operating in a legal grey area. "At the time it was ambiguous to many people as to whether it was illegal or not," one sanctions expert told Bloomberg recently.
And HP wasn't the only American company who used intermediaries to sell their products in countries subject to sanctions. For example, in 2005 the SEC sent a letter to Xerox asking about its relationships with companies that did business in Iran, as well as Syria and Sudan — which were also subject to US sanctions at the time. Xerox responded that it was "terminating all its distribution agreements related to sales in Iran, Sudan and Syria."
Most of HP's major competitors in the printer business are based outside the United States, and so haven't been as constrained by US sanctions. For example, the New York Times reported in 2010 that the Japanese printer giant Canon had been selling products in Iran for at least a decade. Epson, another leading printer company based in Japan, has also had extensive dealings in Iran. Samsung, based in South Korea, has an Iran section on its website.
Last week, Bloomberg described HP as having "unusual omnipresence" inside Iran, but this isn't really accurate. It's true that HP was Iran's leading printer vendor with an estimated 41 percent of the market in 2007. But that's because HP is the leading printer brand around the world, and has been for years. HP sold 49 percent of the world's page printers in 2005, 44 percent of multifunction printers in 2008, and 40 percent of all printers worldwide in 2013. The main reason HP printers have been so popular in Iran is that they're popular everywhere.
It seems pretty easy to defend Fiorina's conduct on the merits here. A CEO's job is to maximize shareholder value while staying within the bounds of the law, and Fiorina seems to have done just that. The law required HP to avoid dealing with Iran. It didn't necessarily require them to scrutinize the activities of every distributor to guarantee that none of its products ever wound up in a country subject to sanctions.
Moreover, the practical damage from HP's actions seem awfully minor. Printers aren't essential military equipment. And if HP had worked harder to block its printers from entering the Iran, that wouldn't have meant Iranians couldn't get printers. It just would have meant they'd buy printers from competitors like Samsung, Canon or Epson.
Fiorina's problem is that it's hard to make this kind of pragmatic argument while simultaneously blasting the Obama administration for his own pragmatism on the Iran issue.
Greece is having an election on Sunday! Yes, they had a legislative election in January. And yes they had a big referendum back in July. But the economic and political crisis in Greece is sufficiently severe as to require yet another round of voting. And while back when the election was first called it looked like it would be an easy win for Prime Minister Alexis Tsipras, polling now shows a neck-and-neck race with his main opponent slightly favored.
At this point, both of the main parties favor accommodating demands from Greece's European creditors so the election is unlikely to spark a new round of economic and political chaos. But this is Greece, and Tsipras and his Syriza party have surprised outsiders many times before so don't entirely count economic and political chaos out.
There are two leading parties in the election:
There's also PASOK, the formerly dominant center-left party that was marginalized by Syriza's rise, and which also supports accommodating the Germans. There's Potami, a newish centrist party that's never held office. There's Popular Unity, which consists of former Syriza members who opposed the European deal. And there's the neo-fascist party Golden Dawn.
The polls show a tight race between Syriza and New Democracy, followed by a close bunching of the smaller parties.
Wykx
That's a big change from the immediate aftermath of Tspiras making a deal with Greece's creditors. For a moment during the summer, he was the absolute master of the Greek political scene having marginalized his rivals to both his right and his left. The high-profile confrontation with European finance ministers cast Tsipras as the embodiment of Greek national interests. The subsequent electoral campaign seems to have succeeded in allowing New Democracy to re-active the underlying ideological disagreements in the Greek population — consolidating most of the right-wing vote behind them while most of the left-wing vote goes for Syriza.
Greece elects a 300-person parliament on a proportional basis, but with two significant twists.
These deviations from proportionality can be very significant. The most recent poll, for example, shows Potami securing about 4.6 percent of the vote which should be good for 12 seats. But if Potami loses half its support and get 2.3 percent of the vote, they don't get six seats — they get zero seats.
That same poll showed Syriza with 31.7 percent of the vote and New Democracy with 30.9 percent of the vote. In a purely proportional system, that would leave Syriza and ND with basically the same number of seats. But in the actual voting system that projects out to 134 seats for Syriza and just 82 for New Democracy.
In other words, while the neck-and-neck race for first place between Syriza and New Democracy isn't quite as consequential as it would be in a zero-sum election (like a US presidential race) it's a much bigger deal than it would be in a more proportional system.
Probably not. It looks like the election will either allow a Syriza-PASOK left-wing coalition to secure a majority or else will allow an ND/PASOK/Potami center-right coalition to secure a majority.
The big background to all of this is that whatever their disagreements, these four parties all fundamentally agree that Greece should continue participating in the Eurozone and that means acceding to the key demands of Greece's creditors. The creditors, in turn, have a set of prescriptions that are sufficiently rigorous as to deny the Greek government many choices to make. The parties that want to break with the EU — Golden Dawn and Popular Unity — are both looking marginalized.
Consequently, it sure seems like there shouldn't be a crisis.
That said, you could imagine a situation in which the numbers work out such that the only way to form a majority would be to have a cabinet that included both Syriza and New Democracy. So-called "grand coalition" governments of that sort are commonplace in some countries, but can be tricky to get off the ground where they haven't existed before. Given the circumstances of the bailout deal with Europe, the actual policy differences between Syriza and ND are modest but there's no history of cooperation between these parties and the differences in social bases of support and self-conception between a radical left party and a conservative establishment party are large.
If a grand coalition becomes necessary, but coalition talks get difficult, you could start to see rumblings of complaint from Brussels, Frankfurt, and Berlin and a new round of economic uncertainty.
The internet is suddenly awash in commentary about ad blocking and ad blockers. The genre that reached its apogee in Casey Johnston's ad blocker thinkpiece for The Awl — which was, in turn, inspired by things like Marco Arment's commentary on the ethics of ad blocking, Matthew Ingram's publisher-blaming commentary, an ongoing series of articles on the subject by Jean Louis-Gassé that has been published at his Monday Note blog for months now, Ben Thompson's "Why Web Pages Suck," and Nilay Patel's "The Mobile Web Sucks" (and even more ominously "Welcome to Hell").
The dispute is about software. Specifically about "extensions" that can be added to (some) web browsers and about JavaScript that runs as part of (some) web ads. It's a discussion that's been running for a long time, but has kicked into overdrive because of Apple's release of a new operating system for iPhones and the launch of new services like Facebook Instant Articles and Apple News. And it's something you'll be hearing more and more about if you read things online, because it touches on something very near and dear to every online writer's heart — whether we can make money publishing on the internet, and the sneaking suspicion that the reasonably journalist-friendly economic climate of the past two or three years may be a mirage.
Desktop web browsers — Firefox, Chrome, Safari, and Internet Explorer — have long made it possible to install browser extensions that give your browser additional capabilities. One popular class of extensions: various forms of "ad blockers," which attempt to sift through the code of the sites you are browsing and prevent the ads from loading.
In principle, the makers of these browsers could include ad-blocking functionality out of the box — and even enable it by default.
Indeed, that's already happened once in the past. Once upon a time, the internet advertising landscape was littered with "pop-up" ads that would automatically spawn a new window when you browsed to a site. That led to the creation of pop-up blockers; eventually, pop-up blocking became a stock feature on most modern web browsers. But desktop browser makers have not chosen to do this to block all ads — so while ad blocking software is popular among some power users, it's a decidedly niche marketplace.
It also doesn't exist at all on Apple's iPhones and other iOS devices, because you can't use browser extensions on Apple's mobile Safari. Not, that is, until iOS 9, the latest iteration of the operating system, which does allow for selective-content-blocking extensions. This feature was previewed to developers months ago, and the developers have been plugging away at creating extensions that will work with iOS 9.
Ad blocking is getting more attention, fundamentally, because people think that Apple's move is going to make it a lot more mainstream.
Interestingly, evidence from past technological shifts suggests that whatever happens with ad blocking technology, it is unlikely to alter the total amount of money spent on advertising. The media industry has changed a great deal since the 1940s. Broadcast television became a thing. It went color. Cable TV was invented. It went digital. Terrestrial radio declined without vanishing. Newspapers boomed and then busted. The internet came around. And all this technological change was deeply intertwined with the advertising industry.
But as Eric Chemi showed in a fascinating Bloomberg article last year, aggregate advertising spending barely budged at all:
Bloomberg
This means that there is a zero-sum element to change in the advertising industry. The rise of new media does not expand the total pie — it grabs a bigger slice away from old media. Ad spending stays consistent at 1 to 2 percent of GDP, no matter what.
Conversely, if content blockers render a whole class of ad spending ineffective, the spending won't vanish — it will pop up someplace else. So to the extent that ad blocking is bad for some ad-supported companies, it will be good for some other companies.
The big question is who will win and who will lose. Three big shifts seem likely:
Conceptually, an ad is basically something you publish because somebody paid you money to publish it. Ad blocking software can identify ad networks, and block certain kinds of advertising scripts, but it can't read minds and discern why a given story was published. Consequently, forms of advertising that fit natively into the editorial content stream should be immune to ad blocking.
John Gruber's Daring Fireball is a very successful one-man operation that will likely benefit. Take this post from his site, for example:
Daring Fireball
From the perspective of ad blocking software, this doesn't look like an ad, it just looks like a regular post. The subject of the post just happens to be Igloo and the virtues of their product, and the reason the post appears is because of a monetary transaction. In other words, it's an ad. But no ad blocker is going to block it.
This is a small-scale version of what larger media companies have taken to calling "native" advertising — advertising that appears in line with editorial content and is formatted to closely resemble editorial content, albeit with clear labeling. In this case it's a weekly "thank you" note from the author of the blog to the sponsor of the week.
Native ad campaigns — usually slicker than the Daring Fireball ones with higher production values (see, e.g., this recent Vox Creative campaign for Walmart) — have been the big trend in the industry for a couple of years now, and ad blocking would only accelerate that trend.
The bulk of modern programmatic advertising is heavily dependent on computer software. When your browser loads a site it activates various "trackers" that attempt to ascertain who you are and what kind of advertisers might want to reach you. This is why, when I was shopping for a lamp recently, suddenly my web experience was dominated by lamp ads.
Critics often find this kind of tracking creepy but programmatic ad selling, despite perennial complaints about invasions of privacy and the low rates it pays, is a godsend to smaller operations because it drastically reduces the need for sales overhead. It has allowed small editorial teams to focus on growing and cultivating their audience, while monetization happens largely in the background.
"Adblocker is brutal for us," Nicole Cliffe, co-founder and co-editor of The Toast, told Casey Johnson for her ad blocking piece in The Awl. At the Awl itself, according to Johnson's article, 75-85 percent of all revenue comes from streams that are susceptible to ad blocking.
If you do a lot of your reading by following the Snapchat Discover channels published daily by CNN, ESPN, Cosmopolitan, Mashable, and others, then ad blocking software isn't going to change your life very much. You view those channels using your Snapchat app, not using a web browser, so browser extensions don't accomplish anything for you. By the same token, publishers with Discover channels can monetize to their heart's content without fear of ad blockers.
Apple News, which launched with iOS 9 right alongside the new mobile ad blocking powers, is another example of a browser-free mode of content consumption. Apple is going to serve ads from inside the News app, and there'll be no blocking there.
Nor does ad blocking software affect the newsfeed inside your Facebook app. And Facebook is rolling out a product it calls "instant" articles, basically articles that you will read without ever leaving your Facebook app. Back in the early summer many smart observers (including Vox.com editor in chief Ezra Klein) saw this kind of distribution to app-based platforms as the future of media even without dwelling on the possible effect of browser ad blocking.
But to the extent that the more open nature of web browsing turns the browser experience into one that's difficult to monetize, that trend will only accelerate. Instead of digital media brands being companies that build websites, they will operate more like television studios — bringing together teams that collaborate on the creation of content, which is then distributed through diverse channels that are not themselves controlled by the studio.
This may or may not work as a sustainable business model, but it also raises fundamental questions about power.
"These larger firms will insist on calling these relationships 'partnerships,'" John Herrman writes, "but they will be nothing of the sort." Platform-owning technology companies will systematically hold the upper hand in negotiations. That most immediately implicates media companies' business models and content strategies, but, more broadly, it raises questions about freedom of speech and the nature of the public sphere.
These various trends have sparked a fierce and moralistic argument about the ethics of ad blocking. Marco Arment, the developer of one of the most popular mobile ad blockers, wrote that ad blocking wassomething like a moral imperative:
Web ads are dramatically different from prior ad media, though — rather than just being printed on paper or inserted into a broadcast, web ads are software. They run arbitrary code on your computer, which can (and usually does) collect and send data about you and your behavior back to the advertisers and publishers. And there’s so much consolidation amongst ad networks and analytics providers that they can easily track your behavior across multiple sites, building a creepily accurate and deep profile of your personal information and private business.
All of that tracking and data collection is done without your knowledge, and — critically — without your consent. Because of how the web and web browsers work, the involuntary data collection starts if you simply follow a link. There’s no opportunity for disclosure, negotiation, or reconsideration. By following any link, you unwittingly opt into whatever the target site, and any number of embedded scripts from other sites and tracking networks, wants to collect, track, analyze, and sell about you.
Similarly, Gruber argues that his approach to advertising isn't just a savvy business strategy — it's an important stance in favor of readers:
I see the fact that Daring Fireball’s revenue streams should remain unaffected by Safari content-blocking as affirmation that my choices over the last decade have been correct: that I should put my readers’ interests first, and only publish the sort of ads and sponsorships that I myself would want to be served, even if that means leaving (significant) amounts of money on the table along the way.
These arguments seem a bit like post hoc rationalizations. When people DVR television shows, they normally fast forward past the ads. Television ads don't involve intrusive JavaScript trackers, or have problematic consequences for battery life. People skip the ads (at least I do) because it is technically possible to skip the ads, because I don't particularly want to see the ads, and because I don't believe my personal decision about whether or not to watch the ads is going to make or break the show. I do that even though I work for an advertising-dependent website, and even though my father is a writer for an advertising-dependent show on NBC.
People block ads because they can, and if they can block more ads they will.
On the flip side, critics of ad blocking see a plot to destroy the underlying revenue stream of beloved publications.
When you block ads, you fuck over people who make things you like on the web. Own up to that. http://t.co/ovCg2LCNFa
Next person who replies to me with "But ads are annoying!!!" gets blocked

Indeed, Arment himself rapidly experienced seller's remorse about the success of his ad blocker and pulled it from the app store.
"Ad blockers come with an important asterisk: while they do benefit a ton of people in major ways," he writes, "they also hurt some, including many who don't deserve the hit."
In truth, however, the shift toward native advertising and toward partner platforms rather than websites was under way well before Apple announced the arrival of mobile ad blocking on iOS 9. It's plausible that very few people will actually bother to install ad blockers, but even if that happens the basic trend will remain the same. Advertisers will pay for more native campaigns, and readers will prefer app-based experiences that can deliver faster load times and a smoother user interface.
These trends are troubling to many in the media because, fundamentally, the industry has had a rough time of things and it was just starting to look sunnier. The media industry entered a recession with the rest of the United States at the turn of the millennium, but then it never really recovered. When I went to my first happy hour as a full-time employee of a magazine back in 2003, my colleagues greeted me with a toast: "welcome to a dying industry."
And for years that's how it looked. The web was taking attention and serving readers, but it wasn't making any money. Then after years of struggle, the advertising market collapsed in the face of a new, bigger recession in 2008. As the American economy climbed back from that recession, this time around the media industry came with it. Suddenly there were successful new venture-backed startups. But the New York Times was growing too. And so was a holdover from the 90s internet like Slate. And so was a bootstrapped company like Gawker. And Jeff Bezos was investing new money into the Washington Post. And Disney was launching exciting new digital brands around Bill Simmons and Nate Silver.
Anxiety about ad blockers, platform-owners, native campaigns and the rest is a queasy feeling that maybe the future's not so bright after all — that commercial success will depend on compliance with the whims and strategic objectives of much larger companies who, whatever their virtues, aren't inspired by the values and objectives that lead people to pursue media careers in the first place.
Elite Daily is trolling the internet with a piece claiming that "If you have savings in your 20s, you’re doing something wrong." This, of course, runs against the conventional wisdom that people should be saving around 15 percent of their income throughout their careers.
The article, written by Lauren Martin, sets up bizarre dichotomy in which people have to choose between career opportunities and a social life or saving money in their 20s. But let's try to take this seriously, as opposed to as a simple act of trolling. A few thoughts:
1. One kernel of truth in Martin's argument is that there are times when spending money   — even in seemingly wasteful ways — can make sense. For example, if you're in a career where networking is important, it may be smart to spend money to take full advantage of social opportunities. You might want to spend a bit extra to live near other young people in your industry. Taxi fares and bar tabs can be seen as investments in relationships that will pay professional dividends for decades to come.
2. But spending beyond your means on this kind of thing only makes sense for a limited period of time. For your first year or two after moving to a new city or entering a new profession, it might make sense to spend extra to help you become better connected. If after several years, you're still spending so much on your social life that you're not accumulating any savings, then something needs to give.
3. You don't want to get to your 30s or 40s and find you have no money in the bank. Seriously. And while your 30s and 40s — and kids, and spouses, and sick parents — may seem a lifetime away in your 20s, they are closer than you think. Sorry.
4. Martin, writing about her sad life before she had her no-saving epiphany, writes that "I was trying to save, which meant trying not to eat. I wasn’t going out with friends, had yet to go to a club and had never seen the inside of a taxi." This gets to a common misconception about how people get in financial trouble.
5. The problem usually isn't daily, discretionary expenses like cab fare or a bar tab. You can always cut those out when you need to. The problem is big-ticket, fixed costs. The biggest of these, especially if you live in a big city, is rent. If you can trim 10 or 20 percent off of your monthly housing costs — perhaps by getting a smaller apartment, moving to a less popular neighborhood, or getting a roommate — that can make a much larger difference to your budget than cutting out small-ticket luxuries like a morning cup of coffee.
6. That's why, when you look at the extreme early retirement community — the folks who stop working in their 30s — their secret is usually that they live somewhere super cheap.
7. American culture encourages people to behave like they're richer than they really are. Many people find it awkward and a little embarrassing to admit that the reason they don't want to go out is that they can't afford it. But that can lead to a bad equilibrium where everyone is spending more money than they want to. It's a shitty thing that we all do to each other without meaning to.
8. Luckily, this isn't actually a hard problem to solve, it just requires a bit of honest communication. Unless your friends are assholes, they're likely to be perfectly willing to come have a drink at your apartment instead of the bar. And there's a good chance they'll appreciate the savings as well as the company.
The Federal Reserve made big news today by doing nothing — higher interest rates are not coming this month.
That's the outcome that most observers were expecting over the past week, but a considerable minority of voices has been calling for higher interest rates all summer. The economy, after all, is much stronger right now than it was five or three or even one year ago. We could surely survive without the extroardinary expedient of super-low interest rates.
After all, when you see a person in the hospital with oxygen tubes in her nose and a saline drip in her arm, you assume the doctors have done this for some good reason. Most likely, if the tubes were removed the patient's health would be in serious jeopardy. But all else being equal, having tubes stuck in you is a pretty crappy situation. It's uncomfortable, and it limits your mobility. As soon as it's safe, you'd want to pull the tubes out. Now that the emergency created by the 2008 financial crisis is over, some people are anxious to pull the tube out and let the patient get back to living a normal life.
But there's actually no reason to think low interest rates are a problem for the US economy. Low interest rates reduce the federal deficit, encourage entrepreneurship, and boost economic growth. As long as inflation stays low — and right now, it's extremely low and likely to stay that way for a long time — we should relax and enjoy the benefits.
Back in early August, the conventional wisdom was that the Federal Reserve would finally raise interest rates for the first time since house prices started to collapse more than seven years ago. Then the financial trauma coming out of Asia cast doubt on that. William Dudley, the influential president of the New York Fed, said recent events made a rate hike "less compelling," and, partly as a result, US markets have been soaring ever since.
But Dudley also said, "I really do hope we can raise interest rates this year," and, most of all, that there's no reason to be thinking about new efforts at monetary stimulus: "I’m a long way from quantitative easing. The US economy is performing quite well."
This central analytic mistake is repeated daily on financial television shows, on "finance Twitter," in the business press, and apparently in staff-level discussions in the Federal Reserve. The conceit is that raising interest rates is a good thing, and the Fed should do it as soon as possible. Debate is entirely focused on whether higher rates would be catastrophic. Any good economic news counts as a reason to think they wouldn't be and therefore should come sooner.
In order to make it seem more obvious that higher interest rates are good, proponents of higher interest rates have taken to calling higher interest rates "normalizing" monetary policy. Normal things are good, right? Who could be against normal?
But this is both totally wrong and a remarkably recent idea.
Back in the 1990s, the Clinton administration wanted to reduce the budget deficit because they perceived that a lower deficit would lead to lower interest rates, which would bring a positive impact to the economy. Back in 2009 when the Great Recession and the Obama stimulus were making the deficit very big, critics warned (wrongly) that "bond vigilantes" would wreck the US economy by bringing higher interest rates.
People knew, in other words, that all else being equal, low interest rates are good. Let me count the ways:
The last point is worth dwelling on. Many people see the relationship between low interest rates and high-tech investments and say that they see a "bubble." The relationship is real, but this is not what a bubble is. Low interest rates are part of the fundamentals of the American economy, and have been for years now. One thing that happens in an economy that has low interest rates is that money flows into the hands of entrepreneurs and innovators rather than being tied up exclusively in financing government debts and plain vanilla mortgages. Having an economy that is friendly to entrepreneurs and innovators is good. It's a reason to hope interest rates stay low.
Of course, just because low interest rates are good doesn't mean that you should never raise rates. A central bank that's determined to keep rates low forever regardless of what happens would eventually overheat the economy and produce troubling levels of inflation.
But the United States does not currently have an inflation problem:
There is an interesting academic question of how much more the US economy can grow before an inflation problem emerges. My view is that it could probably grow quite a bit, but any honest person has to admit there's a lot of uncertainty here. The clearer issue is that there's little risk in trying to find out and considerable benefit to keeping rates as low as possible for as long as possible.
At a recent congressional hearing, Fed Chair Janet Yellen was asked about the black-white unemployment gap and said basically that there's nothing she can do about it. If you delve into the data, it's easy enough to see what she means — the African-American unemployment rate and the white unemployment rate move in tandem, at a 2-to-1 ratio that seems to be fixed by factors that are out of control of monetary policy.
But as Jared Bernstein points out, this semi-fixed ratio actually means that monetary policy matters a great deal for the racial gap. If white unemployment goes from 10 percent to 5 percent, the Fed has achieved a 5 percentage point reduction. At the same time, we would expect black unemployment to fall from 20 percent to 10 percent — a much larger 10 percentage point reduction.
With the United States currently enjoying a lowish 5.5 percent unemployment rate, it's easy for relatively privileged people to neglect the benefits of further small reductions. But for an African-American population that will enjoy a double-scale version of any drop in the unemployment rate, the stakes remain quite high.
The same is true of other kinds of vulnerable populations. The college-educated cohort that dominates discussion of economic policy already has a very low unemployment rate. But working-class Americans could see considerable benefit from a stronger labor market.
What the Fed needs to do is redefine its conception of normalizing policy. Normal monetary policy is pretty simple — higher interest rates when needed to fight inflation, but not otherwise.
That's what normal monetary policy looks like. It's true that slowing population growth, aging, higher levels of foreign savings, and other factors seem to be systematically pushing interest rates to a level below what's historically normal. But it's also true that the US population is older and slower-growing than what's historically normal, which is true of other wealthy countries as well. Things change over time. What shouldn't change is the basic philosophy that tighter money is a solution to a specific problem — economic overheating — not a goal to be pursued at the soonest possible moment.
I was a senior in high school in 1999, and it was pretty awesome — we played that Prince song a lot and didn't care about our grades. As it turned out, it was also the peak of real median household income in the United States for all major racial and ethnic groups, according to new data released today by the Census Bureau.
Yikes.
Now, you will see this chart a lot today, so it's worth keeping in mind that it comes with a lot of caveats.
All that said, data limitations have always applied to efforts to measure living standards. Those efforts used to show a clear upward trend. More recently, they have not. That's a change that should worry us, even if the real situation is likely less bleak than this chart makes it out to be.
Over the last 20 years, as China ramped up heavy industry and grew at a torrid pace, the country consumed staggering quantities of raw materials. This chart by Jeff Desjardins of Visual Capitalist gives a sense of the sheer scale involved:
(Visual Capitalist)
China now burns as much coal as the rest of the world combined, and accounts for roughly half the planet's aluminum, steel, and copper consumption, according to data from the Wall Street Journal. In the last three years alone, China poured more concrete than the United States did in the entire 20th century. This despite only making up 13 percent of global GDP.
China's vast appetite for raw materials is now slowing down — creating turmoil around the world
But now comes a major twist. China's economy has been sputtering of late. The old model of relying on investment — building endless factories, highways, airports — and growing at 10 percent each year seems to be hitting diminishing returns. China's growth rate has fallen sharply this year (official stats say 7 percent annual growth, but many analysts suspect the real number is far lower). The country is also trying to transition to a consumption-based economy, similar to what you see in the United States or Europe, which could entail smaller growth rates going forward.
That means China's vast appetite for raw materials is tapering off, which in turn has had outsized effects on global commodity markets. As China's economy has slowed, the price of oil has fallen by more than half over the past year, while commodities like iron ore, copper, and aluminum have seen drops of 20 percent or more since January.
That slowdown is having ripple effects around the globe. During the 2000s, China's industrial growth was a huge boon for commodity exporters like Brazil, Argentina, Australia, and even Canada. Now that Chinese demand for raw materials is sagging, many of those countries are struggling — particularly Brazil, which has tumbled into recession. Similarly, a big chunk of Africa's export growth since 2005 came from selling raw materials like copper and iron ore to China. Those countries are now taking a hit.
Not everyone loses out, mind you: If waning Chinese demand drives down the price of crude oil, that's a boon for petroleum consumers in places like the United States and Europe. Same goes for, say, users of industrial metals who would benefit from cheaper costs.
Meanwhile, China isn't going to disappear overnight. Even if slower growth becomes the norm, it will remain the world's biggest consumer of raw materials for years to come. And if China makes the switch to a consumption-based economic model, that will propel demand for other "soft" commodities — say, coffee instead of concrete. But as the chart shows, China is so vast that even small blips can reshape global markets, causing turmoil around the world.
Data on how we spend money on everything from haircuts to cold cuts is included in the US Bureau of Labor Statistics' Consumer Expenditure Survey, which reviews the spending habits of Americans every year. It shows us that the average American making anywhere from $10,000 to more than $70,000 in annual salary uses a large share of total take-home pay for housing, transportation, food, and health-care-related costs. Death and taxes are great equalizers ... and so is visiting a doctor.
Check out how your spending compares with the profile of the average income group using the interactive visualization below. Here's how the data is organized: The colored boxes represent expenditure types; the reported amounts of each category add up to the total average expenditure (plus gifts; see note below) for an income group. You can see that, accounting for specific dollars spent, Americans spend the most on housing and transportation overall.
<!--
new pym.Parent('consumer-expenditure-survey__graphic', '//apps.voxmedia.com/graphics/vox-ce-survey/', {xdomain: '.*\.voxmedia\.com'});
// -->
A note on data used: First, the interactive is based on expanded data directly provided by BLS, which surveys reported expenditures for the full 2014 calendar year, January to December. Second, the total expenditures cited here include purchased gifts. Third, it's good to know that all expenditures are not necessarily made with work-related salary or income — money can be spent if it is borrowed money, a gift, collected interest, or other types of account receivables.
What surprised me the most — besides the ongoing consumption of tobacco products across all income groups — was just how similar Americans really are across incomes when it comes to spending. There are many smaller points nestled within groups that provide insight into lifestyles, too. For example, consider a low-income person who spent more than her income, which the BLS attributes to a variety of scenarios in which borrowed money or savings becomes the primary sources of funding, like being a student or experiencing sudden job loss. Consider, too, the fact that lower-income earners tend to spend more of their income on housing and food, which you can read more about in our collection of charts about Americans' financial lives.

The Federal Reserve will decide next week whether to raise interest rates for the first time in almost a decade. And journalists writing about the decision (or at least the people writing their headlines) like to use the word "dilemma" to describe the situation. But a little bit of international perspective helps illustrate that the Fed isn't really facing much of a dilemma.
Take Brazil, which is currently falling into a recession. Ordinarily when an economy turns south, the central bank responds with looser money and lower interest rates. By flooding the economy with liquidity, a central bank can encourage businesses and consumers to spend more, cushioning the impact of the downturn. But there's a problem: Brazil's inflation rate is high and getting higher.
Brazilian inflation rate.
Trading Economics
To deal with inflation, central banks need to tighten monetary policy and raise interest rates. If Brazil's central bank doesn't do this, it risks inflation spiraling out of control.
Hence, Brazil's central bank faces a genuine dilemma. Raising interest rates could push the country deeper into recession. Lowering them could bring more inflation. Both options are bad.
Things are very different here in America. Inflation over the past year has been a minuscule 0.2 percent. That's mostly because oil prices have been falling, but even if you look at "core" inflation — which excludes volatile food and energy prices — the inflation rate is below the Fed's 2 percent target. And market projections show it's likely to stay below 2 percent for the next decade.
America's central bank has a chance to have its cake and eat it too
Meanwhile, the unemployment rate has fallen to a healthy 5.1 percent. But economic growth, job creation, and wage growth have all been a bit sluggish. So the economy is doing pretty well, but not as well as it could be doing.
So the US economy could probably use a bit more help. And with inflation low, there's little risk in the Fed providing that help. So while Brazil's central bank faces a difficult trade-off between unemployment and inflation, America's central bank has a chance to have its cake and eat it too.
So if the Fed has things so easy, why do we see so many headlines about it facing a big dilemma? One reason is that the media likes conflict and drama. "Fed faces dilemma" is a more clickable headline than "The economy is probably going to be fine no matter what the Fed does next week."
But I think a more important factor is that a lot of people haven't fully grasped how much the world has changed in the past few decades. Many of today's elite policymakers and pundits came of age in the 1970s, an era when the United States faced a problem a lot like the one Brazil faces today.
In the late 1970s, the US faced high inflation and high unemployment. That forced the Fed to decide between tough anti-inflation measures — at the likely cost of a recession — or allowing inflation to continue spiraling upward.
Under Paul Volcker, the Fed ultimately chose to focus on fighting inflation, creating a painful recession in 1980. The tough medicine worked, and a generation of economic thinkers drew the lesson that the Fed should focus on keeping inflation low. And many of them have maintained that hawkish attitude even though economic environment in the US is totally different from the one we faced in the 1970s — or Brazil faces today.
The unveiling of Apple's latest smartphone, the iPhone 6S, showed that Apple has an impressive ability to keep pushing forward the frontiers of hardware design. But the announcement also came with one note that struck sour for even some of the company's biggest fans. The entry-level edition of the phone comes with just 16GB of storage — room for songs, movies, photos, apps, etc. — an amount that was arguably too low even a couple of years back.

@siracusa TBT to 2 YEARS AGO when we couldn't believe Apple was sticking with 16 GB. pic.twitter.com/eiUHqcPOuN


The continued fall in storage prices has made Apple's lack of generosity in this regard more glaring. The user experience of an under-equipped iPhone can be quite bad, and the iPhone 6S comes with features — like the ability to shoot ultra-HD video — that are going to fill up a 16GB phone in the blink of an eye.
The decision to sell this device isn't beyond explanation — it pretty clearly boosts Apple's profits — but in a broader sense it's not a very sound business strategy. Apple is already an extremely profitable company with an extremely large existing stockpile of cash. But it suffers from some skepticism about its long-term prospects. Under the circumstances, it ought to leap at an easy opportunity to trade a little profitability now in order to lay the foundation for more success down the road.
It's not too hard to figure out what Apple is up to here. Leaving the entry-level unit at 16GB of storage rather than 32GB drives higher profit margins in two ways. One, it reduces the cost of manufacturing the $649 phone, which increases profit margins on sales of the lowest-end model. Second, and arguably more important, it pushes a lot of people who might be happy with a 32GB phone to shell out $749 for the 64GB model. A 64GB flash storage chip is more expensive than a 16GB flash chip, but it's not anywhere near $100 more expensive, so pushing people up the chain increases not just revenue but profit margins.
So stingy storage on the lowest-end iPhone pushes up Apple's revenue and profit margin, and that's the kind of thing self-interested companies do. Something to whine about perhaps, but not really a shocking story.
This is fine as far as it goes, but it raises the question of what purpose is served by Apple amassing more money. Apple pays out large (and growing) sums of cash to existing shareholders in the form of dividends and buybacks, but its enormous cash stockpile keeps remorselessly marching up toward $200 billion.
This highlights the fact that the margin-boosting potential of the 16GB iPhone 6S doesn't serve any actual purpose.
The marginal extra dollar of iPhone revenue that Apple earns doesn't go into the pockets of shareholders or employees, doesn't finance investment, and isn't realistically going to finance an acquisition. It's just a vague hedge against eventual future bankruptcy. That's a somewhat understandable impulse for an incredibly successful company that actually experienced a near-bankruptcy back in the late 1990s.
But it doesn't really make a lot of sense.
Killing the 16GB phone and replacing it with a 32GB model at the low end would obtain things money can't buy — satisfied customers, positive press coverage, goodwill, a reputation for true commitment to excellence, and a demonstrated focus on the long term. A company in Apple's enviable position ought to be pushing the envelop forward on what's considered an acceptable baseline for outfitting a modern digital device, not squeezing extra pennies out of customers for no real reason.
Silicon Valley is booming. Investors are pouring billions of dollars into hot technology startups. Improbably young technologists are becoming stupendously wealthy, and some are throwing lavish, over-the-top parties. And to many people, it all seems eerily like the last days of the 1990s technology bubble.
These skeptics include technology columnist Nick Bilton, who laid out the parallels last week in a piece for Vanity Fair. He was joined by the Nation's Doug Henwood, who marvels at the eye-popping valuations of companies that have yet to attract a profit — or, in some cases, generate much revenue — in their young lives. As both writers note, there's been rapid growth in the number of "unicorns": privately held technology companies whose value, at least on paper, exceeds a billion dollars.
But while there are some superficial similarities between today's technology boom and the bubble of the late 1990s, there's also a huge difference. The internet not only has 10 times as many users as it had 16 years ago, it's also much more central to users' lives and — therefore — the economy. In 1999, big, profitable internet companies were mostly a theoretical concept. Today, companies like Facebook and Google have proven that it's possible to make huge profits online.
So to figure out whether there's a bubble, you shouldn't look at whether Silicon Valley parties have gotten more extravagant. Instead, you want to do some basic math: Has the value of technology startups grown out of proportion to their future earnings potential? This isn't easy to calculate, because we don't know how much today's technology startups will make in the future, and it's certainly possible that some unicorn investors will lose money.
But publicly traded company valuations have risen slower than profits. And if some of the startup prices you see bandied around in the media sound too high to you, that's partly because of the somewhat misleading way these valuations are reported.
There's no question that the value of technology companies has soared over the last few years. But by itself, that doesn't prove that there's a bubble. When you buy stock in a company, what you're ultimately buying is a share of its future profits. A bubble is when company values soar without a corresponding rise in their earning potential.
So a good indicator for whether there's a bubble is to compare a company's stock price with its profits. If this ratio (known as the "P/E ratio") goes up, that can be a telltale sign of a bubble. Andreessen Horowitz, a venture capital firm that has emerged as a leading anti-bubble voice, compiled a chart showing how the P/E ratio of publicly traded information technology companies that are part of the S&P 500 (which includes 500 of the largest companies in America) has changed over time:
Andreessen Horowitz
The gray line shows that the stock price of big IT firms has risen significantly over the past five years. However, when you divide companies' stock price by their projected earnings — the orange line — it reveals that today's stock market boom is different from the boom of the 1990s. The 1990s saw tech stocks soaring much faster than tech company profits. In the current boom, by contrast, rising stock prices simply reflect rising profitability in the technology sector.

Snapchat CEO Evan Spiegel has yet to earn a single dollar in profit, yet his company is worth $16 billion — at least on paper. (Michael Kovac/Getty Images for Vanity Fair)
If we could make a chart like this to cover the technology industry as a whole, we could settle the bubble debate once and for all. Unfortunately, there are several reasons we can't do this.
One is that this data isn't available for a lot of important technology companies. Microsoft, Google, and Facebook offer their shares to the general public, so the Securities and Exchange Commission requires them to release data on their profits. But many technology companies, including Uber, Airbnb, and hundreds of smaller startups, are privately held. We don't know how much profit they've made — if any — so we can't compute P/E ratios for them.
But even if we did have complete earnings data for privately held companies, we'd still run up against a deeper problem: The values of companies are about investors' projections of future profits. For a big company like Apple or Google, past profits provide a pretty good way to estimate future profits. But a startup like Snapchat (much like Facebook and Google in their early years) has yet to earn a single dollar in profit. That makes a P/E ratio a totally useless way to gauge its value. There are tons of technology startups — including some with values over a billion dollars — in the same boat.

(Barry Chin/The Boston Globe via Getty Images)
Uber CEO Travis Kalanick. (Barry Chin/The Boston Globe via Getty Images)
A final complication to valuing privately held companies is that a company that's worth $1 billion on paper may not actually be worth a billion dollars.
Anyone who owns a share of Apple or Microsoft can sell it and get the current market price. And usually all shares in a publicly traded company have equal value. So to figure out how much a publicly traded company is worth, we can just multiply the share price by the number of outstanding shares. Right now, for example, Apple is worth $644 billion.
Private companies are different. When a company raises funding from a venture capital firm, the deal is usually structured so that the new investors get their money back before anyone else can cash out. This makes good business sense, because it ensures the founders won't get rich unless the investors at least get their money back.
But it also has a tendency to inflate the paper value of privately held firms. Back in July, Uber sold around 2 percent of the company for around $1 billion, giving the company a theoretical value of $50 billion. But if the new investors' shares are given a privileged position (as they usually are in this kind of investment), then they aren't taking as big of a risk as it might appear on paper.  If Uber winds up being worth less than $50 billion, the paper losses will fall more heavily on the founders and earlier investors.
What this means in practice is that a private company being "valued at" $50 billion isn't comparable to a public company with a $50 billion market capitalization. If you think Uber's probably not worth $50 billion, you're in good company. Even the people who invested in Uber at a $50 billion valuation probably don't think Uber is worth $50 billion right now. They do believe that if all goes well, Uber could be worth more than $50 billion in a few years. But they may also have structured the deal so that if Uber underperforms expectations (but doesn't go completely bankrupt), they'll still get most of their money back.
And that, in turn, means that the market hasn't gone as crazy as the number of "unicorns" might make it seem. There are more than 100 companies that are worth more than $1 billion on paper, including Uber, Airbnb, Dropbox, Pinterest, Spotify, Square, Stripe, Zenefits, Lyft, Slack, and many you've never heard of. But it's widely understood and accepted that not all of these companies will ultimately achieve values above $1 billion. (Snapchat is a rare exception to this rule — the investors in its latest $16 billion funding round reportedly did not get a preferential position relative to the company's founders.)
There are also good reasons to think that the current crop of unicorns could earn a lot of money for their investors:
This isn't to say these companies — or any of the other "unicorns" — are guaranteed winners. Obviously, technology startups are risky investments, and some of these companies will fail. But taken as a group, there's every reason to be optimistic about these companies' prospects. Unlike the tech companies of the late 1990s, virtually all of today's unicorns are either generating significant revenues already or have an opportunity to generate revenue using the now-well-understood techniques of online advertising.
Jewel Samad/AFP/Getty Images
Fed Chair Janet Yellen. (Jewel Samad/AFP/Getty Images)
Henwood and Bilton both point to the Federal Reserve, which has kept short-term interest rates near zero for the past seven years, as a major factor in today's alleged technology bubble. As Henwood puts it, "The latest round of irrational exuberance has almost certainly been fueled by the Federal Reserve’s extraordinary efforts to reflate the economy after the financial crisis."
In one sense, he's correct. Basic economic theory says that as interest rates go down, the value of income-producing assets tends to go up. So there's clearly a connection between today's low interest rates and the relatively high value of stocks generally.
But as Vox's Matt Yglesias has pointed out, that's not what a bubble is:
Low interest rates are not irrational exuberance. They're not mass hysteria. They're not hype. They're not a search for a greater fool. They're not overconfidence. They are very real. You can look them up on the internet. It is a genuine fact about the world that if you want a safe financial asset these days, you need to accept a very low nominal rate of return. That genuinely makes other asset classes — everything from houses to ordinary stock shares to zany digital media startups — look more appealing than they would be in a world of higher interest rates.
Of course, it's true that if interest rates start rising, the value of technology companies (and companies generally) will fall somewhat. And that could be bad for investors who invested at the old, higher value. But this is true even when interest rates are high: Higher interest rates could always cause asset values to fall. Conversely, interest rates could fall further (short-term rates might be at zero but longer-term rates are not), which would push the value of technology companies up.
No one — not even Fed Chair Janet Yellen — knows when interest rates will rise or how high they might go. It's true that investors are calibrating their investments to the current interest rate environment, but that's the opposite of a bubble.
While people can quibble about the value of any particular startup, the bigger picture here is that the internet is a vastly larger market today than it was in 1999. In 1999, there were fewer than 300 million people online. Today it's close to 3 billion people. And internet users today are far more accustomed to spending money online than they were 16 years ago.
So there's no reason to be surprised that investors are pouring billions of dollars into internet companies.
We don't know if Uber, Lyft, or some other company will eventually dominate the taxi business, but it's a reasonable guess that some technology company will do so, and that this company will be highly profitable.
We can't predict whether any particular messaging or social media app will continue growing in the coming years, but it's a safe bet that users will spend a lot of time communicating online, and that the companies that facilitate that communication will be able to sell a lot of ads.
We don't know if Zenefits will succeed in revolutionizing the HR industry, or if Slack will manage to replace email as the primary way companies communicate. But it's a safe bet that the companies of the 21st century will use the internet a lot more than those of the 20th, so investing in companies that provide online services to businesses is sensible.
In short, the internet is becoming increasingly central to the world economy. So it's not surprising that companies building internet-based businesses are more valuable than ever.
When the original iPhone shipped in 2007, there was no app store, and you couldn't install any third-party apps on the phone. But it didn't matter, because the phone shipped with a stock app that was really the only app that mattered — the Safari web browser.
It's easy to forget these days what a miracle mobile Safari was. But while the iPhone was neither the first nor the fastest smartphone available at the time, it certainly was the first smartphone to give you a high-quality web browsing experience. And that was crucial, because in the mid-aughts the web was the great equalizer. By having a fully featured web browser, the iPhone transcended the concept of phones and became a true pocket computer — a juggernaut.
On Wednesday September 9, Apple announced a new, massively upgraded Apple TV and the next iteration of its Watch OS.
Neither includes a web browser.
The lack of a browser on the Apple Watch and Apple TV isn't exactly shocking — neither the wrist nor the television screen provides an ideal browsing environment — but the failure to include them is a bit remarkable nonetheless.
After all, my Apple Watch features a watch-optimized version of Apple's photo browsing software, even though a tiny screen on your wrist isn't an ideal photo browsing environment. Apple engineers put it on there because they could, and because photos are integral to the overall Apple ecosystem. Technologically speaking, including a web browser on either device — but especially the television — would be trivial. A browser isn't on there because Apple didn't bother, and Apple didn't bother because it no longer sees web browsing as central to its ecosystem.
In the desktop era, the World Wide Web was so central to the experience of the internet that for years the most popular web browser was literally called Internet Explorer. The internet was the web, and the thing you used to browse the web was the way you explored the internet.
The mobile world is very different.
With less screen space, processor power, and bandwidth available, the web browsing experience is less compelling. The web's point-and-click navigation structure reeks of desktop-first design. And the challenge of monetizing mobile web views has driven major publishers to load their (okay, our) sites with ad technology that further reduces load times and increases reading hassles.
The mobile internet is primarily an internet of apps — my go-tos are Twitter, Instagram, and Messages, but obviously Facebook is dominant, and Pinterest, Snapchat, and a bevy of messaging apps are all coming on strong. On my Mac, I navigate to Amazon.com to buy things, but on my iPhone I fire up the Amazon app for a faster, more native experience. This is the Way We Internet Now, and on both the watch and the set-top box, Apple thinks the web is a ladder we can kick away in favor of native apps with UI that is optimized to the particular device. And it's probably right.
Of course, one reason this makes sense for Apple is that as the world's largest company, and as the owner of a smartphone juggernaut, the company can get people to invest the time and energy into building native apps.
Apple is big enough that a nontrivial number of companies found it worth their while to make apps even when the products had few users — or no users at all. And there is a virtuous circle in this. The guaranteed presence of third-party apps on day one will help sell Apple TVs, and the size of the Apple TV customer base will help drive the development of further apps.
A new entrant would have trouble pulling off that sort of thing.
Ironically, this is exactly why the web was so important to Apple early in the 21st century. For years, the company was stuck on the losing end of that circle. Most people wanted to use Windows PCs because they had all the software, and most people wanted to develop for Windows because it had all the users.
In that world, the web was a game changer for Mac users.
When browsing websites became the most important, most exciting thing to do with your computer, suddenly the Mac and the PC were put on a level playing field. Even better, when Apple rolled out the iPhone it didn't need to get third parties to take speculative bets on the platform's success. The "phone" could browse the web! By building the best pocketable web browser on the planet, Apple rocketed ahead of longtime handset incumbents in a way that was only possible because all the best stuff to do was just a few clicks away.
Of course, for Apple, the fact that the post-web internet makes it harder for the next Apple to arrive is only icing on the cake. And certainly Apple is under no obligation to remain a browser enthusiast just because the Web 2.0 era of browser-mania was very good for the company. Indeed, even if it did include token web browsers on its new products, it seems likely that nobody would use them. The technology fundamentals are dictating both user behavior and business strategy, not vice versa.
But as users and consumers, we should make no mistake — after a brief, entrant-friendly, web-first world, the technology universe is increasingly moving into an incumbent-friendly, app-first world.
At Apple's September 9 event, during which the company unveiled its latest slate of products, Adobe executive Eric Snowden managed to offend a slew of women across the internet as he presented Adobe's photo editing tools on the new iPad Pro.
Humbled to represent  @Adobe in the Apple keynote today. iPad Pro & Apple Pencil are amazing. Can’t wait for you to use our apps with them!
Of the many ways he could have demoed the new technology, Snowden chose to edit a photo of a woman to make her go from unsmiling to smiling — this at an event where women (and, notably, persons of color) were almost entirely absent from view.
In case you need every woman to smile, you can now digitally force them to do so using your iPad Pro.
Giphy
So, the only woman on stage at the Apple Event so far has been a man showing how to Photoshop a woman's smile. Mmmmkkkkk.
Changing the woman's face to a smiling one — and thus one that appears more pleasing to an onlooker's gaze — was seen by some commenters as an act symbolizing male entitlement and sexism.
Stop telling women to smile Apple
There's a well-known trope of a harassing male stranger asking women on the street to smile — and it was digitized by Adobe during the presentation. In the digital world, though, the subject is not asked to smile, but forced to through technology. The imagery made a lot of people uncomfortable.
#applesmile pic.twitter.com/4mNgRICRjQ
Just think what Apple and Adobe could create if they didn’t have to dedicate all these resources to making women smile for once!
Using your finger to artificially create a smile on a woman's face seems very Silence of the Lambs. Is that what Apple was going for?
Disappointed in Apple's lack of diversity today, again. And how they forced a woman to smile. Bummer all around.

Most others who commented on Adobe's presentation either missed the act, disagreed with critical interpretation, ignored it, or expressed a feeling of conflicted support.
People are angry Apple showcased face recognition and editing by making a woman smile? Yall running out of things to get angry about?

As one Apple user noted, Adobe products do some super cool stuff.
They managed to make a model smile more through photoshop?! I don't want to be impressed, but, this is seriously powerful software. #Apple

On his Twitter profile, the speaker favorited more than a dozen congratulatory tweets, and responded to no criticisms. Snowden's presentation was met largely with support by friends and colleagues, based on mentions of his Twitter handle.
Very proud of our Adobe mobile team and thx @ericsnowden for representing us on stage today at Apple keynote. Boom! pic.twitter.com/ATFYIecGEA

I'm not writing to accuse Adobe or Apple of being consciously sexist, but I want to know if Adobe and Apple ever take a hard look at their ethical standards when they are in the pursuit of profit. The more concerning matter of the lack of diversity at the event did not go unobserved.
Apple announced today the release of a new version of the Apple TV, a device that hasn't been upgraded in more than three years and that Apple used to refer to as a "hobby." While the previous Apple TV and competitors like the Roku were really television accessories that contain computer chips, the upgraded Apple TV is much more a real computer that plugs into your television and happens to be optimized to be controlled (via Bluetooth remote or Siri) from couch-distance away rather than used up close the way a desktop computer would be.
The new product is no hobby. It features:

The quasi-open platform of the app store means the ultimate capabilities of the Apple TV won't be limited by Apple's ability to make deals or to imagine what people might want to do. Instead, software companies large and small around the world think of ways to make the hardware useful and relevant to people.
What Apple didn't announce is the creation of a new Netflix-competing streaming service that will define the future of television for the post-cable universe. Accomplishing something like that would require deals with content companies, and Apple hasn't been able to come to terms with them.
Apple announced a new iPad model, the Pro, at a special event on Wednesday, confirming rumors that they will continue investing in tablets despite stalling iPad sales in recent years.
The iPad Pro is the largest and most powerful tablet ever offered by Apple, and comes with about 10 hours of battery life. The screen measures 12.9 inches diagonally and is as wide as the iPad Air is tall. It has 5.6 million pixels, a higher resolution than offered by a Retina MacBook Pro. Weighing in at 1.57 pounds, it is interestingly heavier than very first iPad, as Walt Mossberg notes. It will be offered in space gray, gold, and silver colors, but not the classic Apple white or black.
The Pro is available for purchase starting in November at $799 with 32 GB of storage, $949 for 64 GB, and $1,079 for 128 GB. It's no surprise that the powerful Pro is being offered with new bells and whistles, including a stylus called the Apple Pencil ($99) and a keyboard accessory ($169) to help consumers use the tablet like its bigger brother, the desktop. For more on the Apple Pencil, watch our quick video (below).

The new iPad Pro is tailored for multitasking. First-time tablet users are often surprised at how difficult it is to use more than one app at a time, a capability that desktop computers mastered decades ago. Side-by-side app usage will allow the iPad to work more like the way programs can be used on a desktop computer. Apple is right: this really is the biggest news in iPad since iPad.

Apple showed off its latest series of iPads, available for purchase in November. (Verge)
In fact, Apple says the Pro offers users "desktop-class performance." The simultaneous-use functions will come in handy for Apple's integration with Microsoft Office products, which were featured at Wednesday's event. The partnership will allow Pro users to work in Word and Excel programs at the same time, for example.
The iPad Pro will be one of the most advanced tablets available. It will also be one of the most expensive — tablets running Android are often far cheaper.
Microsoft has struggled to sell its tablets to consumers, but it's been more successful at selling tablets to large businesses, which can buy in bulk and need a reliable supply of tailored products to sustain the way they incorporate technology into their businesses. Only days prior to Apple's event on Thursday, the New York Times reported that Microsoft Surface tablets would be sold by Dell and Hewlett-Packard.
If Apple could become more adept at selling tablets to businesses, it could provide a much-needed boost to flagging iPad sales. The creation of a larger tablet with power-user features like split-screen operation is designed to aid sales to corporate customers.
Sales of the iPad have been slowing down as far back as 2013, a worrying sign that Apple needed to seriously review its commitment to tablets. Just take a look at this chart shared by Benedict Evans, which shows just how different iPad sales are to that of iPhones:
A tale of two curves pic.twitter.com/cax7fH0w9v

Steve Jobs was slow to acknowledge that tablets should be part of the Apple product line. In 2005, he responded to a man practically begging him to consider tablets with an air of inspired bemusement.
Dude asks Steve Jobs to make an iPad in 2005. Jobs: "I like that" cc @karaswisher pic.twitter.com/EnYzl2Q8Cf
Apple users would wait until 2010 for the company to offer its first tablet, the iPad, which actually weighs slightly less than the iPad Pro.
Steve Jobs proudly holds up the first Apple iPad in 2010.
Matt Buchanan/Flickr
For the full breakdown of Apple's other announcements, including the Apple 6S, Apple TV, Apple Mini 2 and Mini 4 tablets, and more, check out our full Apple story stream.
The Port Authority of New York and New Jersey is a sprawling government bureaucracy that controls a number of transportation facilities in the New York Metropolitan area, including Newark Liberty Airport. Newark was historically a hub for Continental Airlines, which merged with United in 2010.
United has long contended that the Port Authority charges excessive fees for the use of Newark airport, relative to fees at other airports in the New York metropolitan area.  With United accounting for 70 percent of the airport's traffic, the airline argued that the fees put it at a competitive disadvantage.
So United has been lobbying Samson to lower the fees ever since he became chair of the Port Authority in 2011. Samson dined with Smisek in September 2011, and according to Bloomberg, he asked Smisek to reinstate a previously-cancelled route from Newark to Columbia, South Carolina, which was close to a vacation home Samson owned.
United initially refused, but relented after Samson allegedly threatened to delay projects favored by United. Bloomberg says it has reviewed documents that "indicate there may have been a direct link between the request for the Columbia flight and the Port Authority’s process of approving projects involving the airport."
The route had one round-trip flight twice a week: It flew from Newark to Columbia on Thursday evenings and returned on Monday morning — perfect for a government official who liked to spend weekends in South Carolina. Records obtained by Bloomberg indicate that it was about half full on a typical flight during its two-year run.
The federal investigation into Samson's dealings with United are a spinoff of a federal investigation into "Bridgegate," a scandal in which Christie aides allegedly conspired to close lanes on the George Washington bridge from New Jersey to New York City in order to retaliate against a perceived political enemy.
Samson, an attorney, advised the Christie gubernatorial campaign and was then named as the chair of Christie's transition committee in 2009. The next year, Christie appointed Samson to the Port Authority board.
During Christie and Samson's tenure, United gave heavily to Christie's gubernatorial campaign, and to other organizations connected to Christie. United executives donated $24,000 to Christie's reelection campaign in 2013, and United also "gave $100,000 to Choose New Jersey, a business group that answers ultimately to Christie," according to WNYC, and another $10,000 to the Republican Governor's Association while Christie was the chairman.
All these donations were part of a campaign to enlist Christie's support to lower the Newark airport fees. The parties came close to reaching a deal in late 2013 that would have cut the fees. But then news of Bridgegate broke, disrupting the Port Authority's operations and preventing an agreement.
Samson resigned in March 2014, in the midst of the Bridgegate scandal. Three days later, United canceled the Newark-to-Columbia route.
Now, with federal investigators probing United's dealings with the Port Authority, Smisek has resigned as CEO of United. He'll be replaced by rail industry executive Oscar Munoz.
Correction: I originally said the flight to Columbia ran once a week, but it actually ran twice a week, according to Bloomberg.
When Apple announced it would be holding a September 9 media event titled "Hey Siri, give me a hint," technology reporters everywhere immediately pulled out their iPhones and said, "Hey Siri, give me a hint." Of course, Siri's "hints" were none too helpful. But technology reporters have found other ways to uncover a lot of information about what will — probably — be unveiled on Wednesday.
A new iPhone is expected to be the star of the show, but there will also be several other major announcements. Read on for details.

(Sunil Ghosh /Hindustan Times via Getty Images)
The iPhone is Apple's most successful product by a wide margin, so upgrades to the iconic product are a huge deal for the company. The last three iPhone models have all been unveiled at September media events like the one Apple is holding on Wednesday, and it would be shocking if Apple didn't announce a new one this week.
Apple has upgraded the iPhone on a two-year cycle: Every other year comes a major upgrade —  iPhone 3G, iPhone 4, iPhone 5, and iPhone 6 — that updated the look of the device and (in the last two cycles) increased the screen size. In alternating years are "speed bump" models — iPhone 3GS, iPhone 4S, and iPhone 5S — that look identical on the outside but have better, faster chips on the inside.
Apple is widely expected to follow this pattern on Wednesday, releasing a new line of phones that look like the iPhone 6 and iPhone 6 Plus on the outside but replace the A8 chip that powers the current iPhone models with a faster and more capable A9 chip. It's a reasonable guess that these devices will be called the iPhone 6S and iPhone 6S Plus — but it's also possible that Apple will rethink its naming conventions.
The new iPhone is expected to adapt the "force touch" feature of the Apple Watch and the latest MacBook. Pushing harder on the screen will trigger different results than an ordinary tap — though we don't yet know what they'll be.
The new iPhone is rumored to include an upgraded camera. Recent iPhone models have sported an 8-megapixel camera. According to some leaks, Apple will bump that up to 12 megapixels. On paper, that will help Apple close the gap with high-end Android phones. However, more pixels aren't necessarily better, because beyond a certain point other factors — particularly the size and quality of the camera's lenses — become the limiting factor in image quality. The new iPhone may also be able to capture video in the next-generation, high-resolution 4k format.
The new iPhone may also sport an upgraded shell with lighter, stronger aluminum.

(Louis Abate/Getty)
Apple has been selling a set-top box for years, but it has never captured the public imagination like the iPod, iPhone, iPad, or Apple Watch, and the company always downplayed expectations for the product by calling it a "hobby." On Wednesday, Apple is expected to drop the hobby talk and take a big swing at the television market.
The company is expected to upgrade a number of Apple TV capabilities. The new model will reportedly have an improved remote, a new app store, and Siri, Apple's voice recognition software. The new Apple TV is also expected to be based on the same iOS software that powers iPhones and iPads, which should give it a number of powerful new capabilities.
Some rumors suggest the Apple TV will double as a video game console. It probably won't pose a serious threat to Sony or Microsoft, whose consoles appeal to hardcore gamers, but it could make the device more attractive to casual gamers who are accustomed to Apple's app store model.
But the most significant thing about the new Apple TV may turn out to be what it's missing: a new content strategy. For years, users have been able to buy movies from the iTunes store and watch them with an Apple TV, but this is much less popular than either traditional cable bundles or Netflix's over-the-top streaming service. Apple has been trying to put together a new streaming service that would cost around $40 per month and serve as a replacement for a conventional cable TV subscription. But negotiations with content companies haven't gone well, and so the product is not expected to be ready for announcement on Wednesday.

(PATRICK KOVARIK/AFP/Getty Images)
Apple followed the original 10-inch iPad with the 7-inch iPad Mini. Now rumors suggest that Apple will make a move in the opposite direction, unveiling a new tablet, possibly called the iPad Pro. It's expected to be larger than the current iPad, at around 13 inches.
Aimed at business users, it's rumored to sport a stylus — aiding the kind of precision work business users need to do — and allow users to run two apps side by side. Apple may partner with companies like IBM to help it sell the product to corporate customers.
Apple may also release an updated iPad Mini, though details on its features haven't leaked. And at least some observers expect Apple to wait until a later event to unveil new iPads.
Apple announced a new news-reading app called Apple News earlier this year, and some reports suggest that the product will be released on Wednesday.
Over the past few years, the news business has fragmented, with a growing number of people getting most of their news by following links from social media sites such as Twitter and Facebook. Apple is hoping to reverse this trend, creating a dedicated human-curated news-reading app that people will browse the way they once browsed a newspaper.
At an event called "Hey Siri," it's a safe bet there will be some announcements about Apple's voice-recognition software. One likely announcement, as already mentioned, is that Siri will be added to the new Apple TVs, allowing you to call up your favorite TV show by speaking its name instead of having to peck at the tiny Apple TV remote.
But other upgrades to the Siri are likely as well. For example, Siri may come with new capabilities to control "internet of things" devices. Companies are putting tiny, wireless computers in everything from lightbulbs to thermostats, but as these devices become more popular, keeping track of them all will become a hassle. Some rumors suggest that Apple will make a bid to put Siri at the center of this experience — perhaps in the future you'll be able to say, "Siri turn on the lights" or, "Siri turn up the heat," and have your iPhone make the necessary changes.
Originally published on Grist.
There’s a bagel place two blocks north of my apartment. During the day, it serves hundreds of people. One of its points of pride is that its bagels are made fresh, daily. From what I understand, that’s kind of the thing with bagels: They have to be made fresh daily.
If I’m walking home late at night, after the grates are pulled over the storefront, I’ll kick the trash bags out front of this shop. Pretty much every time, I’ll find one that feels soft and bready beneath my toe.
This is the free bagel bag. As far as I know, it is my secret.
Though I’m happy for the free bagel or seven, most of these bagels will still be carted off to the dump in the morning. And across New York City, there are likely many free bagel bags going undiscovered.
LeManuel Farrish helps his cousin, Makayla Farrish, age 3, finish her dinner at Cathedral Kitchen on August 21, 2013, in Camden, New Jersey. Cathedral Kitchen is a multi-service soup kitchen that has been serving the Camden homeless community since 1976.
Andrew Burton/Getty Images
Our country throws away 40 percent of its food, routing $165 billion of food to landfills each year. An individual American throws away an average of 20 pounds of food a month, according to a 2012 report by the Natural Resources Defense Council.
At the same time, in 2013, 49.1 million people lived in food-insecure households, according to USDA figures. At some point during 2014, one out of four Americans relied on some sort of federal government food assistance program. The number of Americans turning to these programs has increased since the 2008 financial crisis, yet since the start of the recession, funds for these programs have repeatedly been cut, and congressional Republicans are pushing for further cuts this year.
All of that wasted food, meanwhile, creates a host of environmental problems, growing the size of landfills and contributing to climate change. Organic matter decomposing in dumps is the third largest source of methane emissions, a potent greenhouse gas, in the US.
Not all of the food we send to landfills is fit to be eaten — but a lot of it is. Grocery stores overstock to make their shelves look bountifully full. Industrial kitchens, like those found in universities and hospitals, cook too much to make sure they will have enough food for an unexpectedly large influx of diners. Much of this food would still make a fine dinner up until the moment it gets bagged and tossed in the dumpster.
Shutterstock
So why are we so bad at getting this food to people who want to eat it?
There are a number of answers to that question, says Steve Dietz — none of which amount to terribly good excuses for our wasteful nation. It’s Dietz’s job to convince kitchens of various sorts — those at universities, hospitals, restaurants, airports — that it’s in their best interest to donate food. He heads up business development for the Food Donation Connection, a group that connects 8,000 locations in the US, Canada, UK, and Ireland to around 9,000 nonprofit agencies that get food to people in need.
"So I’ll go up to a CEO and say, ‘We want you to save your surplus food and donate it, and we’ll come up with the process on how to do it, we’ll manage that process for you,’" Dietz explains. "‘We’ll find the agencies, link them, and basically we’ll run the program for you.’" By end of this year, the Food Donation Connection expects it will have rescued 500 million pounds of food.
Dietz says the most common reason kitchens don’t donate is because management is afraid of the risk involved. On one recent survey by the Food Waste Reduction Alliance, 67 percent of wholesalers and retailers in the United States listed liability — say, if someone gets sick from spoiled food, and decides to sue — as their biggest concern about donating.
But that 67 percent of people need not worry. In 1996, Bill Clinton signed the Bill Emerson Good Samaritan Food Donation Act, which protects food sellers and kitchens from any liability should they choose to donate excess food.
Donors are safe "unless there’s gross negligence, and gross negligence has been described to me by several people as someone has to willfully taint the food knowing it’s going to harm someone," says Dietz. "To date, to anyone’s knowledge, no one has ever challenged that in court. Nobody has ever sued anybody under that act."
But potential donors still worry. "Just because I can’t win a lawsuit under the Good Samaritan Act doesn’t mean I can’t drag you through the mud and cost you a fortune," Dietz explains.
Not sure if there's room in the fridge.
Shutterstock
Though liability is the big one, there are other concerns that also sometimes prevent people from donating. Some restaurants, for example, aren’t sure what to do with the food while waiting for the groups that give it to needy people to come pick it up. "We hear about the cost of, you know, ‘What are we going to put it into?’ and ‘Where are we going to leave it?’ — reserving space in the cooler for it," says Emily Broad Leib, an assistant professor of law at Harvard who directs the university’s Food Law and Policy Clinic. "And then, if the food recovery organization isn’t the one picking it up, ‘How are we going to get it to the place where it needs to go?’"
While working with organizations seeking to donate food in Massachusetts, Broad Leib has also found that kitchens can face pushback from health inspectors when they consider setting up a donation program. "I think sometimes health departments get really nervous — they don’t know what the rules are, and they really scare companies," she says. "When a company asks their health inspector, ‘Well, how can I do this?’ they get guidance back that is really onerous."
Perhaps surprisingly, most people I spoke to agreed that retraining workers, or scheduling more workers, to get a food donation program up and running was not a major impediment for potential donors. According to Dietz, Darden Restaurants, one group the Food Donation Connection works with, did a study that found that preparing food for donation took workers about 15 minutes a day, and that that cost could be covered completely by "reallocating labor," without the need to hire new employees.
Shutterstock
But while there are a host of concerns about donating food — the biggest of which, liability, is something of a nothingburger — there’s one big, good reason (at least, for some companies) to donate food: Many corporations are eligible for a tax credit if they donate food that would otherwise be wasted.
The challenge for Dietz’s Food Donation Connection and other groups that want to facilitate food donation is to overcome the burden of concerns about liability and spread the good news about the tax credit.
"So I go to a CEO and I say, ‘We can save you $5 million next year on your income tax,’ we take a small percentage of that to fund us, and the agencies get all the food for free," Dietz says. (The Food Donation Connection is for-profit and makes its money from the corporations that it helps set up donation programs. It’s a model Dietz says better allows the organization to provide food, at no cost, to groups like soup kitchens, and to not compete with them for funding.)
Dietz ran through a hypothetical scenario of how the tax incentive could help a company that regularly throws out its food. Think about a bowl of spaghetti. It costs $10 on the menu. If it costs the restaurant $3 to make the dish and then you take taxes into account, the restaurant might make about $4 in profit on that spaghetti — if you order it.
If you don’t, and the restaurant throws out its $3 of ingredients, it loses $2.05 — it’s not a complete $3 loss because the restaurant gets a small tax benefit just for buying the food in the first place.
But if the restaurant donates those same ingredients — and receives the tax benefit for doing so — it may end up losing only about 85 cents.
The problem is, not every business is certain to get the tax break.
For C corporations — a tax designation that includes many, but not all, American companies that deal with food — the tax break has been in place since 1976. But for years it didn’t apply to other types of corporations, including many small businesses and farmers.  The tax credit was temporarily expanded in 2005, but that expansion has been renewed only sporadically — often, like so many other tax credits, amid a frantic rush of tax extenders at the end of the year. Because of this uncertainty surrounding the tax credit, many people with food to give have remained reluctant to donate — fears about liability trump the potential benefit of an unreliable tax credit.
"People would rather do nothing than take the tiniest bit of risk," says Broad Leib. "We don’t have great data on how much the tax incentive changes people’s minds, but we do have one data point: that in 2005, when we expanded that tax incentive to go to all businesses instead of just C corporations, donations rose by 137 percent the following year."
In the face of federal inaction, some states have set up their own tax incentives for certain groups excluded from the federal tax credit. But other states are taking a different tack: Instead of providing a tax incentive to donate food that might otherwise be wasted, they’re simply banning organic waste from landfills. It’s a method that could cut down on needless food waste even more than tax incentives. (I’ll take a closer look at these food waste bans in my next post.)
New York, in fact, is rolling out such a law. But it’s still getting up and running.
So in the meantime, if you’re interested in acquiring some day-old bagels in bulk, let me know. I can hook you up.
Grist is a nonprofit news site that uses humor to shine a light on big green issues. Get their email newsletter here, and follow them on Facebook and Twitter.
The two media narratives out there about the ever-rising cost of a college degree may have you confused. On the one hand, there are the people saying that in this modern technology-driven economy, education is more important than ever. On the other hand, there are the stories of freshly minted BAs tending bar and endless talk of the burden of student loans.
This new chart from the Bureau of Labor Statistics helps clear it up by showing that essentially both narratives are correct — inflation-adjusted incomes for college grads have fallen, but the gap between college grads' income and everyone else's is bigger than ever:
Bureau of Labor Statistics
In other words, people who say more education is the fix for what's been ailing the economy are wrong — things have been getting worse for even the best-educated workers. But as an individual, you are still much better off with a BA than without one, and the gap actually seems to be growing.
The labor market is a lot healthier in 2015 than it was five years ago, and with the unemployment rate falling, a lot of people are expecting the Federal Reserve to start acting to slow economic growth before workers demanding raises can generate inflation.
A new report from the National Employment Law Project puts that choice in context, by showing that inflation-adjusted wages fell substantially between 2009 and 2014 for almost every occupation under the sun.
One cut at this sorted different occupations into quintiles based on their average 2014 wages and then looked at how each quintile has fared. Researchers found that the rich have gotten poorer, and the poor have gotten a lot poorer:
NELP
Delving into finer-grained data, they look at the 10 most commonly held high-wage jobs in America. They find that for all 10 occupations, wages have fallen.
The rightmost column shows the percentage change in wages from 2009 to 2014. The middle column shows the average hourly wage. And the left column shows the number of people who have the job:
NELP
The good news for high-wage workers is that, with the exception of lawyering, pay has only fallen a little. If you look at the 10 most commonly held low-wage jobs, you see a much worse situation:
The message in these statistics is pretty clear: A little upward pressure on wages would be a welcome corrective to years of falling pay. Under the circumstances, the itchy trigger on the Federal Reserve staff seems out of touch with the basic reality that a years-long spell of high unemployment has given bosses an unprecedented ability to squeeze their employees.
As of this month, the unemployment rate is now lower than it was at any point during Ronald Reagan's administration:

That said, the labor force participation rate has fallen since Reagan's day. That's mostly about population aging — there are a lot more retired people now than there used to be — and a little bit about more people being in college, but that doesn't fully explain it. The labor force participation rate of "prime-aged" men between the ages of 25 and 55 has been steadily declining for decades, and in the past 10 years the participation rate for prime-aged women has fallen slightly as well.
We've been told that millennials don't care about owning things, so it makes sense to think that they might spend less. The latest Consumer Expenditure Survey, which records how Americans spend their income, casts doubt on that assumption. Not only are typical millennials buying a lot, but they're spending their income at a higher average rate than adults between 35 and 44 years of age.
Let's take a look first at the survey's next-older cohort, adults between 35 and 44 years of age. In 2014, they reported an average pre-tax income of $84,094 in 2014. (Since the survey is national, it makes taxes impossible to parse, but it's good to keep in mind that these are all averages.) This older group spent an average of $62,512 per year, which is about 74 percent of their pre-tax income.
Next, let's compare that with younger adults between 25 and 34 years of age. This younger group's income averaged $61,042 a year. They spent about $49,546 that same year, or 81 percent of their income. So this group reported spending 7 percent more of total income than the older group, even though they reported an average of $21,000 less income before taxes.
It's really easy to miss the fact that younger adults are spending a larger portion of their income by only reviewing dollar amounts on individual items. Here are some individual examples that might suggest millennials spend less of their income simply because they make less. For example, millennials spend the most on the big three costs everyone has: shelter, transportation, and food. But they spent less on the big three, on average, than the older cohort:
A rough analysis of the thousands of survey items recorded suggests that at least 60 percent of the time, younger adults reported spending less on individual items. Here are four additional examples where they spent less than the older group on individual things:
Numbers can "lie" to use if we take them out of context. In this case, we find that while millennials made and spent less in dollar amounts, they spent 81 percent of their income, while Gen-Xers spent closer to 74 percent, on average. So unless their spending habits change as they advance in their careers and income, today's 25- to 34-year-olds might end up being bigger consumers than they'd like to admit.


Since January 2011, by which point the ups and downs of the stimulus and the decennial census were behind us, the economy has been adding jobs at a remarkably consistent "slow and steady" pace. There have been a lot of big economic policy stories both at home and abroad, but the pace of labor market improvement has been very consistent.
China is the world's second-largest economy, after the United States, and it's been growing so rapidly for so long that rapid Chinese economic growth has become part of the landscape for an entire generation.
Yet in recent years, people have been warning that the model underlying that rapid growth is unsustainable. And it now looks like the summer of 2015 is the time at which the unsustainable trend finally came to an end.
China has been experiencing a stock market crash all summer, but since that crash was preceded by a ridiculous months-long stock market boom it wasn't initially obvious that this had enormous implications for the real Chinese economy.
More recently, however, it has become clear that there are serious issues in terms of China's real output of goods. You can see this in a sharp contraction in shipping through Singapore, a general decline in the volume of world trade, and the falling price of the Australian dollar, all of which are ripple effects of China importing fewer raw materials and seemingly exporting fewer finished goods.
Meanwhile, China has been furiously cutting interest rates in an effort to stimulate its economy. So far, however, that hasn't seemed to have generated much growth. (It's not yet clear if this monetary stimulus is at least generating inflation, which would have implications for the possible effectiveness of further rate cuts down the road.)
One very serious issue in writing about the Chinese economy is that to understand what's going on you often need to make inferences based on data out of Singapore, Hong Kong, Australia, or other places that enjoy strong economic links to China. The problem is that China's authoritarian political system makes it very difficult to regard any of its economic data as reliable.
Back in 2007, Li Keqiang — now the number two figure in the Chinese government — observed that Chinese economic statistics are "man-made" and therefore unreliable. Some progress has been made since then in improving their rigor. But these statistics are not just man-made, they are the product of a closed and opaque political system with no press freedom, so it would be very difficult for abuses and problems with the data to come to light. What's more, since the Chinese government clearly engages in censorship and information control to maintain its authority, there is no reason to believe it would be forthright about releasing bad economic news.
Even market-based Chinese data like stock prices is unreliable because the government has taken to intervening forcefully to manipulate share prices.  You can infer broad trends from the more reliable foreign data, but to have a finer-grained sense of what's going on you would really need accurate Chinese data, and it simply doesn't exist.
For the past five or six years, Chinese economic growth has been powered by a mind-boggling level of investment spending — both public and private sector.
Tax Foundation
Investments are things that produce an ongoing flow of services in the future. That means everything from new highways and subway tunnels to new apartment blocks and factories. And, to be clear, investment is good! All else being equal, a nation that spends a large share of its income on investment goods is better positioned for long-term growth than a nation that spends a large share of its income on short-lived consumption goods.
But in practice, there's only so much useful investment than can be made in any given span of time. In a very poor country, there should be tons of opportunities for investments with high payoff. But over time, you expect diminishing returns to set in and the level of investment to fall. In China, however, investment had been accelerating even as the country got richer — a trend that pretty clearly needed to reverse.
It's also been clear for some time now that to put itself on a sustainable basis, China needs to shift to a more conventional consumption-based growth model. In other words, it needs a smaller share of its population employed in things like building roads and factories and a larger share of its population employed in things like driving cabs and selling cars.
This is not a particularly controversial idea, in theory. Indeed, it's been the official policy of the Chinese government for years now. The problem is that the practical implications of actually doing it are tricky.
In a very short-term sense, you can always swap out a dollar of investment for an extra dollar of consumption. But because useful investments lay the groundwork for future production, this switch has implications for medium-term growth. As economist Tyler Cowen writes, "There is no simple way to switch to a 'consumption-driven' economy without the growth rate both falling and staying permanently lower."
As long as there are useful investments to make, then growth fuels more growth. You build a mine to dig for coal, then you build a power plant to burn the coal, then you build a cement plant to use the electricity, then you build a factory to manufacture more mining equipment, and so forth. Once you start running out of investments, however, this accelerator process is going to collapse, and the sustainable rate of growth will slow dramatically — even if you pull off the switch to consumption.
China is a nominally socialist society run by a self-proclaimed Communist Party, but it actually features sky-high inequality and a weak welfare state.
Rich people spend a lower share of their income than poor people, and working-age people spend a lower share of their income than retirees. Consequently, a more robust social welfare state that did more to transfer economic resources from the wealthy to the poor and the retired would help bolster consumption and put the Chinese economy on more sustainable footing.
China's economic success story over the past 30 years has been incredibly impressive, and due to the country's vast size it's been incredibly important. But such success is far from unprecedented. A number of other countries have gone through the basic cycle of very rapid export-led industrialization — often leading internal and external observers to believe that the rapid pace of growth can be sustained indefinitely.
In their paper "Asiaphoria Meets Regression to the Mean," Lawrence Summers and Lant Pritchett show that this has not been the case for earlier growth miracle countries. It's not just that growth slows down from its peak blistering pace (which essentially everyone concedes). They find that growth slows all the way down to a global average level, with no persistence whatsoever of past excellent performance.
Trading Economics
A recession, in conventional terms, is when an economy actually shrinks — something that hasn't happened for decades in China. But in countries like the United States, the baseline level of "normal" growth is pretty low — 2 or 3 percent per year — so it only takes a relatively modest decline in the growth rate to push you into negative territory.
China is different. Like most countries around the world, it had a bad year in 2009. But in Chinese terms, "a bad year" still meant a growth rate of more than 6 percent followed by a snapback to almost 12 percent. Growth has slowed considerably since then, and by all signs things are much worse in 2015. But one crucial question is whether China is simply going to slow down a lot — to something like 2 or 3 or 4 percent — or whether there's actually going to be a recession.
One potential problem is that in recent years, Chinese businesses and households have taken on a lot of debt.
BlackRock
Going into debt isn't always a bad idea. In fact, given the very fast growth rate of the Chinese economy between 1995 and 2015, most Chinese companies probably would have been better off borrowing more money in the 1990s.
But if you borrow money expecting an average 7 percent annual growth rate and only get an average 2 percent annual growth rate, then you could wind up in a world of trouble. Potentially, even, in a spiral of bankruptcies and financial crisis that lead to a recession.
The combination of rapid 21st-century economic growth in China, political crises in the United States, and China's authoritarian political system sometimes leads Western commentators to dream hazily about the virtues of Chinese authoritarianism in cutting through the nonsense and letting leaders do what needs to be done.
The reality, however, is that authoritarian political systems still have politics. There are still interest groups, and public officials are still sometimes more loyal to particular interests than to the good of the nation. This is a crucial issue in China's rebalancing process. It's easy for an outsider observer to say that inefficient state-owned enterprises should be shut down. It's harder for a government official who needs to worry about lost jobs. It's easy for an outsider to say that China needs more income redistribution. It's harder to defeat the political power of rich Chinese people who would rather the country not do that. It's easy to say China needs to spend less on construction projects and more on social services. But to do that you need to overcome the entrenched interests of the contractors who benefit from the projects.
China's leaders give every indication of being broadly aware of the nature of the country's problems and the kinds of solutions that are needed. What's less clear is that they can actually deliver these solutions.
Much of this has been in the air for years. The reason it's coming to a head now is that the stock market bubble and subsequent collapse have shaken faith in the Chinese government's ability to form and execute coherent policy.
When the bubble was on its way up, the government tried — and failed — to slow it. Then when it started to pop, the government tried — and, again, failed — to slow the pace of the collapse. China devalued its currency to boost its economy, but didn't go far enough. It's cut interest rates repeatedly, only to find that it needs to cut them again. Now the government seems to be arresting people who express negative opinions about the stock market outlet.
This summer's events have laid bare the reality beneath the incredible successes of the past 20 years. China remains a middle-income country with shaky economic institutions and an opaque and unaccountable political system. Three decades of stellar growth starting from a rock-bottom floor have landed China at a level of per capita prosperity that's similar to Serbia or Peru or the Dominican Republic — places that nobody regards as obviously amazing investment opportunities even though in some ways their political systems are more solid than China's.
Loss of faith has a self-fulfilling aspect to it. To the extent that people believe China can conquer its present-day challenges, actually conquering them becomes easier. To the extent that people begin to write China off, then it will have greater difficulties in pulling off the kind of transition the country needs.
There's a widespread belief that you should always own a home instead of renting, because if you rent you're "throwing your money away," while buying a home means you're building up equity. There's obviously something to this — all else being the same, it's better to accumulate equity than not — but it's definitely not true that you should always buy a house as soon as possible, no matter what.
When you make a mortgage payment, some of the money goes to pay off the principal of the loan, allowing you to build equity in your home. But for the first few years of the loan, a majority of your mortgage payment — nearly 70 percent at current interest rates — will be paying interest rather than principal. A good way to think about this is that you're paying "rent" to the bank to use some money instead of paying rent to a landlord for using an apartment.
Whether renting makes financial sense depends on whether the rent is higher than the costs — interest payments, foregone interest on your down payment, property taxes, maintenance costs, homeowners insurance, and so forth — you'd have to pay as a homeowner. It also depends on whether you'll live in the house long enough for the savings to offset the substantial transaction costs involved in buying a home.
Many people will come out ahead financially by buying a house rather than renting. But it depends on the market, a renter's particular circumstances, and how long the renter plans to live in the house. The New York Times has a handy calculator that helps you run the numbers.
Here are five key rules to follow when weighing whether to rent or buy.
(bikeriderlondon / Shutterstock)
(bikeriderlondon/Shutterstock)
The length of time you'll stay in a home is by far the most important consideration in the rent-or-own calculus. The total cost of a home sale is usually between 5 and 8 percent of its value. That's approximately one year's rent for a similar property. While this cost is generally split between the buyer and the seller, you'll wind up paying both sides if you buy a house and then sell it again within a few years.
What this means is that buying a house that you'll have to sell a few years later is an expensive mistake. While homeownership can provide a variety of cost savings in the long run, it will take several years for these savings to outweigh the transaction costs of buying the home in the first place.
Buying a house that you'll have to sell a few years later is an expensive mistake
So if there's a good chance you'll need to move to another city within a few years, it probably makes sense to rent. Similarly, if you're single but are hoping to start a family within a few years, that's something to take into account. Once you meet that special someone, you might find the place you buy isn't big enough, that it's in the wrong part of town, or that he or she already owns a nicer place.
The number of years it takes to recoup the costs of buying a house depends on many individual factors. But for most people, it doesn't make sense to buy a house they'll live in for fewer than four years. And almost everyone will save money if they live in a house for more than a decade.


(Monkey Business Images/Shutterstock)

One of the biggest advantages of buying a house is that mortgage interest payments are tax-deductible, whereas rent payments are not. The richer you are, the more significant this tax break becomes.
The value of the home mortgage deduction depends not only on how much interest a taxpayer has paid, but also on the taxpayer's tax bracket. Because rich people tend to both buy bigger houses and be in higher tax brackets, they get a larger tax benefit per dollar of housing.
This means the higher your tax bracket, the greater the financial benefits of home ownership. A couple making $130,000 per year and buying a $250,000 house will save about 30 percent more on its taxes, thanks to the home mortgage interest deduction, than a couple with $70,000 in income would save on the same house.
Home ownership benefits wealthy Americans in another way too. Contributions to tax-sheltered retirement accounts such as 401(k)s and IRAs are currently capped at $23,500 per year for most workers. That's more than enough for most people, but wealthy workers often want to save more, and a house is one of the few productive assets a wealthy family can buy that, like a 401(k) or IRA, doesn't trigger federal income taxes. If the family bought stocks, they'd have to pay taxes on the dividends they receive. If they bought a rental property, they would have to pay taxes on the rental income. But they don't have to pay any taxes on the valuable housing services provided by their primary home. Even better, the first $500,000 of a home's price gains is protected from capital gains taxes.


(Andrey_Popov/Shutterstock)

When you rent, you're not just paying for housing, you're also paying for the landlord to make routine repairs and bear the financial risks involved in property ownership. Once you become a homeowner, those hassles and risks fall on your shoulders. When something in the house breaks, you have to either fix it yourself or hire a handyman to do it for you. And if a major appliance like the furnace breaks, you could suddenly find yourself on the hook for major repairs.
The flip side of this is that homeowners have a lot more freedom to customize a home to their liking. If you own your home, you can add a bathroom, remodel the kitchen, or build a back deck.
These kinds of expensive upgrades don't make sense in a rental property. The landlord won't want to pay for them because the next tenant may not be willing to pay extra for them. And tenants won't want to pay for improvements they'll only get to enjoy for a few years. So many renters wind up living in homes they don't love and can't improve. If you're one of them, that's an argument for buying.
One possible downside to owning a home — especially early in your career — is that it limits your economic mobility. Suppose you had gotten a job in the Detroit automobile industry in the early 2000s. If you'd bought a home, you could have wound up in a terrible situation in 2009: Not only could you lose your job, but you could get stuck with a mortgage that was worth more than your home, making it difficult to move to another metropolitan area to get a job.
Some economists see this as a big downside to owning a home. It's good investment practice to diversify: to spread your economic risk around so that one calamity won't wipe you out financially. Buying a home in the same metropolitan area where you work is the opposite of diversification.
Renters face the risk that surging housing demand will cause rents to rise faster than their incomes
However, this argument has limits. For one thing, not all jobs are alike. For example, many government workers enjoy robust civil service protections and don't need to worry that an economic downturn will lead to layoffs. Health-care professionals are less vulnerable to layoffs than most other private sector workers. If you have a secure job and you expect to keep it for many years, then there's little reason to worry about getting underwater with your mortgage — you'll be able to continue living in your home and paying the mortgage regardless of how much it's worth.
Meanwhile, renters face the risk that surging housing demand will cause rents to rise faster than their incomes. If you have a stable job but little prospect for getting raises — or you're retired and on a fixed income — then rising rents could actually be a bigger financial worry than the local economy imploding. Buying a house allows you to hedge against future changes in the housing market, ensuring that you'll be able to afford housing no matter how expensive the rental market gets.
Everyone knows that house prices rose in the aughts and then crashed in the lead-up to the Great Recession. But housing is also a quintessentially local market — you can't just swap a home in San Francisco for one in Detroit.
This great animated map of home values in different areas from HowMuch.net illustrates both how prices changed over time and how they vary from place to place:
HowMuch.net
One thing that really jumps out here is the explosion of the Florida real estate market during the early mid-aughts. The United States has a longstanding divide between more expensive metro areas in the Northeast and Pacific Coast and cheaper ones in the heartland. But Tampa and Miami spend the '90s looking cheap and then suddenly turn very pricey before collapsing.
The flip side of that is that Texas's housing markets were largely insulated from the bubble trend. The Dallas area had an unrelated price explosion in the '80s related to the oil industry, but in the aughts Texans build a lot of new houses and had regulations limiting how much debt they could take on, so things stayed relatively under control there.
When the economy enters a recession, the Federal Reserve normally responds by reducing interest rates to try to stimulate demand for business equipment, houses, cars, and durable goods. When I wrote that the Fed shouldn't raise rates this fall given how benign the inflation rate remains, many people emailed me arguing that the Fed should raise interest rates sooner rather than later because right now rates are at zero, so they can't really be cut. A hike in September or October would give the Fed more ammunition for the next recession.
This is a doubly misguided view. First, it's not true that there's nothing the Fed can do to stimulate the economy with interest rates at zero. Second, even if it were true that the Fed has no other tools, the proposed rate hike wouldn't solve the problem.
It is true that if the Fed raises interest rates this fall, then it has the option of lowering them in the spring if the economy looks weaker. But it is also true that if the Fed doesn't raise interest rates this fall, then it still has the option of deploying zero interest rates in the spring.
The hike-now-to-cut-later proposition is a bit like saying that I should gorge myself on M&Ms this afternoon so that I can lose weight next week by cutting down on snacks. This kind of thing might work as a psychological trick — I smoked more than ever in the three months before I quit smoking — but it doesn't accomplish anything biologically or economically.
Moreover, it's simply not true that there are no stimulative monetary policy measures the Federal Reserve can take when short-term interest rates are already zero.
Policy options include:
Last but by no means least, even though academic economists thought for a long time that it would be impossible to have interest rates that go below zero, this turns out to be empirically false. Academics had thought that because paper money pays a zero percent interest rate (i.e., it's a piece of paper), electronic bank deposits could never pay a lower rate than that, since people would just hold cash instead.
But it turns out that storing gigantic piles of cash in a safe way is expensive and inconvenient, and using giant piles of cash as a payment medium is even more expensive and inconvenient.
You may have heard, for example, that Apple has a $178 billion cash stockpile. This is obviously not an actual pile of physical cash. If he really wanted to, Tim Cook could presumably order the construction of a massive warehouse full of money located in an offshore tax haven. He could hire armed guards to watch over the complex. He could commission a fleet of ships to carry cash around the world to pay Apple's suppliers and collect its revenue. But this would be very expensive. And for all the same reasons that it would be annoying for Apple to conduct business in this manner, Apple's key suppliers and subcontractors would be pretty annoyed if Apple tried to pay them in the form of trucks full of paper money.
Academics are not practically minded people, so this was not really in their minds when they formed the conventional wisdom about the impossibility of negative interest rates. But over the winter of 2014-'15, plenty of European countries experienced negative interest rates, so we know they are possible.
"Higher rates today to cut rates tomorrow" turns out to be a bad solution to a problem that doesn't even exist.
When today's 18-year-old college freshmen were born, the average tuition at a public university was $3,111. At a private university, it was $13,785. Since then, the price of college has risen far faster than inflation: Tuition has tripled at public universities and more than doubled at private universities.
That creates a dilemma for today's parents. It's a safe bet that college will be more expensive by the time their kids get to college. But they don't know how much more expensive, which makes it hard to figure out how much to save.
One way to get a ballpark figure is to assume that college costs will continue increasing at their current rate. It already costs about $60,000 per year to attend a top-tier private college. If college costs keep climbing, that college will cost more than $100,000 per year in 2030. To afford it, the parents of a 3-year-old would need to begin investing about $1,300 per month.
But the way the financial aid system works actually makes the decision a bit simpler for the average parent. That's because you'll come out ahead financially if you max out tax-free retirement savings options before putting any money in a college savings fund. And since the contribution limits on IRA and 401(k) accounts are higher than most people can afford, that means most parents should just focus on saving as much as possible for retirement.


Save for retirement first. Then save early and often for college. (Shutterstock)

The most expensive private colleges now cost more than $60,000 per year. But you shouldn't panic, because most people don't pay close to that amount. After financial aid, the typical family pays $23,550 per year at a private college and $12,830 at a public university.
The most prestigious colleges have financial aid programs that reach well into the upper middle class. Stanford's tuition is free for families making less than $125,000 per year. At Harvard, families making up to $180,000 pay a percentage of their income rather than the full tuition.
Financial aid programs this generous are rare, but financial aid for students even from well-off families is not. About two-thirds of private college students get some kind of financial aid from the college itself, and that includes more than half of students from the wealthiest quartile, those from families with an income of over $106,000 per year. On average, students at nonprofit colleges get about $18,870 per year in grants and tax benefits.
Whether you've saved money for your child's education will obviously affect whether they're eligible for grants based on financial need. Assets saved in the child's name count against their financial aid eligibility more than assets in the parents' names.
But need-based financial aid isn't the only kind — there are also scholarships based on academics, and more nebulous "merit-based aid" that sometimes is just used to attract students to attend one college rather than another.


"I'm so glad we put money in our IRA first." (Shutterstock)

It might seem like you face a difficult choice between saving for your child's education and your own retirement. But almost all financial experts say this isn't actually a tough call: You should save for retirement first. Before you start putting money away for college, make the maximum contributions to your retirement accounts, such as a 401(k) and an individual retirement account.
There are three reasons for this. One is that it's easier to find another way to afford college — grants, loans, or a cheaper option, like transferring from a community college to a four-year university — than it is to support yourself in retirement.
Second, retirement accounts aren't counted when colleges and the federal government figure out eligibility for financial aid. The government expects parents to contribute up to 6 percent of their available assets, including investments, per year to pay for college, but investments in 401(k)s and IRAs are excluded. The additional financial aid application that some colleges expect, the CSS/Financial Aid Profile, also doesn't count retirement assets, although it does ask about them.
But if you're still torn, a retirement vehicle called a Roth IRA allows you to have the best of both worlds: retirement savings that can still be tapped to pay college costs. Each person can contribute up to $5,500 in after-tax money to a Roth IRA. Roth IRA rules allow you to withdraw these contributions — but not any subsequent earnings — without penalty.
Over 18 years, you'll be able to set aside about $100,000 — per parent — that will be available for use, tax- and penalty-free, once your kids reach college age. These funds won't count against your child in financial aid calculations, and if they're not needed for college expenses you can leave them in the Roth IRA until you reach retirement age.
So if you're worried about paying for college, it might make sense to fund a personal Roth IRA before funding an employer-supplied 401(k) account. (But don't skip your 401(k) if your employer is matching contributions — see here for more details.)
Only after you've saved enough to max out both your 401(k) and IRA accounts — about $23,500 per year under current law — should you start contributing to a college-specific savings fund. The best option is generally a tax-advantaged college savings account known as a 529 plan. Contributions aren't tax-deductible, but earnings on the investments grow tax-free and are never taxed if they're used to pay educational expenses.
Anyone — friends, aunts and uncles, and grandparents — can contribute to a 529 for your child. Typically, you can contribute up to $14,000 per year without incurring the federal gift tax; in some cases, you can give up to $70,000 in one year without paying the federal gift tax, because the gift is treated for tax purposes as if it were spread across five years.
That tax advantage might not survive forever, particularly if there's any kind of broad tax reform in the next decade. But the pushback to President Obama's proposal in January to tax 529 plans suggests that they're politically popular enough to stick around.
If you want to figure out how much to save, this calculator, which assumes that college costs will continue to grow at 4 percent per year and you'll get a 6 percent rate of return on your investment, tells you how much you'd need to put away to pay for four years at a college of your choice.
If that's too much uncertainty for you, it's also possible to lock in today's tuition prices through a special type of 529 account known as a prepaid tuition plan. Those plans allow families to pay tuition today to be used years down the road, after their children enroll in college.
Right now, if you live in Virginia, you could buy a semester at the University of Virginia or another in-state public college for a child under 4 years old for $8,100; for a high school freshman, you could buy a semester at UVA for $7,500. Part of that expenditure would be tax-deductible.
Many states have some version of this plan; there's also a prepaid tuition plan available for private colleges. If your child doesn't end up going to a participating state school, it's possible to get a refund and use the money elsewhere.
On Thursday, the National Labor Relations Board issued what observers are already calling its most significant ruling in 35 years. It ruled that the company Browning-Ferris Industries of California is a "joint employer" of workers it hired through a temp agency. The company had contended that the fact that the workers were directly employed by the temp agency, a contractor, meant that it could not be considered their employer for the purpose of unionization. NLRB rejected that reasoning.
Browning-Ferris is not super important as a company. But the NLRB's reasoning opens the door for labor organizing in industries that had previously been resistant. Big franchisers like McDonald's could be targeted. So could big non-unionized government contractors like Booz Allen Hamilton. It's too early to say what the ruling's precise implications will be, but if the ruling holds, they could be massive.
First, some background: waste management firm Browning-Ferris used Leadpoint, a staffing agency, as a subcontractor at a California recycling plant. The Teamsters union organizing the workers argued that Browning-Ferris and Leadpoint were joint employers. Browning-Ferris disagreed, saying they were not the direct employer. The regional NLRB director sided with Browning-Ferris, ruling that its involvement in the lives of these workers was only "routine in nature" and that therefore it was not a joint employer. The national board overruled that judgment.
The Browning decision could be "cataclysmic," according to one attorney
The key question in the case was what makes an employer an employer. The current standard is that a secondary company can be judged a "joint employer" if it has "direct and immediate impact" on the worker's terms and conditions — say, if that second company is involved in hiring and determining pay levels.
In an amicus brief, Meghan Phillips, the counsel for the NLRB general counsel (which is something like a prosecutor's office, and operates separately from the board itself) argued that this should be changed to a much broader definition: "if one of the entities wields sufficient influence over the working conditions of the other entity's employees such that meaningful bargaining could not occur in its absence," then the two entities are joint employers, she says. If you need to be at the table in a labor negotiation, then you're an employer.
While Browning did not directly hire, fire, or set pay levels for the Leadpoint employees, it did determine the facility's hours and when overtime would happen, and it also "closely monitor[ed]" the work that was done in the plant, the AFL-CIO argues in its amicus brief.
"What the union says in Browning-Ferris is, 'Look, we want everybody who controls our terms and conditions of employment at the table,'" says Craig Becker, general counsel at the AFL-CIO and a former NLRB board member.
That standard could mean that many contracting companies and franchisers find themselves designated as joint employers of their contractors' and franchisees' employees.

Could this NLRB decision change life for Walmart workers? (Getty Images)
"The general counsel is trying to say that even if, as employer one, I don't directly tell employees what to do, but in effect I am, through employer two, controlling employees, that makes me joint employer," Barbara Fick, associate professor at Notre Dame Law School and a former NLRB field attorney, told us in December.
Now that the NLRB has agreed with that reasoning, big corporations might start to interact with their subcontractors' or franchisees' workers differently, either fully stepping in and becoming more of a hands-on employer or backing off and trying not to fall under the definition of "joint employer."
labor groups argue that these sorts of working relationships lead to worse conditions and pay
Businesses, of course, are worried about the repercussions of a decision. In a 2014 letter to the NLRB, the International Franchise Association writes that franchises provide "jobs, opportunities, and extraordinarily positive economic results" for the US, and that a decision that extends to franchises would threaten that.
But labor (and the NLRB general counsel) argues that businesses have increasingly used contractors, temp workers, and franchises as means to escape unionization. As Philips writes in the NLRB general counsel's brief:
Some scholars have posited that franchisors consider avoidance of unionization and the collective-bargaining process to be the "prime advantage of franchising," and "[i]n some cases, the driving force behind the conversion of fully integrated, employee-operated businesses to franchised operations is an attempt to prevent or remove the supposedly harmful effects of unionization and thereby increase profits."

The buffer that these sorts of relationships put between larger companies and workers, labor groups also argue, enable worse working conditions, less transparency, and lower pay.
All of this could eventually trickle down to consumers. As Fisk told the New York Times last year, "if labor costs for franchisees go up, then the price of a Big Mac will go up." And it's not just labor prices that might go up — if businesses are now legally liable for what goes on at their franchises, that means insurance will cost more, which could also bump up prices for consumers.

Workers protest at McDonald's in favor of higher wages. (Getty Images)
It's hard to know exactly how many workers could be affected by this decision.  But it could be "cataclysmic," according to Michael Lotito, cochair of the Workplace Policy Institute at Littler Mendelson.
"It has a way of upsetting these business relationships and employers thinking they were separate suddenly finding they are combined," says Lotito. "That has just enormous implications for business relationships."
For example, the NLRB general counsel notes that fast-food chains often provide their franchisees with high-tech scheduling software (sometimes called "just-in-time" software) that uses data and algorithms to determine when workers need to come in and for how long. Though restaurants aren't directly telling workers when to work by using that software, the argument goes that it is indirectly directing scheduling by giving franchisees the software, making it a joint employer of those franchises' employees.
Browning could also affect supply-chain relationships, Lotito says, as some companies create contracts with their suppliers that are restrictive enough that they wind up indirectly dictating the terms of employment at the suppliers' workplaces.
Fick uses Walmart as a hypothetical example: "They're so big they can pretty much control how the people they deal with make their stuff. They wield a lot of influence on the people who are actually doing the business," she says. Walmart's terms in its contracts with its suppliers, she says, can heavily influence pay and benefit levels.
"If Walmart is saying, 'We want 20 gazillion shirts, and we're going to pay you X dollars for it,' well what's the effect of that?"
At the very least, the numbers available suggest that the number of people potentially affected by this decision is growing. The number of franchise employees in the US is growing at 2.3 percent per year, and is currently at around 8.5 million, according to the International Franchise Association. Not only that, but as of November, the number of employees in the temporary help industry was growing at an annual rate of 8.5 percent.
The Browning ruling is the latest in a spate of recent NLRB decisions that have fallen in favor of labor. In 2014, the board made the union election process much speedier (opponents call the new standards the "ambush election" rules) and in a separate case said that employees can organize on workplace email systems. In January 2013, the board ruled that speech on social media is protected speech — in other words, your employer can't ban you from complaining about your working conditions on Twitter.
These actions have angered the business community, causing some to see the Obama-era NLRB as activist.
However, Fick sees a different kind of coherence to these decisions. It's not so much that they're pro-labor as that they're adapting old labor rules to a new world — one in which employees have public conversations about their jobs on Twitter, and also one in which huge corporations increasingly rely on subcontracted or franchise workers.  "As industrial relations change, we have to figure out how to apply the old rules to the new situation," she says.
The board's ruling won't necessarily hold. The case could still be challenged in appeals court, and the pro-business DC Circuit Court of Appeals especially has displayed a willingness to overturn NLRB judgments.
Facebook's biggest problem today is caused and supported by how you consume video — well, you and your family, friends, colleagues, and several of your favorite viral comedians. It's called freebooting, and it might soon rope you in, even though you might never get caught doing it. And if you're the person freebooting? You're enemy number one.
On Thursday, Facebook announced it is expanding its "video matching technology" to a small set of video creators to fight against freebooting. What exactly is freebooting, anyway, and why is it so important to Mark Zuckerberg? It all comes back to you.
How much should Facebook care about other people's problems? It has two philosophical paths to consider. It could turn into a rebellious, freewheeling Napster of video, ignoring the revenue models or copyrights of creators (a position in which YouTube once found itself). Or it could fall in line with wide-ranging demands from video creators who want protection from unauthorized uploads. It's a difficult strategy call for Facebook to make and implement without hiccups, since the platform is home to more than a billion monthly active users.
In the future, video will be even more important than photos —Mark Zuckerberg
People who make money producing online videos want to see their work shared everywhere, especially on the largest social network in the world, right? The short answer is: sometimes. Many creators have voiced frustrations about users who upload videos without permission.
Slate's Will Oremus interviewed one unhappy creator, Destin Sandlin, whose videos were used by others on Facebook:
Two days after he published his tattoo video on YouTube, Sandlin got a message from one of his subscribers who had seen it on Facebook. It turned out his video was a viral smash there, too. In fact, it was spreading even faster on Facebook than it was on YouTube, with more than 18 million views in the first two days alone.
The problem was that Sandlin had never posted it to Facebook, and the version of it that appeared in millions of users’ News Feeds overnight wasn’t his. Rather, a British lads’ magazine calledZoo had apparently downloaded (or "ripped") his video from YouTube, edited it to strip out references to Sandlin and his SmarterEveryDay channel, and posted the edited version on its own page, using Facebook’s native video player. It was an instant sensation, garnering millions of views and a raft of new followers for Zoo’s page. Sandlin, who puts some of the revenue from his YouTube videos toward his kids’ college fund, got nothing. (Zoo’s parent company, Bauer Media, declined to comment for this story.)
Unauthorized uploads are so common on Facebook, it has its own trendy name: freebooting. Last year, Daily Dot's Rob Price called the practice an "epidemic." Let's be clear: Freebooting is explicitly against user rules. Creators are not always aware (or notified) when it happens, though, and infringement can be hard to track down. Facebook scans videos in an effort to limit abuse, lets creators report issues, and suspends repeat offenders, but uploading outlaws remain, aggravating producers.
One particularly unique challenge for Facebook in connecting creators to content is tied to its real-name policy; it can't authenticate content unless it recognizes what users call themselves, which is not always their birth name. Adding to the confusion, amateur video bloggers may not understand all of Facebook's rules, even if they rightfully demand a video is taken down.
Many creators want Facebook to kill freebooting outright, but it's not a simple problem. It will take time for Facebook to come up with a solution that both users and creators mutually accept; there are no guarantees such a solution exists, anyway. In this sense, producers find themselves in a similar position as music record labels were in with Napster, coincidentally co-founded by Sean Parker (Facebook's first president), or even the position Viacom once held against YouTube.
How you share all those cat videos, publicly and privately, will be increasingly monitored on the social network you're most likely to use today.
There's a lot to criticize about how the Chinese government has handled the recent stock market turmoil. Over the past two months, Chinese regulators have banned some executives from selling shares, ordered other companies to buy shares, and provided government funds to finance debt-funded stock speculation. Those steps were only going to make things worse in the long run.
But this week, China's government did something that made sense: It loosened monetary policy. By flooding the economy with cash and lowering interest rates, China's central bank hopes to cushion the economic downtown and hasten a recovery.
Central bankers in the United States and Europe would be well advised to follow China's lead. They can't do exactly what China did because interest rates here and in Europe are already at zero. But the US Federal Reserve and the European Central Bank can and should be doing more to support economic recovery.
The basic job of a central bank like the Federal Reserve is simple. When the economy is weak, the bank boosts economic growth by expanding the money supply. The limit to this strategy is that printing too much money will create inflation. But in general you should try to boost the economy as much as possible without creating an inflation problem.

Right now, most economic data suggests that the Fed has been doing too little to support the economy. Over the past couple of years, the unemployment rate has fallen to 5.3 percent. That's pretty good, but it could be better. The unemployment rate stayed below that level for multiple years during each of the last two expansions. The economy has also been growing at only about 2 percent per year, below the rate of previous expansions.
The Fed is doing too little to support the growth of the American economy
And there's no reason to worry about inflation getting too high. To the contrary, prices rose just 0.2 percent during over the last year, far below the Fed's 2 percent inflation target. That's mostly because energy prices have been dropping, but even if you exclude volatile food and energy prices, the inflation rate is still a too-low 1.8 percent.
Of course, just because inflation is low now doesn't mean it will be forever. But fortunately we can also measure market-based expectations of future inflation by comparing how the market values inflation-adjusted and non-inflation-adjusted bonds. According to this measure, markets expect the average inflation rate over the next decade to be below the Fed's 2 percent target:

<!--
new pym.Parent('vox-10-year-inflation-expectations__graphic', '//apps.voxmedia.com/at-preview/vox-10-year-inflation-expectations/', {xdomain: '.*\.voxmedia\.com'});
// -->
All of these indicators suggest that the Fed is doing too little to support the growth of the American economy.
And things are even worse in Europe. While Germany and a few other countries are enjoying decent unemployment rates, the unemployment rates in Greece and Spain are reminiscent of America's Great Depression. And inflation in the eurozone is an anemic 0.2 percent, suggesting that the European Central Bank could do a lot more to support the economy without worrying about inflation.
Ordinarily, central banks conduct monetary policy by targeting interest rates. When they want to stimulate the economy, they announce that they're going to print more money until short-term interest rates fall to a new, lower level. China did that on Tuesday, cutting a key interest rate to 4.6 percent.
But since the 2008 financial crisis, short-term interest rates in the United States and the eurozone have been close to zero, leaving little room for further rate cuts. That has created a misconception that they can't do more to support economic recovery.
But cutting short-term interest rates is just one way for central banks to boost the economy. Fundamentally, central banks conduct monetary policy by creating new money and using it to buy assets. When a central bank "cuts interest rates," what they're really doing is printing money and buying short-term government bonds with it. That becomes ineffective once short-term interest rates fall to zero. But central banks can always buy other assets.
Cutting short-term interest rates is just one way for central banks to boost the economy
Indeed, that's exactly what the European Central Bank began doing earlier this year: It began buying long-term government bonds in a program called "quantitative easing." The Fed used the same strategy to pull the US economy out of recession from 2008 to 2014. By 2014, the Fed believed it had done enough to get the economy growing again, and it halted the program.
But the last year's economic data suggests that judgment was a mistake. The US economy is still weak, and more stimulus would be helpful. And while the ECB's bond-buying program was a step in the right direction, it's becoming clear that it should be doing more as well.
The fact that China devalued its currency earlier this month and cut interest rates this week provide an additional reason for easier money in the US. A weaker yuan means that Chinese goods are cheaper in world markets, making it harder for US exporters to compete. Looser monetary policy can boost domestic demand, cushioning the blow for US exporters.
The past year has seen slow economic growth and very low inflation, which would ordinarily be seen as signs that monetary policy was too tight. Yet in recent months, the Fed has been debating whether to make monetary policy still tighter, by raising interest rates for the first time in six years.
The reason for this is that despite economic data suggesting monetary policy is too tight, many people believe Fed policy is too loose. Before 2008, it had been decades before interest rates had fallen to zero. And so people believe that six years of zero-percent interest rates must be a sign that monetary policy has been dangerously loose.
But the Fed's hawkish critics are mistaken. Six years of zero-percent interest rates are not necessarily a sign that monetary policy has been too loose. Indeed, if we want to eventually return to a "normal" economic environment of non-zero short-term interest rates, the last thing the Fed should do is raise interest rates now.
One way to see this is to think about the situation in the mid-1970s. Back then, the big economic problem facing US policymakers was high inflation. In an effort to combat this inflation, the Fed raised interest rates as high as 10 percent.
Fed statements about future policy changes can be surprisingly powerful
That was unusually high, and many people thought this meant monetary policy was tight. But they were wrong: Inflation kept going up. It wasn't until Paul Volcker began as Federal Reserve chair in 1979 that the Fed finally got inflation under control. To do it, Volcker had to jack interest rates up to 20 percent.
Today, the US economy is in the opposite situation. Just as 10 percent interest rates in the 1970s wasn't necessarily a sign of tight money, today's historically low zero-percent interest rates aren't necessarily a sign of loose money. If money were really loose, we'd see a booming economy and rising inflation. Instead, growth and inflation have both been low for the last seven years.
Paradoxically, to get interest rates down in the long run, Volcker had to raise them in the short run. Conversely, if the Fed wants to get interest rates up over the next decade, it needs to keep them at zero now. If the Fed raises rates prematurely, it's likely to stall the economy and force another round of rate cutting.
Restarting the quantitative easing program the Fed ended last year would be a big step that could provoke a political backlash. But the Fed can take a smaller, less controversial step to support the economy: announce that it won't be raising interest rates until well into 2016.
Fed statements about future policy changes can be surprisingly powerful, because businesses take future economic forecasts into account when making business decisions. By signaling that interest rates will stay at zero for many more months, the Fed can give businesses more confidence that investments they make today won't be undermined by a 2016 recession. And that can become a self-fulfilling prophecy: Rising business investment itself helps to boost the economy.
Europe's central bank already has a quantitative easing program. The question is whether it should make the program bigger or pledge to continue it for longer. Currently, the ECB has only committed to continuing the program until September 2016. But it could follow the strategy of the Fed's last QE program: Rather than announcing a specific end date, it could pledge to continue the program as long as it took to hit macroeconomic targets such as higher inflation and lower unemployment. It could also increase the size of the program.
In recent years, labor rights groups have campaigned against a common management tactic called on-call scheduling. In an effort to save costs, many retailers require workers to call in just an hour or two before a shift starts to find out if they'll be able to work. That uncertainty can create chaos in workers' finances and personal lives, and it's particularly difficult for workers who need child care.
In a Wednesday blog post, the Gap announced that it is planning to phase out on-call scheduling by the end of September. The move follows earlier announcements by Abercrombie & Fitch and Victoria's Secret, which are also phasing out the practice.
Sonsira Espinal worked for a clothing retailer in New York, and she told me a few weeks ago that on-call shifts were the most frustrating part of her work schedule. "It gets frustrating because you want to work and make money and pay your bills," said Espinal, a member of a workers' rights group called the Retail Action Project. Often, she'd make herself available for a day's work, then be told not to come in.
A new generation of software gives employers the ability to manage their labor costs more precisely than ever before, and this often leads to unpredictable and volatile work schedules.
But the fact that employers can use these techniques doesn't necessarily mean they should. They can save employers money, but they often make lives miserable for low-income workers. And in the long run, treating workers poorly isn't necessarily a good business strategy. Companies such as Costco have figured out how to run a profitable retailer while offering workers stable and predictable schedules.
I asked Anna Haley-Lock, a professor at the school of social work at the University of Wisconsin, how employers set their employees' schedules. She told me that many companies have sophisticated programs that track employee hours in 15-minute increments and help managers make scheduling decisions.
These programs are "value-neutral," meaning they can be used to give workers predictable schedules or erratic ones. But they give managers the ability to manage labor costs in a fine-grained way that might have been challenging in the pre-digital world.
Many companies have sophisticated programs that track employee hours in 15-minute increments
Employers using scheduling software, Haley-Lock says, can "track sales and labor expenditures. If that ratio begins to look labor-heavy, they are eager to reduce the amount of labor expended. They will send people home early and they'll call folks off of shifts."
In larger organizations, managers often feel pressure to do this because they are given strict targets for labor costs. If sales fall short on a particular day, managers have to cut worker hours to hit their targets.
But Haley-Lock says it's not only large companies that have adopted software-based just-in-time scheduling techniques. Small businesses do it too.
For example, Haley-Lock visited a "little private ma-and-pa restaurant in a rural area of Washington state. The owner walked me through with great enthusiasm the Excel spreadsheet he used to track his labor-to-sales ratio. He'd track it on an hourly basis and would use it to send workers home."

(Nicholas Eckhart)
The trend toward using computers to more tightly manage workers' schedules parallels the trend of just-in-time manufacturing. In the past couple of decades, manufacturers have used sophisticated software to slash inventories and order new parts at the last minute. This not only cuts down on warehousing costs, it also makes the whole production process more nimble, because manufacturers can switch to new and improved components as soon as they're available.
Many employers have tried to apply this nimble, waste-conscious attitude toward their workforces. But there's an important difference: Parts in a warehouse don't have personal lives. Workers do. When a company takes principles developed for supply chains and applies them to its labor force, the result can be chaos for workers.
"You’re waiting on your job to control your life," Jannette Navarro, a Starbucks employee in San Diego, told the New York Times last year. She found out each week's schedule just three days ahead of time, and she said that Starbucks software often determined everything from how much sleep her son would get to "what groceries I’ll be able to buy this month." (Starbucks changed its scheduling policies after the Times article was published.)
Erratic shifts that vary from week to week make workers' schedules challenging enough. On-call shifts make things even worse. If the employer cancels a shift, the worker generally gets no pay — and might still be on the hook for child care expenses.
The use of on-call shifts, and variable schedules more generally, also creates a lot of uncertainty about workers' incomes from week to week. If business is slow for several weeks in a row, workers can wind up not making enough money to pay the rent. Espinal, the New York retail worker, says there were some parts of the year, such as after the holidays, when she could go days without getting a single shift.
In a closely related practice, some employers will respond to unexpected demand by calling workers at the last minute and asking them to work unscheduled shifts. Espinal said that during the holidays she would be asked to stay on for extra hours at the end of her shift. That made it hard to have a social life, because she couldn't make plans with friends after work. "You can't really plan ahead or map out your day or week," she says.
If the employer cancels a shift, the worker generally gets no pay
The prevalence of on-call shifts and last-minute call-ins make it hard for workers to earn extra income by taking two jobs. It's becoming common for retail stores and restaurants to build large rosters of employees, giving many employees less than 30 hours of work per week. That wouldn't be so bad if employees had predictable schedules and could supplement their earnings with a second part-time job. But if workers don't have control over the schedules — and don't know if they'll be working until just hours ahead of time — it can be hard to find time for the second job, to say nothing of personal responsibilities.
In this respect, a restaurant or retail establishment with "flexible" hours is the opposite of ride-hailing services like Uber and Lyft. Both types of employment involve irregular hours, but with Uber and Lyft, the drivers decide when and how long to work. They never have to worry about being unable to get the hours they want.
You might think labor law would provide workers with some protections against erratic schedules, but that's generally not the case.
"From an employment law perspective, scheduling is pretty much unregulated," says Charlotte Alexander, a legal scholar at Georgia State University. Indeed, most worker protections related to scheduling take the existence of a schedule for granted.
For example, if a worker reports for his scheduled shift and then is sent home without pay, some states require the worker to be paid a minimum amount — usually between two and four hours of work. But if an employer simply refuses to make a schedule until shortly before a shift starts, these laws don't apply.
Indeed, Alexander worries that beefing up some of the existing worker protections, which take schedules as a given, will push employers toward abandoning schedules altogether, relying instead on a fully on-demand model in which workers don't learn if they have work until the last minute. "I would be afraid about nudging employers any closer to an all-contractor, all-temp world than they're already going," she says.
Instead, Alexander argues, the law should directly regulate scheduling. For example, the law might require employers to provide employees with their schedules a minimum number of days ahead of time. Employers that failed to provide sufficient notice — or who canceled shifts at the last moment — would be required to pay workers extra to compensate them for the inconvenience.

(Mike Mozart)
While just-in-time scheduling techniques have become increasingly common, Haley-Lock stresses that they're not universal. And she argues that companies can turn a profit while providing their employees with predictable schedules and adequate notice of their work hours.
A good example is Costco, a discount retailer that puts a premium on treating its employees well. Haley-Lock and University of Chicago scholar Susan Lambert recently did an in-depth study of Costco's labor practices. With Costco's cooperation, they interviewed managers at a number of Costco locations in Illinois and Washington State. And they found that Costco workers do not suffer from the kind of scheduling instability many other retail workers do.
"Costco is as concerned about profit as the next competitor," Haley-Lock says. "But they think about work hours differently and how they handle and allocate work hours very differently."
She says that Costco "ties their own hands" by guaranteeing full-time workers 38 hours per week and part-time workers 24 hours. Rather than forcing workers to leave early, the company will ask for volunteers — and if no one volunteers, no one will get sent home.
Having a company-wide policy in place protecting workers against unstable work hours changes managers' incentives. Rather than sending workers home at the first sign that business is slow, managers have to look for ways to keep workers busy through the end of their shifts.
In a market as competitive as the restaurant and retail industries, employers can benefit from treating their workers better
One way they do this is by training workers to be proficient in multiple parts of the store, Haley-Lock says. That's valuable on days when demand is high in one part of the store and low in another. Rather than sending someone home in one department and calling in a different person in another — as other retailers might — Costco will transfer a suitably trained worker to the understaffed section of the store.
And, of course, treating employees well makes them less likely to quit, which can reduce recruitment and training costs.
Other employers have had similar experiences. Haley-Lock tells the story of two restaurants — one an upscale "fast casual" restaurant, the other a "cheap family dining" restaurant. The manager of the family dining restaurant told her, "I often lose people who go across the street to the place that pays a little more an hour." However, he said, "then I get them back because they don't get the hours" at the higher-paying restaurant.
Workers don't have much bargaining power individually, but in a market as competitive as the restaurant and retail industries, employers can still benefit from treating their workers better. Employee turnover is a major cost for low-wage employers, and overly aggressive use of just-in-time scheduling techniques might wind up costing more than it saves once recruitment and training costs are taken into account. Restaurants and stores that offer their employees predictable shifts may be able to pay a bit less, and they're likely to hold on to each employee for longer.
Scheduling software can obscure this reality. It can provide short-term "savings" that don't actually save much money because they increase employee dissatisfaction in the long run. Over time, employers may learn to use scheduling software to more precisely manage demand, while avoiding the excesses that make employees miserable.
Correction: An early version of this article suggested that work hour instability was increasing. However, the evidence for this is weak, so I've removed the claim.
China's stock market has been crashing this summer, which is both a sign of and potentially a cause of underlying economic problems in the country. Those problems have also led to a reduction in the value of China's currency. This instability has roiled global financial markets more generally, but Apple — America's largest company — has been hit especially hard, losing 18 percent of its value over the past six months and wiping out many tens of billions of dollars of paper wealth.
The situation got so bad that Apple CEO Tim Cook recently took the extraordinary step of emailing CNBC anchor Jim Cramer to try to intervene in the stock slide, assuring investors that "growth in iPhone activations has actually accelerated over the past few weeks, and we have had the best performance of the year for the App Store in China during the last 2 weeks." The reassurance did at least some good in halting the slide, though Apple shares are still far from making up their losses.
Apple has an unusually heavy exposure to problems in the Chinese economy for reasons that aren't addressed by Cook's letter.
The basic issue is that Apple doesn't like to change its retail prices in response to currency fluctuations. So when a foreign currency declines in value relative to the dollar, the number of dollars Apple earns per sale goes down. Conversely, foreign currency appreciation means Apple is earning more dollars.
Last quarter, 27 percent of all Apple's revenue came from Greater China. More importantly, more than 50 percent of Apple's revenue growth came from China.
Even if Apple's sales — in terms of number of units — hold up, the value of those sales is going to decline at a time when the company was counting on rapid growth to help offset the essentially inevitable slowdown of iPhone sales in the already highly saturated US market.
Apple rather famously relies on Chinese suppliers and assembly facilities, so you might think a falling yuan would saving Apple money. But most of Apple's key contracts with suppliers like Foxconn and Lenovo are denominated in dollars, meaning the suppliers themselves may see a benefit from lower costs but Apple will not.
So Apple is paying Chinese companies dollars to assemble phones that are then sold to Chinese consumers for yuan. When the value of the yuan goes down relative to the dollar, that's not going to be good for Apple's profits.
Oftentimes large companies that are exposed to different kinds of currency risk will try to hedge that risk by buying derivatives. For example, if a more expensive Japanese yen is good for Apple's profitability but a cheaper yen is bad, a company might offset that by placing a speculative bet that the yen will decline in value. That way, any yen-specific changes will be offset, and the success of Apple's Japan operation will be driven by how much Japanese people like iPhones.
The problem is that China's tightly regulated financial markets make hedging difficult and at times expensive.
This seems to be one of the reasons Apple is borrowing a huge number of Australian dollars. Australia exports enormous quantities of raw material to China, so bad economic news from China tends to lead to a declining price of Australian dollars. So-called kangaroo bonds are thus a kind of back-door hedge against Chinese currency risk. But even the best hedging strategy can't bring back the kind of staggering growth opportunity that led to Apple's China revenue more than doubling over the past year.
You've probably heard a lot about trade with China over the years, but it's important to understand that Apple is fairly unusual in terms of relying heavily on Chinese customers. The United States as a whole sells way more stuff to Canada and Mexico than to China and lots of prominent technology companies in particular — Google, Facebook, Twitter — barely even exist in China due to censorship.
But America does buy lots of stuff that is made in China, and while Apple's supplier contracts are structured in a way that doesn't let them take advantage of lower production costs, that's not true for every company. Apple isn't alone in the China boat — airplane manufacturer Boeing is also exposed to the Chinese economy, though its sales are priced in dollars — but it's not a very crowded ship.
China's benchmark Shanghai Composite index fell 1.2 percent on Wednesday, the fifth straight day of losses. Here are 11 charts that show some of the economic forces driving China's stock market turbulence.

(Javier Zarracina/Vox)

Between June 2014 and June 2015, China's Shanghai Composite index rose about 150 percent, reaching a high of 5,166 on June 12. Then the bottom fell out of the market. In less than a month, it fell to 3,507 — a 32 percent decline.
A series of extraordinary interventions by the Chinese government helped stabilize the market and push it back up to 4,000. But the reprieve was short-lived. Over the last five days, the market has lost more than 20 percent of its value; the Shanghai Composite closed at 2,927 on Wednesday.

(Financial Times)
This chart from the Financial Times shows some of the key developments of the past two months. It also points to one possible trigger of the current market rout: a decision by the Chinese Securities Finance Corporation to stop injecting funds into the stock market.
China's central bank had used the CSFC as a conduit to help Chinese people buy stocks with borrowed funds, helping to prop up stock market prices. The authorities probably hoped that after a month of doing this, the stock market had stabilized enough to make further support unnecessary. The market, however, had other ideas.

(Visual Capitalist)
One sign that China's government was worried about its slowing economy was a decision to devalue its currency. Since 2009, rapid growth in the Chinese economy has pushed the value of the yuan up relative to the dollar. But then the slowing Chinese economy started to push the yuan downward.
China's central bank intervened in foreign currency markets to maintain the yuan's value, but on August 11 it decided to let the currency drop by about 3 percent. In theory, this should have provided a boost to the Chinese economy by making Chinese exports more affordable to foreigners. But this wasn't enough to prevent further declines in the stock market.


(Javier Zarracina/Vox)

China's official inflation-adjusted growth rate in 2014 was 7.4 percent, and the economy grew by 7 percent in the first quarter of 2015. If the United States grew at a 7 percent annual rate, it would be considered a huge accomplishment.
But even after two decades of rapid economic growth, China is a lot poorer than the United States. China needs to continue growing rapidly for a couple more decades to catch up to the developed world — and maintain the legitimacy of China's authoritarian political system. The Chinese economy grew at around 10 percent for years for much of the 2000s. So growing at "only" 7 percent a year is seen as a disappointment.
It's worth taking official Chinese economic figures like these with a grain of salt, since even some Chinese officials have privately admitted that they're unreliable. That might explain why we've seen so little volatility in the official figures in the past few years.


(MarketWatch)

From 2005 to 2007, China's benchmark stock index, the Shanghai Composite, grew sixfold, from 1,000 to 6,000. Then the market crashed, falling below 2,000 by the end of 2008.
The cause of this earlier boom-and-bust cycle was obvious: The Chinese economy was growing extremely rapidly in the mid-2000s, so stocks went up. Then the global economy started to implode, so Chinese stocks crashed along with stocks everywhere else.
The latest boom, which started in June 2014, is different. It didn't coincide with particularly strong economic growth — the economy actually grew more slowly in 2014 than in 2013 or 2012.


(Bloomberg)
In the past couple of years, Chinese regulators have relaxed strict limits on buying stocks with borrowed money. As a result, the volume of "margin trading," as it's known, has soared. By the time the stock market reached its peak in June, people had bought 2.2 trillion yuan ($350 billion) of mainland stocks with borrowed money.
And this figure likely understates the role of borrowed money in China's latest stock market boom. Because in addition to officially sanctioned margin trading, Chinese investors have found a variety of ways to covertly invest borrowed money — perhaps another 2 trillion yuan ($320 billion) — in the stock market.

(Javier Zarracina/Vox, based on Macquarie Research, via Bloomberg)
A good way to gauge the significance of margin trading is by comparing it with "free float." This term refers to shares that are available for public trading — as opposed to stock that's locked up by corporate executives, the government, or others.
When margin debt is large compared with free float, it's a sign that borrowing is having a big impact on stock prices. In the past, strict regulations on margin trading meant that China had much less margin debt than other countries. But in the past couple of years, margin debt has skyrocketed. Today, margin debt is much larger, relative to the overall size of the stock market, in China than in the US or Japan.
<picture class="c-picture" data-cid="site/picture_element-1500894433_4847_43646" data-cdata='{"picture":true,"dynamic_picture":false,"convert_picture":false}'>

  

  

  <img srcset="https://cdn.vox-cdn.com/thumbor/eao03DWz71dqTW4lkzHWAFrk6fg=/0x0:858x623/320x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 320w, https://cdn.vox-cdn.com/thumbor/nZmglqF_D2nIjFtlmM102OyKnX4=/0x0:858x623/520x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 520w, https://cdn.vox-cdn.com/thumbor/OhbCi4Zcmc8ocw2XSbWLqT8vAAA=/0x0:858x623/720x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 720w, https://cdn.vox-cdn.com/thumbor/VW_dBBNEu-GvXOCUxfV27TFXU4c=/0x0:858x623/920x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 920w, https://cdn.vox-cdn.com/thumbor/O0Fx-FZxoyh5YdUYT0mD3P-ieHM=/0x0:858x623/1120x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 1120w, https://cdn.vox-cdn.com/thumbor/oLj9HHT3hwzw_dxjHUaJ0h7chPQ=/0x0:858x623/1320x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 1320w, https://cdn.vox-cdn.com/thumbor/oDfT6yEPct4BQ78sBA1NL3knbLk=/0x0:858x623/1520x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 1520w, https://cdn.vox-cdn.com/thumbor/juoEEC11J5IVmGE7zdpW4Dt9t_w=/0x0:858x623/1720x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 1720w, https://cdn.vox-cdn.com/thumbor/bLuoiazU0_YA6_A1T4KCCUufkkg=/0x0:858x623/1920x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif 1920w" sizes="(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw" src="https://cdn.vox-cdn.com/thumbor/nSGyMFDxxSTx2GcbV3JHHoqE6nY=/0x0:858x623/1200x0/filters:focal(0x0:858x623):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3855992/pic7c106a7fb514f374def5831d10b2c742.0.gif">

</picture>

(Mark J. Lundeen)

It's not unusual for stock market booms to be fueled by borrowing. Indeed, borrowing played a prominent role in one of the most famous stock market bubbles — and subsequent crashes — in history: America's in the late 1920s.
America in the 1920s, like China today, had a workforce that was rapidly becoming more educated and urbanized. This was when stock trading first became a mainstream phenomenon, and when ordinary people discovered the idea of trading stocks with borrowed money. The result: a huge stock market boom between 1926 and 1929, followed by a stock market crash and the worst economic downturn in American history.

(Javier Zarracina/Vox, based on a chart by KKR and data from China Securities Depository and Clearing Corporations and Bloomberg)
This chart shows the number of stock trading accounts that have been opened in China over the past decades. As you can see, there was a big jump in new accounts as the stock market jumped in 2006 and 2007.
But in late 2014 and early 2015 China saw a much bigger surge in new accounts being opened. More than 40 million accounts were opened between June 2014 and May 2015. In total, there are now more stock traders in China — 90 million — than members of the Communist Party.
This helps explain why China's leaders are panicking over the stock market's decline. A stock market crash will not only affect those 90 million people, it will affect their friends, family, and neighbors, and could trigger widespread anger at the government.


(IMF)

Recent years have seen the growth of wealth management products in China. Originally these financial products were akin to money market funds in the United States, investing in relatively safe assets and offering Chinese savers a higher return than they could get with a traditional savings account.
But as the WMP market has gotten more competitive, banks have faced pressure to boost returns. This chart shows the result. Not only are there a lot more WMPs being sold than five years ago, but banks are offering their customers higher returns. In 2010, most WMPs offered returns of less than 3 percent. Today, most return 5 percent or more.
But to achieve these higher returns, banks have been doing riskier things with WMP funds. They've loaned them to real estate developers or others engaged in risky projects. They've used them to invest in stocks directly. And in some cases, they've effectively loaned the funds to others who want to invest in the stock market.
If the economy does well, this kind of gamble can work out fine. But as stocks fall and the Chinese economy falters, there's a danger that WMP investors will start losing their money. And that's a problem because many consumers believed WMPs were safe investments akin to a savings account. They're not going to be happy if these supposedly safe investments start producing losses.


(Yan Liang, based on IMF data)

This practice of making investments with borrowed money is known as leverage, and it's not just individual Chinese investors who are doing it. Trusts are a bit like American investment banks or private equity funds: They provide investment opportunities for wealthy clients. And in recent years, they've become a popular way for those clients to evade limits on buying stocks with borrowed funds.
This chart from Willamette University economist Yan Liang compares trusts' equity — the value held by the firms' shareholders — to the total value of their "assets under management." When this ratio is high, it means that the firms are investing with borrowed funds, making them highly vulnerable to market volatility. Liang calls a ratio of 40 to 1 "dangerously high," because a small decline in asset values can wipe out the owners' equity.
This kind of thing was a major factor behind the US financial crisis in 2008: US investment banks became highly leveraged, leaving them with little margin for error when the housing market imploded.

(Javier Zarracina/Vox)
Between June 2014 and June 2015, China's Shanghai Composite index rose by 150 percent. A big reason for the stock market rally was that a lot of ordinary Chinese people began investing in the stock market for the first time. More than 40 million new stock accounts were opened between June 2014 and May 2015.

And many have been buying stocks with borrowed money. The Chinese government used to strictly limit this practice, but over the past five years the government has gradually relaxed those regulations.
Earlier this year, the authorities became concerned that the stock market's rise had become unsustainable. So they began to tighten limits on debt-financed stock market speculation. The stock market peaked in June and then began to fall quickly.
By early July, the market was in free fall, and the Chinese government began to panic. Authorities took a number of steps to push stock prices back up:
Those efforts seemed to work for a few weeks. The Shanghai Composite rose from the July 8 low of 3,507 and seemed more stable. But that proved to be a temporary reprieve. Last week, the market began to plunge again.
Once again, China tried to prop up the stock market, announcing that a major state pension fund will be allowed to invest in stocks for the first time. But the market was unimpressed with the announcement.
According to the Financial Times, Chinese authorities finally concluded this week that propping up the stock market would be too expensive. The government spent more than $200 billion buying Chinese stocks since early July, and faced the prospect of continuing to spend at that rate indefinitely to keep the market from crashing.
No government likes to see its stock market crash, but the plunging Shanghai Composite will be particularly embarrassing for the Chinese authorities. Positive coverage from state-run media helped fuel last year's stock market boom, and last month's decision to intervene in the stock market tied the government's prestige even more tightly to the market's performance.
The broader Chinese economy isn't doing very well either. Official figures show the Chinese economy growing at a 7 percent rate in the second quarter. That's slow by Chinese standards, and many Western economists suggest that the official figures overstate China's growth.
Weak Chinese growth has exerted downward pressure on China's currency. The Chinese central bank allowed the currency to fall by 3 percent earlier this month.
For the past two decades, China has benefited from an export-oriented growth strategy. But exports can't power China's growth forever — world markets just aren't big enough. So China needs to transition to an economy that's powered more by domestic consumption. And as Vox's Max Fisher has written, the economic reforms required to facilitate that won't be easy.
The good people at Google Trends put together a map showing the most-searched-for stock index in each country. It's a bit of an odd thing to research, but it shows some pretty interesting aspects of our financial universe.

There are a handful of countries whose own local stock exchange is the most important one. Then there's another handful of countries that follow the German or French or even Spanish stock market. Then there's the huge dark green sea of countries where people follow America's Dow Jones Industrial Average, the clear global kind of stock indexes.
In terms of global influence, the No. 2 stock index in the world isn't something out of Tokyo or Shanghai — it's Germany's DAX. The German economy is smaller than China's or Japan's, but it's more tied in to cross-border trade, and it's the most-searched-for index in Finland, Turkey, several small central European countries, Namibia, and even Uzbekistan.
Fussy pedants (like yours truly) don't really like to cite the Dow since it's constructed with an unsound methodology and the S&P 500 index is just sitting there ready to measure the same thing (the performance of big US-listed companies) in a much better way. This map shows that a lot of people agree with me about this in Estonia. And nowhere else. Well, Estonia is great!
The UK's FTSE 100 index is more significant than France's CAC 30 by most measures I can think of, but the French stock market seems to have had more staying power in France's former African colonies than the FTSE has in the old British Empire.
Countries like Italy and Brazil have their national stock indexes relegated to "other" status on this map, while tiny Denmark gets an attractive light purple shade. Why? Well, because the Danish stock exchange is important in Greenland, and Mercator Projection maps make Greenland look enormous.
Strange but apparently true.
Stock markets around the world plunged on Monday. The carnage began with an 8.5 percent drop in China's benchmark Shanghai Composite index. Markets in Japan, South Korea, and Australia followed suit. That sparked selloffs in European markets and then the United States. The Standard and Poor's index of 500 large US stocks fell by nearly 4 percent on Monday, adding to losses last week.
The media did not take the news calmly. CNN's homepage was fairly representative:
Get your guns, get your ammo.
There were some real reasons for investors to worry about the future of the global economy.
In the United States, six years of gains have produced prices that some experts believe are unsustainable. China's economy is slowing down, which could produce not only economic hardship but also political challenges for the Chinese government. And much of Europe is still struggling to emerge from the last economic downturn; more market turbulence is the last thing it needs.
In other words, several of the world's major drivers of economic demand face problems ahead. And if they all crack up simultaneously, that would be a bad thing.
But it's also possible that this week's stock market turbulence won't have much broader significance. Sometimes traders panic over what looks like bad economic news, but then world economies wind up doing fine.
The US stock market is down about 10 percent from its highs earlier this summer. That's a significant drop, but it looks less significant when you consider the larger picture. That's because the US stock market has enjoyed a huge boom over the past six years. Even after Monday's fall, the Standard and Poor's 500 index is 170 percent above the low point of the 2009 stock market crash, and 20 percent above the previous stock market peak in 2007.
Google Finance
Has the market gone too high? One way to judge this is to compare companies' stock prices with their profits. This ratio, known as the price-to-earnings ratio, has historically been a pretty good indicator of whether the market is over- or undervalued. And right now, it's significantly higher than the historical average:

Price-to-earnings ratio based on 10 years of earnings.
multpl.com, with data from Robert Shiller
At the start of 2015, the P/E ratio was around 26. That's almost as high as the peak of the 1929 stock market bubble, and higher than at any point between 1930 and 1990. If a high P/E ratio is an indicator that the market is overvalued, then this chart should make stockholders very nervous.
The counterargument, however, is that P/E ratios are affected by interest rates. When interest rates are low, people are willing to pay more for stocks in order to boost their returns. When interest rates are high — as in the late 1970s and early 1980s — stock prices tend to fall, since people can get high returns without taking the risk of owning volatile stocks.
So whether you believe stocks are overvalued depends a lot on what you think will happen to interest rates. If interest rates rise quickly in the next few years, stock prices could fall a lot further. On the other hand, if interest rates stay low, stocks could stay high for a long time.
For the past 25 years, the Chinese economy has delivered impressive economic growth. Where the US economy has grown by 2 or 3 percent per year, China has grown by 7 to 10 percent annually. That growth was facilitated by an export-oriented development strategy that put Chinese people to work making products for international companies.
The strategy has been successful so far, but it also has inherent limits. There's only so much global demand for this kind of work, and as China's living standards rise, it will become harder to compete with other low-wage countries.
So to continue growing, China needs to diversify its economy. Chinese companies need to produce more goods and services for domestic consumption rather than for export. And they need to become better at designing and marketing new products, rather than just manufacturing them.
To continue growing, China needs to diversify its economy
But the Chinese economy isn't set up for this kind of internally driven growth. A big share of China's economy is controlled by bureaucratic and perpetually money-losing state-owned enterprises. These companies are insulated from market forces, and as a result they often make production decisions based on political rather than commercial considerations.
Over the last year, there have been growing signs that the Chinese economy is slowing. The official growth rate is 7 percent over the past year, but it's widely suspected that this figure is inflated. Even some Chinese officials have privately admitted that Chinese economic growth figures are unreliable.
Javier Zarracina/Vox
Javier Zarracina/Vox
In mid-2014, China's stock market began to boom despite the country's increasingly gloomy economic outlook. One reason was that the government relaxed regulations designed to prevent ordinary investors from buying stocks with borrowed money. By early 2015, they became concerned that stocks had become overvalued and began tapping the brakes, which triggered the stock market decline that began in June 2015.
In July, China took a number of drastic measures to try to stop the market's fall. In the process, the government tied its own prestige more tightly to the stock market. That made it particularly embarrassing when stocks began to fall again last week.
The real danger for the government isn't just that China will fall into a recession. It's that a plunging stock market and economic downturn will shake public confidence in China's political institutions more generally. The Chinese government has made rapid economic growth a central part of its bargain with the Chinese people. If that growth falters, it could do real damage to the government's legitimacy.
The Chinese economy is big, but it's not so big that a faltering Chinese economy necessarily spells doom for developed economies in the West. For example, exports to China accounted for less than 1 percent of US economic output in 2012.
But there are two reasons that a declining Chinese economy would be bad news for publicly traded companies in the United States and Europe.
One is that many Western countries are still suffering an economic hangover from the 2008 financial crisis. Ordinarily, central banks fight recessions by cutting interest rates. But in both the United States and the Eurozone, short-term interest rates have already  fallen to zero, making these techniques ineffective.
Central banks' other option, known as "quantitative easing," was controversial, and so the Federal Reserve and the European Central Bank used it sparingly. The result: a sluggish recovery in the United States, and even worse results in some parts of Europe, where unemployment is still in the double digits. And that economic sluggishness — and central banks' reluctance to use unconventional techniques to boost the economy — makes them particularly susceptible to declining exports.
Second, the companies listed in American and European stock markets are disproportionately multinational firms that do a significant amount of business in China. For example, about a quarter of Apple's revenue comes from China, so an economic downturn in China is a big deal for the largest American stock.
When the stock market crashes, pundits have a natural inclination to paint it as a sign of broader economic trends. And it's possible that Monday's stock market turmoil will — like stock market declines in 2000 and 2007 — turn out to be the first tremors of a bigger economic earthquake.
But sometimes traders panic for no good reason. For example, the stock market fell by more than 20 percent on October 19, 1987. And after that, the American economy was totally fine. The economy kept growing. The stock market recovered its losses in less than two years, and went on to produce the bull market of the 1990s.
This week's stock market turbulence could turn out to be a lot like that — a source of stress for traders in the world's stock markets, but not necessarily a sign that larger economic problems are looming.
Javier Zarracina/Vox
Javier Zarracina/Vox

(Javier Zarracina/Vox)

On Monday, the stock market posted its largest decline in years, sparking fear that the US is on the verge of another recession. After initially plunging 6.4 percent in a matter of minutes, it recovered some ground and ended the day down 3.6 percent.
Vox graphics guru Javier Zarracina created this chart to illustrate how Monday's crash compares with other major stock market declines over the past three decades. Here are the biggest stock market declines since the 1980s:
So sometimes a big stock market decline is a sign of deeper economic problems. Other times, it's not. It's too early to say which category Monday's crash is in.
Correction: I originally stated that the Great Recession occurred after the 2008 stock market crashes, but it began in 2007.
As the US stock market heads into what looks to be its worst month in more than five years, the big question for the average person's life is this: Are we watching a replay of 2008 or a replay of 1987? If it's the former, you should freak out. If it's the latter, you just need to hold tight.
It could be really bad, or it could be not so bad. But here's what we do know: The price of stocks declining is unlikely to be the cause of bad things in your life. If it's bad news, it's bad news simply because stock markets offer a fast and highly visible window into economic conditions.
It's unlikely that anybody lost their job during the Great Recession because the price of stocks fell. Some people probably lost jobs because of the falling price of commodities (food, oil, metal, and other raw materials), because lower prices mean less incentive to produce more. But then again, falling commodity prices are good for most people and sometimes provide the economy with a boost.
Nonetheless, the large decline in stock prices that happened in the fall of 2008 was bad news for the vast majority of Americans.
That's because the crash was, in effect, a warning sign that was ignored. Financial markets were signaling an expectation that the outlook for business profits was getting much worse. Commodity prices were signaling an expectation that overall levels of demand would plunge. These dire predictions proved to be 100 percent accurate. It takes weeks and even months for all the relevant data about the performance of the real economy to pile up. But stock markets can move really quickly. Bad things were happening.
Twenty years earlier, though, a similarly dramatic collapse in stock prices had a very different result. Here's how it looked in the heat of the market panic:
But there was no late-Reagan-era recession. No global economic catastrophe. Instead, it looks in retrospect like investors just panicked for no good reason. Or maybe that they had good reason, but then Alan Greenspan moved swiftly to nip it in the bud. Either way, the downturn actually lasted quite a while even though nothing special was happening in the real economy.
Eventually, stocks went back up. After all, nothing bad was going on, so why shouldn't they have?
The August stock slide is a clear sign that investors are worried about corporate America's performance outlook, and since plenty of people work for big American companies, that's reason to be concerned. But not too concerned.
There's no particular reason that cheaper stock prices should cause anything bad to happen to the vast majority of people. A sharp decline in house prices has a huge impact on the real economy because middle-class Americans have so much of their net wealth tied up in houses they bought with borrowed money. The stock market isn't like that. Shares are mostly owned by rich people, and middle-class Americans don't borrow money to buy stocks.
Similarly, though the weak Chinese economy is definitely bad news for Apple and a handful of other American companies with lots of Chinese customers, US exports to China are not that big of a deal overall. Meanwhile, the falling price of oil helps the US trade balance and puts money into the pockets of most people.
So there's a great chance that everything will be fine. But policymakers at the Federal Reserve — and, were it actually a functioning policymaking body, the US Congress — ought to be vigilant. US stocks in decline could be an early sign of some more profound weakness. On Thursday, the Commerce Department will report on second-quarter GDP, and on Friday it will tell us about personal income in July. We'll also get data this week about initial unemployment claims. A stock market decline doesn't necessarily mean anything terrible for the real economy, but it is important context with which to read those reports when they're out.
It's easy to freak out over the US stock market crash when you see a CNN front page like this:
(CNN)
Get your guns, get your ammo.
And it is true that global stock markets have had a rough morning. The Dow fell 1,000 points in its first four minutes of trading Monday morning (although it has recovered a good deal since). Still, when you put that drop into context — as economist Justin Wolfers does — you realize that the drop pales in comparison to all the gains the market has made over the past decade.

The stock market plunge, in perspective. (10-year chart.) pic.twitter.com/M30thHhkrv


So, as the CNN homepage warns (in tiny font that you probably missed the first time): Don't panic. Definitely don't sell off your stocks. Perhaps visit this website. And remember that markets go up and down, and that in the decade-long scheme of things the market still has seen relatively robust growth.
As I entered a 10 o'clock meeting this morning, every metrics dashboard available suggested huge levels of reader engagement with headlines about the Dow's eye-popping thousand-point drop that took place within minutes of the opening bell. The headlines were so juicy and so clicky that even the New York Times felt the need to still be using one at 10:27 am, by which time it was no longer even remotely true that the Dow was down 1,000 points (the market had regained 700 points at that point).
The extreme yo-yo of the index was striking (thrilling, even, to a certain frame of mind) but also easily explicable by technical factors that should have cautioned everyone against alarm.
The key fact about trading early in the morning on any given Monday is that the stock market has been closed since Friday afternoon.
But that doesn't mean nobody has formed opinions about investment strategy in the interim. Money managers, hedge funds, and run-of-the-mill shareholders don't stop thinking about their money just because it's a Sunday. With no trading happening on the market, people trade "futures" instead. When the market opens, all those futures orders need to be filled. Normally nothing especially dramatic happens in the futures market, but that wasn't the case this weekend.
Dow and S&P 500 futures both hit daily limit-down http://t.co/skNkUh3mYL pic.twitter.com/er4FSJpTQU

Starting at about 9 pm Eastern time on Sunday, futures contracts for American shares traded steadily lower. Eventually they reached the limit for how low they are allowed to go before trading is halted. That froze market sentiment in time until the opening bell rang, and all those pessimistic moves made overnight had be fulfilled very rapidly. Hence the 1,000-point plunge in minutes. It's not that anything in particular happened during those four minutes, it's just that changes in sentiment that had played out over hours got officially recorded very suddenly.
Since futures trading had been frozen at a very pessimistic moment, there was no way for more measured takes to be priced in until the formal opening. That's why the decline quickly moderated once things were up and running. Bottom line: The decline in stock prices this August has been large, but we're far from any eye-popping, record-setting moments.
On Friday, August 21, American stock markets had a really bad day with the broad S&P 500 index (roughly the 500 biggest companies listed on US stock markets) losing well over 3 percent of its value — a plunge that was followed by further declines over the weekend and on Monday morning.
The fall, though certainly large, was by no means catastrophic by historical standards. But it is having an outsize psychological impact on stock owners because it comes in the context of what's been an overall very "meh" 2015 for stocks. And it was followed by derivatives trading on Sunday night and Monday morning that indicates further declines are in store.

Dow and S&P 500 futures both hit daily limit-down http://t.co/skNkUh3mYL pic.twitter.com/er4FSJpTQU
Both the real economy and the stock market crashed from the fall of 2007 all the way through to the spring of 2009. But while economic growth since that time has been generally disappointing, the stock market has soared.
In 2015, though, that pattern has broken down.
The economy continues to add jobs at a slow but steady pace, but the S&P index started the year at 2,058 on January 2 and was at 2,060 as of early Thursday morning — dead in the water. In that context, the sudden decline on Friday feels to many like a bad portent, a clear signal that a years-long bull market is over and now the bears are running the show.
It's a huge deal for investment professionals, and a sustained downturn could be very bad for people near retirement. But it's always worth keeping in mind that most people don't have much to fear from a stock market decline — even a severe one.
The truth is that nobody has any idea what causes short-term stock market fluctuations. And to the extent that anyone even thinks they have a way of finding out, they're not going to tell you about it or blab to the press — they're going to trade and make money.
But broadly speaking the key source of negative sentiment seems to be a run of bad economic news out of China. This has been a story all summer, but the declining price of Chinese currency since mid-August has made it clear that there are real international implications.
You can see the central role of China-related fears in the extraordinarily poor performance of companies like Apple (down more than 6 percent) that have relied on Chinese customers to fuel much of their recent growth. The China effect is also visible in the price of a wide range of raw materials, all of which are falling in anticipation of weaker Asian demand.
None of this really explains why Friday in particular was so bad (Chinese growth was also slowing on Wednesday), but it's what traders are thinking about.
Since bottoming out in the spring of 2009, US stock markets have enjoyed an excellent run. There have been some hiccups in the years-long bull market, especially centered on America's sporadic political crises, but mostly it's been an era of up, up, and away for American stocks.
In part, this is because the economy has grown steadily this whole time.
But overall economic growth has still been much less impressive than stock market performance. The excess performance of stocks has been driven by a few factors:
In 2015, that party largely came to an end. The profit share of the economy appears to be shrinking again, as the unemployment rate is now lower and companies no longer have a limitless supply of cheap labor. At the same time, the foreign economic picture now looks very different. The Brazilian and Russian economies are both in a state of chaos, and Chinese growth is — at best — slowing down.
If you are in your 60s, hoping to retire very soon, and have most of the money that you have managed to save tied up in the stock market, then a period of low stock prices is bad news. But while much economic commentary simply assumes that low share prices are bad, the reality is that relatively few people are actually in this situation. If you're not planning to retire for another two or three or four decades, then cheaper stocks are, if anything, a plus — it means your savings will go further as a long-term investment.
What's more, for better or worse most people just don't save that much, and the majority of stock is owned by a relatively small number of rich people.
To the extent that things like a stronger labor market and higher wages are weighing down profits and share prices, that's good for most people. To the extent that weak economic growth in Brazil and China is weighing down share prices, that's terrible for Brazilians and Chinese people but probably doesn't mean much one way or the other to you.
It's unlikely that declining stock prices will cause bad things in the life of the typical American. But rapid movements in financial markets are sometimes a sign of larger problems.
If American economic growth is slowing down, that's going to be bad for most Americans. And slower US growth is the kind of thing that would show up in US stock market prices — probably faster and more suddenly than it would become visible in official government economic data. Most people don't seem to think that's what's happening here, so you shouldn't get too worried. But anyone who was really 100 percent confident they could understand the ups and downs of financial markets would be getting rich, not writing about it on the internet, so it's best to admit to some uncertainty about what's really happening.
Andy Kiersz at Business Insider crunched the numbers from the American Community Survey and the Minnesota Population Center to develop a map showing the most commonly held job by immigrants in every state in the union.

(Business Insider)
You see plenty of stereotypical responses here, with immigrants holding down agricultural labor jobs on the West Coast and housekeeping and construction jobs across much of the South. There are also four states in which the most commonly held immigrant occupation is college professor, and in Delaware it's software developer.
But the most socially and economically significant trend is probably the large number of states that are full of immigrant health aides, nurses, or personal care aides. Given the aging of the population, there is going to be increasing demand for these kinds of services, and our ability, as a society, to provide them to people will depend in part on the availability of immigrant workers.
If you take out a mortgage to buy a house, the federal tax code lets you deduct your interest payments from your taxable income. People can also deduct state and local property taxes from their federal income taxes.
Both of these tax deductions tend to be larger for rich people, who tend to have more expensive houses. And rich people are also in higher tax brackets, making every dollar deducted worth more. As a result, these tax breaks provide the biggest financial benefit to the wealthiest taxpayers. The Urban Institute's John McGinty, Benjamin Chartoff, and Pamela Blumenthal have created a helpful chart showing just how big these tax breaks get.
Urban Institute
The blue bars show the value of these tax breaks for different income brackets. They can be compared with subsidies the federal government provides to low-income people to help them afford housing — represented by the yellow bar. As you can see, the tax breaks provided to the richest Americans, on a per-person basis, dwarf the value of housing subsidies provided to those with low incomes.
But the combined effect of these policies is to hurt the middle class the most. Most households in the middle of the income distribution are too wealthy to qualify for federal housing subsidies. At the same time, they tend to have relatively small houses and be in low tax brackets, so they don't get much benefit from housing-related tax breaks.
If policymakers wanted to make housing tax breaks more progressive, they could make them work more like the student loan interest deduction. The deduction is capped at $2,500, and is phased out altogether for high earners.
Here's a very cool data visualization from HowMuch.net that took me a minute to figure out because it's a little bit unorthodox. The way it works is that it visualizes the entire world's economic output as a circle. That circle is then subdivided into a bunch of blobs representing the economy of each major country. And then each country-blob is sliced into three chunks — one for manufacturing, one for services, and one for agriculture.
Check it out:

You can see some cool things here.
Greek politics is back in the headlines this week. After Prime Minister Alexis Tsipras signed a controversial austerity deal with European leaders earlier this summer, he faced a left-wing rebellion that cost him his parliamentary majority. That created a political crisis for Tsipras and his Cabinet, so he's calling for new elections on September 20.
If you're tired of reading about Greece versus Germany and eurozone debt considerations, never fear — this almost certainly does not represent a resurgence of a Europe-wide political crisis.
Quite the reverse. All signs are that the election will completely marginalize the Greek left, and the old establishment political parties, making Tsipras the absolute master of the scene and giving him freedom to implement the deal.
Sure. In brief:
As you might expect, abandoning all of Syriza's main campaign pledges was somewhat controversial inside the party. Many Syriza leaders, especially those associated with the inter-party group called the Left Platform, opposed the pirouette.
The terms of the agreement between Greece and its creditors require various parliamentary votes to implement various changes. This week, enough Syriza MPs began defecting that Tsipras could only secure a majority for his proposals by relying on votes from the center-right New Democracy party. In Greece's parliamentary system, that made Tsipras's position untenable, so he has called for new elections.
Quite the opposite! To many foreign observers, Tsipras's tenure in office has been a complete catastrophe. He's incurred many of the costs that would be involved in Greece leaving the Eurozone altogether but secured none of the benefits. He put Europe through months of wrangling and the Greek economy through a terrifying week of near-collapse, all just to secure a deal he could have had in February. He's broken all his campaign pledges, and seemingly abandoned the agenda that made him popular in the first place.
But Syriza is enjoying an 18 to 20 percent lead in the polls over New Democracy, and Tsipras personally has a 60 percent approval rating.

September snap election could look very bad for the Left: Left Platform will be pushed from party lists, hard to be viable outside party too


Unless something changes dramatically in the next month, new elections should cement his status as Greece's dominant political figure. Dissident Syriza MPs will be purged from Syriza's electoral lists and replaced with loyalists. The dissidents don't have nearly enough time to organize a new political party. The mainstream parties Syriza crushed in January will be crushed again.

3 Tsipras' problem remains implementation. But elections won't make that worse. May even make it better by paving way for reshuffle


Even better, the brief dissolution of parliament will give Tsipras the chance to reshuffle his Cabinet to ensure a new team that is loyal to him and prepared to implement the deal.
There seem to be three main factors underlying Tsipras's dominance of the political scene.
The vote is on September 20.
Gawker's Sam Biddle has obtained internal financials showing that between January and November 2014, Snapchat had revenues of just $3 million while posting a net loss of $128 million. Biddle asks: "How in the hell did it convince investors it was worth $15 billion?"
The Washington Post's Brian Fung shares Biddle's skepticism, suggesting that Facebook's Mark Zuckerberg dodged a bullet when Snapchat turned down a $3 billion acquisition offer and writing that Snapchat "lacks a clear road to profitability."
But it's actually pretty easy to see how Snapchat could wind up being profitable.
In fact, almost every one of today's big internet companies — Yahoo, Google, Facebook, and Twitter — faced similar skepticism in their early years. Back in 2007, Kara Swisher (who now runs Re/code which, like Vox.com, is part of Vox Media) expressed astonishment that Facebook could be worth $15 billion. A year before that, a Slate headline read "$1 Billion for Facebook? LOL!" (Facebook is now worth $260 billion.)
Then each of these sites made a ton of money with advertising. With hundreds of millions of users, they've been able to generate billions of dollars in revenue. Facebook, Google, and Yahoo have all generated big profits. Twitter hasn't turned a profit yet, but it generated $1.4 billion in revenue in 2014 and is on track to take in more this year.
Snapchat is following the roadmap laid out by its predecessors. Facebook's ad revenue was paltry until it signed an ad deal with Microsoft in 2006. Twitter waited until 2010 to announce its advertising plan. Both companies' advertising revenues surged as their user bases and sales forces grew.
So there's every reason to think Snapchat's ad revenues will be large once the company has finished building its ad-sales machine. Snapchat says it has 100 million daily users who watch 2 billion mobile videos a day. This is a hard figure to compare with other sites, which measure their audience in different ways. But at worst, that makes Snapchat a third the size of Twitter, which has about 300 million monthly active users. Twitter is worth $19 billion, suggesting Snapchat would be worth at least $6 billion.
Of course, Twitter's growth has stalled, whereas Snapchat may still be growing quickly. The data leaked to Biddle doesn't give user growth numbers, so we can't estimate how big Snapchat will be in a year or two. But it's not crazy to think the 4-year-old app might still have significant growth ahead of it.
A company's early ad revenue just doesn't tell us anything interesting about its long-term earnings potential. It takes a while for a company to hire a sales team, settle on an effective advertising format, and build awareness among potential customers.
But while it might take time for Snapchat to build a successful advertising program, there's little doubt that it will be able to. Every day, 100 million people open up the Snapchat app. As long as that's true, advertisers are going to be willing to pay top dollar to reach them.
Many people date the start of the 1990s technology boom to August 9, 1995, the date Netscape had its initial public offering. At this point, the company was just 15 months old, yet it was already offering its shares to the public for anyone to buy. After the offering, Netscape's stock surged, valuing the company at more than $2 billion at the end of the first day of trading.
The IPO became a rite of passage for technology startups during the 1990s. Some of today's technology giants, including Amazon, Yahoo, and eBay, had their IPOs in the late 1990s. Lots of other companies held IPOs and then imploded when the market crashed.
Today Silicon Valley is booming again, but there's been a big change in the way technology companies are financed: Technology startups are increasingly turning to rich insiders, rather than the general public, to finance their growth. Here are four charts from Benedict Evans, of the venture capital firm Andreessen Horowitz, that show how the finances of Silicon Valley have changed.
Andreessen Horowitz
Both the number of technology IPOs and their value are down dramatically from the 1990s. Indeed, over the past decade the number of IPOs has been below the level of the early 1980s — though the amount of money raised has been higher.
Andreessen Horowitz
IPOs aren't becoming less common because people have stopped investing in technology companies. Rather, technology startups are increasingly turning to private sources — venture capital firms, private equity firms, and so forth — for funding instead of offering their stock to the general public. These private sources of funding have always been an important part of Silicon Valley, but recently they've become the dominant way technology companies raise money.
In some cases, technology companies only turn to the public markets when they're forced to by government regulators. The Securities and Exchange Commission effectively requires companies to go public when the number of shareholders exceeds 500. The rule was a big reason Facebook had its IPO in 2012.
Andreessen Horowitz
An investor who bought $1,000 of Microsoft stock shortly after the company's 1986 IPO and held it for the next decade would have wound up with more than $100,000 by the late 1990s. And as this chart shows, big post-IPO gains (represented by the gray bars) weren't that unusual in the 1980s and 1990s.
Things have been different in the new century. Facebook was already worth $100 billion at the time of its IPO in 2012. Since then, the stock has more than doubled, providing investors with a pretty good return. But there's no chance that people who invested in Facebook at the time of the IPO will see their funds grow by a factor of 100. Apple, the most valuable company in the world, is worth around $700 billion — less than seven times Facebook's IPO price.
And the story is the same with other recent technology IPOs. Companies are waiting a lot longer to do their IPOs, leaving public investors with much less potential upside. And because non-wealthy people are legally prohibited from investing in private companies, that means most people have fewer opportunities to make high-risk, high-reward investments than they did two decades ago. Of course, that also means there's less risk that these investors will lose their life savings betting on unproven technology stocks.
Andreessen Horowitz
The value of technology stocks has been soaring recently, causing some people to worry that we're in the middle of another technology bubble. But this chart shows that when you compare tech stock prices to company earnings, recent stock price increases look downright tame.
In the 1990s, technology stock prices soared without any corresponding rise in technology company earnings. When the market realized that companies couldn't possibly deliver on the absurd expectations implied by these high prices, the market crashed. Today, by contrast, stock price increases are largely being driven by growing technology company profits. As a percentage of earnings, technology stocks are actually a bit cheaper than they were five, 10, or 20 years ago.
Studies have shown, over and over again, that hedge funds as a class provide investors with worse returns than simple passive investment strategies.
But a new study by Mikhail Tupitsyn and Paul Lajbcygier of Monash University suggests that the ripoff is in some ways more fundamental than that — most hedge funds don't appear to be doing any hedging or active management at all.
To reach that conclusion, the authors took a large set of hedge funds that deploy a variety of investment strategies and researched whether the funds exhibit linear or nonlinear returns relative to broader markets. The math behind this gets pretty funky, but the basic idea is that linear returns are simply proportional to what you could get with an index fund, whereas nonlinear returns aren't correlated with a simple index.
The theory of a hedge fund, after all, is that it is going to employ some kind of active strategy that gets you a return that's different from just big overall market changes. What the authors find is that in most cases this doesn't happen: "Over the long run many hedge funds behave like alternative beta portfolios and maintain linear exposures to systematic risk factors."
Think of how a recent, less technical study showed that Apple, Facebook, and Google are three of the most widely held hedge fund investments.
These are great companies. And obviously the US high tech sector has done well recently. But owning funds that own stock in gigantic, famous technology companies is just earning you generic exposure to the tech sector minus huge management fees.
The real punchline, though, is that not only is it rare for a hedge fund to have returns that are materially different from what a passive strategy could obtain, but the genuinely active minority exhibits inferior performance. "The overall raw returns of nonlinear funds are 0.1 percent lower than returns of linear funds," the authors find.
In other words, if you buy into a hedge fund hoping to take advantage of an active management strategy, you probably aren't going to get one. And if you do manage to obtain nonlinear exposure to broader market risk, you're going to be even worse off than you would have been if you failed. In other words, even if you're rich enough to gain access to exotic investment materials, you want to follow the same basic investing advice as anyone else — make sure to save enough, own stocks for the long term, and stick to passive strategies rather than trying to beat the market.
Last month, America's most prominent dating site for cheating spouses got egg on its face after hackers stole millions of users' private information. The stolen data reportedly included names and credit card information, photos, and sexually explicit chat logs.
The hackers objected to Ashley Madison's morally dubious business model, and they tried to blackmail the site into shutting down.
Ashley Madison refused to suspend its operations, so now the hackers appear to have retaliated by releasing the stolen data online. While Ashley Madison hasn't officially confirmed the data's authenticity, it appears to be genuine. That's going to cause heartburn for the millions of people who have created accounts on the site.
Ashley Madison has courted controversy by positioning itself as a website for people seeking to cheat on their spouses. Founded in 2001, the site says it has 37 million users around the world. The site's slogan is "Life is short. Have an affair."
It has traded on its notoriety to attract customers. In 2009 Ashley Madison tried to buy a television ad during the Super Bowl, but the offer was rejected. But the rejection itself got a lot of press, and the ad wound up getting more than a million pageviews on YouTube. The company also sought to purchase naming rights for the Meadowlands stadium, where the New York Giants and Jets play, but was rebuffed.
The site has traded on its notoriety to attract customers
The site has faced at least one accusation that many of the female profiles on the site are fake.
The company behind the site, Avid Life Media, also owns several other websites, including Established Men, a site that connects young women with "successful and generous benefactors to fulfill their lifestyle needs."
A hacker group calling itself the Impact Team hacked the site, a company spokesperson confirmed to journalist Brian Krebs in July. The hackers said they had obtained user information from Ashley Madison and several smaller dating sites owned by Avid Life Media.
"Avid Life Media has been instructed to take Ashley Madison and Established Men offline permanently in all forms," the hacker group wrote in a statement released in July. If ALM doesn't comply, "we will release all customer records, including profiles with all the customers' secret sexual fantasies and matching credit card transactions, real names and addresses, and employee documents and emails."
ALM didn't shut down its lucrative site, and now the hackers appear to have followed through on its threat. Ashley Madison hasn't officially confirmed that the stolen data is genuine. But so far, there's every sign that it is.
The leaked files are nearly 10 gigabytes in size, and "appear to include account details and log-ins for some 32 million users," according to Wired.
"I’m sure there are millions of AshleyMadison users who wish it weren’t so, but there is every indication this dump is the real deal," the journalist Brian Krebs wrote on Wednesday.
In addition to charging customers who use the site, Ashley Madison also made money by charging users $20 to fully delete their information from the site.
To show they mean business, the hackers have released selected data
But in a statement provided to Krebs, the hackers said this service didn't work. "Full Delete netted ALM $1.7mm in revenue in 2014. It’s also a complete lie," the hacking group wrote. "Users almost always pay with credit card; their purchase details are not removed as promised, and include real name and address, which is of course the most important information the users want removed."
Avid Life disputes this accusation, however. "The process involves a hard-delete of a requesting user’s profile, including the removal of posted pictures and all messages sent to other system users’ email boxes," the company told the Washington Post. "This option was developed due to specific member requests for just such a service, and designed based on their feedback."
The timing of the hack was particularly inconvenient for Avid Life because the company had been trying to go public. However, the company said its controversial business model makes raising funds difficult. "Europe is the only region where we have a real chance of doing an IPO," the company said in an interview with Bloomberg, because of more liberal attitudes toward adultery on the continent.
The hack and the negative publicity it produced has likely scared away of a lot of existing and new customers. Avid Life has attempted to contain the damage by making the account deletion feature free. But if the hacked data is genuine, then that horse is already out of the barn. And future customers will think twice before entrusting their personal data to the company.
Labor market indicators specifically focused on young people are interesting because to the 16- to 24-year-old age bracket, essentially all of their economic life has existed since the Great Recession of 2008. There's no new normal for these people, just normal normal.
Bureau of Labor Statistics data
According to the latest numbers from the Bureau of Labor Statistics, a years-long trend toward increased employment among white youths has been joined by a leap in Latino youth employment and an enormous jump in black youth employment.
Given the huge black-white racial gap in youth employment, you might think this goes to show that the recovery has been weaker for black youth than for white youth. But that's actually not the case.

Black youth summer employment rate has fully rebounded from recession slump. h/t @conorsen pic.twitter.com/Xo48fTzs1R


With this latest surge, black youth employment has fully recovered to its pre-recession level. It's low today due to whatever big social and structural factors kept it low 10 years ago.
The Bitcoin community is facing one of the most momentous decisions in its six-year history. The Bitcoin network is running out of spare capacity, and two increasingly divided camps disagree about what, if anything, to do about the problem.
If these two sides fail to reach a consensus, the Bitcoin network could — according to one side, at least — slowly grind to a halt as the number of transactions exceeds the network's capacity to process them. Even worse, if a fix for this problem is forced through prematurely, it could split the Bitcoin network in two and permanently damage public trust in the network.
The argument is the closest thing the Bitcoin community has had to a constitutional crisis. Bitcoiners are trying to figure out who, if anyone, has the authority to make technical changes to the Bitcoin network's foundations. So far, neither side in the increasingly heated debate has shown much willingness to compromise.
The Bitcoin network processes transactions in units called "blocks," which are created about every 10 minutes. To prevent malicious parties from clogging up the system with spam, the original Bitcoin software limited the size of each block to one megabyte, which corresponds to a few thousand transactions. When Bitcoin was created in 2009, that left plenty of room for growth.
Blockchain.info
But Bitcoin usage has been growing, bringing the network closer and closer to its maximum capacity. Right now, the network is only 30 to 40 percent full on average, but it sometimes gets congested during periods of high demand, causing delays for users. And if current growth continues, things could get a lot worse in the next year or two, as the network gets closer to 100 percent capacity.
And if Bitcoin is going to become a mainstream payment platform, it's going to have to grow a lot more. Bitcoin handles tens of thousands of transactions per day. Visa handles tens of millions. To compete with Visa and other mainstream payment technologies, the network is going to need more capacity.
The limit is just a number in the Bitcoin software. If that number were changed to a higher value, the Bitcoin network would have more capacity.
The difficulty is that this only works if everyone agrees to raise the limit. The Bitcoin network is built on consensus. If some parts of the Bitcoin network raise the limit and others don't, the network would be split in two. Having two competing versions of the Bitcoin network running simultaneously would be catastrophic. It would destroy trust in the Bitcoin network, since users could never be sure which transactions were official. And it would likely cause the value of bitcoins — the unit of currency — to plunge, as people questioned whether the network had a future at all.
Having two competing versions of the Bitcoin network running simultaneously would be catastrophic
So this seemingly simple technical decision — whether to boost the Bitcoin network's capacity or not — has divided the Bitcoin community into warring camps. Two prominent Bitcoin developers, Mike Hearn and Gavin Andresen, lead the faction that wants to increase the capacity of the network, and they enjoy the support of well-funded Bitcoin startups such as Coinbase and Bitpay.
Their argument is simple: Bitcoin needs to grow if it's going to become a mainstream technology, and the current limit doesn't leave enough room for growth.
But not everyone agrees with them.
Opponents of the proposal make two major arguments. One is that increasing the capacity of the network will lead to centralization of the Bitcoin system.
Right now, Bitcoin transactions are processed in a parallel fashion by thousands of computers distributed around the internet. The Bitcoin network is designed in a clever way that prevents anyone from being able to control how it works — at least so long as no one controls a majority of the network's computing power.
But as the volume of transactions has gone up, the number of computers participating in this transaction-processing task has gone down. And some critics worry that boosting the network's capacity will make it more expensive to participate in the process, further reducing the number of computers that participate. That, in turn, could make the system less reliable, or more vulnerable to attempts by governments or others to seize control of the network.
When the Bitcoin network becomes congested, Bitcoin has a system of transaction fees that help bring supply and demand into balance.
Some people want to simply let this mechanism work. They hope this will spur people to develop technical workarounds that allow transactions to be processed in ways that don't burden the primary Bitcoin network.
The rules of the Bitcoin software act as a kind of constitution for the Bitcoin community
Lurking in the background is a larger philosophical disagreement. Bitcoin is built on the promise that many of its rules can never be changed. For example, the rules of Bitcoin say that there will never be more than 21 million bitcoins created. However, that's just a social convention — the people who write the Bitcoin software could decide to increase the rate at which new bitcoins are created so that many more wind up in circulation.
In short, the rules of the Bitcoin software act as a kind of constitution for the Bitcoin community. And critics of raising Bitcoin's transaction limit worry that a hasty increase — or, perhaps, any increase at all — could undermine the public's trust that other aspects of the system won't be modified in the future.
While increasing the capacity of the Bitcoin network might seem like a minor change, it would be the first change made to the core rules of the Bitcoin network since it was launched in 2009. (Developers quickly fixed a very minor bug that briefly broke the network in 2013.) And there are no established rules for making this kind of change.
As often happens, each side of the argument has developed its preferred talking points. Supporters of the higher limit present it as a matter of common sense. Opponents portray it as a power grab by a handful of prominent developers and deep-pocketed companies. There have been endless debates, proposals, and counterproposals about how to resolve the problem.
Each side accuses the other of endangering the Bitcoin network. Proponents worry that the network will grind to a halt if the limit isn't raised in time. Opponents counter that it's reckless to foist a change on the Bitcoin community before a consensus is reached.
Right now, the most popular Bitcoin software is an open-source project that's managed democratically by a five-person group of developers. Andresen is a member of this group, but he hasn't been able to convince his colleagues to increase the limit. So he and Hearn have created competing software, Bitcoin XT, that supports a higher limit.
Bitcoin XT is programmed so that it won't start supporting a higher transaction limit — breaking compatibility with the older software — until 75 percent of the Bitcoin network (as measured by computing power) adopts the new software. At that point, the other 25 percent of the network will risk being left behind if they don't switch. But we don't know if Hearn and Andresen can convince 75 percent of the network to switch. If they can't, we don't know what will happen next.
Ultimately, how the dispute is resolved may matter more than the specific decision that's reached. If Hearn and Andresen's gambit is successful, it could become a template for resolving future arguments. On the other hand, if Bitcoin XT falls short and the warring camps can't reach a consensus, it could do lasting damage to Bitcoin's reputation.
A new report by the New York Times's Jodi Kantor and David Streitfeld paints Amazon as a rather miserable place for white-collar workers. Some examples the piece documents are truly egregious. A woman with breast cancer was threatened with firing because "difficulties" in her "personal life" had interfered with her work, as was a woman who recently endured a stillbirth. Another woman was forced out after years of high performance marks because she visited her sick father too often. Even Amazon CEO Jeff Bezos has acknowledged those cases are unacceptable, and sent a memo to employees encouraging them to report treatment like that to HR.

But as bad as those anecdotes are, the piece describes an office that is nonetheless far, far preferable to the other workplaces Amazon runs: its warehouses.

Spencer Soper of the Morning Call, a daily paper in Allentown, Pennsylvania, described the local Amazon warehouse in 2011 as constantly overheated, with temperatures of more than 100 degrees during summer heat waves. After a federal investigation into conditions, the company started keeping an emergency vehicle with paramedics outside the warehouse to handle cases of heatstroke. An emergency room doctor who treated some of the warehouse's workers reported Amazon for unsafe work conditions.
Apart from the heat, the warehouses paid little ($11 to $12 an hour) and imposed extremely strict discipline on employees. They used a point-based system wherein missed work, not working fast enough, or breaking safety rules earned a worker points, and employees with too many points were fired. Sick employees had to bring in doctor's notes and request medical waivers if they didn't want to get points. "When the heat index exceeded 110, they'd give you voluntary time off," former worker Robert Rivas told Soper. "If you wanted to go home, they'd send you home. But if you didn't have a doctor's note saying you couldn't work in the heat, you'd get points."
In 2012, after Soper's exposé, Amazon installed additional air conditioning units at its warehouses at a cost of $52 million — not insignificant a firm with profit margins as razor-thin as Amazon's. But conditions still aren't good. Amazon is currently under federal investigation after a worker died at a warehouse in Carlisle, Pennsylvania. It had already been investigated after a worker died in a sorting facility it owned in New Jersey, but ultimately wasn't cited. As of this year, Amazon still advertised jobs paying as little as $11 an hour. Warehouse employees still have to sign detailed noncompete agreements that potentially limit their ability to work at retail outlets selling similar goods to Amazon. Workers aren't unionized, and Amazon beat back an attempt by equipment technicians and mechanics to join the International Association of Machinists and Aerospace Workers in January.
In 2013, a BBC reporter went undercover at an Amazon plant in Wales and found himself walking 11 miles over the course of a 10 1/2-hour shift; he was expected to handle a new order every 33 seconds. Warehouse workers still have to endure long security screenings when leaving the facilities, time for which they are not compensated (Amazon went all the way to the Supreme Court to avoid paying for time spent in security lines); the screenings restrict lunch breaks so much that a group of employees has filed a lawsuit alleging the practice breaks federal wage and hour laws. And the strict discipline that Soper described has endured. In 2013, the Financial Times's Sarah O'Connor reported that one employee had a shift canceled after he took a day off because of blisters he'd developed on the job.
An aerial view of Amazon's warehouse in Hemel Hempstead, England, on December 5, 2014.
Peter Macdiarmid/Getty Images
To be clear: The problems with white-collar worker treatment cited in Kantor and Streitfeld's article are real (and Streitfeld, to his credit, has covered the poor conditions at Amazon warehouses as well). Disciplining workers for getting cancer is horrible.
But white-collar Amazon workers are also typically paid high wages, due to Amazon's need to compete with other firms offering lucrative compensation for talented programmers. If they don't like Amazon's work culture, it's very likely there's another firm that will hire them that offers a more relaxed environment. The tech job market is very tight, and while Amazon's coders shouldn't have to leave to enjoy work-life balance, exit is still a viable option.
Exit is not, generally, a viable option for warehouse employees: $11 an hour is not a competitive wage; generally the only people taking these jobs lack the credentials or skills necessary for more lucrative jobs and are taking positions at Amazon because it's the only work they can get. The alternative to working in a warehouse is, quite possibly, unemployment.
So it's a little rich to see people like best-selling author John Green canceling their Amazon Prime subscriptions due to the company's treatment of its well-paid workers:

This NYT story by @jodikantor made me cancel my Amazon Prime subscription. Worst cult ever. Inside Amazon: http://t.co/L31oPD51Sr


It's fine to be mad about how Amazon treats workers. But let's not forget the workers who are truly getting screwed.
The New York Times has gotten a lot of attention for its feature on Amazon's work culture. Times reporters Jodi Kantor and David Streitfeld portray a ruthlessly competitive workplace where people are expected to work long hours, leaving little time for family.
But it's worth noting that it's not hard to find similar complaints from former employees of other prominent technology companies. Business Insider has a roundup of complaints from Apple employees, including one who "hardly (hardly meaning never) saw my daughter during the week because the hours were so inflexible." An employee in Uber's corporate offices writes that "at Uber, you work nights, weekends, and holidays." Netflix has been described as a high-pressure workplace with a "culture of fear."

Of course, not every high-profile technology company is like this. Google and Facebook are known for emphasizing work-life balance. Yet these companies' work cultures are "balanced" only compared with the insane expectations set by some of their competitors. When I worked as an intern at Google in the summer of 2010, many employees would get free dinner at the company cafeteria and then go back to their desks for a couple more hours of work.
There's a good reason so many technology companies have intense, demanding workplace cultures. Especially in the software industry, employees who work longer hours get more work done. And we all benefit from the resulting innovations.
There's a saying in the technology world that the best programmers are about 10 times as productive as the average programmer. What people mean by this isn't that the best programmers write 10 times as many lines of code. Rather, it means that they're able to find clever solutions that allow them to accomplish more with fewer lines of code.
Some of this is about innate intelligence, but in my experience a bigger factor is that the best programmers spend a huge amount of time absorbing technical information. With knowledge and experience about a broader range of software tools and programming techniques, they're more likely to know about the perfect tool for the job at hand.
Employees who log more hours are broadening their experience in a way that will make them more productive in the future
And a similar point applies to workers who serve other roles — like marketers and product managers — at a company like Amazon. In a dynamic industry, it takes constant effort to keep up with what Amazon and its competitors are doing. Employees who log more hours aren't just accomplishing more this week; they're also broadening their experience in a way that will make them more productive in the future.
Of course, there are diminishing returns to longer work hours. Beyond a certain point, you're so exhausted that you get much less done than you think you do. But some people find work at a company like Amazon so exciting that they don't mind putting in long hours — and they can set the pace for everyone else.
You might wonder why instead of driving employees to the point of exhaustion, technology companies don't hire more employees to spread out the work. But this doesn't necessarily work.
A famous programming aphorism known as Brooks's law explains why. It says that adding programmers to a late project makes it later. It was coined by Fred Brooks, who led one of history's first large-scale programming projects: the development of OS/360, an operating system for IBM computers in the 1960s. All the pieces of the software had to work well together, which meant that programmers on Brooks's team had to spend a lot of time talking to each other. Indeed, the larger the group, the larger the fraction of time each programmer had to spend talking to others.
This is a big reason the most innovative software projects tend to be created by small groups. A 10-person team working 70-hour weeks is going to be a lot more productive than a 20-person team working 35-hour weeks, because the larger group is going to spend a lot more time sitting in meetings, arguing on mailing lists, and waiting to get answers from colleagues about how their respective parts of the software project will work together.
The point applies to non-engineers too. The smaller a team is, the more efficiently it can work. Small teams require fewer meetings and less email discussions. They are less likely to be sidetracked by miscommunication or disagreement. They're more flexible and — ultimately — a lot more productive per person.
That said, there's more to life than working, and it would be pretty depressing to work in a world where working in technology required you to give up on having a personal life. But it's important to remember that most white-collar workers at a company like Amazon have plenty of job options.
Vox's Matt Yglesias writes that he once talked to an Amazon executive who said, "I did the best work of my life, far better than I ever felt possible, and I don't regret leaving at all."
Most white-collar workers at a company like Amazon have plenty of job options
Life at a high-pressure company like Amazon can be exhilarating. Employees can make a lot of money, gain valuable skills, and be part of changing the world. Then if they find the long hours to be incompatible with other goals in their lives — like spending time with their families — they can switch to a less demanding job later in their career.
Of course, some of the specific anecdotes in the Times story — like the "woman who had thyroid cancer" who "was given a low performance rating after she returned from treatment" — are indefensible, as Amazon CEO Jeff Bezos has acknowledged. And there's more reason to be concerned about Amazon's treatment of low-wage workers in its warehouses. But it's not a problem that a company would expect long hours from its best-paid employees. If they don't like it, they can find other jobs. And in the meantime, they might create some amazing products and services.
Donald Trump not only wants to build a wall across the US-Mexico border, he wants to find a way to make Mexico pay for the construction of the wall. It's part and parcel of Trump's bombastic nationalism shtick. But it raises an obvious question: If stopping people from moving here is so important, why quibble about the money? And that, in turn, raises the single most neglected point about the economics of immigration: Even the studies by the most immigration-skeptical economists show that immigration raises the incomes of native-born Americans on average.
Don't take my word for it. Ask George Borjas, who tends to be far and away the leading economist in the immigration-skeptical camp. He says the current level of immigrant workers in the United States raises US GDP by about $1.6 trillion relative to where it would be in a zero-immigration universe.
But he cautions (emphasis added):
Of the $1.6 trillion increase in GDP, 97.8 percent goes to the immigrants themselves in the form of wages and benefits; the remainder constitutes the "immigration surplus" — the benefit accruing to the native-born population, including both workers, owners of firms, and other users of the services provided by immigrants.
Wow — 97.8 percent! That sure sounds like a high number.
But the key thing about it is that 97.8 percent is less than 100 percent. Which is to say that immigrants — unlike, say, thieves — are not imposing any net costs on the native-born. In fact, while drastically raising their own income they are slightly raising everyone else's income. And that's according to an economist who thinks high levels of immigration are bad public policy. Other studies by more immigration-friendly economists see considerably larger gains to the native-born. But the whole argument is about how big the net economic benefits to the native-born are, not whether they exist.
Under the circumstances, Trump is correct. In strictly economic terms it doesn't make sense to be expending resources on trying to keep Latin Americans from moving to the United States. Immigration isn't costly, it's beneficial.
Of course, this makes the rest of his punitive anti-immigrant plan seem very costly in economic terms. But people have lots of concerns about language and culture that aren't captured in dollars and cents, and research indicates that these fears are what drives most anti-immigration politics. Trump does a good job of expressing that.
I once had the opportunity to ask a former very high-level executive with Amazon what it had been like to work with Jeff Bezos. "I did the best work of my life," he told me, "far better than I ever felt possible, and I don't regret leaving at all."
That's what I thought of when I read Sunday's lengthy New York Times article on "Amazon's Bruising, Thrilling Workplace." The Times highlights a few instances of clearly abusive behavior that go beyond what any sane company would want to see. A woman suffering from breast cancer was apparently told that "difficulties" in her "personal life" were impairing her job performance in a way that put her at risk of being fired. Another story tells of a person returning from treatment for thyroid cancer to a negative performance review.
But Amazon is a large organization, and some edge cases of impropriety and misconduct are going to happen anywhere. In an email to employees in the wake of the article, Jeff Bezos clarified that if people see instances of employees "being treated without empathy while enduring family tragedies and serious health problems," they should report them to HR.
But the core thrust of the article isn't about the most egregious cases. It's about the culture that former executive described, except with a relentless focus on the "I don't regret leaving at all" side of the equation. It also doesn't get at what I think is a core reason that Amazon's culture of relentlessness is so important to the company: It's not profitable.
Amazon's modest to nonexistent profitability makes the company very different, both culturally and operationally, from other big, mature tech companies like Apple, Microsoft, Google, or even the relatively new Facebook. Those are all companies who've found their way to core operations that are extremely high-margin and throw off tons of cash.
Amazon looks much more like a relatively early-stage startup. Its relentless focus on low prices in pursuit of growth leaves it with very low margins. And whatever revenue it does scare up is invested in the further pursuit of growth. The mission is to get as big as possible, as fast as possible. The company squeezes costs remorselessly, but passes all that forward to customers in pursuit of even faster growth.
There's a lot to like about this business strategy.
But for a publicly traded company to deliberately eschew profitability over such a long span of time is asking Wall Street to have a lot of faith. Bezos has done remarkable things across a number of dimensions, but one of his most underrated skills as a CEO is simply his ability to sell investors on this strategy. There is no "quarterly capitalism" at Amazon, and in fact the time horizon on the plan for world domination is so long that one can question whether there's any capitalism at all.
That, I think, is the context in which you have to understand Amazon's corporate culture. For a company with Amazon's quarterly earnings reports to develop a reputation as a really sweet, caring workplace full of tons of supportive people who recognize the importance of living a full, rich, and balanced life could be absolutely deadly to Bezos's sales pitch to investors.
Wall Street will tolerate "less profit now in pursuit of more profit later." Wall Street will absolutely not tolerate "less profit now in pursuit of being a nice boss."
Fat profits will, by contrast, earn you the right to do pretty much whatever you want with your company. Tim Cook can angrily dismiss questions about Apple's environmental and accessibility initiatives by saying he doesn't care about return on investment because he's earning hundreds of dollars in profit off every iPhone he sells. Because Apple is relentlessly profit-focused, it would like to highlight its charitably minded activities.
By contrast, when I wrote that Amazon was like a charity, Bezos denounced me in a letter to shareholders. He doesn't like bad publicity, but what he really fears is that Wall Street will worry he's gone soft.
The good news for white-collar workers put off by Amazon's corporate culture is that there's always the option of leaving. Precisely because Amazon has a reputation as such a hothouse place to work, nobody will look at you crosswise if you say you want to leave. And a stint at Amazon on your résumé looks great. The actual victims in this whole system are the blue-collar workers at Amazon's fulfillment centers.
As you can read here or here or here, these are not good jobs. The working conditions are bad. The pay is bad. The prestige is low. Nobody walks away feeling pride in having done the best work of their lives. And working at a warehouse does not look particularly great on your résumé.
The upshot of those brutal warehouse conditions is cheaper stuff and faster delivery for millions of middle-class customers. If the warehouses paid better, we would have to pay more for stuff. If you want to feel bad — or morally conflicted, or self-righteous — then I would focus on that.
America's labor markets are tightening, and you can see that playing out in the slew of stories in recent weeks about employers struggling to recruit enough employees:
Here's what you should know about America's tightening labor markets.


(Glenn Koenig/Los Angeles Times via Getty Images)

Often, stories about shortages in a specific industry focus on identifying industry-specific causes for the shortage and industry-specific strategies for alleviating it. For example, some trucking companies that traditionally demanded at least two years of experience behind the wheel have begun paying for new employees to go to trucking school. In education, as another example, some schools are seeking permission to have teachers teach subjects outside their certified area of expertise.
But in the long run, the best solution to a worker shortage is simple: Pay more. Any one employer can almost always get more workers if it pays enough, and if wages rise in an industry as a whole, that will attract more entry-level workers and career switchers.
One sign that worker shortages haven't gotten too serious yet is that wages are still rising more slowly than in previous economic recoveries:
This chart, which shows the rate at which average wages have been rising over the past 25 years, is not adjusted for inflation. In inflation-adjusted terms, American workers' wages have been flat since the start of the Great Recession.
That's a difference between the current economic boom and previous ones. During the boom periods of the late 1990s and mid-2000s, workers saw their wages rise by an average of about 4 percent per year. So far that hasn't really happened during the current economic recovery.
So while labor markets have obviously tightened a lot since the depths of the Great Recession, there's little sign that the economy is overheating. If the Federal Reserve maintains its current low interest rate policies, the economic environment could continue improving for workers for several more years without producing much inflation.
Of course, many business owners say they can't afford to give raises. For example, a lot of restaurant owners say they just don't have the money to pay their chefs more without raising prices. And in a competitive restaurant industry, that might not be an option.
That might be true in the restaurant industry, but it's not true across the economy:
FRED
For the past few years, corporate profits have been at record highs. Businesses could be using those profits to boost worker pay. And if labor markets continue to tighten, they might be forced to do so.
The Great Recession, like all recessions, hurt a lot of American workers. The worst hit were people who were laid off and never found another job.
There were also workers who wound up stuck in jobs and careers they didn't like. During a recession, people have few job options and may be worried about investing in training if they're not sure it will lead to a better job afterward.
A tight labor market is a boon both for long-term unemployed people and for people looking to change careers. Employers often pass over job applicants with long periods of unemployment on their resumes, but a worker shortage forces them to give some of these workers a second look.
And it's a lot easier to switch careers in an environment where employers are hiring every qualified applicant they can find. Some employers will be willing to hire inexperienced career switchers for entry-level positions and train them on the job. And employees will feel more confident going back to school to train for a new career when demand for workers is high.
This week the Chinese government has allowed its currency, the yuan, to decline in value by about 4 percent against the US dollar. The move has renewed a long-simmering debate about China's exchange rate and whether a cheap yuan will be harmful to the US economy.
In the wake of the 2008 financial crisis, critics faulted the Chinese government for intervening in the market to make its currency artificially cheap. A cheap yuan gave Chinese exporters an advantage in world markets, which critics said was harming US businesses.

Today, the situation is different in an important respect: The Chinese economy is weak while the US economy is strong, which is exerting downward pressure on the yuan. That means China doesn't have to intervene to make its currency cheaper — it can just let market forces push the yuan down.
At the same time, the healthier US economy makes it easier for the US Federal Reserve to counter the harmful effects of a cheap yuan on US exports. So while there were good reasons for Americans to worry about a cheap yuan a few years ago, there's less reason to be concerned today.
I asked Joseph Gagnon, an expert on international economics at the Peterson Institute for International Economics, to help me understand what's happening in China. Here's what I learned.
You can think of currency devaluation as a kind of nationwide sale. There are thousands of businesses in China that sell goods and services to customers in foreign countries like the United States. Their goods are generally priced in China's own currency, the yuan. So if the yuan becomes less valuable relative to the dollar, Chinese imports suddenly become cheaper here in America. In other words, when the yuan falls by 4 percent, as it has over the past few days, it's as if every business in China cut its prices for Americans by 4 percent.
And just as sales help stores sell more of their products, a currency devaluation helps countries sell more exports, boosting the economy. Right now the Chinese economy is in the midst of an economic slowdown and has suffered from stock market turmoil, so it can use some extra help.
Of course, everything I've just said works in reverse for the United States. As the yuan gets cheaper from the perspective of American consumers, the dollar gets more expensive from the perspective of Chinese consumers. That means it's getting more expensive for Chinese people to import American-made goods, so they're likely to import fewer of them. Lower demand for US goods could mean slightly slower economic growth here in the US. (And the same, of course, is true of other countries whose currencies are gaining value relative to the yuan.)
It's as if every business in China cut its prices for Americans by 4 percent
For this reason, people often treat currency devaluation as a "win" for the devaluing country and a "loss" for the country whose currency gets more valuable. That's why Chinese officials have had to defend themselves against criticism from abroad — people outside China worry that further declines in the yuan could weaken economic growth outside of China.
But it's important not to forget that the first-order result of a cheaper yuan is that American consumers pay lower prices for Chinese goods. That's good for American consumers. So if the Fed can offset the negative macroeconomic effects (which it probably can right now — more on that below), a cheap yuan could be good for Americans overall.
Japanexperterna

(Japanexperterna)

Most developed countries, including the United States, allow the market to set the value of their currency. US policies can affect the value of the dollar indirectly, of course, but day-to-day fluctuations in the dollar's value are determined by supply and demand for dollars, not by the US government.
China has taken a different approach. Until 2005, the government kept its currency pegged to the dollar, with the central bank buying or selling currency as necessary to ensure that one dollar was worth around 8.2 yuan. Since 2005, the currency has been pegged to a basket of currencies, and the exchange rate has changed over time, but China still actively manages the currency's value on a day-to-day basis.
For much of the past decade, China faced accusations that it was using its control over the currency to make Chinese exports artificially cheap. Especially in the years after the 2008 financial crisis, US critics accused China of using control over its currency to give Chinese companies an unfair advantage over US companies. That was a big deal because in the depths of the recession, US businesses needed all the customers they could get.
No one expects China to let go of the leash altogether
But things have changed. Over the past five years, the US economy has been getting stronger, pushing up the value of the US dollar. Meanwhile, the Chinese economy has been getting weaker. The result: The Chinese government no longer needs to intervene in the market to get a cheaper yuan — and the export boost that comes with it. It simply needs to relax its control over the currency and let market forces push its value down.
Still, Gagnon stresses that "the People's Bank of China has complete control over what happens to their currency." If the government had wanted to prevent the yuan from falling, it could have used its vast currency reserves to accomplish that. It chose not to.
In the long run, China hopes to emulate developed economies with fully flexible exchange rates. That's an essential precondition if the yuan is ever to challenge the dollar as the world's reserve currency. However, China has been moving slowly.
"It's like having your dog on a leash," Gagnon says. "Think of a flexible exchange rate as you cut the leash. China's version of it is, 'We'll let another 6 inches of leash out, but it's still on a leash.'"
So while this week's devaluation is a step toward greater flexibility, no one expects China to let go of the leash altogether. If exchange rates move too far in a direction the Chinese government doesn't like, the Chinese central bank will intervene.
Jewel Samad/AFP/Getty Images
(Jewel Samad/AFP/Getty Images)
It's the job of the US Federal Reserve to manage monetary policy in a way that provides adequate demand for US companies. The Fed was struggling to do that in 2009. The Fed cut interest rates to zero and took other extraordinary measures — and the economy still performed poorly. In that environment, there was reason to worry that a cheap yuan was contributing to America's economic slump.
But the situation is a lot different today. The economy has been expanding for several years. Indeed, things are going so well that the Fed has stopped debating how to stimulate the economy, and is instead debating how quickly to tighten monetary policy. The central bank ended its aggressive "quantitative easing" policy last year, and is widely expected to begin raising interest rates in the coming months.
This means the Fed is in a much better position to offset the effects of a cheap yuan than it was five or six years ago. If the Fed is worried that weak exports will hurt the US economy, it could delay an interest rate increase that is widely expected to occur later this year.
Gagnon believes the cheaper yuan is "perhaps something the Fed should take into consideration to delay a rate rise."
The fact that the yuan's current decline is driven by market forces instead of Chinese intervention will also scramble the debate over Chinese currency manipulation. For years, people have been pressuring the Obama administration to fight China's cheap-yuan policy. But the Chinese government doesn't have a cheap-yuan policy anymore — if anything, the Chinese government may be intervening to prevent the yuan from falling even further.
China has always been a convenient villain for US currency hawks
Of course, that doesn't prove that currency manipulation isn't a problem. Other countries manipulate their currencies, and China might go back to making its currency artificially cheap in the future. Groups that have faulted President Obama for failing to get currency manipulation rules in the Trans-Pacific Partnership deal will probably continue advocating such rules.
But China has always been a convenient villain for US currency hawks. Now that the country has stopped pushing down the value of its currency — at least temporarily — critics' arguments will lose a lot of their bite.
On Monday I profiled Redfin, a technology company that set out to revolutionize the real estate industry but wound up adopting many of its practices instead. When I interviewed CEO Glenn Kelman for the story, I asked him if he saw any smaller, hungrier real estate startups following in Redfin's footsteps.
"Not really, but I worry about it all the time," Kelman told me.
After my story ran, I was contacted by a real estate startup that's doing just that. SQFT has created a mobile app and a set of real estate services that allow people to sell their homes for a third the cost of a traditional listing agent. I talked to the company's CEO, James Simpson, on Wednesday.
Here's what distinguishes SQFT's business model from Redfin's — and what they still need to overcome to prove their approach is viable.
From the outset, Redfin has offered services for both buyers and sellers, but because its original innovation was showing real estate listings on a map, most of its business came from buyers at first. One of the big hurdles Redfin faced was the fact that representing buyers is labor intensive.
Buyers expect their agents to drive them around town touring houses, and a company can only offer that service if it has a significant staff on the ground in every city where it operates. That's why it has taken Redfin nine years and tens of millions of dollars to reach 36 states. It's not so labor-intensive to serve sellers, and SQFT hopes to get by with many fewer agents per city, allowing it to expand more quickly.
This is significant because the sellers' side of the market has the most room for innovation. The seller is the one who sets the rules of any real estate transaction. So if a company wants to experiment with ways to make the real estate market more efficient, it needs to work with people who are selling homes, not just buying them.
A traditional listing agent will run open houses for a property (Redfin does this too). That's a godsend for sellers who are nervous about interacting directly with buyers. But Simpson believes that some sellers will be willing to hold open houses themselves in exchange for thousands of dollars in savings — helping to keep SQFT's headcount down.
Simpson told me that his company has closed just 20 sales in the two months since it launched. Most of those sales occurred in Colorado, where the startup is based (it has ties to Boulder-based Techstars). It's raised $1.4 million in funding and has around a dozen people on staff.
Listing agents normally charge sellers 3 percent of a home's sales price — for example, $15,000 for a $500,000 house. SQFT charges just 1 percent — $5,000 for the same property. That compares favorably to Redfin's service for sellers, which charges 1.5 percent in most markets, though it has experimented with charging 1 percent in a few locations, including Washington, DC.
SQFT will save customers 2 percent of their home's value compared with a traditional listing service, but that's only a good deal if homes sold on SQFT can fetch prices as high as homes sold by more traditional realtors. Conventional realtors argue that their knowledge and experience — about advertising, staging furniture, timing, and other sales tactics — can fetch sellers a higher price than do-it-yourself sellers can earn. Unsurprisingly, Simpson disagrees — he thinks that with some advice from an SQFT agent, sellers willing to put in the necessary effort can sell a home as effectively as a professional.
Still, "we may not appeal to a first-time home seller who has never sold a house before," Simpson concedes. "They might be a little bit anxious about using a service like ours. We're not going to appeal to everyone, but I think those that have been through a couple of transactions are going to be very comfortable using us."
Real estate startups like SQFT have to deal with the traditional real estate agents who still dominate the market, and who do things much as they did a couple of decades ago, so there's not a ton of room to change how real estate is sold, at least in the short run. That's probably why SQFT isn't dramatically different from Redfin's service for sellers. SQFT offers a bit less service — no agent-run open houses — and charges a modestly lower price — 1 percent compared with 1.5 percent.
Yet that doesn't necessarily mean SQFT's launch is insignificant. For the past few years, Redfin has benefited from being essentially the only technology company that also operated as a real estate brokerage. That might have been because Redfin itself seemed to be struggling to make its business model work. But now that Redfin has clearly found its footing, it's starting to attract imitators. That will force Redfin to keep innovating while keeping costs down, to the benefit of customers.
"You know, if I were to get hit by a bus today," Google co-founder Larry Page once reportedly said, "I should leave all of it to Elon Musk."
That's admittedly an unorthodox way to handle one's estate. Most wealthy individuals leave their money either to heirs or to a charitable foundation. But as Page later explained, he thought the Tesla Motors/SpaceX CEO could do more good with the money. In an interview with Charlie Rose, Page mentioned Musk's idea of "backing up humanity" by creating a parallel civilization on Mars as an example of an effective way to improve the world through business. "That’s a company, and that’s philanthropical," he said.
In retrospect, now that he's founding Alphabet as a way to keep researching big moonshot ideas, Page's comments seem less like idle musings and more like a coherent theory of how to best use his money to change the world: not by giving it away, but by investing it in projects he thinks could be truly revolutionary.

As the above chart shows, the main factor in whether a country escapes extreme poverty is whether its economy grows. You can see an animated version of the graph covering many years here.
Page's career is premised on the idea that advancing technology through a for-profit company can meaningfully improve people's lives — and indeed, there's a decent argument to be made that, historically, profit-motivated technical advances have helped people more than charity has.
If you look at the major forces of progress in world history, philanthropy isn't high up there. Scientific research and technological innovation, however, are. The most important force in lifting people out of extreme poverty has, at least since the Industrial Revolution, been economic growth, which is boosted by scientific discovery but not by charity. Improvements in life expectancy have been driven both by increased wealth and by medical advances, which are often funded and backed by pharmaceutical companies and other for-profit actors.
Even major charitable success stories stand on the backs of technological and medical innovation. The eradication of smallpox was a major humanitarian undertaking, but one that required the invention of readily deployable vaccines. The Green Revolution — which dramatically increased crop yields in Mexico, India, and elsewhere — was sponsored by the Ford and Rockefeller Foundations, but worked by spreading existing technological improvements in farming to poor countries.

Ken Thompson (left) and Dennis Ritchie, who invented UNIX and C at Bell Labs. (The Jargon File)
So let's suppose you're Larry Page. You have billions upon billions of dollars. You feel, as any decent billionaire would, an urge to give back to the world. You could do that by starting a foundation and giving away your money, or you could join Warren Buffett and dedicate your money to someone else's foundation, so you don't have to worry about setting up a totally new one.
But you're not necessarily good at running a foundation, or even at picking the best one out of the existing options. What you are good at is making consumer products. It seems like if you want to do some good for the world, that's a useful skill set to draw upon. Things like Google Maps and Gmail and Hangouts and Android have already made life better for millions of people. Why not do more of that — and do it bigger?
This may not be the most profitable path for Google. But then again, AT&T didn't reap most of the benefits when its Bell Labs researchers invented the laser, or the transistor, or UNIX or the C programming language. Those advances trickled out and made the whole world better. Same goes for Xerox, whose Xerox PARC researchers invented the graphical user interface, which made widespread computer ownership and usage possible, and then saw companies like Apple and Microsoft profit from it while Xerox got little back.

Google's self-driving car; if these go to market, they could save thousands of lives, help end congestion, and improve the world in countless other ways. (Google)
Alphabet gives Page the freedom to pursue those kinds of bigger projects. The reorganization's main purpose is to cleave the core functionality of Google — search, Maps, Docs, Gmail, YouTube, etc. — from the company's more far-out research projects: self-driving cars, giant wind-energy-collecting kites, attempts to radically extend human lifespans, balloon-based wifi provision, etc. By placing those initiatives as subsidiaries of a company, just like Google, Page is signaling that he regards them as peers of similar importance, and suggesting that Alphabet's focus as a company will be just as much on exploring those kinds of moonshots as on improving Google's core business. The self-driving cars aren't a fun hobby supported by the search engine business, in other words. They're an equally crucial part of the business.
Page also frees himself, and Sergey Brin, to focus on those projects rather than on Google qua Google. Page and Brin's time and attention are scarce and valuable resources at Alphabet, and by committing them to moonshots, Page improves their likelihood of success on the margin.
He's also suggesting that he's going to use his own money to enforce a vision of Alphabet/Google as a company that invests in ambitious, crazy-seeming ideas. Page and Brin have purposefully structured Google such that not all shareholders have equal voting power — and so that the minority of shares (only about 14 percent) owned by Page and Brin wind up having a majority of votes. Because Google sells "Class C" stock that has no voting power, it can still raise money from investors without giving up any control.
Page wants Google to be doing more to aggressively change the world. And Alphabet is set up to enable just that.
This releases Page and Brin from any need to pursue share buybacks, pay out big dividends, or otherwise appease investors. Instead, profits can be plowed back into investments, including the long-shot projects Page is so passionate about. This only works, though, if he and Brin hold on to their stakes. If they were to sell them off and give the money to a foundation, they'd lose their ability to force Alphabet to invest in ambitious ideas. But by holding on to the roughly $30 billion apiece in Google stock they own, they can raise many more billions from investors to spend on self-driving cars, wind energy kites, and defeating death itself. They're leveraging their money to get even more money for the charitable cause Page thinks is most important: major, revolutionary innovation.
Page said as much in his interview with Rose, arguing that using his money to influence and benefit his own company was the best method he had for doing good. "You're working because you want to change the world. You want to make it better. Why isn't the company that you work for worthy not just of your time but your money as well?" he asked (emphasis mine). "I mean, but we don't have a concept of that. That's not how we think about companies, and I think it's sad, because companies are most of our effort. They're where most of people's time is, where a lot of the money is, and so I think I'd like for us to help out more than we are."
Page wants Google to be doing more to aggressively change the world. And Alphabet is set up to enable just that.
Larry Page and Sergey Brin have always seen Google's aim as more than mere profits. "Google’s mission is to organize the world’s information and make it universally accessible and useful," reads the company website. But even that's come to seem too small to its founders. In their 2004 IPO letter, they put it more broadly: "We aspire to make Google an institution that makes the world a better place."
A more precise mission statement may be, simply, "Google: better living through technology." Page and Brin have become obsessed in recent years with what they see as a kind of market/cultural failure to pursue the big, expensive ideas that might truly change lives. In an interview with the Financial Times, Page was unsparing:
Page estimates that only about 50 investors are chasing the real breakthrough technologies that have the potential to make a material difference to the lives of most people on earth. If there is something holding these big ideas back, it is not a shortage of money or even the barrier of insurmountable technical hurdles. When breakthroughs of the type he has in mind are pursued, it is "not really being driven by any fundamental technical advance. It’s just being driven by people working on it and being ambitious," he says. Not enough institutions – particularly governments – are thinking expansively enough about these issues: "We’re probably underinvested as a world in that."
As Ben Thompson writes, Google's founders aren't business-and-strategy nerds, which is what continuing to run Google's search and advertising products would require. They are change-the-world nerds, and that's why they're reorganizing their company around breakthrough technologies.
But in this, Google — excuse me, Alphabet — is walking well-trod territory. AT&T took its monopoly profits and funded Bell Labs, which racked up Nobel Prizes, invented the transistor, and revolutionized our understanding of how the world began. Xerox took its profits and built PARC labs, which developed the graphical user interface that led to the Macintosh. And now Google wants to take the massive profits from its search-and-advertising business and fund its own factory dedicated to changing the world.
Michael Hiltzik is the author of Dealers of Lightning: Xerox PARC and the Dawn of the Computer Age, as well as the new book Big Science: Ernest Lawrence and the Invention That Launched the Military-Industrial Complex. And so I asked him: Does Google have a chance at really making these moonshot technologies work? Or is this just founder ego run amok? A lightly edited transcript of our conversation follows.
Do you think the comparison of Google and Bell Labs or Xerox-PARC is valid?
There are a few things you need to do what Google seems to want to do. One is a huge flow of revenue. This is something AT&T had when it was a monopoly provider of communication services and Xerox had when it was exploiting the revenue flow from what was then one of the most successful commercial products in history.
The next thing was to create an atmosphere in the research arm that allowed serendipitous development. Most of what Bells Labs was trying to do was advance communications technology. But communication encompasses a lot of things. The transistor was the product of the idea that we should be more effective and efficient transmitters of voice information. They were looking for an alternative to vacuum tubes. When they discovered the background radiation of the Big Bang, they were ostensibly researching communications technology — they won a Nobel Prize, and that was okay.
Xerox-PARC was the same way. The idea was to keep an eye on the digital future. Xerox deliberately established PARC on the other side of the country. They accepted it when the guy they put in charge of PARC said, Don’t expect anything you can commercialize in the next five years. So they ended up with the personal computer and the graphical user interface. No one could have foreseen that from the original charge.
So when I look at Google’s R&D, what interests me is they’re not only working on the self-driving car, which would be easy to commercialize, but life-extension technology, which is way out there. That reflects this culture where they want to nurture a spirit of inquiry.
From the corporate perspective, are Bell Labs and Xerox-PARC examples of success or failure? Bell Labs created the transistor, but it was Intel that commercialized it. Xerox-PARC created the graphical user interface, but it was Apple that commercialized it. There's huge social benefit in all this, but even if Google makes breakthroughs, is it likely to benefit from them?
It depends on the company. I’ve been talking about the culture of the research organization, but there’s also the question of the culture of the company and the reality of their business. AT&T had a communications monopoly. So it could get into anything related to communications.
Xerox was a prisoner of the success of the copier business — it had a whole sales and manufacturing structure devoted to this product. The way Xerox made its money wasn't even selling copiers, it was leasing them. You paid based on how many copies you made. So it was very hard for Xerox to get into anything that wasn’t really connected to the copier. They had 250,000 salesmen, and when they looked at the personal computer it wasn't even clear how they made their commission off of it.
Google, almost from its inception, has had a much broader idea of what could be its business. Google engineers have always been given time to work on whatever they want. That tells you Google conceives of its business based on what it discovers. And that may mean the company is more able to absorb dramatically different technologies and discoveries.
But isn't the creation of Alphabet a signal that Page and Brin don't think that's true? It seems that implicit in this move is the idea that these other ideas and products are being somehow stanched by being inside Google, and they need to be spun out into separate entities if they're going to succeed.
That’s very possible. A company can also come to believe what it’s doing is costing it shares because Wall Street doesn’t understand how it all fits together. That's one reason you often see businesses spin out new product lines or break themselves into pieces.
I was just looking at Google financials, and in 2014 they brought in $66 billion in revenue, brought in $10 billion profit, and they were holding over $60 billion in cash. Investors can’t say, Don’t use that money to look ahead. But things change over time. That’s why this is encouraging. They’re setting up a culture that looks ahead to innovations.
In his Financial Times interview, Page almost seems to be saying that there's a market failure around moonshot innovations — that for reasons both cultural and financial, there's too little investment in very big ideas, and so there's both good to be done there but also money to be made there. I guess another way of putting that is that Alphabet doesn't face competition for talent or big thinking right now from a Bell Labs or a Xerox-PARC. Do you think he's right?
I look at it in a broader sense. Traditionally — which is to say the last 50 to 75 years — the patron of basic research has been the government. The government doesn’t have these imperatives to think only about commercializable research. The internet was a government project. But what we’ve seen in recent decades is that government has started to withdraw from that role because it doesn’t want to spend that much and because the funding has become more politicized. Scientific research is easy to caricature and thus easy to cut. So basic scientific research has moved toward private industry, but they have these imperatives to foster the bottom line.
Google is now the epitome of a company that has so much money coming in that they have the luxury of steering some of that money to worlds that no one knows exist yet.
Google CEO Larry Page announced on Monday that he intends to create a new corporate parent, called Alphabet, which will own Google as well as a variety of other ventures.
One way to understand the move is as a response to a problem that Hillary Clinton identified in a campaign speech last month: "quarterly capitalism."
Clinton argued that "everything is focused on the next earnings report or the short-term share price, and the result is too little attention on the sources of long-term growth: research and development, physical capital, and talent."
In a sense, Page is trying to prove Clinton wrong, by building a company that's focused on ambitious long-term investments rather than quarterly financial results. But Page is also the exception that proves the rule: He and co-founder Sergey Brin have total control of Google, which isn't true of most other CEOs.
The villain in Clinton's story is really Wall Street's focus on quarterly financial results. If a company reports several straight quarters of disappointing financial results, the CEO starts to worry about losing his job. So, the argument goes, she cuts back on long-term investments that could produce profits years in the future, in favor of incremental changes designed to juice profits in the next few months. In the long run, this means that companies produce fewer breakthrough innovations, and the economy as a whole grows more slowly.
Clinton wants to tackle this problem with changes to public policy, including higher taxes on investors who hold stocks for fewer than six years and perhaps tweaks to corporate governance rules that give activists shareholders less influence over management. She hopes these changes will insulate CEOs from their shareholders, allowing them to focus more on the long term.
Page is tackling the same problem from a very different angle: He wants to turn Google — now Alphabet — into a company dedicated to making big, risky, long-term investments. Google has long been a company with an interest in long-term investments — as evidenced by its "moonshot" investments in things like self-driving cars and life-extension technology — but the creation of Alphabet makes it official. Where Google was a search company with a side interest in moonshots, Alphabet aims to be a moonshot company whose most successful moonshot is Google itself.
It might seem like Page's plan proves Clinton's thesis wrong, by demonstrating that companies are still able to make long-term bets. But it's important to recognize how unusual Page's position is. Through savvy negotiating in Google's early years, Page and co-founder Brin were able to maintain a majority of Google's voting rights. That means Page can't be fired by other Google shareholders, no matter how bad Google's quarterly results look or how much its share price drops.
But the vast majority of public company CEOs don't enjoy this degree of autonomy. They serve at the pleasure of their shareholders, and are liable to lose their jobs if their share price falls too much. So most CEOs couldn't emulate Page if they wanted to; if they tried to turn their companies into moonshot factories, they'd face a revolt from their boards and likely lose their jobs. So it's worth thinking about whether there are ways to make it easier for other CEOs to behave more like Larry Page.
Google CEO Larry Page is an ambitious man. Not satisfied with founding one of the world's biggest and most influential technology companies, he's now plotting to spend billions of dollars in Google profits on new ventures that are far removed from Google's original search business.
To do that, Page and co-founder Sergey Brin are planning to give Google a new parent company called Alphabet. Alphabet will own Google plus a variety of other companies. These include technology businesses like Nest (which Google bought in 2014) and Google Fiber (which provides home internet access in certain cities). It will also include more radical efforts like Calico, a company that's trying to increase human lifespans. Each of these businesses will have its own CEO and business strategy. And Alphabet will include new ventures that Page and Brin conceive in the coming years.
Clearly separating Google from other ventures could give the CEO of each company the ability to focus on their unique areas of expertise.
Not much will change from the perspective of a Google user. Products will continue to use their existing brands — there won't be an Alphabet search engine or an Alphabet smartphone OS. Google will get a new CEO, Sundar Pichai, who has been at Google for a decade. He was promoted to be Page's top deputy last year, putting him in line to be CEO.
Like many founders, Page and Brin are more excited about launching new ventures than they are about managing existing ones. The new structure will allow them to periodically create new projects and then hire others — such as Pichai and Calico CEO Arthur Levinson — to handle day-to-day operations of individual companies.
Page and Brin's ambitious plans for Alphabet are made possible by Google's unusual corporate structure, which gives the co-founders a majority of the voting power. As a result, they have wide discretion to do as they please with Google, without worrying about what shareholders want.
Profitable companies often face pressures to return cash to shareholders through dividends and buybacks, but Page is making clear he has no intention of doing that. Instead, he is creating Alphabet because he believes he can invest Google's billions of dollars in annual profits more effectively than Wall Street can.
On Monday, Google CEO Larry Page announced a major reorganization: The search giant is getting a new parent company, called Alphabet. In addition to owning Google, Alphabet will own other business ventures launched by Page and Google co-founder Sergey Brin.
It used to be more common for big companies to plow their profits into ambitious research and development projects. But in recent years, companies have been increasingly returning their profits to shareholders through dividends and share buybacks instead. Page is bucking that trend, betting that he and Brin can invest Google's vast profits more effectively than the broader market can.
He could be right. Google is structured in a way that gives Page and Brin total control over Google, which means that the founders can make long-term bets that would be hard for most CEOs — who serve at the pleasure of their boards — to make.


An office with IBM computing equipment in the 1950s. (Getty Images)

To see why Alphabet could be a big deal, it helps to look back to the mid-20th century. In many ways, this was a golden age for American innovation generally, and computer technology in particular. A lot of these innovations were driven by a handful of huge conglomerates. The transistor was invented by the national telephone monopoly, AT&T. The early computer industry was dominated by an office equipment manufacturer, IBM. The graphical user interface was invented by a Xerox research lab.
But in the 1970s, things began to shift. When we think of the major innovations of the past 40 years, we don't think of industrial giants like AT&T or IBM. Rather we think about Bill Gates, Steve Jobs, and Mark Zuckerberg creating new companies and new product categories from scratch.
In the modern invention story, big companies are less likely to be a source of inventions than an obstacle to progress — or simply irrelevant. One generation's disruptors become the next generation's disruptees.


Activist investors like Carl Icahn have been pressuring companies like Apple to return their profits to shareholders. (Adam Jeffery/CNBC/NBCU Photo Bank via Getty Images)

Over the same period, we've seen a big shift in what CEOs do with their companies' profits. Instead of plowing their profits back into new investments, as they might have done a generation earlier, companies are increasingly returning the profits to investors through dividends and share buybacks.
And that's not a coincidence. If you believe that innovation mostly comes from venture-backed startups that disrupt established companies, and that established companies mostly squander resources in a futile effort to ward off obsolescence, then this is precisely what you should want big companies to do.
Also, capital markets are larger and more sophisticated than they were a few decades ago. In the early days of Silicon Valley, even the most promising startups struggled to find anyone willing to fund them, so working at a big company was often the only way to get the funding needed to get a cutting-edge idea off the ground.
Now Silicon Valley is awash in capital. There are dozens of venture capital firms eager to fund every promising technology idea. So, the theory goes, technology visionaries no longer need the backing of big companies to fund their great idea.


As long as Page has the support of co-founder Sergey Brin, he can do what he wants with Google's billions. (Justin Sullivan/Getty Images)

So most companies face pressure to stick to making products in their core area of competence — in this case, online services — and return extra profits to shareholders. But Page has no intention of doing that. Indeed, last year he reorganized Google in a way that allows him and co-founder Sergey Brin to raise more capital without losing control of the company. Page thinks he and Brin will be able to put Google's profits to use more effectively than Google's shareholders could.
There are obviously many examples of the conventional venture capital approach working well and producing major innovations. But there may be some innovations that a huge, well-funded organization like Alphabet might be better positioned to accomplish than a conventional venture-backed startup can. There are now a ton of venture capital firms looking to fund innovative startups. But there are very few technology companies that are controlled by their founders and have significant cash to invest. Google is one of them, which means it can do things few other companies can.
A big disadvantage of the venture capital model is that startup founders have to choose between raising large sums of money and maintaining control of their companies. Some founders, such as Mark Zuckerberg and Page and Brin themselves, have managed to build huge companies while maintaining control. But that was only possible because they were able to get a product to market with a small initial investment. That meant that as Google and Facebook grew, its founders could run their companies in ways they thought made sense without worrying much about what investors wanted.
But there are many types of innovation where this just isn't possible: It costs so much to get the company off the ground that founders wind up as minority shareholders in their own companies. And once founders lose control of their companies, they face more pressure to worry about short-term profitability. Venture capitalists are willing to lose money for several years in hopes of a significant payoff down the road, but they still want to have a clear plan to reach profitability. Hardly any are willing to invest in wide-ranging research for a decade or more in hopes that it will eventually produce a marketable product.
And most Fortune 500 CEOs face a similar constraint. They might have plenty of cash, but they face pressure from Wall Street to deliver solid financial results on a quarterly basis. In practice, that creates pressures not that different from those exerted by venture capital firms: CEOs can invest, but only in projects that have the prospect to produce returns within a few years.
But Google is structured in a way that guarantees Page and Brin will control the company as long as they're both alive and working for the company. They're relatively young men, and could easily run Google for another three or four decades. That allows them to make long-term bets in technologies — like self-driving cars or life-extension technology — that might not pay off for a decade or more. These are investments that few venture capital firms — or most large, established companies — would be willing to make.
Obviously, it's impossible to predict how successful this strategy will be. Page and Brin might wind up wasting their shareholders' money on boondoggles that never produce significant benefits.
But it's also possible they'll find big opportunities that investors with shorter time horizons have missed. Perhaps the pendulum has swung too far toward a world where companies are a little too accountable for delivering short-term financial results. Maybe the American economy needs some companies engaged in the kind of ambitious, long-term research that companies like AT&T and Xerox engaged in a half-century ago. Larry Page is determined to find out.
Disclosure: My brother is an executive at Google.
Google founders Larry Page and Sergey Brin have never been known for thinking small.   The journalist Steve Levy writes about a 2004 conversation between Google co-founder (and now CEO) Page and then-CEO Eric Schmidt. They were discussing international expansion, and Schmidt asked Page how big Google should get.
"How many engineers does Microsoft have?" Page asked. Page was told Microsoft had about 25,000 engineers. "We should have a million," Page said.
That kind of restless ambition was on display today as Page and co-founder Sergey Brin announced a massive reorganization of Google. When the process is complete, Google will become a subsidiary of a new company called Alphabet, which will be a holding company for a variety of ambitious ventures undertaken by Brin and Page. Larry Page is stepping down as CEO in favor of a relative unknown, Sundar Pichai.
Google started as a company that built a search engine, but over time it's become a lot more than that. The Mountain View, California, company has created or acquired a number of other hugely popular internet products, including YouTube, Android, and Gmail. More recently, the company has begun pouring resources into projects like self-driving cars, anti-aging technology, and balloon-powered internet access.
Page and Brin believe that these projects have become too diverse and sprawling for a single operating company to manage all of them effectively. Different projects require different types of leaders, different company cultures, and different types of resources. So they're creating Alphabet as a holding company that will oversee all of these different ventures while allowing each to have more independence.
"We’ve long believed that over time companies tend to get comfortable doing the same thing, just making incremental changes," Page wrote in his blog post announcing the change. "But in the technology industry, where revolutionary ideas drive the next big growth areas, you need to be a bit uncomfortable to stay relevant."
Page hopes that giving the various parts of the Google empire more autonomy will make it easier for them to stay outside their comfort zones and push the technological envelope.


Sundar Pichai (LLUIS GENE/AFP/Getty Images)

Google's new CEO is Sundar Pichai, who has been at the company since 2004. Last year, a management shakeup made him Larry Page's top deputy. Fortune explained Pichai's rise through the ranks in a 2014 article.

Pichai has managed a number of Google products over the past decade. He was an early leader of Google Chrome, which was launched in 2008 and has become the world's most popular web browser. As Fortune put it, Chrome's success "became the engine that powered Pichai through one of the fastest corporate ascents in the technology industry."
Pichai was put in charge of Gmail and then Android, two other highly successful Google products. Last year he was put in charge of the majority of Google's products, including its search engine, a position that put him in line to succeed Page.
Insiders say that Pichai is almost universally liked within Google and has a knack for navigating Google's politics without ruffling too many feathers. He's adept at understanding Larry Page's vision and translating it into practical business decisions and getting different parts of Google's often fractious organization to work together.
"Sundar has been saying the things I would have said (and sometimes better!) for quite some time now, and I’ve been tremendously enjoying our work together," Page wrote today. "He has really stepped up since October of last year, when he took on product and engineering responsibility for our Internet businesses."
Page will be the CEO of Alphabet, and Brin will be its president. Page hopes the reorganization will allow him and Brin to focus on the big picture. But their announcement isn't very clear about what exactly that means.
Page and Brin are more excited about launching new ventures than they are about managing existing ones
"Our model is to have a strong CEO who runs each business, with Sergey and me in service to them as needed," Page wrote. "We will rigorously handle capital allocation and work to make sure each business is executing well."
A big part of the duo's new role will be to focus on "starting new things." Like many founders, Page and Brin are more excited about launching new ventures than they are about managing existing ones. The new structure will allow them to periodically create new projects and then hire others to handle day-to-day operations.
"We are not intending for this to be a big consumer brand with related products," Brin says. "The whole point is that Alphabet companies should have independence and develop their own brands."
From a shareholder perspective, Alphabet is just the new name for the company that used to be called Google. Google shares will become Alphabet shares, and existing Google shareholders will continue to hold a stake in all of the Alphabet companies.
Full details of Alphabet's structure haven't been released yet, but Page did mention several ventures that will be pulled out of Google and may become independent ventures under the Alphabet umbrella:
In the short run, it won't affect you at all. Most of the popular Google products you probably use every day will stay under the Google umbrella and will continue to operate the way they always have.
If the launch of Alphabet affects users, it will be because some of those more ambitious projects pay off. For example, the Calico project hopes to extend human lifespans — that's probably not going to happen in the next year or even the next decade. Indeed, as I think Page himself would acknowledge, most of Google's ambitious bets are unlikely to pay off at all. But if a few of them do work out, it could have huge benefits.
Disclosure: My brother is an executive at Google.
At Walmart, Best Buy, or Whole Foods, the listed price on any item is usually what you pay. You might be able to get a discount with a coupon, but asking store employees for a discount generally won't work.
But not every industry works like this. Haggling is common in expensive industries, like car and jewelry sales. Because customers don't participate in these markets very often, there's less incentive to win customer loyalty with fair and transparent pricing, and more opportunities to dupe unsophisticated buyers into overpaying.
Or take the mattress industry. It's notorious for inflated prices, confusing branding, and gimmicks that trick consumers into overpaying.
Yet underpaying for a mattress can also be a big problem. After all, most people spend about eight hours per day — that's a third of their life — sleeping. And a good mattress will last a decade or more. So it's worth investing in a mattress that will help you wake up well rested every morning.
So how do you buy a mattress that will help you get a good night's sleep without getting ripped off? Read on for details.

Sleepy's is one of the nation's largest mattress chains. (John Greim/LightRocket via Getty Images)
Mattress salespeople's power comes from the fact that they know what a fair price is for each mattress and you don't. Many mattress stores invent hugely inflated "standard" retail prices and then offer "discounts" that still price the mattress way above its actual cost. Department stores are particularly notorious for this.
For example, a price tag might claim that a mattress normally costs $3,000 but is currently available for 60 percent off at $1,200. In reality, no one ever pays $3,000; $1,200 is the regular price. And if you negotiate effectively, you'll be able to get it for hundreds of dollars less.
As with any negotiation, the key to getting a better deal is to demonstrate that you know the product's real value and won't pay more. The easiest way to do that is by playing brick-and-mortar stores against online ones.
Once you find a mattress you like at a brick-and-mortar mattress store, use your favorite search engine to find the lowest price for that same mattress from an internet retailer. If you have a smartphone, you might be able to do this right in the store, though it might make sense to go home, do your research on a PC, and then go back to the store.
Once you know the best price offered by competitors, ask the salesperson to beat it. He or she might say no, in which case you can go to another store or just order online. But most stores will agree to match the price.



(Amber Rhea)

Of course, the mattress industry hates this kind of comparison shopping. To discourage it, some mattress manufacturers will give the same mattress different names in different stores.
For example, the popular Simmons Beautyrest line has different brand names at different stores. The "Beautyrest Recharge Allie" at Macy's is called the "Beautyrest Recharge Devonwood Luxury" at Sears, the "Recharge Signature Select Hartfield" at Mattress Firm, and the "Beautyrest Recharge Lyric Luxury" at US-Mattress.com. If customers don't realize these are names for the same mattress, it's harder for them to bargain effectively.
Fortunately, this kind of obfuscation isn't too hard to overcome. Often you'll be able to find charts online that tell you exactly which mattress models are equivalent. Otherwise, you should be able to figure it out by comparing features. US-Mattress.com, for example, says that the Beautyrest Recharge Lyric Luxury has 1 1/4 inches of AirFeel foam, an inch of AirCool foam, a half inch of GelTouch foam, one inch of energy foam, 476 "800-series" coils, and so forth. Ask your brick-and-mortar store for this kind of information on the mattress you want, and then find prices for similar mattresses from online retailers.


(Andrew Burton/Getty)

One thing that makes mattress shopping hard is that there's no fast, foolproof way to tell if a particular mattress is going to be comfortable. The only way to be sure is to spend a lot of time on it.
Experts recommend setting aside several hours for mattress shopping. Bring a book to the mattress store and spend about 15 minutes lying on each bed.
mattress salespeople's power comes from the fact that they know what a fair price is for each mattress and you don't
But even a leisurely in-store evaluation period won't guarantee that it will be comfortable for a full night's sleep. So you want to make sure that you can return a mattress if it proves less comfortable in your bedroom than it seemed in the store.
Stores' return policies differ dramatically. Many charge hefty fees. Some charge as much as half the price of the original mattress to swap it out for a new one. So before you agree to buy a mattress, make sure you understand its return policy.
Totally free returns are fairly rare, because it costs money to send a truck to retrieve the old mattress and bring a new one. But if a company charges high fees for returning a mattress, that's a reason to call around to see if another store will offer a more generous return policy.
Mattresses also come with separate warranties provided by the manufacturer. These generally range from 5 to 20 years. Longer warranties may be a sign of quality, but don't put too much stock into warranties longer than 10 years, since it's a good practice to replace your mattress after a decade of use.


Casper's cofounders on a Casper bed. CEO Philip Krim is in the center. (Casper)

We don't think of the mattress industry as a hotbed of innovation, but the last two years have seen the emergence of a new generation of direct-to-customer mattress companies. The most famous of these companies is Casper, but it faces competition from Tuft and Needle and Leesa.
These companies are all based on the same basic idea: they sell mattresses made of foam that can be compressed enough to fit in a box the size of a dorm fridge. That lowers shipping costs and makes it easier to get the bed into tight spaces. Once removed from the box, the mattress expands to its full size.

You might think a mattress that expands from a box wouldn't be very comfortable, but reviews so far have been generally positive. These mattresses use materials similar to those found in high-end memory foam beds that can cost thousands of dollars through conventional retail channels.
Casper and Leesa charge around $850 for a queen-size mattress. Tuft and Needle is even cheaper at $600. And because the companies sell their product directly to consumers via the web, there's no haggling.
To entice customers to give the mattress a try, Casper and its rivals have introduced another innovation: a free, no-hassle return policy. All three companies let you try their mattresses for free for 100 days, and then return them if you're not satisfied.
The big downside with these companies is a limited selection. Each company sells just one model (though it's available in a variety of sizes). All three companies have targeted the middle of the firmness scale. That means if you prefer a mattress that is particularly firm, or particularly soft, these products won't be a good option.
Also, some people find conventional coil mattresses more comfortable than high-tech memory foam ones. These mattresses do not come in a box the way foam mattresses do, though there is at least one online-only retailer that sells them.
"Real estate is by far the most screwed up industry in America," Glenn Kelman declared in a 2007 interview on 60 Minutes. Kelman, the CEO of the online real estate company Redfin, was following the familiar script of a disruptive internet startup. "We feel like things that Amazon or eBay or Yahoo have done for other industries, we can do for the real estate industry," he said.
Redfin showed homes for sale on an interactive map — a fairly new concept in 2007. And it had an equally novel business model: a do-it-yourself real estate service that let customers buy houses for a third of the cost of  a conventional agent.
You know how this story is supposed to turn out: The startup upends the old way of doing things, driving established competitors out of business. But that's not what happened. Over the next few years, Redfin was forced — slowly and reluctantly — to operate more like a conventional realty company. As Redfin beefed up its service, it charged more too. Today, Redfin owes its success as much to adapting to conventional real estate practices as to defying them.
When I met with Kelman at Vox headquarters in April, he spoke with the same quiet intensity as the man who denounced the real estate industry on national television eight years earlier. He still believes Redfin is changing the real estate industry for the better — and that Redfin's unique business model allows it to do things other technology and real estate companies can't. But the gospel Kelman is preaching today is more nuanced than the David-and-Goliath tale he told nearly a decade ago.
"I can't walk around with a swagger and talk about destroying an industry," he told me. "I am more confident than ever that this change that we're creating is going to continue and accelerate. But if that means that some other real estate agent at some other brokerage has a tougher time making a living, that's not a reason for me to throw a party."
A lot of early internet companies, including Yahoo, Google, and Facebook, were online-only operations. But as the internet becomes ever more deeply embedded in our daily lives, companies that straddle the line between the physical and online worlds will become ever more important. Redfin doesn't have as many users as online-only competitors Zillow and Trulia. But in some ways it's having a bigger impact on the real estate industry.
"To change the game, sometimes you have to learn the game," Kelman told me. "To affect the real world, you have to be in the real world."


Putting real estate listings on a map was the original innovation of Redfin. (Redfin/Vox)

I don't just write about Redfin, I'm also a customer; my wife and I bought a house with Redfin in June.
I became interested in Redfin after talking to my friend Adrienne about her home-buying process for an article about home-buying last year. "Redfin was perfect for a type-A person like me," she told me. "Their agents are very knowledgeable and responsive, but they are not going to hand-hold you through finding houses to view."
As a type-A person myself, that sounded pretty good to me. I'm good at finding and organizing information on the internet, so I didn't feel like I needed a lot of hand-holding.
"I can't walk around with a swagger and talk about destroying an industry"
Yet our Redfin experience wasn't actually that different from the experience we would have had with a conventional realtor. We were assigned an agent named Thomas, who took us on our first home tour. He answered questions about the home-buying process and encouraged us to keep looking until we found a property we wanted to buy. Later tours were performed by other agents, but Thomas was always available to answer questions and guide us through the process of making offers.
If we'd been shopping for a home back in 2007, when Redfin first entered the Washington, DC, market, we would have gotten a more extreme do-it-yourself experience. Back then, Redfin charged customers $250 to go on a home tour — if they had agents available to show the property at all.
Back then, Kelman thought customers would jump at the chance to do most of the work themselves and pocket thousands of dollars in extra savings. He was wrong.
The early Redfin business model attracted a small, hardcore fan base, but it gradually became clear that it wouldn't go further than that. The per-tour fee stressed people out. Also, first-time homebuyers have a lot of questions that Redfin wasn't really set up to answer. When Redfin surveyed its customers, the feedback was clear: They wanted to be able to tour more homes and ask more questions, even if the service cost more.
"We didn't want to show houses because we knew it would take a decade to hire all these people," Kelman told me. "And we knew the shape of the business's profits would be a lot different."
"Redfin started life as a cult, but our goal has always been to become a religion"
The most successful internet companies exploit the fact that computers are cheap and human labor is expensive. For example, because almost all of Facebook's interactions with users are automated, a few thousand employees can serve a billion users. The more labor-intensive Redfin's service became, the slower and more arduous it would be to grow it and eventually turn a profit.
This is probably why Zillow and Trulia, which were founded around the same time and also displayed real estate listings on a map — never copied Redfin's brokerage model. They just ran websites and charged traditional real estate agents for referrals. That low-overhead approach allowed Zillow and Trulia to grow rapidly — today Zillow is the market leader with almost 10 times as many users as Redfin.
But by 2008 Redfin was already in the brokerage business. And it had become clear that the original, bare-bones brokerage model would never appeal to a mass audience. So in November 2008, as the real estate market was imploding, Redfin took the plunge.
"Redfin started life as a cult," Kelman wrote on the Redfin blog. "But our goal has always been to become a religion."
Shifting to a full-service model required hiring a lot more real estate agents. And that, in turn, would cost money. Traditionally, a buyer's agent gets 3 percent of the sale price. Before, Redfin had kept 1 percent of the sale price and rebated the other 2 percent to customers. Now it was keeping 1.5 percent, a 50 percent increase.
In 2012, Redfin beefed up its service again, hiring 50 more agents so it could reduce each one's workload and give agents time to get to know customers personally. Once again, the improved service came with a higher price. Today, Redfin often keeps more than 2 percent of a home's sale price, rebating less than 1 percent to the customer.
Buying a house isn't like other consumer purchases. I can order a book or an airline ticket in minutes. By contrast, I spent months poring over housing listings to find the perfect property. And because I'd never purchased a house before, I had a lot of questions that I wanted a human being to answer.
And after almost a decade in the business, Redfin still hasn't automated many key steps in the home-buying process. For example, the company doesn't offer an automated way to get estimates of home values — when we needed guidance on how much to offer for a property, we emailed our Redfin agent for a personalized estimate. That's probably because publicly available data on homes is unreliable — Zillow offers a "Zestimate" of home values, but these figures are not very reliable.
Similarly, Redfin has done little to change the process of making an offer on a home. It does use a service that lets customers sign PDF documents online. But the documents themselves get filled out by Redfin agents and sent to customers by email — there was no way for me to prepare an offer on my own.
Ultimately, real estate has proved less prone to disruption than other industries that have been transformed by digital technology. At first glance, it strikes some people as outrageous that someone could earn more than $10,000 to help someone buy a house.  But when Redfin offered customers a radically cheaper alternative, most of them didn't want it. Buying a home is the biggest financial decision most homeowners will ever make, and so most customers are willing to pay a premium to make sure they don't make a mistake.


(Timothy B. Lee/Vox)

In its early years, Redfin was more popular among buyers than sellers. Kelman says there are a couple of good reasons for this. One is that Redfin's original innovation — putting real estate listings on a map — was targeted at buyers. Also, sellers are older, on average, than buyers, and therefore less likely to take a risk on an untested new online realty service.
But more recently, Redfin has attracted a significant number of sellers. And Kelman sees that as a big opportunity.
"Uber could have waited for self-driving cars, but they didn't"
"When you sell a house, you're the one who gets to make the rules for how it's going to be sold," Kelman says. Sellers decide how homes are presented online, when and how offers are accepted, and more. The power of sellers meant that Redfin had limited opportunity to innovate when it was primarily a website for homebuyers. But now that Redfin is representing a lot of sellers, it gets more say in how homes are sold.
Redfin now discounts more aggressively on the seller's side of the market than on the buyer's side. The company generally takes a commission of more than 2 percent when it represents a buyer. For sellers, it takes 1.5 percent, and in Washington, DC, it is experimenting with charging just 1 percent — a third of the 3 percent fee many real estate agents charge sellers.
Redfin has also invested in technology to show 3D walk-throughs of homes it's trying to sell.
And while he refuses to provide details, Kelman hints that Redfin is working on other ways to improve the home-selling experience. He points out that in Australia, for example, homes are more often sold in auctions. It would be hard for a conventional realtor to conduct an online home auction, but Redfin's broad audience of potential buyers might give it a unique opportunity to experiment with different approaches.
Redfin may or may not be changing the real estate industry, but it's thriving as a business. In December, the company raised $70 million to fund expansion into new markets. That's on top of $95 million the company received in earlier fundraising rounds.

Redfin has operations in 36 states and the District of Columbia (Redfin)
Redfin has long aspired to be a national brand, but until recently it was limited to a handful of major metropolitan areas. Redfin's labor-intensive business model meant that expanding into new markets was an expensive proposition, and it took a while to demonstrate that the investment was worth it. But now Kelman says they've done it.
"The business has become very explicable to investors," Kelman says. "Anyone can understand how long it's going to take us to build share, what the profit from that market will be. And once you have that understanding, it's very straightforward to get capital."
The latest capital infusion has allowed Redfin to add more than two dozen new markets since the start of the year. The company now serves more than 70 markets overall. Recent additions have included El Paso, Texas; Reno, Nevada; and Dayton, Ohio.
There's a danger that bulking up will harm Redfin's ability to innovate. The larger Redfin's staff is, the harder it will be for new innovations to percolate throughout the company's nationwide workforce, and the more challenging it will be to keep standards of customer service high.
But Kelman argues that Redfin's growing staff of real estate agents will let it innovate in ways that a purely virtual company couldn't. He draws a parallel to Uber and Lyft, two other technology companies whose services depend on large workforces. "You could argue that Lyft or Uber isn't disruptive because you still have a human being driving a car," he says. "Uber could have waited for self-driving cars. But they didn't, and I don't know many people who aren't glad."
We're used to thinking of the internet and the physical world as different domains. But in a world where everyone has the internet in their pocket, the biggest opportunities may be for businesses that have a foot in each world, using digital technology to make a conventional service faster, cheaper, or better.
Correction: I misattributed a real estate agent's critique of Zillow that appeared in the Washington Post to the Washington Post itself.
The prominent venture capitalist Chris Sacca has endorsed Twitter co-founder and interim CEO Jack Dorsey to be the company's permanent CEO. His opinion matters because Sacca was an early Twitter investor, holds a lot of Twitter stock, and is also well-known in the investing world. Sacca explained his reasoning in a tweetstorm:
The big question is whether Dorsey is willing or able to do the job. After he co-founded Twitter, Dorsey left to become the CEO of the successful payment company Square. Being CEO of Twitter and CEO of Square are both full-time jobs in their own right, and it's not clear if Dorsey could do both jobs well. On the other hand, some CEOs have managed it. For several years, Elon Musk has been running both Tesla and SpaceX, and seems to be doing well in both jobs. But Musk is an extremely unusual human being.
The Bureau of Labor Statistics announced today that the American economy added 215,000 jobs in July, with the unemployment rate holding steady at 5.3 percent.
This was very slightly low relative to the expectations of economic forecasters, who'd told a Bloomberg survey taken in the days before the report that they were expecting 225,000 jobs and no change in the unemployment rate.
Here's what we're looking for in today's jobs report. pic.twitter.com/1oUwmlveVf
More important in some ways than the preliminary data from July is the revisions to the May and June data that collectively added 14,000 jobs to the overall picture.
Due to some scheduling quirks, this is one of the least-anticipated monthly jobs reports in some time. That's because the Federal Reserve does not hold a monetary policy meeting in August, so all this data will be revised and updated in early September in advance of the next meeting. People are very curious as to whether Fed Chair Janet Yellen and her colleagues will raise interest rates for the first time in many years at that meeting, but today's jobs report doesn't tell us anything about that question that won't be overridden in a month.
At first glance, the online travel booking industry seems pretty competitive. You can book airplane tickets and hotel reservations using Expedia, Travelocity, Orbitz, Priceline, Hotels.com, Hotwire, and Kayak, among many other sites. The problem is that all of these brands are owned by three big companies — Expedia, Orbitz, and Priceline.
Skift
As this chart from the travel site Skift shows, the online travel industry used to have four big players. But earlier this year, Expedia bought Travelocity, reducing competition down to three big companies. Now Expedia wants to acquire Orbitz, which could give Expedia control of as much as 75 percent of the online travel booking market in the United States and only one major competitor.
As the Washington Post's Brian Fung notes, the hotel industry is lobbying the government to stop the deal. And federal regulators could block the transaction using antitrust laws. The question is whether critics can convince them that the deal would be bad for consumers.
This is a market where size really matters; the larger Expedia gets, the more leverage it has in negotiations with hotels, airlines, and others who provide travel services. Hotels fear that Expedia's growing share of online bookings will allow the company to charge providers larger booking fees — fees that hotels will ultimately pass along to customers.
And this is a relatively mature industry, so it won't be easy for new companies to build competing sites. Google has recently shown some interest in the market, but so far has chosen not to compete directly with Priceline and Expedia by offering online bookings. So if the government lets Expedia buy Orbitz, we could wind up with an online travel duopoly for the foreseeable future. That could be bad for both the travel industry and travelers.
Vox's Ezra Klein says that Carly Fiorina won the first Republican debate on Thursday, which featured candidates who didn't make the cut for the top-tier debate later in the evening. And lots of other pundits — on the left and right — agree. Her strong debate performance will cause many voters, donors, and political pundits to give her candidacy a second look, and could propel her onto the main stage for future debates.
Fiorina is an unorthodox presidential candidate with an interesting life story. In the 1990s, she broke the glass ceiling to become one of the first women to lead a Fortune 500 company. But she had a rocky tenure there and was fired after six years on the job. Since then, she's battled cancer and made an unsuccessful run for US Senate.
Fiorina argues that her experience running a Fortune 500 company gives her executive skills and an outsider's perspective that would be valuable in the presidency. But she still faces an uphill battle to convince voters to choose her over candidates with a more conventional background in elected office.
With no experience in elected office and a limited base of political support, Fiorina has fared poorly in the polls, so she was not able to participate in Thursday's prime time debate. Instead, she was relegated to the earlier debate alongside long shots like George Pataki, Jim Gilmore, and Lindsey Graham.
But her clear, confident answers to the moderators' questions, and her attacks on Hillary Clinton and Donald Trump, helped her stand out from the crowd.
"Hillary Clinton lies about Benghazi, she lies about emails," Fiorina said. "She is still defending Planned Parenthood. And she is still her party's frontrunner."
Fiorina also attacked Republican frontrunner Donald Trump.
"I didn't get a phone call from Bill Clinton before I jumped in the race," she said. "Maybe it's because I hadn't given money to the foundation or donated to his wife's Senate campaign."
Fiorina was widely hailed as the winner of the early debate by pundits. "Carly Fiorina won the ‘Happy Hour’ debate. By a lot," gushed the Washington Post's Chris Cillizza. Chris Wallace and George Will on Fox News both concurred.


(Grabowsky/ullstein bild via Getty Images)

Fiorina is best known as the former CEO of Hewlett-Packard. Fiorina was named to that post in 1999, after two decades as an executive at AT&T and its spinoff, Lucent. Her appointment to run HP instantly made her one of the most prominent women in the business world.
Almost immediately, Fiorina became a polarizing figure at HP and in the technology industry more generally. She was the first outsider to take the helm of the company and also the first non-engineer, causing some HP veterans to wonder if she could really understand the company's engineering-centric culture. Fiorina's supporters, by contrast, saw bringing an outsider to the firm as a perfect way to shake up the company's insular culture.
And Fiorina wasted no time in shaking up HP. Her biggest move was to acquire one of the company's biggest rivals, Compaq. Fiorina argued that the deal would cement HP's leadership of the computer industry, but critics — including Walter Hewlett, the son of co-founder William — argued that HP was hitching itself to a company with poor growth prospects, and that integrating the two huge companies would be expensive and distracting. Fiorina won a shareholder vote to approve the merger by a razor-thin margin, and the merger was completed in 2002.
Even with a decade of hindsight, it's hard to say for sure who was right about the merger. Combining the two companies did prove difficult and expensive, just as critics predicted. Fiorina lost the support of her board — and her job — in 2005. "I was fired in a boardroom brawl," Fiorina said earlier this year.
HP's stock price fell from around $50 when she took over HP in 1999 to around $20 when she left her job in 2005. But of course that decline isn't entirely Fiorina's fault — technology companies in general were struggling during the later years of Fiorina's tenure.
In 2010, two successful Republican businesswomen ran high office in California. Meg Whitman, former CEO of eBay, ran for governor. Fiorina ran to represent California in the US Senate. Both women lost.
Fiorina ran against incumbent Sen. Barbara Boxer (D-CA). She ran in a good year for Republicans — it was the year a Tea Party wave gave Republicans control of the House — but she was running in heavily Democratic California against a popular incumbent. Boxer also tried to make Fiorina's tenure at HP as a liability, repeatedly mentioning her decisions to lay off 30,000 HP workers.
Fiorina's campaign featured what was probably the strangest and most baffling ad of the 2010 election cycle. It portrayed her primary opponent, Tom Campbell, as a "demon sheep," complete with glowing red eyes:

Boxer beat Fiorina by a 52-to-42 margin. You might not expect a losing Senate campaign to be the model for a presidential run five years later, but that's exactly how Fiorina sees it today.
"When I entered the California Senate race one year before the election — bold, because I had just finished chemotherapy — all the polls and all the pundits said I didn’t have a shot," she said in April. "I lost the general election, but I won more Republican votes, more Democratic votes, and more independent votes than virtually anyone else running anywhere in the country that year."
What does an engineer look like?
Isis Anchalee is a platform engineer at a company called OneLogin who appeared in a recruiting ad for her company. The ad sparked some sexist social media commentary from people who implied that this actual image of an actual woman who is an actual engineer was not a plausible "image of what a female engineer looks like." She launched the  hashtag #ILookLikeAnEngineer in response to show that women who are also engineers look like ... women.
Isis Anchalee wrote on Medium: "This is literally just ME, an example of ONE engineer at OneLogin."
Does this look like an engineer? Yes.
Anchalee, who is also an engineer, wrote: "I’m just a human and I prefer to keep my life simple/reserved, but it blows my mind that my fully-clothed smiling face with unbrushed hair and minimal makeup on a white wall is seemingly more controversial in some communities than this simply because of my gender."
Software Engineer developing simulations #ILookLikeAnEngineer pic.twitter.com/7CF9hjDQJu

Oh hey, #ILookLikeAnEngineer #ILookLikeADork cc @isisAnchalee pic.twitter.com/9u2W5EqthT

#ILookLikeAnEngineer #notjustforboys #riyadhmetro #designteam #AtkinsProject #Atkinsgraduate @atkinsglobal pic.twitter.com/j1SpaycaL8
My mom, Perl hacker, 20+ years sys analyst. Nuclear physicist. Started coding on punch cards! #iLookLikeAnEngineer pic.twitter.com/0VhMB56ps6

#MomOps to 3 {autism, T1 Diabetes, & Tethered Spinal Cord} Ops, Infrastructure, Full Stackaroni #ILookLikeAnEngineer pic.twitter.com/zcr3NrmfEK

Basically, every time you input text in Windows there are a bunch of women behind it all! #ILookLikeAnEngineer pic.twitter.com/STmAT2JS6v

I run the npm registry. #ILookLikeAnEngineer pic.twitter.com/hfpdDRfYRp

i'm a motorcycle babe and i design the network sowtware that works #ILookLikeAnEngineer pic.twitter.com/C8kJLcvnim

#ILookLikeAnEngineer software developer at a major record label        pic.twitter.com/fN2LqfiWw4

Deborah is a #ManyMentors #Mentor & BioEng #PhD student researching osteochondral repair!   #ILookLikeAnEngineer pic.twitter.com/rPLajrTq5R

I build awesome things #ILookLikeAnEngineer pic.twitter.com/E0LxxFADSf

#code #chicken #carting #ILookLikeAnEngineer cc @Andela pic.twitter.com/sxCyLrAZIJ

Just a few of the faces we've seen around @EmbryRiddle College of Engineering at our campuses. #ILookLikeAnEngineer pic.twitter.com/DRmR4GWACE

IntelUK: What do #Intel engineers look like? This. #ILookLikeAnEngineer pic.twitter.com/JgyUwIiQfo

#ilooklikeanengineer because I happen to be a Signalling engineer. Now mind the closing doors... pic.twitter.com/NC8YzO5mlu

#ILookLikeAnEngineer - software engineer staff for aviation and pride lead @LockheedMartin! #LGBT #diversityMatters pic.twitter.com/bdRYoIcee5

When I say I'm a Network Engineer: "oh right so you're smart too" as if it's a big compliment. #ILookLikeAnEngineer pic.twitter.com/KKjjEkY9Om

I help build product people need. Smile a Lot and love nappy hair! #ILookLikeAnEngineer #Pikiz #Girlwhocode pic.twitter.com/ePQGzvak4s

LOVELOVELOVE this! #ILookLikeAnEngineer pic.twitter.com/Nnue4Q5Ht4

Hello, engineers! I made a Twitter photo generator to share your #ILookLikeAnEngineer pride: http://t.co/eRGOGwJHZM pic.twitter.com/Mz9wCWyweC
In case you're not sure if you look like an engineer, check out Alisha Ramos's #ILookLikeAnEngineer generator and see for yourself.

Syracuse University researchers shared a surprising fact recently — the federal prosecution of white-collar crimes is at a 20-year low in 2015, down by nearly 4,000 annual cases when compared with 1995 (h/t Christopher Ingraham):
Syracuse University's Transactional Records Access Clearinghouse (TRAC): "The long term downward trend in the prosecutions of these matters going back to FY 1995 is more clearly shown in Figure 1. The vertical bars in Figure 1 represent the number of white collar crime prosecutions recorded each fiscal year. Projected figures for the current fiscal year are shown. Each presidential administration is distinguished by the color of the bars."
The US Department of Justice Executive Office for United States Attorneys (EOUSA) uses the following guidelines — and as Syracuse University researchers note in their latest TRAC report, the changing roles of local, state, and federal agencies might account for part of the drop in total federal prosecutions:
White collar crimes — as defined by the EOUSA — involve a wide range of activities including the violation of health care, tax, securities, bankruptcy, antitrust, federal procurement and other laws. Because such enforcement by state and local agencies for these crimes sometimes is erratic or nonexistent, the declining role of the federal government could be of great significance.
The long list of the crimes included in the definition of white-collar crime includes such a wide range of activities that multiple federal agencies are involved. The below (poorly colored) pie chart shows that going after white-collar crime isn't a challenge of any single agency:
The FBI accounted for 27.8 percent of prosecutions; IRS/Dept. of Treasury 15.8%; Secret Service 13.1%, USPS 8.3%; SSA 5.3%. The "other" category includes HHS (4.9%), ICE (3.5%), Customs (3.0%), and other Homeland Security branches (2.4%).

As mentioned earlier, it's possible that the drop in white-collar prosecution is partly a matter of recording which local, state, and federal entities prosecute white-collar crime.
A significant portion of the total decline is seen in the records of the biggest single federal agency to prosecute these offenses — the FBI. As TRAC reported in 2013, the FBI's prosecutions alone dropped from nearly 5,000 in 1993 to 3,000 by 2013, accounting for a large portion of the total decline in white-collar prosecutions recorded thus far in 2015.
TRAC
A dramatic downward trend begins, as shown above, in 2002 and likely relates to the rising salience of terrorism as an FBI mission. As TRAC stated, based on its research in 2013, "The 9/11 attacks of 2001 prompted the agency [FBI] to focus more and more of its investigative powers on trying to deal with international and domestic terrorism and weapons of mass destruction."
The Trans-Pacific Partnership, a trade deal the United States is negotiating with 11 other Pacific Rim nations, is a big, complicated document. But if you want to boil the fight over the deal down to its essence, it would be hard to do better than this sentence from Jonathan Weisman at the New York Times, discussing why last week's negotiations in Hawaii didn't produce a deal:
Virtually all of the parties hated American protections of pharmaceutical firms, but a compromise on that issue could cost the support of Republicans in Congress.
This is referring to "data exclusivity," an obscure but important provision of US pharmaceutical regulations. If the US gets other countries to adopt its approach, it could lead to less competition and higher prices for medicine in other TPP nations.
Before a company can introduce a new drug, it must convince the Food and Drug Administration that it's safe and effective. To prove that, companies conduct expensive clinical trials. Sometimes a second company will develop a drug that's chemically similar to an earlier drug and will want to use data from the first company's clinical trials in its own application. But for an important class of drugs called biologics, US law bars companies from doing this for 12 years, forcing these generic drugmakers to either do their own, redundant clinical trials or to wait until that period is over.
The US is trying to use the TPP to export this system to other Pacific Rim nations, most of which have data exclusivity periods for biologics of five or eight years. That would mean higher drug prices around the world, which is why public health groups like Doctors without Borders hate it.
Even the Obama administration — at least the part of the administration in charge of writing the president's budget proposals — thinks US law is too generous to drug companies. The administration has proposed reducing data exclusivity from 12 years to seven here in the United States, even as it pushes for treaty language pushing the rest of the world in the opposite direction.
The broader point here is that while the TPP is usually described as a trade deal, President Obama and his (mostly Republican) allies in Congress are making it clear that freer trade isn't necessarily their highest priority. The deal is widely seen as a vehicle for doing favors for special interests in the United States — some of which have only a tenuous connection to trade.
When Amazon gave 60 Minutes a sneak peek at its drone delivery plans in 2013, it was easy to imagine that it was just a publicity stunt. The announcement was the day before Cyber Monday, the unofficial start of the holiday shopping season online. And the idea of drones delivering packages seemed a bit like science fiction.
But last week came the latest sign that Amazon is deadly serious about getting into the drone delivery business. In a pair of brief white papers released at a NASA conference in Silicon Valley, Amazon laid out its vision for regulations that would govern a world where thousands — perhaps millions — of drones buzzed over American cities every day.
Drone technology today is in a similar place to automotive technology in the early 20th century. Cars existed back then, but were still a niche technology limited to hobbyists and rich people. There were so few cars that the rules and infrastructure that support cars today — stoplights, speed limits, controlled-access freeways, parking laws, and so forth — mostly weren't needed. That changed as cars became mainstream.
Amazon thinks we're on the cusp of a similar transition with drones. The e-commerce giant believes — or hopes — that there will be exponentially more drones in the sky in a decade than there are today. And the company is advocating new rules to ensure that those drones don't crash into each other, or into conventional planes, birds, or other obstacles.
Amazon's vision for drone traffic management looks like this:
Amazon.com
Above 500 feet is "integrated airspace," where conventional aircraft fly today. Current regulations place strict limits on flights below that. But Amazon wants to carve out a zone between 200 and 400 feet for a new class of small, autonomous, unmanned vehicles — like Amazon delivery drones.
To prevent crashes, Amazon would establish high technical standards for vehicles that use this new airspace. Autonomous drones would need a GPS and highly accurate geospatial data, a reliable internet connection, the ability to communicate wirelessly with other drones, and sensors to detect and avoid collisions with other objects in the sky.
The result could be a dramatic transformation of the space above us. Right now, people see an occasional airplane or helicopter overhead — usually thousands of feet in the air. But in the future, drones buzzing overhead could be as commonplace as cars driving on a nearby street. And Amazon hopes that many of those vehicles will be owned by Amazon and delivering packages to customers in less than an hour.
Three months ago, a Seattle businessman had an epiphany. Dan Price, the CEO and co-owner of Gravity Payments, concluded that everyone in the company — including him — would be happier if he took a big pay cut and used the money to give his lowest-paid employees big raises. So he instituted a new policy where within three years, every employee in the company would make at least $70,000 per year. For some employees, that meant tens of thousands of dollars in raises.
You might think this was a win-win situation for everyone. A bunch of employees got raises. Price thought he'd get more satisfaction from helping his employees than from making more money himself. No one else's salary went down.
But as the New York Times reports, the plan made a lot of people upset. Most upset were employees who were already making salaries near the new $70,000 minimum. They felt that giving formerly much lower-paid employees the same salary as them deprived them of their status as highly paid employees. Two employees even quit in protest after the raises were announced.
Also upset were some of Price's peers in the business community. They felt the $70,000 salary minimum was unrealistic, and they worried that they'd now face pressures for higher wages from their own employees.
The lesson here is that employee compensation is a lot more than a coldly rational calculation of costs and benefits. Financially speaking, it doesn't hurt one worker when another worker gets a raise. But in practice, people's salaries are seen as a key way employers communicate approval of their subordinates. It doesn't feel good if your co-worker gets a raise and you don't.
And that's especially true if employees feel the pay structure doesn't recognize the contributions of a company's longest-serving and hardest-working employees. One person who felt this way at Gravity Payments was Maisey McMaster, a 26-year-old who "joined the company five years ago and worked her way up to financial manager, putting in long hours that left little time for her husband and extended family."
McMaster feels that by only raising salaries for workers at the bottom of the pay scale, Price failed to properly recognize workers like her who had devoted years to building the company. She left after the raises were announced. She told the Times that Price "gave raises to people who have the least skills and are the least equipped to do the job, and the ones who were taking on the most didn’t get much of a bump."
Here's a small sign that one of the drivers behind US income inequality may have reversed itself over the past few years.
The chart below compares the hourly compensation of all private sector workers (in red) to the hourly compensation of just production and nonsupervisory (in blue) private sector workers:

What this chart shows is that although wage growth has been generally slow since the start of the recession in 2007, wage growth for the bottom 80 percent (the blue line) has actually been a little bit faster than wage growth for all workers (the red). The wage gap between managers and non-managers, in other words, is narrowing.*
That doesn't mean that overall income inequality is declining, however. Rich people also tend to have investment income from owning financial assets such as stocks and bonds, and very rich people — almost by definition — own a lot of financial assets. These asset prices have recovered from the recession more robustly than wages, thus creating a whole different source of inequality. But wage inequality was a major force in the 1980s and 1990s, and the news that it seems to have gone into reverse is interesting and important.
* Note: The "all workers" data set only goes back to 2006, so we can't do any useful historical analysis of this. But the "production and nonsupervisory" series goes back to 1964, and we know it covers about 80 percent of the workforce. We also know that average pay in the "all workers" series is higher, which makes sense since the other 20 percent is composed of managers and supervisors.
The technology boom of the 1990s ended in a spectacular wave of failure, as huge swaths of the sector proved to be based on fundamentally unsound business models.
Today's business models look, on the whole, to be much stronger. And that's why I've never believed the dozens of people who've spent the past four years crying bubble. But Conor Sen of New River Investments has a very smart post making the point that the expansion cycle can fail for other reasons. In particular, he says, "there’s just not enough 'stuff' to go around."
To keep growing, the technology sector needs to keep adding skilled workers and office space, and both San Francisco and Silicon Valley are running out of both. That means that even companies with perfectly plausible business ideas are going to find costs rising faster than revenue, and the sector is going to need to stall out until some companies fail and free up more resources for the others.
Jason Freedman from the real estate website 42Floors has a fascinating observation that could spell the end of the current cycle of expansion in the internet startup sector. It's not about an investment bubble or any problems with the basic product of any of today's startups. Instead, it's a funny observation about the commercial real estate market.
42Floors
Office rents are skyrocketing and vacancy rates plummeting in San Francisco. But there's always more money.
The real problem, he writes, is that many of the city's landlords "are trying as hard as they can to get non-startup tenants right now. We at 42Floors recently experienced this firsthand when we were searching for our new office space."
And it's not about money. It's about risk. "Landlords look at their tenants as a portfolio of revenue streams and risks," Freedman says, and they want to hedge against a possible bust in the startup market by making sure that they don't have a portfolio that's too crowded with internet startups. There comes a point when a landlord is willing to take a significant hit on the rent to be leasing to some lawyers or accountants or architects or anything that won't vanish if a wave of venture capital skepticism suddenly sweeps the country.
Of course, your company always could try to leave the ultra-hot San Francisco/Silicon Valley real estate market in favor of someplace more affordable. There's plenty of office space for rent in Cleveland or Detroit and no problem building more in Phoenix or San Antonio.
The problem is that almost any move you could make to mitigate your real estate problems is going to exacerbate your skilled labor problem.
The reason is that startups are, inherently, risky places to work. But if you have the kind of skills to get a good job at a startup, you can greatly mitigate that risk by living in a city that's full of similar startups that need people with similar skills. You mitigate that risk, in other words, by living in Silicon Valley or San Francisco.
Which means that if you're a company that needs startup workers, you're going to find that moving to Cleveland to avoid the Bay Area office crunch is going to leave you with a shortage of workers. Heck, even moving to Oakland is going to leave you with a shortage of workers since, at the end of the day, you'll be at a recruiting disadvantage vis-a-vis companies that can offer a more pleasant commute.
These supply constraints on the startup economy are, of course, surmountable, and given time they will be surmounted. More people are learning to code to take advantage of job opportunities there, and smart companies are making efforts to be more attractive workplaces for a more diverse population in order to be able to draw on a broader talent base.
But unless the Bay Area changes its attitude toward new building permits, the office space crunch will remain, and there will be a fundamental physical constraint on the number of people who can find housing in the technology hub.
Rezoning would be the easiest fix but, in some ways, the most politically unlikely one. Breaking the bottleneck, then, will eventually require some new technology hubs to emerge in places that are more eager to embrace new construction. But until that happens — and it's difficult to pull off — the "only so much stuff to go around" problem will be with us, and technology booms will be somewhat self-limiting.
Every quarter the government releases its estimate for the gross domestic product of the United States. At the same time, it also releases an estimate for the gross domestic income of the United States. Confusingly, if you crack open an economics textbook it will tell you that GDP and GDI are the same thing — identical by definition, as if you were to release a person's mass and a person's weight-at-sea-level-on-planet-Earth simultaneously.
And yet Wednesday the government announced that it is going to start tracking a third measurement of the United States of America's economic activity — gross domestic output, which is defined as the average of GDP and GDI.
Yes, the average of two identical quantities.
And no, it's not a joke. There is good reason to believe that this will improve the accuracy of our understanding of the state of the economy, and that in the future we may find ourselves using GDO as our standard metric of economic activity. GDP itself is relatively new to the game, and used to be overshadowed by gross national product, so there's no reason to think it should reign supreme forever. But more than a tweak to government accounting, the switch is a window into the gap between the pristine clarity of economic theory and the murky swamps of economic reality.
The canonical equation that defines GDP goes like this:
GDP = Government Purchases + Consumer Purchases + Business Investment + Exports - Imports
And the canonical equation that defines GDI goes like this:
GDI = Employee compensation + Profits + Taxes - Subsidies
The key trick, however, is that these quantities are equal.
The total value of everything sold is the same thing as the total earnings amassed by selling things. It just is.
But it isn't:
Council of Economic Advisors
The good news is these two bars do add up to being pretty similar-looking. The bad news is that $300 billion is actually quite a lot of money. The statistical discrepancy is about equal to the entire economic output of Israel or Denmark. It's similar in size to the combined economic output of Alaska, Maine, South Dakota, Wyoming, Rhode Island, Montana, and Vermont.
Those are, admittedly, small states. But if the government just forgot to count them in a survey, people would think it was a big problem.
The problem is that while GDP and GDI are, in theory, identical in practice they are constructed by adding up data sets that, like all human endeavors, are measured by human beings. We can't measure household consumption perfectly and we can't measure workers' compensation perfectly either. In life, nothing is perfect.
But just as you can improve your understanding of the state of public opinion by averaging several polls to reduce sampling error, by averaging together GDP and GDI you should be able to reduce the extent to which measurement error biases your estimate.
Taking two different stabs at measuring the same thing and then averaging them together, in other words, is more likely to get you close to the true quantity than taking either measurement approach alone.
At a conference, an economist once observed to me that one problem with fancy economists with jobs at prestigious schools is that they get to spend all their time working with theoretical quantities. Less-fancy economists with less-fancy jobs need to spend more time working with the murky and often annoying process of actually assembling economic data.
That can leave them more attuned to the practical policy problems that arise due to measurement error and ambiguity.
For example, in 2009 the Obama administration and their friends in Congress outlined an economic stimulus package that they thought would be roughly appropriate in size given the scale of the recession. What they did not know what that subsequent revisions to the data would reveal that the economy collapsed much more rapidly in the winter of 2008-'09 than the initial estimates had shown. Had they been more mindful of the error-prone nature of initial data, they might have designed their legislative proposal somewhat differently.
Another example is that the tax code provides for investment income to be taxed at a lower rate than labor income.
This is supposed to encourage well-to-do people to save and invest in a way that encourages long-term economic growth rather than squandering their earnings on yachts and fancy cars. But it also creates a large incentive for people to simply find ways to classify their income as investment income. Thus the general partners in hedge, venture capital, and private equity funds managed to identify a legal loophole through which much of their management fees can be classified for tax purposes as investment gains.
This costs the Treasury money, of course, but it also creates misleading official statistics — labor income vanishes and reappears as investment income even though nothing in the real world has changed.
There's been a lot of media discussion recently of robots taking humans' jobs. A Gartner report last year claimed that "one in three jobs will be converted to software, robots and smart machines by 2025." Obviously it's impossible to know what will happen in the future. But one sign that robots aren't having much of an impact on the livelihood of workers today comes from this chart from the International Federation of Robotics:
International Federation of Robotics
The first thing to notice about this chart is that the numbers are tiny. Manufacturers shipped a record number of robots in 2013, but the total number of robots shipped worldwide — 178,000 — is surprisingly small. In a global labor market with billions of workers, that just isn't enough robots to have much of an effect.
The same is true if you focus on the United States. In North America, factories ordered 23,700 industrial robots in 2013, a tiny fraction of the 12 million workers in America's manufacturing sector or the roughly 1 million new workers the US economy adds each year.
The second thing to notice about this chart is the surprisingly slow growth of robot shipments. About 70,000 robots were shipped in 1995. After 18 years, the figure was only about 2.5 times larger.
The IFR predicts that growth is about to accelerate. It projects that robot shipments will reach 288,000 by 2017, which would represent an impressive 13 percent annual growth rate over four years. If that pace of growth occurred for a couple of decades, the world's workers could face a serious threat sometime in the 2030s. But right now, there just aren't enough industrial robots to have a significant effect on the job market.
Thanks to Jim Bessen for pointing out this chart to me.
Correction: This post originally misstated the number of robots sold in the US in 2013.
Rick Perry has a plan to change the way the federal government regulates Wall Street, and it is … kind of left-wing. Almost shockingly so for the very conservative former governor of Texas.
He laid out his plan in a Wednesday speech. He hit on many familiar conservative themes, but also some not-so-familiar ones. For example, he credited Texas's relatively strong weathering of the Great Recession in part to strict financial regulation. "But there’s another thing we have in Texas that the rest of the country could learn from," he said. "We regulate, in an intelligent way, the use of a type of mortgage called 'cash-out refinancing.'"
The Perry campaign does not have a ton of specific details to offer about his ideas, and financial regulation is certainly an area in which the devil is frequently in the details. But in broad strokes, Perry has some pretty good ideas combined with a standard Republican aversion to any kind of consumer financial protection. His proposals are aimed, overwhelmingly, at reducing the amount of debt in the financial system both by regulating big banks and by reducing the tendency of federal programs to encourage middle-class households to borrow heavily to buy houses. The total impact would be a financial system that is considerably less fragile, albeit one in which it is also easier for financial firms to make a quick buck by pulling the wool over consumers' eyes.
The headline here is that Perry comes close to calling for a breakup of big multi-line financial conglomerates, with his fact sheet saying that "requiring banks to separate their commercial lending and investment banking practices should be considered." This is something liberals have made a lot of noise about since the financial crisis, and that Hillary Clinton has declined to endorse even as Martin O'Malley and Bernie Sanders have. But Perry's backup idea — "alternatively, require these banks to hold a significant additional capital cushion for their trading activities" — is probably a better idea.
What this means is that Perry would make a more complicated bank be more cautious about borrowing money than a similarly sized but less-complicated entity would have to be.
This would make complexity less profitable and create a financial incentive to shrink and simplify unless you're really reaping massive efficiency gains. At the same time, it would ensure that a complicated bank is especially unlikely to go bust — and thus that difficult questions about how to deal with the failure of such a bank are unlikely to arise.
Unfortunately for fans of ideologically unexpected financial regulation proposals, Perry's presidential campaign seems to be going nowhere fast. He's currently polling in ninth place in Iowa and 11th place nationally, so these ideas have relatively little chance of impacting the course of national politics.
Still, on paper Perry has considerable strength. With 14 years as governor of the nation's second-largest state on his résumé, he's about the most experienced candidate in the field. And he has the best story of economic achievement to tell of anyone in the race. His ideas on finance, meanwhile, seem to indicate that he's a more nuanced and creative thinker than his national reputation might suggest. But thus far, none of that is doing him any good.
Is the AI apocalypse near? Movies like the Terminator franchise and the Matrix have long portrayed dystopian futures where computers develop superhuman intelligence and destroy the human race — and there are also thinkers who think this kind of scenario is a real danger.
We interviewed one of them, Oxford philosopher Nick Bostrom, last year. Others include singularity theorist Ray Kurzweil and Robin Hanson, an economist at George Mason University.
But these thinkers overestimate the likelihood that we'll have computers as smart as human beings and exaggerate the danger that such computers would pose to the human race. In reality, the development of intelligent machines is likely to be a slow and gradual process, and computers with superhuman intelligence, if they ever exist, will need us at least as much as we need them. Here's why.

(Matt)
Bostrom, Kurzweil, and other theorists of super-human intelligence have seemingly infinite faith in the power of raw computational power to solve almost any intellectual problem. Yet in many cases, a shortage of intellectual horsepower isn't the real problem.
To see why, imagine taking a brilliant English speaker who has never spoken a word of Chinese, locking her in a room with an enormous stack of books about the Chinese language, and asking her to become fluent in speaking Chinese. No matter how smart she is, how long she studies, and how many textbooks she has, she's not going to be able to learn enough to pass herself off as a native Chinese speaker.
That's because an essential part of becoming fluent in a language is interacting with other fluent speakers. Talking to natives is the only way to learn local slang, discover subtle shades in the meanings of words, and learn about social conventions and popular conversation topics. In principle, all of these things could be written down in a textbook, but in practice most of them aren't — in part because they vary so much from place to place and over time.
A machine trying to develop human-level intelligence faces a much more severe version of this same problem. A computer program has never grown up in a human family, fallen in love, been cold, hungry or tired, and so forth. In short, they lack a huge amount of the context that allows human beings to relate naturally to one another.
And a similar point applies to lots of other problems intelligent machines might tackle, from drilling an oil well to helping people with their taxes. Most of the information you need to solve hard problems isn't written down anywhere, so no amount of theoretical reasoning or number crunching, on its own, will get you to the right answers. The only way to become an expert is by trying things and seeing if they work.
And this is an inherently difficult thing to automate, since it requires conducting experiments and waiting to see how the world responds. Which means that scenarios where computers rapidly outpace human beings in knowledge and capabilities doesn't make sense — smart computers would have to do the same kind of slow, methodical experiments people do.

Machines need humans to help maintain complex machinery like oil rigs. (Marianne Muegenburg Cothern)
In the Terminator series, a military AI called Skynet becomes self-aware and begins using military hardware to attack humans.
This kind of scenario drastically underestimates how much machines depend on human beings to keep them working. A modern economy consists of millions of different kinds of machines that perform a variety of specialized functions. While a growing number of these machines are automated to some extent, virtually all of them depend on humans to supply power and raw materials, repair them when they break, manufacture more when they wear out, and so forth.
You might imagine humanity creating still more robots being created to perform these maintenance functions. But we're nowhere close to having this kind of general-purpose robot.
Indeed, building such a robot might be impossible due to a problem of infinite regress: robots capable of building, fixing, and supplying all the machines in the world would themselves be fantastically complex. Still more robots would be needed to service them. Evolution solved this problem by starting with the cell, a relatively simple, self-replicating building block for all life. Today's robots don't have anything like that and (despite the dreams of some futurists) are unlikely to any time soon.
This means that, barring major breakthroughs in robotics or nanotechnology, machines are going to depend on humans for supplies, repairs, and other maintenance. A smart computer that wiped out the human race would be committing suicide.

(Brad Aaron)
Bostrom argues that if nothing else, scientists will be able to produce at least human-level intelligence by emulating the human brain, an idea that Hanson has also promoted. But that's a lot harder than it sounds.
Digital computers are capable of emulating the behavior of other digital computers because computers function in a precisely-defined, deterministic way. To simulate a computer, you just have to carry out the sequence of instructions that the computer being modeled would perform.
The human brain isn't like this at all. Neurons are complex analog systems whose behavior can't be modeled precisely the way digital circuits can. And even a slight imprecision in the way individual neurons are modeled can lead to a wildly inaccurate model for the brain as a whole.
A good analogy here is weather simulation. Physicists have an excellent understanding of the behavior of individual air molecules. So you might think we could build a model of the earth's atmosphere that predicts the weather far into the future. But so far, weather simulation has proven to be a computationally intractable problem. Small errors in early steps of the simulation snowball into large errors in later steps. Despite huge increases in computing power over the last couple of decades, we've only made modest progress in being able to predict future weather patterns.
Simulating a brain precisely enough to produce intelligence is a much harder problem than simulating a planet's weather patterns. There's no reason to think scientists will be able to do it in the foreseeable future.

(White House)
Bostrom suggests that intelligent machines could "become extremely powerful to the point of being able to shape the future according to its preferences." But if we think about how human societies work, it's obvious that intelligence by itself isn't sufficient to become powerful.
If it were, societies would be run by their scientists, philosophers, or chess prodigies. Instead, America — like most societies around the world — is run by men like Ronald Reagan, Bill Clinton, and George W. Bush. These men became powerful not because they were unusually bright, but because they were well-connected, charismatic, and knew how to offer the right combination of carrots and sticks to get others to do their bidding.
It's true that brilliant scientists have played an important role in creating powerful technologies such as the atomic bomb. And it's conceivable that a super intelligent computer would conceive of similar breakthroughs. But building new technologies and putting them into practice usually requires a lot of cash and manpower, which only powerful institutions like governments and large corporations can muster. The scientists who designed the atomic bomb needed Franklin Roosevelt to fund it.
The same point applies to intelligent computers. Any plausible plan for taking over the world would require the cooperation of thousands of people. There's no reason to think a computer would be any more effective at enlisting their assistance for an evil plot than a human scientist would be. Indeed, given that persuasion often depends on long-standing friendships, in-group loyalties, and charisma, a disembodied, friendless computer program would be at a huge disadvantage.
A similar point applies to the "singularly," Ray Kurzweil's idea that computers will someday become so intelligent that humans will no longer even be able to understand what they're doing. The most powerful ideas aren't ones that only their inventor can understand. Rather, powerful ideas are ones that can be widely understood and adopted by many people, multiplying their effect on the world. That will be as true of computer-generated ideas as it is of ideas generated by people. To change the world, a super-intelligent computer would need to bring the human race along with it.

You might expect that computers will use their superior intelligence to become fabulously wealthy and then use their vast wealth to bribe humans into doing their bidding. But this ignores an important economic principle: as a resource grows more abundant, its value falls.
Sixty years ago, it cost millions of dollars to buy a computer that could do less than a modern smartphone. Today's computers can do vastly more than earlier generations, but the value of computing power has fallen even faster than computers' capabilities have improved.
So the first super-intelligent computer might be able to earn a lot of money, but its advantage will be fleeting. As computer chips continue getting cheaper and more powerful, people will build more and more super-intelligent computers. The unique capabilities of super-intelligent computers, whatever those turn out to be, will become commodities.
In a world of abundant intelligence, the most valuable resources will be those that are naturally limited, like land, energy, and minerals. Since those resources are controlled by human beings, we'll have at least as much leverage over intelligent computers as they'll have over us.
Yesterday, Twitter released financial results that beat Wall Street's expectations. The company is still losing money, but its losses were smaller than many feared. Today, Twitter's stock plunged by 13 percent anyway.
The problem: Comments by Twitter executives in the earnings call set off alarm bells for investors. "We don't expect to see sustained, meaningful growth until we reach the mass market," said chief financial officer Anthony Noto. "We expect it to take a considerable period of time."
Noto spoke alongside Twitter co-founder and interim CEO Jack Dorsey. Both men believe that Twitter's complexity has become an obstacle to further growth. Twitter has about 300 million users, less than a quarter as many as Facebook. Twitter's top brass think 300 million users isn't good enough; they want to revamp Twitter to make it easier to use, allowing it to reach a Facebook-size audience in the coming years.
That sounds good in theory, but it could be disastrous in practice. Twitter is the power users' social network. It demands more from users of Facebook or Instagram, but users who master its complexities are able to sift through large volumes of online information more efficiently than they can with other social media tools. If Twitter tries to simplify its product, it risks alienating its existing users without attracting many new ones.


PCs are computing devices for power users. (Quattro Vageena)

If you walk by the desks of software developers here at Vox — or at virtually any other company — there's a good chance you'll see them using a Unix command-line interface that dates back to the 1970s. Geeks continue to use the Unix command line because — once you know how to use it — it's a powerful way to perform complex computing tasks.
But most users don't need the power, complexity, or hassles of using a Unix command line, which is why it never caught on with ordinary users. Until recently, most people used Windows PCs or Macs with a more user-friendly graphical user interface. Lately people have been shifting toward even simpler computing technologies: smartphones and tablets. These mobile platforms provide fewer capabilities than a conventional PC — it's hard to write a blog post or manage a complex spreadsheet on an iPhone — but they're also easy to learn and demand little of users.
The older, more complex computing platforms didn't die. Programmers still use Unix-based operating systems. Many white-collar professionals still use PCs. But for the average person, the complexity of a PC is more trouble than it's worth. So smartphones are becoming the most popular category of computer.

A similar principle applies to social media technologies: The most popular services tend to be the ones that demand the least from their users. And Twitter demands a lot more of users than Facebook does.
Most people don't want to sift through large volumes of information
To make Twitter manageable, you have to carefully curate the list of people you follow to avoid being overwhelmed. The rules for Twitter conversations — for example, the fact that starting a tweet with someone's username will hide it from anyone not already following that user — are not intuitive to someone dropping by the site for the first time, or even the 10th. And many users find it intimidating to write tweets that anyone in the world could read.
Twitter helps users sift through a lot of information efficiently, which makes it invaluable for a media professional like me. But most people don't want to sift through large volumes of information. They just want to look at pictures of their friends' weddings, vacations, and babies with a minimum of hassle. And Facebook makes this really easy.


Jack Dorsey might have to just accept that Facebook's Mark Zuckerberg is going to have a more popular website. (Josh Edelson/AFP/Getty Images)
Twitter is under pressure to expand its audience so it can generate the kind of revenues and profits Facebook does. But there are good reasons to think this won't work — and that trying to make it work might destroy the site in the process.
Microsoft's struggles to adapt to the mobile revolution provide an instructive analogy. For years, Microsoft has been struggling to produce a version of its Windows operating system that works well on tablets. The result has often been products that occupy an awkward middle ground — neither as powerful as a full-scale Windows PC nor as user-friendly as an iPad. It's hard to reduce the complexity of a Windows PC without simultaneously eliminating features that make it useful. After several flops, Microsoft has finally achieved modest success with the Surface Pro 3, but Windows-based tablets are still a lot less popular than iPads and Android tablets.
A similar point applies to social networks. Twitter's complexity isn't just a problem the company needs to eliminate, it's an essential part of what makes the site useful right now. Twitter facilitates a type of rich, open conversation that's much harder to have on a more restrictive platform like Facebook or Instagram. It's why its most committed users are so incredibly committed, and why they create so much valuable, free content for the service.
While more complex products tend to be less popular in relative terms, they can still be huge markets in absolute terms. Microsoft is a hugely profitable company because it can continue selling its products to businesses that need the power of a full-scale PC. Similarly, the rapid growth of Facebook and Instagram doesn't mean that Twitter is doomed; there will continue to be tens or even hundreds of millions of people who want to use Twitter.
Twitter's problem is that it hasn't found a way to monetize its relatively small but highly engaged and influential audience. Microsoft makes a lot of money from every Windows license it sells, so it doesn't matter that people buy fewer PCs than mobile devices. But advertisers don't seem willing to pay more to advertise to a Twitter user than a Facebook user. So Twitter's smaller audience has translated to a lot less money in the bank.
But 300 million users is still a lot, and it includes a lot of prominent and wealthy people. Rather than risk alienating its existing users in an effort to become more like Facebook, Twitter might want to focus on generating more revenue from the users it has.
Robert Manduca, a PhD candidate in sociology at Harvard, assembled a dot map showing every job in the United States of America, color-coded by industry segment. It's pretty cool.
The way it works is that red dots signify manufacturing and trade; blue dots are professional services; green dots are health care, education, and government; and yellow dots are retail and other services.
Robert Manduca
Which makes sense, since you can't have a job without working within commuting distance.
Robert Manduca
Hudson County, New Jersey, just west of Manhattan, is one of the most densely populated places in the United States. But there aren't many jobs there.
Robert Manduca
The mismatch between people and jobs is especially striking in Chicago, whose outlying neighborhoods are full of people but scarce on employment. It's a classic form of schematic city planning, in which freeways and transit lines radiate out from a hyper-concentrated zone of employment.
Robert Manduca
Los Angeles looks very different. Yes, there are a lot of jobs downtown, especially red dots signifying light industry and warehousing. But there is a thick stretch of employment stretching west of downtown and arcing toward the Pacific Ocean in Santa Monica. Then south of that arc you see several small clusters of employment. It's especially noteworthy that the blue dots of professional services are really, truly not concentrated downtown — office clusters are everywhere.
Robert Manduca
Official government statistics record Silicon Valley as a suburb of San Jose, but as the map shows, there is no real concentration of jobs — especially not the blue-colored professional services jobs — in San Jose. Instead, the economic heart of the region is a series of diffuse corporate campuses strung out along the west coast of the San Francisco Bay. As individual campuses these places not very dense, and they're not packed together, either.
Meanwhile, the residential areas surrounding them are mostly built as low-density suburbs. The result is a housing shortage that drives up prices, but also a constant transportation capacity crunch that feeds opposition to new housing.
There's one thing everyone thinks they know about the seemingly endless problems in the eurozone: It's about who will make sacrifices, the thrifty Germans or the heavily indebted south.
Except this is totally wrong, as economist Robert Waldmann explains in a brilliant paragraph that comes in the midst of an effort to adjudicate a debate between two other writers. What Europe needs from Germany is not sacrifice, but self-indulgence — lower taxes, higher wages, and more consumption:
I would say that the Eurozone has two huge problems. One is that Greece has debts it can't and won't repay. The other is that aggregate demand is too low. One perfectly fine solution to the aggregate demand problem would be for German taxpayers to grit their teeth and accept a tax cut. This would stimulate German demand including demand for imports. If Germans were feeling incredibly generous, they might also consider accepting an increase in wages. What the Euroblock needs most is higher aggregate demand -- self indulgence, the illusion of wealth of those who think government bonds are net wealth and all that. What we need is less German self sacrifice not more.
The case for a German tax cut is even stronger when you consider that the country is currently paying an interest rate of less than 0.7 percent on its 10-year bonds. When you take inflation into account, it's actually cheaper for Germany to pay for government spending with debt than with taxes.
Germany levies a 19 percent value-added tax (basically a sales tax) on almost all consumer good purchases. A nice big cut in that rate — financed entirely with borrowing rather than spending cuts — would make German people better off, with benefits especially flowing to lower-income Germans, students, and retirees. But it would also speed up economic recovery throughout the continent. It is a win-win option that would by no means solve all of Europe's problems, but would ameliorate most of them.
The journalism world is never short on gloom and doom, but two charts I saw recently offer some grounds for optimism about the future of digital media as a business.
First, though there is a lot more internet ad spending than there used to be, exactly none of this has come at the expense of television ad spending:
Andreesen Horowitz
Second, television viewership seems poised for collapse:

TV is toast.   This one crazy chart shows why.  http://t.co/nb8WWrcSze pic.twitter.com/azvFVIVOHL


In other words, the internet advertising business we see today isn't the end of the story. The basic pattern of print, where first the audience left and then the ad dollars followed later, will happen with television, too, increasing the opportunity for revenue in the digital space.


(Javier Zarracina / Vox)

Three weeks ago, the Chinese government took extreme measures to reverse a massive 32 percent drop in stock prices. The plan worked — over the next two weeks, stocks gained 17 percent. But now the government has a bigger problem: Stocks fell 8.5 percent on Monday, the largest one-day decline in eight years, and people are blaming the government for it.
Stock markets play an essential role in developed economies, directing resources to businesses where they'll be used most productively. But they can only serve this role if governments let them. This month, the Chinese government has made it clear that its political goals will take a higher priority. And now that Beijing has tied its reputation to rising stock market prices, it will be harder than ever to step back.
When the Chinese stock market crashed in early July, the Chinese government took drastic steps to prevent further stock market declines. The government banned major shareholders from selling their shares for six months, ordered companies to buy back some of their own shares, halted initial public offerings of stock, and provided more money for Chinese people to buy stock with borrowed funds.
But while these measures appear to have accomplished the government's short-term objective of halting a politically embarrassing slide in stock prices, the government now faces a problem that could prove more serious in the long run: The Chinese government's reputation is now even more tied to the stock market's fortunes, and the government will face pressure to intervene further every time prices decline.
The Wall Street Journal's write-up of Monday's stock market crash illustrates the problem. It focuses on whether the government will intervene to keep prices up. Some analysts think the government is drawing down support from the stock market. Others predict the government will step in and push stock prices back up in the next few days.
That's not surprising. A couple of weeks ago, the Financial Times reported that students at Tsinghua University, sometimes described as the MIT of China, were instructed to chant the slogan "Revive the A shares, benefit the people" at their graduation ceremony. Obviously, having students chant slogans won't directly boost stock prices. But by holding this kind of demonstration, the government signaled that it was committed to keeping stock prices up.
Political pressure for the Chinese government to prop up stock prices is intensified by the fact that retail investing has exploded in China. Between June 2014 and May 2015, 40 million new brokerage accounts were opened in China, and many of them invested in stocks with borrowed money. China isn't a democracy, but the government is still sensitive to public opinion. Having 40 million Chinese people lose their savings in a stock market crash would be very bad for the government's reputation.
But in the long run, the larger danger may be if the government refuses to let stock prices decline. The government knows it needs to shift away from inefficient state-owned enterprises in favor of allocating investment capital based on market forces. The Chinese stock market is a key part of that effort.
This will only work if the government actually lets the market set the prices of Chinese companies. If the government perpetually props up the value of nominally private companies in China, the country won't enjoy the efficiency benefits of a truly private stock market.
As part of her plan to reduce the impact of short-term thinking on corporate America, Hillary Clinton is proposing a revamp of how investment income is taxed in America. Right now, the tax code distinguished between a short-term investment held for less than a year and a long-term investment held for longer than that. She wants to replace that with a different system, featuring a six-year sliding scale of rates to give genuinely long-term investors a leg up.
A capital gain is income that a person makes from investment. If you buy a house for $200,000 and sell it 10 years later for $250,000, you have scored a $50,000 capital gain. The current tax code largely exempts capital gains earned buying and selling owner-occupied houses, so the debate over capital gains taxation generally focuses on capital gains secured by buying and selling stocks, bonds, and other financial assets.
Right now the tax code distinguishes between short-term capital gains and long-term capital gains. A short-term capital gain is defined as a gain on an asset that you owned for less than a year, while a long-term capital gain is defined as a gain on an asset that you owned for longer than a year. Short-term capital gains are taxed at the same rate as wage or salary income, but long-term capital gains are taxed at a lower rate.
In other words, the current tax code already features lower tax rates for income derived from long-term capital gains than for income derived from other sources. Clinton is proposing, essentially, to extend the logic of the current system, not to replace it with a whole new logic.
There are three big explanations for the current system — a cynical one, one grounded in political rhetoric, and an economics-y one:
Her campaign has not yet released a fully-fleshed out plan, but they say she wants to make two changes. One is to push the current one-year definition of short-term capital gains out to two-years.
The second is that she doesn't want to give every investment held for longer than two years equal treatment. Instead, she wants a sliding scale of rates over a multi-year period so that you would need to hold an investment for a full six years to qualify for the discount rate.
Needless to say, people disagree. In practice, there appears to be very strong political consensus around preferential treatment for investment income. Even very liberal members of Congress, for example, do not propose ending the exemption of capital gains income from the payroll tax that finances Social Security. Nor do liberal members of Congress propose to end the exemption of profits made by selling owner-occupied homes from capital gains taxation. Countries all around the world feature some form of preferential treatment of investment income, and despite the partisan controversies around the capital gains tax rate nobody in American politics is actually proposing to do away entirely with our own preferential treatment.
That said, as is typical with highly theoretical results in macroeconomics, there are massive challenges in saying whether the Chamley-Judd construct applies in a meaningful way to the actual policy choice at hand. As economist Matthew Martin writes, "Any graduate macro text will show you some of the ways in which Chamley-Judd assumptions are violated in reality, producing a non-zero optimal tax rate."
Empirical studies also struggle to confirm the idea that tax rates on investment income are an important driver of real investment activity. A recent, statistically sophisticated study of the 2003 dividend tax cut by Danny Yagan, for example, finds that "the tax cut caused zero change in corporate investment."
Note, however, that even if the optimal tax rate for capital gains isn't zero it might still be optimal to have a lower rate on investment income than on wage income.
Rather typically for Clinton as a political actor, what she seems to be zeroing in on is a clever way to build consensus between competing factions of wonks.
A serious venture capitalist, for example, would almost certainly find himself still qualifying for the preferential rate. But a corporate raider looking to buy a company, strip assets, improve quarterly results, and then exit as quickly as possible would not.
Expect the campaign to front-load this short-term versus long-term issue, since it's emerging as a key theme for Clinton overall. But also note that in theory one could accomplish the same thing with a tax cut. Take today's rate for investments held over one year and apply it to investments held for one to three years. Take longer-term investments and apply a new lower rate to them. This would address the short-termism concern, while also addressing the GOP's opposition to higher taxes.
Clinton won't offer a proposal along those lines because for her, tax revenue and tax system progressivity are at least as important as the short-term versus long-term issue.

Chrysler will distribute USB sticks with upgraded software to affected customers.
In a terrifying demonstration to Wired reporter Andy Greenberg earlier this week, two hackers showed the ability to hack into a Jeep Cherokee from miles away, gain control of its internal network, and then tamper with its transmission, brakes, and other safety-critical features.
As the two hackers remotely toyed with the air-conditioning, radio, and windshield wipers, I mentally congratulated myself on my courage under pressure. That’s when they cut the transmission.
Immediately my accelerator stopped working. As I frantically pressed the pedal and watched the RPMs climb, the Jeep lost half its speed, then slowed to a crawl. This occurred just as I reached a long overpass, with no shoulder to offer an escape. The experiment had ceased to be fun.
The hackers, Charlie Miller and Chris Valasek, are professional security researchers, so they aren't planning to use their discovery for evil. But malicious hackers could use the same techniques to remotely tamper with cars across the country. From his home in the St. Louis area, Miller scanned the network for vulnerable vehicles and showed Greenberg vulnerable cars in Texarkana, Texas; San Diego; and Michigan's Upper Peninsula. If he'd wanted to, he could have hacked into any of these vehicles and interfered with their brakes and transmissions, potentially causing a crash.
Miller and Valasek notified Chrysler about this problem nine months ago, and the company recently released a software patch to fix the vulnerability. However, that patch wasn't easy for customers to install. The decision to issue a formal recall suggests that Chrysler is now taking the problem more seriously.
According to the Wall Street Journal, affected vehicles include "2013-2015 Dodge Viper specialty vehicles; a variety of 2013-2015 Ram pickup trucks and chassis cabs; 2014-2015 Jeep Grand Cherokee and Cherokee SUVs; 2014-2015 Dodge Durango SUVs; 2015 Chrysler 200, Chrysler 300 and Dodge Charger sedans; and 2015 Dodge Challenger sports coupes."
The move underscores the fact that car manufacturers are in the software business now. Security is one of the most important responsibilities of a major software company. Companies like Microsoft and Google have hundreds of security experts on staff — and security flaws in Windows and Android generally won't get anyone killed. Car companies are going to have to beef up their own security capabilities if they want to keep their customers safe from hackers.
When Uber got into a big fight with New York Mayor Bill de Blasio, Republican candidates for president leaped to Uber's defense. Jeb Bush, Marco Rubio, and Rand Paul have all praised the company. Ted Cruz has even compared himself to Uber.
Meanwhile, Democratic frontrunner Hillary Clinton recently warned that the "on-demand, or so-called 'gig economy'" is "raising hard questions about workplace protections" — not an explicit reference to Uber but an allusion to a class of companies of which Uber is the largest and most prominent.
There's something a little bit backward about this, as Uber is most popular in big cities with less than universal car ownership and lots of Democratic voters. But that's part of the reason talking about Uber is good politics for Republicans. It could help the party appeal to young, urban professionals who lean toward Democrats on cultural grounds but might find things to like in the GOP's economic message. It helps to drive a wedge between Uber-using urban professionals and more traditional — or more deeply ideological — liberals who see Uber's "gig economy" model as a threat to worker rights.
Of course, Uber itself cares less about presidential politics than about local regulation, where things tend to be less partisan in practice. Some Republican officeholders have been hostile to Uber, while many Democratic ones have been supportive. When the rubber meets the road, ordinary interest-group politics wind up mattering more than ideological considerations. But that doesn't stop Uber from being a potent tool in national politics, serving as a symbol for liberal fears and conservative hopes.


Marco Rubio points toward a sharing-economy future. (Tom Williams/CQ Roll Call)

Innovative businesses being held back by outdated regulations is a favorite conservative theme. And Uber makes an ideal poster child for this message. Uber was enabled by the invention of smartphones, and it solved a concrete problem — slow and unreliable taxi service — that many people encountered in their regular lives.
Taxi companies and their allies in city government are cast as the villains in the Uber morality play, trying to impose burdensome and arbitrary requirements on a company that had invented a better way of doing things.
Republican candidates for president have talked about Uber a lot on the campaign trail.
Jeb Bush made a point of riding in an Uber earlier this month during a campaign stop in San Francisco. Marco Rubio has been touting Uber for over a year, and he tweeted in support of Uber during this week's confrontation with New York Mayor Bill de Blasio.
Ted Cruz compared himself to Uber last December, saying he hoped to disrupt Washington in the same way Uber has disrupted the taxi business. Rand Paul tweeted in defense of Uber earlier this month, and Scott Walker signed Uber-friendly legislation in May.
It's natural for conservatives to side with a business fighting regulators, but the inclination to highlight this particular business has a lot to do with political demographics. Republican voters tend to be older and more rural than Democrats. Uber has a young and disproportionately urban customer base. If Republicans can turn Uber into a salient example of government regulation, it could broaden the GOP's demographic appeal without compromising on conservative principles.


Hillary Clinton has avoided taking a strong stance on Uber. (Melina Mara/the Washington Post via Getty Images)

Best of all for Republicans, Uber makes a great wedge issue. Some liberals dislike Uber on ideological grounds, but others — especially in the media, politics, and technology centers of New York, Washington, and San Francisco — are regular Uber customers.
On one side of this debate are old-school liberals with strong ties to the labor movement and urban political machines. For them, Uber is a conventional story about worker and consumer rights. Labor unions believe Uber is flouting the law by classifying workers as independent contractors rather than employees. And they would love to unionize Uber's fast-growing workforce.
More broadly, conventional liberals are suspicious of claims that deregulation and innovation will benefit workers and consumers in the long run. They view Uber's "gig economy" as part of a broader trend toward declining worker power. They blame decades of deregulation — under both Republicans and centrist Democrats like Bill Clinton — for this trend, and believe stricter regulation of Uber could be part of a larger trend toward stricter regulation of labor markets more generally.
In his campaign against Uber this week, Bill de Blasio primarily focused on congestion concerns, but he also mentioned workers' rights as a major concern.
On the other side of the debate are liberals — many of them Uber customers — who see Uber as an innovative company fighting entrenched special interests. While they might be sympathetic to theoretical arguments for government regulation, they remember what the taxi market was like before Uber came along.
Recognizing that in practice it needs friends in big liberal cities, Uber has worked hard to cultivate this base of support. Uber hired Obama strategist David Plouffe last year to help the company craft its political strategy, and Uber CEO Travis Kalanick has hailed Obamacare for helping Uber drivers get health insurance.
Hillary Clinton wants to attract supporters from both of these camps, so she has carefully hedged her bets. She recently credited "on-demand" companies like Uber with "creating exciting opportunities and unleashing innovation" while also acknowledging that the company is "raising hard questions."


Former Arizona Gov. Jan Brewer, a Republican, is not an Uber booster. (BRENDAN SMIALOWSKI/AFP/GettyImages)

While Republicans campaigning for national office have made a point of praising Uber, things have been more complicated at the state and local level. In Philadelphia, a Republican majority on the Philadelphia Parking Authority (which is appointed by state, not city, officials) has fought Uber's expansion. Jan Brewer, the Republican who was Arizona governor until January, vetoed pro-Uber legislation last year (her Republican successor has been more favorable to Uber). The Orlando Airport Authority, chaired by a Republican appointee, has been feuding with Uber, as has the city government in conservative San Antonio, Texas.
One reason for this divide is that presidential candidates don't actually have much skin in the game. Car services are mostly regulated at the state and local level, so the next president won't have much power to help or hurt Uber. So it's easy for Republicans seeking the presidency to employ pro-Uber rhetoric without committing to any specific policy positions.
Meanwhile, state and local officeholders have to worry more about the practical aspects of regulating Uber. Republicans have to worry about political pressures from taxi companies and others who are threatened by Uber's rise. And they have to worry that an excessively laissez-faire approach could fail to properly protect consumers and workers.
The opposite point applies for Democrats. Liberal politicians who are sympathetic to anti-Uber arguments in theory have to contend with the fact that thousands of constituents are regular Uber users, which helps explain why Democrat-controlled states like California and Colorado have passed Uber-friendly legislation.
And that means that national Republicans' enthusiasm for Uber isn't necessarily a good thing for the company. The national Republican Party would love to make Uber into a partisan wedge issue. But if they succeed, it won't be good for Uber, because the policy decisions Uber cares about most are made by mayors and city councils in big cities. And those are going to be in Democratic hands for the foreseeable future.
Correction: This story originally implied that Jan Brewer was governor of Arizona, but she stepped down in January.
In his new book The Alliance, Reid Hoffman argues that the relationship between employers and employees is built on "a dishonest conversation."
Hoffman would know. As co-founder and executive chairman of LinkedIn, he sits atop the largest, most data-rich hiring platform the world has ever seen. As a venture capitalist who made early investments in everything from Facebook to Airbnb, he's helped some of the era's most successful companies grow.
And now he wants both workers and employers to begin having honest conversations with one another — conversations that admit employment isn't for life, that loyalty only lasts so long as it coincides with self-interest, and that the relationship doesn't have to end when the worker leaves.
"The biggest lie is that the employment relationship is like family," Hoffman says.
He goes on to describe two versions of the lie. "One is where the employer is actually deluding themselves." Employers may want to believe their workplace really is like a family, and, in that moment, they may convince themselves it actually is like a family.
The other version of the lie comes because the employer wants the employee to believe it. "They really want the employee to be loyal to the company," Hoffman continues. "That's when it gets deceptive."
But the employer-employee relationship isn't like a family. "You don't fire your kid because of bad grades," Hoffman says.
But it's not just employers who lie. Prospective employees do, too.
"They know that employers want loyalty," Hoffman says. "They know they want to hear, 'Oh, I plan on working here for the rest of my career.' But most employees recognize that career progression probably requires eventually moving to another company. But that never comes up."
This is core to Hoffman's idea that both employers and employees should look at a particular job less as a lifetime contract and more as a "tour of duty" — a limited-time engagement meant to achieve specific ends on both sides. But until employers stop pretending employees are family and employees stop pretending their aim is a job they'll never leave, neither side can have that conversation.
LinkedIn is an organization dedicated to helping other companies hire talent. It has access to more hiring data than arguably any other corporation on earth. So I asked Hoffman: how do they hire? What do they ask that most companies don't?
"All of our managers and recruiters ask about how working here will be transformational to your career," Hoffman says. "For example, our SVP of engineering, Kevin Scott, will ask, 'What's the next job that you would like to have post-LinkedIn?' That's not because we don't want our stars to stay at LinkedIn for a long time. It's because we're so committed to the idea that we're going to be transformative in the prospective employee's career. So we need to know, what's the next job after this? What do you want it to be?"
But don't job candidates find that weird?
"No," Hoffman says. "It's framed as, 'We're planning on having a huge impact in your career if you're working here.' And they find that liberating. It brings some honesty to what is otherwise kind of a collective self-deception dance. And it also means that when they leave, we still care about them."
"I was at an Airbnb board meeting and I ran into two former LinkedIn employees who walked up to me and said, 'Hey, how's it going? I'm working here now. I'd love to tell you about some of the stuff that I'm learning.' They know the way that we operate, is not, 'Oh, you've left LinkedIn, so you're no longer part of our tribe.' We continue to be allies. We can continue to try to help each other. That lets them come up and start telling me things about things could be really helpful to LinkedIn."
By signing up, you agree to our terms. For more newsletters, check out our newsletters page.
A key part of every hiring process I've ever been a part of — both as the applicant and as the employer — is the job interview. And I've never felt very good about it. Don't job interviews bias you toward gregariousness? Is there any real reason to believe shy employees perform worse than extroverted ones?
"I think you can learn some useful things from an interview," Hoffman says. "You just have to be clear about what it is you're actually trying to learn. I think you can learn about chemistry and fit. I think you can learn about a person's immediate response to a challenge. But if you told me, 'Pick one — you could either get references or an interview,' I would pick references every day of the week.
"I advise all the companies that I affiliate with to take reference checking very seriously. References actually tell you how people work, what their work ethic is. That is a critical piece of data that cannot be put aside or done casually. Frequently employers are so casual about references they either a) don't check them, or b) only check the ones the prospective candidate gives them. In fact, you want both those references and others."
Remember Web 2.0?
Hoffman's former chief of staff, Ben Casnocha, wrote an interesting piece on leadership lessons he's learned from Hoffman. This one in particular surprised me: "If you’re choosing between working with someone who’s a trusted friend and a 7 out of 10 on competence, versus a stranger who’s a 9 out of 10 on competence, who should you pick? Answer: if the trusted friend is a fast learner, pick the trusted friend."
The normal management guidance is don't hire your friends. According to Nick Bilton's history of Twitter, when Evan Williams asked legendary CEO coach Bill Campbell what the worst mistake he could make is, Campbell replied: "Hire your fucking friends!" So I asked Hoffman why he believes in hiring friends.
"You need to handle it well," Hoffman replied. "If I get to the point where I'm hiring a friend, I say, 'Look. Here's how we keep the friendship and the work stuff different. Here's how I'm going to treat you a little differently as a friend. Here's how you're going to act a little differently as a friend.' I'm going to be clear about the fact that I'm not going to privilege them at all in the continuum to the job and promotions and bonuses. All of that will be done in a very fair way.
"On the other hand, I will actually, as a friend, go out of my way to invest even more energy than I normally do to make this work. I'm committing to put in a little bit more energy. In return, one thing is I want you, as a friend, to do the same. The benefit you get from this is both a) a higher level of trust, and b) you get to work with people that you actually really like to spend time with. Which usually facilitates a generally positive working relationship anyway."
Hoffman's background isn't typical. He didn't study computer science or get an MBA. He studied philosophy. And he thinks he's better off for it.
"One of the things that philosophy is very helpful on is how to think pretty precisely about arguments, and an investment thesis is fundamentally an argument. Part of philosophical training is making you really understand how good an argument is and how to think through the alternatives. Philosophy is really good at posing the question, 'If the universe were such that this data would be different or the universe was such that this framework would be wrong, what happens to the argument then?' Questioning those premises really helps you figure out why someone smart might actually hold a different point of view.
"We live in a probabilistic universe, and we tend to think in determinist ways. If A is data-driven and I think I have that data, how certain am I that I have that data? What could I discover that might actually tell me that that data is formulated wrongly? When you dig into it, most of your arguments are actually probabilistic. They're not certain, even when you have data. You're really trying to get a sense of whether you have a reasonable bet on the probability."
Correction: Ben Casnocha is Hoffman's former chief of staff, not his current one. The text has been updated to reflect this fact.

On Wednesday, Bill de Blasio signed a truce with Uber. The New York City Council had been on the verge of voting on a controversial proposal to cap the number of vehicles Uber and other paid car services could have on the road. But Uber organized a massive public protest that forced the mayor to scrap the proposal.
In an overwhelmingly liberal city, both sides have argued that they represent the progressive side of the debate. De Blasio not only blamed Uber for growing congestion, but also faulted the company for its poor treatment of drivers and its cavalier attitude toward following the law.
For its part, Uber argued that capping the growth of car services will harm minorities and people in the outer boroughs, who are sometimes poorly served by conventional taxicabs. It also accused de Blasio of carrying water for taxicab companies.
According to the New York Times, "The city will conduct a four-month study on the effect of Uber and other for-hire vehicle operators on the city’s traffic and environment."
While the study is being conducted, de Blasio won't seek to cap the number of new vehicles Uber or other car services can put on the road. But de Blasio administration officials say a cap is still a possibility in the future.
Uber mounted a broad publicity campaign against the mayor's proposal, enlisting the support of celebrities such as Kate Upton, Ashton Kutcher, and Neil Patrick Harris:

.@BilldeBlasio Why do you want to return to days when only those in Midtown & Lower Manhattan could get a ride?#UberMovesNYC

10,000 jobs is nothing to scoff at, @BilldeBlasio #uberNYC


.@BilldeBlasio: 25K new residents use @Uber_NYC each week. How is a fixed # of cars supposed to serve this demand for rides? #UberMovesNYC


Another key Uber ally was New York Gov. Andrew Cuomo, who weighed in on the debate on Wednesday. "I don’t think government should be in the business of trying to restrict job growth," he said in a radio interview.
It's hard to say, but the four-month study contemplated in the new deal might give us a better idea.
Uber has about 26,000 drivers in New York City — about double the number of conventional taxicabs. On the other hand, there are a lot of other cars on the street in New York, too. Uber says that a total of 2.7 million people enter New York in their own cars each day; that includes about 750,000 vehicles entering Manhattan below 60th street every workday.
About 750,000 vehicles enter Manhattan below 60th street every workday
Of course, an Uber car is going to be on the road longer than a regular private car, so Uber may be contributing more to congestion problems than you'd think from the raw numbers. On the other hand, some Uber trips are replacing ones that people would have taken in their own cars, saving parking spaces and congestion from people circling the block looking for parking.
And this could be especially true in the long run. By making it easier for people to get around without a car, services like Uber may encourage more people to give up owning their own vehicles.
Uber had depicted it as a disaster for its customers. It had added a "de Blasio" tab on its app purporting to show the long wait times that would occur if the mayor's proposal for a cap was adopted.
The company says it's attracting 25,000 new customers a week and has to hire hundreds of drivers per week to keep up with the demand. If it can't do that, there could be driver shortages and long waits to get an Uber.
Presumably, Uber would deal with this problem by raising prices — either increasing prices across the board or invoking surge pricing more often to deal with demand spikes.
African Americans have long complained that taxicabs don't serve them well. Cabbies would sometimes refuse to stop to pick up black people, and taxicabs would spend disproportionate time in Manhattan — where fares are easiest to find — rather than in outlying areas where many minorities live.
Uber says its smartphone-based hailing technology has helped with this. Its software tracks how drivers respond to hails and penalizes those who decline them too often, discouraging them from discriminating among passengers. And the technology also makes it easier for drivers and passengers to find each other in the relatively sparsely populated outer boroughs.

Uber says this responsiveness has been made possible by rapid growth in the number of drivers. By flooding the market, the company is able to ensure that even people in the outlying areas of the city are able to get a car in a reasonable amount of time. But Uber's drivers are free agents; Uber can't order them to the outer boroughs. So if demand outstrips supply, drivers are likely to focus on the busiest areas of Manhattan, where wait times are shortest.
And Uber has had some success rallying black leaders to its side. For example, two black elected officials from outlying areas of New York denounced de Blasio's proposal at an Uber-organized rally yesterday.



New York Mayor Bill de Blasio. (Spencer Platt/Getty Images)

While de Blasio's case for the cap has focused on congestion concerns, the mayor has also made the case that Uber is a bad corporate citizen that has grown wealthy by exploiting its drivers.
Uber classifies its drivers as independent contractors rather than employees. That means they don't get health insurance or disability benefits, nor does Uber reimburse them for work expenses as a company would for an employee. Uber's critics have charged that this is unfair and illegal. Last month, one California regulator agreed with the critics, ruling that Uber drivers were employees under California law, which entitled them to more benefits.
Every business benefits from limiting its competition; conventional taxi companies have long lobbied to limit the expansion of ride-hailing companies like Uber and Lyft.
But taxi companies also have a more direct financial interest in limiting the expansion of those competing services. To operate a cab in New York requires a taxi medallion, and the number of medallions has grown much more slowly than demand. As a result, operating a taxi became extremely lucrative, and the value of these medallions has skyrocketed to as much as $1.3 million each.
But since Uber entered the market, taxis have faced more competition, and so the value of taxi medallions has been falling. That's another reason taxi companies — which have given to Mayor de Blasio's campaign — would benefit from limits on the number of ride-hailing cars on the road.
Dorothy was right about Kansas. It's a great place to live, and there's no place like home — especially for homebuyers. WalletHub says as much, crowning Overland Park, Kansas, as the best US city for first-time homebuyers.
This interactive map shows how 300 US cities ranked against one another for first-time homebuyers. Indicated by blue dots are the friendlier areas for buying a home; orange dots indicate less-friendly places.


Let's be honest: The American dream is so closely tied with home ownership, it's difficult to name an example archetype of a successful American who rents. That is, unless your definition of success includes the Dude, who abided in an apartment.
Reaction GIFs
What factors did WalletHub consider to determine that Kansas is so wonderful? The site looked at an index of factors that it believes make housing a good investment, including affordability, the living environment, and the strength of the local real estate market (read the full methodology here). Overland Park, Kansas, came out on top, but only in an average kind of way. Here's the list of the top 10 cities, based on WalletHub's three focus areas:
WalletHub
Five Texas cities joined Overland Park on the list, as did three Colorado cities and Broken Arrow, Oklahoma. No single city won the top spot in every factor ranking, which makes sense: Some cities have more houses available to buy, but the options may not be in good living environments, and vice versa.
Overland Park, with fewer than 200,000 residents, hit a high of about 75 degrees on Tuesday. Beyond good weather, homebuyers also care about things like proximity to family, jobs, and lifestyle preferences. Since bigger cities tend to offer more options, let's take a look at how they ranked (again, blue is friendlier):



There's one big problem with using population size alone as a measurement of opportunity: Many cities are struggling to grow their economy despite a large population. A good example of this is Detroit, which ranked 104th out of the 300 largest global metropolitan areas in a Brookings Institution study of city growth since 2009. When comparing the growth of the same 300 cities between 2013 and 2014, Detroit ranked 237th.
So if you still want to buy in or near a city, consider a smaller city. In the ranking below, large is considered to be a city with more than 300,000 residents, midsize is 150,000 to 300,000, and small is fewer than 150,000. Just look at all these unusual options:
WalletHub
How do you feel about Frisco, Texas (and not "Frisco," California)? Maybe you're coming around to Overland Park, and starting to sway from Bryant Park. Wherever you choose to live, you'll need luck, patience, and a bit of the Dude's chill attitude to get there.

Apple released its third-quarter earnings today, providing our first look at the performance of the Apple Watch and an ongoing glance at the staggering success of the iPhone — essentially the most popular and commercially successful product ever made.
Apple earned $31 billion (yes, that's a "b") selling iPhones in the quarter — which, due to its place in the life cycle of the profit, is not traditionally that strong a quarter — representing a staggering 59 percent increase on the previous year. In terms of units, sales went up "only" 35 percent, which is extremely impressive on its own merits. Basically Apple succeeded in getting many more people to buy iPhones, while also increasing the average price of the phones sold.
That would be a notable achievement under any circumstances, but it's doubly impressive because the iPhone was already an extremely popular product a year ago and already occupied the high end of the smartphone niche. The iPhone is so huge that it accounts for more than 60 percent of the revenue of the biggest company on the planet.
The company's overall revenue was up 33 percent year on year, which is impressive. And the big driving force behind that 33 percent increase was a mind-blowing 112 percent increase in revenue deriving from Greater China, of which the People's Republic of China is far and away the largest part.
Greater China was so big that the company's four other regions were all below average. It's now blown past Europe to be Apple's No. 2 regional market behind the Americas, though there's still a substantial gap there.
Apple's "other" revenue, which includes the Apple Watch, Beats by Dre headphones, Apple TV, and sundry accessories, was up a relatively modest 49 percent. That would be a great increase, of course, in a genuinely static category.
But a year ago, there was no Apple Watch at all. If the watch had been an enormous hit product, we would have seen an enormous increase in "other" revenue. Instead the total "other" category remains smaller than Macs, smaller than iPads, and smaller even than the iTunes and App Store groups.
And yet even this modest product is bigger than the original launch quarters for the iPad or iPhone. The question for Apple is whether further iterations of the watch that add power and capacity broaden its appeal to people beyond the hardcore early adopters.
The 9 percent year-on-year growth in Mac revenue is not huge compared with the overall scale of Apple's operations. But in a world in which the overall market for personal computers is shrinking, the fact that the Mac continues to grow at all is impressive.
Apple long ago lost the war for PC market share, but as the industry enters its senescent phase it's staging a surprisingly robust comeback.
Sales of the iPad fell 23 percent year on year. What's striking is that nobody else in the tablet market appears to be doing particularly well, either. After launching to great fanfare and acclaim in 2010, the entire tablet segment appears to be slumping as people decide that big-screen smartphones are all the mobile device they need.
We're used to thinking of smartphones and tablets as separate product categories. The first iPhone was small — its screen measured 3.5 inches diagonally. The original iPad was big — its screen was almost 10 inches.
But it's becoming clear that for many customers, the "sweet spot" for a touchscreen mobile device is somewhere in the middle. More evidence for this can be found in Apple's latest financial results.
On the one hand, iPads continued their two-year-long decline. Between April and June 2015, Apple sold 18 percent fewer iPads than in the same quarter of 2014. The iPad is still a big hit, of course, but it turns out that the demand for full-size tablets is weaker than people expected a couple of years ago.
Benedict Evans
But the really interesting news comes from Apple's iPhone numbers. Apple introduced two new, larger iPhones last September, and they've been a big hit with consumers. The company sold 35 percent more iPhones last quarter than in the same quarter of 2014. But revenue from those iPhones grew by an even more impressive 59 percent.
That suggests that not only do consumers love Apple's larger iPhone, but that Apple sold a fair number of the larger iPhone 6 Plus — which retails for an extra $100 — last quarter.
There's basically one thing everyone wants to know about Apple's business right now — how many people bought an Apple Watch, and how much did they pay?
Unfortunately for analysts, investors, and journalists alike, in today's quarterly earnings report we're not going to find out. The company has traditionally broken out its revenue into five buckets:
In recent quarters, "accessories" was relabeled as "other" revenue, and both the Apple Watch and Beats by Dre headphones are getting folded into that category.
Of course, you don't need to be totally dumb about it. To the extent that "other" revenue surges this quarter relative to the year-ago quarter, common sense says that's because of Apple Watch sales rather than skyrocketing popularity of the years-old Thunderbolt Display or an inexplicable number of people running out to buy spare keyboards.
But even so, the raw revenue number for Apple Watch is going to be extremely uninformative because the product is sold at so many different price points. The 38-millimeter Apple Watch Sport costs $349 while a 42-millimeter Apple Watch with Milanese Loop band costs $699, and this gold Apple Watch Edition costs $15,000. People would really like to not just know how much money Apple made selling watches, but have some sense of how many watches they sold. And there's just going to be no way to tell.
That, of course, is no coincidence.
Among the list of "people" who would like to know are Apple's competitors, who could better understand how to position competing products if they understood which price points were appealing to Apple's customers. That's why Apple isn't going to tell us. Which, in turn, is why the earnings report isn't going to clarify the most interesting issue about the company.
Retirement planning is a topic that fills many people with dread. Not just because saving is difficult, but because advice on how to do it well is complex, confusing, and often contradictory.
Vox is here to help. While saving for retirement seems complicated, there are four simple rules that — if followed — will get you on the path to a comfortable retirement:
That's it. If you follow these four rules, you have a high probability of enjoying a comfortable retirement. Read on for more details.
How much should you be saving? That depends on a number of factors, including your age, income, and marital status. Fill out the form below and we'll give you a personalized estimate.

.yuri-stuffs button {
  -webkit-transition: all 0.30s ease-in-out;
  -moz-transition: all 0.30s ease-in-out;
  -ms-transition: all 0.30s ease-in-out;
  -o-transition: all 0.30s ease-in-out;
text-transform: normal;
width: 150px;
line-height: 30px;
font-weight: 700;
font-family: Balto, sans-serif;
}
#optimal_savings { background: #6d98a8; color: #fff; display: none; padding: 15px; }
#optimal_savings p { margin-bottom: 0; }
#optimal_savings li { list-style: disc; position: initial; margin: 1em 0 0 0; }
.yuri-hide { display: none; }
.yuri-stuffs fieldset { background: #fff; padding: 15px; margin-bottom: 20px; max-width: 100%; }
.yuri-stuffs .fieldgroup { margin-bottom: 20px; }
.yuri-stuffs label { color: #6a6a6a; font-family: Balto, sans-serif; font-size; .8em; }
.yuri-stuffs #age,
.yuri-stuffs #income,
.yuri-stuffs #current_savings,
.yuri-stuffs #spouse_age,
.yuri-stuffs #spouse_income { color: #3c3c3c; font-style: normal; margin: 0 10px; padding: 5px; }
.yuri-stuffs label.error { color: #f04124; font-size: .8em; font-style: italic; }
.yuri-stuffs #age,
.yuri-stuffs #spouse_age { width: 50px; }
.yuri-stuffs #income,
.yuri-stuffs #spouse_income { width: 100px; }
.yuri-stuffs #current_savings { width: 100px; }
.yuri-stuffs input[type=radio] { margin: 0 5px 0 10px; }
.yuri-stuffs input[type=text] {
  border: 1px solid #ddd;
  outline: none;
  -webkit-transition: all 0.30s ease-in-out;
  -moz-transition: all 0.30s ease-in-out;
  -ms-transition: all 0.30s ease-in-out;
  -o-transition: all 0.30s ease-in-out;
}
.yuri-stuffs input[type=text]:focus {
  border: 1px solid #fff200;
  box-shadow: 0 0 5px #fff200;
}
.yuri-show-advanced { display: block; margin-bottom: 20px; }
.yuri-stuffs select {
background-color: #fafafa;
border: 1px solid #cccccc;
font-size: 0.77778rem;
color: rgba(0, 0, 0, 0.75);
line-height: normal;
border-radius: 0;
height: 2.05556rem;
padding: 0.44444rem;
display: block;
margin-top: 10px;
width: 100%;
}
This calculator assumes that you'll be able to withdraw between 4.7 and 5.5 percent (depending on your retirement age) of your nest egg each year for the rest of your life. That's the approximate rate you can get from a life annuity, an insurance product that pays a fixed (inflation-adjusted) amount each month until you die.
The calculator assumes you'll need 80 percent of your pre-retirement income to live comfortably. It assumes that you'll receive annual raises of 3 percent (plus cost of living) until age 50, and that after that you'll only get cost-of-living increases. It assumes you'll get average stock market returns (after inflation) of 4 percent. (These assumptions can all be changed by clicking "Show advanced options.")
It takes into account your projected Social Security benefit. Social Security has a progressive benefit formula, meaning that wealthier taxpayers have a smaller fraction of their income replaced in retirement. So the wealthier you are, the more you'll need to save to replace your pre-retirement income.
To protect your privacy, all calculations are done inside your browser. Information you enter into this form is never sent to Vox's servers.

(401(k) 2012)
Many employers offer to match the first 1 to 3 percent of salary an employee saves. If your employer offers an option like that, you should always take it. That's hundreds of dollars in free cash you get just for doing something you should be doing anyway.
<!--
window.pym || document.write( '<scr' + 'ipt src="http://apps.voxmedia.com/tools/javascripts/vendor/pym-15baa7e3.js"></scr' + 'ipt>' );
// -->
<!--
var Inflationadjusted_growth_of_10000_SP_500_investment = new pym.Parent( "Inflationadjusted_growth_of_10000_SP_500_investment", "http://apps.voxmedia.com/tools/charts-public/?labels=1990%2C1991%2C1992%2C1993%2C1994%2C1995%2C1996%2C1997%2C1998%2C1999%2C2000%2C2001%2C2002%2C2003%2C2004%2C2005%2C2006%2C2007%2C2008%2C2009%2C2010%2C2011%2C2012%2C2013%2C2014%2C2015&datasets=10000%2C9127%2C11587%2C12143%2C13016%2C12778%2C17222%2C20476%2C26984%2C34127%2C40238%2C35397%2C30714%2C23333%2C29444%2C31587%2C31984%2C36111%2C36587%2C22937%2C28413%2C32143%2C31905%2C36349%2C47381%2C53500&title=Inflation-adjusted%20growth%20of%20%2410%2C000%20S%26P%20500%20investment&description=&source=Robert%20Shiller%2FMoneyChimp&link=http%3A%2F%2Fwww.moneychimp.com%2Ffeatures%2Fmarket_cagr.htm&type=line&legend=Portfolio%20value", { xdomain: ".*.voxmedia.com" } );
// -->
Someone who invested $10,000 in the S&P 500 on January 1, 1990, and reinvested dividends, would have had almost $60,000 (in 1989 dollars) on January 1, 2015. Notice that even after stock market crashes in 2001-'03 and 2008-'09, our hypothetical investor still had more than twice his initial investment.
A fundamental principle of investing is that there's a trade-off between risk and reward. A savings account is a much safer place to put your money than the stock market in the short run, but staying out of the stock market is likely to leave you poorer in the long run.
In 2008 the S&P 500 — an index of the stocks of the 500 largest companies in America — lost more than a third of its value. The experience soured many people on the whole concept of investing in the stock market. Yet it's important to look at things from a long-term perspective. Anyone who started investing in the 1970s, 1980s, or early 1990s was still ahead after the 2008 crash. And anyone who held on to their stocks through the 2008 stock market plunge enjoyed big gains over the next six years. By the start of 2015, the market had regained all of its losses and was setting new records.
By the end of 2013, the market had erased all of its 2008 losses and then some
Things look even better if we look further back in history. Since the modern stock market emerged in the late 19th century, there has never been a 20-year period when average stock market returns were negative. Since 1915, the average return on the 500 largest US stocks — after adjusting for inflation — has been 6.9 percent.
So in the long run, stocks are likely to provide higher returns than less volatile investments. And if you're under 45, you can afford to take a long-term view. If the stock market crashes next month, you'll still have 20 years for the value of your portfolio to rebound. The odds are high that you'll come out ahead.
But it's essential not to panic when the stock market does fall. When the stock market crashed in 2008, a lot of people were tempted to sell. But that proved to be a big mistake. People who held on to their stocks wound up way ahead of people who sold in 2008 or 2009.

(Al Bello/Getty Images)
Okay, so you should buy some stocks. Which ones? The answer is simple: Buy all of them.
Individual stocks can be extremely volatile. There's always a risk that you'll pick the next Enron and be left with nothing. But there's more safety in numbers. On any given day, one stock might crash but others will be rising. So a basket of many stocks is less volatile than any single stock by itself.
This is known as diversification. And it applies beyond the American stock market. In addition to buying domestic stocks, you should also buy some foreign stocks. And you should buy bonds — the debt of corporations and governments.
Bonds are less volatile than stocks, and the value of stocks and bonds often move in opposite directions. So a mixed portfolio of stocks and bonds is a lot less volatile than an all-stock portfolio.
It would be a huge hassle to buy thousands of stocks one at a time. But fortunately, mutual fund companies have made the process relatively painless. Mutual fund companies offer funds that allow you to buy a small share of thousands of different stocks or bonds — just by buying into one fund.

Pay no attention to stock tips from finance gurus like CNBC's Jim Cramer. (Tulane)
Open a personal finance magazine and you'll see articles touting the latest hot stock tips. You'll also see ads from mutual fund companies touting their above-average investment returns. The evidence suggests that this is all kind of a scam.
Active mutual fund managers don't produce returns higher than the market average
A lot of people on Wall Street make a lot of money by convincing ordinary investors that they can provide better-than-average returns. But the reality is that beating the market is really difficult. Most people who promise to do it don't deliver.
In the 1960s, academic researchers began to show that "active" mutual fund managers — those who try to select stocks that will perform better than average — don't produce higher average returns than the market as a whole. This research led to the rise of a new type of mutual fund known as an index fund. Rather than trying to beat the market, these passively managed funds simply try to match the returns of a stock index such as the S&P 500. Index funds allow investors to earn the average market return, with as few expenses as possible.
A half-century later, studies are still finding that passively managed funds tend to beat actively managed ones. It's hard to outperform the market, but it's easy to waste clients' money trying. The higher expenses of actively managed funds wind up coming out of the pocket of ordinary investors.
So when choosing mutual funds, your most important criteria should be keeping costs down. Every mutual fund publishes an "expense ratio," which is the percentage of your investment that will get eaten up by management expenses each year. Whenever you have a choice between two similar funds, you should pick the one with lower expenses.

(Stefan Irvine/LightRocket via Getty Images)
Which fund should you buy? The best type of fund for a novice investor is a "target retirement" fund. You pick the year you want to retire, and the fund automatically allocates your savings to a mix of stocks and bonds that's appropriate for your expected retirement date.
There are two good options for target retirement funds. Vanguard funds such as the Target Retirement 2050 plan have a modest expense ratio of 0.18 percent, meaning that investors lose just $18 per year for every $10,000 invested. (Disclosure: I have most of my retirement savings in Vanguard mutual funds, and because Vanguard is structured as a cooperative, that technically makes me a Vanguard shareholder.)
Recently, State Street Bank and Fidelity began offering low-cost index funds of their own. With expense ratios of 0.17 percent and 0.16 percent, respectively — slightly cheaper than Vanguard's — these are also great options.
These expenses can add up to thousands of dollars in lost returns
Unfortunately, most other target retirement funds are a lot more expensive. For example, while the Fidelity Freedom Index funds have low costs, Fidelity also sells a similarly named "Freedom 2050" fund with an expense ratio of 0.77 percent. T. Rowe Price's Retirement 2050 funds has an expense ratio of 0.76 percent. If you invest $10,000 in these funds, you'll lose more than $70 every year (and more as your money grows). That's a terrible deal.
Unfortunately, employers don't always offer their employees access to low-cost target retirement funds. If your employer is one of them, you'll need to do a bit of extra work. Instead of buying a single target retirement fund, you'll want to invest in funds from the three categories I mentioned before: domestic stocks, international stocks, and bonds.
For each category, you'll want to choose the broadest fund with the lowest expense ratio. For example, Fidelity's Spartan Total Market fund, with an expense ratio as low as 0.05 percent, is a good choice for domestic stocks. It invests in more than 3,000 US stocks. Fidelity also has a Spartan International fund (0.12 percent expense ratio) for international stocks and a Spartan US Bond fund (0.10 percent expense ratio) for bonds.

Unfortunately, many mutual fund companies don't offer low-cost index funds. The table above shows some of the largest mutual fund companies in America, along with their lowest-cost fund in the three asset categories I mentioned before. In the right column is a weighted average of these expenses, assuming a portfolio of 60 percent domestic stocks, 20 percent international stocks, and 20 percent bonds.

(Education Images/UIG via Getty images)
As you can see, only Fidelity and Vanguard offer truly low-cost index funds. These companies let you construct a diversified portfolio with an expense ratio as low as 0.07 percent. State Street is next, offering funds with expense ratios of 0.16 percent or lower. But the other companies on the list charge 3 to 8 times as much as Vanguard and Fidelity.
While a fraction of a percentage point might not seem like a big difference, these expenses can add up to thousands of dollars in lost returns over the course of a typical worker's career. So if your employer only offers high-cost mutual funds in your 401(k) plan, you might want to ask your HR department to add lower-cost options from Vanguard, Fidelity, or State Street.
If that doesn't work, you should consider consider opting out of your employer's 401(k) plan altogether and invest in an IRA (discussed below) instead. That would allow you to take advantage of low-cost index funds or — even better — Vanguard's low-cost target retirement funds. But the rules about when you can do that are complicated and beyond the scope of this article.
If you don't have a target retirement fund, then you'll need to decide how much money to allocate to different types of funds. Here are some guidelines:

If you're under 45, you should have most of your money in high-risk, high-reward stocks (including both domestic and foreign companies), and only a small share in safe, low-return bonds. As you get older, you'll want to gradually shift to more bonds. About half of your retirement savings should be in bonds by the time you reach retirement age.
The exact ratio of stocks to bonds depends on how much risk you feel comfortable taking. If seeing the stock market plunge gives you heartburn, you might want to allocate a larger share of your portfolio to bonds. If you're willing to take a bit more risk in pursuit of higher returns, you should have a portfolio that's weighted more toward stocks. Of course, the closer you are to retirement the more conservative you'll want to be with your money.
If you're under 40, you should have most of your money in high-risk, high-reward stocks
In some years, stocks will perform dramatically better than bonds, pushing the ratio of stocks to bonds upward. In other years, stock prices will fall, leading to a portfolio with bonds over-represented. When this happens, you should sell some of the over-represented assets and buy more of the under-represented ones, bringing your portfolio back into balance.
This will mean selling assets that have performed well and buying assets that perform poorly. That might seem counterintuitive, but think about it this way: Selling stocks as they rise helps to lock in some of the profits even if prices subsequently crash. And buying stocks when they're cheap gives you more upside if they subsequently rise in value.
Target retirement funds handle this chore for you automatically. If you're managing your portfolio yourself, then you'll want to log in every six months to make sure the ratio of stocks to bonds (and of domestic stocks to international ones) stays on target.

(Education Images/UIG via Getty Images)
If you have a job that offers a 401(k) plan, this is a convenient way to save for retirement. The money is automatically deducted from your paycheck, helping you to stay on track. And you don't have to pay taxes on money in your 401(k) until you withdraw it in retirement.
But if you don't have a 401(k) at work — or you don't have a full-time job at all — you should still be saving for retirement. Congress has created a separate system for people in this situation. Known as an Individual Retirement Account, it provides tax benefits similar to those of a 401(k) for those who don't have an employer-sponsored retirement plan.
There are two types of IRAs. A traditional IRA works a lot like a 401(k) plan. Contributions can be deducted from your taxes, and taxes are deferred on earnings. But as with a 401(k), you have to pay a hefty penalty if you take out the money before you reach retirement age. And you also pay taxes on money you withdraw from the IRA during retirement.
A Roth IRA works the other way around: You pay taxes when you put money in, but earnings and withdrawals are tax-free once you retire. You can also withdraw your contributions (but not earnings) to a Roth IRA at any time without paying a penalty.
Which one you should pick depends on whether you expect your tax rate in retirement to be higher or lower than the tax rate you're paying now. When you're just starting your career, you might be in a lower tax bracket than you expect to be in later in life. In that case, a Roth IRA is a good choice. On the other hand, if you expect to be in a lower tax bracket in retirement, then a traditional IRA might make more sense.
There are also income-based limits on contributing to IRAs, so if you make more than $116,000 you'll want to double-check your eligibility (and also check if you're eligible for the back-door Roth loophole).
<!--
var VOX = VOX || {};
(function(jQuery) {

  var $ = jQuery;

  VOX.YuriSpecial = (function ( $ ) {

    var showHideDiv = function () {
      var div_to_showHide = $( this ).data( 'div' ),
          current_status  = $( this ).data( 'status' ),
          html_for_open   = 'Hide advanced options',
          html_for_closed = 'Show advanced options';
      // Show hidden div
      $( '.' + div_to_showHide ).toggle( 'slow' );
      // Change language and status
      if ( current_status == 'closed' ) {
        $( this ).html( html_for_open );
        $( this ).data( 'status', open );
      } else {
        $( this ).html( html_for_closed );
        $( this ).data( 'status', closed );
      }
    };

    var showHideSpouse = function () {
      var marriage_status = $( '#married:checked' ).val();
      if ( marriage_status == 'married' ) {
        $( '.yuri-spouse' ).show( 'slow' );
      } else {
        $( '.yuri-spouse' ).hide( 'slow' );
      }
    };

    var addEvents = function () {
      $( '.yuri-show' ).on( 'click', showHideDiv );
      $( 'input[name=marital_status]:radio' ).on( 'change', showHideSpouse );
    };

    var init = function () {
      addEvents();
    };

    init();

  })(jQuery);

  jQuery.validator.addMethod("money", function(value, element) {
    return this.optional(element) || 
                 /^\$?(\d{1,3}(\,\d{3})*|(\d+))(\.\d{2})?$/.test(value);
  }, "Error");

  jQuery.validator.addMethod("money_and_married", function(value, element) {
    return ((this.optional(element) 
                   || /^\$?(\d{1,3}(\,\d{3})*|(\d+))(\.\d{2})?$/.test(value))
                 || !($("#married").is(':checked')));
  }, "Error");

  jQuery.validator.addMethod("age_and_married", function(value, element) {
    return !($("#married").is(':checked')) ||
                 (parseInt(value) > 12 && parseInt(value) < 68);
  }, "Error");

  $( document ).ready( function () {

    $("select#return_rate").val("4");
    $("select#wage_growth").val("3");
    $("select#retirement_age").val("67");
    $("select#income_replacement_rate").val("80");
    $("select#social_security_reduction").val("0");
    $('input:radio[name="marital_status"][value="single"]').click();

    $( "#retirement_form" ).validate( {
        rules: {
            income:
            {
              required: true,
              money: true,
            },
            age: 
            {
              required: true,
              number: true,
              min: 13,
              max: 67,
            },
            current_savings: 
            {
              required: true,
              money: true,
            },
            spouse_income: 
            {
              required: "#married:checked",
              money_and_married: true,
            },
            spouse_age: 
            {
              required: "#married:checked",
              age_and_married: true,
            },
        },
        messages: {
            income: "Please enter your income",
            age: "Please enter an age between 13 and 67",
            current_savings: "Please enter your current savings",
            spouse_income: "Please enter your spouse's income",
            spouse_age: "Please enter an age between 13 and 67",
        },
        submitHandler: calculate,
    });
  });

  // Grab data from the form and do a bunch of calculations

  function calculate() {

      // Age of the user

      age = parseInt(document.getElementById("age").value);

      // Current income of the user

      income = getDollar(document.getElementById("income").value);

      // Average rate of return on savings

      return_rate = parseInt(document.getElementById("return_rate").value)/100;

      // Desired age of retirement

      retirement_age = parseInt(document.getElementById("retirement_age").value);

      // How much will Congress cut Social Security benefits?

      social_security_reduction = parseFloat(document.getElementById("social_security_reduction").value);

      // How much the user has in the bank right now

      current_savings = getDollar(
                          document.getElementById("current_savings").value);

      // Rate at which wages increase prior to age 50 (we assume 0 after that)

      wage_growth = 1+parseFloat(
                          document.getElementById("wage_growth").value)/100;

      // Fraction of user's pre-retirement income needed to live comfortably

      income_replacement_rate = parseInt(
                          document.getElementById("income_replacement_rate").value)/100;

      if(document.getElementById("married").checked)
      {
        married = true;
        spouse_income = getDollar(document.getElementById("spouse_income").value);
        spouse_age = parseInt(document.getElementById("spouse_age").value);
      }
      else
      {
        married = false;
      }

      // Compute the user's expected Social Security benefit amount based on
      // projected income

      social_security_benefit = compute_ss(age, retirement_age, income, 
                                           wage_growth, social_security_reduction);

  //    console.log("Me: "+social_security_benefit);

      if(married)
      {
        spouse_retirement_age = retirement_age-age+spouse_age;
        spouse_ss_benefit = compute_ss(spouse_age, retirement_age-age+spouse_age,spouse_income, wage_growth, social_security_reduction);

  //    console.log("Spouse: "+spouse_ss_benefit);

        // If one spouse's SS benefit is more than twice as big as the other's,
        // the second spouse's benefit gets bumped up to half the first spouse's
        // benefit.

        if(spouse_ss_benefit < social_security_benefit/2)
        {
          spouse_ss_benefit = social_security_benefit/2;
        }

        // This goes both ways

        if(spouse_ss_benefit > social_security_benefit * 2)
        {
          social_security_benefit = spouse_ss_benefit < 2;
        }

        social_security_benefit += spouse_ss_benefit;
        income += spouse_income;
      }

      // Compute how much money the user will need by the time he reaches
      // retirement age.

      required_savings = get_required_savings(income, wage_growth, 
                      age, retirement_age, income_replacement_rate,
                      current_savings, return_rate);

      // Compute the savings rate that will allow the user to reach the
      // required level of savings.

      required_savings_rate = get_required_savings_rate(age, retirement_age,
                      income, return_rate, required_savings, wage_growth);

      age_25_income = income*get_wage_factor(age, 25, wage_growth);

      // Compute the necessary savings rate if the user had started
      // saving at age 25

      optimal_savings = get_required_savings(income, wage_growth, 
                      age, retirement_age, income_replacement_rate,
                      0, return_rate);

      optimal_savings_rate = get_required_savings_rate(
                      25, 
                      retirement_age,
                      age_25_income,
                      return_rate,
                      optimal_savings,
                      wage_growth);

      now_optimal_savings = calculate_savings(25, age, age_25_income, 
                          return_rate, optimal_savings_rate, 0, wage_growth);

      retirement_optimal_ratio = calculate_savings(25, retirement_age, 
              age_25_income, return_rate, optimal_savings_rate, 0, wage_growth)
                  / (age_25_income*get_wage_factor(25, retirement_age, wage_growth));

      set_messages_about_savings(age, now_optimal_savings, current_savings,
                           retirement_optimal_ratio,
                           retirement_age, required_savings_rate, income_replacement_rate);
  }

  function set_messages_about_savings(age, now_optimal_savings, current_savings,
                           retirement_optimal_ratio,
                           retirement_age, required_savings_rate, income_replacement_rate)
  {
  $( '#optimal_savings' ).show();
  $('html,body').animate({
     scrollTop: $("#optimal_savings").offset().top - 20
  });
    s = "";

    if(required_savings_rate == 0)
    {
      document.getElementById("optimal_savings").innerHTML  =
        "<p>Congratulations! You've done all the saving you'll need to do to "+
        "reach your goals. Just leave your current savings of <b>$"+
        number_with_commas(current_savings)+
        "</b> in a diversified portfolio (as described below) "+
        " until age "+retirement_age+" and you'll be able to "+
        "retire in comfort.</p>";
      return;
    }

    if(age<30)
    {
      
      document.getElementById("optimal_savings").innerHTML  =
        "<p>Congrats on starting to save when you're under 30. "+
        "You have a lot of time to save, so it will be easier "+
        "than for people who start saving later in life. "+
        "To retire at age "+retirement_age+", you'll need to save <b>" +
        round_to(required_savings_rate*100,1) +
        " percent</b> of your income each year between now and then.";

      return;
    }

    if(required_savings_rate > .40)
    {
      document.getElementById("optimal_savings").innerHTML  =
        "<p>You would need to save more than "+
        "<b>40 percent</b> of your income between "+
        "now and retirement to retire at age "+retirement_age+". "+
        "You may need to delay retirement in order to give you more time to "+
        "accumulate savings."
      
      return;
    }
      
    if(current_savings > now_optimal_savings)
    {
      s += 
        "<p>You're doing great!</p>"+
        "<ul><li>At this point in your career you should have "+
        "around <b>$"+number_with_commas(round_to(now_optimal_savings, -3))+
        "</b> in the bank. You're ahead of the "+
        "curve, with <b>$"+number_with_commas(current_savings)+"</b>.</li> ";

      s += "<li>To meet your retirement goals, you need to save <b>" +
           round_to(required_savings_rate*100,1) +
           " percent</b> of your income each year between now and age "+
           retirement_age+"</li>";
    }

    if(current_savings <= now_optimal_savings &&
       current_savings > now_optimal_savings * 0.6)
    {
      s += 
        "<p>You've done a significant amount of saving, but you'll "+
        "need to save a higher percentage of your income to retire by "+
        "age "+retirement_age+".</p> "+
        "<ul><li>At this point in your career you should have "+
        "around <b>$"+number_with_commas(round_to(now_optimal_savings, -3))+
        "</b> in the bank. You're a little bit behind the curve with "+
        "savings of <b>$" +
        number_with_commas(current_savings)+"</b>.</li>";

      s += "<li>To catch up, you need to save <b>" +
           round_to(required_savings_rate*100,1) +
           " percent</b> of your income each year between now "+
           "and retirement.</li>\n\n";
    }

    if(current_savings <= now_optimal_savings * 0.6)
    {
      s += 
        "<p>You're going to need to save more "+
        "if you want to retire by age "+retirement_age+".</p>"+
        "<ul><li> At this point in your career you should have "+
        "around <b>$"+number_with_commas(round_to(now_optimal_savings, -3))+
        "</b> in the bank"

      if(current_savings > 0)
      {
        s+= ", but you only have $" + number_with_commas(current_savings)+".</li>";
      }
      else
      {
        s+= ".</li>";
      }

      s += "<li>You'll need to increase your savings rate to <b>"+
           round_to(required_savings_rate*100,1) +
           "</b> percent to reach your retirement goal.</li>";
    }
    s +=
      "<li>You'll want your savings at your retirement age of "+retirement_age+" to be "+
      round_to(retirement_optimal_ratio,1) + " times your income at age "+
      retirement_age+". </li>";

    if(current_savings <= now_optimal_savings * 0.6)
    {
      s +=
        "<li>If these figures seem out of reach, remember that every little bit helps. "+
        "Social Security only replaces 40 percent of pre-retirement income for a "+
        "typical worker. If you can save enough to boost the figure to 50 or 60 percent, "+
        "that will substantially improve your quality of life. And the sooner you start, "+
        "the more time your savings will have to grow."+
        "</li>";
    }

    s +=
      '<li>Click "Show advanced options" to change your retirement age, how fast '+
      'you expect your income to grow, and other assumptions.</li>';


    s += "</ul>"

    document.getElementById("optimal_savings").innerHTML  = s;
  }

  function round_to(x,n)
  {
    return Math.round(x*Math.pow(10,n))/Math.pow(10,n);
  }

  function get_required_savings(income, wage_growth, starting_age, retirement_age,
                      income_replacement_rate, current_savings, return_rate)
  {
    retirement_income = income * get_wage_factor(starting_age, retirement_age, wage_growth);

    target_income = retirement_income * income_replacement_rate
                      - social_security_benefit * 12;

    required_savings = target_income / get_annuity_rate(retirement_age)
      - current_savings * Math.pow(1+return_rate, retirement_age-starting_age);

    return (required_savings)
  }

  function get_annuity_rate(retirement_age)
  {
    return 0.045+(retirement_age - 60)*.001;
  }

  function get_required_savings_rate(starting_age, retirement_age, income, 
                        return_rate, required_savings, wage_growth)
  {
    if(required_savings <= 0)
    {
      return 0;
    }

    if(required_savings > calculate_savings(starting_age, retirement_age,
                           income, return_rate, 1, 0, wage_growth))
    {
      return 1;
    }

    error = 1000;

    rate = .50;

    delta = .25;

    count = 0;

    while(Math.abs(error) > 1)
    {
      count++;

      if(count>100) { return 1};

      savings = calculate_savings(starting_age, retirement_age, income, 
                        return_rate, rate, 0, wage_growth);

      error = savings - required_savings;


      if(error < 0)
      {
        rate = rate + delta;
      }
      else
      {
        rate = rate - delta;
      }

      delta=delta/2;

    }

    return rate;
  }

  // Compute the monthly social security benefit you can expect given
  // the retirement age, income, etc.

  function compute_ss(current_age, retirement_age, income, 
                      wage_growth, social_security_reduction)
  {
    years_to_retirement = retirement_age - current_age;

    if(years_to_retirement < 10)
    {
      benefit_cut =0;
    }
    else
    {
      if(years_to_retirement < 20)
      {
        benefit_cut = social_security_reduction * (years_to_retirement-10) * 0.1
      }
      else
      {
        benefit_cut = social_security_reduction;
      }
    }

    starting_age = retirement_age-35;

    starting_wage = income / get_wage_factor(starting_age, current_age, wage_growth);

    total_wages = 0;

    for(i=0;i<35; i++)
    {
      total_wages += starting_wage 
                  * get_wage_factor(starting_age, starting_age+i, wage_growth);
    }

    monthly_earnings = Math.min(total_wages/35, 117000)/12;

    first_component = Math.min(monthly_earnings,816)*0.9;
    second_component = Math.min(Math.max(monthly_earnings-816,0),4917-816)*0.32;
    third_component = Math.min(Math.max(monthly_earnings-4917,0),9750-4917)*0.15;

    monthly_benefit = first_component + second_component + third_component;

    ss_reduction_factor = compute_ss_reduction(current_age, retirement_age);

    return(monthly_benefit * ss_reduction_factor * (1-benefit_cut));
  }

  function get_wage_factor(starting_age, age, wage_growth)
  {
    // Lower wage growth after age 50

    fifty_plus_rate = 1;

    if(age<=50 && starting_age <= 50 )
    {
      return Math.pow(wage_growth, age-starting_age);
    }

    if(starting_age>50 && age > 50)
    {
      return Math.pow(fifty_plus_rate, age-starting_age);
    }

    if(starting_age<=50 && age > 50)
    {
      return Math.pow(wage_growth, 50-starting_age)
               * Math.pow(fifty_plus_rate, age-50);
    }

    // Note that these exponents are negative so the value returned wil be
    // < 1

    return (Math.pow(fifty_plus_rate, 50-starting_age)
               * Math.pow(wage_growth, age-50));
  }

  // Social Security benefits are reduced or incraesed based on whether you
  // retire before or after your nomal retirement age.

  function compute_ss_reduction(current_age, retirement_age)
  {
    if(retirement_age>70)
    {
      retirement_age = 70;
    }

    if(retirement_age <62)
    {
      return 0;
    }

    normal_retirement_age = get_normal_retirement_age(current_age);

    // Normal retirement

    if(retirement_age == normal_retirement_age)
    {
      return 1;
    }

    // Retirement delayed beyond normal retirement age

    if(retirement_age>normal_retirement_age)
    {
      return 1 + 0.08*(retirement_age-normal_retirement_age);
    }

    // Early retirement

    if(retirement_age>normal_retirement_age - 3)
    {
      return(1-0.2/3*(normal_retirement_age - retirement_age));
    }
    else
    {
      return(0.80-0.05*(normal_retirement_age-retirement_age -3));
    }
  }

  // The Social Security eligibility age is higher for people born after 
  // the 1950 than for people born before. I'm cheating a little bit
  // by pretending the eligibility year jumps in 1957. Actually the increase
  // is phased in in 2-month increments.

  function get_normal_retirement_age(current_age)
  {
    year = new Date().getFullYear();

    birth=year-age;

    if(birth<1957)
    {
      return 66;
    }
    else
    {
      return 67;
    }
  }

  function calculate_savings(starting_age, ending_age, income, return_rate, 
                             savings_rate, current_savings, wage_growth)
  {
    savings = current_savings;

    for(i = 0; i<ending_age-starting_age+1; i++)
    {
      savings *= (1 + return_rate);
      savings += income 
               * get_wage_factor(starting_age, starting_age+i, wage_growth)
               * savings_rate;
    }

    return savings;
  }

  function getDollar(string)
  {
    return parseInt(string.replace(/[^\d\.\-]/g, ""));
  }

  function number_with_commas(x) {
      var parts = x.toString().split(".");
      parts[0] = parts[0].replace(/\B(?=(\d{3})+(?!\d))/g, ",");
      return parts.join(".");
  }

})(jQuery);
// -->
A rejection letter written in 1938 to a young woman applying for a creative position at Walt Disney serves as a reminder of the casual nature of socially accepted discrimination against female workers. The letter states that "women do not do any of the creative work in connection with preparing the cartoons for the screen, as that work is performed entirely by young men. For this reason girls are not considered for the training school."
Kevin Burg/Flickr
Almost an exact version of it was sent to Frances Brewer in 1939, although on significantly less-cool letterhead.
It’s not that Disney didn’t employ women. It employed lots of them as "inkers" who corrected and filled animations, and worked in physically separate environments from the more prestigious male animators. In this video, you can see how the studio separated "creative" animation from inking:

But inking is just another part of the animation process — at times a grueling one, as Vanity Fair profiled in 2010. The segregation of work was doomed to fail, in part because of war. In 1941, the studio began training female employees to animate, and in a speech, Walt Disney told employees why. Note that Disney calls the adult women employees "girls":
The girls are being trained for inbetweens for very good reasons. The first is, to make them more versatile, so that the peak loads of inbetweening and inking can be handled. Believe me when I say that the more versatile our organization is, the more beneficial it is to the employees, for it assures steady employment for the employee, as well as steady production turnover for the Studio.
The second reason is that the possibility of a war, let alone the peacetime conscription, may take many of our young men now employed, and especially many of the young applicants. I believe that if there is to be a business for these young men to come back to after the war, it must be maintained during the war. The girls can help here.
Third, the girl artists have the right to expect the same chances for advancement as men, and I honestly believe that they may eventually contribute something to this business that men never would or could. In the present group that are training for inbetweens there are definite prospects, and a good example is to mention the work of Ethel Kulsar and Sylvia Holland on "The Nutcracker Suite," and little Retta Scott, of whom you will hear more when you see Bambi.
It's easy to forget that tragic events like war can, at times, yield positive social benefits, but the need for a reliable pool of workers seems to have pushed Walt Disney to allow women to "contribute something to this business that men never could or would." But don't take the historic changes in training to mean there's no longer a need or room for progress — Disney had its first woman film director in 2013 (Frozen).