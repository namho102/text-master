70 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 6, NO. 1, MARCH 2011
Visual Cryptography for Biometric Privacy
Arun Ross, Senior Member, IEEE, and Asem Othman, Student Member, IEEE
Abstract—Preserving the privacy of digital biometric data (e.g.,
face images) stored in a central database has become of paramount
importance. This work explores the possibility of using visual cryptography
for imparting privacy to biometric data such as fingerprint
images, iris codes, and face images. In the case of faces, a
private face image is dithered into two host face images (known
as sheets) that are stored in two separate database servers such
that the private image can be revealed only when both sheets are
simultaneously available; at the same time, the individual sheet images
do not reveal the identity of the private image. A series of experiments
on the XM2VTS and IMM face databases confirm the
following: 1) the possibility of hiding a private face image in two
host face images; 2) the successful matching of face images reconstructed
from the sheets; 3) the inability of sheets to reveal the identity
of the private face image; 4) using different pairs of host images
to encrypt different samples of the same private face; and 5) the
difficulty of cross-database matching for determining identities. A
similar process is used to de-identify fingerprint images and iris
codes prior to storing them in a central database.
Index Terms—De-identification, face, fingerprint, IrisCodes, privacy,
visual cryptography.
I. INTRODUCTION
BIOMETRICS is the science of establishing the identity of
an individual based on physical or behavioral traits such
as face, fingerprints, iris, gait, and voice [1]. A biometric authentication
system operates by acquiring raw biometric data from a
subject (e.g., face image), extracting a feature set from the data
(e.g., eigen-coefficients), and comparing the feature set against
the templates stored in a database in order to identify the subject
or to verify a claimed identity. The template of a person in
the database is generated during enrollment and is often stored
along with the original raw data. This has heightened the need
to accord privacy1 to the subject by adequately protecting the
contents of the database.
For protecting the privacy of an individual enrolled in a biometric
database, Davida et al. [2] and Ratha et al. [3] proposed
storing a transformed biometric template instead of the original
biometric template in the database. This was referred to as a
Manuscript received June 28, 2010; revised September 24, 2010; accepted
November 02, 2010. Date of publication December 06, 2010; date of current
version February 16, 2011. This work was supported by U.S. NSF CAREER
Award IIS 0642554. A preliminary version of this work was presented at the
SPIE 2010 Conference, Orlando, FL. The associate editor coordinating the review
of this manuscript and approving it for publication was Dr. Ajay Kumar.
The authors are with the Lane Department of Computer Science and Electrical
Engineering, West Virginia University, Morgantown, WV 26506-6109
USA (e-mail: arun.ross@mail.wvu.edu; asem.othman@mail.wvu.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TIFS.2010.2097252
1The term “privacy” as used in this paper refers to the de-identification of
biometric data.
private template [2] or a cancelable biometric [3]. Feng et al.
[4] proposed a three-step hybrid approach that combined the
advantages of cryptosystems and cancelable biometrics. Apart
from these methods, various image hiding approaches [5]–[7]
have been suggested by researchers to provide anonymity to the
stored biometric data.
For according privacy to face images present in surveillance
videos, Newton et al. [8] and Gross et al. [9] introduced a face
de-identification algorithm that minimized the chances of performing
automatic face recognition while preserving details of
the face such as expression, gender, and age. Bitouk et al. [10]
proposed a face swapping technique which protected the identity
of a face image by automatically substituting it with replacements
taken from a large library of public face images. However,
in the case of face swapping and aggressive de-identification,
the original face image can be lost. Recently, Moskovich and
Osadchy [11] proposed a method to perform secure face identi-
fication by representing a private face image with indexed facial
components extracted from a public face database.
In this paper, the use of visual cryptography is explored to
preserve the privacy of biometric data (viz., raw images) by decomposing
the original image into two images in such a way
that the original image can be revealed only when both images
are simultaneously available; further, the individual component
images do not reveal any information about the original image.
Figs. 1 and 2 show block diagrams of the proposed approach for
three biometric modalities. During the enrollment process, the
private biometric data is sent to a trusted third-party entity. Once
the trusted entity receives it, the biometric data is decomposed
into two images and the original data is discarded. The decomposed
components are then transmitted and stored in two different
database servers such that the identity of the private data is
not revealed to either server. During the authentication process,
the trusted entity sends a request to each server and the corresponding
sheets are transmitted to it. Sheets are overlaid (i.e.,
superimposed) in order to reconstruct the private image thereby
avoiding any complicated decryption and decoding computations
that are used in watermarking [5], [6], steganography [7],
or cryptosystem [12] approaches. Once the matching score is
computed, the reconstructed image is discarded. Further, cooperation
between the two servers is essential in order to reconstruct
the original biometric image.
For irides and fingerprints, as shown in Fig. 1, the biometric
image is decomposed by the visual cryptography scheme and
two noise-like images known as sheets are produced. In the case
of securing an iris template, the iris code is encrypted instead of
the iris image.
For faces, as shown in Fig. 2, each private face image is decomposed
into two independent public host images. In this scenario,
the private image can be viewed as being encrypted into
two host face images.
1556-6013/$26.00 © 2010 IEEE
ROSS AND OTHMAN: VISUAL CRYPTOGRAPHY FOR BIOMETRIC PRIVACY 71
Fig. 1. Proposed approach for de-identifying and storing a fingerprint image.
A similar technique is used for iris codes.
Fig. 2. Proposed approach for de-identifying and storing a face image.
The use of face images as hosts for a private face image (as
opposed to using random noise or other natural images) has several
benefits in the context of biometric applications. First, the
demographic attributes of the private face images such as age,
gender, ethnicity, etc. can be retained in the host images thereby
preserving the demographic aspects of the face while perturbing
its identity. Alternately, these demographic attributes, as manifested
in an individual’s face, can also be deliberately distorted
by selecting host images with opposite attributes as that of the
private image. Second, a set of public face images (e.g., those
of celebrities) may be used to host the private face database. In
essence, a small set of public images can be used to encrypt the
entire set of private face images. Third, using nonface images
as hosts may result in visually revealing the existence of a secret
face as can be seen in Fig. 4. Finally, while decomposing
the face image into random noise structures may be preferable,
it can pique the interest of an eavesdropper by suggesting the
existence of secret data.
Additionally, the proposed approach addresses the following
template protection requirements [12]–[14]. 1) Diversity: Since
different applications can adopt different sets of host images
for encrypting the same private face image, cross-matching
across applications to reveal the identity of a private face
image will be difficult. For iris codes and fingerprints, the
sheets appear as random noise making it difficult to match
them across databases. 2) Revocability: If the private data is
deemed to be compromised, then it can be decomposed again
into two new sheets based on new host images. However, in
reality, break-ins to a server are very hard to detect when the
attacker simply steals certain information without modifying
the stored data. To strengthen security, the decomposing operation
can be periodically invoked at regular time intervals.
3) Security: It is computationally hard to obtain the private
biometric image from the individual stored sheets due to the
use of visual cryptography. Furthermore, the private image is
revealed only when both sheets are simultaneously available.
By using distributed servers to store the sheets, the possibility
of obtaining the original private image is minimized. There
have been numerous efforts in the literature to guarantee that
the data stored in distributed databases are protected from
unauthorized modification and inaccurate updates (e.g., [15])
4) Performance: As will be shown in the experiments section,
the recognition performance due to the reconstructed image is
not degraded after decryption.
The rest of the paper is organized as follows. In Section II a
basic introduction to visual cryptography and its extensions are
presented. Sections III and IV discuss the proposed approach
for securing iris, fingerprint, and face images. Section V reports
the experimental results and Section VI concludes the paper.
II. VISUAL CRYPTOGRAPHY
One of the best known techniques to protect data such as biometric
templates [16] is cryptography. It is the art of sending
and receiving encrypted messages that can be decrypted only
by the sender or the receiver. Encryption and decryption are
accomplished by using mathematical algorithms in such a way
that no one but the intended recipient can decrypt and read the
message. Naor and Shamir [17] introduced the visual cryptography
scheme (VCS) as a simple and secure way to allow the
secret sharing of images without any cryptographic computations.
VCS is a cryptographic technique that allows for the encryption
of visual information such that decryption can be performed
using the human visual system. The basic scheme is referred
to as the -out-of- VCS which is denoted as VCS
[17]. Given an original binary image , it is encrypted in images,
such that
(1)
where is a Boolean operation, , is an
image which appears as white noise, , and is the number
of noisy images. It is difficult to decipher the secret image
using individual ’s [17]. The encryption is undertaken in
such a way that or more out of the generated images are
necessary for reconstructing the original image .
In the case of (2, 2) VCS, each pixel in the original image
is encrypted into two subpixels called shares. Fig. 3 denotes the
shares of a white pixel and a black pixel. Note that the choice
of shares for a white and black pixel is randomly determined
(there are two choices available for each pixel). Neither shares
provide any clue about the original pixel since different pixels
in the secret image will be encrypted using independent random
choices. When the two shares are superimposed, the value of
the original pixel can be determined. If is a black pixel, we
get two black subpixels; if it is a white pixel, we get one black
subpixel and one white subpixel. Therefore, the reconstructed
image will be twice the width of the original secret image and
72 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 6, NO. 1, MARCH 2011
Fig. 3. Illustration of a 2-out-of-2 VCS scheme with 2 subpixel construction.
Fig. 4. Encryption of a private face image in two standard host images.
(a) Host 1: Cameraman image. (b) Host 2: Lena image. (c) A private face
image. (e) and (f) The two host images after visual encryption (two sheets).
(g) Result of superimposing (e) and (f).
Fig. 5. Encryption of a private face image in two prealigned and cropped face
images. (a) and (b) are two host images. (c) is a private face image. (e) and
(f) are the host images after visual encryption (two sheets). (g) is the result of
overlaying (e) and (f).
there will be a 50% loss in contrast [17]. However, the original
image will become visible.
In 2002, Nakajima and Yamaguchi [18] presented a
2-out-of-2 extended VCS for natural images. They suggested
a theoretical framework for encoding a natural image in innocuous
images as illustrated in Figs. 4 and 5. This is known as
the gray-level extended visual cryptography scheme (GEVCS).
In this work, the basic VCS is used to secure iris codes and
fingerprint images and the extended VCS for grayscale images
is used to secure face images. The basic VCS and its extension
(GEVCS) are discussed in detail below.
A. Visual Cryptography Scheme (VCS)
There are a few basic definitions which need to be provided
before formally defining the VCS model and its extensions.
1) Secret image : The original image that has to be hidden.
In our application, this is the private biometric image. 2) Hosts
: These are the face images used to encrypt the secret
image using the GEVCS. In our application, these correspond
to the face images in the public dataset. 3) Sheets : The
secret image is encrypted into sheet images which appear as
random noise images (in the case of VCS) or as a natural
host image (in the case of GEVCS). 4) Target : The
image reconstructed by stacking or superimposing the sheets.
5) Subpixel: Each pixel is divided into a certain number of
subpixels during the encryption process. 6) Pixel Expansion
: The number of subpixels used by the sheet images to encode
each pixel of the original image. 7) Shares: Each pixel
is encrypted by collections of black-and-white subpixels.
These collections of subpixels are known as shares. 8) Relative
Contrast : The difference in intensity measure between
a black pixel and a white pixel in the target image. 9) OR-ed
-vector : An matrix is transformed to an -dimensional
vector by applying the Boolean OR operation across each
of the columns. 10) Hamming weight : The number
of “1” bits in a binary vector .
The -out-of- VCS deals with binary images. Each pixel is
reproduced as shares with each share consisting of subpixels.
This can be represented and described by an
Boolean matrix where if and only if the
th subpixel in the th share is black. The matrix is selected
randomly from one of two collections of Boolean matrices
and ; the size of each collection is . If the pixel
in the secret image is a white pixel, one of the matrices in is
randomly chosen; if it is a black pixel, a matrix from is randomly
chosen. Upon overlaying these shares, a gray level for
the pixel of the target image becomes visible and it is proportional
to the Hamming weight, , of the OR-ed -vector
for a given matrix . It is interpreted visually as black if
and as white if for some fixed
threshold and relative difference . The contrast
of the target is the difference between the minimum
value of a black pixel and the maximum allowed value for
a white pixel, which is proportional to the relative contrast
and the pixel expansion . The scheme is considered valid
if the following three conditions are satisfied. Condition 1: For
any matrix in , the OR operation on any of the rows
satisfies . Condition 2: For any matrix in
, the OR operation on any of the rows satisfies .
Condition 3: Consider extracting rows, , from two matrices,
and resulting in new matrices and
. Then, and are indistinguishable in that there exists
a permutation of columns of which would result in . In
other words, any matrix and are identical
up to a column permutation.
Conditions 1 and 2 define the image contrast due to VCS.
Condition 3 imparts the security property of a VCS which
states that the careful examination of fewer than shares will not
provide information about the original pixel . Therefore, the
important parameters of the scheme are the following. First, the
number of subpixels in a share ; this parameter represents
the loss in resolution from the original image to the resultant
target image and it needs to be as small as possible such that the
ROSS AND OTHMAN: VISUAL CRYPTOGRAPHY FOR BIOMETRIC PRIVACY 73
Fig. 6. Illustration of a 2-out-of-2 scheme with 4 subpixel construction.
target image is still visible. In addition, the subpixels need
to be in the form of a matrix where in order
to preserve the aspect ratio of the original image. Second, ,
which is the relative difference in the Hamming weight of the
combined shares corresponding to a white pixel and that of a
black pixel in the original image; this parameter represents the
loss in contrast and it needs to be as large as possible to ensure
visibility of the target pixel. Finally, the size of the collection
of and , , which represents the number of possibilities
for . This parameter does not directly affect the quality of the
target image.
The scheme can be illustrated by a (2, 2) VCS example which
is shown in Fig. 6. One pixel of the original image corresponds
to four pixels in each share. Therefore, six patterns of shares are
possible. Based on this, the following collection of matrices are
defined:
This 2-out-of-2 VCS has the parameters , ,
and . A secret image is encrypted by selecting shares in
the following manner. If the pixel of the secret binary image is
white, the same pattern of four pixels for both shares is randomly
selected which is equivalent to randomly selecting a Boolean
matrix from the collection . If the pixel of the original
image is black, a complementary pair of patterns is randomly
picked which is equivalent to selecting a Boolean matrix from
the collection . Conditions 1 and 2 can be easily tested to
validate this (2, 2) VCS. The last condition which is related to
the security of the scheme can be verified by taking any row
from and and observing that they have the
same frequency of black and white values.
B. Gray-Level Extended Visual Cryptography Scheme
(GEVCS)
VCS allows one to encode a secret image into sheet images,
each revealing no information about the original. Since
these sheets appear as a random set of pixels, they may pique
the curiosity of an interceptor by suggesting the existence of
a secret image. To mitigate this concern, the sheets could be
reformulated as natural images as stated by Naor and Shamir
[17]. Ateniese et al. [19] introduced such a framework known
as the extended VCS. Nakajima and Yamaguchi [18] proposed
a theoretical framework to apply extended visual cryptography
on grayscale images (GEVCS) and also introduced a method
to enhance the contrast of the target images. The GEVCSoperates
by changing the dynamic range of the original and host
images, transforming the gray-level images into meaningful binary
images (also known as halftoned images) and then applying
a Boolean operation on the halftoned pixels of the two hosts and
the original image. However, some of these pixels (in the host
and the original) have to be further modified. This is explained
in more detail below.
1) Digital Halftoning and Pixel Expansion: Digital
halftoning is a technique for transforming a digital gray-scale
image to an array of binary values represented as dots in the
printing process [20]. Error diffusion is a type of halftoning
technique in which the quantization error of a pixel is distributed
to neighboring pixels which have not yet been processed. Floyd
and Steinberg [21] described a system for performing error
diffusion on digital images based on a simple kernel. Their
algorithm could also be used to produce output images with
more than two levels. So, rather than using a single threshold
to produce a binary output, the closest permitted level is determined
and the error, if any, is diffused to the neighboring pixels
according to the chosen kernel. Therefore, grayscale images
are quantized to a number of levels equalling the number of
subpixels per share, . During the dithering process at the
pixel level, any continuous tone pixel is expanded to a matrix
of black and white subpixels defined by the gray level of the
original pixel. The proportion of white subpixels in this matrix
is referred to as pixel transparency. In our application, the host
images used for encrypting a private face image and the private
image itself are converted to halftoned images.
2) Encryption: The encryption process is applied on a
pixel-by-pixel basis using the three halftoned images (the two
hosts and the original image). The arrangement of the subpixels
in the shares of both the hosts has to be controlled such that the
required transparency (the number of white subpixels) of the
target pixel is obtained. The arrangement is determined based
on the pixel transparencies triplet . , , and are
transparencies of the entire subpixel region for share 1, share
2, and the target, respectively.
The security of the scheme is also important. Therefore,
during encryption, a Boolean matrix is randomly selected
from a set of Boolean matrices for every pixel
in the original image. This is the primary difference between
this scheme and Naor-Shamir’s scheme: in the latter, only a
74 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 6, NO. 1, MARCH 2011
Fig. 7. Example of an impossible arrangement.
single collection of matrices is required which depends on
the number of hosts and the pixel expansion . Nakajima
and Yamaguchi describe in detail the method to compute this
collection of Boolean matrices [18].
However, as shown in Fig. 7, there are cases when the required
transparency for the corresponding pixel in the target
image cannot be obtained, no matter how the shared subpixels
are rearranged. Therefore, to determine if it is possible to obtain
the target transparency by rearranging the transparent (white)
subpixels in the shares, the target transparency must be within
the following range [condition (T1)] [18]:
(2)
where , , and are the transparencies of the entire
pixel region for share 1, share 2, and the target, respectively. The
range of each of these transparencies for the entire image corresponds
to the dynamic range of the pixel intensities of the respective
images. Assuming that the dynamic ranges of the transparencies
of the two sheets are the same, , all the
triplets, , would satisfy condition (T1) if and only if
the dynamic range of the target fulfils condition (T2) [18]
(3)
Nakajima and Yamaguchi [18] described a method to enhance
the image quality (contrast) and decrease the number of violated
triplets by performing an adaptive dynamic range compression.
In their method, the dynamic range of the sheets and
the target are modified as , , and
, respectively, where denotes the lower
bound of the sheets’ dynamic range and is a fixed value. It is
clear that 0 is the most appropriate value for the lower bound of
the target to ensure that the target is darker than both sheets [18].
However, after enhancing the contrast, it is necessary to consider
condition (T1) again before encryption. Thus, if a triplet violates
condition (T1), the gray levels of the conflicting triplets are
adjusted and the resulting errors diffused to the nearby pixels.
Consequently, both halftoning and encryption are done simultaneously
to facilitate this adjustment.
To perform this adjustment, a 3-D space is defined using the
transparencies of the pixels in the three images: the -axis represents
the transparencies of the pixels in share 1, the -axis represents
the transparencies of the pixels in share 2, and the -axis
represents the transparencies of the pixels in the target image.
Any point in this space is characterized by a triplet representing
transparencies in the three images. The volume corresponding
to the points for which reconstruction is possible (Fig. 8) is determined.
Every point outside this volume is adjusted. Assume a
point outside the determined volume. To encrypt
this triplet without degrading the images, will be replaced
with where is the closest point to in the constructed
volume. Thus, the transparencies of the corresponding
pixels in share 1, share 2, and target will become , , and
Fig. 8. Examples of subpixel arrangements.
Fig. 9. Flowchart for illustrating GEVCS at the pixel-level.
, respectively. If condition (T1) is violated, the errors are calculated
and diffused using an error-diffusion algorithm to the
nearby pixels. These steps are summarized in Fig. 9.
III. SECURING IRIS AND FINGERPRINT TEMPLATES
The use of basic visual cryptography for securing fingerprint
and iris templates was suggested in [22] and [23], respectively;
however, no experimental results were reported to demonstrate
its efficacy. Moreover, basic VCS leads to the degradation in
the quality of the decoded images, which makes it unsuitable
for matching process, as shown in Fig. 10(a), where the white
background of the original image becomes gray in the decrypted
(target) image. The overlaying or superimposing operation in visual
cryptography is computationally modeled as the binary OR
operation which causes the contrast level of the target image to
be lowered. Loss in contrast in target images could be addressed
by simply substituting the OR operator with the XOR operator
[24]. Furthermore, the target image can be down-sampled by
reconstructing just one pixel from every block. Thus, the
reconstructed image will be visually appealing while requiring
less storage space. Fig. 10 shows the difference in quality between
the secret images recovered using the OR and XOR operations.
It is clearly evident that the contrast of the original image
is restored in the latter.
IV. SECURING PRIVATE FACE IMAGES
Let be the public dataset containing
a set of candidate host images that can hide the assigned private
face image . The first task is to select two host images and
, and , from . Note that due to
variations in face geometry and texture between the images in
the public dataset and the private face image, the impact of the
ROSS AND OTHMAN: VISUAL CRYPTOGRAPHY FOR BIOMETRIC PRIVACY 75
Fig. 10. Reconstructed fingerprint image when using the (a) OR and (b) XOR
operators.
Fig. 11. Block diagram of the proposed approach for storing and matching face
images.
Fig. 12. Example of an annotated face.
target image on the sheet images and vice versa may become
perceptible. This issue can be mitigated if the host images for
a particular private image are carefully chosen. Fig. 11 shows
the block diagram that illustrates the key steps of the proposed
approach. These steps will be explained in more detail in the
following subsections.
A. Active Appearance Model
The proposed approach essentially selects host images that
are most likely to be compatible with the private image based
on geometry and appearance. Therefore, an active appearance
model (AAM) [25] that characterizes the shape and texture of
the face is utilized to determine the similarity between the private
face image and candidate host images (Fig. 11). The steps
for building the AAM and using it for locating predefined landmarks
on face features, as shown in Fig. 12, is discussed in detail
in [26] and [25] and is summarized below.
1) Building the AAM: Four steps are needed for building a
basic AAM from a set of training images.
a) Annotate the Training Set: First, for each face image
in the training dataset, its face features are annotated manually
by landmarks of a predefined shape. Each shape is stored
in a vector format, where and is the number of
training images. This representation does not include any information
about the connection between landmarks. Thus,
(4)
where is the number of landmarks used to locate and annotate
face features.
b) Building the Shape Model: A shape alignment process
is performed to remove the effects of affine transformations
(translation, scaling, and rotation). Then the principle component
analysis (PCA) is used to construct a simple linear model
of shape variability across the training images
(5)
Here, is the mean shape vector, is a matrix describing
the modes of variation derived from the training set, and is
the shape model parameters vector.
c) Building the Texture Model: All images in the training
set are warped to the mean shape by utilizing the annotated landmarks.
Next, the pixel values in each warped image is consolidated
to create a texture vector. Then, a photometric normalization
is used to minimize the effects of lighting changes on the
texture vector. The normalized texture vector is
(6)
where is the number of pixels within the image. Then, PCA
is used to linearly model the texture vectors as in (7)
(7)
Here, is the mean texture vector, is the modes of variation
matrix, and is the texture model parameter vector.
d) Building the Combined AAM: Shape and texture are
often correlated [26] and, so, PCA is once again used to construct
a compact model from and resulting in a set of combined
parameters . This helps in synthesizing an image with a
given shape and texture using one set of parameters as
shown below
(8)
(9)
2) Annotating an Image: A randomly selected template
model is initially generated and an image based on the corresponding
model parameters is synthesized. The error between
the input image ( , that has to be annotated) and the
synthesized image needs to be minimized. The
solution is found by varying two sets of parameters: the combined
model parameters and the pose parameters (translation,
scaling, and rotation).
76 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 6, NO. 1, MARCH 2011
Fig. 13. Shape-free image of annotated face image in Fig. 12.
B. Selection of Hosts
For selecting compatible hosts, the cost of registering
(aligning) each image in the public dataset with the private
image is computed as . These costs are sorted in order to
locate two host images, and , which have the smallest
registration cost. However, as will be shown in the experiments
section, this cost alone is not sufficient. So the texture is used
as an additional criteria and the cost associated with this is
denoted as . Therefore, the final cost , which is associated
with each host image, is the sum of the normalized transformation
cost and the normalized appearance cost . The
simple minimum–maximum normalization technique is used to
normalize both costs.
1) Transformation Cost : This cost measures the amount
of geometric transformation necessary to align two images
based on the annotated landmarks generated by the AAM.
Given the set of correspondences between these finite sets of
points on two face images, a transformation
can be estimated to map any point from one set to the other.
While there are several choices for modeling this geometric
transformation, the thin plate spline (TPS) model is used [27].
The transformation cost is the measure of how much transformation
is needed to align the two face images by utilizing the
thin plate spline model, which is the bending energy necessary
to perform the transformation.
2) Appearance Cost : First, the private face image
and the host image are normalized by warping them to the
mean shape, , resulting in shape-free texture images and
. Fig. 13 shows an example of a shape-free image for a private
face image. This normalization step uses the mean shape computed
during the AAM training phase. Each shape-free image is
represented as a texture vector (6).
Both and can be expressed by the texture model parameter
vector, . In order to get these basis vectors, each image
is projected onto the texture space by using the stored modes of
variation
(10)
The appearance cost is defined as the Manhattan distance
between the basis vectors corresponding to and .
C. Image Registration and Cropping
In this step, the global affine transformation component of the
thin plate spline model is used to align the two selected host images
with the secret image . Next, the aligned
hosts and the secret image are cropped to capture only the facial
features which have been located by AAM as illustrated in
Fig. 12.
D. Secret Encryption and Reconstruction
GEVCS is used to hide the secret image in the two host
images and resulting in two sheets denoted as and
, respectively. and are superimposed in order to reveal
the secret private image. The final target image is obtained by
the reconstruction process that reverses the pixel expansion step
to retain the original image size.
V. EXPERIMENTS AND RESULTS
A. Securing Iris and Fingerprint Images
In the case of iris, the performance of the proposed technique
was tested on a subset of the MBGC database containing
NIR-iris videos. The left iris videos of 110 subjects were used in
the experiments. Five frames were manually selected from each
of these videos. Every frame was manually segmented and normalized
to separate the iris region from the eye image. An open
source Matlab implementation [28] based on Daugman’s approach
[29] was used to encode and match the normalized irides.
There were five iris codes per subject: one of these was used as
a probe and the rest were added to the gallery. The probe iris
codes were encrypted and reconstructed using the (2, 2) VCS.
The experiment consisted of matching the probes against the
gallery entries. The equal error rate (EER) was used to observe
the matching performance of the original as well as the reconstructed
probes. In both cases, the EER was the same ( 6.3%).
Next, the possibility of exposing the identity by using the sheet
images as probes and the original iris codes as gallery was investigated.
However, this resulted in an EER of 50% suggesting
the difficulty in using individual sheets to reveal the original iris
code.
In the case of fingerprints, the performance of the proposed
technique was tested on the NIST-4 fingerprint database2 containing
inked fingerprints exhibiting large variations in quality.
The database consists of the grayscale images of 2000 fingers
with two impressions per finger. One of these impressions was
used as a probe image and the other was added to the gallery.
Since the proposed technique was devised for binary fingerprint
images, a threshold value was used to generate the binary
image for each probe. Each binary image was then decomposed
into two sheets using (2, 2) VCS. The sheets were superimposed
to get the target image, as shown in Fig. 1. The reconstructed
as well as the original grayscale fingerprint probes were
matched against the impressions in the gallery. Using the original
fingerprint images as probes resulted in an EER of 8%.3
Table I shows the result of using the reconstructed fingerprints as
probes; the performance is reported as a function of the different
threshold values used to binarize the original probe images. It is
observed that a threshold of 180 results in an EER of 9.13%.
These experiments suggest the possibility of decomposing and
storing fingerprint images.
B. Securing Private Face Images
In the case of faces, the performance of the proposed technique
was tested on two different databases: the IMM and
2http://www.nist.gov/data/WebGuide/SD_4/FingerprintDB_4.htm
3No attempt was made to optimize the performance of the fingerprint matcher
(VeriFinger SDK) on this dataset.
ROSS AND OTHMAN: VISUAL CRYPTOGRAPHY FOR BIOMETRIC PRIVACY 77
TABLE I
EQUAL ERROR RATES (%) AT DIFFERENT THRESHOLD
VALUES
Fig. 14. Images in the public datasets for both the (a) IMM and (b) XM2VTS
databases.
XM2VTS databases. These databases were used since the
facial landmarks of individual images were annotated and
available online. These annotations were necessary for the
AAM scheme. The IMM Face Database [30] is an annotated
database containing 6 face images each of 40 different subjects;
3 of the frontal face images per subject were used in the experiments.
Twenty-seven subjects were used to construct the private
dataset and the remaining 13 were used as the public dataset.
The XM2VTS frontal image database [31] consists of 8 frontal
face images each of 295 subjects. One hundred ninety-two
of these subjects were used to construct the private dataset
and 91 subjects were used to construct the pubic dataset. The
remaining subjects were excluded because several of their face
images could not be processed by the commercial matcher. The
composition of the public dataset is shown in Fig. 14. The AAM
for each database was constructed using the face images (one
per subject) from the public dataset. Fig. 15 shows examples of
Fig. 15. Illustration of the proposed approach using images from the IMM database.
TABLE II
EQUAL ERROR RATES (%) WHEN USING DIFFERENT PUBLIC DATASETS
WITH 
 AND 

TABLE III
EQUAL ERROR RATES (%) WHEN USING DIFFERENT PUBLIC DATASETS
WITH 
 AND 

the proposed approach when dataset D in Fig. 14(a) is used as
the public dataset (here ).
In the following experiments, the match scores were generated
using the Verilook SDK.4 In order to establish a baseline,
the images in the private database were first matched against
each other. This resulted in an EER of 6% for the IMM database
and 2% for the XM2VTS database.
1) Experiment 1: In this experiment, the impact of varying
the number of images in the public dataset was investigated
(datasets A, B, C, D, and E were used). The selection of hosts
from the public dataset was based only on the transformation
cost. The experiment consisted of matching the reconstructed
private images against each other. EERs using the five public
datasets are shown in Tables II and III. For the IMM database in
Table II, it is clear that adding more images to the public dataset
4Available: http://www.neurotechnology.com
78 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 6, NO. 1, MARCH 2011
TABLE IV
EQUAL ERROR RATES (%) WHEN DIFFERENT SELECTION CRITERIA ARE
USED WITH

 AND 

TABLE V
EQUAL ERROR RATES (%) WHEN DIFFERENT SELECTION CRITERIA ARE
USED WITH

 AND 

TABLE VI
EQUAL ERROR RATES (%) FOR DIFFERENT VALUES OF
AND 
.
THE CHOICE OF
IS BASED ON [18]
Fig. 16. Examples of reconstructed images for a subject with different values
for the pixel expansion factor, . (a) 
	; (b) 
; (c) 
;
(d) 
.
TABLE VII
EQUAL ERROR RATES (%) FOR DIFFERENT VALUES OF
AND 
.
THE CHOICE OF
IS BASED ON [18]
initially improves the result. However, Dataset E results in the
worst EER with respect to the other datasets. This drop in performance
could be attributed to the inclusion of an individual
with a beard in the public dataset: the absence of the appearance
cost led to the selection of this host image even for those private
face images that did not possess a beard, thereby affecting the
reconstructed images.
2) Experiment 2: In this experiment, the appearance cost was
added to the criterion to select the host images and it is clear that
this solves the problem encountered in Experiment 1. Dataset E
is used in this experiment to select the hosts . Tables IV
and V show the EERs of the reconstructed images when host
images are selected using (a) the transformation cost only
and (b) the sum of the normalized transformation cost and
appearance cost .
From both the above experiments it is also apparent that
and results in better matching performance.
3) Experiment 3: The purpose of this experiment was to determine
if the encrypted face images upon reconstruction could
be successfully matched against the original private face images.
To evaluate this, the public Dataset A in Fig. 14, consisting of
two fixed face images as hosts, was used. For each subject in
the private dataset, one frontal face image was selected5 as the
secret image to be encrypted by the two host face images. The
VCS was invoked with contrast and a pixel expansion
factor of . The reconstructed images were observed
to match very well with the original images resulting in an EER
of 0% in the case of the IMM database and 0.5% in the case
of the XM2VTS database. On other hand, when either of the
sheets were matched against the original images, the resultant
EERs were greater than 45%.
4) Experiment 4: The purpose of this experiment was to determine
if the reconstructed face images could be successfully
matched against those images in the private dataset that were
not used in Experiment 3. To establish this, for each subject in
the reconstructed dataset, frontal face images were chosen
from the private database to assemble the gallery ( for
IMM and for XM2VTS). The matching exercise consisted
of comparing the reconstructed face images (from Experiment
1) against these gallery images (not used in Experiment
1). An EER of 2% was obtained for the IMM database.
This performance, in this case, was even better than that of the
original images EER . The improvement could be due
to the contrast enhancement of the private face images that occurs
when increasing the dynamic range of the sheets resulting
in improved quality of the reconstructed secret image. For the
XM2VTS database, the obtained EER was 6% which is still
comparable with the 2% obtained when matching the original
images.
5) Experiment 5: By using public Dataset D and
and , sheet images were created with different contrast values:
. Tables VI and VII report the
EERs for these different values of . Here, the matching procedure
was the same as that of Experiment 4. For both databases,
results in better performance than the other values.
This improvement could be due to the contrast enhancement of
the target images that occurs by increasing the dynamic range
of the sheets and, consequently, the quality of the target image.
6) Experiment 6: Next, the effect of pixel expansion on the
final reconstructed image was tested. Fig. 16 shows that details
of the sheets can appear on the final image for higher values
of . The impact of on matching performance is shown in
Table VIII. Here, the matching procedure was the same as that
of Experiment 4. The host images were selected from Dataset D
with . As shown in Fig. 16, the pixel expansion value
affects the number of gray-levels in the reconstructed image,
and this impacts the amount of detail appearing in it. Therefore,
when is 100, the visual details of the sheet images appear
on the reconstructed image resulting in a drop in overall performance.
7) Experiment 7: In this experiment, the possibility of exposing
the identity of the secret image by using the sheet images
in the matching process is investigated. For this experiment,
the sheet images for three different face samples of the
5In the case of IMM database, the face sample exhibiting neutral expression
and diffuse light was selected
ROSS AND OTHMAN: VISUAL CRYPTOGRAPHY FOR BIOMETRIC PRIVACY 79
TABLE VIII
EQUAL ERROR RATES FOR DIFFERENT VALUES OF
Fig. 17. Examples from experiment 7 where (a), (d), and (g) are the first sheets
and (b), (e), and (h) are the second sheets. (c), (f), and (i) are the corresponding
reconstructed face images.
same subject were first computed. Next, the reconstructed images
and the corresponding sheets were independently used in
the matching process (i.e., sheet image 1 of all the private images
were matched against each other; sheet image 2 of all the private
images were matched against each other; reconstructed images
of all the private images were matched against each other).
Fig. 17 shows that each subject in the private dataset has three reconstructed
images. The public datasets used in this experiments
were datasets A, F, and G. This experiment resulted in three
EERs: the first was a result of using the reconstructed target images
for matching, while the second and the third EERs were a
result of using the first sheet and second sheet, respectively, for
matching. The results in Table IX confirm the difficulty of exposing
the identity of the secret face image by using the sheets
alone.
Note that Experiment 7 involves automatic host selection
from the public dataset based on the registration cost described
earlier. The positive impact of automatic host selection
is seen in Fig. 17 where the selected host images (sheets) and
the secret image are observed to have compatible expressions.
8) Experiment 8: Different applications may employ different
public datasets for host image selection. Thus, the
hosts selected for encrypting an individual’s face image can
differ across applications. This experiment seeks to confirm
that cross-matching of the stored sheets across applications
(and inferring identities) will not be feasible. To demonstrate
this, the possibility of using host images from different public
databases for encrypting the same identity (i.e., face image) was
investigated. The experiment was set up as follows. Two face
samples of each of the 192 subjects in the XM2VTS private
dataset were randomly selected. For an arbitrary subject, let
and denote the two face samples that were selected. Further,
let be encrypted into sheets and using a public
TABLE IX
EQUAL ERROR RATES (%) FOR EXPERIMENT 7. EXPERIMENTS CONFIRM
THE DIFFICULTY OF USING INDIVIDUAL SHEET IMAGES TO
REVEAL THE SECRET IMAGE
dataset from the IMM database. Similarly, let be encrypted
into sheets and using a public dataset
from the XM2VTS database. Let and denote the reconstructed
face images pertaining to and , respectively.
The following matching exercises were conducted: (a)
against ; (b) against ; (c)
against ; (d) against ; (e) against
. The public datasets used in this experiment was the same
as Experiment 7 (i.e., Datasets A, F, and G). Table X shows
the EERs for these matching experiments and it is clear that it
is difficult to perform cross-matching across different applications.
However, when the corresponding reconstructed images
( and ) are compared, the resulting EER
suggests the possibility of successful matching.
VI. CONCLUSION AND DISCUSSION
This paper explored the possibility of using visual cryptography
for imparting privacy to biometric templates. In the
case of fingerprints and iris, the templates are decomposed
into two noise-like images using (2, 2) VCS, and since the
spatial arrangement of the pixels in these images varies from
block to block, it is impossible to recover the original template
without accessing both the shares. The XOR operator is used
to superimpose the two noisy images and fully recover the
original template. In addition, the contribution of this paper
includes a methodology to protect the privacy of a face database
by decomposing an input private face image into two
independent sheet images such that the private face image can
80 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 6, NO. 1, MARCH 2011
TABLE X
EQUAL ERROR RATES (%) FOR EXPERIMENT 8
be reconstructed only when both sheets are simultaneously
available. The proposed algorithm selects the host images that
are most likely to be compatible with the secret image based
on geometry and appearance. GEVCS is then used to encrypt
the private image in the selected host images. It is observed
that the reconstructed images are similar to the original private
image. The study on the effect of various parameters ( and
) on the matching performance suggests that there is indeed
a relation between the quality of the reconstructed secret and
these parameters. Finally, experimental results demonstrate the
difficulty of exposing the identity of the secret image by using
only one of the sheets; further individual sheets cannot be used
to perform cross-matching between different applications.
Increasing the pixel expansion factor can lead to an increase
in the storage requirements for the sheets. In the recent
literature there have been some efforts to develop a VCS without
pixel expansion [32], [33]. But no such scheme currently exists
for generating sheets that are not random noisy images. Thus,
more work is necessary to handle this problem.
ACKNOWLEDGMENT
The authors are grateful to R. Jillela for his assistance with
the iris experiments.
REFERENCES
[1] A. Jain, P. Flynn, and A. Ross, Handbook of Biometrics. New York:
Springer, 2007.
[2] G. I. Davida, Y. Frankel, and B. J. Matt, “On enabling secure applications
through off-line biometric identification,” in Proc. IEEE Symp.
Security and Privacy, 1998, pp. 148–157.
[3] N. Ratha, J. Connell, and R. Bolle, “Enhancing security and privacy in
biometrics-based authentication systems,” IBM Syst. J., vol. 40, no. 3,
pp. 614–634, 2001.
[4] Y. Feng, P. Yuen, and A. Jain, “A hybrid approach for face template
protection,” in Proc. SPIE Conf. Biometric Technology for Human
Identification, Orlando, FL, 2008, vol. 6944.
[5] A. Jain and U. Uludag, “Hiding biometric data,” IEEE Trans. Pattern
Anal. Mach. Intell., vol. 25, no. 11, pp. 1494–1498, Nov. 2003.
[6] J. Dong and T. Tan, “Effects of watermarking on iris recognition performance,”
in Proc. 10th Int. Conf. Control, Automation, Robotics and
Vision, 2008 (ICARCV 2008), 2008, pp. 1156–1161.
[7] N. Agrawal and M. Savvides, “Biometric data hiding: A 3 factor
authentication approach to verify identity with a single image using
steganography, encryption and matching,” in Proc. Computer Vision
and Pattern Recognition Workshop, 2009, vol. 0, pp. 85–92.
[8] E. M. Newton, L. Sweeney, and B. Malin, “Preserving privacy by
de-identifying face images,” IEEE Trans. Knowl. Data Eng., vol. 17,
no. 2, pp. 232–243, Feb. 2005.
[9] R. Gross, L. Sweeney, F. De la Torre, and S. Baker, “Model-based face
de-identification,” in IEEE Workshop on Privacy Research in Vision,
Los Alamitos, CA, 2006.
[10] D. Bitouk, N. Kumar, S. Dhillon, P. Belhumeur, and S. K. Nayar, “Face
swapping: Automatically replacing faces in photographs,” ACM Trans.
Graph., vol. 27, no. 3, pp. 1–8, 2008.
[11] B. Moskovich and M. Osadchy, “Illumination invariant representation
for privacy preserving face identification,” in Proc. IEEE Computer
Society and IEEE Biometrics Council Workshop on Biometrics, San
Francisco, CA, Jun. 2010, pp. 154–161.
[12] A. Jain, K. Nandakumar, and A. Nagar, “Biometric template security,”
EURASIP J. Advances Signal Process., pp. 1–17, 2008.
[13] D. Maltoni, D. Maio, A. Jain, and S. Prabhakar, Handbook of Fingerprint
Recognition. Secaucus, NJ: Springer-Verlag New York, Inc.,
2003.
[14] S. Prabhakar, S. Pankanti, and A. Jain, “Biometric recognition: Security
and privacy concerns,” IEEE Security Privacy, vol. 1, no. 2, pp. 33–42,
Mar./Apr. 2003.
[15] B. Thuraisingham and W. Ford, “Security constraint processing in
a multilevel secure distributed database management system,” IEEE
Trans. Knowl. Data Eng., vol. 7, no. 2, pp. 274–293, Apr. 1995.
[16] C. Soutar, D. Roberge, A. Stoianov, R. Gilroy, and B. Kumar, “Biometric
encryption,” in ICSA Guide to Cryptography. New York: McGraw-Hill,
1999.
[17] M. Naor and A. Shamir, “Visual cryptography,” in Proc. EUROCRYPT,
1994, pp. 1–12.
[18] M. Nakajima and Y. Yamaguchi, “Extended visual cryptography for
natural images,” J. WSCG, vol. 10, no. 2, pp. 303–310, 2002.
[19] G. Ateniese, C. Blundo, A. Santis, and D. Stinson, “Extended capabilities
for visual cryptography,” Theor. Comput. Sci., vol. 250, no. 1–2,
pp. 143–161, 2001.
[20] S. Shevell, The Science of Color. Amsterdam, The Netherlands: Elsevier
Science Ltd., 2003.
[21] R. Floyd and L. Steinberg, “An adaptive algorithm for spatial
greyscale,” SPIE Milestone Series, vol. 154, pp. 281–283, 1999.
[22] Y. Rao, Y. Sukonkina, C. Bhagwati, and U. Singh, “Fingerprint
based authentication application using visual cryptography methods
(improved id card),” in Proc. IEEE Region 10 Conf., Nov. 2008, pp.
1–5.
[23] P. Revenkar, A. Anjum, and W. Gandhare, “Secure iris authentication
using visual cryptography,” Int. J. Comput. Sci. (IJCSIS), vol. 7, no. 3,
pp. 217–221, Mar. 2010.
[24] D. Jin, W.-Q. Yan, and M. S. Kankanhalli, “Progressive color visual
cryptography,” J. Electron. Imag. vol. 14, no. 3, p. 033019, 2005 [Online].
Available: http://link.aip.org/link/?JEI/14/033019/1
[25] T. Cootes et al., “Active appearance models,” IEEE Trans. Pattern
Anal. Mach. Intell., vol. 23, no. 6, pp. 681–685, Jun. 2001.
[26] M. B. Stegmann, “Active Appearance Models: Theory, Extensions
and Cases,” Master’s thesis, Informatics and Mathematical Modelling,
Technical University of Denmark, DTU, Kgs. Lyngby, Aug. 2, 2000
[Online]. Available: http://www.imm.dtu.dk/aam/main/
[27] F. Bookstein, “Principal warps: Thin-plate splines and the decomposition
of deformations,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 11,
no. 6, pp. 567–585, Jun. 1989.
[28] L. Masek and P. Kovesi, Matlab Source Code for a Biometric Identifi-
cation System Based on Iris Patterns. Perth, Australia: Dept. of Computer
Science and Software Engineering, The University of Western
Australia, 2003.
[29] J. Daugman, “Demodulation by complex-valued wavelets for stochastic
pattern recognition,” Int. J. Wavelets, Multiresolution Inf.
Process., vol. 1, no. 1, pp. 1–17, 2003.
[30] M. B. Stegmann, B. K. Ersbøll, and R. Larsen, “FAME—A flexible
appearance modelling environment,” IEEE Trans. Med. Imag., vol. 22,
no. 10, pp. 1319–1331, Oct. 2003.
[31] K. Messer, J. Matas, J. Kittler, J. Luettin, and G. Maitre, “XM2VTSDB:
The extended M2VTS database,” in Proc. 2nd Int. Conf. Audio and
Video-Based Biometric Person Authentication, 1999, pp. 965–966.
[32] Y. Chen, Y. Chan, C. Huang, M. Tsai, and Y. Chu, “A multiple-level
visual secret-sharing scheme without image size expansion,” Inf. Sci.,
vol. 177, no. 21, pp. 4696–4710, 2007.
ROSS AND OTHMAN: VISUAL CRYPTOGRAPHY FOR BIOMETRIC PRIVACY 81
[33] T. Lin, S. Horng, K. Lee, P. Chiu, T. Kao, Y. Chen, R. Run, J. Lai, and
R. Chen, “A novel visual secret sharing scheme for multiple secrets
without pixel expansion,” Expert Systems With Applications, vol. 37,
no. 12, pp. 7858–7869, 2010.
[34] A. Ross and A. A. Othman, “Visual cryptography for face privacy,”
in Proc. SPIE Biometric Technology for Human Identification VII, Orlando,
FL, 2010, vol. 7667.
Arun Abraham Ross (S’00–M’03) received the
B.E. (Hons.) degree in computer science from the
Birla Institute of Technology and Science, Pilani,
India, in 1996, and the M.S. and Ph.D. degrees in
computer science and engineering from Michigan
State University, East Lansing, in 1999 and 2003,
respectively.
Between 1996 and 1997, he was with the Design
and Development Group of Tata Elxsi (India) Ltd.,
Bangalore, India. He also spent three summers
(2000–2002) with the Imaging and Visualization
Group of Siemens Corporate Research, Inc., Princeton, NJ, working on
fingerprint recognition algorithms. He is currently a Robert C. Byrd Associate
Professor in the Lane Department of Computer Science and Electrical Engineering,
West Virginia University, Morgantown. His research interests include
pattern recognition, classifier fusion, machine learning, computer vision, and
biometrics. He is actively involved in the development of biometrics and
pattern recognition curricula at West Virginia University. He is the coauthor of
Handbook of Multibiometrics and coeditor of Handbook of Biometrics.
Dr. Ross is a recipient of NSF’s CAREER Award and was designated a Kavli
Frontier Fellow by the National Academy of Sciences in 2006. He is an Associate
Editor of the IEEE TRANSACTIONS ON IMAGE PROCESSING and the IEEE
TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY.
Asem Othman (S’09) received the B.Sc. (Hons.)
and M.Sc. degrees in systems and biomedical
engineering from Cairo University, Cairo, Egypt, in
2004 and 2008, respectively. He is currently working
toward the Ph.D. degree in the Lane Department of
Computer Science and Electrical Engineering, West
Virginia University, Morgantown.
His current research interests are image processing,
computer vision, and biometrics.

Leakage-Resilient Cryptography From the Inner-Product Extractor
Stefan Dziembowski1? Sebastian Faust2??
1 University of Warsaw and Sapienza University of Rome
2 Aarhus University
Abstract. We present a generic method to secure various widely-used cryptosystems against arbitrary side-channel
leakage, as long as the leakage adheres three restrictions: first, it is bounded per observation but in total can be arbitrary
large. Second, memory parts leak independently, and, third, the randomness that is used for certain operations
comes from a simple (non-uniform) distribution.
As a fundamental building block, we construct a scheme to store a cryptographic secret such that it remains information
theoretically hidden, even given arbitrary continuous leakage from the storage. To this end, we use a randomized
encoding and develop a method to securely refresh these encodings even in the presence of leakage. We then show
that our encoding scheme exhibits an efficient additive homomorphism which can be used to protect important cryptographic
tasks such as identification, signing and encryption. More precisely, we propose efficient implementations
of the Okamoto identification scheme, and of an ElGamal-based cryptosystem with security against continuous
leakage, as long as the leakage adheres the above mentioned restrictions. We prove security of the Okamoto scheme
under the DL assumption and CCA2 security of our encryption scheme under the DDH assumption.
? The European Research Council has provided financial support to the first author of this paper under the European Community’s
Seventh Framework Programme (FP7/2007-2013) / ERC grant agreement no CNTM-207908.
?? Sebastian Faust acknowledges support from the Danish National Research Foundation and The National Science Foundation of
China (under the grant 61061130540) for the Sino-Danish Center for the Theory of Interactive Computation, within part of this
work was performed. Part of this work was done while being at KU Leuven.
1 Introduction
Recently, a large body of work attempts to analyze the effectiveness of side-channel countermeasures in a
mathematically rigorous way. These works propose a physical model incorporating a (mostly broad) class
of side-channel attacks and design new cryptographic schemes that provably withstand them under certain
assumptions about the physical hardware (see, e.g., [30,16,17,21,10,6,29] and many more). By now we have
seen new constructions for many important cryptographic primitives such as digital signature and public key
encryption schemes that are provably secure against surprisingly broad classes of leakage attacks.
Unfortunately, most of these new constructions are rather complicated non-standard schemes, often relying
on a heavy cryptographic machinery, which makes them less appealing for implementations on computationally
limited devices. In this work, we take a different approach: instead of developing new cryptographic
schemes, we ask the natural question whether standard, widely-used cryptosystems can be implemented effi-
ciently such that they remain secure in the presence of continuous bounded leakage. We answer this question
affirmatively, and show a generic way that “compiles” various common cryptosystems into schemes that
remain secure against a broad class of leakage attacks.
Similar to earlier work, we make certain restrictions on the leakage. We follow the work of Dziembowski
and Pietrzak [16], and allow the leakage to be arbitrary as long as the following two restrictions are satisfied:
1. Bounded leakage: the amount of leakage in each round is bounded to λ bits (but overall can be arbitrary
large).
2. Independent leakage: the computation can be structured into rounds, where each such round leaks
independently (we define the notion of a “round” below).
In addition to these two restrictions, we require that our device has access to a source of correlated randomness
generated in a leak-free way – e.g., computed by a simple leak free component. We elaborate in the
following on our leakage restrictions.
1.1 Our Leakage Model
ON THE BOUNDED LEAKAGE ASSUMPTION. Most recent work on leakage resilient cryptography requires
that the leakage is bounded per observation to some fraction of the secret key. This models the observation
that in practice many side-channel attacks only exploit a polylogarithmic amount of information, and typically
require thousands of observations until the single key can be recovered. This is, for instance, the case
for DPA-based attacks where the power consumption is modeled by a weighted sum of the computation’s
intermediate values. We would like to mention that all our results also remain true in the entropy loss model,
i.e., we do not necessarily require that the leakage is bounded to λ bits, but rather only need that the min
entropy of the state remains sufficiently high even after given the leakage.
ON INDEPENDENT LEAKAGES. The assumption that different parts of the memory leak independently –
originally put forward by Micali and Reyzin [30] as the physical axiom “only computation leaks information”
– constitutes a spatial restriction of the leakage and has been used in several works [30,16,33,26,17]
(and more). In this paper, we assume that the memory of the device is divided into three parts L, R and C
where (L, C) and (R, C) leak independently. To use the independent leakage assumption, we structure the
computation into rounds, where each round only accesses either (L, C) or (R, C). One may object now that
leakage is a global phenomenon. Indeed, this is true and many important leakage functions, for instance,
the power consumption of a device modeled by the Hamming weight, are rather a global function of the
computation’s intermediate values. We would like to emphasize, however, that many relevant global leakage
functions can be computed from just local leakages. This is not only true for the prominent Hamming weight
leakage, but more generally, for any affine leakage function. Hence, independent leakages still allow for a
broad class of practically relevant global leakage functions.
1
Recently, it has been pointed out that the independent leakage assumption does not capture so-called
“coupling effects” that may occur between gates and add a non-linear term to the leakage function [38]. As
such coupling effects typically occur between gates, it may contradict locality assumptions that are made at
a very low architectural level – e.g., if we assume that each gate of the computation leaks independently. In
our case, coupling effects may be much less dangerous, as we make the assumption of independent leakages
at a much higher architectural level, i.e., we just assume that two parts of the memory leak independently.
ON LEAK-FREE COMPONENTS. We use a biased source of randomness that outputs correlated randomness
sampled in a leak-free way. Such a source can, for instance, be implemented by a probabilistic leak-free
component that outputs the correlated randomness. As in earlier works that made use of leak-free components
[20,18,25,21], we require that our component leaks from its outputs, but the leakage function cannot
view the internals of the ongoing computation. More concretely, in the simplest case our component O outputs
two random vectors A, B ← F
n
(with F being a finite field and n being a statistical security parameter)
such that their inner product is 0, i.e., P
i Ai
· Bi = 0. We require that A gets stored on one part of the
memory, while B gets stored on the other, thus, we require that A and B leak independently.
Our component O is simple and small: it can be implemented in size linear in n, as one simply needs
to sample uniformly at random vectors
P
A and (B1, . . . , Bn−1) and computes the last element Bn such that
i Ai
· Bi = 0.
3 Second, we use O in a very limited way, namely, we need it only when we refresh the
secret key (cf. Section 1.3 for further discussion on this). Finally, O does not take any inputs, and hence its
computation is completely oblivious of the actual computation (e.g., encryption or signing) that is carried
out by the device. Moreover, this property gives rise to an alternative implementation as pointed out by Faust
et al. [18]: instead of assuming leak-free computation, we can have O simply read its output one by one from
a pre-computed list. Thus, it suffices to have leak-proof one-time storage instead of leak-proof computation.
This may be an option if the computation is performed only a bounded number of times.
We would also like to emphasize that a leak-free component that does not take any inputs is much harder
to attack by side-channel analysis, as successful attacks usually require some choice (or at least knowledge)
over the inputs that are taken by the device. Also, we would like to stress that such a component can be
tested (regarding its side-channel resistance) independently of the environment in which it is going to be
used eventually.
We will further discuss our model and how it relates to earlier work in the next sections.
1.2 Leakage Resilient Implementation of Standard Cryptographic Schemes
As outlined in the introduction, many recent works in leakage resilient cryptography design new cryptographic
schemes that remain secure against certain (often very broad) classes of leakages. While the design
of new cryptographic schemes with built-in leakage resilience is a very important research direction, we
believe that most current results suffer from one of the following weaknesses:
1. For many security related tasks such as authentication or confidentiality of data, certain cryptographic
schemes have become part of widely used international standards. Even if desirable, it is unlikely that
in near future these standards will be adjusted to include recent scientific progress from leakage resilient
cryptography.
2. Even though by now schemes that remain secure in surprisingly powerful leakage models have been
proposed, they are often very complicated, rely on non-standard complexity assumptions and are often
rather inefficient.
In this work, we take a different approach and propose general techniques that allow to implement efficiently
standard cryptographic schemes that remain provably secure in the above described leakage model. Before
3
For simplicity, we assume that Ln is non-zero.
2
we given an overview of our contributions in the next section, we discuss some related literature that has
dealt with similar questions before.
LEAKAGE RESILIENT CIRCUIT COMPILERS. One fundamental question in leakage resilient cryptography
is whether any computation can be implemented in a way that resists certain side-channel leakages. This
question has been studied in a series of works and dates back to the work of Ishai et al. [24]. They propose
a circuit compiler that transforms any Boolean circuit into one that is secure against an adversary who reads
off the values from a bounded number of wires. This work has recently been extended by Faust et al. [18] to
consider larger classes of computationally bounded leakages – e.g., the leakage is modeled by an AC0 circuit
that takes as input the entire state of the circuit. While these schemes only achieve security against restricted
function classes (either probing attacks or AC0), the works of Juma and Vahlis [25] and Goldwasser and
Rothblum [21] study the question whether any computation can be implemented in a way that withstands arbitrary
polynomial-time computable leakages. As a building block these schemes use a public-key encryption
scheme and essentially encrypt the entire computation of the circuit. More precisely, the approach of Juma
and Vahlis makes use of fully homomorphic encryption, while Goldwasser and Rothblum generate for each
Boolean wire of the circuit a new key pair and encrypt the current value on the wire using the corresponding
key. We would like to emphasize that all circuit compilers (except for the one of Ishai et al.) require leak-free
components. Notice also that the two latter works require the independent leakage assumption: while Juma
and Vahlis use – similar to us – a device whose memory is divided into two parts, Goldwasser and Rothblum
assume that essentially every individual gate (of the original circuit) leaks independently.
LEAKAGE RESILIENT ELGAMAL. While circuit compilers allow to secure any (cryptographic) computation
against leakage, they typically suffer from a large efficiency overhead. A recent work of Kiltz and
Pietrzak [26] takes on this efficiency challenges and shows that certain standard cryptographic schemes can
be implemented efficiently in a leakage resilient way. The authors propose an efficient “bilinear version” of
the ElGamal encryption scheme that is CCA1-secure even if the computation from the decryption process
leaks information. The main weakness of this work is that the security proof is given in the generic group
model. That is, group elements are modeled as uniformly random values and to perform a group operation
or compute a bilinear map one has to query an oracle. Such a proof only implies that there are no "generic"
leakage attacks that would work on any underlying group, i.e., it shows security against any attack that is
independent of the representation of the group elements.
1.3 Our contribution
We continue this line of research and show a generic method to implement various standard cryptographic
schemes that are provably secure in the above described leakage model. More precisely, we propose efficient
and simple implementations of the Okamoto authentication/signature scheme and show that standard security
properties (such as existentially unforgeability) carry over under continuous leakage attacks. Moreover,
we prove that a simple variant of the ElGamal encryption scheme is CCA2 secure in the random oracle
model even if the decryption process leaks continuously. We also discuss why our techniques are fairly general
and may find applications for the secure implementation of various other cryptographic schemes. As a
fundamental tool, we introduce an information theoretically secure scheme to refresh an encoded secret in
the presence of continuous leakage. We detail on our results below.
LEAKAGE RESILIENT REFRESHING OF ENCODED SECRETS. Recently, Davi et al. [9] introduced the notion
of leakage resilient storage (LRS). Such a scheme encodes a secret S such that given partial knowledge
about the encoding an adversary does not obtain any knowledge about the encoded secret S. One of their
instantiations relies on the inner product two-source extractor introduced in the seminal work of Chor and
Goldreich [8]. Essentially, in this scheme the secret S is encoded as a pair (L, R) ∈ F
n × F
n
, where F is
some finite field, and hL, Ri := P
i Li
· Ri = S. Unfortunately, the construction of Davi et al. has one
3
important weakness: it can trivially be broken if an adversary continuously leaks from the two parts L and
R. The first contribution of this paper is to avoid such attacks and propose an efficient refreshing scheme for
the inner product based encoding.
To make such a refreshing secure against continuous leakage attacks, we divide the memory of the device
into three parts L, R and C, where initially (L, R) are chosen uniformly subject to the constraint that
hL, Ri = S, and C is empty. Our refreshing scheme Refresh takes as input (L, R) and outputs a fresh encoding
(L
0
, R0
) of S. The computation of Refresh will be structured into several rounds, where in each round
we only touch either (L, C) or (R, C), but never L and R at the same time. We will allow the adversary to
adaptively leak a bounded amount of information from (L, C) and (R, C). In fact, this is the only assumption
we make, i.e., we do not require that the rounds of the computation leak independently. Since in our protocol
the third part C is only used to “communicate” information between L and R, we will usually describe our
schemes in form of a 2-party protocol: one party, PL, is controlling L, while the second party, PR, holds R.
The third part C is used to store messages that are exchanged between the parties. Hence, instead of saying
that we allow the adversary to retrieve information from (L, C) and (R, C), we can say that the leakage
functions take as inputs all variables that are in the view of PL or PR.
Our protocol for the refreshing uses the following basic idea. Suppose initially PL holds L and PR holds
R with hL, Ri = S, then we proceed as follows:
1. PL chooses a vector X that is orthogonal to L, i.e., hL, Xi = 0, and sends it over to PR.
2. PR computes R0
:= R + X and chooses a vector Y that is orthogonal to R0
and sends it over to PL.
3. PL computes L
0
:= L + Y .
The output of the protocol is (L
0
, R0
). By simple linear algebra it follows that hL, Ri = hL
0
, R0
i = S.
One could also hope that this scheme remains secure in the presence of continuous leakage attacks. Perhaps
counterintuitive, we show (cf. Appendix D.1) that this simple protocol can be completely broken if the
leakage function can be evaluated on (L, X, Y ) and (R, X, Y ). To prevent this attack, we need a method
for PL to send a random X to PR in an “oblivious” way, i.e., without actually learning anything about X,
besides of the fact that X is orthogonal to L (and symmetrically a similar protocol for PR sending Y to
PL). We propose an efficient protocol that achieves this property by making use of our source of correlated
randomness (A, B) ← O. Notice that even given access to such a distribution, the refreshing of an encoded
secret is a non-trivial task, as, e.g., just computing L
0 = L+A and R0 = R+B does not preserve the secret.
The protocol that we eventually construct in Figure 1 solves actually a more general problem: we will
consider schemes for storing vectors S ∈ F
m, and the encoding of a secret S will be a random pair (L, R)
where L is a vector of length n and R is an n×m-matrix (where n  m is some parameter), and S = L·R.
LEAKAGE RESILIENT AUTHENTICATION AND SIGNATURES. We then use our protocol for refreshing an
encoded secret as a building block to efficiently implement standard authentication and signature schemes
in a way that withstands leakage attacks. More concretely, we show that under the DL assumption a simple
implementation of the widely-used Okamoto authentication scheme is secure against impersonation attacks
even if the prover’s computation leaks continuously. Using the standard Fiat-Shamir heuristic, we can turn
our protocol into a leakage resilient signature scheme.
At a high level, our transformation of the standard Okamoto scheme encodes the original secret keys with
our inner product based encoding scheme. Then, we carry out the computation of the prover in “encoded
form”, and finally after each execution of the prover, we refresh the encoded secrets using our leakage
resilient refreshing scheme. To carry out the computation of the prover in an encoded, and hence, in a leakage
resilient way, we make use of the following two observations about the inner product based encoding:
1. it exhibits an additive homomorphism, i.e., if we encode two secrets S1, S2 as (L, Q) and (L, R), then
(L, Q + R) represents an encoding of S1 + S2. Moreover, if Q and R are stored on the same memory
part, then this computation can be carried out in a leakage resilient way.
4
2. for two secrets S1 and S2 and two group generators g1 and g2, it allows to compute g
S1
1
· g
S2
2
in a
leakage-resilient way. To illustrate this, suppose that S1 is encoded by (L, Q) and S2 is encoded by
(L, R). A protocol to compute g
S1
1
· g
S2
2
proceeds then as follows. PR computes the vector A :=
g
Q
1
g
R
2 =

g
Q1
1
g
R1
2
, . . . , g
Qn
1
g
Rn
2

and sends it over to PL. Next, PL computes the vector B := AL =
(A
L1
1
, . . . , ALn
n
) and finally it computes g
S1
1
g
S2
2 =
Q
i Bi
.
Together with our scheme for refreshing the inner product encoding, these both basic components suffice to
implement the standard Okamoto authentication scheme in a leakage resilient way (cf. Section 4).
LEAKAGE RESILIENT CCA2-SECURE ENCRYPTION. As a third contribution, we show that a simple and
efficient variant of the ElGamal cryptosystem can be proven to be CCA2 secure in the RO model even if the
computation from the decryption process leaks continuously. We would like to emphasize that our implementation
is the first construction of a leakage resilient encryption scheme that allows the leakage to depend
on the target ciphertext, i.e., we allow the adversary to obtain leakage after seeing the target ciphertext. We
solve this obstacle by exploiting the independent leakage assumption, i.e., we encode the secret key as (L, R)
and carry out the computation using the above described protocol for secure exponentiation. This together
with our protocol for refreshing the inner product encoding yields a leakage resilient implementation of an
ElGamal-based encryption scheme under the DDH assumption. We would like to note that even though our
scheme uses a simulation sound (SS) NIZK, our construction is rather efficient, as SS-NIZKs can be implemented
efficiently via the Fiat-Shamir heuristic. Moreover, notice that the Fiat-Shamir heuristic is the only
place where the random oracle assumption is used, which in particular means that we do not make any additional
restrictions on the class of leakage functions, as, e.g., leakage functions can query the random oracle
at any point.
A GENERAL PARADIGM FOR LEAKAGE RESILIENT IMPLEMENTATIONS. We observe that our methods for
implementing cryptographic schemes is fairly general. Indeed, the two main properties that we require are
1. the secret key of the cryptosystem is an element in a finite field, and the scheme computes only a linear
function of the secret key in this field, and
2. the secret key is hidden information theoretically even given the transcript that an adversary obtains when
interacting with the cryptosystem.
Various other cryptosystems satisfy these properties. For instance, we can use our techniques to construct a
(rather inefficient) leakage resilient CCA2-secure encryption scheme that is provably secure in the standard
model.
ON THE EFFICIENCY OF OUR SCHEMES. For a statistical security parameter n, we increase the secret key
size and computation complexity by a factor of n compared to the underlying schemes. That is, instead of
using two group elements as secret key, our implementations need to store 3n group elements. Moreover, if
the underlying scheme needs to carry out 2 exponentiations our leakage resilient implementations requires
3n exponentiations. The public key size of both the underlying cryptosystem and our implementation is
identical. As already discussed above, an alternative for implementing standard cryptosystems is via leakage
resilient circuit compilers. These are, however, considerably less efficient due to the following three reasons:
1. Circuit compilers typically consider the question of how to implement Boolean circuits in a leakage
resilient way. Hence, to implement, e.g., the Okamoto authentication, one first needs to “compile” the
scheme into a Boolean circuit and only then implements it using the techniques from the leakage resilient
circuit compilers. Our techniques are more direct and do not require such a detour via Boolean circuits.
2. Non-linear operations (e.g., AND that is heavily needed for exponentiations and multiplications) are
significantly more expensive than the implementation of linear operations. More concretely, for any nonlinear
operation the efficiency loss is quadratic in the security parameter.
5
3. The current circuit compilers that protect against arbitrary polynomial-time computable leakage [25,21]
either carry out the complete computation using a fully homomorphic encryption scheme, or they encrypt
every bit on a wire with a new secret/public key pair. In contrast, we do not use any additional public key
cryptography.
Of course, circuit compilers have an important advantage over our work. While we focus on certain cryptographic
schemes, leakage resilient circuit compilers allow to implement any computation in a leakage
resilient way. Hence, they may be used to implement, e.g., the AES in a leakage resilient way.
We would like to point out that the scheme of Kiltz and Pietrzak [26] is considerably more efficient than
our scheme and results only into a constant loss in efficiency (compared to standard ElGamal). However, this
comes at the price that the security proof is done in the generic group model. Moreover, we would like to
mention that in this work we settle a question raised in [26]. We propose the first encryption scheme that is
CCA2 secure in the presence of leakage attacks.
ON THE LEAK-FREE COMPONENT. In our work, we require access to correlated randomness that is sampled
in a leak-free way. It is interesting to see how our requirement relates to earlier work that made use of
similar assumptions [20,18,25,21]. We focus in the following on the results of Juma and Vahlis [25] and
Goldwasser and Rothblum [21], which both work in a similar leakage model as we do. In the work of
Juma and Vahlis, the leak-free component has to sample a public/secret key pair for a fully homomorphic
encryption scheme together with two ciphertexts C and C
0
that are encryptions of 0. On the other hand, in
the work of Goldwasser and Rothblum the leak free component takes as input a public key and a mode of
operation, and either outputs a fresh encryption of 0 or an encryption of a random bit b. It is easy to see that
the computation that is carried out by our leak-free component O is considerably simpler as it just involves a
small number of simple operations. Moreover, we would like to emphasize that our component is only needed
to refresh the secret key (and not for signing or decryption), while in Goldwasser and Rothblum the leakfree
component is required O(k) times for every NAND gate in the original circuit (here k is the security
parameter). On the positive side, we would like to note, that the entire output of the leak-free component
in [21] can leak jointly, while in our case the two parts A and B have to leak independently. The same is true
for the component of Juma and Vahlis where the secret key cannot leak jointly with the ciphertexts.
COMPARISON TO OTHER RELATED WORK. We would like to mention that in a series of important recent
works [10,6,29,28,5] new schemes for leakage resilient signing and encryption (CPA-secure) have been proposed.
While these works have an obvious advantage over our work by considering a more powerful leakage
model, we would like to point out that these schemes are non-standard and rather inefficient. Furthermore,
they rely on non-standard assumptions (e.g., subgroup decisional assumption), or only allow a small constant
fraction (or even logarithmic fraction) of key leakage during the update process. Moreover, we would
like to emphasize that the goal of our work is different: we are interested in the question whether standard
cryptosystems can be efficiently implemented in a leakage resilient way. For instance, our method for storing
and refreshing a secret key works generically and independently of the proposed scheme. We would like to
note that Dodis et al. [12] recently introduced a method for storing and refreshing a secret. Their construction
does not require leak-free components, but is rather inefficient and relies on computational assumptions.
Moreover, it is not clear if it can be used for other purposes such as implementing standard cryptosystems.
It is an interesting research question whether our results can be combined with the storage and refreshing
scheme of [12].
2 Preliminaries
For a natural number n the set {1, . . . , n} will be denoted [n]. If X is a random variable then we write
x ← X for the value that the random variable takes when sampled according to the distribution of X. In
this paper, we will slightly abuse notation and also denote by X the probability distribution on the range of
6
the variable. A vector V is a row vector, and we denote by V
T its transposition. We let F be a finite field
and for m, n ∈ N, let F
m×n denote the set of m × n-matrices over F. Typically, we use Mi
to denote the
column vectors of the matrix M. For a matrix M ∈ F
m×n
and an m bit vector V ∈ F
m we denote by V · M
the n-element vector that results from matrix multiplication of V and M. For a natural number n by (0n
)
we will denote the vector (0, . . . , 0) of length n. We will often use the set of non-singular m × m matrices
denoted by NonSingm×m(F) ⊂ F
m×m.
Let in the rest of this work n be the statistical and k be the computational security parameter. Let G be a
group of prime order p such that log2
(p) ≥ k. We denote by (p, G) ← G a group sampling algorithm. Let g be
a generator of G, then for a (column/row) vector A ∈ Z
n
p we denote by g
A the vector C = (g
A1
, . . . , gAn ).
Furthermore, let C
B be the vector (g
A1B1
, . . . , gAnBn ). In the following, we will often omit to explicitly
specify the security parameter k, and assume that the information theoretic security parameter n is a function
of k.
2.1 Basic Definitions from Information Theory
We denote with Un the random variable with distribution uniform over {0, 1}
n
. Let X0, X1 be random
variables distributed over X and let Y be a random variable over a set Y, then we define the statistical
distance between X0 and X1 as ∆(X0; X1) = P
x∈X 1/2|Pr[X0 = x] − Pr[X1 = x]|. Moreover, let
∆(X0; X1|Y )
def = ∆((Y, X0); (Y, X1)) be the statistical distance conditioned on Y . For random variables
X over X and Y over Y let d(X) := ∆(X;U) and d(X|Y ) := ∆(X;U|Y ) (where U is uniform and
independent from Y ). It is easy to verify that for any event E we have
d(X|Y ) = 1
2
X
x∈X,y∈Y
|Pr [X = x ∧ Y = y | E] − Pr [Y = y | E] /|X ||. (1)
For random variables X, Y we define the min-entropy of X as H∞(X) = − log maxx∈X Pr[X = x] and
the average min-entropy X given Y as [13]
H˜∞(X|Y ) := − log 
Ey←Y
h
2
−H∞(X|Y =y)
i .
We prove some basic information theoretic lemmata that will be used throughout the paper in Appendix A.
2.2 Leakage Model
As described in the introduction, in this work we will assume that the memory of a physical device is split
into two parts, which leak independently. We model this in form of a leakage game, where the adversary can
adaptively learn information from each part of the memory. More formally, let L, R ∈ {0, 1}
s be the two
parts of the memory, then for a parameter λ ∈ N, we define a λ-leakage game played between an adaptive
adversary A – called a λ-limited adversary – and a leakage oracle Ω(L, R) as follows. For some t ∈ N,
the adversary A can adaptively issue a sequence {(fi
, xi)}
t
i=1 of requests to the oracle Ω(L, R), where
xi ∈ {L, R} and fi
: {0, 1}
s → {0, 1}
λi
. For the ith query the oracle replies with fi(xi) and we say that in
this case the adversary A retrieved the value fi(xi). The only restriction is that in total the adversary does
not retrieve more than λ bits from each L and R. In the following, let Out(A, Ω(L, R)) be the output of A at
the end of this game. Without loss of generality, we assume that Out(A, Ω(L, R)) := (f1(x1), . . . , ft(xt)).
LEAKAGE FROM COMPUTATION. So far, we discussed how to model leakage from the memory of a device,
where the memory is split into two parts (L, R). If the physical device carries out “some computation” using
its memory (L, R), and this computation leaks information to the adversary, then we need a way to describe
the leakage from such computation. As discussed in the introduction, we do this in form of a two-party
7
protocol Π = (PL, PR), which is executed between the two parties PL and PR and an adversary is allowed
to obtain partial information (the leakage) from the internal state of the players.
Initially, the party PL holds L, while PR holds R. The execution of Π with initial inputs L and R, denoted
by Π(L, R), proceeds in rounds. In each round one player is active and sends messages to the other one.
These messages can depend on his input (i.e., his initial state), his local randomness, and the messages that
he received in earlier rounds. Additionally, the user of the protocol (or the adversary – in case the user is
malicious) may interact with the protocol, i.e., he may receive messages from the players and sends messages
to them. For simplicity, we assume that messages that are sent by the user to the protocol are delivered to
both parties PL and PR. At the end of the protocol’s execution, the players PL and PR (resp.) may output a
value L
0
and R0
(resp.). These outputs may be viewed as the new internal state of the protocol and of course
are not given to the adversary.
One natural way to describe the leakage of the computation (and memory) of such a protocol is to allow
the adversary to adaptively pick at the beginning of each round a leakage function f and give f(state) to
the adversary. Here, state contains the initial state of the active party, its local randomness and the messages
sent and received during this round by her. Indeed, in our setting, we allow the adversary to learn such
leakages. However, to simplify exposition, we consider actually a stronger model, and use the concept of a
leakage game introduced earlier in this section. More precisely, for player Px ∈ {PL, PR}, we denote the
local randomness that is used by Px during the execution of Π(L, R) as ρx, and all the messages that are
received or sent (including the messages from the user of the protocol) by Mx. At any point in time, we
allow the adversary A to play a λ-leakage game against the leakage oracle Ω((L, ρL, ML); (R, ρR, MR)). A
technical problem may arise if A asks for leakages before sending regular messages to the players. In such a
case parts of Mx may be undefined, and for simplicity, we will set them to constant 0. For some initial state
(L, R), we denote the output of A after this process with A  (Π(L, R) → (L
0
, R0
)).
As we are interested in the continuous leakage setting, we will mostly consider an adversary that runs in
many executions of A  (Π(L, R) → (L
0
, R0
)). For the ith execution of the protocol Π(L
i−1
, Ri−1
), we
will write A 

Π(L
i−1
, Ri−1
) → (L
i
, Ri
)

, where the current initial state of this round is (L
i−1
, Ri−1
)
and the new state of PL and PR will be (L
i
, Ri
). After A 

Π(L
i−1
, Ri−1
) → (L
i
, Ri
)

, we assume
that the players PL and PR erase their current state except for their new state L
i
and Ri
, respectively. More
precisely, for the ith execution of A 

Π(L
i−1
, Ri−1
) → (L
i
, Ri
)

, we let the adversary interact with
the leakage oracle Ω((L
i−1
, ρi
L
, Mi
L
); (Ri−1
, ρi
R
, Mi
R
)), where (ρ
i
L
, ρi
R
) denotes the randomness used during
this execution, and (Mi
L
, Mi
R
) denotes the messages that the players send and receive. If A is a λ-limited
adversary, then we allow him to learn up to λ bits from the oracle in each such execution.
2.3 Leakage-resilient Storage
Davi et al. [9] recently introduced the notion of leakage-resilient storage (LRS) Φ = (Encode, Decode).
An LRS allows to store a secret in an “encoded form” such that even given leakage from the encoding no
adversary learns information about the encoded values. One of the constructions that the authors propose
uses two source extractors and can be shown to be secure in the independent leakage model. More precisely,
an LRS for the independent leakage model is defined for message space M and encoding space L × R as
follows:
– Encode : M → L × R is a probabilistic, efficiently computable function and
– Decode : L × R → M is a deterministic, efficiently computable function such that for every S ∈ M
we have Decode(Encode(S)) = S.
An LRS Φ is said to be (λ, )-secure, if for any S, S0 ∈ M and any λ-limited adversary A, we have
∆(Out(A, Ω(L, R)); Out(A, Ω(L
0
, R0
))) ≤ ,
8
where (L, R) := Encode(S) and (L
0
, R0
) := Encode(S
0
).
In this paper, we consider a leakage-resilient storage scheme that allows to efficiently store elements
S ∈ F
m for some m ∈ N. Namely, we propose Φ
n,m
F = (Encoden,m
F
, Decoden,m
F
) defined as follows:
– Encoden,m
F
(S) first selects L ← F
n\{(0n
)} at random, and then samples R ← F
n×m such that L·R = S.
It outputs (L, R).
– Decoden,m
F
(L, R) outputs L · R.
The following lemma shows that Φ
n,m
F
is a secure LRS. The proof uses the fact that an inner product over a
finite field is a two-source extractor [8,35] and appears in Appendix C.
Lemma 1. Let m, n ∈ N with m < n and let F such that |F| = Ω(n). For any 1/2 > δ > 0, γ > 0 the LRS
Φ
n,m
F
as defined above is (λ, )-secure, with λ = (1/2 − δ)n log |F| − log γ
−1 and  = 2m(|F|
m+1/2−nδ +
|F
m| γ).
The following is an instantiation of Lemma 1 for concrete parameters.
Corollary 1. Suppose |F| = Ω(n) and m < n/20. Then, LRS Φ
n,m
F
is (0.3·|F
n
| , negl(n))-secure, for some
negligible function negl.
Proof (of Corollary 1). In Lemma 1 set δ = 0.10 and γ := |F|
−n/10. It is easy to see that for such a choice of
parameters  (as defined in Lemma 1) is negligible. We also have that λ is equal to 0.4n log |F|−n log |F| /10,
which is equal to 0.3 · |F
n
|. ut
3 Leakage-Resilient Refreshing of LRS
An obvious drawback of an LRS is the fact that the total leakage from the memory is bounded by some small
constant λ. Indeed, if an adversary can continuously learn information from the encoded secret (L, R) ←
Encode(S), then after a few observations L and R are completely known, and the adversary can trivially
break the LRS. To solve this problem, we need a method of “pumping” new randomness into the encoding. To
this end, we show how to securely refresh an LRS encoding. More precisely, we will develop a probabilistic
protocol (L
0
, R0
) ← Refresh(L, R) that securely refreshes (L, R), even when the adversary can continuously
observe the computation from the refreshing process. The only additional assumption that we make is that
the protocol has access to a simple leak-free source O of correlated randomness.
For a secret S and a leakage-resilient storage Φ = (Encode, Decode) with message space M, the refreshing
of an encoded secret (L, R) ← Encode(S) is done by a two-party protocol (L
0
, R0
) ← Refresh(L, R).
Initially, PL holds L and PR holds R. At any point during the execution of the protocol, the adversary can
interact with a leakage oracle and learn information about the internal state of PL and PR. At the end the
players output the “refreshed” encoding (L
0
, R0
), i.e., the new state of the protocol. Notice that there is no
interaction between the refreshing protocol and the user of the protocol. In other words: the only way in
which the adversary can “interact” with the protocol is via the leakage oracle.
For correctness, we require that Decode(L, R) = Decode(L
0
, R0
), i.e., the refreshed encoding decodes to
the stored secret S. Informally, for security, we require that no λ-limited adversary can learn any significant
information about S (for some parameter λ ∈ N). We will define the security of the refreshing protocol
using an indistinguishability notion. Intuitively, the definition says that for any two secrets S, S0 ∈ M the
view (i.e., the leakage) resulting from the execution of the refreshing of secret S is statistically close to the
view from the refreshing of secret S
0
. Before we formally define security of our refreshing, we consider the
following experiment, which runs the refreshing protocol for ` rounds and lets the adversary play a leakage
game in each round. For a protocol Π, an LRS Φ, an λ-bounded adversary A, ` ∈ N and S ∈ M, we have
Exp(Π,Φ)
(A, S, `):
9
1. For a secret S, we generate the initial encoding as (L
0
, R0
) ← Encode(S).
2. For i = 1 to ` run A against the ith round of the refreshing protocol: A 

Π(L
i−1
, Ri−1
) → (L
i
, Ri
)

.
3. Return whatever A outputs.
The experiment outputs whatever A outputs after interacting with Π for ` iterations (without loss of generation
we can assume that A outputs just a single bit b ∈ {0, 1}). To simplify notation, we will sometimes omit
to specify Φ in Exp(Π,Φ)
(A, S, `) explicitly. We are now ready to define security of a refreshing protocol.
Definition 1 (A (`, λ, )-refreshing protocol). For a LRS Φ = (Encode, Decode) with message space M,
a refreshing protocol (Refresh, Φ) is (`, λ, )-secure, if for every λ-limited adversary A and any two secrets
S, S0 ∈ M, we have that ∆(Exp(Refresh,Φ)
(A, S, `); Exp(Refresh,Φ)
(A, S0
, `)) ≤ .
In the rest of this section, we construct a secure refreshing protocol for the LRS scheme Φ
n,m
F =
(Encoden,m
F
, Decoden,m
F
) from Section 2.3. Our protocol can refresh an encoding (L, R) ← Encoden,m
F
(S)
any polynomial number of times, and guarantees security for λ being a constant fraction of the length of L
and R (cf. Theorem 1 and Corollary 2 for the concrete parameters). For ease of notation, we will often omit
to specify the Φ
n,m
F when talking about the refreshing protocol (Refreshn,m
F
, Φn,m
F
) and just write Refreshn,m
F
or Refresh when clear otherwise.
As already mentioned in the introduction, we will assume that the players have access to a non-uniform
source of randomness. More precisely, they will access an oracle O, that samples pairs (A, B) ∈ F
n ×
NonSingn×m(F) such that A 6= (0n
) and A · B = (0m). In each iteration the players will sample the oracle
twice: once for refreshing the share of PR (denote the sampled pair by (A, B)), and once for refreshing
the share of PL (denote the sampled pair by (A, ˜ B˜)). The protocol is depicted on Fig. 1. To understand the
main idea behind the protocol, the reader may initially disregard the checks (in Steps 1 and 4) that L and
R0 have full rank (these checks were introduced only to facilitate the proof and only occur with very small
probability: cf. Lemma 3). The reader may also initially assume that m = 1 (the case of m > 1 is a simple
generalization of the m = 1 case). The main idea of our protocol is that first the players generate the value
X ∈ F
n×m such that L · X = (0m), and then in Steps 3 the player PR sets R0
:= R + X (note that, by
simple linear algebra L · R0 = L · (R + X) = L · R + L · X = L · R). Symmetrically, later, the players
generate Y ∈ F
n
such that Y · R0 = (0m) and set (in Step 6) L
0 = L + Y . By a similar reasoning as before
we have L
0
· R0 = L · R0
(= L · R).
The generation of X and Y is done in an “oblivious” way: the player PR will learn X and the player
PL will learn Y , but X will be secret for PR and Y will be secret for PR. In Appendix D.1, we show that a
simpler, and more natural protocol, in which X and Y are generated by PL and PR (resp.) and communicated
to each other is actually insecure. We now first show correctness of our protocol from Figure 1.
Lemma 2 (Correctness of the refreshing). Assuming that the players PL and PR did not abort, we have
for any S ∈ F
m: Decoden,m
F
(Refreshn,m
F
(S)) = S.
Proof. As we assume that A and B have a full rank, and we check (in Steps 1 and Step 4) that L and R0
have full rank, by Lemma 15 in Appendix B we can sample a random solution M and M˜ for the equations
in Steps 2 and 5 (resp.). The rest of the proof follows by simple linear algebra:
L
0
· R
0 =

L + A˜ · M˜

· R
0
(2)
= L · R
0 + A˜ · M˜ · R
0
(3)
= L · R
0 + A˜ · B˜ (4)
= L · R
0
, (5)
where (2) follows from the construction of the protocol (Step 6), Eq. (3) follows from the linearity of the inner
product, Eq. (4) comes from the fact that M˜ · R0 = B˜ (cf. Step 5), and (5) follows from A˜ · B˜ = (0, . . . , 0).
10
Similarly (5) is equal to L · (R + M · B) = L · R + L · M · B. By a similar reasoning as above we get
that L · M · B = A · B = (0, . . . , 0). Hence, (5) is equal to L · R, which decodes to S. This finishes the
proof. ut
Protocol (L
0
, R0
) ← Refreshn,m
F
(L, R):
Input (L, R): L ∈ F
n
is given to PL and R ∈ F
n×m is given to PR.
Refreshing the share of PR:
1. If L does not have a full rank then the players abort. Let (A, B) ← O and give A to PL and B to PR.
2. Player PL generates a random non-singular matrix M ∈ F
n×n
such that L · M = A and sends it to PR.
3. Player PR sets X := M · B and R
0
:= R + X.
Refreshing the share of PL:
4. If R
0
does not have a full rank then the players abort. Let (A, ˜ B˜) ← O and give A˜ to PL and B˜ to PR.
5. Player PR generates a random non-singular matrix M˜ ∈ F
n×n
such that M˜ · R
0 = B˜ and sends it to PL.
6. Player PL sets Y := A˜ · M˜ and L
0
:= L + Y .
Output: The players output (L
0
, R0
).
The adversary plays a λ-leakage game against: Ω

(L, A, M, A, ˜ M˜ ) ; (R, B, M, B, ˜ M˜ )

Fig. 1. Protocol Refreshn,m
F
. The oracle O samples randomly pairs (A, B) ∈ F
n×NonSingn×m(F) such that
A 6= (0n
) and A·B = (0m). The text in the frame describes the leakage game played by the adversary, when
the protocol is executed. Note that by Lemma 15 in Appendix B, sampling the random matrices in Steps 2
and 5 can be done efficiently.
What remains is to show that protocol Refreshn,m
F
from Figure 1 satisfies Definition 1. This is done in
the following theorem.
Theorem 1 (Security of Refreshn,m
F
). Let m/3 ≤ n, n ≥ 16 and ` ∈ N. Let n, m and F be such that Φ
n,m
F
is (λ, )-secure (for some λ and ). The protocol Refreshn,m
F
is a (`, λ/2 − 1, 0
)-refreshing protocol for an
LRS Φ
n,m
F with 
0
:= 2` |F|
m (3 |F|
m  + m |F|
−n−1
).
To prove this theorem, we will need to show that any adversary A that interacts for ` iterations with the
refreshing experiment ExpRefresh (as given in Definition 1), will only gain a negligible (in n) amount of
information about the encoded secret S. Notice that this in particular means that A’s interaction with the
leakage oracle given in the frame of Figure 1 will not provide the adversary with information on the encoded
secret. More formally, we will show that for every (λ/2 − 1)-limited A and every S, S0 we have:
∆(ExpRefresh(A, S, `); ExpRefresh(A, S0
, `)) ≤ 2` |F|
m (3 |F|
m  + m |F|
−n−1
). (6)
This will be proven using the standard technique called the “hybrid argument” by creating a sequence
of “hybrid distributions” – denoted by Hybi
(A, S, S0
, `) and Hyb ]i
(A, S, S0
, `). We will show that the
first distribution in this sequence is statistically very close to ExpRefresh(A, S, `), and the last one is very
close to ExpRefresh(A, S0
, `). Moreover, each two consecutive distributions in the sequence will be very
close. Hence, by applying the triangle inequality multiple times, we will obtain that ExpRefresh(A, S, `) and
ExpRefresh(A, S0
, `) are close.
Following the notation of ExpRefresh, we denote in the hybrid experiments Hybi
and Hyb ]i
the input
to the jth execution of Refreshn,m
F
by (L
j−1
, Rj−1
), and its output by (L
j
, Rj
). We can now define
the hybrid distributions as follows. For each i ∈ [n] let Hybi
(A, S, S0
, `) be defined in the same way as
11
ExpRefresh(A, S, `) (i.e., run ` iterations of the protocol from Fig. 1) except that in the ith iteration in Step 2
for the refreshing of PR’s share, instead of using the oracle O we use an oracle O0
that samples (A, B) from
the set
{(A, B) ∈ F
n × NonSingn×m(F) : A 6= (0, . . . , 0) and A · B = S
0 − S}.
Observe that this means that for j ≤ i−1 we have L
j
·Rj = S since we proceed as in ExpRefresh(A, S, `) for
the first j executions of Refreshn,m
F
. As in the ith iteration for refreshing the share of PR we use the oracle
O0 by simple calculation we get that
L
i−1
· R
i = L
i−1
· (R
i−1 + X) = L
i−1
· (R
i−1 + M · B) = S + L
i−1
· M · B = S + A · B = S
0
.
Since from then on we continue with using the oracle O, we get for j ≥ i that L
j
· Rj = S
0
. Similarly,
let Hyb ]i
(A, S, S0
, `) be defined in the same way as ExpRefresh(A, S, `) except that in the ith iteration of
Refreshn,m
F
for refreshing the share of PR we sample (A, ˜ B˜) from the oracle O0
.
Before we show in Lemma 4 that these hybrid distributions are indeed close, let us prove a simple
lemma about the event Q that the players abort in the protocol. Recall that in Figure 1 PL or PR may abort
the execution of the protocol, in case that L (cf. Step 1) or R0
(cf. Step 4) do not have full rank. To preserve
correctness of the protocol, we reconstruct the secret in case of abortion. Obviously, in such a case the
distance between the distributions will not be small anymore. Hence, we need to bound the probability that
such an event occurs.
Lemma 3 (Probability of abort). For any S, we have Pr [Q] ≤ 2`m · |F|
m−n
in ExpRefresh(A, S, `).
Proof. For each j we define the event E(j) that the players abort in the jth iteration. This means that either
L
j−1 or Rj does not have full rank. Note that (L
0
, R0
) are chosen uniformly at random subject to the
constraint that they encode the value S. By the construction of our protocol, it is easy to verify that this
carries over to each L
j
and Rj
. In other words for each E(j) we can view L
j−1
as being chosen uniformly at
random and each of the m columns of Rj
as being chosen from an n−1 dimensional subspace of F
n
. Hence,
from Lemma 16 the probability that (Rj
)
T does not have a full rank is at most m · |F|
m−n
. This carries over
to Rj by Lemma 18 from the appendix. Clearly, L
j does not have a full rank only if it is equal to (0, . . . , 0),
which happens with probability |F|
−n ≤ m·|F|
m−n
. Therefore, we get from the union-bound that for each j
we have Pr[E(j)] ≤ 2m·|F|
m−n
and by applying again the union-bound, we get that Pr [Q] ≤ 2`·m·|F|
m−n
.
ut
It is easy to see that the above Lemma 3 works also in case of the hybrid experiments, and hence for both
Hybi
(A, S, S0
, `) and Hyb ]i
(A, S, S0
, `), we have
Pr [Q] ≤ 2`m · |F|
m−n
.
We now have the main technical lemma of this section.
Lemma 4. For the parameters `, n, m, λ, , F as in Theorem 1, for every (λ/2 − 1)-limited A and every
S, S0 we have the following:
1. ∆

ExpRefresh(A, S, `) ; Hyb1
(A, S, S0
, `) |Q

≤ 2 |F|
2m ,
2. for every i = 1, . . . , ` it holds that ∆

Hybi
(A, S, S0
, `) ; Hyb ]i
(A, S, S0
, `) | Q

≤ 2 |F|
2m ,
3. for every i = 1, . . . , ` − 1 it holds that ∆

Hyb ]i
(A, S, S0
, `) ; Hybi+1(A, S, S0
, `) | Q

≤ 2 |F|
2m ,
4. ∆

Hyb ]`
(A, S, S0
, `) ; ExpRefresh(A, S0
, `) | Q

≤ 2 |F|
2m .
12
Proof. We show only the proof of Point 3. The proof of the remaining points is analogous. The table below
represents the inner products of L
j
and Rj
in the hybrids Hyb ]i
(A, S, S0
, `) and Hybi+1(A, S, S0
, `).
j = 1 2 · · · i i + 1 i + 2 · · · `
L
j L
0 L
0 L
1 L
1
· · · L
i−1 L
i−1 L
i L
i L
i+1 L
i+1
· · · L
`
Rj R0 R1 R1 R2
· · · Ri−1 Ri Ri Ri+1 Ri+1 Ri+2
· · · R`
(∗) in Hybi+1(A, S, S0
, `) S S S S · · · S S S S
0 S
0 S
0
· · · S
0
(∗∗) in Hyb ]i
(A, S, S0
, `) S S S S · · · S S S
0 S
0 S
0 S
0
· · · S
0
(7)
It is easy to see that the only difference between Hyb ]i
(A, S, S0
, `) and Hybi+1(A, S, S0
, `) is that in the
former L
i
· Ri = S
0
and in the latter L
i
· Ri = S. We will show that for any (λ/2 − 1)-limited adversary A
∆

Hyb ]i
(A, S, S0
, `) ; Hybi+1(A, S, S0
, `)|Q

≤ 2 |F|
2m . (8)
We prove this by contradiction. Suppose there exists an adversary A for which Eq. (8) does not hold, then we
construct a λ-limited adversary S, that we call the simulator, which will be able to break the (λ, )-security
of Φ
n,m
F
. S runs A as a sub-routine and simulates its environment according to either Hyb ]i
(A, S, S0
, `)
or Hybi+1(A, S, S0
, `) by just having access to its target oracle Ω(L, R). We will show that in case that
(L, R) ← Encoden,m
F
(S
0
) the simulation of A is as Hyb ]i
(A, S, S0
, `) (cf. (**) in Table 7), while in case
of (L, R) ← Encoden,m
F
(S) the simulation is as in Hybi+1(A, S, S0
, `) (cf. (*) in Table 7). To this end,
S “plugs” the encoding (L, R) from its target oracle into (L
i
, Ri
), and uses access to its target oracle to
simulate the leakage from ExpRefresh that depends on (L
i
, Ri
). One main difficulty is that ExpRefresh may
run for many iterations, hence, allowing the adversary to learn a large amount of information, while on the
other hand S only can retrieve up to λ bits from its target oracle. To solve this problem S will simulate most
leakages “off-line”, i.e., without using access to its target oracle. For the ith and (i+1)th execution, however,
S will use access to its target oracle to make the leakages from these rounds consistent with the “off-line”
leakages. Eventually, the simulator will output whatever A outputs, or abort, in which case it outputs ⊥. We
give the details below.
The adversary S will simulate A in the following way.
Pre-processing I: generating the L
j and Rj variables except for (L
i
, Ri
): He sets(L
0
, R0
) ← Encoden,m
F
(S).
He performs (i−1) iterations of the refreshing procedure, which results into (L
0
, R0
), . . . ,(L
i−1
, Ri−1
)
and all the messages that are generated during the execution of the protocol from Figure 1. He then sets
(L
i+1, Ri+1) ← Encoden,m
F
(S
0
) and performs the remaining executions of the refreshing procedure. He
stores all the variables used in these executions. Note, that the only thing that the simulator misses for
the simulation of A are the variables used in the ith and (i + 1)th iteration.
Pre-processing II: simulating the first i − 1 iterations: The simulator S starts A and simulates him on
the variables that he generated previously for the first (i − 1) iterations of the refreshing protocol. This
can be done easily, as all the variables for the simulation are known.
Leakage of (L
i
, Ri
) ← Refreshn,m
F
(L
i−1
, Ri−1
) in the ith iteration: Now, the simulator simulates the leakage
from phase i. Note that he does not know (L
i
, Ri
) – since it is equal to (L, R) he has access to it
only via the leakage oracle. We first describe how he can do it if he knows (L
i
, Ri
) completely and later
argue that it can be done also just by leaking limited amount of data from L
i
and Ri
.
First, S simulates the refreshing of PR’s share. He sets
X := R
i − R
i−1
. (9)
13
He checks if L
i−1
· X = (0, . . . , 0) (or, equivalently: if L
i−1
· Ri = S). If not, then he aborts (let Q1
denote this event). Otherwise he chooses M ∈ NonSingn×n
(F) uniformly at random and computes
B := M−1
· X (10)
He also computes
A := L
i−1
· M (11)
Note that A · B := L
i−1
· M · M−1
· X = L
i−1
· X = (0, . . . , 0).
Now, to simulate the refreshing of the share of PL, he chooses a random M˜ ← NonSingn×n
(F). He
computes
Y := L
i − L
i−1
. (12)
He sets:
A˜ := Y · M˜ −1
. (13)
He also computes
B˜ := M˜ · R
i
. (14)
Note that we have
A˜ · B˜ = Y˜ ·

M˜
−1
· M˜ · R
i = Y˜ · R
i = (L
i − L
i−1
) · R
i =

(0, . . . , 0) if L
i
· Ri = S
S
0 − S if L
i
· Ri = S
0
.
(15)
The simulator also checks if the values A, B, A˜ and B˜ have a full rank (so that they look like generated
by the oracle O). If not, then he aborts. Call this event Q2.
Now, the simulator has all the variables needed to simulate the game between A and
Ω

(L
i−1
, A, M, A, ˜ M˜ ) ; (R
i−1
, B, M, B, ˜ M˜ )

.
The only problem, that we did not address so far, is that in reality the simulator has access to L
i
and Ri
only via the leakage oracle Ω(L; R). The main observation is now that the above simulation is done in
such a way that the leakage function can compute (a) (L
i−1
, A, M, A, ˜ M˜ ) just from L
i
:= L and (b)
(Ri−1
, B, M, B, ˜ M˜ ) just from Ri
:= R.
First, observe that L
i−1
and Ri−1
are chosen by S in advance in the pre-processing I phase. Moreover, S
can also choose M and M˜ beforehand, as they are just chosen randomly from NonSingn×n
(F). Hence,
(L
i−1
, Ri−1
, M, M˜ ) can be treated as constants and “hard-wired” into the leakage function that A issues
to its leakage oracle in the ith iteration.
Now, to see (a) observe that A is a function of L
i−1
and M (cf. (11)), which are “hard-wired” into the
leakage function, and A˜ is a function of L
i
, Li−1
and M˜ (cf. (12) and (13)), where L
i−1
and M˜ are
“hard-wired” and L
i
:= L comes from the target oracle).
To see (b) observe that B is a function of M, Ri
and Ri−1
(cf. (9) and (10)), where M and Ri−1
are
“hard-wired”, and B˜ is a function of M˜ (a “hard-wired” value), and Ri
(cf. 14).
Hence, the (λ/2 − 1)-leakage game run by A at the ith iteration can be simulated by S using a (λ/2)-
leakage game against Ω(L; R) (the “+1” overhead comes from the fact that we need a little bit of extra
space in order to communicate the fact that the simulation aborted).
Leakage of (L
i+1, Ri+1) ← Refreshn,m
F
(L
i
, Ri
) in the (i + 1)th iteration: Simulating the leakage form phase
i + 1 is done in a very similar way. First the simulator chooses random non-singular matrices M and M˜ .
He sets: X := Ri+1 − Ri
, and B := M−1
· X. Then he calculates A := L
i
· M.
14
He then computes Y := L
i+1 − L
i
and A˜ := Y · M˜ −1
, and finally B˜ := M˜ · Ri
. He aborts in case
L
i
· Ri+1 6= S (denote this event by Q0
1
), or in case one of A, B, A˜ and B˜ does not have a full rank
(denote this event by Q0
2
). Similarly to (15) it is easy to calculate that
A · B =

(0, . . . , 0) if L
i
· Ri = S
0
S
0 − S if L
i
· Ri = S.
(16)
Moreover, it is easy to check that, exactly as before, the (λ/2 − 1)-leakage game performed by A in the
(i + 1)th iteration can be simulated by S using a (λ/2)-leakage game against Ω(L; R).
Post-processing: simulating the remaining iterations: The simulator S simulates A on the variables that
he generated previously for the i + 1th,. . . , nth iteration. Exactly as in “pre-precessing II” he can do it
since he generated the corresponding variables himself. At the end he outputs the output of A.
We now prove that for any b ∈ {0, 1} we have the following:
Pr[Out(S, Ω(L, R)) = b | Q1 ∨ Q2 ∨ Q0
1 ∨ Q0
2
] = (
Pr[Hyb ]i
(A, S, S0
, `) = b | Q] if L · R = S
Pr[Hybi+1(A, S, S0
, `) = b | Q] if L · R = S
0
(17)
To show it, we assume that the players and the simulation did not abort (i.e., we have Q and Q1 ∨ Q2 ∨ Q0
1 ∨ Q0
2
).
It is easy to see that the distributions of the variables created by the simulator and Hyb ]i
(A, S, S0
, `) and
Hybi+1(A, S, S0
, `) are equal for the first i − 1 iterations, and for the iterations i + 2, . . . , n. The only
non-trivial things happen in the ith and (i + 1)th iteration. The main difference between Hyb ]i
(A, S, S0
, `)
and Hybi+1(A, S, S0
, `) can be summarized as follows:
Hyb ]i
(A, S, S0
, `) Hybi+1(A, S, S0
, `)
A˜ · B˜ in ith iteration S
0 − S (0, . . . , 0)
A · B in (i + 1)th iteration (0, . . . , 0) S
0 − S
The variables created by our simulator indeed satisfy these relations, as shown on (15) and (16). It remains
to show that the distribution of the variables generated by S when interacting with Ω(Encoden,m
F
(S)) or
Ω(Encoden,m
F
(S
0
)) (resp.) is identical to Hybi+1(A, S, S0
, `) or Hyb ]i
(A, S, S0
, `) (resp.). To this end,
consider the execution of the ith iteration of Refreshn,m
F
in Hyb ]i
(A, S, S0
, `) experiment and compare it
to the simulation of the ith iteration assuming that L
i
· Ri = S
0
(the remaining cases can be analyzed in a
similar way).
ith iteration in Hyb ]i
(A, S, S0
, `):
(A, B) ← O
M is a random non-singular matrix s. t. L
i−1M =
A
X := M · B
Ri
:= Ri−1 + X
(A, ˜ B˜) ← O0
M˜ is a random non-singular matrix s. t. M˜ ·Ri = B˜
Y := A˜ · M˜
L
i
:= L
i−1 + Y
ith iteration of simulation, with L · R = L
i
· Ri =
S
0
:
X := Ri − Ri−1
check if L
i−1
· X = (0, . . . , 0)
M is a random non-singular matrix
A := L
i−1
· M
B := M−1
· X
Y := L
i − L
i−1
M˜ is a random non-singular matrix
A˜ := Y · M˜ −1
B˜ := M˜ · Ri
.
Let us now discuss why these methods of sampling the variables are identical if the abort events do not occur.
15
1. L
i−1
, Ri−1
, A and M: In both settings(L
i−1
, Ri−1
) are sampled in the same way. Together with Lemma 17
from the Appendix B we get that in both cases L
i−1
, Ri−1
, A and M are distributed identically.
2. B, X and Ri
:
– Left hand side: B comes from the oracle O and is a random matrix from NonSingn×m(F) subject to
the constraint that A · B = (0, . . . , 0). Then, we compute X := M · B and Ri
:= Ri−1 + X.
– Right hand side: Here, Ri
and Ri−1
are fixed and we compute X := Ri − Ri−1
and then B :=
M−1
· X.
It is easy to see that in the first case, X is a random n × m matrix subject to the constraint that its
column vectors are orthogonal to L
i−1
. In the second case X is computed from the matrices Ri
and
Ri−1
, where (L
i−1
, Ri−1
) ← Encoden,m
F
(S) and (L
i
, Ri
) ← Encoden,m
F
(S
0
) are sampled randomly
and independently. Hence, X := Ri − Ri−1
is a random matrix. As on the right hand side we further
assumed that L
i−1
· X = (0, ...0) (i.e., the check does not fail), we have that also on the right hand side
X is a random n × m matrix with column vectors that are orthogonal to L
i−1
, which implies that both
distributions are identical.
3. (A, ˜ B˜), M˜ and L
i
: We can argue this similar to above.
It remains to bound the probability that the abort does not occur during the simulation.
Claim. In the above simulation we have:
Pr h
Q1 ∧ Q2 ∧ Q0
1 ∧ Q0
2
i
≥ |F|
−2m /2. (18)
Proof. The event Q1 occurs if L
i−1
· Ri 6= S. Since clearly L
i−1
· Ri has a uniform distribution over |F|
m
and the same holds for Q0
1
, we have
Pr[Q1] = Pr[Q
0
1
] = |F|
−m . (19)
We next define the events QA, QB, QA˜ and QB˜ as the events that the corresponding variables A, B, A˜ and
B˜ do not have a full rank. Similarly, we define the events Q0
A
, Q0
B
, Q0
A˜
and Q0
B˜
. As M is a full rank matrix
and L
i−1
is a random vector in F
n
, we get that A is chosen uniformly at random in F
n
, which gives us:
Pr[QA|Q1 ∧ Q
0
1
] ≤ |F|
−n
. (20)
Let us next consider the event QB. It is easy to see that the rows of XT are chosen uniformly at random from
the subspace of vectors that are orthogonal to L
i−1
. Hence, by Lemma 16, it follows that XT has rank m with
probability at least 1 − m · |F|
m−n
. By Lemma 18, this implies that rank(X) = m with probability at least
1 − m · |F|
m−n
, and by the same lemma, we get that rank(B) = m with probability at least 1 − m · |F|
m−n
.
As a similar argument works for QB˜ , we get:
Pr[QB|Q1 ∧ Q
0
1
] ≤ m · |F|
m−n
, (21)
Pr[QB˜ |Q1 ∧ Q
0
1
] ≤ m · |F|
m−n
. (22)
Next, we consider QA˜. As M˜ has full rank and conditioned on Q1 the vector Y is a random vector from an
n − m dimensional subspace, we get
Pr[QA˜|Q1 ∧ Q
0
1
] ≤ |F|
m−n
. (23)
16
The same arguments work for bounding Q0
A
, Q0
B
, Q0
A˜
and Q0
B˜
. We now get:
Pr h
Q1 ∧ Q2 ∧ Q0
1 ∧ Q0
2
i
= Pr[Q2 ∧ Q
0
2
|Q1 ∧ Q
0
1
] · Pr[Q1] · Pr[Q
0
1
] (24)
= Pr[Q2 ∧ Q
0
2
|Q1 ∧ Q
0
1
] · |F|
−2m (25)
= (1 − Pr[Q2 ∨ Q0
2
|Q1 ∧ Q
0
1
]) · |F|
−2m (26)
≥ (1 − Pr[QA|Q1 ∧ Q
0
1
] − . . . − Pr[Q
0
B˜
|Q1 ∧ Q
0
1
]) · |F|
−2m (27)
≥ (1 − 8m · |F|
m−n
) · |F|
−2m (28)
≥ |F|
−2m /2. (29)
Eq. (24) follows from the fact that Q1 and Q0
1
are independent and (25) from Eq. (20). Eq.(26) is a standard
transformation and Eq.(27) follows from the union bound. Eq.(28) follows from Eq.(20)-(23) and
m · |F|
m−n ≥ |F|
−n
. Finally, Eq. 29 uses that (1 − 8m · |F|
m−n
) ≥ 1/2 when m ≤ n/2 and n ≥ 16.
This concludes the proof. ut
We are now ready to obtain a contradiction:
∆

Out(S, Ω(Encoden,m
F
(S))) ; Out(S, Ω(Encoden,m
F
(S
0
)))
≥ ∆

Out(S, Ω(Encoden,m
F
(S))) ; Out(S, Ω(Encoden,m
F
(S
0
)))|Q1 ∧ Q
0
1 ∧ Q2 ∧ Q
0
2

· Pr[Q1 ∧ Q
0
1 ∧ Q2 ∧ Q
0
2
]
≥ ∆

Out(S, Ω(Encoden,m
F
(S))) ; Out(S, Ω(Encoden,m
F
(S
0
)))|Q1 ∧ Q
0
1 ∧ Q2 ∧ Q
0
2

· |F|
−2m /2
≥ ∆

Hyb ]i
(A, S, S0
, `) ; Hybi+1(A, S, S0
, `)|Q

· |F|
−2m /2
≥ 2 |F|
2m  · |F|
−2m /2 = .
As further S retrieves in total λ bits from each party (λ/2 in phase i and λ/2 in phase i + 1) we get a
contradiction to the (λ, )-security of Φ
n,m
F
, which concludes the proof of the lemma. ut
Proof (of Theorem 1). As shown in Lemma 4 conditioned on Q the distance between each consecutive
distributions ExpRefresh(A, S, `), Hyb1
(A, S, S0
, `), Hyb ]1
(A, S, S0
, `), . . ., ExpRefresh(A, S0
, `) is at most
2 |F|
2m . Since the sequence of distributions has length 2`+2, we get by the triangle inequality (applied 2`+
1 times) that the distance between the first ExpRefresh(A, S, `) and the last distribution ExpRefresh(A, S0
, `)
conditioned on Q is at most (2` + 1)2 |F|
2m  ≤ 6` |F|
2m . With Lemma 3, we then get:
∆(ExpRefresh(A, S, `); ExpRefresh(A, S0
, `)) ≤ (6` |F|
2m ) Pr[Q] + Pr[Q]
≤ 6` |F|
2m  + Pr[Q] ≤ 6` |F|
2m  + 2`m · |F|
m−n−1
≤ 2` |F|
m (3 |F|
m  + m |F|
−n−1
).
This proves (6), and hence shows the statement of the theorem. ut
Combining this theorem with Corollary 1 we get the following.
Corollary 2. Let n ∈ N be the security parameter. Suppose |F| = Ω(n) and let m = o(n). Then Refreshn,m
F
is a (`, 0.15 · n log(|F|) − 1, negl(n))-refreshing protocol for the LRS Φ
n,m
F
, where ` is a polynomial in n
and negl(n) is some negligible function.
17
3.1 Security of Refreshing with Additional Auxiliary Information
Consider a secret S ∈ Mm and suppose we use our protocol in a setting where the secret is sampled
from an affine subspace Z ⊆ Mm of dimension m0 < m that is known to the adversary beforehand.4
In
such a case our security definition says that an adversary that observes leakage from the refreshing cannot
learn any additional information about S. In this section, we extend our security notion and show that the
above statement holds even when the adversary obtains some auxiliary information on the encodings. More
precisely, for an affine subspace Z of dimension m0
, let W be a m × (m − m0
)-matrix of full rank and
Q ∈ Mm−m0
be a vector such that the solution space of S · W = Q defines the affine subspace Z. Then,
we show that for any S ∈ Z and (L
0
, R0
) ← Encode(S), given auxi−1 = Ri−1
· W from the execution of
(L
i
, Ri
) ← Refresh(L
i−1
, Ri−1
) does not provide the adversary with information other than the fact that S
belongs to the subspace Z. To define this more formally, we extend the experiment ExpRefresh(A, S, `) from
above in the following way:
– initially we give aux0 = R0
· W to the adversary A
– for each iteration in Step 2, we run A(W, Q) 

Refresh(L
i−1
, Ri−1
) → (L
i
, Ri
)

and additionally
give auxi = Ri
· W to A.
We denote this experiment with Expaux
Refresh(A, S, `, W, Q), and consider the following extension of Definition
1.
Definition 2. [(`, λ, )-refreshing protocol with auxiliary information] Let Z ⊆ Mm be an m0 < m
dimensional affine subspace defined by W and Q as given above. For a LRS Φ = (Encode, Decode) with
message space M, a refreshing protocol Refresh is a (`, λ, )-refreshing protocol with auxiliary information
defined by (W, Q), if for every λ-limited adversary A and every pair of messages S, S0 ∈ Z we have that
∆(Expaux
Refresh(A, S, `, W, Q); Expaux
Refresh(A, S0
, `, W, Q)) ≤ .
The reader may ask why such an extended security definition is useful at all. Indeed, it turns out that such
an extension is helpful when we want to apply our refreshing protocol to construct leakage-resilient cryptographic
schemes. We will detail on this in the next sections.
Before we show that our refreshing protocol also satisfies this stronger notion of security, notice that
since the adversary can choose the leakage function after learning auxi
, he can essentially leak from PL the
value of L
i
· auxi = L
i
· Ri
· W = S · W (if m − m0
is small), i.e., he can learn some linear function of
the secret. The good news is that he knows S · W already because it is equal to Q! As it turns out, this is the
only information that he will learn. Formally, we can show the following generalization of Theorem 1.
Theorem 2 (Generalization of Theorem 1). Let m/4 ≤ n, n ≥ 16 and ` ∈ N. Let (W, Q) be as above
defining an m0 < m dimensional affine subspace Z. Let n, m0 and F be such that Φ
n,m0
F
is (λ, )-secure (for
some λ and ). The protocol Refreshn,m
F
is a (`, λ/2 − 1, 0
)-refreshing protocol with auxiliary information
defined by (W, Q) for Φ
n,m
F
. Here, we have: 
0 ≤ 2` |F|
m (3 |F|
2m  + m |F|
−n−1
).
Proof (sketch). The proof is very similar to the proof of Theorem 1 and we only repeat the relevant details
here. In the reduction of Theorem 1, we need to build a λ-limited simulator S that can simulate the view of
a (λ/2 − 1)-limited adversary in Expaux
Refresh(A, S, `, W, Q). To this end, let us first consider the case when
the m × (m − m0
)-matrix W has a special form (call it W0
): namely, its 1 on its diagonal and otherwise 0.
Note that knowledge of W0
and Q with S · W0 means that the first m − m0
coordinates of S are given to the
adversary.
4
In such cases, a natural idea to make the encoding more efficient is to fix some bijection f : Mm0 → Z and encode x ∈ Mm0
instead of encoding f(x). This is of course possible only if f is efficiently computable. As it turns out, in some cases such f
cannot be efficiently computed. This happens e.g., if we use the encoded secrets in computationally-secure protocols (e.g., the
Okamoto identification scheme — cf. Sect. 4).
18
Let S, S0 ∈ Z be two vectors which are equal on their first m − m0
coordinates, and we denote by
S˜ and S˜0
the last m0
coordinates of S and S
0
, respectively. As in Theorem 1 consider Hyb ]i
(A, S, S0
, `)
and Hybi+1(A, S, S0
, `) which differ only in the ith and (i + 1)th round. This means for the first i − 1
executions of Refresh the simulator will refresh an encoding of S and for the last (i + 2) rounds, it refreshes
and encoding of S
0
. Notice that for j ∈ {0, . . . , i − 1, i + 2, . . . , `} the simulator S can trivially generate
auxj = Rj
· W0
, as Rj
is known completely to S.
For the simulation of the ith and (i + 1)th execution S uses access to its target oracle Ω(L, R), where
(L, R) ← Encoden,m0
F
(S˜) or (L, R) ← Encoden,m0
F
(S˜0
). In the simulation S sets L := L
i
and the last m0
columns of Ri
to R. To sample the first (m−m0
) columns of Ri
it proceeds as follows. It samples uniformly
at random vectors R1, . . . , Rm−m0 and checks with access to Ω(L, R), whether L · (R1, . . . , Rm−m0) =
(S1, . . . , Sm−m0). If it does not hold, then S aborts. Let Q be the event that S does not abort. In the simulation
S sets:
R
i
:= (R1, . . . , Rm−m0, R),
and then proceeds as described in the proof of Theorem 1 to sample the remaining variables. Since (R1, . . . , Rm−m0)
are known and W0 has the special form as described above, S can easily compute auxi = Ri
· W.
It remains to analyze why the simulation as described above has the right distribution. It suffices to argue
why (L
i
, Ri
) has the required distribution, as the remaining variables are sampled as in Theorem 1. This is
easy to see as conditioned on Q the first (m − m0
) column vectors of Ri
are sampled uniformly at random
(and independently of R) subject to the constraint that L · (R1, . . . , Rm−m0) = (S1, . . . , Sm−m0). Since
Pr[Q] ≥ F
−m+m0
, we get together with the analysis from Theorem 1 that

0
:= ∆(Expaux
Refresh(A, S, `, W, Q) ; Expaux
Refresh(A, S0
, `, W, Q)) ≤ 2` |F|
m (3 |F|
2m  + m |F|
−n−1
).
The general case, i.e., when W is an arbitrary matrix, follows from the fact that every W ∈ F
m×(m−m0
)
can
be transformed to this special form W0 by multiplying it (from the left side) by some non-singular matrix
N ∈ F
m×m (let W0 = N · W). Hence, we can adjust the computation that is carried out by the simulator by
multiplying the appropriate variables by N. ut
4 Identification and Signature Schemes
In an identification scheme ID a prover attempts to prove its identity to a verifier. For a security parameter k,
ID consists out of three PPT algorithms ID = (KeyGen,P, V):
– (pk, sk) ← KeyGen(1k
): It outputs the public parameters of the scheme and a valid key pair. The public
key is known to both the prover P and the verifier V.
– (P(pk, sk), V(pk)): An interactive protocol in which P tries to convince V of its identity by using his
secret key sk. The verifier V outputs either accept or reject.
We require that ID is complete. This means that an honest prover will always be accepted by the verifier. To
define (black-box) security of an identification scheme ID, we consider a polynomial-time adversary A that
gets the public key pk and interacts with the prover P(pk, sk) playing the role of a verifier. At the end of
this interaction the adversary tries to impersonate P(pk, sk) by engaging in an interaction with V(sk). The
adversary successfully impersonates the prover, if V(sk) outputs accept. We say that the scheme is secure if
every polynomial-time adversary A impersonates the prover with only negligible probability.
We will now extend this standard security notion to capture leakage attacks on the prover, where the
adversary obtains leakage from the prover’s computation. To this end, we let the adversary take the role of
V in the execution of the protocol (P(pk, sk), V(pk)) and allow him, besides exchanging messages with
19
the prover, to obtain leakage from the prover’s execution. We denote a single execution of this process by
A 

P(sk) → sk0

, where sk0 may be the updated key. In the definition below, we formalize security
against such an adversary.
Definition 3 (Security against Leakage and Impersonation Attacks (ID-Leak security)). Let k ∈ N be
the security parameter. An identification scheme ID = (KeyGen,P, V) is λ(k)-ID-Leak secure if for any PPT
λ(k)-limited adversary A it holds that the experiment below outputs 1 with probability at most negl(k):
1. The challenger samples (pk, sk 0
) ← KeyGen(1k
) and gives pk to A.
2. Repeat for i = 0 . . . poly(k) times: A 

P(ski
) → ski+1
, where in each execution the adversary can
interact with the honest prover and retrieves up to λ(k) bits about the current secret state ski
and the
randomness that is used.
3. A impersonates the prover and interacts with V(pk). If V(pk) accepts, then output 1; otherwise output
0.
Notice that the adversary is allowed to obtain λ bits of information for each execution of the identification
protocol. Hence, in total the adversary may learn poly(k) · λ(k) bits of information.
4.1 A Construction of a Leakage-Resilient Identification Protocol
Our construction is based on the standard Okamoto identification scheme [31], which works as follows.
Let g1 and g2 be two generators of G such that α = logg1
(g2) is unknown. The secret key sk is equal to
(x1, x2) ← Z
2
p
and the public key pk is g
x1
1
· g
x2
2
.
1. The prover chooses (w1, w2) ← Z
2
p
, computes a := g
w1
1
g
w2
2
, and sends a to the verifier.
2. The verifier chooses c ← Zp and sends it to the prover.
3. The prover computes z1 := w1 + cx1 and z2 := w2 + cx2 and sends (z1, z2) to the verifier.
4. The verifier accepts if and only if g
z1
1
g
z2
2
?= a · pkc
.
It has been shown that the Okamoto scheme is secure against impersonation attacks under the discrete
logarithms assumption. We now describe how to implement the Okamoto scheme such that it remains
secure even if the computation of the prover is carried out on a leaky device. Verification is as in the
standard Okamoto scheme, while the key generation and the computation of the prover is adjusted to
protect against leakage attacks. More precisely, instead of using (x1, x2) ∈ Z
2
p
as secret key, we store
(L,(R1, R2)) ← Encoden,2
F
(x1, x2) and implement the computation of the prover as a two-party protocol
run between PL(L) and PR(R1, R2). To this end, we will use the fact that the Okamoto identification
protocol only requires to compute a linear function of the encoded secret key. As outlined in the introduction
such functions can be implemented in a “leakage-resilient way”. The protocol is given in Figure 2.
Finally, we will combine our identification protocol with our refreshing protocol from Section 3 to construct
an identification scheme Oka = (KeyGen,P, V, Refreshn,2
Zp
) that is ID-Leak secure, i.e., secure even
against a polynomial number of observations. More precisely, in the ith execution of (P(pk,(L, R)), V(pk))
after Step 5 in Figure 2, we execute (L
i+1, Ri+1) ← Refreshn,2
Zp
(L
i
, Ri
) and set the prover’s secret key for
the next round to ski+1 := (L
i+1, Ri+1). Notice that in such a case, we include into the leakage oracle from
the figure the variables that are used by the refreshing and let the adversary interact in each round with the
following leakage oracle:
Ω

(L
i
, U, Z, A, M, A, ˜ M˜ ) ; (R
i
, W, A, M, A, ˜ M˜ )

.
It is easy to see that the above protocol satisfies the completeness property. This is due to the soundness
of the refreshing protocol, and the fact that messages that are exchanged by the parties P and V in Figure 2
are as in the original Okamoto protocol. To prove leakage-resilience of Oka = (KeyGen,P, V, Refreshn,2
Zp
),
we will proceed in three steps:
20
Key generation KeyGen(1k
):
Sample (p, G) ← G(1k
), generators g1, g2 ← G, S = (x1, x2) ← Z
2
p and (L, R) ← Encoden,2
Zp
(S). We output
sk = (L, R) and pk = (p, g1, g2, h), where h := g
x1
1
g
x2
2
.
The identification protocol (P(pk,(L, R)), V(pk))
Input for prover (L, R): L is given to PL and R is given to PR.
Computation of Prover P(pk,(L, R)): Computation of Verifier V(pk):
1. PR samples (W1, W2) ← Z
2n
p , computes U := g
W1
1  g
W2
2
and sets
W := (WT
1 , WT
2 ). The vector U is sent to PL ( is component-wise
multiplication of vectors).
2. PL computes V = U
L
and a =
Q
i
Vi. The value a is sent to V.
3. Pick c ∈ Zp and send it to P.
4. PR computes the n × 2 matrix Z := W + cR and sends it to PL.
5. PL computes (z1, z2) = L · Z. The values (z1, z2) are given to V.
At any time, the adversary can play a λ-leakage game against:
Ω ((L, U, Z) ; (R, W)). We set Z = 0 for leakage queries that are
asked before c is fixed.
6. Accept iff g
z1
1
g
z2
2 = ahc
.
Fig. 2. The key generation algorithm and the protocol (P(pk,(L, R)), V(pk)) for identification.
(P(pk,(L, R)), V(pk)) is an interactive protocol between a prover P and a verifier V.
1. We first consider a single execution of the protocol (P(pk,(L, R)), V(pk)) from Figure 2 and prove a
simple property in the information theoretic setting. Namely, we show show that the there exists an (unbounded)
simulator S(pk, aux) with access to a leakage oracle Ω(L
∗
, R∗
) that, given “some” auxiliary
information aux, can simulate A(pk)’s view in A  (P(L, R)) → (L
0
, R0
)) (cf. Lemma 5). In this step
the analysis neglects the leakage from the refreshing process.
2. We next consider the setting where unbounded A runs in many iterations of A 

P(L
i
, Ri
)) → (L
i+1, Ri+1)

,
where we also take into account that the refreshing of (L
i
, Ri
) leaks information. We will combine our
results from the last section with the simulator from Lemma 5 to show that any unbounded adversary
will only learn a negligible amount of information about the secret key (cf. Lemma 6).
3. Finally, we will argue why this proves the ID-Leak security of our scheme. To this end, we rely on a
recent result of Dodis et al. [3], which shows security of the original Okamoto scheme for keys sampled
from a high average min-entropy source.
We now follow the three steps given above and start by proving a simple property of a single execution
of the protocol (P(pk, sk), V(pk)) from Figure 2. Informally speaking, we show in the lemma below that
for every unbounded adversary A, there exists an unbounded simulator S that satisfies one of the following
two properties:
1. S perfectly simulates the view of A in A  (P(pk, sk) → (L, R)) with sk ← Encoden,2
Zp
(x1, x2), or
2. S aborts the simulation, and outputs ⊥. We denote the event that S aborts by Q.
Lemma 5. Let (pk,(L, R)) ← KeyGen(1k
) where (x1, x2) = Decoden,2
Zp
(L, R). Then for any (unbounded)
λ-limited adversary A, there exists a (λ + 3 log p)-limited simulator S with access to Ω(L
∗
, R∗
) (here
21
(L
∗
, R∗
) ← Encoden,1
F
(x1)) and an event Q with Pr
Q

≥ 1/p such that for any b ∈ {0, 1}
Pr[Out(S(pk, aux), Ω(L
∗
, R∗
)) = b|Q] = Pr[
A(pk) 

P(pk,(L, R)) → (L
0
, R0
)
 = b]. (30)
Here, we have that aux = (1, α) · R with α = logg1
(g2).
Notice that the simulator S only has leakage access to an encoding of a single value, namely to (L
∗
, R∗
) ←
Encoden,1
F
(x1), while he has to simulate the leakage of the refreshing of (L, R) ← Encoden,2
F
(x1, x2).
Notice, however, that S additionally knows aux = (1, α) · R. From aux and R∗
the simulator can easily
compute a consistent encoding of x2, as we will see in the proof below.
Proof. For an unbounded adversary A, the information that is learnt by her contains (1) the messages that
she receives from P, i.e., the data that she learns via black-box access to the prover, and (2) the leakage from
the execution of (P(pk,(L, R)), V(pk)). More formally, we can describe this information by:
1. Messages sent by P to the adversary:
N
z }| {

1 α 0 0
0 0 1 α
c 0 1 0
0 c 0 1

 ·


x1
x2
w1
w2

 =


logg1
(pk)
logg1
(a)
z1
z2


Recall that A is unbounded, hence she can compute discrete logarithms in G.
2. Access to the leakage oracle via Ω ((L, U, Z) ; (R, W)). Again, as A is unbounded, she can compute the
discrete logarithm of U to the basis g1 which is the vector W1 + αW2. Hence, information theoretically
it suffices to consider Ω ((L, W1 + αW2, Z) ; (R, W)).
We need to show that S(pk, aux) can do a perfect simulation of this view with just access to the leakage
oracle.
1. Simulation of the leakage oracle as specified in 2: To this end, we need to simulate the variables from
the leakage oracle:
Ω ((L, W1 + αW2, Z) ; (R, W)), (31)
which is done with access to Ω(L
∗
, R∗
) as follows:
– The encoding of the secret (L, R): S can simulate these variables by setting L := L
∗
and the first
column of R to R1 := R∗
. The second column is computed by R2 := (aux − R∗
)/α.
– The vectors W1 + αW2 and the matrix Z: As W1 and W2 are sampled uniformly at random, S can
draw Z ← Z
2n
p uniformly at random. As the vector aux and the column vector of Z span a vector
space of dimension 3 and W1 + αW2 lies in this vector space, we can compute a consistent vector
W1 + αW2 as a linear combination of aux and Z.
– The matrix W: Consider the following equation system:
N ·

RT
WT

=


aux = R1 + αR2
W1 + αW2
Z1
Z2

 . (32)
Here, the right side of the system is fixed and known to the simulator. Further, R is fixed as above,
i.e., by the target oracle and aux. Hence, in this equation system it remains to compute the matrix W.
22
Since by our choice of W1 + αW2 and Z the equation system is consistent and the last three rows of
N are linearly independent, there exists a unique solution for (W1, W2) (recall that R is fixed which
reduces the space of solutions to dimension 1). Since Z was sampled uniformly at random, it is easy
to verify that also (W1, W2) is uniformly distributed conditioned on satisfying the above equation
system. Hence, the distribution of the simulated W is as in the real experiment.
2. Simulation of the messages sent by the prover as specified in 1: As from the previous step the simulator
knows (W1 + αW2, Z), he can query its leakage oracle to obtain logg1
(a), z1 and z2. Notice that this
requires S to learn 3 log p additional bits from its leakage oracle.
Finally, observe that since A may access its leakage oracle at any time (in particular before choosing c),
but for the simulation from above we need to know the matrix N – in particular the value c, we let S
simply guess c at the beginning of the simulation. If the guess was correct, then we perfectly simulated
A(pk)  (P(pk,(L, R)) → (L
0
, R0
)); otherwise the event Q occurs. As this happens with probability at
least 1/p, we get the claim of the lemma. ut
LEAKAGE FROM `-EXECUTIONS. In the lemma above, we showed that the leakage from a single execution
of the protocol can be perfectly simulated. We will now use this observation and prove that the leakage
from several rounds will also not help in learning much about the encoded secret (cf. Step 2 in the above
outline). This will require to refresh the encoded secret key periodically, as otherwise an adversary that
continuously learns information from the device can trivially break the security. To this end, we consider
Oka = (KeyGen,P, V, Refreshn,2
Zp
) and assume that after each execution of the protocol from Figure 2, the
prover executes (L
0
, R0
) ← Refreshn,2
Zp
(L, R) and sets the new secret key (for the next execution) to (L
0
, R0
).
We denote such a prover by P
0
and denote the ith execution of the identification protocol (with refreshing)
by (P
0
(pk,(L
i−1
, Ri−1
)), V(pk)).
Lemma 6. Let (pk, sk) ← KeyGen(1k
), ` ∈ N, α = logg1
(g2) and W the column vector (1, α). Suppose
n, λ and  are such that Φ
n,1
Zp
is (λ, )-secure. Then, for every S = (x1, x2) and S
0 = (x
0
2
, x0
2
) that correspond
to the same public key pk (cf. “key generation” on Fig. 2), and any (λ/2 − 1 − 3 log p)-limited adversary A
we have that
∆

Expaux
P0(pk)
(A, S, `, W, pk); Expaux
P0(pk)
(A, S0
, `, W, pk)

≤ 2`p7
(3 + 2p
−n−5
).
Proof. Notice that (W, pk) defines a 1-dimensional subspace Z ⊂ (Zp)
2
that contains all the pairs (x1, x2)
that correspond to the public key pk. For any S, S0 ∈ Z and any (λ/2 − 1)-limited adversary A we have by
Theorem 2 for the refreshing of Φ
n,2
Zp
that
∆

Expaux
Refresh(A, S, `, W, pk); Expaux
Refresh(A, S0
, `, W, pk)

≤ 2`p2
(3p
4
 + 2p
−n−1
) = 2`p6
(3 + 2p
−n−5
).
(33)
The above experiment considers only the leakage from the refreshing of (L
i
, Ri
). To combine this with
leakage from the identification protocol, i.e., leakage from the prover P(pk) we use the simulation from
Lemma 5. We can apply this lemma since (1) Eq. (33) is shown by reduction to the (λ, )-security of Φ
n,1
Zp
and (2) auxi = Ri
· W is know to the simulator5
. As the simulation from Lemma 5 is perfect, but fails with
probability 1 − 1/p, the error from Eq. (33) increases by at most a factor of p. Furthermore, notice that the
simulation additionally needs to learn 3 log p bits from its target oracle (for Φ
n,1
Zp
), which gives us the claimed
statement. ut
The following corollary can be obtained from Lemma 6 in a similar way as Corollary 1 from Theorem 1
5 Notice that this was the whole purpose of the extension presented in Theorem 2.
23
Corollary 3. Let n ∈ N be the statistical security parameter. Furthermore, let (pk, sk) ← KeyGen(1k
),
` = poly(n), α = logg1
(g2) and W be the column vector (1, α). For every S = (x1, x2) and S
0 = (x
0
2
, x0
2
)
that correspond to the same public key pk (cf. “key generation” on Fig. 2), and any ((0.15·n−3) log p−1)-
limited adversary A we have that
∆

Expaux
P0(pk)
(A, S, `, W, pk); Expaux
P0(pk)
(A, S0
, `, W, pk)

≤ negl(n).
We can now show that our scheme Oka satisfies the security notion of Definition 3.
Theorem 3. Oka = (KeyGen,P, V, Refreshn,2
Zp
) is ((0.15 · n − 3) log p − 1)-ID-Leak secure, if the DL
assumption holds.
Proof. It has been proven in Theorem 4.1 in [3] that the Okamoto scheme is secure against impersonation
attacks under the DL assumption, even if the secret keys are sampled from some source with high average min
entropy. From Corollary 3, we know that for any two uniformly sampled keys S := (x1, x2), S0
:= (x
0
1
, x0
2
)
that correspond to the same public key pk and any ((0.15 · n − 3) log p − 1)-limited adversary A
∆

Expaux
P0(pk)
(A, S, `, W, pk); Expaux
P0(pk)
(A, S0
, `, W, pk)

≤ negl(n).
Hence, information theoretically an adversary does not learn much about the secret key S or S
0
, respectively,
by running in the experiment Expaux
P0(pk)
. More formally, by Lemma 9 in the appendix, this implies that the
secret key has high average min-entropy even given the leakage and the public messages from the execution
of the identification protocol (i.e., pk and a, z1, z2). This gives us with Theorem 4.1 in [3] that our scheme is
((0.15 · n − 3) log p − 1) ID − Leak-secure under the DL assumption. ut
LEAKAGE RESILIENT SIGNATURES It is well known fact that the Okamoto identification protocol can be
turned into a signature scheme using the Fiat-Shamir heuristic. Similarly, we can turn the scheme from
Figure 2 into a leakage resilient signature scheme which can be proven secure against continuous leakage
attacks in the random oracle model under the DL assumption.
5 Leakage Resilient Encryption
In this section, we construct an efficient encryption schemes that is secure against continuous leakage attacks.
Our construction is based on a variant of the ElGamal cryptosystem and is proven secure against adaptive
chosen message and leakage attacks (CCLA2) in the Random Oracle model.
5.1 Definitions
For security parameter k a public-key encryption scheme PKE = (KeyGen, Encr, Decr) consists of three
PPT algorithms.
– (pk, sk) ← KeyGen(1k
): It outputs a valid public/secret key pair.
– c ← Encr(pk, m): That is, a probabilistic algorithm that on input some message m and the public key
pk outputs a ciphertext c = Encr(pk, m).
– m = Decr(sk, c): The decryption algorithm takes as input the secret key sk and a ciphertext c such that
for any plaintext m we have m = Decr(sk, Encr(pk, m)).
The standard security notion for an encryption scheme is security against chosen plaintext attacks (INDCPA).
In a CPA attack against a public-key encryption scheme the adversary obtains pk, then picks two
messages m0, m1 and has to guess the bit b on input c
∗ = Encr(pk, mb). We can strengthen this notion by
24
additionally allowing the adversary to ask for the decryption of chosen ciphertexts. A scheme that remains
secure even if the adversary can ask for decryptions of chosen ciphertexts prior to seeing c
∗
is said to be
secure against non-adaptive chosen ciphertext attacks (IND-CCA1 secure). If the adversary can additionally
make decryption queries after seeing c
∗
, then the scheme is said to be secure against adaptive chosen
ciphertext attacks (IND-CCA2 secure).
In the setting where computation leaks information, security against chosen plaintext and leakage attacks
is not very interesting, as the adversary is not allowed to ask for decryption queries. On the other hand, the
notion of CCA1/2-security can naturally be extended to the continuous leakage setting. Here, we allow the
adversary to query the decryption oracle on some chosen ciphertext c, and additionally allow him to obtain a
bounded amount of leakage from the decryption process. This may be repeated many times, hence, eventually
the adversary may learn a large amount of information. Formally, we define security against adaptive chosen
ciphertext and leakage attacks (IND-CCLA2 security) as follows.
Definition 4 (Security against Chosen Ciphertext Leakage Attacks (CCLA2)). Let k ∈ N be the security
parameter. A public-key encryption scheme PKE = (KeyGen, Encr, Decr) is λ(k)-IND-CCLA2 secure if for
any PPT λ(k)-limited adversary A the probability that the experiment below outputs 1 is at most 1/2 +
negl(k).
1. The challenger samples b ∈ {0, 1} and (pk, sk) ← KeyGen(1k
). It gives pk to A.
2. Repeat until A(1k
) outputs (m0, m1): A 

Decr(sk, c) → sk0

, where for each decryption query c the
adversary additionally retrieves up to λ(k) bits about the current secret state sk. Set the key for the next
round to sk := sk0
.
3. The challenger computes c
∗ ← Encr(pk, mb) and gives it to A.
4. Repeat until A(1k
) outputs b
0
: A 

Decr(sk, c) → sk0

, where for each decryption query c 6= c
∗
the
adversary additionally retrieves up to λ(k) bits about the current secret state sk. Set the key for the next
round to sk := sk0
.
5. If b = b
0
then output 1; otherwise output 0.
The weaker notion of CCLA1-security can be obtained by omitting Step 4 in the experiment above. Notice
that the adversary is allowed to obtain λ bits of information for each decryption query. Hence, in total the
adversary may learn poly(k) · λ(k) bits of information.
5.2 An Efficient IND-CCLA2-secure Encryption Scheme in the Random Oracle Model
An important tool of our encryption scheme is a simulation-sound (SS) NIZK. Informally, a NIZK proof
system is said to be simulation sound, if any adversary has negligible advantage in breaking soundness
(i.e., forging an accepting proof for an invalid statement), even after seeing a bounded number of proofs
for (in)valid statements. We refer the reader to [4,36] for the formal definition of NIZKs and simulation
soundness. SS-NIZKs can be instantiated in the common random string model using the Groth-Sahai proof
system [23] and the techniques of [22]. Unfortunately, as pointed out by Dodis et al. [11], this results into an
impractical scheme. In contrast, in the random oracle model using the Fiat-Shamir heuristic [19] simulation
soundness can be achieved efficiently. In particular, it has been proven in [1] that the standard ChaumPedersen
protocol [7] for proving equivalence of discrete logarithms can be turned into a SS-NIZK using
the Fiat-Shamir heuristic. Let in the following (Prov, Ver) denote such a non-interactive proof system for
proving the equivalence of discrete logarithms.
Our scheme can be viewed as a leakage-resilient implementation of the following simple variant of the
ElGamal encryption scheme using the above simulation sound NIZK obtained via the Fiat-Shamir heuristic.
Let g1, g2 be two generators of a prime order p group G. Let sk = (x1, x2) ∈ Z
2
p be the secret key and pk =
(g1, g2, h = g
x1
1
· g
x2
2
) the public key. To encrypt a message m ∈ G, pick uniformly r ← Zp and compute
25
c = (u := g
r
1
, v := g
r
2
, w := h
rm, π), where π := Prov(u, v, r) is a NIZK proof of logg1
(u) = logg2
(v). To
decrypt c = (u, v, w, π), verify the NIZK, and if it accepts, output w · (u
−x1
· v
−x2 ).
It can easily be shown that this scheme achieves standard CCA2 security in the RO model. In this section,
we will show how to implement this scheme such that it remains secure even if the decryption continuously
leaks information. Similar to our transformation of the Okamoto scheme, we store the secret key (x1, x2)
as (L, R) ← Encoden,2
F
(x1, x2) and implement the computation of the decryption process as a two-party
protocol run between PL(L) and PR(R). The protocol for key generation and decryption is given in Figure
3 and uses similar ideas as in our implementation of the Okamoto scheme. Finally, we will combine
the protocol from Figure 3 with our refreshing protocol from Section 3 to construct an encryption scheme
PKE = (KeyGen, Encr, Decr, Refreshn,2
Zp
) that is CCLA2 secure, i.e., secure even against a polynomial number
of observations of the decryption process.
Key generation KeyGen(1k
):
Let (p, G) ← G(1k
), g1, g2 ← G, S = (x1, x2) ← Z
2
p and (L, R) ← Encoden,2
Zp
(S). Let sk = (L, R) and pk =
(p, g1, g2, h := g
x1
1
g
x2
2
).
Encryption Encr(pk, m) :
Sample r ← Zp uniformly at random and compute c = (u := g
r
1, v := g
r
2, w := h
rm). Run the NIZK prover Prov(u, v, r)
to obtain a proof π for logg1
(u) = logg2
(v). Return (c, π).
The protocol for decryption Decr(sk, c) :
Input for decryption sk := (L, R): L is given to PL and R is given to PR.
Both parties obtain c and parse it as (u, v, w, π). PL runs the NIZK verifier Ver(u, v, π) to check that π is an accepting proof.
If the verification fails, then output ⊥ and stop; otherwise proceed as follows:
1. PR computes the vector U := u
R1  v
R2
. U is sent to PL ( denotes component-wise multiplication of vectors).
2. PL computes V = U
−L
and outputs w
Q
i
Vi.
Notice that we can omit the leakage from the verification of the NIZK as it only includes publicly known values. At
any time, the adversary can play a λ-leakage game against: Ω ((L, U) ; R).
Fig. 3. The key generation KeyGen and the decryption process Decr of our public-key encryption scheme
PKE.
SECURITY ANALYSIS OF PKE = (KeyGen, Encr, Decr, Refreshn,2
Zp
). The formal security proof proceeds
similar as the proof of security in the last section. We first show in Lemma 7 that the leakage from a single
decryption query can be simulated in a perfect way with just access to a retrieving oracle Ω(L
∗
, R∗
). For
this simulation to go through, we require that an adversary can only observe leakage from operations that
involve the secret key, if the decryption oracle is queried on a valid ciphertexts. We call a ciphertext valid,
if logg1
(u) = logg2
(v) holds. Notice that this is also the reason why we need NIZKs and cannot use the
standard techniques to get CCA1/2 security based on hash proof systems. In the next step, we show that
even when the adversary can continuously obtain leakage from the decryption, he will not be able to learn
information about the encoded secret key. To this end, we will combine the scheme from Figure 3 with our
refreshing protocol Refreshn,2
Zp
to refresh the encoded secret key (L, R). Finally, we show in Theorem 4 that
such a construction is IND-CCLA2 secure.
Lemma 7. Let (pk,(L, R)) ← KeyGen(1k
) with (x1, x2) = Decoden,2
Zp
(L, R). Then for any (unbounded)
λ-limited adversary A, there exists a λ-limited simulator S with access to Ω(L
∗
, R∗
) (here (L
∗
, R∗
) ←
26
Encoden,1
Zp
(x1)) such that for any b ∈ {0, 1}
Pr[Out(S(pk, aux), Ω(L
∗
, R∗
)) = b] = Pr[
A(pk) 

Decr((L, R), c) → (L
0
, R0
)
 = b], (34)
where aux = (1, α) · R with α = logg1
(g2). Furthermore, we assume that c = (u, v, w, π) is a valid
ciphertext (i.e., logg1
(u) = logg2
(v)).
Proof. The proof is very similar to the proof of Lemma 5. For the simulation to go through, it will be
crucial that the adversary can only ask for decryptions of valid ciphertexts, i.e., in the following we consider
logg1
(u) = logg2
(v) = r. For an unbounded adversary A, the information that is learnt from decryptions of
ciphertexts c = (u, v, w, π) can be described as follows:
1. The decrypted plaintext m that corresponds to the ciphertext c.
2. Leakage from the decryption: This involves the leakage from the verification of the NIZK π and the
decryption of (u, v, w). As the verification of the NIZK only uses publicly known values, the simulation
is trivial and will be omitted in the following. Hence, we can describe the leakage from the decryption
by access to the following leakage oracle
Ω ((L, r(R1 + αR2)) ; R).
We need to show that S(pk, aux) can do a perfect simulation of the above described view with just access to
its leakage oracle Ω(L
∗
, R∗
). In fact, given the auxiliary information aux this simulation is trivial:
1. Simulation of the leakage oracle as specified in Step 2: We consider first how to simulate the leakage
oracle. In the simulation, S identifies R1 with R∗
and can compute R2 from R∗
and aux. As S is
unbounded, given the ciphertext c, he can compute r = logg1
(u). Together with aux the simulator can
compute r(R1 + αR2), which suffices to simulate the leakage queries.
2. Simulation of the plaintext m = Decr(sk, c): Again, as S knows r it can decrypt valid ciphertexts by
w · h
−r
.
It is easy to see that for valid ciphertexts we get a perfect simulation. Further, since S does not need to learn
extra information from its leakage oracle, we get the claimed result. ut
In the lemma above, we showed that the leakage from a single execution of the decryption process can be
perfectly simulated. We will now use this observation and prove that the leakage from several rounds will
also not help in learning much about the encoded secret. This will require to refresh the encoded secret key
periodically, as otherwise an adversary that continuously learns information from the device can trivially
break the security. To this end, we consider PKE = (KeyGen, Encr, Decr, Refreshn,2
Zp
) that executes after
each run of the decryption process from Figure 3, the refreshing protocol (L
0
, R0
) ← Refreshn,2
Zp
(L, R). The
new secret key (i.e., for the next execution) is set to (L
0
, R0
). We denote such a decryption process by Decr0
.
We can now prove the following:
Lemma 8. Let (pk, sk) ← KeyGen(1k
), ` ∈ N, α = logg1
(g2) and W the column vector (1, α). Suppose
n, λ and  are such that Φ
n,1
Zp
is (λ, )-secure and that in the experiments below the decryption process
Decr0
(·) is only run on valid ciphertext. Then, for every S = (x1, x2) and S
0 = (x
0
2
, x0
2
) that corresponds
to the same public key pk (cf. “key generation” on Fig. 3), and any (λ/2 − 1)-limited adversary A we have
that
∆

Expaux
Decr0
(·)
(A, S, `, W, pk); Expaux
Decr0
(·)
(A, S0
, `, W, pk)

≤ 2`p6
(3 + 2p
−n−5
).
Proof (sketch). The proof is along the lines of Lemma 6. The only difference is that there is no need for the
simulator to abort (recall that in the proof of the security of the Okamoto scheme the simulator needed to
guess the value of c, that was later chosen by the simulated A, and abort if he did not guess it correctly).
Hence, we save a factor of p.
27
Similar to the last section, we can now obtain the following corollary that plugs-in concrete numbers.
Corollary 4. Let n ∈ N be the statistical security parameter and suppose that in the experiments below
the decryption process Decr0
(·) is only run on valid ciphertext. Furthermore, let (pk, sk) ← KeyGen(1k
),
` = poly(n), α = logg1
(g2) and W be the column vector (1, α). For every S = (x1, x2) and S
0 = (x
0
2
, x0
2
)
that correspond to the same public key pk (cf. “key generation” on Fig. 3), and any (0.15·n log p−1)-limited
adversary A we have that
∆

Expaux
Decr0
(·)
(A, S, `, W, pk); Expaux
Decr0
(·)
(A, S0
, `, W, pk)

≤ negl(n).
The above corollary says that an adversary that continuously observes the computation from the decryption
process will not be able to learn any useful information about the encoded secret key. In the next
theorem, we will show that such a property suffices to prove the IND-CCLA2 security of our scheme.
Theorem 4. PKE is (0.15 · n log p − 1)-IND-CCLA2 secure in the random oracle model, if the DDH assumption
holds.
Proof. We prove this by a series of games. The games are all variants of the security experiment given in
Definition 4. We will show that in the last game any adversary can guess the target bit b with probability
at most 1/2. As we will also show that the distances between the games are negl(k) this will prove the
statement of the theorem.
Game 0: This is as the original experiment as given in Definition 4. That is, a bit b ← {0, 1} is sampled
and the initial key (pk, sk) ← KeyGen(1k
) is generated and used to answer the decryption and leakage
queries from Decr0
(sk, c) (recall again that Decr0
denotes the decryption process from Figure 3 followed
by the key-refreshing with Refreshn,2
Zp
). The target ciphertext c
∗
is generated by computing honestly
c
∗ = (u
∗
, v∗
, w∗
) ← Encr(pk, mb) and running the NIZK prover Prov(u
∗
, v∗
, r∗
) to obtain a proof π
∗
for logg1
(u
∗
) = logg2
(v
∗
).
Game 1: This is as Game 1, but we generate the target ciphertext using the secret key. More precisely, we
compute c
∗ = (u
∗
, v∗
, w∗
, π∗
) as follows: pick randomly r ← Zp and compute u
∗ = g
r
1
, v
∗ = g
r
2
and
w
∗ = (u
∗
)
x1
· (v
∗
)
x2
. Furthermore, compute π
∗
as above. Trivially, the distance between Game 0 and
Game 1 is 0.
Game 2: This is as Game 1 (i.e., we simulate the answers to decryption and leakage queries honestly), but
instead of running the NIZK prover that requires as input (u
∗
, v∗
, r∗
) (where r
∗
is the common discrete
logarithm of u
∗
and v
∗
) to obtain the proof π
∗
, we run the NIZK simulator that only uses (u
∗
, v∗
). By the
zero-knowledge property of the NIZK the distance between the generated views in Game 1 and Game 2
is negligible.
Game 3: This is as Game 2, but we sample (u
∗
, v∗
) randomly such that logg1
(u
∗
) 6= logg2
(v
∗
). More
precisely, as in Game 2, we sample the initial key (pk, sk) ← KeyGen(1k
). This allows us to answer the
decryption queries and the corresponding leakage queries of the adversary. If A asks for a ciphertext of
the messages (m0, m1), we reply with c
∗ = (u
∗
, v∗
,(u
∗
)
x1
· (v
∗
)
x2 mb, π∗
). By the DDH assumption
the distance between the views generated in Game 2 and Game 3 is negligible.
Game 4: This is as Game 3, but we reject to answer decryption queries for ciphertexts (u, v, w, π) with
logg1
(u) 6= logg2
(v). The views that are generated in Game 3 and Game 4 are close by the simulation
soundness of the NIZK. Recall that simulation soundness guarantees that the adversary cannot generate
accepting proofs of wrong statements, even if he has obtained accepting proofs of wrong statements
earlier (this is the case as the target ciphertext c
∗
that the adversary sees in Step 3 below includes a proof
of a wrong statement). To sum it up, Game 4 proceeds as follows:
1. Sample b ← {0, 1} and a random (x1, x2) and compute sk ← Encoden,2
F
(x1, x2). Compute pk from
(x1, x2).
28
2. Answer valid decryption and leakage queries with sk until the adversary asks for (m0, m1).
3. Generate the target ciphertext c
∗ = (u
∗
, v∗
, w∗
, π∗
) by sampling (u
∗
, v∗
) such that logg1
(u
∗
) 6=
logg2
(v
∗
), and computing w
∗ = (u
∗
)
x1
· (v
∗
)
x2
· mb. Give (u
∗
, v∗
, w∗
, π∗
) to the adversary.
4. Answer valid decryption and leakage queries with sk.
Game 5: This is as Game 4 with the following changes:
1. Sample a random (x1, x2) and compute pk from (x1, x2). Sample (x
0
1
, x0
2
) ← {(y, z)|g
y
1
· g
z
2 =
g
x1
1
g
x2
2
} uniformly at random and set sk0 ← Encoden,2
F
(x
0
1
, x0
2
).
2. Answer the decryption and leakage queries with sk0
until the adversary asks for (m0, m1).
3. Generate the target ciphertext c
∗
as in Game 3 by using (x1, x2).
4. Answer the decryption and leakage queries with sk0
.
The distance between Game 4 and 5 is negligible by Lemma 8 (or the corresponding Corollary 4). More
precisely, we have the following claim:
Claim. The distance between Game 4 and Game 5 is negligible in n.
Proof. We show this by reduction to Lemma 8 or the corresponding Corollary 4. Suppose we have
given a distinguisher D for Game 4 and 5, and we will use it to construct an adversary A that breaks
Corollary 4. A needs to simulate the view of the distinguisher D either in Game 4 or Game 5. To this end,
it samples (x1, x2) at random, and samples (x
0
1
, x0
2
) ← {(y, z)|g
y
1
· g
z
2 = g
x1
1
g
x2
2
} uniformly at random.
Furthermore, it samples the corresponding public key pk. To answer the decryption and leakage queries,
A asks its challenge oracle that either replies with the decryption and the corresponding leakage either by
using Decr0
(Encoden,2
Zp
(x1, x2), ·) or by using Decr0
(Encoden,2
Zp
(x
0
1
, x0
2
), ·). Notice that here it is crucial
that in Game 4 and 5 the adversary only asks for decryptions of valid cihpertexts, as the challenge oracle
only replies to such queries. Next, A generates the target ciphertext c
∗
as described in Game 4 (which is
identical to Game 5) and then it continues to answer decryption and leakage queries using its challenge
oracle. It is easy to see that depending on whether A’s target oracle uses Decr0
(Encoden,2
Zp
(x1, x2), ·) or
Decr0
(Encoden,2
Zp
(x
0
1
, x0
2
), ·) the view of D is either as in Game 4 or Game 5. ut
It remains to show that in Game 5 the adversary’s view is independent of the bit b. Hence, the guessing
probability in Game 5 is at most 1/2.
Claim. The adversary’s view in Game 5 is independent of the target bit b.
Proof. Consider the target ciphertext c
∗
:= (u
∗
, v∗
, w∗
, π∗
), where w
∗ = z
∗
· mb with z
∗ = g
r1x1
1
· g
r2x2
2
and r1 6= r2. We will show that z
∗
acts as an information theoretically one-time pad. An (unbounded)
adversary in Game 5 can compute from the public key pk the value logg1
(h) = x1 + α · x2. By the fact
that in Game 5 the adversary only asks for valid cihpertexts (i.e., for a decryption query c = (u, v, w, π)
we have logg1
(u) = logg2
(v)) he does not learn more than this. Furthermore, since we used in Game 5
sk0 ← Encoden,2
Zp
(x
0
1
, x0
2
) to answer the leakage queries and (x
0
1
, x0
2
) is chosen independent of (x1, x2), the
adversary in Game 5 learns indeed no more than x1 + α · x2. To sum it up, together with the information
from the target ciphertext, the adversary learns:

logg1
(h)
logg1
(z
∗
)

=

1 α
r1 r2α

·

x1
x2

.
Since α 6= 0 and r1 6= r2 the 2 × 2 matrix is non-singular, and hence logg1
(h) and logg1
(z
∗
) are linearly
independent. ut
As the distance between all games is negligible, we get the claimed result. ut
29
6 A General Paradigm for Leakage-Resilient Cryptographic Schemes
In the last sections, we proposed leakage-resilient implementations of standard cryptographic schemes.
Namely, we showed how to implement the standard Okamoto identification scheme and a variant of the
ElGamal encryption scheme such that they satisfy strong security guarantees even under continuous leakage
attacks. The security proof of both schemes relied on very similar observations, namely:
1. The underlying cryptographic scheme (e.g., the Okamoto scheme or the ElGamal variant) computes
only a linear function of the secret key. Notice that in the examples of the last section the linear function
was essentially computed in the exponent of a group generator g. This is not a problem as long as the
computation can be carried out efficiently. This was indeed the case for the schemes of the last sections.
2. The secret key is hidden information theoretically even given the protocol transcript that an adversary
obtains when interacting with the underlying cryptographic scheme. In the protocols from the last section,
this meant, for instance, that the secret key (x1, x2) was information theoretically hidden even given the
corresponding public key. Furthermore, for the Okamoto scheme this holds even given (a, z1, z2), which
were sent by the prover to the verifier during the execution of the identification protocol.
Various other cryptographic schemes satisfy the above properties, and hence can be made secure against
continuous leakage attacks. For instance, the Pedersen commitment scheme [32], which is informationtheoretically
hiding and at the same time only requires to compute a linear function of its secrets.6 Another
example of the above paradigm is a variant of the linear Cramer-Shoup cryptosystem as presented in [37].
Notice that as in the encryption scheme from Section 5, this requires to use as a check for the validity
of the ciphertexts a NIZK proof system. One can instantiate such a NIZK in the standard model using the
Groth-Sahai proof system [23]. This gives us an efficient CCLA1-secure public-key encryption scheme in the
standard model, and a rather inefficient CCLA2-secure scheme using the extensions of [22]. We suggest that
many other standard cryptographic schemes can be proven secure following the ideas that were presented in
this paper.
Acknowledgments. The authors are grateful to Francesco Davi, Yevgeniy Dodis, Krzysztof Pietrzak, Leonid
Reyzin and Daniele Venturi for helpful discussions on the problem of leakage-resilient refreshing.
References
1. Michel Abdalla, Xavier Boyen, Céline Chevalier, and David Pointcheval. Distributed public-key cryptography from weak
secrets. In Public Key Cryptography, pages 139–159, 2009.
2. Adi Akavia, Shafi Goldwasser, and Vinod Vaikuntanathan. Simultaneous hardcore bits and cryptography against memory
attacks. In Omer Reingold, editor, Theory of Cryptography, 6th Theory of Cryptography Conference, TCC 2009, San Francisco,
CA, USA, March 15-17, 2009. Proceedings, volume 5444 of Lecture Notes in Computer Science, pages 474–495. Springer,
2009.
3. Joël Alwen, Yevgeniy Dodis, and Daniel Wichs. Leakage-resilient public-key cryptography in the bounded-retrieval model. In
CRYPTO, pages 36–54, 2009.
4. Manuel Blum, Paul Feldman, and Silvio Micali. Non-interactive zero-knowledge and its applications (extended abstract). In
STOC, pages 103–112, 1988.
5. Elette Boyle, Gil Segev, and Daniel Wichs. Fully leakage-resilient signatures. In EUROCRYPT, pages 89–108, 2011.
6. Zvika Brakerski, Yael Tauman Kalai, Jonathan Katz, and Vinod Vaikuntanathan. Overcoming the hole in the bucket: Public-key
cryptography resilient to continual memory leakage. In FOCS, pages 501–510, 2010.
7. David Chaum and Torben P. Pedersen. Wallet databases with observers. In CRYPTO, pages 89–105, 1992.
8. Benny Chor and Oded Goldreich. Unbiased bits from sources of weak randomness and probabilistic communication complexity.
SIAM J. Comput., 17(2):230–261, 1988.
9. Francesco Davì, Stefan Dziembowski, and Daniele Venturi. Leakage-resilient storage. In SCN, volume 6280 of Lecture Notes
in Computer Science, pages 121–137. Springer, 2010.
6 Notice that we computed a Pedersen commitment as part of the prover’s protocol in our implementation of the Okamoto scheme.
30
10. Yevgeniy Dodis, Kristiyan Haralambiev, Adriana López-Alt, and Daniel Wichs. Cryptography against continuous memory
attacks. In FOCS, pages 511–520, 2010.
11. Yevgeniy Dodis, Kristiyan Haralambiev, Adriana López-Alt, and Daniel Wichs. Efficient public-key cryptography in the presence
of key leakage. In ASIACRYPT, pages 613–631, 2010.
12. Yevgeniy Dodis, Allison Lewko, Brent Waters, and Daniel Wichs. How to store a secret on continually leaky devices.
manuscript, 2011.
13. Yevgeniy Dodis, Rafail Ostrovsky, Leonid Reyzin, and Adam Smith. Fuzzy extractors: How to generate strong keys from
biometrics and other noisy data. SIAM Journal on Computing, 38(1):97–139, 2008.
14. Stefan Dziembowski and Ueli Maurer. Optimal randomizer efficiency in the bounded-storage model. Journal of Cryptology,
17(1):5–26, January 2004. Conference version appeared in Proc. of STOC 2002.
15. Stefan Dziembowski and Krzysztof Pietrzak. Intrusion-resilient secret sharing. In FOCS, pages 227–237, 2007.
16. Stefan Dziembowski and Krzysztof Pietrzak. Leakage-resilient cryptography. In FOCS ’08: Proceedings of the 49th Annual
IEEE Symposium on Foundations of Computer Science, Washington, DC, USA, 2008. IEEE Computer Society.
17. Sebastian Faust, Eike Kiltz, Krzysztof Pietrzak, and Guy N. Rothblum. Leakage-resilient signatures. In Daniele Micciancio,
editor, Theory of Cryptography, 7th Theory of Cryptography Conference, TCC 2010, Zurich, Switzerland, February 9-11, 2010.
Proceedings, volume 5978 of Lecture Notes in Computer Science, pages 343–360. Springer, 2010.
18. Sebastian Faust, Tal Rabin, Leonid Reyzin, Eran Tromer, and Vinod Vaikuntanathan. Protecting circuits from leakage: the
computationally-bounded and noisy cases. In EUROCRYPT, pages 135–156, 2010.
19. Amos Fiat and Adi Shamir. How to prove yourself: Practical solutions to identification and signature problems. In CRYPTO,
pages 186–194, 1986.
20. Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum. One-time programs. In David Wagner, editor, Advances in
Cryptology - CRYPTO 2008, 28th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 17-21, 2008.
Proceedings, volume 5157 of Lecture Notes in Computer Science, pages 39–56. Springer, 2008.
21. Shafi Goldwasser and Guy N. Rothblum. Securing computation against continuous leakage. In CRYPTO, pages 59–79, 2010.
22. Jens Groth. Simulation-sound nizk proofs for a practical language and constant size group signatures. In ASIACRYPT, pages
444–459, 2006.
23. Jens Groth and Amit Sahai. Efficient non-interactive proof systems for bilinear groups. In EUROCRYPT, pages 415–432, 2008.
24. Yuval Ishai, Amit Sahai, and David Wagner. Private Circuits: Securing Hardware against Probing Attacks. In CRYPTO, pages
463–481, 2003.
25. Ali Juma and Yevgeniy Vahlis. Protecting cryptographic keys against continual leakage. In CRYPTO, pages 41–58, 2010.
26. Eike Kiltz and Krzysztof Pietrzak. Leakage resilient elgamal encryption. In ASIACRYPT, pages 595–612, 2010.
27. Paul C. Kocher, Joshua Jaffe, and Benjamin Jun. Differential power analysis. In CRYPTO, pages 388–397, 1999.
28. Allison Lewko, Mark Lewko, and Brent Waters. Achieving leakage resilience through dual system encryption. to appear at
TCC 2011, 2011.
29. Allison Lewko, Mark Lewko, and Brent Waters. How to leak on key updates. to appear at STOC 2011, 2011.
30. Silvio Micali and Leonid Reyzin. Physically observable cryptography (extended abstract). In Moni Naor, editor, TCC, volume
2951 of Lecture Notes in Computer Science, pages 278–296. Springer, 2004.
31. Tatsuaki Okamoto. Provably secure and practical identification schemes and corresponding signature schemes. In CRYPTO,
pages 31–53, 1992.
32. Torben P. Pedersen. Non-interactive and information-theoretic secure verifiable secret sharing. In CRYPTO, pages 129–140,
1991.
33. Krzysztof Pietrzak. A leakage-resilient mode of operation. In Antoine Joux, editor, Advances in Cryptology - EUROCRYPT
2009, 28th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Cologne, Germany,
April 26-30, 2009. Proceedings, volume 5479 of Lecture Notes in Computer Science, pages 462–482. Springer, 2009.
34. Jean-Jacques Quisquater and David Samyde. Electromagnetic analysis (ema): Measures and counter-measures for smart cards.
In E-smart, pages 200–210, 2001.
35. Anup Rao. An exposition of bourgain’s 2-source extractor. Electronic Colloquium on Computational Complexity (ECCC),
14(034), 2007.
36. Amit Sahai. Non-malleable non-interactive zero knowledge and adaptive chosen-ciphertext security. In FOCS, pages 543–553,
1999.
37. Hovav Shacham. A cramer-shoup encryption scheme from the linear assumption and from progressively weaker linear variants.
Cryptology ePrint Archive, Report 2007/074, 2007. http://eprint.iacr.org/.
38. François-Xavier Standaert, Olivier Pereira, Yu Yu, Jean-Jacques Quisquater, Moti Yung, and Elisabeth Oswald. Leakage resilient
cryptography in practice. Towards Hardware Intrinsic Security: Foundation and Practice, pages 105– 139, 2010.
39. Yu Yu, François-Xavier Standaert, Olivier Pereira, and Moti Yung. Practical leakage-resilient pseudorandom generators. In
ACM Conference on Computer and Communications Security, pages 141–151, 2010.
31
A Information Theoretic Definitions and Lemmata
An important primitive in our work are randomness two-source extractors, which are formally defined as
follows.
Definition 5 (Two-source Extractor [8]). Let L, R and M be three sets. A function ext : L × R →
M is a (k0, k1, )-two source extractor if for random variables L over L and R over R with H∞(L) ≥
k0 and H∞(R) ≥ k1 we have that d(ext(L, R)) ≤ . It is a strong (k0, k1, )-two-source extractor if
d(ext(L, R)|L) ≤  and d(ext(L, R)|R) ≤ .
We need some simple facts from information theory that are proven below.
Lemma 9. Let  > 0 and let X, Y, Z be random variables such that I(X;Z) = 0, i.e. X and Z are
independent, and ∆((X, Y ); (X, Z)) ≤ , then
H˜∞(X|Y, U) ≥ min(H∞(X) − 1, log 
−1 − 1)
Proof. We prove this by contradiction. Suppose H˜∞(X|Y ) < min(H∞(X) − 1, log 
−1 − 1), then we
consider two cases: (a) H∞(X) ≤ log 
−1
and (b) H∞(X) > log 
−1
. Suppose (a) holds, then H˜∞(X|Y ) <
H∞(X) − 1, which means that there exists an algorithm A that given Y predicts X with probability at least
2
−H∞(X)+1, i.e.,
Pr[A(Y ) = X] > 2
−H∞(X)+1
. (35)
(36)
Given such a A we can build a distinguisher D that contradicts ∆((X, Y ); (X, Z)) ≤ . D takes as input
(X, U), where U is either Y or Z. It runs A(U) and if its output is equal to X it guesses 1; otherwise it
returns 0. By Eq. 35, we get Pr[D(X, Y ) = 1] > 2
−H∞(X)+1, while by independence of X and Z it follows
that Pr[D(X, Z) = 1] = 2−H∞(X)
. Putting this together with H∞(X) ≤ log 
−1
, we get:
∆((X, Y ); (X, Z)) > 2
−H∞(X)+1 − 2
−H∞(X) ≥ ,
which gives a contradiction.
Now suppose that (b) holds. In this case, we have H˜∞(X|Y ) < log 
−1 − 1, which gives us a predictor
A with Pr[A(Y ) = X] > 2. With the same distinguisher as above, we get
∆((X, Y ); (X, Z)) > 2 − 2
−H∞(X) ≥ 2 −  = ,
where the last inequality follows by (b). ut
Lemma 10. Let A, B be two random variables, then H˜∞(A|B) ≥ H∞(A, B) − log |B|.
Proof.
H˜∞(A|B) = − log 
Eb←B max
a
Pr[A = a|b = b]

= − log X
b
max
a
Pr[A = a|B = b] Pr[B = b]
!
= − log X
b
max
a
Pr[A = a, B = b]
Pr[B = b]
Pr[B = b]
!
≥ − log 
|B| · max
a,b
Pr[A = a, B = b]

= − log |B| − log 
max
a,b
Pr[A = a, B = b]

= H∞(A, B) − log |B| .
32
ut
Lemma 11. Let A, B be two random variables, then H∞(A, B) ≤ H∞(A) + log |B|.
Proof.
H∞(A, B) = − log 
max
a,b
Pr[A = a, B = b]

= − log 
max
a,b
Pr[A = a] Pr[B = b|A = a]

≤ − log 
max
a
Pr[A = a] |B|
−1

= H∞(A) + log |B| .
ut
We now recall some standard lemmata about the statistical distance (cf. e.g. [14]).
Lemma 12. For any variables X1, . . . , Xn we have d(X1, . . . , Xn) ≤
P
i
d(Xi
|X1, . . . , Xi−1).
Lemma 13 (Triangle inequality for the statistical distance). For any X, Y, Z we have that ∆(X;Z) ≤
∆(X; Y ) + ∆(Y ;Z).
Lemma 14. For every X and Y and any function f we have d(X|Y ) ≥ d(X|f(Y )).
B Basic Linear Algebra
Suppose m < n. Let T ∈ F
m×n
and C ∈ F
m×n
. It is a well-known fact that if T and C have full rank then
there always exists a solution M ∈ NonSingn×n
(F) of the equation
T · M = C. (37)
Furthermore, we now show a method to sample such a solution uniformly at random.
Lemma 15. Let T and C have full rank. There exists an efficient procedure that samples a solutions of the
equation T · M = C uniformly at random.
Proof. The procedure is given on Fig. 4. First, it is easy to see that this procedure indeed finds all the solutions
1. Let T
0
be an arbitrary non-singular n × n-matrix such that the first m rows of T
0
are equal to T (since T has a full rank, such
a matrix T
0
always exists).
2. Sample C
0
from a set of non-singular n×n-matrices whose first m rows are equal to C and the other rows are chosen uniformly
at random (since C has a full rank, such a matrix C
0
always exists)
3. Output M0
:= (T
0
)
−1 C
0
. Since M0
is a product of two non-singular matrices hence M0
is non-singular.
Fig. 4. A procedure for sampling a solution M of an equation T · M = C. We assume that T and C have
full rank.
of the T · M = C equation. This is because if M0
is a solution of this equation, then for any T
0
(chosen is
Step 1) we have that C
0 = T
0
·M0
is a non-singular matrix (since it is a product of two non-singular matrices)
such that its first m rows are equal to the first m rows of C (so C
0 belongs exactly to the set considered in
Step 2 . Therefore, since in Step 3 we set M0 = (T
0
)
−1 C
0
, hence this solution will always be found, and
each solution has the same probability. ut
33
Lemma 16. Let `, m, n ∈ N be such that m < n − `. Consider the following way to sample a matrix
M ∈ F
m×n
: each row of M is sampled independently from an n − ` dimensional subspace of F
n
. The
probability that a matrix M sampled in this way has full rank is at least 1 − m · |F|
−n+m+`−1
.
Proof. For every i ∈ [1, m], let Ei denote the event that the ith row of M does not belong to the linear
sub-space spanned by the first i−1 rows of M. We clearly have p = Pr [E1]·· · ··Pr [Em] (as all these events
are independent). It is also easy to see that for each i we have Pr [Ei
] ≥ 1 − |F|
−n+`+m−1
. This is because
for i ≤ m the space spanned by the first i − 1 rows of M has a dimension at most m − 1, and hence the
probability that a random vector sampled from a n − ` dimensional subspace lies in the m − 1 dimensional
subspace is at least |F|
−n+`+m−1
. Hence p ≥ (1 − |F|
−n+`+m−1
)
m which by Bernoulli’s inequality is at
least 1 − m |F|
−n+`+m−1
. ut
Notice that in the above Lemma if ` = 0, then this means that M ← F
m×n
is sampled uniformly at random.
Lemma 17. Consider the following experiments:
Exp0
: sample at random T0 ∈ F
m×n and C0 ∈ F
m×n of full rank, and then a random solution M0 of
C0 = T0 · M0,
Exp1
: sample at random T1 ∈ F
m×n and M1 ∈ F
n×n both of full rank, and then calculate C1 = T1 · M1.
Then the distributions of (T0, M0, C0) and (T1, M1, C1) are identical.
Proof. Since C0 is a function of T0 and M0, and C1 is the same function of T1 and M1, it is enough to
show that (T0, M0) and (T1, M1) have the same distribution. Variables (T1, M1) and T0 have a uniform
distribution, and therefore the only thing that remains to show is that the conditional distribution of M0
given that T0 is fixed is uniform. This easily follows from Lemma 15. Take any non-singular k × k-matrix
T
0
0
such that the first m rows of T
0
0
are equal to T0. Let C
0
0
be a random non-singular n × n-matrix whose
first m rows are equal to C0 and the other rows are chosen uniformly at random. Since C0 is random, also
C
0
0
is random. Therefore, since M0
0
is a product of (T
0
0
)
−1
and a random C
0
0
, hence M0
0
is also random.
We will also need the following well known facts from linear algebra.
Lemma 18. Let A be a (k × m)-matrix with rank m and B a (m × n)-matrix then we have
rank(A · B) = rank(B) (38)
rank(A) = rank(A
T
) (39)
C Leakage-resilient storage
In this section we present the proof of Lemma 1. We start with the following auxiliary lemmata (that use
lemmata and terms introduced in Appendix A)
C.1 Auxiliary lemmata
Lemma 19. For any λ ∈ N and any λ-limited adversary A, if L and R are independent, then L and R are
independent conditioned on Out(A, Ω(L, R)), i.e.,
I(L; R|Out(A, Ω(L, R))) = 0.
Proof. This directly follows from Lemma 4 in [15]. ut
34
Lemma 20. For δ > 0, λ ∈ N and any λ-limited adversary A, we have
Pr
v←Out(A,Ω(L,R))
[H∞(L|Out(A, Ω(L, R)) = v) ≤ H∞(L) − λ − log(1/δ)] ≤ δ,
Pr
v←Out(A,Ω(L,R))
[H∞(R|Out(A, Ω(L, R)) = v) ≤ H∞(R) − λ − log(1/δ)] ≤ δ.
Proof. This directly follows from Lemma 2.2 in [13]. ut
Consider any strong two-source extractor ext : L × R → M, then we can define a extm : L × Rm → Mm
as
extm(L,(R1, . . . , Rm)) = (ext(L, R1), . . . , ext(L, Rm)).
Lemma 21. Let ext : L×R → Mbe a strong (kL, kR, )-two source extractor (cf. Appendix A). For m ∈ N
and any γ > 0 the function extm as defined above is a (kL,(m−1) log |R|+kR +log(1/γ), m(+γ))-two
source extractor.
Proof. We need to show that for sources L and (R1, . . . , Rm) with H∞(L) ≥ kL and H∞(R1, . . . , Rm) ≥
(m − 1) log |R| + kR + log(1/γ), we have
d(ext(L, R1), . . . , ext(L, Rm)) ≤ m( + γ). (40)
From Eq. (40), we get
d(ext(L, R1), . . . , ext(L, Rm)) ≤
X
i∈[m]
d(ext(L, Ri)|ext(L, R1), . . . , ext(L, Ri−1))
≤
X
i∈[m]
d(ext(L, Ri)|L, R1, . . . , Ri−1). (41)
The first inequality follows by Lemma 12 and the second by Lemma 14 in Appendix B. We now need to
upper-bound d(ext(L, Ri)|L, R1, . . . , Ri−1). To this end, from Lemma 11 in Appendix B, we have that for
each i ∈ [m]:
H∞(R1, . . . Ri) ≥ H∞(R1, . . . , Rm) − (m − i) log |R|
≥ (m − 1) log |R| + kR + log(1/γ) − (m − i) log |R| = (i − 1) log |R| + kR + log(1/γ).
For i ∈ [m] we use Lemma 10 in Appendix B, which gives us
H˜∞(Ri
|R1, . . . , Ri−1) ≥ H∞(R1, . . . Ri) − (i − 1) log |R|
≥ kR + log(1/γ).
Therefore, from Lemma 2.2 in [13] the probability that
H∞(Ri
|R1, . . . , Ri−1) = (r1, . . . , ri−1) ≥ kR (42)
is at least 1 − γ. For each i ∈ [m] let E(i) be an event that (42) holds, then as ext is a strong (kL, kR, )-two
extractor, for each i ∈ [m] we get that d(ext(L, Ri)|L, R1, . . . , Ri−1, E(i)) ≤ . From Lemma 2 in [9], we
have
d(ext(L, Ri)|L, R1, . . . , Ri−1) ≤ d(ext(L, Ri)|L, R1, . . . , Ri−1, E(i)) + Pr[E(i)] ≤  + γ.
With Eq. (41) this concludes the proof. ut
35
Lemma 22. Let γ, λ > 0 and let ext : L×R → Mis an (log |L|−λ−log(1/γ)), log |R|−λ−log(1/γ)), )-
two source extractor satisfying the following property:
If L ← L and R ← R are sampled uniformly at random, then ext(L, R) is distributed uniformly over M.
(43)
Define an LRS Φext = (Encodeext, Decodeext) as follows:
– Encodeext : M → L × R: On input S ∈ M sample uniformly at random elements (L, R) such that
S = ext(L, R).
– Decodeext : L × R → M: Decodeext(L, R) = ext(L, R) = S.
Then Φext is a (λ, 2 |M|  − 2γ)-secure LRS.
Proof. Suppose that (L, R) is sampled uniformly and independently from L × R. Let EL be an event that
H∞(L|Out(A, Ω(L, R))) ≤ log |L| − λ − log(1/γ)
and let ER be an event that
H∞(R|Out(A, Ω(L, R))) ≤ log |R| − λ − log(1/γ).
From Lemma 20, we know that the probability of both of these events is at most γ, and hence, by the
union-bound: Pr [EL ∪ ER] ≤ 2γ. Now, suppose E := EL ∪ ER occurred. For any S, S0 ∈ M we have:
 ≥ d(ext(L, R)|Out(A, Ω(L, R)), E) (44)
=
1
2
X
S∈M,w∈{0,1}
λ
|Pr[ext(L, R) = S ∧ Out(A, Ω(L, R)) = w | E] − (45)
Pr[Out(A, Ω(L, R)) = w | E]/ |M| |
≥
1
2
X
w∈{0,1}
λ
X
s∈{S,S0}
|Pr[ext(L, R) = m ∧ Out(A, Ω(L, R)) = w | E] −
Pr[Out(A, Ω(L, R)) = w | E]/ |M| |
≥
1
2
X
w∈{0,1}
λ
|Pr [ext(L, R) = S ∧ Out(A, Ω(L, R)) = w | E] − (46)
Pr
ext(L, R) = S
0 ∧ Out(A, Ω(L, R)) = w | E
|
=
1
2 |M|
X
w∈{0,1}
λ
|Pr
Out(A, Ω(L, R)) = w | ext(L, R) = S
0 ∧ E
− (47)
Pr
Out(A, Ω(L, R)) = w | ext(L, R) = S
0 ∧ E
|
=
∆(Out(A, Ω(Encode(S))); Out(A, Ω(Encode(S
0
))))|E)
2 |M| (48)
≥
∆(Out(A, Ω(Encode(S))); Out(A, Ω(Encode(S
0
)))) − Pr
E

2 |M| (49)
≥
∆(Out(A, Ω(Encode(S))); Out(A, Ω(Encode(S
0
)))) − 2γ
2 |M| . (50)
Here, (44) follows from the definition of a two-source extractor, and the fact that L and R are independent
given Out(A, Ω(L, R)) (this, in turn, follows from Lemma 19 and the fact that L and R were chosen
independently at random, and hence I(L, R) = 0). Eq. (45) comes form the definition of the statistical
distance (cf. (1) in Section 2.1), Eq. (46) comes from the triangle inequality, and (47) from the definition of
the conditional probability and the fact that we assumed that ext satisfies Property (43). Again, (48) follows
36
from the definition of the statistical distance, and (49) comes from the fact that the statistical distance is at
most equal to 1. Clearly (50) implies that
∆(Out(A, Ω(Encode(S))); Out(A, Ω(Encode(S
0
)))) ≤ 2 |M|  − 2γ.
This finishes the proof. ut
C.2 Proof of Lemma 1
In order to show Lemma 1 we use a technique that is an extension of the technique from [9]. In our proof
we will use the fact that an inner product over a finite filed is a strong two-source extractor. This fact was
first stated in the seminal work of Chor and Goldreich [8], where it was shown for a field GF(2). Rao [35]
extended this result and proved that the inner product over arbitrary finite fields F is a strong two-source
extractor. More precisely, it was shown that for any finite field F, any δ > 0 and n ∈ N the function
extn
F
: F
n × F
n → F (cf. [35], Theorem 3.1) defined as extn
F
(L, R) = hL, Ri =
P
i LiRi
is a (kext, ext)-
two source extractor, for ext = |F|
(n+1)/2
2
−kext and kext = (1/2 + δ)n log |F|, and |F| = Ω(n). Here we
generalize this fact in the following way.
Lemma 23. For n, m ∈ N and a finite field F such that |F| = Ω(n) define extn,m
F
: F
n × F
n×m → F
m as
extn,m
F
(L, R) = L · R. For any δ > 0 and γ > 0 we have that extn,m
F
is a ((1/2 + δ)n log |F| ,(m − 1/2 +
δ)n log |F| + log(γ
−1
), m(|F|
(n+1)/2
2
−(1/2+δ)n log|F| + γ))-extractor.
Proof. Apply Lemma 21 to the extractor extn
F
. This can be done because we can view the function extn,m
F
:
F
n × F
n×m → F
m defined as extn,m
F
(L, R) = L · R as ext ˜
n,m
F
: F
n × (F
n
)
m → F
m defined as
ext ˜
n,m
F
(L,(R1, . . . , Rm)) = (hL, R1i, . . . ,hL, Rmi) = (extn
F
(L, R1), . . . , extn
F
(L, Rm)). ut
We now have the following.
Proof (of Lemma 1). We will combine Lemma 23 with Lemma 22. Recall that Lemma 22 states that every
extractor can be converted into an LRS scheme, as long as it satisfies property (43). The extractor extn,m
F
constructed in Lemma 23 does not satisfy (43) if it is consider over the domain F
n × F
n,m. This is because
for L = (0n
) the value of extn,m
F
(L, R) is equal to (0m) for any R. It is easy to see, however, that if extn,m
F
is considered over a restricted domain (F
n \ {(0n
)} ×F
n,m then the property (43) is satisfied7
. Therefore the
LRS Φextn,m
F
(cf. Lemma 22) is (λ, )-secure (if considered over the restricted domain), with
λ = (1/2 − δ)n log |F| − log γ
−1
 = 2m(|F|
m+1/2−nδ + |F
m| γ).
This finishes the proof since Φextn,m
F
is exactly the same as Φ
n,m
F
. ut
D Flawed constructions of a refreshing scheme
In this section we present insecure protocols for refreshing and attacks against them. We do it for two reasons:
first, the insecure protocol FlawedRefresh is easier to understand and already outlines the basic idea of the
more complicated (secure) refreshing scheme Refresh. Second, on first sight FlawedRefresh looks like a
secure method for refreshing the LRS. Somewhat surprisingly, as we will show in this section, the protocol
FlawedRefresh can be completely broken (i.e., the adversary can recover the encoded secret S) with a simple,
non-adaptive leakage attack (essentially, the only thing that we require is that the adversary can probe some
parts of the memory when the computation takes place).
7 This is because if L 6= (0n
) then for every X ∈ F
m the set of solutions of L·R = X is an affine subspace of F
n×m of dimension
m(n − 1), and hence has a cardinality |F|
m(n−1)
.
37
D.1 A First Attempt for Refreshing the LRS Φ
n,m
F
To simplify exposition, we focus in this section on the case when m = 1. The protocol FlawedRefreshn,1
F
(L, R)
is given in Figure 5. The inner box inside of the protocol description is not part of the protocol, but only
needed to illustrate the leakage game that the adversary can play when running the protocol FlawedRefreshn,1
F
(L, R).
Protocol (L
0
, R0
) ← FlawedRefreshn,1
F
(L, R) :
Input (L, R): L is given to PL and R is given to PR.
Refreshing the share of PR:
1. PL samples X such that hX, Li = 0 and sends X to PR.
2. PR sets R
0
:= R + X.
Refreshing the share of PL:
3. PR samples Y such that hY, R0
i = 0 and sends Y to PR.
4. PL sets L
0
:= L + Y .
Output: The players output (L
0
, R0
).
The adversary plays a λ-leakage game against the leakage oracle:
Ω ((L, X, Y ) ; (R, X, Y ))
Fig. 5. The flawed protocol for refreshing FlawedRefreshn,1
F
. The text in frames describes the leakage game
played by the adversary.
It is easy to see that the protocol satisfies the correctness property as
hL
0
, R0
i = hL + Y, Ri = hL, R0
i + hY, R0
i = hL, R0
i,
where the first equality comes from the construction of the protocol, the second one from the linearity of the
inner product, and the last one from the fact that hY, R0
i = 0. By a symmetric reasoning we get hL, R0
i =
hL, Ri. Hence, the protocol is correct. Notice that the refreshing protocol from Figure 5 does not depend
on any message sent by the adversary, thus, we may assume that the adversary plays the leakage game just
before the end of the protocol. This game is depicted in the text in the frame on Fig. 5. Furthermore, notice
that as L
0
and R0
are functions of (L, X, Y ) and (R, X, Y ) respectively, we do not explicitly need to include
them into the inputs of the oracle Ω.
At first glance, the protocol shown in Figure 5 looks like a promising candidate for a secure refreshing
protocol, as the secrets L and R held by the players get completely “refreshed” by adding to them a highentropy
vectors Y and X (resp.). In the attack below, we will show that unfortunately such a simple refreshing
protocol is not secure.
AN ATTACK AGAINST THE PROTOCOL FlawedRefresh FROM FIG. 5. In the following, if V = (V1, . . . , Vn)
is a vector then V [a, . . . , b] (for 1 ≤ a ≤ b ≤ n) will denote the vector (Va, . . . , Vb). We show a (2 |F|)-
limited adversary A that attacks FlawedRefreshn,1
F
and recovers the encoded message S after ` = n rounds
of the refreshing protocol. Let L
j−1
and Rj−1 denote the shares held by the players PL and PR at the
beginning of the jth round. Let further Xj
, Y j denote the randomness sampled for the refreshing in the jth
round of the protocol. This means that in the jth round the adversary can interact with the leakage oracle
38
Ω(L
j−1
, Xj
, Y j
; Rj−1
, Xj
, Y j
). We will show how a (2 |F|)-limited adversary A can by interaction with
Ω(L
j−1
, Xj
, Y j
; Rj−1
, Xj
, Y j
) learn Wj
:= hL
j
[1, . . . , j], Rj
[1, . . . , j]i. Clearly, after showing this we
are done, as for j := n the adversary can recover S = Wn
.
The attack works by induction. Trivially for j = 1 we can compute W1 by retrieving from the leakage
oracle L
1
[1] and R1
[1]. For j ≥ 2 assume that at the end of the (j−1)th iteration the adversary knows Wj−1
,
and we will show how the adversary can learn Wj
at the end of the jth iteration. At the end of the jth iteration
the adversary A retrieves the following from PL: the value of C
j
L = hL
j−1
[1, . . . , j − 1], Xj
[1, . . . , j − 1]i
and D
j
L = L
j
[j], and from PR he retrieves C
j
R
:= hY
j
[1, . . . , j − 1], Rj
[1, . . . , j − 1]i, and D
j
R = Rj
[j].
We now have:
Wj = hL
j
[1, . . . , j], Rj
[1, . . . , j]i (51)
= hL
j
[1, . . . , j − 1], Rj
[1, . . . , j − 1]i + L
j
[j] · R
j
[j]
= hL
j
[1, . . . , j − 1], Rj
[1, . . . , j − 1]i + D
j
LD
j
R
= hL
j−1
[1, . . . , j − 1], Rj
[1, . . . , j − 1]i + hY
j
[1, . . . , j − 1], Rj
[1, . . . , j − 1]i + D
j
LD
j
R
(52)
= hL
j−1
[1, . . . , j − 1], Rj
[1, . . . , j − 1]i + C
j
R + D
j
LD
j
R
= hL
j−1
[1, . . . , j − 1], Rj−1
[1, . . . , j − 1]i + hL
j−1
[1, . . . , j − 1], Xj
[1, . . . , j − 1]i + C
j
R + D
j
LD
j
R
= Wj−1 + C
j
L + C
j
R + D
j
LD
j
R
, (53)
where (52) and (53) come from the linearity of the inner product, and the rest are simple algebraic transformations.
By assumption, the adversary knows Wj−1
in (53). Therefore he can also calculate Wj
.
A FIRST ATTEMPT TO FIXING THE PROBLEM. The main problem with the protocol from Fig. 5 is that the
players PL and PR know the values of X and Y (resp.), and therefore they can calculate joint functions on
(L, X, Y ) and (R, X, Y ) (resp.). Our method for overcoming this problem is to design a scheme, where
X and Y are sent in an “oblivious” way: e.g. the player PR will be able to learn a random X such that
hL, Xi = 0, while PL will not learn any additional information on X. One natural idea to implement this,
is the following. In Step 1, instead of choosing X randomly, PL chooses a random matrix M in such a way
that each column of M is orthogonal to L, which can be expressed algebraically as:
L · M = (0, . . . , 0). (54)
(for simplicity assume that M is a n × n-matrix of rank n − 1). Then PL sends M to PR. In Step 2 player
PR calculates X := M · B, where B is a random column vector of length n (in other words: X is a random
linear combination of the columns of M), and sets R0
:= R + XT. By simple linear algebra we have
hL, Xi = hL, M · Bi = L · M · B = (0, . . . , 0) · B. Symmetrically, in Step 3 player PR chooses a random
n×n-matrix M˜ (of rank n−1) such that M˜ ·R0 = (0, . . . , 0). Then, PR sends M˜ to PR. In Step 4 player PL
calculates Y := A˜·M˜ , where A˜ is a random column vector of length n, and then he sets L
0
:= L+Y . Again,
it can be easily verified that hR0
, Xi = 0. This protocol may look secure since obviously PL does not learn
X, as (from his point of view) it is a random element sampled from a linear space of vectors orthogonal to L.
Unfortunately, now the problem appears on the other side, since PR, after receiving M, can solve (54) and
compute L (and similarly PL can compute R from M˜ ). Hence, this protocol is not better than an (obviously
not secure) solution where the players simply send their shares L and R to each other. We also note that
attempts to repair this problem by decreasing the rank or the dimension of M and M˜ does not seem to lead
to any solution.

Fast Multi-precision Multiplication for
Public-Key Cryptography on Embedded
Microprocessors
Michael Hutter and Erich Wenger
Institute for Applied Information Processing and Communications (IAIK),
Graz University of Technology, Inffeldgasse 16a, 8010 Graz, Austria
{Michael.Hutter,Erich.Wenger}@iaik.tugraz.at
Abstract. Multi-precision multiplication is one of the most fundamental
operations on microprocessors to allow public-key cryptography such
as RSA and Elliptic Curve Cryptography (ECC). In this paper, we
present a novel multiplication technique that increases the performance
of multiplication by sophisticated caching of operands. Our method significantly
reduces the number of needed load instructions which is usually
one of the most expensive operation on modern processors. We evaluate
our new technique on an 8-bit ATmega128 microcontroller and compare
the result with existing solutions. Our implementation needs only 2, 395
clock cycles for a 160-bit multiplication which outperforms related work
by a factor of 10 % to 23 %. The number of required load instructions is
reduced from 167 (needed for the best known hybrid multiplication) to
only 80. Our implementation scales very well even for larger Integer sizes
(required for RSA) and limited register sets. It further fully complies to
existing multiply-accumulate instructions that are integrated in most of
the available processors.
Keywords: Multi-precision Arithmetic, Microprocessors, Elliptic Curve
Cryptography, RSA, Embedded Devices.
1 Introduction
Multiplication is one of the most important arithmetic operation in public-key
cryptography. It engross most of the resources and execution time of modern
microprocessors (up to 80 % for Elliptic Curve Cryptography (ECC) and RSA
implementations [6]). In order to increase the performance of multiplication, most
effort has been put by researchers and developers to reduce the number of instructions
or minimize the amount of memory-access operations.
Common multiplication methods are the schoolbook or Comba [4] technique
which are widely used in practice. They require at least 2n2 load instructions
to process all operands and to calculate the necessary partial products. In 2004,
Gura et al. [6] presented a new method that combines the advantages of these
methods (hybrid multiplication). They reduced the number of load instructions
B. Preneel and T. Takagi (Eds.): CHES 2011, LNCS 6917, pp. 459–474, 2011.

International Association for Cryptologic Research 2011

IJCSI International Journal of Computer Science Issues, Vol. 8, Issue 3, No. 1, May 2011
ISSN (Online): 1694‐0814
www.IJCSI.org    543
Visual Cryptography Scheme for Color Image Using Random Number
with Enveloping by Digital Watermarking
Shyamalendu Kandar1
, Arnab Maiti2
, Bibhas Chandra Dhara3

1,2 Computer Sc. & Engineering
Haldia Institute of Technology
Haldia, West Bengal, India
3
Department of Information Technology
Jadavpur University
Kolkata, West Bengal, India
Abstract
Visual Cryptography is a special type of encryption technique to
obscure image-based secret information which can be decrypted
by Human Visual System (HVS). This cryptographic system
encrypts the secret image by dividing it into n number of shares
and decryption is done by superimposing a certain number of
shares(k) or more. Simple visual cryptography is insecure
because of the decryption process done by human visual system.
The secret information can be retrieved by anyone if the person
gets at least k number of shares. Watermarking is a technique to
put a signature of the owner within the creation.
In this current work we have proposed Visual Cryptographic
Scheme for color images where the divided shares are enveloped
in other images using invisible digital watermarking. The shares
are generated using Random Number.
Keywords: Visual Cryptography, Digital Watermarking,
Random Number.
1. Introduction
Visual cryptography is a cryptographic technique where
visual information (Image, text, etc) gets encrypted in
such a way that the decryption can be performed by the
human visual system without aid of computers [1].
Like other multimedia components, image is sensed by
human. Pixel is the smallest unit constructing a digital
image. Each pixel of a 32 bit digital color image are
divided into four parts, namely Alpha, Red, Green and
Blue; each with 8 bits. Alpha part represents degree of
transparency.
A 32 bit sample pixel is represented in the following
figure [2] [3].
11100111 11011001 11111101 00111110
Fig 1: Structure of a 32 bit pixel
Human visual system acts as an OR function. Two
transparent objects stacked together, produce transparent
object. But changing any of them to non-transparent, final
objects will be seen non-transparent. In k-n secret sharing
visual cryptography scheme an image is divided into n
number of shares such that minimum k number of shares
is sufficient to reconstruct the image. The division is done
by Random Number generator [4].
This type of visual cryptography technique is insecure as
the reconstruction is done by simple OR operation.
To add more security to this scheme we have proposed a
technique called digital enveloping. This is nothing but an
extended invisible digital watermarking technique. Using
this technique, the divided shares produced by k-n secret
sharing visual cryptography are embedded into the
envelope images by LSB replacement [5]. The color
change of the envelope images are not sensed by human
eye [ 6]. (More than 16.7 million i.e.224 different colors
are produced by RGB color model. But human eye can
discriminate only a few of them.). This technique is
known as invisible digital watermarking as human eye
can not identify the change in the envelope image and the
enveloped (Produced after LSB replacement) image [7].
In the decryption process k number of embedded
envelope images are taken and LSB are retrieved from
each of them followed by OR operation to generated the
original image.
In this paper Section 2 describes the Overall process of
Operation, Section 3 describes the process of k-n secret
sharing Visual Cryptography scheme on the image,
Section 4 describes the enveloping process using invisible
digital watermarking, Section 5 describes decryption
process, Section 6 describes the experimental result, and Al Section 7 draws the conclusion. pha Red Green Blue
IJCSI International Journal of Computer Science Issues, Vol. 8, Issue 3, No. 1, May 2011
ISSN (Online): 1694‐0814
www.IJCSI.org    544
2. Overall Process
Step I: The source image is divided into n number of
shares using k-n secret sharing visual cryptography
scheme such that k number of shares is sufficient to
reconstruct the encrypted image.
Step II: Each of the n shares generated in Step I is
embedded into n number of different envelope images
using LSB replacement.
Step III: k number of enveloped images generated in Step
II are taken and LSB retrieving with OR operation, the
original image is produced.
The process is described by Figure 2
3. k-n Secret Sharing Visual Cryptography
Scheme
An image is taken as input. The number of shares the
image would be divided (n) and number of shares to
reconstruct the image (k) is also taken as input from user.
The division is done by the following algorithm.
Step I: Take an image IMG as input and calculate its
width (w) and height (h).
Step II: Take the number of shares (n) and minimum number
of shares (k) to be taken to reconstruct the image where k must
be less than or equal to n. Calculate RECONS = (n-k)+1.
Step III: Create a three dimensional array
IMG_SHARE[n][w*h][32] to store the pixels of n
number of shares. k-n secret sharing visual cryptographic
division is done by the following process.
for i = 0 to (w*h-1)
{
 Scan each pixel value of IMG and convert it into 32 bit
binary string let PIX_ST.
 for j = 0 to 31
 { if (PIX_ST.charAt(i) =1){
 call Random_Place (n, RECONS)
 }
 for k = 0 to (RECONS−1)
 {
 Set IMG_SHARE [RAND[k]][i][j] = 1
 }
 }
}
Secret Sharing with Digital Enveloping
Original
Image
k-n secret
sharing visual
cryptography Share 1
Share n
Share 2 ……
Envelope 1
Envelope 2
Envelope n
Enveloped
Image 1
Enveloped
Image 2
Enveloped
Image n
 L S B R E P L A C E M E N T
Enveloped
Image 1
Enveloped
Image 1
Enveloped
Image n
…
……
……
k number of
Enveloped
Images
LSB Retrieve with OR
Original
Image
Decryption Process
 Fig 2: Block diagram of the overall process 
IJCSI International Journal of Computer Science Issues, Vol. 8, Issue 3, No. 1, May 2011
ISSN (Online): 1694‐0814
www.IJCSI.org    545
Step IV: Create a one dimensional array IMG_CONS[n]
to store constructed pixels of each n number of shares by
the following process.
for k1 = 0 to (n-1)
{ for k2 = 0 to (w*h-1)
 { String value= “”
 for k3 = 0 to 31 {
 value = value+IMG_SHARE [k1][k2][k3]
 }
Construct alpha, red, green and blue part of each pixel
by taking consecutive 8 bit substring starting from 0.
Construct pixel from these part and store it into
IMG_CONS[k1] [4].
 }
 Generate image from IMG_CONS [k1]1
 [8].
}
subroutine int Random_Place(n, RECONS)
{ Create an array RAND[RECONS] to store the
generated random number.
 for i = 0 to (recons-1)
 {
 Generate a random number within n, let rand_int. [9]
 if (rand_int is not in RAND [RECONS])
 RAND [i] = rand_int
 }
 return RAND [RECONS]
}
4. Enveloping Using Invisible Digital
Watermarking
Using this step the divided shares of the original image
are enveloped within other image. Least Significant Bit
(LSB) replacement digital watermarking is used for this
enveloping process. It is already discussed that a 32 bit
digital image pixel is divided into four parts namely
alpha, red, green and blue; each with 8 bits. Experiment
shows that if the last two bits of each of these parts are
changed; the changed color effect is not sensed by human
eye[6]. This process is known as invisible digital
watermarking [7]. For embedding 32 bits of a pixel of a
divided share, 4 pixels of the envelope image is
necessary. It means to envelope a share with resolution w
X h; we need an envelope image with w X h X 4 pixels.
Here we have taken each envelope of size 4w X h.
The following figure describes the replacement process.
For replacing 8 bit alpha part, a pixel of the envelope is
needed. In the same way red, green and blue part are
enveloped in three other pixels of the envelope image.
The enveloping is done using the following algorithm
Step I: Take number of shares (n) as input.
 for share = 0 to n-1 follow Step II to Step IV.
Step II: Take the name of the share, let SHARE_NO (NO
is from 0 to n-1) and name of the envelope, let
ENVELOPE_NO (NO is from 0 to n-1) as input. Let the
width and height of each share are w and h. The width of
the envelope must be 4 times than that of SHARE_NO.
Step III: Create an array ORG of size w*h*32 to store
the binary pixel values of the SHARE_NO using the loop
for i = 0 to (w*h-1)
 { Scan each pixel value of the image and convert it into
32 bit
 binary string let PIX
 for j = 0 to 31
 { ORG [i*32+j] = PIX.charAt(j)
 }
 }
Create an array ENV of size 4*w*h*32 to store the binary
pixel values of the ENVELOPE_NO using the previous
loop but from i = 0 to 4*w*h*32 −1.
Step IV: Take a marker M= −1. Using the following
process the SHARE_NO is embedded within
ENVELOPE_NO.
for i = 0 to 4*w*h −1
{
 ENV [i*32+6] = ORG [++M];
 ENV [i*32+7 ] = ORG [++M];
 ENV [i*32+14] = ORG [++M];
 ENV [i*32+15] = ORG [++M];
 ENV [i*32+22] = ORG [++M];
 ENV [i*32+23] = ORG [++M];
 ENV [i*32+30] = ORG [++M];
 ENV [i*32+31] = ORG [++M];
}
Construct alpha, red, green and blue part of each pixel by
taking consecutive 8 bit substring starting from 0.
Construct pixel from these part and store it into a one
dimensional array let IMG_CONS of size 4*w*h [4].
 }
 Generate image from IMG_CONS [ ]1
.
Fig 3: Enveloping Process 
IJCSI International Journal of Computer Science Issues, Vol. 8, Issue 3, No. 1, May 2011
ISSN (Online): 1694‐0814
www.IJCSI.org    546
5. Decryption Process
In this step at least k numbers of enveloped images are
taken as input. From each of these images for each pixel,
the last two bits of alpha, red, green and blue are retrieved
and OR operation is performed to generate the original
image. It is already discussed that human visual system
acts as an OR function. For computer generated process;
OR function can be used for the case of stacking k
number of enveloped images out of n.
The decryption process is performed by the following
algorithm.
Step I: Input the number of enveloped images to be taken
(k); height (h) and width (w) of each image.
Step II: Create a two dimensional array STORE[k
][w*h*32 ] to store the pixel values of k number of
enveloped images. Create a one dimensional array
FINAL[(w/4)*h*32] to store the final pixel values of the
image which will be produced by performing bitwise OR
operation of the retrieved LSB of each enveloped images.
Step III:
for share_no = 0 to k-1
{
Take the name of the enveloped image to be taken and
store the pixel values in STORE [share_no][w*h*32]
using the following loop.
 for i = 0 to (w*h-1)
 { Scan each pixel value of the Enveloped image and
convert
 it into 32 bit binary string let PIX.
 for j = 0 to 31
 { STORE[share_no][i*32+j] = PIX.charAt(j)
 }
 }
 }
Step IV: Take a marker M= −1. Using the following
process the last two bits of alpha, red, green and blue of
each pixel of each k number of enveloped images are OR
ed to produce the pixels of the original image.
for i = 0 to w*h
 {
Consider 8 integer values from C0 to C7 and set all of
them to 0.
 for SH_NO = 0 to k-1
 {
 c0 = c0 | STORE [SH_NO] [i*32+6]; // | is bitwise
OR
 c1 = c1 | STORE [SH_NO] [i*32+7];
 c2 = c2 | STORE [SH_NO] [i*32+14];
 c3 = c3 | STORE [SH_NO] [i*32+15];
 c4 = c4 | STORE [SH_NO] [i*32+22];
 c5 = c5 | STORE [SH_NO] [i*32+23];
 c6 = c6 | STORE [SH_NO] [i*32+30];
 c7 = c7 | STORE [SH_NO] [i*32+31];
 }
FINAL [++M] =c0;
FINAL [++M] = c1;
FINAL [++M] = c2;
FINAL [++M] = c3;
FINAL [++M] = c4;
FINAL [++M] = c5;
FINAL [++M] = c6;
FINAL [++M] = c7;
 }

Create a one dimensional array IMG_CONS[ ] of size
(w/4)*h to store constructed pixels.
Construct alpha, red, green and blue part of each pixel by
taking consecutive 8 bit substring from FINAL[ ] starting
from 0.
Construct pixel from these part and store it into
IMG_CONS[(w/4)*h]
Generate image from IMG_CONS[ ].
6. Experimental Result
Division using Visual Cryptography:
Source Image: Lena.png
Source image is
Fig 4: Source Image
Number of Shares: 4
Numbers of shares to be taken: 3
Image shares produced after applying Visual
Cryptography
are:
0img.png 1img.png 
IJCSI International Journal of Computer Science Issues, Vol. 8, Issue 3, No. 1, May 2011
ISSN (Online): 1694‐0814
www.IJCSI.org    547
2img.png 3img.png
   Fig 5: Encrypted Shares
Enveloping using Watermarking:

 0img.png Envelope0.png
                                                                                                                                  Final0.png
 1img.png
                            
 Final1.png
 2img.png
+
+
+
Envelope1.png
Envelope2.png
 Final2.png 
IJCSI International Journal of Computer Science Issues, Vol. 8, Issue 3, No. 1, May 2011
ISSN (Online): 1694‐0814
www.IJCSI.org    548
 3img.png Envelope3.png
 Fig 6: Enveloping shares using Digital Watermarking
Decryption Process:
Number of enveloped images taken: 3
Name of the images: Final0.png, Final2.png, Final3.png

 Fig 7: Decryption Process
+
LSB RETRIEVE WITH OR OPEARTION
 Final3.png 
IJCSI International Journal of Computer Science Issues, Vol. 8, Issue 3, No. 1, May 2011
ISSN (Online): 1694‐0814
www.IJCSI.org    549
7. Conclusion
Decryption part of visual cryptography is based on OR
operation, so if a person gets sufficient k number of
shares; the image can be easily decrypted. In this current
work, with well known k-n secret sharing visual
cryptography scheme an enveloping technique is
proposed where the secret shares are enveloped within
apparently innocent covers of digital pictures using LSB
replacement digital watermarking. This adds security to
visual cryptography technique from illicit attack as it
befools the hackers’ eye.
The division of an image into n number of shares is done
by using random number generator, which is a new
technique not available till date. This technique needs
very less mathematical calculation compare with other
existing techniques of visual cryptography on color
images [10][11][12][13]. This technique only checks ‘1’
at the bit position and divide that ‘1’ into (n-k+1) shares
using random numbers. A comparison is made with the
proposed scheme with some other schemes to prove the
novelty of the scheme.
Table 1: Margin specifications
Other Processes Proposed Scheme
1. k-n secret sharing process is
Complex[10][11][12].
1. k-n secret sharing process is
simple as random number is
used.
2. The shares are sent through
different communication
channels, which is a concern to
security issue [10][11][12][13].
2. The shares are enveloped
into apparently innocent cover
of digital pictures and can be
sent through same or different
communication channels.
Invisible digital watermarking
befools the hacker.
References:
[1] M. Naor and A. Shamir, “Visual cryptography,” Advances in
Cryptology-Eurocrypt’94, 1995, pp. 1–12.
[2] P. Ranjan, “Principles of Multimedia”, Tata McGraw Hill,
2006.
[3] John F Koegel Buford, Multimedia Systems, Addison
Wesley, 2000.
[4] Kandar Shyamalendu, Maiti Arnab, “K-N Secret Sharing
Visual Cryptography Scheme For Color Image Using
Random Number” International Journal of Engineering
Science and Technology, Vol 3, No. 3, 2011, pp. 1851-1857.
[5] Naskar P., Chaudhuri A, Chaudhuri Atal, Image Secret
Sharing using a Novel Secret Sharing Technique with
Steganography, IEEE CASCOM, Jadavpur University,
2010, pp 62-65.
[6] Hartung F., Kuttter M., “Multimedia Watermarking
Techniques”, IEEE, 1999.
[7] S. Craver, N. Memon, B. L. Yeo, and M. M. Yeung.
Resolving Rightful Ownerships with Invisible
Watermarking Techniques: Limitations, Attacks and
Implications. IEEE Journal on Selected Areas in
Communications, Vol16, No.4 May 1998, pp.573–586,.
[8] Schildt, H. The Complete Reference Java 2, Fifth Ed. TMH,
Pp 799-839
[9] Krishmoorthy R, Prabhu S, Internet & Java Programming,
New Age International, pp 234.
[10] F. Liu1, C.K. Wu1, X.J. Lin, Colour visual cryptography
schemes, IET Information Security, July 2008.
[11] Kang InKoo el. at., Color Extended Visual Cryptography
using Error Diffusion, IEEE 2010.
[12] SaiChandana B., Anuradha S., A New Visual Cryptography
Scheme for Color Images, International Journal of
Engineering Science and Technology, Vol 2 (6), 2010.
[13] Li Bai , A Reliable (k,n) Image Secret Sharing Scheme by,
IEEE,2006.
Appendix:
1
 Java Language implementation is
int c=0;
int a=(Integer.parseInt(value.substring(0,8),2))&0xff;
int r=(Integer.parseInt(value.substring(8,16),2))&0xff;
int g=(Integer.parseInt(value.substring(16,24),2))&0xff;
int b=(Integer.parseInt(value.substring(24,32),2))&0xff;
img_cons[c++]=(a << 24) | (r<< 16) | (g << 8) | b; 

International Journal of Computer Applications (0975 – 8887)
Volume 14– No.5, January 2011
45
Comparative Study of Arithmetic and Huffman Data
Compression Techniques for Koblitz Curve Cryptography
O. Srinivasa Rao
Dept. of CSE
University College of Engineering
JNTUK-Vizianagaram
Andhra Pradesh, India-535 003
Dr S.Pallam Setty
Professor of CS&SE
University College of Engg.,
Andhra University, Visakhapatnam
Andhra Pradesh, India-530 003
ABSTRACT
Over the past 20 years, numerous papers have been written on
various aspects of ECC implementation. In this paper we
investigate the superiority of the Arithmetic data compression
technique over the Huffman data compression technique in
reducing the channel bandwidth and the transmission time.
The main purpose of data compression is to reduce the
memory space or transmission time, while that of
cryptography is to ensure the security of the data. Applying
Data compression techniques not only reduces the bandwidth
but also enhances the strength of the cryptosystem. It is also
observed that even if the given string is doubled i.e. AAAA
(4A’s) to AAAAAAAA (8A’s), the compression ratio remains
constant. Further in Arithmetic Data Compression the
compression ratio is 50% more when compared to the
Huffman Data Compression and the ratio increases with
increasing string length.
General Terms
Your general terms must be any term which can be used for
general classification of the submitted material such as Pattern
Recognition, Security, Algorithms et. al.
Keywords
Elliptic curve cryptography, Koblitz curves, Huffman Data
compression, Arithmetic Data Compression
1. INTRODUCTION
In 1985, Neal Koblitz [1] and Victor Miller [5] independently
proposed using the group of points on an elliptic curve
defined over a finite field in discrete logarithm cryptographic
systems. In 1991, Koblitz[1] suggested using a special family
of elliptic curves now popularly referred to as Koblitz curves.
Koblitz curves have been widely studied in the academia and
have been included in certain standards [2-4]. In the Koblitz
curves point multiplication is considerably more efficient than
on general curves.
The primary advantage that elliptic curve systems have over
systems based on the multiplicative group of a finite field (and
also over systems based on the intractability of integer
factorization) is the absence of a sub exponential-time
algorithm (such as those of ―index-calculus‖) to find discrete
logarithms in these groups. Consequently, one can use an
elliptic curve group that is smaller in size and still maintain
the same level of security. The result is smaller key sizes,
bandwidth savings, and faster implementations—features that
are especially attractive for security applications in smart
cards, personal digital assistance, and wireless devices where
computational power and integrated circuit space are limited.
Elliptic curve cryptographic protocols for digital signatures,
public-key encryption, and key establishment have been
standardized by numerous standards organizations including:
American National Standards Institute (ANSI X9.62
[6], ANSI X9.63 [7]).
Institute of Electrical and Electronics Engineers
(IEEE 1363-2000 [8]).
International Standards Organization (ISO/IEC
15946-3 [9]).
U.S. government’s National Institute for Standards
and Technology (FIPS 186-2 [2]).
Internet Engineering Task Force (IETF PKIX [7],
IETF OAKLEY [10]).
Standards for Efficient Cryptography Group (SECG
[3]).
 Majority of the products and standards use RSA public-key
cryptography for encryption and digital signatures. As seen,
the bit length for secure RSA has increased over the years,
thus putting a heavier processing load on applications. This
burden has ramifications, especially for electronic commerce
sites that conduct large numbers of secure transactions.
Recently elliptic curve based cryptosystems have emerged as
a competing alternative to RSA. [8,11,17]
2. ELLIPTIC CURVE CRYPTOGRAPHY
Elliptic curve cryptography makes use of elliptic curves in
which the variables and coefficients are all restricted to
elements of a finite field. Two families of elliptic curves are
used in cryptographic applications: Prime curves defined over
Zp and binary curves constructed over GF (2m).
Fernandes[12] points out that prime curves are best suited for
software applications, as the extended bit –fiddling operations
needed by binary curves are not required; ,and that binary
curves are best for hardware applications, where it takes
remarkably few logic gates to create a powerful and fast
cryptosystem. In this paper we used Koblitz curves which are
a variant of binary curves for analysis purpose.
2.1 Koblitz curves
A koblitz curve E over F2m is an elliptic curve whose
defining equation has coefficients in F2. There are two koblitz
curves: y2+xy=x3+1 and y2+xy=x3+x2+1.These elliptic
curves were first proposed for cryptographic use by koblitz
[1].They have advantage over randomly selected curves over
binary fields because the point multiplication operation in
Koblitz curves involves no point doubling (See Solinas [14,
15, 19]).Koblitz curves have been standardized in NIST’s
FIPS (186-2[2]).
2.2 Elliptic Curves Arithmetic over F2
m
A (non-super singular) elliptic curve E(F2
m
,) over F2
m
, defined

International Mathematical Forum, Vol. 6, 2011, no. 49, 2409 - 2418
An Application of Discrete Algorithms
in Asymmetric Cryptography
F. Amounas1 and E. H. El Kinani2
1 Informatics Department, Faculty of Sciences and Technics
Moulay Isma¨ıl University
Box 509 Errachidia, Morocco
2 Mathematical Department, Faculty of Sciences and Technics
Moulay Isma¨ıl University
Box 509 Errachidia, Morocco
elkinani 67@yahoo.com
A. Chillali
Mathematical Department, Faculty of Sciences and Technics
Sidi Mohammed Ben Abdelalh University
Box 2202 F`es, Morocco
Abstract
In this paper we propose an application of public key distribution
based on the security depending on the difficulty of elliptic curve discrete
logarithm problem. More precisely, we propose an example of Elgamal
encryption cryptosystem on the elliptic curve given by the equation:
y2 = x3 + 70x + 57[73].
Mathematics Subject Classification: 11G07, 94A60, 11T71, 14G50,
68P25
Keywords: Cryptography, elliptic curve, discrete logarithm, elliptic curve
cryptosystem
1 Introduction
Elliptic curves are fundamental objects in a large part of mathematics they
are very interesting because their study involves several fields of mathematics.
The study of elliptic curves has a long history and still there are many
2410 F. Amounas, E.H. El Kinani and A. Chillali
unsolved problems. In the last decade the application of the elliptic curves in
cryptography have been attracting increased attention of many scientists [see
e.g [1, 2]] because they have opened a wealth possibilities in terms of security.
The elliptic curve cryptosystem (ECC), which was originally proposed by Niel
Koblitz and Victor Miller in 1985 [2], is seen as a serious alternative to RSA
because there key size is much shorter than that of RSA and Elgamal [3]. The
application of elliptic curves to the field of cryptography has been relatively
recent, numerous cryptosystems base their security on the difficulty of solving
the discrete logarithm problem. The comparison of two cryptosystems using
public key cryptosystem RSA and the cryptosystem based on elliptic curve
is done in [4]. Recently the author [5], describes the first practical experiments
employing cryptography based on elliptic curves. In [6] a new public
key cryptosystem (analogue of RSA) based on elliptic curves over the ring
Zn is described. Indeed the security of the RSA and Elgamal cryptosystems
[3, 9] is generally equated to the difficulty of integer factorization and that of
the computation of discrete logarithms in finite fields respectively. This paper
describes the public-key cryptosystems based on the elliptic curve discrete
logarithm problem. In particular, here we propose an example of Elgamal
encryption cryptosystem based into an elliptic curve given by the following
equation: y2 = x3 + 70x + 57[73]. The paper is organized as follows, first
we give some preliminary notes connected with the elliptic curves, the rules
for addition on its points and the discrete logarithm problem. Section 3, is
devoted to the main results, first we give the table of the curve points, the corresponding
alphabetical symbols and the corresponding code, then we follow
the Elgamal cryptosystem to encrypt and to decrypt the message which Alice
wishes to send Bob.
2 Preliminary Notes
In this section, we introduce some basics notions connected with elliptic curves.
For more details on the theory of elliptic curves, we refer interested reader to
[7, 8].
2.1 Definition of the Elliptic Curves
Here we begin with the definition of an elliptic curve. Let K be a field. For
example, K can be the finite (extension) field Fqr of Fq, the prime field Zp
where p is a (large) prime, the field R of real numbers, the field Q of rational
numbers, or the field C of complex numbers.
Definition 2.1 An elliptic curve over a field K is the set of points satisfying
Application of discrete algorithms in asymmetric cryptography 2411
the Weierstrass equation:
y2 + a1xy + a3y = x3 + a2x2 + a4x + a6, (1)
and also an element denoted O and called the point at infinity, where a1, a3, a2, a4,
a6 ∈ K.
The elliptic curve E over K is denoted E(K) and the number of points on E
is denoted card E(K).
Remarks
1-For fields of various characteristics, the Weierstrass equation Eq.(1) can be
transformed into different forms by a linear change of variables.
2-For the homogeneous, so called also projective, coordinate system, (x, y) =
( X
Z , Y
Z ), the equation (1) determining an elliptic curve point takes the following
form :
Y 2
Z + a1XY Z + a3Y Z2 = X3 + a2X2
Z + a4XZ2 + a6Z3
. (2)
The point at infinity is the collection of points on the projective plane for
which Z = 0. The point at infinity is the point of intersection where the y-axis
and the line at infinity meet. More precisely, the point at infinity is (0, 1, 0)
in the projective plane (the equivalence class with X = Z = 0). An elliptic
curve E over a finite field K can be made into an abelian group by defining
an additive operation on its points.
2.2 The Rules for Addition
Theorem 2.2 For each three points M(x1, y1), N(x2, y2) and R(x3, y3) of
the elliptic curves defined in Eq(2) such that R = M +N. Then R is given by:
i)R = O for x1 = x2 and y2 = −y1 − a1x1 − a3
ii)x3 = t
2 + a1t − a2 − x1 − x2 and y3 = −(t + a1)x3 − s − a3
with
t =
⎧
⎪⎪⎨
⎪⎪⎩
y2−y1
x2−x1 , if M = N
3x2
1+2a1x1+a4−a1y1
2y1+a1x1+a3 , if M = N
and
s =
⎧
⎪⎪⎨
⎪⎪⎩
y1x2−y2x1
x2−x1 , if M = N
−x3
1+a4x1+2a6−a3y1
2y1+a1x1+a3 , if M = N
The addition operation defined above turns E(K) into an abelian group that
has O as the identity element.
2412 F. Amounas, E.H. El Kinani and A. Chillali
2.3 The Discrete Logarithm Problem
Recall that the discrete logarithm problem (LDP) for some group G, is to find
an integer p such that pg1 = g2 ( where g1, g2 ∈ G). Analogously and since an
elliptic curve E(K) is made into an abelian group by an additive operation. In
the elliptic curve discrete logarithm problem (EDLP) we solve for an integer
x such that xα = β given α, β ∈ E(K). The security of ECC (Elliptic Curve
Cryptosystem) depends on the difficulty of elliptic curve discrete logarithm
problem. In fact for a given two points on E(K), it is computationally infeasible
to solve the corresponding elliptic curve discrete logarithm problem. The
elliptic curve cryptosystems described in the next section is dependent on the
presumed intractability of the EDLP.
3 Main Results
In this section, we present a our main result. First consider the elliptic curve
c given by the Weierstrass equation:
Y 2 = x3 + 70x + 57[73]. (3)
The following table gives the code of the curves points, here the choosing
curve contains 74 points, then if P is the generator point of the group. It is
the point witch represents the letter a, as well as 2P represents the letter b,...,
74P represents ’?’
Application of discrete algorithms in asymmetric cryptography 2413
curve point corresponding code alphabetical corresponding symbol
[3, 41] 000001101010010000001 a
[66, 10] 100001000010100000001 b
[45, 4] 010110100001000000001 c
[60, 4] 011110000001000000001 d
[47, 58] 010111101110100000001 e
[21, 35] 001010101000110000001 f
[41, 69] 010100110001010000001 g
[53, 72] 011010110010000000001 h
[42, 56] 010101001110000000001 i
[64, 31] 100000000111110000001 j
[29, 59] 001110101110110000001 k
[35, 66] 010001110000100000001 l
[19, 56] 001001101110000000001 m
[63, 67] 011111110000110000001 n
[11, 48] 000101101100000000001 o
[13, 5] 000110100001010000001 p
[32, 5] 010000000001010000001 q
[26, 53] 001101001101010000001 r
[52, 35] 011010001000110000001 s
[50, 2] 011001000000100000001 t
[4, 67] 000010010000110000001 u
[12, 17] 000110000100010000001 v
[57, 30] 011100100111100000001 w
2414 F. Amounas, E.H. El Kinani and A. Chillali
curve point corresponding code alphabetical corresponding symbol
[1, 37] 000000101001010000001 x
[0, 38] 000000001001100000001 y
[71, 37] 100011101001010000001 z
[23, 16] 001011100100000000001 A
[44, 65] 010110010000010000001 B
[22, 28] 001011000111000000001 C
[24, 31] 001100000111110000001 D
[55, 22] 011011100101100000001 E
[38, 49] 010011001100010000001 F
[28, 68] 001110010001000000001 G
[58, 31] 011101000111110000001 H
[6, 6] 000011000001100000001 I
[46, 47] 010111001011110000001 J
[62, 0] 011111000000000000001 K
[46, 26] 010111000110100000001 L
[6, 67] 000011010000110000001 M
[58, 42] 011101001010100000001 N
[28, 5] 001110000001010000001 O
[38, 24] 010011000110000000001 P
[55, 51] 011011101100110000001 Q
[24, 42] 001100001010100000001 R
[22, 45] 001011001011010000001 S
[44, 8] 010110000010000000001 T
[23, 57] 001011101110010000001 U
[71, 36] 100011101001000000001 V
[0, 35] 000000001000110000001 W
[1, 36] 000000101001000000001 X
[57, 43] 011100101010110000001 Y
[12, 56] 000110001110000000001 Z
[4, 6] 000010000001100000001 0
[50, 71] 011001010001110000001 1
[52, 38] 011010001001100000001 2
[26, 20] 001101000101000000001 3
[32, 68] 010000010001000000001 4
Application of discrete algorithms in asymmetric cryptography 2415
curve point corresponding code alphabetical corresponding symbol
[13, 68] 000110110001000000001 5
[11, 25] 000110110001000000001 6
[63, 6] 011111100001100000001 7
[19, 17] 001001100100010000001 8
[35, 7] 001001100100010000001 9
[64, 42] 010001100001110000001 /
[64, 42] 001110100011100000001 @
[42, 17] 100000001010100000001 e´
[53, 1] 010101000100010000001 e`
[41, 4] 011010100000010000001 u`
[21, 38] 010100100001000000001 a`
[47, 15] 001010101001100000001 .
[60, 69] 010111100011110000001 ,
[45, 69] 011110010001010000001 ˙,
[66, 63] 010110110001010000001 +
[3, 32] 100001001111110000001 −
O 000000000000010000001 ?
Table.1 giving the curves points, corresponding codes and the corresponding
alphabetical symbol.
Here we follow Elgamal cryptosystem [3], first recall that the Elgamal cryptosystem
consist in the following steps:
Suppose that we have some elliptic curve E defined over a finite field Fq and
that E and a point P ∈ E are publicly known, as is the embedding system
m −→ Pm; which imbed plain text on an elliptic curve E. Then, when Alice
wants to communicate secretly with Bob, they proceed thus:
step 1. Bob chooses a random integer a, and publishes the point aP (while
a remains secret).
step 2. Alice chooses her own random integer l and sends the pair of points
(lP, Pi + l(aP)) to Bob (while a remains secret).
step 3. To decrypt the message, Bob calculates a(lP) from the first part of
the pair, then subtracts it from the second part to obtain Pi +l(aP)−a(lP) =
Pi+laP −laP = Pi, and then reverses the embedding to get back the message.
Here in our case Alice wishes to send a message ’cryptography’ to Bob.
First, she imbeds the message ’cryptography’ onto the elliptic curve E, i.e. she
2416 F. Amounas, E.H. El Kinani and A. Chillali
represents the plain text ’cryptography’ as a set of points Pi ∈ E (where i take
the alphabetical letter of plain text ’cryptography’) .
In our case we have K = (P, a, R) with P = [3, 41], a = 41, R = aP.
and we take l ∈ 0, 1, 2........, 73 random, l = 33 the encryption function is:
eK(Pi)=(Yi, Zi)
with Yi = Y = 33P = [28, 68]; (which is fixed for each i)
and Zi = 33R + Pi = [4, 67] + Pi
The cipher text is given in the following table
plain text the point Pi eK(Pi) cipher text
C [22, 28] ([28, 68], [1, 36]) GX
r [26, 53] ([28, 68], [6, 67]) GM
y [0, 38] ([28, 68], [44, 8]) GT
p [13, 5] ([28, 68], [62, 0]) GK
t [50, 2] ([28, 68], [28, 5]) GO
o [11, 48] ([28, 68], [46, 47]) GJ
g [41, 69] ([28, 68], [44, 65]) GB
r [26, 53] ([28, 68], [6, 67]) GM
a [3, 41] ([28, 68], [12, 17]) Gv
p [13, 5] ([28, 68], [62, 0]) GK
h [53, 72] ([28, 68], [22, 28]) GC
y [0, 38] ([28, 68], [44, 8]) GT
Table.2: the embedding of the plain text into elliptic curve, the encryption
function and the corresponding cipher text
Hence the message ’Cryptography’ is transformed into the message ’GXGMGTGKGOGJGBGMGVGKGCGT’,
then from the table.1, the message becomes
a series of codes these :
00111001000100000000100000101001000000001001110010001000000001
000011010000110000001001110010001000000001010110000010000000001
001110010001000000001011111000000000000001001110010001000000001
001110000001010000001001110010001000000001010111001011110000001
001110010001000000001010110010000010000001001110010001000000001
000011010000110000001001110010001000000001000110000100010000001
Application of discrete algorithms in asymmetric cryptography 2417
001110010001000000001011111000000000000001001110010001000000001
001011000111000000001001110010001000000001010110000010000000001
When Bob received the above series of bits, he transform it into pair of
points (Yi, Zi) and compute the corresponding decryption function:
dK(Yi, Zi) = Zi − aYi = [4, 67] + Pi − 41Yi.
After decrypting the received message and using the table.3, we obtain the
plain text ’Cryptography’.
cipher text the point (Yi, Zi) dK(Pi) plain text
GX ([28, 68], [1, 36]) [22, 28] C
GM ([28, 68], [6, 67]) [26, 53] r
GT ([28, 68], [44, 8]) [0, 38] y
GK ([28, 68], [62, 0]) [13, 5] p
GO ([28, 68], [28, 5]) [50, 2] t
GJ ([28, 68], [46, 47]) [11, 48] o
GB ([28, 68], [44, 65]) [41, 69] g
GM ([28, 68], [6, 67]) [26, 53] r
Gv ([28, 68], [12, 17]) [3, 41] a
GK ([28, 68], [62, 0]) [13, 5] p
GC ([28, 68], [22, 28]) [53, 72] h
GT ([28, 68], [44, 8]) [0, 38] y
Table.3 : the cipher text, the corresponding points, the decryption function
and the plain text
4 Conclusion
In this paper, we have proposed an application of public key distribution based
on the security depending on the difficulty of elliptic curve discrete logarithm
problem. More precisely, we have proposed an example of Elgamal encryption
cryptosystem on the elliptic curve given by the following equation: y2 = x3 +
70x + 57[73].
References
[1] V. S. Miller. Use of Elliptic Curves in Cryptography. Advances in Cryptology
CRYPTO’85(1986), pp. 417-426.
[2] N. Koblitz. Elliptic Curve Cryptosystems. Mathematics of Computation,
Vol. 48, No. 177 (1987), pp. 203-209.
2418 F. Amounas, E.H. El Kinani and A. Chillali
[3] T.Elgamal,
public key cryptosystem and a signature scheme based
on discrete logarithms. IEEE, Transactions on Information Theory,
Vol.31(1985), pp.473- 481.
[4] T.E. Rakotondraina., F.Randimbindrainibe, J.Razakarivony. ”Performance
des crypto syst`emes bas´es sur les courbes elliptiques”, ACM, Vol.
21(1978), pp.120-126.
[5] R. Lercier. ”Courbes Elliptiques et cryptographie”. Num´ero 64 dans Revue
Scientifique et Technique de la D´efense, (2004), pp.59-66. D´el´egation
g´en´erale pour l’armement.
[6] N. Demytko. A New Elliptic Curve Based Analogue of RSA. in T. Helleseth,
editor, Advances in Cryptology-Eurocrypt’93, Springer-Verlag, New
York, (1994), pp. 4049.
[7] J. W. S. Cassels. Lectures on Elliptic Curves. Cambridge University Press,
1991.
[8] A. Atkin and F. Morain. Elliptic curves and primality proving. Mathematics
of Computation, Vol. 61, No. 203(1993), pp. 29-68.
[9] M. Saeki. Elliptic curve cryptosystems. M.Sc. thesis, School of Computer
Science, McGill University, 1996.
Received: April, 2011
by the parameters a, b є F2
m
, b ≠ 0 , is the set of all solutions
(x, y), x, y є F2
m
, to the equation y
2
+xy=x3
+ax2
+b, together
with an extra point O, which is the point at infinity.
International Journal of Computer Applications (0975 – 8887)
Volume 14– No.5, January 2011
46
The set of points E(F2
m
) forms a group with the following
additional rules:
1. O+O =O
2. (x, y)+O=O+(x, y)=(x, y) for all (x, y) ϵ E(F2
m
).
3. (x, y)+(x, x + y)=O for all (x, y) ϵ E(F2
m
)
 (i.e., the negative of the point (x, y) is –(x, y)=(x, x +y)).
4. (Rules for adding two distinct points that are not inverse of
each other) Let P = (x1
, y1
) ϵ E(F2
m
) and Q=(x2
,y2
) ϵ E(F2
m
)
be two points such that x1≠x2
.Then
 P+Q=(x3
,y3
),where
x3=λ2
+ λ+x1+x2+a,
y3= λ(x1+x3
) +x3+y1
, and
λ = (y2+y1
)/(x2+x1
)
5. (Rule for doubling a point)
Let P=(x1
, y1
) ϵ E (F2
m
) be a point with x1≠0. (If x1=0 then
P=-P, and so 2P=O) Then 2P =(x3
, y3
), where
 x3= λ2
+ λ + a
y3=x1
2
+ (λ+1) x3
, and
λ =x1+ (y1
/x1
)
3. DATA COMPRESSION TECHNIQUES
A data compression method is called universal if the
compressor and decompressor do not know the statistics of
the input stream. A universal method is optimal if the
compressor can produce compression factors that
asymptotically approach the entropy of the input stream for
long inputs. Compression performance: Several quantities are
commonly used to express the performance of a compression
method. The Compression ratio is one of the quantities used
to express compression efficiency and is defined as
Compression ratio =Size of the output stream/size of the input
stream.
A value of 0.6 means that after compression the data occupies
60% of its original size. Values greater than 1 imply that the
output stream is bigger than the input stream (negative
compression). The compression ratio can also be called bpb
(bit per bit), since it equals the number of bits in the
compressed stream needed, on an average, to compress one
bit in the input stream. In image compression, the same term,
bpb stands for ―bits per pixel.‖In modern, efficient text
compression methods, it makes sense to talk about bpc (bits
per character)—the number of bits it takes, on average, to
compress one character in the input stream.
3.1 Huffman coding
A commonly used method for data compression is Huffman
coding. It serves as the basis for several popular programs
used in personal computers. Some of them use just the
Huffman method, while others use it as one step in a multistep
compression process. The Huffman method [15] is somewhat
similar to the Shannon-Fano method. It generally produces
better codes, and like the Shannon-Fano method, produces
best code when the probabilities of the symbols are negative
powers of 2. The main difference between the two methods is
that Shannon-Fano constructs its codes from top to bottom
(from the leftmost to the rightmost bits), while Huffman
constructs a code tree from the bottom (builds the codes from
right to left). Since its development, in1952, by D. Huffman,
this method has been the subject of intense research in data
compression.
The method starts by building a list of all the alphabet
symbols in descending order of probabilities. It then
constructs a tree, with a symbol at every leaf, from the bottom
up in steps, where at each step the two symbols with the
smallest probabilities are selected, added to the top of the
partial tree, deleted from the list, and replaced with an
auxiliary symbol representing the two symbols. When the list
is reduced to just one auxiliary symbol (representing the entire
alphabet), the tree is complete. The tree is then traversed to
determine the codes for the symbols.
3.2 Arithmetic Coding
The Huffman method is simple, efficient, and produces the
best codes for the individual data symbols. However, it is
shown that the only case where it produces ideal variable-size
codes (codes whose average size equals the entropy) is when
the symbols have probabilities of occurrence that are negative
powers of 2 (i.e., numbers such as1/2, 1/4, or 1/8). This is
because the Huffman method assigns a code with an integral
number of bits to each symbol of the alphabet. Information
theory shows that a symbol with probability 0.4 should ideally
be assigned a 1.32-bit code, since −log20.4 ≈ 1.32.The
Huffman method, however, normally assigns such a symbol a
code of 1 or 2 bits. Arithmetic coding overcomes the problem
of assigning integer codes to the individual symbols by
assigning one (normally long) code to the entire input file.
The method starts with a certain interval, it reads the input file
symbol by symbol, and uses the probability of each symbol to
narrow down the interval. Specifying a narrower interval
requires more bits, so the number constructed by the
algorithm grows continuously. To achieve compression, the
algorithm is designed such that a high-probability symbol
narrows the interval less than a low-probability symbol, with
the result that high-probability symbols contribute fewer bits
to the output .An interval can be specified by its lower and
upper limits or by one limit and width (range). We use the
latter method to illustrate how an interval’s specification
becomes longer as the interval narrows. The interval [0, 1] can
be specified by the two 1-bit numbers 0 and1. The interval
[0.1, 0.512] can be specified by the longer numbers 0.1 and
0.412. The very narrow interval [0.12575, 0.1257586] is
specified by the long numbers 0.12575 and 0.0000086.
4. ECC ENCRYPTION AND
DECRYPTION
Several approaches to encryption/ decryption using elliptic
curves have been analyzed. This paper describes one of them.
The first task in this system is to encode the plaintext message
m to be sent as an x-y point Pm. It is the point Pm that will be
encrypted to cipher text and subsequently decrypted. Note that
we cannot simply encode the message as the x or y coordinate
of a point, because not all such coordinates are in Ep(a, b).
There are techniques for encoding. We developed a scheme
that will be reported elsewhere. As with the key exchange
system, an encryption/decryption system requires a point G
and an elliptic group Ep(a, b) as parameters. Each user selects
a private key nA and generates a public key PA = nA x G.
To encrypt and send a message Pm to B, A chooses a random
positive integer x and produces the cipher text Cm
corresponding to the pair of points ([7],[18],[20] )
Cm= {xG, Pm + xPB} (1)
International Journal of Computer Applications (0975 – 8887)
Volume 14– No.5, January 2011
47
Note that A has used B’s public key PB. To decrypt the cipher
text, B multiplies the first point in the pair by B’s secret key
and subtracts the result from the second point:
Pm + xPB – nB(xG) = Pm + x(nBG) – nB(xG) = Pm(2)
A has masked the message Pm by adding xPB to it. Nobody
but A knows the value of x, so even though PB is a public key,
nobody can remove the mask xPB. However, A also includes a
―clue,‖ which is enough to remove the mask if one knows the
private key nB. For an attacker to recover the message, he
would have to compute x, given G and xG, which is hard.
5. Analytical study of Bandwidth for
Koblitz Curve using Huffman Data
Compression and Arithmetic Data
compression
We have taken an irreducible polynomial x7
+x+1, and the
Koblitz curve of y2
+xy=x3
+x2
+1 in the binary field. Then we
generated the (x, y) points for the chosen koblitz curve. These
points were mapped to the alphanumeric characters [16]. The
mapped points are encrypted using equation (1). The coordinates
of the koblitz curve, encryption and decryption of
the input strings, Data compression algorithms are
implemented in C and the results are shown in table1 and
table2 and plot of these tables are shown Figure 1 and Figure
2. From these tables and graphs it is revealed that if the input
string contains alphabets which are repeating, the compression
ratio is high. The compressed data to be sent to the destination
is much less in size and thus requires less bandwidth. The
compression ratio in Arithmetic Data Compression is 50%
more when compared to the Huffman Data Compression
.Further the Compression increases with increase in string
length. At the destination the data is uncompressed and
original text is recovered by using the equation (2).
6. CONCLUSION
We compare the performance of arithmetic and Huffman
Compression techniques for different input strings. It is
observed that Arithmetic compression technique is more
appropriate than Huffman data compression technique in
reducing the channel bandwidth and the transmission time in
Elliptic curve based cryptosystems.
Table 1
S.No Input Data String Encrypted
data
Size(bits)
Huffman
Compressed
Data Size
(bits)
Arithmetic
Compressed
Data Size
(bits)
Huffman
Compression
Ratio
(Percentage)
Arithmetic
Compression
Ratio
(Percentage)
1 AAAAA 70 10 7 14.285714 10
2 AAAAE 70 20 9 28.571429 12.857142
3 AAADA 70 20 9 28.571429 12.857142
4 AAADE 70 30 15 42.857143 21.428571
5 AACAA 70 20 9 28.571429 12.857142
6 AACAE 70 30 15 42.857143 21.428571
7 AACDA 70 30 15 42.857143 21.428571
8 AACDE 70 30 15 42.857143 21.428571
9 ABAAA 70 20 9 28.571429 12.857142
10 ABAAD 70 30 15 42.857143 21.428571
11 ABADA 70 30 15 42.857143 21.428571
12 ABADE 70 30 24 42.857143 34.285714
13 ABCAA 70 30 15 42.857143 21.428571
14 ABCDA 70 30 24 42.857143 34.285714
15 ABCDE 70 30 25 42.857143 35.714285
16 JNTU 56 24 20 42.857143 35.714285
17 JNTUKAKINADA 168 96 26 57.142857 15.476190
18 JNTUKAKIADAVIZIANAGARAM 336 240 26 71.428571 7.7380952
Table 2
S.No Input Data String Encrypted data
Size(bits)
Huffman Compression Arithmetic Compression
Compressed
Data Size
(bits)
Compression
Ratio
(Percentage)
Compressed
Data Size
(bits)
Compression
Ratio
(Percentage)
1 AAAAAAAAAAAA 168 24 14.285714 7 4.166666
2 AAAAAABBBBBB 168 48 28.571428 14 8.333333
3 AAAABBBBCCCC 168 72 42.857143 21 12.5
4 AAABBBCCCDDD 168 72 42.857143 24 14.285714
International Journal of Computer Applications (0975 – 8887)
Volume 14– No.5, January 2011
48
5 AABBCCDDEEFF 168 72 42.857143 26 15.47169
6 AABBCCDDDEEE 168 72 42.857143 26 15.47169
7 AAAABCCDDDD 154 66 42.857143 21 13.636363
8 ABCDEEEFFFG 168 96 57.142857 27 16.071428
9 ABCDEEEEEEF 154 88 57.142857 27 17.532467
10 DDEEFGHHHII 154 88 57.142857 27 17.532467
11 KLKLFGHIJJJ 154 88 57.142857 23 14.935064
12 AABCCCDHIJK 154 88 57.142857 26 16.883116
13 AAABBBCDEFJ 154 88 57.142857 24 15.584416
14 AAAABBBBCCC 154 66 42.857143 21 13.636363
15 IJKIJKIJKIJK 168 72 42.857143 19 11.309528
16 GHIJGHIJILAA 168 72 42.857143 25 14.880952
17 CCCDDDABCDEF 168 96 57.142857 20 11.904761
18 AABBBBKLKLKL 168 72 42.857143 24 14.285714
7. REFERENCES
[1] N.Koblitz, CM-curves with good cryptographic
properties in: Advances in cryptology, CRYPTO’91,
Lecture note in Computer Science,Vol.576, Springer
1991, pp 279-287
[2] National Institute of Standards and Technology (NIST),
Digital Signature Standards(DSS), Federal information
processing standard, FIPS PUB 186-2, January 27,2000.
[3] Certicom Research, SEC 1: Elliptic Curve Cryptography,
Standards for efficient cryptography, September,
2000
[4] Certicom Research, SEC 2: Recommended Elliptic
Curve domain parameters, Standards for efficient
cryptography, September 20,2000
[5] V. Miller, ―Uses of elliptic curves in cryptography‖,
Advances in Cryptology– Crypto’85, Lecture Notes in
Computer Science, 218 (1986), Springer-Verlag, 417-
426.
[6] Certicom Corp., ― An Introduction to Information
Security‖, No. 1, March 1997.
[7] ANSI X9.63, Public Key Cryptography for the Financial
Services Industry: Elliptic CurveKey Agreement and
Key Transport Protocols, ballot version, May 2001.
[8] Internet Engineering Task Force, The OAKLEY Key
Determination Protocol, IETF RFC 2412, November
1998.
[9] ISO/IEC 15946-3, Information Technology–Security
Techniques– Cryptographic Techniques Based on
Elliptic Curves, Part 3, Final Draft International Standard
(FDIS), February 2001
[10] M. Jacobson, N. Koblitz, J. Silverman, A. Stein and E.
Teske, ―Analysis of the xednicalculus attack‖, Designs,
Codes and Cryptography, 20 (2000), 41-64.
[11] S. Arita, ―Weil descent of elliptic curves over finite
fields of characteristic three‖, Advances in
Cryptology–Asiacrypt 2000, Lecture Notes in Computer
Science, 1976 (2000),Springer-Verlag, 248-259.
[12] Fernandes, A. ―Elliptic Curve Cryptography‖, Dr.Dobb’s
journal, December 1999
[13] J.Solinas, ―An improved algorithm for arithmetic on a
family of elliptic curve‖, Advances in Cryptology -
CRYPTO '97, Lecture Notes in Computer Science, 1997,
Volume 1294/1997, 357-371, DOI:
10.1007/BFb0052248 ,1294(1997). Springer-Verlog,
357-371
[14] J.Solinas,‖ Efficient arithmetic on koblitz Curves‖,
Design codes and cryptography, 19(2000), 195-249
[15] Huffman, David (1952) ―A Method for the Construction
of Minimum Redundancy Codes,‖ Proceedings of
the IRE 40(9):1098–1101.
[16] O.Srinivasa Rao, S.Pallam Setty, ―Efficient mapping
methods of Elliptic Curve Crypto Systems‖ International
Journal of Engineering Science and Technology, Vol.
2(8), 2010, pp. 3651-3656
[17] M.Prabu, R.Shanmugalakshmi ―A Comparative and 
International Journal of Computer Applications (0975 – 8887)
Volume 14– No.5, January 2011
49
Overview Analysis of Elliptic Curve Cryptography over
Finite Fields‖2009, International Conference on
Information and Multimedia Technology, IEEE
computer society.
[18] Billy Bob Brumley and Kimmo U. Jarvinen, Member,
IEEE ―Conversion Algorithms and Implementations
for Koblitz Curve Cryptography‖, IEEE Transactions on
computers Vol.59, No.1, January 2010
[19] Yong-hee Jang, Yong-jin Kwon ―Efficient Scalar
Multiplication Algorithms Secure against Power
Analysis Attacks for Koblitz Curve Cryptosystems‖
2010, 10th Annual International Symposium on
Applications and the Internet, IEEE Computer Society
[20] Chang Shu, Soonhak Kwon, and Kris Gaj
―Reconfigurable Computing Approach for Tate Pairing
Cryptosystems over Binary Fields‖ IEEE Transactions
on computers Vol.58, No.8, September 2009

