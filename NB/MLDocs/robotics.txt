* Corresponding author. Tel.: +1 (217) 333-2854; fax.: +1 (217) 244-0323. E-mail address: grift@uiuc.edu (T. Grift) A review of automation and robotics for the bio-industry Tony Grift a, *, Qin Zhang a, Naoshi Kondo b, K.C. Ting a aDepartment of Agricultural & Biological Engineering, University of Illinois, Urbana-Champaign, 360J Agricultural Engineering Sciences Building, 1304 West Pennsylvania Avenue, Urbana, IL 61801, USA. bKyoto University, Kyoto, Japan. Abstract Automation technology research in agriculture is proliferating throughout the globe. There are several trends that drive the application of automation technology in agriculture. Firstly, by the year 2042, the world population is projected to increase to 9 billion souls. There will be a huge challenge in providing abundant high quality, affordable, safe and nutritious foods for such population, especially in light of the trend to use arable land for bio-fuel production. Secondly, the labor force in agriculture is declining and automation technology can be used to replace some traditional labor. For instance, in specialty crop production labor is often tedious, non-ergonomic and carried out by unskilled personnel. Automation technology can improve the productivity, health and job-satisfaction of personnel, but there are serious technical challenges in automating operations especially in horticulture and viticulture. Thirdly, the environmental impact of Agricultural production needs to be limited. For instance, today worldwide seven weed species have been identified as being resistant to glyphosate. The only truly sustainable solution for this problem is high-speed mechanical weed control which is under development. Although automation technology holds ample promise for the future, currently the overall performance of the machines is often insufficient to compete with traditional methods. The limited performance of the machinery is one of the reasons why to date few of the technologies developed have been commercialized. However, the role of automation technology will increase and its impact on agriculture as we know it will be profound. This paper describes agricultural automation research in areas that typically constitute automated systems, being 1) Sensing and perception, 2) Reasoning and Learning, 3) Data Communication and 4) Task planning and execution. A separate section is devoted to Robotics www.tibm.org.tw Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 38 T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 applications within plant production, animal husbandry, controlled environment as well as field robotics. 1. Introduction The development of agriculture in traditional hunter-gatherer societies started around 10,000 years ago and has been crucial to the formation of human civilizations across the globe. Over the centuries agriculture has morphed into the modern large-scale bio- industry it is today, producing goods through the growing of plants, animals and other organisms in close interaction with the environment. The major changes in agriculture have occurred through domestication of crops and animals, weed control techniques, water management, fertilizer/pesticide application, genetic engineering and the large- scale mechanization that occurred in the middle 1990s. Although the improved methods and techniques over time have resulted in a global system capable of feeding 6 billion souls, it has also caused major concerns regarding its impact on the environment. In addition, owing to the recent worldwide attention to energy security as well as climate change, agriculture is projected as the supplier of bio-energy from renewable sources, opening up a new realm of opportunity and responsibility. Some of the issues facing agricultural production today include (1) managing and utilizing resources in the production while ensuring a sustainable natural environment; (2) laborious operations under conditions not conducive to human productivity; (3) advancement of technologies in other industries that threaten to attract labor force away from agriculture; (4) an increased demand for higher product quality; (5) the necessity to modernize agriculture using technology; (6) the trend towards organic farming and (7) to employ human intelligence and machine power in a sustainable and economical manner. The application of automation technology plays a role in all these issues: It can contribute to sustainability by providing field information through sensing, and to offer optimization tools. Robots are being developed to replace manual labor in the harvesting of fruits and vegetables. Weeding robots can replace chemical herbicide application in organic farming. Automation technology inherently addresses the issue of a dwindling labor force. The current plant factories in Japan produce high quality vegetables, free of disease or insect damage and are run with little human intervention. It is evident that automation technology is a field that can offer significant benefits to producers and consumers in the near future. Before addressing the (potential) applications of automation in agriculture it is useful to state a definition: The term automation signifies the added quasi-anthropomorphic intelligence to mechanized processes and/or devices (Ting, 1997). The capabilities of intelligence-enabled machines include: (1) Sensing and perception obtaining the awareness of surroundings; i.e., gathering, processing, and interpretation of information about situations, (2) Reasoning and learning  conducting logical deduction, mathematical analysis, heuristic inference, and experiential adaptation used to derive conclusions, make decisions, and issue instructions, (3) Communication  coordinating and delivering information among various entities (4) Task planning and execution  T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 39 effecting device operations for control activation and physical work. Commonly seen additional components are external sensing, transporting, and traveling devices (Kondo and Ting, 1998). This article provides a review of past and current research and development in automation technology for the bio-industry. 2. Sensing and perceptions The aim of agricultural production managers is to optimize crop yield and consequently profit. Therefore, the crop needs to be protected against common biotic stresses such as diseases, insect infestations, and competition from weeds as well as a- biotic factors such as nutrient and water stress. Precision crop nutrition management has been the traditional tool to achieve optimized yield and it requires accurate and reliable information about the soil and crop conditions. Important soil parameters that need to be measured are moisture level, nitrogen level, pH, compaction levels and organic matter content. Ehsani et al. (1999) developed a Near Infrared (NIR) based technique to measure the nitrogen content of the soil. To assess the depth and strength of a compaction layer Grift et al. (2005a) developed an acoustic method in a laboratory setting and Adamchuk et al. (2001) developed a strain gage based method to measure soil mechanical impedance. Electrical Conductivity (EC) has been used extensively as a proxy measurement for soil fertility which is related to organic matter (Fraisse et al., 2001; Mueller et al., 2003). EC sensors in combination with pH sensors are commercially available. In standing crops there is a need to measure and assess nutrition level, disease and pest infestations, bacterial/viral infections, overall plant health and the proliferation of weeds. Among these, weed proliferation monitoring is easiest: it can be based on morphological properties, such as shape, size and color using cameras. CCD (charge coupled device) cameras have been applied successfully for detecting weeds in soybean fields (Tian, 2002) and in cotton fields (Downey et al., 2003). In weed management, there are currently two schools of thought being weed detection, where the crop plants are detected and all other plants are considered weeds and weed identification. The latter is becoming increasingly important, since there are currently several weed species that have shown resistance to glyphosate, the main ingredient in Roundup, a popular herbicide in the United States. The most threatening resistant species is common waterhemp (Amaranthus rudis) and tall waterhemp (A. tuberculatus), collectively referred to as waterhemp. This species has shown resistance to protoporphyrinogen oxidase (PPO)- inhibiting herbicides as well as ALS-inhibiting and triazine herbicides (Patzoldt et al. 2005). This waterhemp biotype uses a unique mechanism of resistance to survive exposure to PPO herbicides (Patzoldt et al. 2006). For weed identification algorithms are used such as artificial neural networks (ANNs), (Burks et al., 2000) genetic algorithms (Tang et al., 2000) and wavelets (Tang et al., 2003). The emergence of weeds that exhibit resistance to herbicides will require the development of high-speed mechanical in-row weed control technology which is in development. On-board imaging systems have also 40 T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 been used for plant counting to accurately estimate the corn population in an early growth stage (Shrestha and Steward, 2003). The use of multispectral-image-based perception methods has been studied extensively to assess the crop nutrition level based on crop canopy reflectance in multiple spectral bands (Kim et al., 2000; Sui et al., 2005). Remote sensing, which uses multi and hyper-spectral imagery originating from satellites (Yang et al., 2004); airplanes (Yao and Tian, 2004) or helicopters (Sugiura et al., 2002), has been used to assess crop nutrition stress. After comparing the Normalized Difference Vegetation Index (NDVI) calculated using both satellite- and aerial-based crop canopy images Han et al. (2002) found that both methods were highly correlated to ground truth data when crop conditions were relatively heterogeneous across a field. When the crop conditions were more uniform, the correlation decreased significantly. Though aerial and satellite imageries are useful for research, both require extra expense to farmers since up-to-date images must be purchased annually. Alternatively, on-board systems are in development that can provide the farmer with up-to-date imagery in time and space. Kim et al. (2000) and Noh et al. (2005) developed on-board systems for real-time detection of nitrogen concentrations in corn plants to enable variable-rate fertilization. Both systems were based on NDVI estimation in terms of light reflectance intensity on leaves in various spectral bands. Reum and Zhang (2007) describe an innovative approach enabling more sensitive detection of crop nutritional stress levels. They represented the reflectance of corn leaves images in terms of a one-dimensional intensity distribution pattern in specific signal bands, after which they applied a wavelet transform to map the resulting patterns to various crop nutritional stress levels. This method offers a more accurate crop nutrition level perception since it is capable of making such an assessment based on individual plant data. Crop diseases require early detection to prevent potential widespread crop losses. The difficulty in detecting infections at an early stage also results in excessive use of pesticides and increased production costs (Sasaki and Suzuki, 2003). Conventional detection of disease infection is based on visual inspection, which is often too late to prevent damage. With the increased application of optical sensing technologies in agriculture, researchers have attempted various approaches to detect crop diseases and viral infections at an early stage. One of such approaches is the measurement of radiation reflectance intensity from plant leaves over a wide spectrum. This method is based on the fact that many kinds of diseases and viral infections cause a change in optical reflectance properties of the leaf surface, often resulting in an increase of reflectance in the visible bands (West et al., 2003). Examples of disease and virus infections using this approach include detection of Puccinia striiformis in wheat (Bravo et al., 2003), the Botrytis fabae (Chocolate spot disease) fungus infection in field beans (Malthus and Madeira, 1993), and Late Blight in tomatoes (Wang et al., 2008). Other commonly used crop disease sensing technologies include fluorescence and thermal imaging, which can extend and improve the capability of various crop disease sensing techniques. Arguably the largest number of CCD based cameras is applied in the product quality inspection stage. In a recent citrus fruit grading system, 6 color cameras were applied to measure color, size, shape, and defects on the top, bottom, and 4 lateral sides of a fruit T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 41 (Njoroge, et al., 2002). Near infrared (NIR) inspection has been used to enhance the fruit market value because it can determine not only sugar and acid contents but also internal qualities such as rotten core, black heart, maturity, tannin, and cavity (Lu and Ariana, 2002). In addition, X-ray imaging systems have been used to inspect internal structural defects such as rind-puffing and the granulation status of the juice sacs (Njoroge, et al., 2002). Recently, X-ray sensors were also used for kiwi fruits, apples, pears, peaches, persimmon, potatoes, melons and other fruits (Tao et al., 1990; Miller and Delwiche, 1991; Kondo, 2003). To measure the degree of gloss on whole eggplant fruit surfaces, 10 cameras (6 color and 4 monochrome) were installed in a grading facility at Okayama, Japan (Kondo et al., 2007a). Proper lighting is an essential component of any machine vision system. Since bio-products have varying optical characteristics in various spectra, many types of imaging techniques and devices have been developed, from the visible region to X-ray, UV, and infrared regions. The latest technologies use Terahertz (THz) imaging through the development of new light sources and detectors (Hu and Nuss, 1995; Kawase et al., 2003). In addition, nuclear magnetic resonance (NMR) technology has been also applied to bio-products (Chen et al., 1989; Song and Litchfield, 1990; Wang et al., 1988). Whereas hyper-spectral images are effective for food quality and safety monitoring, fluorescent imaging can aid in the detection of defects in fruits, plants, and meats (Bodria et al.,2002; Kim et al., 2001; Kim et al, 2004; Kondo et al, 2007b). Another application of optical perception technology is the guidance of robotic equipment. In the early 1980s, a research team at Michigan State University, USA, studied the potential of acquiring tractor guidance information from field images by evaluating several image processing techniques (Gerrish and Stockman, 1985). Their effort led to the development of a vision-guided tractor capable of following straight crop rows with an accuracy of 6 to 12 cm (Gerrish et al., 1997). In the same period, a Texas A&M University, USA, research team investigated a novel approach of steering a tractor following both straight and curved row crops. It demonstrated through field tests that their algorithm could detect heading errors within 0.5 and offset errors of less than 5 cm (Reid and Searcy, 1986). In the late 1990s, a team of the University of Illinois, USA, developed a research program on path perception technologies for autonomous agricultural equipment. Some of the early achievements included the use of redundant navigation sensors by fusing machine vision sensing with GPS and inertial sensor data. The combination of sensors provided reliable navigation information for guiding agricultural equipment performing various field tasks at normal operation speeds. Vision- based path perception was used to guide agricultural tractors performing field operations at speeds of up to 17 km/h on straight rows and up to 10 km/h on curved rows (Zhang et al., 1999; Will et al., 2000; Han et al., 2004. The sensor fusion-based path finder methods for guiding agricultural equipment all achieved a tracking accuracy of 2.5 cm at typical speeds (Han et al. 2003; Zhang and Qiu, 2004). To improve the accuracy of object localization within the perceived scene under quickly varying light conditions, the research team also successfully used stereovision for to guide tractors performing field operations (Rovira-Ms et al., 2004; Kise et al., 2005a). Benson et al., (2003) 42 T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 demonstrated a vision-based guidance system that uses the edge of the cut-uncut crop for guidance of a combine harvester at normal operating speeds. Some other advancements on robotic equipment navigation perception technology researches include the work reported by Subramanian et al. (2006) who used a monocular camera to observe citrus grove alleyways, and Nara and Takahashi (2006) who applied a vision system to detect obstacles. However, little has been reported on using vision-based navigation to guide agricultural vehicles traveling in an open field without structured crops as landmark references. The challenge in using visual sensor to navigate a vehicle traveling on an open terrain is to find and utilize landmark points from unknown and randomly present textures. In contrast there are examples of guiding robotic vehicles on planetary-like terrains (Gonzalez-Barbosa and Lacroix, 2002), on urban streets (Saeedi et al., 2006), and agricultural fields (Wang and Zhang, 2007). In most of these researches, stereo cameras were used to perceive the environment because of their ability to provide 3D information. Furthermore, stereovision has important advantages for robotic equipment navigation in a natural environment, including moderate insensitivity to shadows and lighting changes and the capability to detect obstacles. To navigate autonomous vehicles in fields, in addition to optical sensors, laser range finders have been used. To navigate an autonomous vehicle between tree rows, Barawid et al., (2007) reported on the successful development of a laser range finder based guidance system, using the Hough transform to recognize the trees. Laser range finder technology was also used as a real-time collision avoidance sensor in agricultural fields (Kise et al., 2005b). Lee and Ehsani (2008) investigated the accuracy of two common laser range finder units. 3. Reasoning and learning The Internet has made information sources readily available, but the question how to use information intelligently is still a major research interest. In order to enable intelligence empowered bio-production systems, capabilities are required for automated data processing, logical/mathematical/heuristic reasoning, and experiential learning. Commonly seen machine reasoning and learning processes are in the forms of computer models, expert systems, artificial neural networks and decision support systems (Fang et al., 1992; Humphreys et al., 1994; Chao and Ting, 2003; Fleisher et al., 2002). Systems informatics and analysis is the branch of science and engineering that develops tools to gather, store, retrieve, analyze, present, and interpret information to aid in the process of decision-making (Snow and Lovatt, 2008; Krner and Van Straten, 2008; Matthews et al., 2008). A system is a set of interrelated components organized to achieve certain goals. The systems paradigm emphasizes the performance of a system as a whole through understanding all components in the system, as well as the interrelationships among the components (Lejars et al., 2008). The importance of the systems approach arises from the fact that (1) individually functioning components do not necessarily constitute a working system, (2) piece-wise knowledge about individual components does not automatically provide a complete understanding of the overall system, and (3) necessary yet missing components can be detected after observing/analyzing the system as a whole. T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 43 The challenges in the integration of scientific information are as follows: (1) Many scientists have been very successful within their well defined disciplinary boundaries and it is not clear to individual scientists, why active participation in the effort of information integration is of any value; (2) the concept of systems analysis has not received the attention it deserves in the agricultural research community and the mechanism of systems analysis is perceived as frightening; (3) the tools used for systems analysis are mostly not user-friendly and incapable of dealing with dynamically changing information bases in a real-time fashion; (4) the integration of information from traditionally unrelated fields, such as life science and engineering, is likely to encounter new challenges; (5) the assumptions of systems analysis and methods of handling uncertain and incomplete information are not transparent; (6) it is difficult to balance analysis and action (Ting et al., 2003). In order to successfully address the issues and solve the problems associated with agricultural production systems, core competencies of automation, culture, environment, and systems (i.e., the ACESys paradigm) are required. The culture (i.e., biosciences and biotechnologies) and environment set the governing conditions under which agricultural operations take place. Automation deals with information processing and task execution, and often plays the role of integrator for a functional system. Automation adds to machines the quasi-anthropomorphic capabilities of perception, reasoning & learning, communication, and task planning & execution. Systems analysis and integration is a methodology that starts with the definition of a system and its goals and leads to the conclusion regarding the systems workability (i.e., technical feasibility and practicality), productivity, economic viability, reliability, and other performance indicators for decision support purposes. Computers, with their vast storage capacities for data and algorithms and high-speed information processing, have brought about ever increasing possibilities for effective automation, with high precision, for agricultural systems (Ting, 2000). The ACESys concept is very useful in determining the abstraction (in the forms of foundation classes representing objects of interest) and information flows for bio- production systems. This systems abstraction technique may be applied to any bio- production system. The resulting foundation classes may represent the system components in as much breadth and depth as needed. The major difference will be the culture classes and objects. For example, if a controlled environment plant production system is under study, objects and classes that describe plant biological characteristics and processes will need to be developed and incorporated in the appropriate automation and environment (Fleisher et al., 1999; Ting and Sase, 2000). 4. Data communication Communication technology is an essential component of automation in agriculture since it provides information flows among intelligent machines and human interfaces (Zhang and Ehsani, 2007). The convergence of sensing, computing and communication technologies for agricultural applications can be termed an agricultural infotronics systems (AIS), essentially a real-time network topology connecting all on-farm production data management systems (Zhang et al., 2000). 44 T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 In-vehicle communication has been standardized in the Controller Area Network (CAN), a serial two-wire multi-node message broadcast system with a maximum signaling rate of 1 Mbit per second. CAN is now common on many types of agricultural machinery, and the data communication protocol used is ISOBUS, standardized in ISO 11783. An overview of the Controller Area Network can be found in Etschberger (2001) and Benneweis (2005) provides an overview of the status of the ISO 11783 standard. Although there is great interest in inter-vehicle communication to optimize the performance of machines working in cooperative systems such as in large-scale harvesting operations, there is no communication standard available for this purpose. Wireless data communication can be implemented using the common Local Area Network (LAN) such as WiFi (IEEE 802.11.b), or a Personal Area Network (PAN) such as BlueTooth (IEEE 802.15.1), a low-power, short-range wireless industry standard often used to connect sensors to Electronics Control Units (ECUs) within a short range (Zhang and Ehsani, 2007; Kim et al., 2006). A strong alternative to the short-range BlueTooth is Zigbee (IEEE 802.15.4) and Zigbee Pro, the latter having an outdoor range specification of 1500 m. Since Zigbee is a multi-node network the range can be extended indefinitely by using intermediate nodes and information relay nodes. Zigbee is currently used in viticulture for distributed data acquisition (Morais et al., 2008) as well as animal tracking (Nadimi et al., 2008). An overview of Zigbee wireless data communication technology is given in Hebel, (2007). Another class of wireless data communication devices is Radio Frequency Identification (RFID). These devices consist of small tags which are used for human, animal and product tracking applications (Sahin et al., 2002). A complete overview of wireless sensor applications in agriculture and food industry is given in Wang et al., (2006). 5. Task planning and execution Task planning and execution are essential functions of a highly automated machine. For instance, an assembly robot with an arm and gripper needs to have enough intelligence to automatically synthesize a manipulation plan when presented with randomly oriented parts (Tung and Kak, 1996). In agricultural robot applications the planning and execution task are usually far more complicated than their counterparts in industrial robotics, since the objects to be handled are usually unstructured and presented in random locations such as in cucumber harvesting (Van Henten et al., 2003). Similarly, in field robotics, an autonomous weeding robot has a set of actions it can perform to move itself around a field such as turn left,backup, and extend effector. To perform an overall task such as weeding, the robot must follow a sequence of subtasks in a certain order. This order may be fixed or adaptive: In the latter case the order must be decided by an intelligent algorithm that takes into account the environment through sensors and plans tasks according to a certain optimization criterion. Jorgensen et al. (2008) showed planning algorithms written in a scripting language to guide a weeding robot in a realistic field. Greenhouse control is another area where task planning is needed to achieve goals such as a target harvest date (Albright, 1990). T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 45 6. Robotics Robotics in Agriculture is not a new phenomenon: In controlled environments it has a history of over 20 years. However, with the latest increase in computational power combined with a cost reduction, robotics applications are spreading. For convenience, we will categorize the applications in plant oriented robotics, animal robotics, controlled environment robotics (green houses) as well as field robotics. 6.1. Plant production The study of agricultural robot application for plant production presumably started with a tomato harvesting robot (Kawamura et al., 1984). Currently there are automated harvesters in the research phase for cherry tomatoes (Kondo et al. 1996a), cucumber (Van Henten et al., 2002), mushrooms (Reed et al., 2001), cherry (Tanigaki et al., 2008) and other fruits (Kondo et al., 1996b). In horticulture, robots have been applied to harvest citrus (Hannan and Burks, 2004) and apples (Bulanon et al., 2001). So far, no harvesting robot has reached the stage of commercialization, because of their low operation speeds, low success rates, and high costs. A recent robot which is the closest to commercialization may be a strawberry harvesting robot (Kondo et al., 2005). The robot operates during night time and harvests fruits hung from the sides of a table top culture in approximately 20 second, yielding a harvest capacity of 0.3 ha greenhouse per night. In seedling production, there are many operations such as seeding, thinning, grafting, cutting sticking, transplanting, and others. Some of them are automated and robotized, while some robots have been commercialized with cell trays in the 1990s. A seedling transplanting system was developed (Ting et. al., 1990a) based on a 4 Degree Of Freedom (DOF) SCARA robot and a sliding-needle type end-effector (Ting et. al., 1990b). Later Yanmar Co., Ltd., Japan started selling a four fingered robotic transplanter which transplants seedlings from a cell tray to pots using a Cartesian coordinate manipulator. Visser company, the Netherlands also produces a type of transplanting robot which uses machine vision and end-effectors to replace defective seedlings. The former and the latter robots have capacities of handling 6000 seedlings/h and 4500 seedlings/h respectively. The cutting/sticking operation is often conducted for seedling propagation where individual leaves are cut from the mother plant, and placed inside a tray in which they grow to full plants. A chrysanthemum cutting/sticking robotic system consisting of machine vision and a manipulator was developed at Okayama University (Kondo and Monta, 1997). Based on the experimental results, a fully automatic model and a semi- automatic model for commercialization were developed by Panasonic company and Iseki Co., Ltd. The fully automatic robot was capable of sticking a cutting in 5 to 6 seconds. Another type of cutting/sticking robot was developed for geranium at the University of Georgia, USA (Simonton and Pease, 1990). The grafting operation ensures higher quality production and disease resistance to seedlings. Although a semi-automatic grafting robot which could process 800 cucumber seedlings was commercialized by many companies 15 years ago (Kondo and Ting, 1998), 46 T. Grift et al. / Journal of Biomechatronics Engineering Vol. 1, No. 1, (2008) 37-54 two operators were required to service the robot, and it is desirable to fully automate the operation. The plant factory arguable constitutes the pinnacle of automation technology in plant production. It is a highly automated facility where vegetables and fruits can be produced with minimal human intervention in an environment free of disease, insects and the risk of mechanical damage. Mitsubishi Heavy Industry Company and Kyushu Electric Company (Mitsuhashi et al., 1994) attempted to build a fully automated plant factory which contained automatic machines and environments for seeding, germination, seedling nursery, transplanting, seedling spacing, harvesting and packaging. The production sequence was as follows: A seeding device places coated seeds into twelve holes of a urethane cube shaped by a cutting device. The seeded tray is then transported to a germination platform where it is irrigated at regular intervals. After germination, the seedling is transported to a nursery platform where it is grown under controlled artificial lighting in a hydroponic solution. When the seedling has matured sufficiently, a transplanting device picks up the urethane cube with the seedling and places it into a growing bar using four fingers. This growing bar method was adopted so that the space among the seedlings can be varied in relation to the growth stage of the seedlings. When the seedling has grown to full maturity, the growing bars are transported to the harvesting machine, which cuts the roots after which the plants are weighed and wrapped in a film. The capacity of the system is equivalent to four operators, because the devices in the system can work for a total of 33 person hours a day, where the system produces 1500 vegetables per day. The breakdown of the 33 hours is 8% for seeding, 12% for transplanting, 27% for spacing, 30% for harvesting and wrapping, 11% for washing materials and equipment, 9% for shipping, and 3% for seedling nursery. 77% of the 33 hours is automated, while the remaining 23% for the latter three items is conducted manually (Kondo and Ting, 1998). 6.2. Animal husbandry Milking is the most laborious task in dairy cattle husbandry. In The Netherlands, two types of robot milking systems are on the market (Kuipers, 1996). In both systems the robot is stationary the cows have to visit a milking box where they are milked and fed simultaneously. The attachment of teat cups in one system was based on teat locations stored a priori in a computer, combined with a vision system and the teat cups were attached simultaneously. The other system employed a robotic arm that was positioned below the udder and ultrasonic sensors were used to determine the locations of the teats. After these locations are determined, the teat cups are attached individually (Hogewerf et al., 1992). There are currently companies selling the milking robots in The Netherlands, Germany, Sweden, USA, and Japan. Developmental research on autonomous milking systems for stanchion barns has been conducted as well (Hachiya et al., 1996). In this system the animals remain stationary while the milking robot moves along a gantry system. To reduce the cost of wool harvesting, two types of wool shearing robot systems were developed at the University of Western Australia (Trevelyan, 1992) and at the Australian Wool Corporation (Australian Wool Corporation, 1988). Since sheep are easily damaged

1
Fuzzy Constraint Satisfaction Approach for
Landmark Recognition in Mobile Robotics
∗
Abraham Otero
a
,
∗∗
,PauloF ́
elix
a
Carlos Regueiro
b
Miguel Rodr ́
ıguez
a
and
Sen ́
en Barro
a
a
Department of Electronics and Computer
Science. University of Santiago de Compostela.
15782 Santiago de Compostela, SPAIN. E-mail:
{
abraham, paulo, mrodri, senen
}
@dec.usc.es
b
Department of Electronics and Systems.
University of A Coru ̃
na. 15701 A Coru ̃
na,
SPAIN. E-mail: cvazquez@udc.es
This work deals with landmark recognition in mobile
robotics, using a new model based on Constraint Satis-
faction Problems (CSP): the Multivariable Fuzzy Tem-
poral Profile model (MFTP). A representation sup-
ported by CSPs makes it possible to capture a morpho-
logical description of the patterns that landmarks give
rise to on sensor readings. Its representation, based
on Fuzzy Set Theory, allows the imprecision and un-
certainty that are characteristic of the problem to be
handled. The work places special emphasis on those
aspects that are resolved by means of this approach:
the ability to model semantically rich landmarks, the
simplicity of its description, and the high computa-
tional efficiency of the proposed detection algorithms.
Finally, a validation of the model in the detection of
various landmarks over ultrasound (US) sensors is pre-
sented. In spite of these sensors being highly noisy and
imprecise, the MFTP model successfully detects 95%
of the landmarks on the reference wall.
Keywords: Landmark recognition, constraint satisfac-
tion  problems,  data  fusion,  fuzzy  sets,  autonomous
navigation
*
This work was supported by the Spanish CICYT and
Xunta  de  Galicia  through  grants  TIC2003-09400-C04-03
and PGIDT04SIN206003PR, respectively.
**
Corresponding  author:  Abraham  Otero,  Electronics
and Computer Science. Universidade de Santiago de Com-
postela. 15782 Santiago de Compostela, SPAIN.
1. Introduction
The autonomous navigation of a mobile robot
requires having a representation  of the environ-
ment in which the robot has to move. Obtaining a
high quality representation is a complicated task
[12,21,29]. On one hand, the sensors used to per-
ceive an environment have a limited range, which
forces the robot to move to build up a complete
representation, introducing odometric errors into
the measurements. On the other hand, these sen-
sors usually have a high level of noise, which gives
rise to an inadequate and even erroneous percep-
tion of the environment. Furthermore, the envi-
ronment  may  have  dynamic  characteristics,  and
the robot must deal with its representation in real
time.
This representation can be drawn up by identi-
fying certain elements from the environment, re-
ferred to in the bibliography as landmarks or bea-
cons. Any relevant object in the environment that
can be recognized in a robust and reliable manner
can be considered to be a landmark. A landmark-
based representation of the environment incorpo-
rates an abstraction operation over the perceived
information, allowing the representation to be sim-
plified  and  structured;  it  projects  the  informa-
tion in symbolic terms, which simplifies the res-
olution  of  high-level  tasks,  such  as  planning  or
communication with humans. In the bibliography,
two types of landmarks can be distinguished: on
one hand, some authors define landmarks with a
low semantic content, but which are easily iden-
tifiable  (e.g.,  flat  surfaces,  edges,  cylinders,  etc
[7,15,27,28,33]), while others use landmarks with
a greater semantic content, but which are more
difficult to identify (e.g., doors, corners, corridors,
etc. [2,14,16,18,26]). In general, the latter are the
most useful, as their higher semantic content aids
in  defining  and  reasoning  about  the  topological
structure of the environment. Another factor to
be taken into consideration for evaluating the use-
AI Communications
ISSN 0921-7126, IOS Press. All rights reserved
2           A. Otero et al. / Fuzzy Constraint Satisfaction Approach for Landmark Recognition in Mobile Robotics
fulness of a landmark is whether it is common to
a large number of environments, since the more
environments have this landmark the more gen-
eral the navigation system upon which it is based
will be. In indoor environments, corridors, which
contain information that is essential for naviga-
tion, and doors, which connect the different places
of the environment, are probably the most useful
landmarks, as besides bearing valuable topologi-
cal information, they are common to almost all in-
door environments. Doors have an additional char-
acteristic that makes them even more interesting:
in the majority of indoor environments they are
the most common landmark, and thus can be very
helpful for localizing mobile robots. For example,
a short trajectory in a given corridor may be suf-
ficient for door-based localization, while corridor-
based localization may require the robot to travel
a considerable distance through a number of cor-
ridors.
The  bibliography  shows  the  use  of  different
types  of  sensors  for  landmark  detection:  sonar,
laser  [20,32],  and  video  camera  [5,9].  The  most
frequently-used  sensors  in  mobile  robotics  are
sonar belts [4,10], where each sensor measures the
distance to an obstacle in the environment. The
widespread use of these sensors is due principally
to their low cost, simplicity and low energy con-
sumption;  nevertheless,  their  measurements  are
greatly affected by noise, and are highly imprecise,
which  severely hampers their use in recognition
tasks. It is possible to obtain more precise mea-
surements of the environment, with less noise, us-
ing laser sensors; the downside is their high cost,
which makes them unadvisable if a low-cost robot
is aimed for, and their high energy consumption,
which can severely curtail the robot’s autonomy.
Video cameras allow large quantities of informa-
tion to be extracted from the environment, but
making use of all this information implies a high
computational load.
In  this  work  we  use  the  Multivariable  Fuzzy
Temporal  Profile  model  (MFTP),  a  new  model
that is based on the Constraint Satisfaction Prob-
lem (CSP) formalism [8], and on the Fuzzy Set
Theory [35], to detect landmarks over the sensors
of mobile robots. We have applied this model to
the recognition of landmarks over sonar sensors,
to show the model’s capability of handling noisy
signals. The MFTP model makes it possible to de-
scribe the patterns produced by landmarks on the
sensor signals, and to project them into a com-
putable representation, which is used to identify
the pattern, and thus the landmark, over the sen-
sor readings. We have developed a tool that per-
mits the description and validation of the pattern
over the sensor readings, and a software applica-
tion that works as a client of the robot, enabling
real-time identification of landmarks.
This paper is structured as follows: in the next
section the problem of sonar landmark detection
is  described,  and  the  most  relevant  approaches
from the bibliography are appraised. Section 3 ex-
plains the MFTP model, the matching process and
how MFTP is capable of modelling patterns cor-
responding to different landmarks that are com-
mon in indoor environments. Section 4 shows the
experimental results obtained for the Nomad 200
and Pioneer AT robots in different environments,
and these results are discussed in section 5. Finally,
in section 6 the most relevant conclusions of this
work are presented, along with its possible future
extension.
2. US based landmark-detection: related work
The operation of US sensors is based on the mea-
surement of the time elapsed from the emission of
a sound pulse, of a range of frequencies, until its re-
flection off objects ahead of the sensor is detected
[19]. Based on the speed of sound, the distance to
the reflecting objects can be calculated. These sen-
sors are inexpensive, simple to install, relatively
precise, light, and energy efficient. Nevertheless,
they do have limitations, the most important pos-
sibly being their low angular resolution, since the
pulses are emitted forming a conical beam of ap-
proximately 10
o
. Moreover, very smooth surfaces
or highly oblique angles of incidence may give rise
to specular reflections and hinder the detection of
the object. On occasion, the reflected beam col-
lides with another new object, giving rise to a dis-
tance that is greater than the true one. An addi-
tional problem is
crosstalking
: a beam emitted by
one sensor may be received by another one. This
can be minimized by following certain sensor trig-
ger patterns.
All these problems result in sonar readings hav-
ing high levels of noise and imprecision, the re-
sult  of  which  is  that  there  are  few  successful
works in the literature where they have been ap-

Interval analysis for Certied Numerical Solution of
Problems in Robotics
Jean-Pierre Merlet
To cite this version:
Jean-Pierre Merlet.  Interval analysis for Certied Numerical Solution of Problems in Robotics.
International  Journal  of  Applied  Mathematics  and  Computer  Science,  University  of  Zielona
Gora Press, 2009.
<
inria-00362431
>
HAL Id:  inria-00362431
https://hal.inria.fr/inria-00362431
Submitted on 18 Feb 2009
HAL
is   a   multi-disciplinary   open   access
archive  for  the  deposit  and  dissemination  of  sci-
entic research documents, whether they are pub-
lished  or  not.    The  documents  may  come  from
teaching  and  research  institutions  in  France  or
abroad, or from public or private research centers.
L'archive ouverte pluridisciplinaire
HAL
, est
destinee au dep^ot et a la diusion de documents
scientiques de niveau recherche, publies ou non,
emanant des etablissements d'enseignement et de
recherche  francais  ou  etrangers,  des  laboratoires
publics ou prives.
Int. J. Appl. Math. Comput. Sci., 2008, Vol. , No. , –
DOI:
INTERVAL ANALYSIS FOR CERTIFIED NUMERICAL SOLUTION OF
PROBLEMS IN ROBOTICS
J-P. M
ERLET
INRIA,2004 Route des Lucioles, 06902 Sophia-Antipolis,Fr
ance
nd
nite
round-o
e
ien
Keywords:
1.  Introduction
We will consider in this paper robotized systems whose
main purpose is to manipulate objects, although many
other objectives may be assigned to such systems. A first
important componentof the robot is its
end-effector
which
will grasp the object.  The
pose
of the end-effector is
defined as a set of parameters that allows one to deter-
mine what is the location/orientation of the end-effector
in its surrounding world.  For that purpose a reference
frame
R
f
= (
O,x,y,z
)
is defined, while a mobile frame
R
m
= (
C,x
r
,y
r
,z
r
)
is attached to the end-effector. A
possible set of parameters for defining a pose is first the
three coordinates of the point
C
of the end-effector and
three angles (such as the Euler’s angles) that allows one
to define a rotation matrix
R
between the vectors of the
mobile frame and those of the reference frame. The end-
effector is thus considered as a rigid body and it is well
known that in the 3D space the minimal number of param-
eters necessary to define the location/orientation of this
body is 6. The objective of a robot manipulator is to con-
trol all or part of the possible motion of the end-effector,
called its
degree of freedom
. If a robot allows to control
all possible motion of the end-effector it will be called a 6
degrees-of-freedom robot or 6 d.o.f. robot for short. For
some tasks it is not necessary to control all motion: for ex-
ample a crane that moves an object only along the
x,y,z
axis without offering the possibility of changing its orien
-
tation is a 3 d.o.f. robot.
In order to control the d.o.f. of the end-effector a
robot manipulator has a mechanical structure, i.e. an ar-
rangement of
joints
and
links
. A link is a rigid body that
connect two (or more) joints. A joint allows for relative
motion between two links that are connected to it.  In
robotics the most frequently used joints allows only one
possible type of motion between the links, for example a
2
J-P. Merlet
rotation around a given axis for
revolute joint
or a transla-
tion along a given axis for
prismatic joint
. Joints may be
passive
(they just follow the overall motion of the struc-
ture according to mechanical laws) or
actuated
: a motor
is able to modify the relative position of the links that are
connected to the joint. For actuated joints
sensors
are used
to measure the relative motion of the links.
A typical robot manipulator is the
Scara
robot pre-
sented in figure1. It has 4 d.o.f., allowingto movethe end-
effector along the
x,y,z
axis, but also to rotate it along the
z
axis.
joint
links
end-effector
Fig. 1. The 4 d.o.f SCARA robot
Its mechanical architecture is called
serial
: starting
from the ground we find a series of links and actuated
joints. If we denote by
L
a link, by
R
a revolute joint and
by
P
a prismatic joint, then the structure of the robot may
be described as
LRLRLRLP
, the end-effector being con-
nected to the extremity of the prismatic joint. All joints of
this robot are actuated and it has no passive joint.
Hence a robot is a motion generator that allows one
to modify the pose
q
of the end-effector (the objective) by
adjusting the relative position
θ
of the links of the struc-
ture using the actuated joints (the control). As we will
see most robotics problems involve the management of
the relationship between
q
and
θ
(and possibly their time
derivatives) under various constraints.
2.  Robotics and certification
Certification is a crucial issue in robotics at different lev
-
els:
•
for a better understandingof the complex behavior of
robotized systems
: simulations, even based on a the-
oretical model of the robot, should be able to present
all aspects of the possible behavior of the robot. For
example a robot may move among obstacles that
have to be avoided and a simulation system should
be able to detect all such collisions in spite of numer-
ical round-off errors
•
for critical applications
: robots may have to perform
safety-critical applications (e.g. medical robots per-
forming surgical operations) and have thus to be cer-
tified, i.e. we have to ensure that even in the worst
case the robot will behave correctly.
However, as every mechanically controlled system, un-
certainties are an unavoidable element of a robotized sys-
tem: we have manufacturing tolerances in the mechani-
cal parts, sensor measurement errors, control errors, nu-
merical round-off errors in the computer used for control
and uncertainties in the surrounding world of the robot,
to name a few. All these elements have to be taken into
account when designing and building the robot and when
controlling its motion.
Fortunately all these uncertainties have a common
feature: they may be all
bounded
, i.e.  we are able to
determine intervals for each of them so that we are sure
that the
real
value of a given parameter lie within the
interval.  Hence interval analysis is a tool that has to
be considered when dealing a robotic problem. Interval
analysis (Hansen, 2004),(Jaulin, Kieffer, Didrit and Wal-
ter, 2001),(Moore, 1979) is a numerical method that al-
lows one to solve a broad range of problems (going from
system solving to global optimization). In robotics it has
been early used for solving the inverse kinematics prob-
lem (a problem that will be developed in the next section)
for serial
6R
robot (Rao, Asaithambi and Agrawal, 1998)
but is now used for addressing other robotic problems
such as:
•
the effect of clearance on the accuracy of robots (Wu
and Rao, 2004),
•
ensuring robot reliability (Carreras and Walker,
2001),
•
mobile   robot’s   localization   and   naviga-
tion (Ashokaraj et al.,   July,  20-23,   2004),
(Clerenti et al., September, 16-18, 2003),(Kieffer,
Jaulin, Walter and Meizel, August 2000),(Seignez
et al.,  August, 2-6,   2005), and simultaneous
localization  and  mapping  (SLAM)  (Drocourt
et al., 2003),
•
planning the motion of robot (for example for avoid-
ing obstacles) (Piazzi and Visioli, 2000),
•
collision detection (Redon et al., 2004),
•
calibration (i.e. find the real value of some geometri-
cal parameters of the robot, the input being external
measurements of the end-effector pose at various lo-
cation) (Daney, Andreff, Chabert and Papegay, Au-
gust 2006)
to name a few. We will address in this paper some of
these problems and will explain how interval analysis may
provide a certified answer to them.
Interval analysis for Certified Numerical Solution of Probl
ems in Robotics
3
3.  Interval analysis
In this special issue we will assume that the basic princi-
ples of interval arithmetic have been exposed. In practice
forthe implementationwe are using the interval arithmetic
package
BIAS/Profil
1
that is widely distributed. Our
algorithms will use interval boxes (i.e. a set of intervals)
and we will assume that we are looking for a solution of
a robotics problem only within a bounded domain, called
the
search domain
, in the unknownsspace. For the sake of
simplicity we will assume that the search domain is also
defined as a box, but this assumption may be dropped at
will. In general an interval analysis algorithm may be de-
scribed as the management of a list of boxes, each box in
the list being submitted to 4 operators, namely filtering,
evaluation, existence and bisection. We will now briefly
describe the role of these operators when applied on a
given box:
•
filtering
: this operator may show, in a certified way,
that either the problem has no solution within the cur-
rent box or that only a smaller box strictly included in
the current box may contain solutions of the problem
•
evaluation
: this operator may show, in a certified
way, that the problem has no solution within the cur-
rent box or that all values of the unknowns within the
current box are solutions of the problem
•
existence
: this operator may show, in a certified way,
that there is a single solution of the problem in a box
included in the current box, solution that may be cal-
culated with an arbitrary accuracy
•
bisection
: this operator splits the current box in two
(or more) boxes by splitting one of the box interval
into two (or more) intervals whose union is the initial
interval
A box procedure manages the boxes list, which has a sin-
gle element, the search domain, when starting the algo-
rithm. It will discard from the list the boxes that have
already been submitted to the operators or have been elim-
inated by the filtering or evaluation operators and add to
the list the boxes resulting from the bisection operator. It
will also store the solution as determined by the existence
operatorand the algorithm will complete wheneverthe list
becomes empty. It may be seen that such algorithm is of
the branch and bound type, whose worst case complexity
is exponential because of the bisection process. However
the practical complexity is quite often tractable, as will b
e
seen later on.
We will now present some practical examples of the
filtering, evaluation and existence operators, applied on a
very simple example, finding the solutions of the equation

TEACHING ROBOTICS I
N
, BUILDING
A. Warszawski and H
.
Argaman
Building Research Station - Faculty of Civil Engineering
Technion
-
Israel Institute of Technology
,
Haifa, ISRAEL
1. Introduction
The possible applications of robotics to building activities
has been
receiving growing attention over the last few years.
A number
of robot
prototypes, which have
been
already developed and successfully used in
construction
sites
,
were described
in (2),(3), and other
sources. A
growing effort
is expended
,
in several
countries,
on research and
development of new
and more extensive
applications. It seems that this
trend towards
an increased
automation in building will have an evident
effect on the nature of construction operations and their
management in
future years. It is, therefore, appropriate to seriously consider an
introduction of orderly automation courses into the curricula of civil
engineering education at its various levels.
Such studies should include two types of subjects: one - the general
knowledge in the field of automation and robotics, and the other - its
application to the building construction tasks. The instruction, as is
customarily done in the teaching of industrial robotics, is divided into
lectures and laboratory
assignments
. A similar approach should be
undertaken in teaching of construction robotics.
The following paper will examine the problems of the teaching of
this subject. It will focus, in particular, on the laboratory
assignments
adapted to the special features of the building tasks.
2. The special problems in teaching of building robotics
The teaching of building robotics, as noted before, must include two
domains. The first involves the general knowledge of robotics which, of
course, forms also the basis for operation of construction robots. This
knowledge includes:
274
a. The various configurations of robots
,
their dimensions
,
performance
capacity, accuracy, etc.
b. The kinematics and dynamics of the robot arm.
c. The various types of robot effectors.
d. The robot control and intelligence on various levels.
e. The robot sensors and the energy transduction processes associated with
it.
f. The robot mobility, and the automated guided vehicles' application.
The second subject
-
the special needs of teaching in building
robotics are derived from the problems of application of robotics to
building construction
.
These problems were explored in (4), and other
sources
,
and can be summarized as follows:
a. The building work consists of a great number of interrelated tasks.
Each such task requires a separate attention from the point of view of
robotization
.
Moreover
,
most of the tasks are specifically adapted to
the capacity of the human worker, and must be restructured for
efficient
performance
by a robot.
b. Every building project
has some unique
features in terms of its
purpose, geometry, location, and the composition of building works.
Furthermore, this is usually true for the different parts of the same
project. The robot must therefore be specifically
programmed
for each
project and its different
segments.
c. The location of the work within the project or its part continuously
changes, so that the robot must be able to move with the work progress.
d. The robot must operate in a rugged and inaccurate environment; the
various building components have considerably larger production
tolerances than typical work pieces in other industries. The
robot, therefore, in order to do efficient work, must be able to
275

In: New Developments in Robotics Research                                             ISBN 1-59454-593-6 
Editor:
John X. Liu, pp. 217-252                                     © 2005 Nova Science Publishers, Inc. 
Chapter 7 
R
OBOTICS
,
A
UTOMATION
,
 AND 
S
TATISTICAL 
L
EARNING FOR 
P
ROTEOMICS
Gil Alterovitz
1
,
Ehsan Afkhami
2
, and Marco Ramoni
3
1
Health Science and Technology/Electrical Engineering & Computer Science, 
Massachusetts Institute of Technology, Cambridge, MA, USA.  
2
Electrical and Computer Engineering, Boston University, Boston, MA, USA.  
3
Harvard Medical School and Harvard Part
ners Center for Genetics & Genomics, 
Boston, MA, USA 
Abstract 
During the era of the Human Genome Project [1], the emphasis was on sequencing and 
annotating individual genes. At that time, the number of estimated human genes was thought 
to be 100 thousand genes. Yet, as the human genome project draws to a close [2], recent work 
has decreased the estimate to between 20-25 thousand not far from the number of genes in a 
simple worm (i.e. 
C. elegans
). Thus, the complex engineering of a human must be from other 
areas such as the interactions of the gene’s 
products, or proteins. Given this, the field of 
proteomics has quickly been drawn to center st
age. While biologists seek to study proteins, 
methods have been rather primitive until recently. A sudden surge of engineering and other 
technical talent has led this field and associated research to grow dramatically in the last 
couple of years. 
In this chapter, the topic of proteomics is introduced to an engineering/technical audience with 
an emphasis on the robotics and intelligent systems technologies used in this field. These 
include issues in protein extraction, separation, and identification. The associated analysis 
algorithms and statistical learning methods are also discussed. Two case studies regarding the 
above topics are then explored. Lastly, the future direction of the field and its challenges are 
delineated. Clinical applications of proteomics such as cancer diagnosis and drug discovery 
are expounded upon as relevant. 
Keyword:
 Proteomics, Robotics, Automation, Statistical Learning, Mass spectrometry 
Gil Alterovitz,
Ehsan Afkhami, and Marco Ramoni 
218 
I     The Promise of Proteomics 
Proteins are essentially the small machines that allow an organism to function. “Proteomics,” 
a term introduced in the early 1990s, is a field concerned with determining the structure, 
expression, localization, interactions and cellular roles of all proteins within a particular 
organism or subset of one [3]. Yet, until recen
tly, it was only possible to
 explore proteins and 
their function one at a time. Indeed, the key to proteomics is its intrinsic focus on 
parallelization and computational techniques to study myriad proteins at the same time. 
Proteomics is set to have a profound impact on clinical diagnosis and drug discovery. In 
fact, most drugs target and inhibit the functions of specific proteins. 
Proteomics has come a long way since the mid-1990s when protein networks were 
largely studied using 2-D gel electrophoresis (discussed later) [3]. Clinical proteomics is 
concerned with identifying protein networks 
and the intracellular interactions between 
proteins as applied to clinical aims [4]. The functioning of the human cell can be likened to 
the operation of a factory, as proteins ar
e machines that process/deliver products and 
messages to other proteins via biochemical interactions. These messaging pathways or routes 
are essential for cellular function. As such, their malfunction can also be the cause or 
consequence of a disease process [4]. It is th
is notion that stimulated the application of 
proteomic technologies 
to: oncology [5], neurol
ogy [6], toxicology [7
], immunology [8], and 
many other areas [9-11]. Later in the chapter, mass spectrometry methods and their 
proteomics applications will be outlined. With robust and high throughput features, these 
tools have enabled the resolution of thousands of proteins and peptide species in bodily fluids 
ranging from blood [12] to urine [13, 14]. Such technologies have advanced research in early 
cancer diagnosis as well as in Human Immunodeficiency Virus (HIV) inhibiting drugs 
[4, 15]. 
Proteomics can and does leverage some of the engineering and statistical methodology 
developed for functional genomics approaches [16]. However, challenges have arisen in this 
new field and customized solutions such as fabrication of chips for parallelization of 
experiments [17-24], robotics [25-31], and machine learning techniques for intelligent 
decision analysis [32-34] need to be engineered. Other challenges are completely new and 
proteome specific. For example, post-transitional modifications of proteins can be vital for 
cell function. In such cases, one to one correspondence does not exist between each protein 
and its encoding gene. This is significantly diffe
rent from the relatively static nature of DNA. 
Since the post-translational modifications occu
r after the protein is created (based on the 
genetic blueprint), such modifications cannot be seen via traditional genomics approaches. 
The Human Genome Project has demonstrated that speed, cost, and precision are the 
underlying factors in any large scale biological endeavor and that technological hurdles can 
be overcome with novel engineering approaches. Higher throughput and sensitivity are 
requirements of technologies aiming to capture quality snapshots of cellular activity. It is with 
this aim that academia and industry are pushing
 ahead in the automating processes such as 
robotic sample preparation [35], alternative re
adouts for protein interactions [36-38], and 
microfluidics [39]. Current instrumentation is
 far from optimal, however, partly because 
manufacturers have not yet had the necessary lead
 time to build systems 
perfectly tailored to 
protein analysis [40]. 

The 9th International Symposium on Automation and Robotics in Construction June 3-5,1992 Tokyo, Japan
CURRENT STATUS OF CONSTRUCTION AUTOMATION
AND ROBOTICS
IN THE UNITED
STATES OF
AMERICA
Panel Discussion Paper
by
Mirostaw J. Skibniewski
current address:
Division of Building, Construction and Engineering
Commonwealth Scientific and Industrial Research
Organisation
P.O. Box 56, Graham Rd.
Highett, Victoria 3190, Australia
on leave from
Division of Construction
Engineering and Management
School of Civil Engineering
Purdue University
West Lafayette, Indiana 47907-1294, U.S.A.
ABSTRACT
Construction automation and robotics research and development in the United
States is more than a decade old. A number of research institutions, universities,
construction equipment manufacturers and construction engineering firms have
been involved in these efforts. This paper summarizes the recent American
accomplishments and current efforts in several representative areas. It is concluded
that the United States research and development community seems to maintain its
leadership primarily in construction automation software design and software
engineering. However, a more intensive effort and dedication to automation
concepts is needed to capitalize on the potential benefits of automation, particularly
in the practicing engineering community and among the industry practitioners.
Introduction
Automation and robotics has been in all likelihood the most challenging endeavor in the American
construction engineering academic community over the past decade. Similar enthusiasm for this field
has been shared by several government and private research institutions and laboratories. The
industry, including design and construction firms, material suppliers, equipment manufacturers and
owners, with a few notable exceptions, was somewhat slower in relating itself to this new field of
research and development activity. However, the process of disseminating the early results from the
research and development community to industry practice is now slowly beginning to take place.
There are no universally adopted definitions for the terms 'construction automation' and
'construction robotics.' For the sake of our discussion, we will assume that 'construction
automation' refers to the engineering or performance of any construction process, on-site or off-site,
by means of teleoperated, numerically controlled, semiautonomous, or autonomous equipment.
'Construction robotics,' as discussed here, refers to advanced construction equipment exhibiting any
level of capability related to teleoperation, sensory data collection and processing, numerically
controlled, or autonomous task performance.



