Mobile Networks and Applications 10, 563–579, 2005
C 2005 Springer Science + Business Media, Inc. Manufactured in The Netherlands.
MANTIS OS: An Embedded Multithreaded Operating System
for Wireless Micro Sensor Platforms
SHAH BHATTI, JAMES CARLSON, HUI DAI, JING DENG, JEFF ROSE, ANMOL SHETH, BRIAN SHUCKER,
CHARLES GRUENWALD, ADAM TORGERSON and RICHARD HAN *
Department of Computer Science, University of Colorado at Boulder, Campus Box 430, Boulder, CO 80309-0430
Abstract. The MANTIS MultimodAl system for NeTworks of In-situ wireless Sensors provides a new multithreaded cross-platform
embedded operating system for wireless sensor networks. As sensor networks accommodate increasingly complex tasks such as compression/aggregation
and signal processing, preemptive multithreading in the MANTIS sensor OS (MOS) enables micro sensor nodes to natively
interleave complex tasks with time-sensitive tasks, thereby mitigating the bounded buffer producer-consumer problem. To achieve memory
efficiency, MOS is implemented in a lightweight RAM footprint that fits in less than 500 bytes of memory, including kernel, scheduler,
and network stack. To achieve energy efficiency, the MOS power-efficient scheduler sleeps the microcontroller after all active threads have
called the MOS sleep() function, reducing current consumption to the µA range. A key MOS design feature is flexibility in the form of
cross-platform support and testing across PCs, PDAs, and different micro sensor platforms. Another key MOS design feature is support for
remote management of in-situ sensors via dynamic reprogramming and remote login.
Keywords: embedded operating system, sensor networks, multithreaded, lightweight, low power, cross-platform, dynamic reprogramming
1. Introduction
The popularity of wireless sensor networks (WSNs) as an important
new research domain has grown dramatically [3,29].
WSN systems typically consist of resource-constrained micro
sensor nodes that self-organize into a multi-hop wireless
network. This sensor network monitors the environment,
collects sensed data and relays the data back to a collection
point typically residing on the Internet. WSNs integrate
hardware platforms, embedded operating systems, networked
communication, and backend data services together into a
complete system capable of providing novel distributed in-situ
sensing of environmental phenomena. Standard micro sensor
systems include Berkeley’s Mote/TinyOS architecture [25],
MetaCricket [40], MIT’s location-aware cricket [47], CUBoulder’s
MANTIS system [1], Europe’s Smart-Its [52],
Eyes [53], and BTNodes [35] projects.
This automated time-slicing considerably simplifies programming
for an application developer. This paper demonstrates
that the added OS complexity needed to support
preemptive time-slicing is easily accommodated in today’s
MICA2 motes, with a kernel memory cost of the less than 500
bytes, including the scheduler and network stack. Moreover,
the paper shows that multithreading and energy efficiency are
not mutually exclusive, i.e. that a multithreaded system can be
designed to sleep efficiently when application threads indicate
that there is no useful work to be done.
The finely interleaved concurrency of multithreading is
useful in sensor systems to prevent one long-lived task from
blocking execution of a second time-sensitive task. Sensor
* Corresponding author.
networks are being tasked to perfom increasingly complex
duties such as signal processing and collaborative target tracking,
time synchronization [12,17], localization [47], compression/aggregation
[59], and encryption. As we will show
later in Section 3, such tasks can be long-lived enough in
a single-threaded run-to-completion system to prevent timesensitive
processing of other tasks, e.g., processing of radio
packets by different layers of the network stack. If the network
stack is blocked from fully processing arriving packets
until the long-lived task runs to completion, then the network
stack’s bounded buffers could quickly overflow, especially
in sensor nodes with limited RAM, resulting in lost
packets. Multithreading conveniently mitigates this classic
bounded buffer producer-consumer problem by interleaving
processing of packets by the network stack thread with execution
of multiple long-lived complex tasks, so that packets
are emptied from the buffer before overflow is reached.
Our discussion focuses on a loose interpretation of the
bounded buffer problem in terms of its resource constraints
rather than its more traditional interpretation in the field of
synchronization.
The challenges of designing a multithreaded embedded operating
system for WSNs are motivated by the severe resource
constraints imposed by micro sensor nodes, e.g., their limited
run-time memory as well as their limited energy lifetimes. The
run-time RAM available on micro sensor nodes is exceedingly
scarce, e.g., 4 KB for today’s MICA2 motes [11]. While sensor
nodes may diversify towards nano nodes and macro nodes with
lesser and greater capabilities, this current generation of micro
sensor nodes is the standard starting reference that is assumed
in this paper. Because of these severe memory constraints,
traditional multithreaded embedded operating systems such
564 BHATTI ET AL.
as QNX and VXWorks occupy too large of a memory footprint
to execute on micro sensor nodes [25], with embedded
Linux facing the same limitations. Two embedded real-time
embedded operating systems, AVRX [6] andµCOS [30], have
been written for the AVR microcontroller found on the MICA2
motes. Both achieve preemptive multitasking in a lightweight
RAM footprint of less than 4 KB. µCOS is a licensed commercial
OS, while AVRX is open source. The MANTIS open
source OS (MOS) differs from these two embedded RTOSs
by being adapted to the additional requirements imposed by
sensor networks, e.g., the development of a power-efficient
scheduler to reduce energy consumption and the implementation
of advanced sensor-specific features like remote dynamic
reprogramming of micro sensor nodes.
In addition to memory efficiency, micro sensor nodes also
require energy efficiency in the design of the sensor OS. Micro
sensor nodes are often deployed in-situ apart from the
electrical power grid, and therefore rely on battery power or
energy harvesting, e.g., solar cells. Given a set of new AA
batteries, the lifetime of such nodes can be extended to a
few months depending upon the extent to which the duty cycle
is lowered [38]. Key new challenges in the design of a
thread-driven sensor OS therefore include achieving both a
lightweight memory footprint as well as energy-efficient operation.
This paper describes MANTIS OS, a lightweight and
energy-efficient multithreaded operating system for MultimodAl
NeTworks of In-situ micro Sensor nodes. At present,
the MOS kernel is able to achieve multithreaded preemptively
scheduled execution with standard I/O synchronization and a
network protocol stack, all for less than 500 bytes of RAM,
not including individual thread stack sizes. In addition, MANTIS
OS is designed to provide cross-platform support across
PC’s, PDAs, as well as diverse micro sensor hardware platforms.
For example, MANTIS OS currently supports both the
MICA2 motes as well as the MANTIS nymph. MANTIS OS
also seeks to provide tools to ease deployment and management
of in-situ sensor networks.
In order to achieve cross-platform support, MOS was designed
to leverage the properties of a portable standard programming
language, in this case the C programming language.
MOS enables the same application code to execute on a variety
of platforms, ranging from PC’s to PDA’s to different micro
sensor platforms. As detailed in our earlier work [1], this
enables phased deployment of applications from an Internetbased
environment to a physical deployment, i.e. application
code can be tested first on a virtual sensor node executing on
PC’s and/or PDA’s provided that the same API was preserved
on in-situ micro sensor nodes. For example, the MOS userlevel
network stack permits a network layer routing algorithm
to be tested first on virtual sensor nodes on a Linux PC before
being deployed. The emStar system also advocates crossplatform
support though the approach is focused on TinyOS,
as explained later [18].
As added benefits to this cross-platform approach, MOS
achieves code reuse and a low barrier to entry in terms of
programming for sensor networks. For example, a standard
stop-and-wait reliable protocol as well as a standard RC5 security
algorithm [48] are both available as C code, and have
been ported into MOS. Also, the standard programming language
and standard threading model ease the barrier to entry
to programming for sensor networks. Since the kernel is also
written in C, then kernel development can leverage the same
skills used for application development.
MOS is also designed to provide advanced remote management
capabilities for in-situ sensor networks. Towards
this end, the goals of MOS are to support useful yet sophisticated
features, including dynamic reprogramming of sensor
nodes via wireless, remote debugging of sensor nodes,
and multimodal prototyping of virtual and deployed sensor
nodes.
In the remainder of the paper, Section 2 describes the MOS
architecture, including scheduler and network stack, and how
MOS achieves a lightweight implementation. Section 3 provides
a discussion of different sensor OS models and programming
paradigms. Section 4 describes how the multithreaded
MOS achieves power efficiency. Section 5 explains the goals
of MOS with respect to in-situ features. Section 6 summarizes
the MANTIS hardware nymph. Section 7 concludes with future
work.
2. Lightweight MANTIS operating system design
In this section, we describe the architecture of the MANTIS
operating system, which adheres to a classical layered multithreaded
design, as shown in figure 1. Application threads
are separated by the API from the underlying OS. By preserving
the API across platforms, MOS enables cross-platform
support. MOS consists of a lightweight and energy-efficient
scheduler, a user-level network stack, as well as other components
such as device drivers.
2.1. Applications and APIs
MANTIS provides a convenient environment for creating
WSN applications. Figure 2 illustrates a simple yet commonly
Figure 1. MANTIS OS architecture compresses a classic multithreaded layered
operating system design into <500 bytes of RAM.
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 565
Figure 2. Simple sample code of sense-and-forward application sender.
used sense and forward application thread, which is available
along with the complete open source MANTIS software
release at http://mantis.cs.colorado.edu/. This simple application
thread, which runs on a micro sensor node such as the
MICA2 mote, reads a sensor value from an analog to digital
converter (ADC) port, toggles the LED, and then transmits
the value of the sensor over the radio—all in about ten lines
of code.
All applications begin with start, which is similar to
main(). The system properly initializes other system-level
threads, such as the network stack, which is just another
application thread. Though not shown in this example, this
sense-and-forward application thread can spawn new threads
by calling thread new, as can all applications.
The program is compact and requires a fairly shallow learning
curve for C programmers. Early empirical experience with
MOS suggests that application developers can rapidly prototype
new applications in this environment. Applications such
as a sensor-enabled conductor’s wand [8] were prototyped in
hours, while applications such as a frequency-hopping protocol
and a port of the RC5 security standard were completed
in less than two nights.
MANTIS provides a comprehensive set of System APIs for
I/O and system interaction. For a complete list and information
on all the APIs please refer to http://mantis.cs.colorado.edu/.
For the preceding sense and forward application example,
the APIs that were used in the application can be categorized
as:
 Networking: com send, com recv, com ioct, com mode
 On board sensors (ADC): dev write, dev read
 Visual Feedback (LEDs): mos led toggle
 Scheduler: thread new (could have been used, but was
not)
The choice ofaC language API simplifies cross-platform
support and the development of a multimodal prototyping environment.
The MANTIS System API is preserved across both
physical sensor nodes as well as virtual sensor nodes running
on X86 platforms. As a result, the same C code developed
for MANTIS sensor Nymphs with ATMEL microcontrollers
[5] can be compiled to run on X86 PCs with little to no
alteration.
2.2. Kernel and scheduler
The design of the MOS kernel resembles classical, UNIXstyle
schedulers. The services provided are a subset of POSIX
threads [46], most notably priority-based thread scheduling
with round-robin semantics within a priority level. Binary
(mutex) and counting semaphores are also supported. The
goal of the MOS kernel design is to implement these familiar
services in a manner efficient enough for the resourceconstrained
environment of a sensor node.
The most limited resource on a MANTIS node is the RAM.
There are two logically distinct sections of RAM: the space
for global variables that is allocated at compile time, and the
rest of RAM that is managed as a heap. When a thread is
created, stack space is allocated by the kernel out of the heap.
The space is recovered when the thread exits. In the current
implementation, the user is not encouraged to dynamically
allocate heap space, although that was an API decision and is
not an inherent limitation of MOS. This limitation is imposed
because with such limited memory it is important to have a
well planned and coherent memory management policy.
The kernel’s main global data structure is a thread table,
with one entry per thread. Since the thread table is allocated
statically, there is a fixed maximum number of threads and a
fixed level of memory overhead. The maximum thread count
is adjustable at compile time (the default is 12). Each thread
table entry is ten bytes and contains a current stack pointer,
stack boundary information (base pointer and size), a pointer
to the thread’s starting function, the thread’s priority level,
and a next thread pointer for use in linked lists. Note that
pointers on the AVR microcontroller are only two bytes. A
thread’s current context, including saved register values, is
stored on its stack when the thread is suspended. This is significant,
because the context is much larger than a thread table
entry, and it only needs to be stored when the thread is allocated.
Thus the static overhead of the thread table is only
120 bytes.
The kernel also maintains ready-list head and tail pointers
for each priority level (5 by default, for 20 bytes total). Keeping
both pointers allows for fast addition and deletion, which
improves performance when manipulating thread lists. This
is important because those manipulations are frequent and always
occur with interrupts disabled. There is also a current
thread pointer (2 bytes), an interrupt status byte, and one byte
of flags. The total static overhead for the scheduler is thus 144
bytes.
Semaphores in MOS are 5-byte structures that are declared
as needed by applications; they contain a lock or count byte
along with head and tail list pointers. At any given time,
each allocated thread is a member of exactly one list; either
one of the ready lists or a semaphore list. Semaphore operations
move thread pointers between lists, and the scheduler
566 BHATTI ET AL.
cycles through the ready lists to locate the next thread to
execute.
The scheduler receives a timer interrupt from the hardware
to trigger context switches; switches may also be triggered by
system calls or semaphore operations. The timer interrupt is
the only one handled by the kernel–other hardware interrupts
are sent directly to the associated device drivers. Upon an interrupt,
a device driver typically posts a semaphore in order
to activate a waiting thread, and this thread handles whatever
event caused the interrupt. There are currently no ’soft’ interrupts
supported by the MOS kernel, although the design
does not preclude adding them in the future. The time slice is
configurable, and is currently set to about 10 ms.
In addition to driver threads and user threads, there is also
an idle thread created by the kernel at startup. The idle thread
has low priority and runs when all other threads are blocked.
The idle thread is in a position to implement power-aware
scheduling, as it may detect patterns in CPU utilization and
adjust kernel parameters to conserve energy.
2.3. Network stack and “Comm” layer
Wireless networking is critical for the correct operation of
a network of sensors. Such communication is typically realized
as a layered network stack, not to be confused with the
thread stack. The design of the MANTIS network stack is
focused on efficient use of limited memory, flexibility, and
convenience. The stack is implemented as one or more userlevel
threads, as shown in figure 1, following the design of
ALPINE [19]. A user-level network stack enables easy experimentation
with the network stack in user space, and also
enables cross-platform prototyping of network stack functionality
on X86 PCs prior to deployment in WSNs, e.g., a new
data-driven routing protocol can be tested in virtual sensor
nodes on Linux PCs before deployment, as explained in a
later section. The term user space is more aptly applied to manipulation
of the network stack on X86 PCs, where there is a
clear distinction between user space and kernel space, rather
than on ATMega128 MCU sensor nodes, where there is no
such distinction.
Figure 3. The MOS communication COMM layer (left) is designed for asynchronous I/O with the radio, serial, . . . and achieves zero copy operation and
zero polling. The device DEV layer (right) is designed for synchronous I/O, e.g., sensor readings.
Different layers can be flexibly implemented in different
threads, or all layers in the stack can be implemented in one
thread. The tradeoff is between performance and flexibility.
The stack is designed to minimize memory buffer allocation
through layers. The data body for a packet is common through
all layers within a thread. In this way, the network stack avoids
data copies and resembles the zero copy approach of TinyOS,
SMAC [57] and zero copy sockets [27].
The stack supports layer three and above, i.e. network layer
routing, transport layer, and application layer. MAC protocol
support is performed by the communication layer, also called
the “comm” layer, which is located in a separate lower layer
of the OS, distinct from and below the user-level networking
stack.
The MOS comm layer provides a unified interface for
communications device drivers (for interfaces such as serial,
USB, or radio devices). The comm layer is shown in figure 3.
The comm layer also manages packet buffering and synchronization
functions. The network or application thread interacts
with communications devices through four functions:
com send, com recv, com mode, and com ioctl.
When com send is called, the sending thread (the network,
or perhaps an application thread) passes a pointer to a packet
buffer, called a comBuf. The comm layer blocks the sending
thread and passes the pointer to the specified device driver.
While device drivers may be implemented as threads, the typical
implementation is in terms of an interupt-driven state machine.
This state machine proceeds to send the packet through
the hardware device, and the sending thread is resumed when
the state machine reaches its complete state.
While sending can be synchronous, receiving must happen
in the background even when a network or application thread
is not currently making a com recv call. Memory for received
packets is thus managed by the comm layer itself, which owns
a number of comBufs. Device drivers may request comBufs,
which are then allocated to that device. Once a comBuf is obtained,
the device driver may fill it with a received packet, as
directed by its interrupt state machine. When a packet reception
is complete, the device driver calls com swap bufs, which
exchanges the full comBuf for an empty one. Full packets are
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 567
buffered in order by the comm layer. When a thread calls
com recv, it is blocked until a full comBuf on the specified
device is available, at which time a pointer to that comBuf
is returned. Since the receiving thread now possesses a buffer
that was allocated by the comm layer, it must call com free buf
when it is finished with the buffer; this advises the comm layer
that the buffer may be reused. The extra call to free a buffer
is more complexity for the receiving thread, but it allows the
comm layer to provide true zero-copy service. Also, because
the comm layer is completely interrupt-driven, the comm layer
achieves zero polling, which is energy efficient.
Besides send and receive functions, the comm layer provides
mode and ioctl calls. The mode call is used to power up
or power down the device when needed. The meaning of the
ioctl call is device-specific.
The MAC layer protocol is located within the device driver
for the radio, which is housed in the comm layer. The MAC
layer is responsible for controlling such aspects as network
duty cycle, wherein the radio is adaptively slept to save on
energy consumption, and transmit power control. The MAC
layer flexibly supports multi-frequency radio communication
over 30 channels, enabling research into MAC protocol design,
security and reliability. A flexible range of packet sizes
is supported, with a maximum of 64 bytes. An early version of
the MAC protocol supported random backoff, while the current
version of the MAC supports TDMA for star topologies.
MOS will support CSMA in the near future, by adopting and
augmenting SMAC and/or BMAC.
The lower layers of the network stack, including MAC and
physical layers, occupy about 64 bytes of RAM total to support
three communication interfaces, namely the radio, serial link,
and loopback interfaces. Additional RAM buffers must be allocated
to store packet data. Thus comm buffs are allocated
at 64 bytes per buffer, with an added three bytes of overhead
per buffer. Currently, five such buffers are allocated, though
the plan is to allocate more buffers from all RAM. Since these
buffers will be passed directly to applications, then there are
zero copies. An additional small amount of space is consumed
by low-level configuration parameters for the CC1000 radio.
Modules for a broadcast flooding routing protocol and a simple
stop and wait protocol are provided in MOS as default
examples for developing protocols at the network and application
layers. Network layer broadcast flooding adds an additional
thirty bytes of RAM. The size of the user-level network
stack will depend on the complexity of the protocol(s) the
user desires for implementation. Overall, the network stack
consumes less than 200 bytes of RAM.
2.4. Device drivers
MANTIS adopts the traditional logical/physical partitioning
with respect to device driver design for the hardware. The ‘device
layer, or “dev” layer shown in figure 3 houses drivers for
synchronous I/O, e.g., sensors, external storage, etc. Drivers
for asynchronous communication, e.g., radio or serial, are
housed in the comm layer. Several POSIX-style system calls
dev read(), dev write(), dev mode(), and dev ioctl() are implemented
for each device in a simple device layer. A single
static table is used to store function pointers for each device’s
implementation of the device layer model. Devices are specified
by their index into this table rather than using a file descriptor,
to save on code size and memory usage. Since the
table is static, there is some lost overhead if it is not full. Each
device has only 4 functions to implement, and a mutex, so this
overhead is minimal. After the initialization of the device, a
call to dev register() is made, to place the device’s function
pointers into the call table, and initialize the mutex associated
with the device. This driver scheme has been implemented for
EEPROM, several assorted sensors, and is planned for accessing
flash storage. We foresee drivers for each possible device
easily conforming to this model.
The dev mode() call is provided to interface with the power
management system. Devices can currently be in a state of on,
off, or idle. If users know they will not be using the device
for a period of time, they may set it to off or idle, depending
on their needs, for a savings on power consumption. Before
accessing the device again, its mode must be set back to on.
The dev ioctl() call is a generic function, taking devicespecific
variable arguments. A device such as an EEPROM can
use this function to set the memory address where dev read()
and dev write() access the hardware. As more drivers are written,
device-specific routines that do not fit into the normal
device model will be accessed through this interface.
2.5. Summary
Together, the code size of the kernel, scheduler, and network
stack occupies less than 500 bytes of RAM and about 14 KB
of flash. This permits sufficient space for multiple application
threads to execute in the ATMega128’s 4 KB of RAM, as well
as sufficient storage in the ATMega128’s 128 KB of flash
storage.
3. Discussion: Threads and events
This section discusses first the benefits and then the costs of
preemptively time-sliced multithreading in sensor systems.
The following discussion refers to figure 4, which depicts two
execution models for sensor systems: an event-driven run-tocompletion
single-threaded approach on the left; and a preemptively
time-sliced multithreaded model on the right. The
literature contains a variety of examples of thread-driven and
event-driven systems, as well as comparisons between the
two models [2,25,31,32,43,55]. A recent paper suggests that
thread-driven systems can achieve the high performance of
event-based systems for concurrency intensive applications,
with appropriate modifications to the threading packages [55].
TinyOS is a standard embedded OS for sensor networks
based on an event-driven design philosophy. The simplicity
of the system is tailored for event-driven sensor I/O. Tasks
run to completion with respect to other tasks but may be interrupted
by events. Only one stack is needed because only one
task is running, so that there are no context switches. TinyOS
568 BHATTI ET AL.
Figure 4. A Bounded Buffer Producer/Consumer Application avoids buffer
overflow in a preemptively time-sliced system of interleaved threads (right),
because the consumer can execute and empty the buffer earlier. A singlethreaded
event-driven run-to-completion system (left) can overflow the buffer
when a consumer task is forced to wait for a long-lived task to finish, e.g.,
producer or other complex task.
also assumes a modularized programming language nesC, an
extension of C. It is a static language in which all run-time
memory usage is preallocated. Besides its modularized fashion,
nesC also analyzes the code and handles concurrency
inside the language instead of at the user level. The designers
of TinyOS also believe that an event-based approach is able to
create an energy-efficient system since there is neither blocking
nor polling in an event system. Unused CPU cycles can be
spent in the sleep state as opposed to actively looking for an
interesting event. TinyOS provides an event-driven paradigm
that meets the requirements of simple tasks characteristic of
today’s sensor nodes.
The MANTIS multithreaded OS seeks to provide a pathway
to evolve sensor systems to support increasingly complex
tasks, while at the same time meeting the resource constraints
of energy and memory typical of sensor networks. Time-sliced
multithreading offers automatic preemption, which has the advantage
that a single segment of application code cannot block
the execution of other tasks. This is important in sensor systems,
since blocking certain time-critical tasks from executing,
such as network packet processing, can result in overflow
of network buffers when tasks are sufficiently long-lived and
a sensor node’s RAM buffers are sufficiently small.
To illustrate the bounded buffer producer-consumer problem
as it applies to sensor networks, figure 4 depicts two
tasks, namely a producer and a consumer. Such pairs of tasks
are common, and typically share a buffer between them, not
shown. As the producer generates data, the producer places
this data in the bounded buffer between the two tasks. The
consumer empties the buffer whenever it has a chance to execute.
If the consumer is unable to execute for some time while
the producer continues to add data to the buffer, then the buffer
will eventually overflow.
For sensor networks, a typical consumer would be a network
stack that needs to process incoming packets and route
these packets to/from the radio. In a typical sensor network
topology, a sensor node relays data from several children
nodes to a parent node that is closer to the ultimate destination,
namely the base station. An arriving radio packet typically
causes an interrupt that can preempt an executing task.
A small interrupt handler then transfers the packet to a buffer
for complete processing at some later time by another task
such as the network stack. Thus, multiple downstream nodes
act as producers of sensor data whose packets are received
and deposited into the relay node’s buffer, awaiting further
processing by the relay’s network stack.
As sensor nodes are called upon to perform increasingly
complex tasks, the likelihood increases that a long-lived task
in a run-to-completion system can block processing by the network
stack consumer, resulting in lost packets due to buffer
overflow. Such tasks could include aggregation via standard
compression algorithms, standard encryption/decryption, and
standard signal processing techniques. Though today’s aggregators
typically do little more than summarize multiple
sensor values by calculating an average, it is not unreasonable
to expect aggregation to employ more sophisticated yet
memory-efficient compression algorithms in the near future.
For example, we have ported a lightweight compression algorithm
that uses arithmetic coding to the MICA2 motes. This
compression code executes in the 4 KB of RAM provided
by the ATMEL chip. Other researchers have ported the LZ77
compression algorithm to the MICA2 [42]. Similarly, though
today’s sensor nodes employ scalar values to trigger actions
such as routing, e.g., temperature > T degrees, future behavior
may well be triggered by simple frequency analysis of the
sensor data, e.g., the sensor data has a strong tone at 1 kHz.
Thus, we have also ported a standard 64-point FFT algorithm
based on integer arithmetic for fast execution on the MICA2
motes. Other researchers have implemented a much slower
floating point FFT on the MICA2 [42]. In previous work, we
have implemented both RC5 and AES encryption on MICA
motes [14], but present improved implementations in this paper.
The resulting execution times are summarized in Table 1.
We found that that a standard compression task such as
arithmetic coding is relatively long-lived. Arithmetic compression
of 128 samples of data took 321 ms, while arithmetic
decompression of 128 samples took 504 ms. Arithmetic coding
was chosen for its near-optimal compression efficiency.
An alternative would be Huffman coding, which would sacrifice
compression for a speed improvement of about a factor
of two [7]. Also, the 64-point integer FFT required 56 ms to
Table 1
Execution times for various complex tasks on MICA-2.
Complex task Execution time
Arithmetic coding: Compression 321 ms
Arithmetic coding: Decompression 504 ms
64-point FFT (integer) 56 ms
512-point FFT (floating point) 30 sec [42]
RC5 encryption (12 rounds) 2 ms/32 bytes
AES encryption (no pre-computed table) 28 ms/32 bytes
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 569
execute. We expect that 128-point and 256-point FFTs will
require hundreds of milliseconds to run to completion. AES,
in low memory mode, required 28 ms to complete encryption
on just 32 bytes of data.
Any task that is sufficiently long-lived during its run to
completion is a candidate for causing buffer overflow, and
lost packets. Suppose there are 200 bytes of RAM devoted to
the network stack’s buffer. Suppose also that packets arrive
from four downstream neighbors at the rate of 5 packets/sec,
with each packet of size 30 bytes. In this case, sensor data
arrives at a rate of 600 bytes/sec. If any of the above complex
tasks takes more than a few hundred milliseconds to run to
completion, then the bounded buffer will overflow. In contrast,
in a multithreaded system, a network stack consumer thread
will be given its time slice despite the presence of long-lived
threads and thus be able to process its traffic and limit the loss
of data.
To address this bounded buffer problem, a programmer
in a run-to-completion system is therefore burdened with several
difficult and time-consuming tasks. First, the programmer
must decompose their code into sufficiently small execution
modules. In some cases, e.g., arithmetic compression, correct
partitioning of the code may require a semantic understanding
of the algorithm, which is a stiff requirement for a programmer
who only wishes to port the code to a micro sensor platform.
For example, the decomposition of LZ77 compression
code into TinyOS modules required detailed semantic awareness
[42]. Second, understanding when the code modules are
“sufficiently” small to avoid blocking other tasks depends both
upon the other tasks that will be executing as well as their application
tolerances, neither of which are known a priori by
the programmer. The designer may be forced to choose the
finest granularity to avoid the pitfalls of run-to-completion.
The least difficult option of porting code as one monolithic
module runs the risk of the run-to-completion bounded buffer
problem. Third, the programmer must invest significant time
to make sure to relinquish control properly in each module.
For example, the programmer must ensure that each module
avoids busy-wait polling and/or infinite loops in order to avoid
indefinitely blocking other tasks.
In contrast, programmers in MOS do not have to alter their
programming practices to accommodate the above concerns.
A program can be written without having to physically partition
the thread of execution, though the programmer is free to
generate multiple threads if desired. In addition, since there
is a vast body of code already written for threaded operating
systems, a programmer can port code to MOS with relative
ease without requiring a deep semantic understanding of the
coded algorithm. A programmer can also write a long-lived
task without explicitly ensuring that the program does not
block or hinder other processes.
Support for multithreading in MOS comes at the cost of
context switching overhead and additional stack memory for
each thread. First, our claim is that the context switching overhead
is only a moderate issue in WSNs. Each context switch
incurs only about 60 microseconds of overhead (about 120
instructions, or approximately 400 clock cycles), since ∼30
registers need to be reset. In comparison, the default time
slice is much larger at 10 ms. This is less than 1 percent of the
microcontroller’s cycles. Since WSNs are largely focused on
I/O, e.g. sensor data acquisition and packet forwarding, and
not with the computational performance of compute-bound
threads, then the modest slowdown in pure computational
speed should not affect the primary function of micro sensor
nodes.
The second cost of multithreading is memory allocated for
each thread’s stack, though this can be mitigated with intelligent
stack analysis. The default thread stack size in MOS is
128 bytes. Since 4 KB of RAM are available in the MICA2
motes, and the kernel occupies less than 500 bytes, then there
is considerable space left to parameterize MOS to support up
to a double digit number of user threads. For the early Rene
motes with only 512 bytes total of RAM, it would be infeasible
to fit both the MOS kernel and user threads into such a
constrained space. Since current and future sensor nodes are
likely to contain at least the MICA2’s present capacity of 4 KB
RAM, then MOS demonstrates that there is sufficient memory
to fully support both the OS and multithreaded applications.
However, the degree of multithreading remains an issue, because
of the possibility of stack overflow. If insufficient space
is allocated, then the thread’s stack can overflow. To mitigate
this issue, we are currently developing stack analysis tools
that accurately forecast the stack needs of each thread, and
allocate sufficient memory to avoid stack overflow.
The programming paradigm of MOS is based on a standard
programming language C. This enables a shallow learning
curve, cross-platform support, and code reuse. While nesC is
an extension of C, additional investment is required to understand
how to program using nesC modules.
Over time, the two types of sensor systems may very well
converge and/or coexist. In the future, we could envision a sensor
system that combines the best of both the thread-driven
system’s flexibility as well as the event driven system’s ef-
ficiency. A thread-driven model provides a general solution
for synchronous code, preemption syntax and priority mechanisms.
Yet events are well-adapted to many sensing applications
as well. By analogy, arguments between the adaptability
and reconfigurability of microkernels and the performance
of monolithic kernels resulted in the development of modular
kernels that combined the advantages of both. Moreover,
as sensor networks diversify, some micro sensor nodes
may run event-driven code and communicate with others that
execute via multithreading, e.g., aggregator or applicationspecific
nodes.
4. Power management
A challenge in the design of energy-efficient thread-driven
systems is sleeping the scheduler when there are no more
threads that need to be scheduled, i.e. all threads are either
blocked on I/O, blocked for other reasons or have no useful
work to perform. In this section, we describe how MANTIS
OS achieves energy efficiency via a sleep() function that is
570 BHATTI ET AL.
designed to resemble the semantics of the UNIX sleep() function,
i.e. taking a parameter for the duration of the sleep,
but differs in the behavior of the OS after all application
threads have called sleep. This sleep() function enables a
threaded system to shut down when there is no meaningful
work to do, thereby avoiding energy-consuming busy-wait
polling.
A typical wireless node will last only a few days on two
AA batteries when used for continuous monitoring. Two
AA batteries at 3000 milliampere per hour (mAhr) will
last approximately 5 days at 25 mA of power consumption
(3000 mAhr/25mA = 120 hr or 5 days). The most effective
technique for extending the lifetime of in-situ sensor nodes is
a low duty cycle that sleeps the node most of the time. Traditional
power management techniques for laptops transition
between idle and active modes of operation, which is the approach
explored in this work. Additional low power methods
such as throttling the performance of a processor or turning
off only parts of a processor [4], as well as varying the voltage
in real-time embedded systems [37] are not pursued in this
work.
If sensor nodes are to sleep with a low duty cycle, then
the value of the duty cycle must be determined, as well as its
periodicity. These important parameters controlling energy
efficiency should be both application-specific and adaptive.
If a sensor node employs only one sensor, e.g., to monitor
temperature once per second, then the period is simply set to
one second. However, most sensor nodes have the capability
to monitor more than one sensing domain simultaneously,
e.g., both temperature and relative humidity [38]. Given multimodal
sensing, the low duty cycle behavior becomes more
complex. If the temperature sensor is monitored every three
seconds, and humidity is monitored every seven seconds, then
we desire a sensor OS capable of integrating such staggered
and offset application-specific sleep periods. Moreover, we
desire that a sensor OS be responsive to changing environmental
conditions within the sensing zone. For example, at
run time, an application that is tracking an event may wish to
change its sampling frequency or periodicity in response to
sensed data, e.g., motion of an animal. The sensor OS should
provide energy-efficient mechanisms for adapting to run-time
changes in sampling frequencies and duty cycles for each application.
In addition, the behavior of compute-bound applications
such as aggregation is far different than data-driven I/Obound
tasks such as periodic temperature and humidity sensing.
An aggregation application may wish to delay sleeping
of a sensor node until its computation is complete,
regardless of the various sensing periodicities. A sensor
OS should therefore be flexible enough to accommodate
compute-bound application behavior in addition to datadriven
sensing applications with varying periodicities and duty
cycles.
These examples illustrate that a sensor OS should provide
application-specific mechanisms that enable diverse applications
to indicate when and how often they wish to sleep,
in order to achieve power efficiency. The sensor OS should
Figure 5. MOS provides application threads with a sleep(PERIOD) function.
If all threads call sleep(), then the OS shuts down the microcontroller until
the first sleep deadline expires.
combine these application-specific natures and emerge with a
scheduling timetable that meets application needs while also
achieving energy efficiency. The OS scheduler should determine
when it is safe for the system to sleep. In addition, the
sensor OS should adapt to changing conditions, so that applications
at run time can change their sleep times, patterns and
periodicities.
As an initial step towards building sleep-oriented capabilities,
we have implemented a sleep() function as shown
in figure 5, similar to the UNIX sleep() function. First,
the application thread must enable power-save mode, which
is accomplished by the call mos enable power mgt(). All
threads should enable power-save mode, though by default
this option is not turned on and must be explicitly activated.
This was chosen to maintain compatibility with the
UNIX sleep()’s behavior. Next, the application thread may
call mos thread sleep(PERIOD), with a parameter PERIOD
specifying the duration to sleep. This was chosen to mimic the
behavior of UNIX sleep(). However, MOS adds the capability
that, if all application threads call sleep, then the system truly
sleeps most of the time. For example, if there is one application
thread, then the system will periodically wake up according
to the PERIOD specified by that thread. If there are multiple
application threads each calling sleep(), and each specifying
a different sleep duration, then the scheduler will keep track
of when the earliest deadline expires and wake the system;
otherwise, the system will sleep.
Table 2 lists the current consumed by a sense and forward
application thread on a MICA2 mote running MOS for different
duty cycles. While actively executing the application
code, the MICA2 mote running sense and forward consumed
20 mA. However, while the application thread slept, the power
consumption was only 20 µA. This confirmed that MOS was
correctly sleeping the microcontroller and was also able to
periodically wake the thread to execute its code. Thus MOS is
able to achieve energy efficiency while maintaining a threaded
scheduling capability.
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 571
Table 2
Power consumption for MOS in sleep mode and awake
mode on MICA-2.
Power
Sleep 20 µA
Sense and forward (awake) 20 mA
1.0% Duty Cycle for a 300 sec Cycle 66 mAsec
0.5% Duty Cycle for a 300 sec Cycle 36 mAsec
Figure 6 illustrates the energy-efficient MOS scheduler.
The ready Queue of the MOS scheduler consists of five priorities,
high to low: Kernel, Sleep, High, Normal and Idle. The
scheduler selects the highest priority ready task and either
executes it to completion or puts it in the ready queue if its
time slice expired. The scheduler uses 16-bit Timer1 for for
multi threading and time slicing. When no threads are ready
for execution, then the system sleeps automatically instead
of spinning at a 100% duty cycle in the idle loop. The depth
of sleep varies as follows. If the system is suspended on I/O,
Figure 6. Energy-efficient MOS scheduler.
then the system enters the ATMEL’s moderate idle sleep mode.
Otherwise, if all application threads have called sleep(), then
the system enters the deep power-save sleep mode. A separate
sleep queue maintains an ordered list of threads that have
called sleep(), and is ordered by sleep times, low to high.
When the sleep time of the thread in the front of the queue
expires, the queue is shortened and sleep times are readjusted.
Timer/Counter0 is used to implement the sleep timer because
it allows clocking from an external 32 kHz Watch Crystal independent
of the internal CPU clock, which is necessary to
wake the processor from deep sleep. The “sleep” priority in
the ready queue enables newly woken threads to have higher
priority so that they can be serviced first after wake up.
MOS also achieves energy efficiency by implementing the
comm layer so that it is completely interrupt-driven. There is
zero polling in the comm layer.
5. Advanced features of MANTIS OS
Sensor networks impose additional unique demands on the
design of operating systems beyond resource constraints.
572 BHATTI ET AL.
Sensor networking application developers need to be able to
prototype and test applications prior to distribution and physical
deployment in the field. Also, during deployment, in-situ
sensor nodes need to be capable of being both dynamically
reprogrammed and remotely debugged. In the next sections,
MANTIS identifies and implements each of these three key
advanced features for expert users of general-purpose sensor
systems.
5.1. Bridging the internet and sensor network with
multimodal prototyping
The MANTIS prototyping environment provides a framework
for prototyping diverse applications and bridging these applications
between the Internet and the deployed sensor network.
A key requirement of sensor systems is the need to provide
a prototyping environment to test sensor networking applications
prior to deployment. Postponing testing of an application
until after its deployment across a distributed sensor network
can incur severe consequences. As a result, a prototyping environment
is an especially helpful tool for sensor network
application developers.
The MANTIS prototyping environment extends beyond
simulation to provide a larger framework for development of
network management and visualization applications as virtual
nodes within a MANTIS sensor network. First, MANTIS
has the desirable property of enabling an application developer
to test execution of the same C code on both virtual
sensor nodes and later on in-situ physical sensor nodes. Second,
MANTIS seamlessly integrates the virtual environment
with the real deployment network, such that both virtual and
physical nodes can coexist and communicate with each other
in the prototyping environment, as shown in figure 7. Seamless
integration enables phased deployment and testing of an
application, i.e. application code could first be evaluated on
an all-virtual network, then be deployed without modification
to a hybrid network of both virtual and a few physical nodes,
followed by full deployment on an all-physical network. The
Figure 7. Virtual MOS sensor nodes on the Internet are seamlessly connected
with real MOS sensor nodes by preserving a common cross-platform API
across X86 PCs and ATMEL micro sensor nodes.
combination of all-virtual, hybrid, and all-physical modes of
testing form a multimodal prototyping environment. Third,
MANTIS permits a virtual node to leverage other APIs outside
of the MANTIS API, e.g., a virtual node with the MANTIS
API could be realized as a UNIX X windows application
that communicates with other renderering or database APIs to
build visualization and network management applications, respectively.
This virtual node, a.k.a. UNIX application, would
incorporate the MANTIS system API as a simple means of
becoming just another node within the MANTIS network of
virtual and physical nodes. For example, our “cortex” visualization
application connects to two API’s: the MANTIS API
in order to behave as a virtual sensor node and receive sensor
data streams; and a second graphical API in order to render
sensor data. This flexibility is illustrated in figure 7.
MANTIS achieves a multimodal prototyping environment
by preserving a common C API across all platforms. This approach
resembles WINE [58], but eliminates the problems of
hidden system calls, since all such calls are publicly known
in MANTIS. Due to the wide availability and support by the
GNU tool chain for multiple platforms, it is possible to build
MOS, with minor modifications, as an application that runs on
the X86 platform over both Linux and Windows. We call this
user space application running on an X86 platform XMOS.
For example, figure 8 illustrates XMOS utilizing a POSIX
shim layer to translate between MANTIS’ uniform API and
the underlying UNIX operating system. In this way, MOS
applications can be realized as both virtual sensor nodes on
X86 platforms as well as live applications on ATMEL sensor
nodes (AMOS). This enables MANTIS to support multimodal
networks, consisting of XMOS nodes and AMOS nodes
seamlessly interacting with each other. The same C source
code runs transparently over both XMOS and AMOS platforms,
enabling phased deployment from XMOS to AMOS.
Figure 7 shows the structure of the network, with the two networks
connected to each other via a serial RS232 link. Thus, a
com send() system call on the AMOS nodes causes the data to
Figure 8. x86 MANTIS OS (XMOS) architecture uses the POSIX shim layer
to translate to/from underlying OS.
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 573
be transmitted over the radio. The bridge nodes on either side
of the bridging serial link would additionally send the data
over the serial link using the com send(..) call. A com send()
call on the XMOS nodes causes the data to be transmitted over
the IP network instead.
The structural implications of the above multimodal prototyping
environment afford great flexibility to application
developers. First, XMOS nodes need not be identical and indeed
heterogeneous applications can be supported simultaneously.
For example, some XMOS nodes can be written as base
stations, while others may perform aggregation duties for directed
diffusion [26], and still others may coexist to perform
multicast routing [51]. Second, XMOS nodes are not confined
to a single PC, and can be distributed across any number of
PCs, maintaining communication via IP packets. This eases
the ability of the prototyping environment to scale to large
numbers of XMOS virtual nodes. Third, an arbitrary number
of bridging links can connect XMOS and AMOS environments,
and need not be limited to serial links either. Fourth,
virtual nodes must support but are not limited to the MANTIS
API. As a result, a virtual node realized as a UNIX application
could be integrated into the MANTIS sensor network on one
side and speak with a rendering API, database API, X windows
API, or socket API on another side. Thus, the sensor network
can be accessed from any virtual node, easing development
of applications for visualization, network management, and
gateway translation to other networks. The gateway function
is especially critical to translate sensor packet data to/from
IP networks. Fifth, since the network stack is implemented
as user-level thread(s) above the common API, then an added
bonus is that the XMOS environment can be used to prototype
OS functionality in the form of networking routing and reliability
functions. XMOS is not confined to prototyping user
programs only. Finally, provided that hardware translation is
correct, the XMOS architecture offers the potential to feed real
sensor data into virtual nodes to drive prototype evaluation.
A variety of other sensor networking simulators possess
some but not all of the features of the MANTIS multimodal
prototyping environment. TOSSIM is a simulator for TinyOS
[33], and enables the same code to run in PC simulation as
on real sensor nodes, enabling debugging and verification on
PCs prior to deployment. However, the simulator has to run on
one machine and with the same application instance inside.
TOSSF extends TOSSIM to enable heterogeneous applications,
but they’re still confined to one PC [45]. Sensorsim is
an extension to ns2 and provides a simulation framework that
models the sensor nodes and also provides a hybrid simulation
combining the real and virtual network [44]. However, the
sensor network applications are required to be re-implemented
for the target platform, resulting in two completely different
code bases that must be maintained.
emStar is a framework for developing applications for wireless
sensor networks that shares many of the principles of the
MOS system. emStar combines pure simulation, hybrid mode
and real distributed deployments [22]. Just as in MOS, the
same code can be reused in the simulation environment and
the real platform, whose targets include the iPAQ and Crossbow
Stargate platforms. Just as in MOS, a POSIX compatible
programming interface is provided. TinyOS is supported by
the emStar framework.
The MANTIS multimodal framework does have some limitations.
By choosing to preserve a high-level API across
platforms rather than low-level instructions as in a virtual
machine, each XMOS node does not perfectly model the performance
of a sensor node. Our tradeoff has been for improved
flexibility rather than precise emulation. Also, not all OS functionality
can be tested in the above architecture. While the
network stack and remote shell via the command server can
be tested, as well as user programs, other functionality such as
the kernel’s scheduler are at present beyond the cross-platform
testing capabilities of XMOS.
5.2. Dynamic reprogramming
Dynamic reprogramming or retasking is an especially useful
feature for sensor networks. Research has found that sensor
nodes should be remotely reconfigurable over a wireless
multi-hop network after being deployed in the field [38]. Since
sensor networks may be deployed in inaccessible areas and
may scale to thousands of nodes [54], this simplifies management
of the sensor network, i.e. so that biologists need not go
into the field again to reprogram sensors and change parameters
such as the sensor’s sampling rate and trigger threshold or
algorithms such as sensor calibration or time synchronization.
The goal of MOS is to achieve dynamic reprogramming on
several granularities: reflashing of the entire OS; reprogramming
of a single thread; and changing of variables within a
thread. Another feature that is especially useful for sensor systems
is the ability to remotely debug a running thread. MOS
provides a remote shell that enables a user to login and inspect
the sensor node’s memory, e.g., the thread table of an
executing thread.
To overcome the difficulty of reprogramming the network,
MOS includes two reprogramming modes. The simpler programming
mode is similar to that used in many other systems
and involves direct communication with a specific MANTIS
node. On a Nymph, this would be accomplished via the serial
port: The user simply connects the node to a PC and opens
the MANTIS shell. Upon reset, MOS enters a boot loader
that checks for communication from the shell. At this point,
the node will accept a new code image, which is downloaded
from the PC over the direct communication line. From the
shell, the user also has the ability to inspect and modify the
node’s memory directly (peek and poke), as well as spawn
threads and retrieve debugging information including thread
status, stack fill, and other such statistics from the operating
system. The boot loader transfers control to the MOS kernel
on command from the shell, or at startup if the shell is not
present.
The more advanced programming mode is used when a
node is already deployed, and does not require direct access
to the node. The spectrum of dynamic reprogramming of
in-situ sensor networks ranges from fine grained reprogramming
(modifying constants like sampling rate) to complete
574 BHATTI ET AL.
reprogramming of the sensor nodes. At the present time,
MOS can support remote login and changing of variables/parameters.
Support for dynamic reprogramming of the entire OS is
in progress. The dynamic reprogramming capability is actually
implemented as a system call library, which is built into
the MOS kernel. Any application may write a new code image
through calls to this library; the code image is stored into
external storage (flash or EEPROM) as it is written. The application
then calls a commit function that writes out a control
block for the MOS boot loader, which causes it to install the
new code on reset. A software reset completes the reprogramming
process. Using the reprogramming library, the intent is
for an application–such as the MANTIS command server–to
download a patch using any communications method it desires
(typically the regular network stack), apply the patch to the existing
code image, and run the updated code. Thus, the entire
code image, with the exception of the locked boot loader section,
may be reprogrammed over an arbitrary network while
the node is deployed.
Reflashing parts of the OS, e.g., one thread, is a difficult
research challenge that will be addressed after dynamic reprogramming
of the full OS image has been completed.
Current solutions for dynamic reprogramming [34] are virtual
machine (VM) -based where the VM resides over the underlying
sensor operating system and processes the incoming
code capsules. A special stack-based instruction set is used
to reprogram the sensor nodes, reducing the amount of data
that is transmitted over the network. In contrast to the VM
based approach, MOS allows binary updates to reprogram a
node. The developer does not need to learn a new stack-based
instruction set; instead, the existing deployed application only
needs to be modified and recompiled, then a binary patch may
be transmitted to the micro sensor node.
5.3. Remote shell, cortex application and command server
Existing solutions for monitoring sensor networks consider
topology extraction [13] and computing summaries of network
properties for energy efficient monitoring of sensor networks
[59]. In addition to these mechanisms, the user may
wish to manage the nodes in the network in other ways. To
provide this flexibility, MOS includes the MANTIS Command
Server (MCS). From any device in the network equipped with
a terminal (a laptop PC, for example), the user may invoke the
command server client (also referred to as the shell) and log
in to a node. This node may be either a physical node (e.g., on
a Nymph or Mica board) or it may be a virtual node running
as a process on a PC.
The MCS itself is implemented as an application thread.
It listens on the serial and radio for commands either sent to
the kernel or to an application. The user may view the list
of functions supported by the MCS, inspect and modify the
node’s memory, change configuration settings, run or kill programs,
view the thread table or restart the node. Additionally
user applications can register their own functions to be called
when a specific command is entered from the shell. After this
function is called, the user application can receive parameters
for their function. This allows user applications to remain
dormant until a command is issued. The shell is a powerful
debugging tool, since it allows the user to examine and modify
the state of any node, without requiring physical access to the
node.
The remote shell is part of a visualization application called
the “cortex” that runs on a remote laptop. Figure 9 illustrates an
example of the cortex visualization GUI that renders and plots
sensor data in real time, maintaining multiple sliding window
histories. This application is included as part of the MANTIS
release. The cortex can be used not only to receive sensor data,
but also to initiate commands to the sensor network. In this
demo application, clicking on the LED’s will light the LED
on all sensor nodes. More advanced commands are sent via
the remote shell interface, not shown in this screenshot. The
cortex application is an example of an XMOS virtual sensor
node. More precisely, a server application acts as an XMOS
virtual sensor node, receiving sensor data packets from the
real sensor network. The visualization GUI then connects to
the server. This concept of connecting Internet applications as
part of the virtual sensor network in order to receive data is
illustrated in figure 7.
6. MANTIS hardware
The MANTIS hardware nymph’s design was inspired by the
Berkeley MICA and MICA2 Mote architecture [25]. To help
lower our development costs, shorten our development cycle,
and enhance our research goals, we designed the MANTIS
hardware nymph sensor node, adhering to the same themes
of ease of use, flexibility, and adaptation to sensor networks
that characterized our software design. The learning curve for
novice users is lowered by employing a single-board design, as
shown in figure 10, altogether incorporating a low power Atmel
Atmega128(L) microcontroller (MCU) [5], analog sensor
and digital ports, a low power Chipcon CC1000 multi-channel
RF radio [49], EEPROM, power ADC sensor, and serial ports
on a quad-layer 3.67∗3.3 cm Printed Circuit Board (PCB). For
the common user, the single-board design eliminates the need
for a separate sensor board or separate programming board,
which reduces volume and cost. The pins for the serial interface
are directly accessible on the nymph in a standard DIP
package, enabling direct connection of each nymph to a laptop
via a serial cable, as shown in the figure. Direct serial accessibility
combined with dynamic reprogramming over wireless
largely eliminate the need for a programming board for the
common user. Nymphs are versatile in that any node can serve
as a base station or as a leaf. In addition, three sensor interfaces
are built into each nymph and are directly accessible to
the user via wire-wrappable DIP pins, eliminating the need
for the sensor board in the common case. A standard threewire
interface similar to the popular Lego Mindstorms was
selected, enabling a novice to quickly prototype from a large
selection of inexpensive resistive sensors. Also, GPS capability
has been added to each nymph in the form of a connector
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 575
Figure 9. Screenshot of the cortex visualization application for rendering sensor data, part of the MANTIS release.
that fits the Trimble Lassen SQ GPS chip shown to the right
of the nymph in figure 10. Again, the goal is to simplify deployment
of GPS-enabled applications for beginning users.
If the GPS chip is not needed, then the connector is simply
vacant. Finally, the nymph includes an AC/DC option. This
is useful for prototyping in the lab and avoids excessive consumption
of batteries. An AC/DC adapter from Radioshack
is satisfactory. A simple 3-way switch toggles between the
AC/DC option, OFF and the battery option. We envision that
the power option will be useful in future deployments of indoor
sensor networks, where power outlets are readily available for
exploitation.
To support advanced research, the nymph includes several
interfaces that allow expert users to extend its capability.
First, the nymph exports a standard sized JTAG DIP interface
for expert users that need to burn the bootloader into the
Atmel’s flash. For example, researchers experimenting with
dynamic reprogramming may need to reset the fuses on the
flash. For the novice user, we envision that the bootloader
will be preinstalled by the manufacturer or an expert user
with access to a JTAG programming device. In difficult debugging
situations, the JTAG interface can also be used for
line by line, in-system debugging using GDB. Second, the
nymph includes a 20-pin connector with standard DIP interface
for wire-wrapping or development of advanced add-on
boards with mating connector. This connector has direct access
to the MCUs external interrupt pins, I 2C bus, data lines,
timers, and pulse width modulation (PWM) pins. Some potential
add-on boards would be I 2C expanders that use the
interrupt and I 2C pins to add touch pads for example. The
data lines may be used to add liquid crystal displays, while
the PWM pins may be used for controlling motors, timers for
time sensitive applications, or simply as more pins for general
digital I/O. Third, the MANTIS nymph supports multiple antenna
options, including the addition of an antenna amplifier,
via another connector. This connector acts more like a jumper
Figure 10. MANTIS nymph micro sensor node.
576 BHATTI ET AL.
enabling and disabling the built in low-range low power capabilities
and replacing them by add-on circuitry. The addon
circuitry implements a 30 dB low-noise power amplifier
that is a 24-pin chip plus its additional support circuitry and
properly matched 915 MHz antenna. The addition of the amplifier
increases the communication range of the MANTIS
Nymph to up to 2 km at the cost of up to half a Watt additional
power consumption. For those reasons we provide the connector
as an option and not a requirement. One final important
advanced feature is the addition of a single channel I 2C 16-
bit ADC. This ADC enables monitoring of the battery voltage
level.
Power consumption numbers for the nymph are given in
previous work [1]. GPS was found to consume significant
power and will require careful power management to limit
its impact on battery lifetime. Comparable recent hardware
technology with GPS capability includes the MICA2 Motes
[10] and the GPS-enabled GNOMES [56].
7. Future work
The MANTIS system is still very much a work in progress.
Low power management continues to be a challenge, though
sleeping the scheduler has largely eliminated the wasteful busy
waiting or polling of normal threaded systems. A followon
approach would incorporate dynamic hints from within
the application with a power hint call to modify the applicationís
requirements dynamically. Prior work on powerefficient
scheduling and systems should be leveraged [23,24].
Additional complications will result from integrating components
such as the Atmel and CC1000 with multiple low
power modes. At present, MOS exports setting these modes
through the API, but applications have not yet been developed
to exploit these low power features. We are further interested
in pushing the power-efficient scheduler into user space
to further streamline the kernel, similar to the micro-kernel
architecture [20].
There is still some work to be done in demonstrating reliability
for code updates over the network, optimizing the
size of updates, and ensuring the security and authenticity of
updates. Even after those issues are addressed, we have only
solved the problem of reprogramming a single node remotely.
While one could certainly iterate through all nodes in a network
in order to reprogram them all, that would be inefficient
and perhaps infeasible if the network were large. The broader
problem of remotely reprogramming a network, as opposed
to a node, will be addressed in future work.
We also intend to integrate security into dynamic reprogramming,
so that downloaded code can be authenticated,
decrypted, and checked for tampering. At present, we have
implemented an RC5-based CBC mode block cipher encryption/decryption
library. This library also provides functions
for sending encrypted packets and generating message authentication
codes to protect the integrity of packets. The API
is:
mos sec send to(uint16 t addr, uint8 t port, char∗ data,
char dataLen, uint8 t proto, rc5key info ∗rc5key); mos
sec recv(Packet∗ pkt, uint8 t port, uint8 t proto, rc5key info ∗rc5key);
The overhead of this security library is very small, about
110 bytes of RAM. The encrypted packet transmission function
adds about 6% delay compared to non-encrypted packet
transmission.
As MANTIS matures, we see several directions to evolve
the device interface. For example, with the addition of timers,
the devices will gain the ability to set a read interval for
multi-byte reads. More specifically, if the user were trying
to obtain light samples from a sensor board, currently they are
only able to read one byte at a time. With the addition of timers,
users will be able to set the read interval through a dev ioctl()
call, and their dev read() call, called with a multi-byte size,
will fill in the buffer of that length, one byte at a time, for each
interval. As this operation will block, this provides an ideal
method for filling in a radio packet with sensor values over a
period of time, and sending only full radio packets as enough
data are received.
An area that has not yet been addressed is simulating the
wireless channel within the multimodal prototyping environment.
One challenge is the difficulty of simulating wireless
communication channels, especially indoor communication.
Another challenge is building a structure that enables medium
contention among multiple virtual nodes.
The MANTIS project was awarded an NSF SENSORS
2003 grant to study the role of sensor networks in fighting
forest fires Stay tuned to the MANTIS Web site http://mantis.
cs.colorado.edu
8. Conclusion
The MANTIS sensor system achieves a lightweight classically
structured multithreaded operating system in a memory footprint
of less than five hundred bytes, including scheduler and
network stack. The MANTIS OS achieves energy efficiency
by implementing a sleep function. Its power-efficient scheduler
recognizes when all threads are sleeping and then sleeps
the microcontroller for a duration deduced from each thread’s
sleep time. MOS supports a simple C API that enables crossplatform
support, reuse of a large installed code base, and a
low barrier to entry in terms of programming for sensor networks.
MOS also supports advanced sensor OS features such
as multimodal prototyping, dynamic reprogramming, and remote
shells. The MANTIS nymph offers a single-board GPSenabled
solution that is also extensible.
References
[1] H. Abrach, S. Bhatti, J. Carlson, H. Dai, J. Rose, A. Sheth, B. Shucker,
J. Deng and R. Han, “MANTIS: System Support for MultimodAl NeTworks
of In-situ Sensors, in: 2nd ACM International Workshop on Wireless
Sensor Networks and Applications (WSNA) (2003) pp. 50–59.
[2] A. Adya, J. Howell, M. Theimer, W.J. Bolosky and J.R. Douceur, Cooperative
Task Management Without Manual Stack Management, in:
Proceedings of the 2002 Usenix ATC, (June 2002).
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 577
[3] I.F. Akyildiz, W. Su, Y. Sankarasubramaniam and E. Cayirci, A Survey
on Sensor Networks, IEEE Communications Magazine, (August 2002).
[4] D. Albonesi, R. Balasubramonian, S. Dropsho, S. Dwarkadas, E. Friedman,
M. Huang, V. Kursun, G. Magklis, M. Scott, G. Semeraro, P. Bose,
A. Buyuktosunoglu, P. Cook, and S. Shuster, Dynamically Tuning Processor
resources with Adaptive processing, IEEE Computer (December
2003) 49–58.
[5] Atmel AVR 8-bit RISC processor, http://www.atmel.com/ products/AVR
[6] AVRX Real-Time Multitasking Kernel for the Atmel AVR series of
micro controllers, http://www.barello.net/avrx/index.htm.
[7] A. Bookstein and S.T. Klein, Is Huffman coding dead?. Computing 50
(1993) 279–296.
[8] J. Carlson, R. Han, S. Lao, C. Narayan and S. Sanghani, Rapid Prototyping
Of Mobile Input Devices Using Wireless Sensor Nodes, in:
5th IEEE Workshop On Mobile Computing Systems and Applications
(WMCSA) (2003).
[9] J.D. Case, M. Fedor, M.L. Schostall and C. Davin, RFC
1157: Simple network management protocol (SNMP). RFC, IETF,
(May 1990).
[10] Crossbow, http://www.xbow.com/.
[11] Crossbow motes, http://www.xbow.com.
[12] H. Dai and R. Han, TSync: A Lightweight Bidirectional Time Synchronization
Service for Wireless Sensor Networks, ACM SIGMOBILE
Mobile Computing and Communications Review, Special Issue
on Wireless PAN and Sensor Networks 8(1) (January 2004) pp. 125–
139.
[13] B. Deb, S. Bhatnagar and B. Nath, A Topology Discovery Algorithm
for Sensor Networks with Applications to Network Management, DCS
Technical Report DCS-TR-441, Rutgers University (May 2001).
[14] J. Deng, R. Han and S. Mishra, A Performance Evaluation of IntrusionTolerant
Routing in Wireless Sensor Networks, IEEE 2nd International
Workshop on Information Processing in Sensor Networks (IPSN ’03),
(2003), Palo Alto, California, pp. 349–364.
[15] J. Elson and D. Estrin, Time Synchronization for Wireless Sensor Networks,
International Parallel and Distributed Processing Symposium
(IPDPS), Workshop on Wireless and Mobile Computing, (April 2001).
[16] J. Elson and K. Rmer, Wireless Sensor Networks: A New Regime for
Time Synchronization, in: proceedings of the First Workshop on Hot
Topics In Networks (HotNets-I), Princeton, New Jersey, October 28–29
(2002).
[17] J. Elson, L. Girod and D. Estrin, Fine-Grained Network Time Synchronization
using Reference Broadcasts, in OSDI 2002, Boston, MA.
(December 2002).
[18] J. Elson, S. Bien, N. Busek, V. Bychkovskiy, A. Cerpa, D. Ganesan, L.
Girod, B. Greenstein, T. Schoellhammer, T. Stathopoulos and D. Estrin,
EmStar: An Environment for Developing Wireless Embedded Systems
Software, CENS Technical Report 0009, (March 24) 2003.
[19] D. Ely, S. Savage, and D. Wetherall, Alpine: A User-level Infrastructure
For Network Protocol Development,” in: Proc. 3rd USENIX Symposium
on Internet Technologies and Systems (March 2001) pp. 171–183.
[20] D.R. Engler, M. Frans Kaashoek and J. O’Toole Jr., Exokernel: An
Operating System Architecture for Application-level Resource Management,
Symposium on Operating Systems Principles (SOSP), (December
1995) 251–266.
[21] S. Ganeriwal, R. Kumar, S. Adlakha and M. Srivastava, Network-wide
Time Synchronization in Sensor Networks, Technical report, UCLA,
Dept of Electrical Engineering (2002).
[22] L. Girod, J. Elson, A. Cerpa, T. Stathopoulos, N. Ramanathan and D.
Estrin, EmStar: A Software Environment for Developing and Deploying
Wireless Sensor Networks, to appear in the Proceedings of USENIX
04.
[23] D. Grunwald, C.B. Morrey III, P. Levis, M. Neufeld and K. Farkas,
Policies for Dynamic Clock Scheduling, Operating Systems Design
and Implementation (2000).
[24] W. Hamburgen, D. Wallach, M. Viredaz, L. Brakmo, C. Waldspurger, J.
Bartlett, T. Mann and K. Farkas, Itsy: Stretching the Bounds of Mobile
Computing, IEEE Computer 34(4) (April 2001) 28–36.
[25] J. Hill, R. Szewczyk, A. Woo, S. Hollar, D. Culler and K. Pister, System
Architecture Directions for Networked Sensors. in: Proceedings
of Ninth International Conference on Architectural Support for Programming
Languages and Operating Systems (ASPLOS), (November
2000).
[26] C. Intanagonwiwat, R. Govindan and D. Estrin, Directed Diffusion,
ACM MobiCom (2000) pp. 56–67.
[27] H.K. Jerry Chu, Zero-Copy TCP in Solaris, in: Proceedings of the
USENIX 1996 Annual Technical Conference, San Diego, California
(January 1996).
[28] P. Juang, H. Oki, Y. Wang, M. Martonosi, L. Peh and D. Rubenstein,
Energy-efficient Computing For Wildlife Tracking: Design Tradeoffs
and Early Experiences With Zebranet, In ASPLOS, San Jose, CA, (October
2002).
[29] J. Kumagi, The Secret Life of Birds, IEEE Spectrum 41(4) (April 2004)
42–49.
[30] J. Labrosse, MicroC/OS-II: The Real-Time Kernel, 2nd edition, CMP
Books, (November 1998).
[31] H.C. Lauer and R.M. Needham, On the Duality of Operating System
Structures, in Second International Symposium on Operating Systems,
IR1A (October 1978).
[32] J. Larus and M. Parkes, Using Cohort Scheduling to Enhance Server
Performance, Technical Report MSR-TR-2001-39, Microsoft Research,
(March 2001).
[33] P. Levis and N. Lee, Simulating Tinyos Networks. http://www.
cs.berkeley.edu/ pal/research/tossim.html.
[34] P. Levis and D. Culler Mate, A Virtual Machine for Tiny Networked
Sensors, ASPLOS, (Oct. 2002).
[35] M. Leopold, M.B. Dydensborg and P. Bonnet, Bluetooth and Sensor
Networks: A Reality Check. 1st ACM conference on Sensor Systems,(Sensys’03)
LA, CA, (November 2003).
[36] C. Lefurgy, K. Rajamani, F. Rawson, W. Felter, M. Kistler and T. Weller,
Energy Management for Commercial Servers, IEEE Computer, (December
2003) pp. 39–48.
[37] J. Luo and N.K. Jha, Battery-Aware Static Scheduling for Distributed
Real Time Embedded Systems, in: Proc. 38th Design Automation Conference,
ACM Press, (2001) pp. 444–449.
[38] A. Mainwaring, J. Polastre, R. Szewczyk D. Culler and J. Anderson,
Wireless Sensor Networks for Habitat Monitoring, First ACM Workshop
on Wireless Sensor Networks and Applications (WSNA) (2002)
pp. 88–97.
[39] F. Martin, B. Mikhak and B. Silverman, MetaCricket: A Designer’s
Kit For Making Computational Devices, IBM Systems Journal 39(3/4)
(2000).
[40] F. Martin, B. Mikhak and B. Silverman, MetaCricket: A designer’s
kit for making computational devices, IBM Systems Journal 39(3/4)
2000.
[41] R. Min, M. Bhardwaj, S. Cho et al., An Architecture for a PowerAware
Distributed Microsensor Node, in: IEEE Workshop on Signal
Proc. Systems (Oct 2000) pp. 581590.
[42] Ning Xu, Implementation of Data Compression and FFT on TinyOS,
Embedded Networks Laboratory, Computer Science Dept. USC. Los
Angeles, http://enl.usc.edu/ ningxu/papers/lzfft.pdf.
[43] J.K. Ousterhout, Why Threads Are A Bad Idea (for most purposes),
Presentation given at the 1996 Usenix Annual Technical Conference,
(January 1996).
[44] S. Park, A. Savvides and M.B. Srivastava, SensorSim: A Simulation
Framework for Sensor Networks, in: the Proceedings of MSWiM 2000,
Boston, MA, August 11 (2000).
[45] L.F. Perrone and D.M. Nicol, A Scalable Simulator for TinyOS Applications,
Winter Simulation Conference, (2002).
[46] Portable Operating System Interface(POSIX)—Part 1: System Application
Programming Interface (API)[C Language] ISO/IEC 9945-
1:1996, IEEE.
[47] N.B. Priyantha, A. Chakraborty and H. Balakrishnan, The Cricket
Location-Support System, in: Proc. of the Sixth Annual ACM International
Conference on Mobile Computing and Networking (MOBICOM),
(August 2000).
578 BHATTI ET AL.
[48] R.L. Rivest, the RC5 Encryption Algorithm, in: Proceedings of the 1994
Leuven Workshop on Fast Software Encryption, pp. 86–96.
[49] Single chip ultra low power RF transceiver http://www.chipcon.com/
files/CC1000 Data Sheet 2 1.pdf, 2001.
[50] Simple Network Time Protocol, (SNTP) version 4. IETF RFC 2030.
[51] A. Sheth, B. Shucker and R. Han, VLM2: A Very Lightweight Mobile
Multicast System for Wireless Sensor Networks, IEEE Wireless
Communications and Networking Conference ( WCNC) (2003), New
Orleans, Louisiana.
[52] The Smart-Its project, http://www.smart-its.org/.
[53] The Eyes project, http://eyes.eu.org/.
[54] S. Tilak, N.B. Abu-Ghazaleh and W. Heinzelman, A Taxonomy of
Wireless Micro-sensor Network Models, ACM SIGMOBILE Mobile
Computing and Communications Review 6(2) (2002) 28–36.
[55] R. von Behren, J. Condit and E. Brewer, Why Events Are A Bad Idea (for
High-concurrency Servers), 9th Workshop on Hot Topics in Operating
Systems (HotOS IX) (2003).
[56] E. Welsh, W. Fish and P. Frantz, GNOMES: A Testbed for Low-Power
Heterogeneous Wireless Sensor Networks, IEEE International Symposium
on Circuits and Systems (ISCAS), Bangkok, Thailand, (2003).
[57] Wei Ye, John Heidemann and Deborah Estrin, An Energy-Efficient
MAC Protocol for Wireless Sensor Networks, in: Proceedings INFOCOM,
New York, NY, USA, (June 2002).
[58] WINE, http://www.winehq.com/.
[59] J. Zhao, R. Govindan and D. Estrin, Computing Aggregates for Monitoring
Wireless Sensor Networks, First IEEE International Workshop
on Sensor Network Protocols and Applications, Anchorage, AK. (May
2003).
Shah Bhatti is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He also
works as a Senior Program Manager in the R&D Lab
for Imaging and Printing Group (IPG) at Hewlett
Packard in Boise, Idaho. He has participated as a
panelist in workshops on Integrated Architecture
for Manufacturing and Component-Based Software
Engineering, at IJCAI ’89 and ICSE ’98, respectively.
Hewlett Packard has filed several patents on
his behalf. He received an MSCS and an MBA from
the University of Colorado, an MSCE from NTU and a BSCS from Wichita
State University. His research interests include power management, operating
system design and efficient models for wireless sensor networks.
E-mail: shah.bhatti@hp.com
James Carlson is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He received
his Bachelor’s degree from Hampshire College
in 1997. His research is supported by the BP
Visualization Center at CU-Boulder. His research
interests include computer graphics, 3D visualization,
and sensor-enabled computer-human user interfaces.
E-mail: James.Carlson@colorado.edu
Hui Dai is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He received
his B.E. from the University of Science and
Technology, China in 2000, and received has M.S.
in Computer Science from the University of Colorado
at Boulder in 2002. He has been co-leading
the development of the MANTIS OS. His research
interests include system design for wireless sensor
networks, time synchronization, distributed systems
and mobile computing.
E-mail: Hui.Dai@colorado.edu
Jing Deng is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He received
his B.E. from Univeristy of Electronic Science
and Technology of China in 1993, and his M.E
from Institute of Computing Technology, Chinese
Academy of Science in 1996. He has published
four papers on security wireless sensor networks
and is preparing a book chapter on security, privacy,
and fault tolerance in sensor networks. His research
interests include wireless security, secure network
routing, and security for sensor networks.
E-mail: Jing.Deng@colorado.edu
Jeff Rose is an M.S. student in Computer Science at the University of
Colorado at Boulder. He received his B.S. in Computer Science from the
University of Colorado at Boulder in 2003. He has been co-leading the development
of the MANTIS operating system. His research interests include
data-driven routing in sensor networks.
E-mail: Jeff.Rose@colorado.edu
Anmol Sheth is a Ph.D. student in Computer Science at the University
of Colorado at Boulder. He received his B.S. in Computer Science from
the University of Pune, India in 2001. His research interests include MAC
layer protocol design, energy-efficient wireless communication, and adapting
communications to mobility.
E-mail: Anmol.Sheth@colorado.edu
Brian Shucker is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He
received his B.S. in Computer Science from the University
of Arizona in 2001, and his M.S. in Computer
Science from the University of Colorado at
Boulder in December 2003. He has been co-leading
the development of the MANTIS operating system.
His research interests in wireless sensor networks
include operating systems design, communication
networking, and robotic sensor networks.
E-mail: Brian.Shucker@colorado.edu
Charles Gruenwald is an undergraduate student in
Computer Science at the University of Colorado at
Boulder. He joined the MANTIS research group in
Fall 2003 as an undergraduate researcher.
E-mail: Charles.Gruenwald@colorado.edu
Adam Torgerson is an undergraduate student in
Computer Science at the University of Colorado at
Boulder. He joined the MANTIS research group in
Fall 2003 as an undergraduate researcher.
E-mail: Adam.Torgerson@colorado.edu
MANTIS OS
: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 579
Richard Han joined the Department of Computer
Science at the University of Colorado at
Boulder in August 2001 as an Assistant Professor,
http://www.cs.colorado.edu/ rhan. Prof. Han
leads the MANTIS wireless sensor networking
research project, http://mantis.cs.colorado.edu. He
has served on numerous technical program committees
for conferences and workshops in the field of
wireless sensor networks. He received a National
Science Foundation CAREER Award in 2002 and
IBM Faculty Awards in 2002 and 2003. He was a Research Staff Member
at IBM’s Thomas J. Watson Research Center in Hawthorne, New York from
1997-2001. He received his Ph.D. in Electrical Engineering from the University
of California at Berkeley in 1997, and his B.S. in Electrical Engineering
with distinction from Stanford University in 1989. His research interests include
systems design for sensor networks, secure wireless sensor networks,
wireless networking, and sensor-enabled user interfaces.
E-mail: Richard.Han@colorado.edu


Mobile Networks and Applications 10, 563–579, 2005
C 2005 Springer Science + Business Media, Inc. Manufactured in The Netherlands.
MANTIS OS: An Embedded Multithreaded Operating System
for Wireless Micro Sensor Platforms
SHAH BHATTI, JAMES CARLSON, HUI DAI, JING DENG, JEFF ROSE, ANMOL SHETH, BRIAN SHUCKER,
CHARLES GRUENWALD, ADAM TORGERSON and RICHARD HAN *
Department of Computer Science, University of Colorado at Boulder, Campus Box 430, Boulder, CO 80309-0430
Abstract. The MANTIS MultimodAl system for NeTworks of In-situ wireless Sensors provides a new multithreaded cross-platform
embedded operating system for wireless sensor networks. As sensor networks accommodate increasingly complex tasks such as compression/aggregation
and signal processing, preemptive multithreading in the MANTIS sensor OS (MOS) enables micro sensor nodes to natively
interleave complex tasks with time-sensitive tasks, thereby mitigating the bounded buffer producer-consumer problem. To achieve memory
efficiency, MOS is implemented in a lightweight RAM footprint that fits in less than 500 bytes of memory, including kernel, scheduler,
and network stack. To achieve energy efficiency, the MOS power-efficient scheduler sleeps the microcontroller after all active threads have
called the MOS sleep() function, reducing current consumption to the µA range. A key MOS design feature is flexibility in the form of
cross-platform support and testing across PCs, PDAs, and different micro sensor platforms. Another key MOS design feature is support for
remote management of in-situ sensors via dynamic reprogramming and remote login.
Keywords: embedded operating system, sensor networks, multithreaded, lightweight, low power, cross-platform, dynamic reprogramming
1. Introduction
The popularity of wireless sensor networks (WSNs) as an important
new research domain has grown dramatically [3,29].
WSN systems typically consist of resource-constrained micro
sensor nodes that self-organize into a multi-hop wireless
network. This sensor network monitors the environment,
collects sensed data and relays the data back to a collection
point typically residing on the Internet. WSNs integrate
hardware platforms, embedded operating systems, networked
communication, and backend data services together into a
complete system capable of providing novel distributed in-situ
sensing of environmental phenomena. Standard micro sensor
systems include Berkeley’s Mote/TinyOS architecture [25],
MetaCricket [40], MIT’s location-aware cricket [47], CUBoulder’s
MANTIS system [1], Europe’s Smart-Its [52],
Eyes [53], and BTNodes [35] projects.
This automated time-slicing considerably simplifies programming
for an application developer. This paper demonstrates
that the added OS complexity needed to support
preemptive time-slicing is easily accommodated in today’s
MICA2 motes, with a kernel memory cost of the less than 500
bytes, including the scheduler and network stack. Moreover,
the paper shows that multithreading and energy efficiency are
not mutually exclusive, i.e. that a multithreaded system can be
designed to sleep efficiently when application threads indicate
that there is no useful work to be done.
The finely interleaved concurrency of multithreading is
useful in sensor systems to prevent one long-lived task from
blocking execution of a second time-sensitive task. Sensor
* Corresponding author.
networks are being tasked to perfom increasingly complex
duties such as signal processing and collaborative target tracking,
time synchronization [12,17], localization [47], compression/aggregation
[59], and encryption. As we will show
later in Section 3, such tasks can be long-lived enough in
a single-threaded run-to-completion system to prevent timesensitive
processing of other tasks, e.g., processing of radio
packets by different layers of the network stack. If the network
stack is blocked from fully processing arriving packets
until the long-lived task runs to completion, then the network
stack’s bounded buffers could quickly overflow, especially
in sensor nodes with limited RAM, resulting in lost
packets. Multithreading conveniently mitigates this classic
bounded buffer producer-consumer problem by interleaving
processing of packets by the network stack thread with execution
of multiple long-lived complex tasks, so that packets
are emptied from the buffer before overflow is reached.
Our discussion focuses on a loose interpretation of the
bounded buffer problem in terms of its resource constraints
rather than its more traditional interpretation in the field of
synchronization.
The challenges of designing a multithreaded embedded operating
system for WSNs are motivated by the severe resource
constraints imposed by micro sensor nodes, e.g., their limited
run-time memory as well as their limited energy lifetimes. The
run-time RAM available on micro sensor nodes is exceedingly
scarce, e.g., 4 KB for today’s MICA2 motes [11]. While sensor
nodes may diversify towards nano nodes and macro nodes with
lesser and greater capabilities, this current generation of micro
sensor nodes is the standard starting reference that is assumed
in this paper. Because of these severe memory constraints,
traditional multithreaded embedded operating systems such
564 BHATTI ET AL.
as QNX and VXWorks occupy too large of a memory footprint
to execute on micro sensor nodes [25], with embedded
Linux facing the same limitations. Two embedded real-time
embedded operating systems, AVRX [6] andµCOS [30], have
been written for the AVR microcontroller found on the MICA2
motes. Both achieve preemptive multitasking in a lightweight
RAM footprint of less than 4 KB. µCOS is a licensed commercial
OS, while AVRX is open source. The MANTIS open
source OS (MOS) differs from these two embedded RTOSs
by being adapted to the additional requirements imposed by
sensor networks, e.g., the development of a power-efficient
scheduler to reduce energy consumption and the implementation
of advanced sensor-specific features like remote dynamic
reprogramming of micro sensor nodes.
In addition to memory efficiency, micro sensor nodes also
require energy efficiency in the design of the sensor OS. Micro
sensor nodes are often deployed in-situ apart from the
electrical power grid, and therefore rely on battery power or
energy harvesting, e.g., solar cells. Given a set of new AA
batteries, the lifetime of such nodes can be extended to a
few months depending upon the extent to which the duty cycle
is lowered [38]. Key new challenges in the design of a
thread-driven sensor OS therefore include achieving both a
lightweight memory footprint as well as energy-efficient operation.
This paper describes MANTIS OS, a lightweight and
energy-efficient multithreaded operating system for MultimodAl
NeTworks of In-situ micro Sensor nodes. At present,
the MOS kernel is able to achieve multithreaded preemptively
scheduled execution with standard I/O synchronization and a
network protocol stack, all for less than 500 bytes of RAM,
not including individual thread stack sizes. In addition, MANTIS
OS is designed to provide cross-platform support across
PC’s, PDAs, as well as diverse micro sensor hardware platforms.
For example, MANTIS OS currently supports both the
MICA2 motes as well as the MANTIS nymph. MANTIS OS
also seeks to provide tools to ease deployment and management
of in-situ sensor networks.
In order to achieve cross-platform support, MOS was designed
to leverage the properties of a portable standard programming
language, in this case the C programming language.
MOS enables the same application code to execute on a variety
of platforms, ranging from PC’s to PDA’s to different micro
sensor platforms. As detailed in our earlier work [1], this
enables phased deployment of applications from an Internetbased
environment to a physical deployment, i.e. application
code can be tested first on a virtual sensor node executing on
PC’s and/or PDA’s provided that the same API was preserved
on in-situ micro sensor nodes. For example, the MOS userlevel
network stack permits a network layer routing algorithm
to be tested first on virtual sensor nodes on a Linux PC before
being deployed. The emStar system also advocates crossplatform
support though the approach is focused on TinyOS,
as explained later [18].
As added benefits to this cross-platform approach, MOS
achieves code reuse and a low barrier to entry in terms of
programming for sensor networks. For example, a standard
stop-and-wait reliable protocol as well as a standard RC5 security
algorithm [48] are both available as C code, and have
been ported into MOS. Also, the standard programming language
and standard threading model ease the barrier to entry
to programming for sensor networks. Since the kernel is also
written in C, then kernel development can leverage the same
skills used for application development.
MOS is also designed to provide advanced remote management
capabilities for in-situ sensor networks. Towards
this end, the goals of MOS are to support useful yet sophisticated
features, including dynamic reprogramming of sensor
nodes via wireless, remote debugging of sensor nodes,
and multimodal prototyping of virtual and deployed sensor
nodes.
In the remainder of the paper, Section 2 describes the MOS
architecture, including scheduler and network stack, and how
MOS achieves a lightweight implementation. Section 3 provides
a discussion of different sensor OS models and programming
paradigms. Section 4 describes how the multithreaded
MOS achieves power efficiency. Section 5 explains the goals
of MOS with respect to in-situ features. Section 6 summarizes
the MANTIS hardware nymph. Section 7 concludes with future
work.
2. Lightweight MANTIS operating system design
In this section, we describe the architecture of the MANTIS
operating system, which adheres to a classical layered multithreaded
design, as shown in figure 1. Application threads
are separated by the API from the underlying OS. By preserving
the API across platforms, MOS enables cross-platform
support. MOS consists of a lightweight and energy-efficient
scheduler, a user-level network stack, as well as other components
such as device drivers.
2.1. Applications and APIs
MANTIS provides a convenient environment for creating
WSN applications. Figure 2 illustrates a simple yet commonly
Figure 1. MANTIS OS architecture compresses a classic multithreaded layered
operating system design into <500 bytes of RAM.
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 565
Figure 2. Simple sample code of sense-and-forward application sender.
used sense and forward application thread, which is available
along with the complete open source MANTIS software
release at http://mantis.cs.colorado.edu/. This simple application
thread, which runs on a micro sensor node such as the
MICA2 mote, reads a sensor value from an analog to digital
converter (ADC) port, toggles the LED, and then transmits
the value of the sensor over the radio—all in about ten lines
of code.
All applications begin with start, which is similar to
main(). The system properly initializes other system-level
threads, such as the network stack, which is just another
application thread. Though not shown in this example, this
sense-and-forward application thread can spawn new threads
by calling thread new, as can all applications.
The program is compact and requires a fairly shallow learning
curve for C programmers. Early empirical experience with
MOS suggests that application developers can rapidly prototype
new applications in this environment. Applications such
as a sensor-enabled conductor’s wand [8] were prototyped in
hours, while applications such as a frequency-hopping protocol
and a port of the RC5 security standard were completed
in less than two nights.
MANTIS provides a comprehensive set of System APIs for
I/O and system interaction. For a complete list and information
on all the APIs please refer to http://mantis.cs.colorado.edu/.
For the preceding sense and forward application example,
the APIs that were used in the application can be categorized
as:
 Networking: com send, com recv, com ioct, com mode
 On board sensors (ADC): dev write, dev read
 Visual Feedback (LEDs): mos led toggle
 Scheduler: thread new (could have been used, but was
not)
The choice ofaC language API simplifies cross-platform
support and the development of a multimodal prototyping environment.
The MANTIS System API is preserved across both
physical sensor nodes as well as virtual sensor nodes running
on X86 platforms. As a result, the same C code developed
for MANTIS sensor Nymphs with ATMEL microcontrollers
[5] can be compiled to run on X86 PCs with little to no
alteration.
2.2. Kernel and scheduler
The design of the MOS kernel resembles classical, UNIXstyle
schedulers. The services provided are a subset of POSIX
threads [46], most notably priority-based thread scheduling
with round-robin semantics within a priority level. Binary
(mutex) and counting semaphores are also supported. The
goal of the MOS kernel design is to implement these familiar
services in a manner efficient enough for the resourceconstrained
environment of a sensor node.
The most limited resource on a MANTIS node is the RAM.
There are two logically distinct sections of RAM: the space
for global variables that is allocated at compile time, and the
rest of RAM that is managed as a heap. When a thread is
created, stack space is allocated by the kernel out of the heap.
The space is recovered when the thread exits. In the current
implementation, the user is not encouraged to dynamically
allocate heap space, although that was an API decision and is
not an inherent limitation of MOS. This limitation is imposed
because with such limited memory it is important to have a
well planned and coherent memory management policy.
The kernel’s main global data structure is a thread table,
with one entry per thread. Since the thread table is allocated
statically, there is a fixed maximum number of threads and a
fixed level of memory overhead. The maximum thread count
is adjustable at compile time (the default is 12). Each thread
table entry is ten bytes and contains a current stack pointer,
stack boundary information (base pointer and size), a pointer
to the thread’s starting function, the thread’s priority level,
and a next thread pointer for use in linked lists. Note that
pointers on the AVR microcontroller are only two bytes. A
thread’s current context, including saved register values, is
stored on its stack when the thread is suspended. This is significant,
because the context is much larger than a thread table
entry, and it only needs to be stored when the thread is allocated.
Thus the static overhead of the thread table is only
120 bytes.
The kernel also maintains ready-list head and tail pointers
for each priority level (5 by default, for 20 bytes total). Keeping
both pointers allows for fast addition and deletion, which
improves performance when manipulating thread lists. This
is important because those manipulations are frequent and always
occur with interrupts disabled. There is also a current
thread pointer (2 bytes), an interrupt status byte, and one byte
of flags. The total static overhead for the scheduler is thus 144
bytes.
Semaphores in MOS are 5-byte structures that are declared
as needed by applications; they contain a lock or count byte
along with head and tail list pointers. At any given time,
each allocated thread is a member of exactly one list; either
one of the ready lists or a semaphore list. Semaphore operations
move thread pointers between lists, and the scheduler
566 BHATTI ET AL.
cycles through the ready lists to locate the next thread to
execute.
The scheduler receives a timer interrupt from the hardware
to trigger context switches; switches may also be triggered by
system calls or semaphore operations. The timer interrupt is
the only one handled by the kernel–other hardware interrupts
are sent directly to the associated device drivers. Upon an interrupt,
a device driver typically posts a semaphore in order
to activate a waiting thread, and this thread handles whatever
event caused the interrupt. There are currently no ’soft’ interrupts
supported by the MOS kernel, although the design
does not preclude adding them in the future. The time slice is
configurable, and is currently set to about 10 ms.
In addition to driver threads and user threads, there is also
an idle thread created by the kernel at startup. The idle thread
has low priority and runs when all other threads are blocked.
The idle thread is in a position to implement power-aware
scheduling, as it may detect patterns in CPU utilization and
adjust kernel parameters to conserve energy.
2.3. Network stack and “Comm” layer
Wireless networking is critical for the correct operation of
a network of sensors. Such communication is typically realized
as a layered network stack, not to be confused with the
thread stack. The design of the MANTIS network stack is
focused on efficient use of limited memory, flexibility, and
convenience. The stack is implemented as one or more userlevel
threads, as shown in figure 1, following the design of
ALPINE [19]. A user-level network stack enables easy experimentation
with the network stack in user space, and also
enables cross-platform prototyping of network stack functionality
on X86 PCs prior to deployment in WSNs, e.g., a new
data-driven routing protocol can be tested in virtual sensor
nodes on Linux PCs before deployment, as explained in a
later section. The term user space is more aptly applied to manipulation
of the network stack on X86 PCs, where there is a
clear distinction between user space and kernel space, rather
than on ATMega128 MCU sensor nodes, where there is no
such distinction.
Figure 3. The MOS communication COMM layer (left) is designed for asynchronous I/O with the radio, serial, . . . and achieves zero copy operation and
zero polling. The device DEV layer (right) is designed for synchronous I/O, e.g., sensor readings.
Different layers can be flexibly implemented in different
threads, or all layers in the stack can be implemented in one
thread. The tradeoff is between performance and flexibility.
The stack is designed to minimize memory buffer allocation
through layers. The data body for a packet is common through
all layers within a thread. In this way, the network stack avoids
data copies and resembles the zero copy approach of TinyOS,
SMAC [57] and zero copy sockets [27].
The stack supports layer three and above, i.e. network layer
routing, transport layer, and application layer. MAC protocol
support is performed by the communication layer, also called
the “comm” layer, which is located in a separate lower layer
of the OS, distinct from and below the user-level networking
stack.
The MOS comm layer provides a unified interface for
communications device drivers (for interfaces such as serial,
USB, or radio devices). The comm layer is shown in figure 3.
The comm layer also manages packet buffering and synchronization
functions. The network or application thread interacts
with communications devices through four functions:
com send, com recv, com mode, and com ioctl.
When com send is called, the sending thread (the network,
or perhaps an application thread) passes a pointer to a packet
buffer, called a comBuf. The comm layer blocks the sending
thread and passes the pointer to the specified device driver.
While device drivers may be implemented as threads, the typical
implementation is in terms of an interupt-driven state machine.
This state machine proceeds to send the packet through
the hardware device, and the sending thread is resumed when
the state machine reaches its complete state.
While sending can be synchronous, receiving must happen
in the background even when a network or application thread
is not currently making a com recv call. Memory for received
packets is thus managed by the comm layer itself, which owns
a number of comBufs. Device drivers may request comBufs,
which are then allocated to that device. Once a comBuf is obtained,
the device driver may fill it with a received packet, as
directed by its interrupt state machine. When a packet reception
is complete, the device driver calls com swap bufs, which
exchanges the full comBuf for an empty one. Full packets are
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 567
buffered in order by the comm layer. When a thread calls
com recv, it is blocked until a full comBuf on the specified
device is available, at which time a pointer to that comBuf
is returned. Since the receiving thread now possesses a buffer
that was allocated by the comm layer, it must call com free buf
when it is finished with the buffer; this advises the comm layer
that the buffer may be reused. The extra call to free a buffer
is more complexity for the receiving thread, but it allows the
comm layer to provide true zero-copy service. Also, because
the comm layer is completely interrupt-driven, the comm layer
achieves zero polling, which is energy efficient.
Besides send and receive functions, the comm layer provides
mode and ioctl calls. The mode call is used to power up
or power down the device when needed. The meaning of the
ioctl call is device-specific.
The MAC layer protocol is located within the device driver
for the radio, which is housed in the comm layer. The MAC
layer is responsible for controlling such aspects as network
duty cycle, wherein the radio is adaptively slept to save on
energy consumption, and transmit power control. The MAC
layer flexibly supports multi-frequency radio communication
over 30 channels, enabling research into MAC protocol design,
security and reliability. A flexible range of packet sizes
is supported, with a maximum of 64 bytes. An early version of
the MAC protocol supported random backoff, while the current
version of the MAC supports TDMA for star topologies.
MOS will support CSMA in the near future, by adopting and
augmenting SMAC and/or BMAC.
The lower layers of the network stack, including MAC and
physical layers, occupy about 64 bytes of RAM total to support
three communication interfaces, namely the radio, serial link,
and loopback interfaces. Additional RAM buffers must be allocated
to store packet data. Thus comm buffs are allocated
at 64 bytes per buffer, with an added three bytes of overhead
per buffer. Currently, five such buffers are allocated, though
the plan is to allocate more buffers from all RAM. Since these
buffers will be passed directly to applications, then there are
zero copies. An additional small amount of space is consumed
by low-level configuration parameters for the CC1000 radio.
Modules for a broadcast flooding routing protocol and a simple
stop and wait protocol are provided in MOS as default
examples for developing protocols at the network and application
layers. Network layer broadcast flooding adds an additional
thirty bytes of RAM. The size of the user-level network
stack will depend on the complexity of the protocol(s) the
user desires for implementation. Overall, the network stack
consumes less than 200 bytes of RAM.
2.4. Device drivers
MANTIS adopts the traditional logical/physical partitioning
with respect to device driver design for the hardware. The ‘device
layer, or “dev” layer shown in figure 3 houses drivers for
synchronous I/O, e.g., sensors, external storage, etc. Drivers
for asynchronous communication, e.g., radio or serial, are
housed in the comm layer. Several POSIX-style system calls
dev read(), dev write(), dev mode(), and dev ioctl() are implemented
for each device in a simple device layer. A single
static table is used to store function pointers for each device’s
implementation of the device layer model. Devices are specified
by their index into this table rather than using a file descriptor,
to save on code size and memory usage. Since the
table is static, there is some lost overhead if it is not full. Each
device has only 4 functions to implement, and a mutex, so this
overhead is minimal. After the initialization of the device, a
call to dev register() is made, to place the device’s function
pointers into the call table, and initialize the mutex associated
with the device. This driver scheme has been implemented for
EEPROM, several assorted sensors, and is planned for accessing
flash storage. We foresee drivers for each possible device
easily conforming to this model.
The dev mode() call is provided to interface with the power
management system. Devices can currently be in a state of on,
off, or idle. If users know they will not be using the device
for a period of time, they may set it to off or idle, depending
on their needs, for a savings on power consumption. Before
accessing the device again, its mode must be set back to on.
The dev ioctl() call is a generic function, taking devicespecific
variable arguments. A device such as an EEPROM can
use this function to set the memory address where dev read()
and dev write() access the hardware. As more drivers are written,
device-specific routines that do not fit into the normal
device model will be accessed through this interface.
2.5. Summary
Together, the code size of the kernel, scheduler, and network
stack occupies less than 500 bytes of RAM and about 14 KB
of flash. This permits sufficient space for multiple application
threads to execute in the ATMega128’s 4 KB of RAM, as well
as sufficient storage in the ATMega128’s 128 KB of flash
storage.
3. Discussion: Threads and events
This section discusses first the benefits and then the costs of
preemptively time-sliced multithreading in sensor systems.
The following discussion refers to figure 4, which depicts two
execution models for sensor systems: an event-driven run-tocompletion
single-threaded approach on the left; and a preemptively
time-sliced multithreaded model on the right. The
literature contains a variety of examples of thread-driven and
event-driven systems, as well as comparisons between the
two models [2,25,31,32,43,55]. A recent paper suggests that
thread-driven systems can achieve the high performance of
event-based systems for concurrency intensive applications,
with appropriate modifications to the threading packages [55].
TinyOS is a standard embedded OS for sensor networks
based on an event-driven design philosophy. The simplicity
of the system is tailored for event-driven sensor I/O. Tasks
run to completion with respect to other tasks but may be interrupted
by events. Only one stack is needed because only one
task is running, so that there are no context switches. TinyOS
568 BHATTI ET AL.
Figure 4. A Bounded Buffer Producer/Consumer Application avoids buffer
overflow in a preemptively time-sliced system of interleaved threads (right),
because the consumer can execute and empty the buffer earlier. A singlethreaded
event-driven run-to-completion system (left) can overflow the buffer
when a consumer task is forced to wait for a long-lived task to finish, e.g.,
producer or other complex task.
also assumes a modularized programming language nesC, an
extension of C. It is a static language in which all run-time
memory usage is preallocated. Besides its modularized fashion,
nesC also analyzes the code and handles concurrency
inside the language instead of at the user level. The designers
of TinyOS also believe that an event-based approach is able to
create an energy-efficient system since there is neither blocking
nor polling in an event system. Unused CPU cycles can be
spent in the sleep state as opposed to actively looking for an
interesting event. TinyOS provides an event-driven paradigm
that meets the requirements of simple tasks characteristic of
today’s sensor nodes.
The MANTIS multithreaded OS seeks to provide a pathway
to evolve sensor systems to support increasingly complex
tasks, while at the same time meeting the resource constraints
of energy and memory typical of sensor networks. Time-sliced
multithreading offers automatic preemption, which has the advantage
that a single segment of application code cannot block
the execution of other tasks. This is important in sensor systems,
since blocking certain time-critical tasks from executing,
such as network packet processing, can result in overflow
of network buffers when tasks are sufficiently long-lived and
a sensor node’s RAM buffers are sufficiently small.
To illustrate the bounded buffer producer-consumer problem
as it applies to sensor networks, figure 4 depicts two
tasks, namely a producer and a consumer. Such pairs of tasks
are common, and typically share a buffer between them, not
shown. As the producer generates data, the producer places
this data in the bounded buffer between the two tasks. The
consumer empties the buffer whenever it has a chance to execute.
If the consumer is unable to execute for some time while
the producer continues to add data to the buffer, then the buffer
will eventually overflow.
For sensor networks, a typical consumer would be a network
stack that needs to process incoming packets and route
these packets to/from the radio. In a typical sensor network
topology, a sensor node relays data from several children
nodes to a parent node that is closer to the ultimate destination,
namely the base station. An arriving radio packet typically
causes an interrupt that can preempt an executing task.
A small interrupt handler then transfers the packet to a buffer
for complete processing at some later time by another task
such as the network stack. Thus, multiple downstream nodes
act as producers of sensor data whose packets are received
and deposited into the relay node’s buffer, awaiting further
processing by the relay’s network stack.
As sensor nodes are called upon to perform increasingly
complex tasks, the likelihood increases that a long-lived task
in a run-to-completion system can block processing by the network
stack consumer, resulting in lost packets due to buffer
overflow. Such tasks could include aggregation via standard
compression algorithms, standard encryption/decryption, and
standard signal processing techniques. Though today’s aggregators
typically do little more than summarize multiple
sensor values by calculating an average, it is not unreasonable
to expect aggregation to employ more sophisticated yet
memory-efficient compression algorithms in the near future.
For example, we have ported a lightweight compression algorithm
that uses arithmetic coding to the MICA2 motes. This
compression code executes in the 4 KB of RAM provided
by the ATMEL chip. Other researchers have ported the LZ77
compression algorithm to the MICA2 [42]. Similarly, though
today’s sensor nodes employ scalar values to trigger actions
such as routing, e.g., temperature > T degrees, future behavior
may well be triggered by simple frequency analysis of the
sensor data, e.g., the sensor data has a strong tone at 1 kHz.
Thus, we have also ported a standard 64-point FFT algorithm
based on integer arithmetic for fast execution on the MICA2
motes. Other researchers have implemented a much slower
floating point FFT on the MICA2 [42]. In previous work, we
have implemented both RC5 and AES encryption on MICA
motes [14], but present improved implementations in this paper.
The resulting execution times are summarized in Table 1.
We found that that a standard compression task such as
arithmetic coding is relatively long-lived. Arithmetic compression
of 128 samples of data took 321 ms, while arithmetic
decompression of 128 samples took 504 ms. Arithmetic coding
was chosen for its near-optimal compression efficiency.
An alternative would be Huffman coding, which would sacrifice
compression for a speed improvement of about a factor
of two [7]. Also, the 64-point integer FFT required 56 ms to
Table 1
Execution times for various complex tasks on MICA-2.
Complex task Execution time
Arithmetic coding: Compression 321 ms
Arithmetic coding: Decompression 504 ms
64-point FFT (integer) 56 ms
512-point FFT (floating point) 30 sec [42]
RC5 encryption (12 rounds) 2 ms/32 bytes
AES encryption (no pre-computed table) 28 ms/32 bytes
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 569
execute. We expect that 128-point and 256-point FFTs will
require hundreds of milliseconds to run to completion. AES,
in low memory mode, required 28 ms to complete encryption
on just 32 bytes of data.
Any task that is sufficiently long-lived during its run to
completion is a candidate for causing buffer overflow, and
lost packets. Suppose there are 200 bytes of RAM devoted to
the network stack’s buffer. Suppose also that packets arrive
from four downstream neighbors at the rate of 5 packets/sec,
with each packet of size 30 bytes. In this case, sensor data
arrives at a rate of 600 bytes/sec. If any of the above complex
tasks takes more than a few hundred milliseconds to run to
completion, then the bounded buffer will overflow. In contrast,
in a multithreaded system, a network stack consumer thread
will be given its time slice despite the presence of long-lived
threads and thus be able to process its traffic and limit the loss
of data.
To address this bounded buffer problem, a programmer
in a run-to-completion system is therefore burdened with several
difficult and time-consuming tasks. First, the programmer
must decompose their code into sufficiently small execution
modules. In some cases, e.g., arithmetic compression, correct
partitioning of the code may require a semantic understanding
of the algorithm, which is a stiff requirement for a programmer
who only wishes to port the code to a micro sensor platform.
For example, the decomposition of LZ77 compression
code into TinyOS modules required detailed semantic awareness
[42]. Second, understanding when the code modules are
“sufficiently” small to avoid blocking other tasks depends both
upon the other tasks that will be executing as well as their application
tolerances, neither of which are known a priori by
the programmer. The designer may be forced to choose the
finest granularity to avoid the pitfalls of run-to-completion.
The least difficult option of porting code as one monolithic
module runs the risk of the run-to-completion bounded buffer
problem. Third, the programmer must invest significant time
to make sure to relinquish control properly in each module.
For example, the programmer must ensure that each module
avoids busy-wait polling and/or infinite loops in order to avoid
indefinitely blocking other tasks.
In contrast, programmers in MOS do not have to alter their
programming practices to accommodate the above concerns.
A program can be written without having to physically partition
the thread of execution, though the programmer is free to
generate multiple threads if desired. In addition, since there
is a vast body of code already written for threaded operating
systems, a programmer can port code to MOS with relative
ease without requiring a deep semantic understanding of the
coded algorithm. A programmer can also write a long-lived
task without explicitly ensuring that the program does not
block or hinder other processes.
Support for multithreading in MOS comes at the cost of
context switching overhead and additional stack memory for
each thread. First, our claim is that the context switching overhead
is only a moderate issue in WSNs. Each context switch
incurs only about 60 microseconds of overhead (about 120
instructions, or approximately 400 clock cycles), since ∼30
registers need to be reset. In comparison, the default time
slice is much larger at 10 ms. This is less than 1 percent of the
microcontroller’s cycles. Since WSNs are largely focused on
I/O, e.g. sensor data acquisition and packet forwarding, and
not with the computational performance of compute-bound
threads, then the modest slowdown in pure computational
speed should not affect the primary function of micro sensor
nodes.
The second cost of multithreading is memory allocated for
each thread’s stack, though this can be mitigated with intelligent
stack analysis. The default thread stack size in MOS is
128 bytes. Since 4 KB of RAM are available in the MICA2
motes, and the kernel occupies less than 500 bytes, then there
is considerable space left to parameterize MOS to support up
to a double digit number of user threads. For the early Rene
motes with only 512 bytes total of RAM, it would be infeasible
to fit both the MOS kernel and user threads into such a
constrained space. Since current and future sensor nodes are
likely to contain at least the MICA2’s present capacity of 4 KB
RAM, then MOS demonstrates that there is sufficient memory
to fully support both the OS and multithreaded applications.
However, the degree of multithreading remains an issue, because
of the possibility of stack overflow. If insufficient space
is allocated, then the thread’s stack can overflow. To mitigate
this issue, we are currently developing stack analysis tools
that accurately forecast the stack needs of each thread, and
allocate sufficient memory to avoid stack overflow.
The programming paradigm of MOS is based on a standard
programming language C. This enables a shallow learning
curve, cross-platform support, and code reuse. While nesC is
an extension of C, additional investment is required to understand
how to program using nesC modules.
Over time, the two types of sensor systems may very well
converge and/or coexist. In the future, we could envision a sensor
system that combines the best of both the thread-driven
system’s flexibility as well as the event driven system’s ef-
ficiency. A thread-driven model provides a general solution
for synchronous code, preemption syntax and priority mechanisms.
Yet events are well-adapted to many sensing applications
as well. By analogy, arguments between the adaptability
and reconfigurability of microkernels and the performance
of monolithic kernels resulted in the development of modular
kernels that combined the advantages of both. Moreover,
as sensor networks diversify, some micro sensor nodes
may run event-driven code and communicate with others that
execute via multithreading, e.g., aggregator or applicationspecific
nodes.
4. Power management
A challenge in the design of energy-efficient thread-driven
systems is sleeping the scheduler when there are no more
threads that need to be scheduled, i.e. all threads are either
blocked on I/O, blocked for other reasons or have no useful
work to perform. In this section, we describe how MANTIS
OS achieves energy efficiency via a sleep() function that is
570 BHATTI ET AL.
designed to resemble the semantics of the UNIX sleep() function,
i.e. taking a parameter for the duration of the sleep,
but differs in the behavior of the OS after all application
threads have called sleep. This sleep() function enables a
threaded system to shut down when there is no meaningful
work to do, thereby avoiding energy-consuming busy-wait
polling.
A typical wireless node will last only a few days on two
AA batteries when used for continuous monitoring. Two
AA batteries at 3000 milliampere per hour (mAhr) will
last approximately 5 days at 25 mA of power consumption
(3000 mAhr/25mA = 120 hr or 5 days). The most effective
technique for extending the lifetime of in-situ sensor nodes is
a low duty cycle that sleeps the node most of the time. Traditional
power management techniques for laptops transition
between idle and active modes of operation, which is the approach
explored in this work. Additional low power methods
such as throttling the performance of a processor or turning
off only parts of a processor [4], as well as varying the voltage
in real-time embedded systems [37] are not pursued in this
work.
If sensor nodes are to sleep with a low duty cycle, then
the value of the duty cycle must be determined, as well as its
periodicity. These important parameters controlling energy
efficiency should be both application-specific and adaptive.
If a sensor node employs only one sensor, e.g., to monitor
temperature once per second, then the period is simply set to
one second. However, most sensor nodes have the capability
to monitor more than one sensing domain simultaneously,
e.g., both temperature and relative humidity [38]. Given multimodal
sensing, the low duty cycle behavior becomes more
complex. If the temperature sensor is monitored every three
seconds, and humidity is monitored every seven seconds, then
we desire a sensor OS capable of integrating such staggered
and offset application-specific sleep periods. Moreover, we
desire that a sensor OS be responsive to changing environmental
conditions within the sensing zone. For example, at
run time, an application that is tracking an event may wish to
change its sampling frequency or periodicity in response to
sensed data, e.g., motion of an animal. The sensor OS should
provide energy-efficient mechanisms for adapting to run-time
changes in sampling frequencies and duty cycles for each application.
In addition, the behavior of compute-bound applications
such as aggregation is far different than data-driven I/Obound
tasks such as periodic temperature and humidity sensing.
An aggregation application may wish to delay sleeping
of a sensor node until its computation is complete,
regardless of the various sensing periodicities. A sensor
OS should therefore be flexible enough to accommodate
compute-bound application behavior in addition to datadriven
sensing applications with varying periodicities and duty
cycles.
These examples illustrate that a sensor OS should provide
application-specific mechanisms that enable diverse applications
to indicate when and how often they wish to sleep,
in order to achieve power efficiency. The sensor OS should
Figure 5. MOS provides application threads with a sleep(PERIOD) function.
If all threads call sleep(), then the OS shuts down the microcontroller until
the first sleep deadline expires.
combine these application-specific natures and emerge with a
scheduling timetable that meets application needs while also
achieving energy efficiency. The OS scheduler should determine
when it is safe for the system to sleep. In addition, the
sensor OS should adapt to changing conditions, so that applications
at run time can change their sleep times, patterns and
periodicities.
As an initial step towards building sleep-oriented capabilities,
we have implemented a sleep() function as shown
in figure 5, similar to the UNIX sleep() function. First,
the application thread must enable power-save mode, which
is accomplished by the call mos enable power mgt(). All
threads should enable power-save mode, though by default
this option is not turned on and must be explicitly activated.
This was chosen to maintain compatibility with the
UNIX sleep()’s behavior. Next, the application thread may
call mos thread sleep(PERIOD), with a parameter PERIOD
specifying the duration to sleep. This was chosen to mimic the
behavior of UNIX sleep(). However, MOS adds the capability
that, if all application threads call sleep, then the system truly
sleeps most of the time. For example, if there is one application
thread, then the system will periodically wake up according
to the PERIOD specified by that thread. If there are multiple
application threads each calling sleep(), and each specifying
a different sleep duration, then the scheduler will keep track
of when the earliest deadline expires and wake the system;
otherwise, the system will sleep.
Table 2 lists the current consumed by a sense and forward
application thread on a MICA2 mote running MOS for different
duty cycles. While actively executing the application
code, the MICA2 mote running sense and forward consumed
20 mA. However, while the application thread slept, the power
consumption was only 20 µA. This confirmed that MOS was
correctly sleeping the microcontroller and was also able to
periodically wake the thread to execute its code. Thus MOS is
able to achieve energy efficiency while maintaining a threaded
scheduling capability.
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 571
Table 2
Power consumption for MOS in sleep mode and awake
mode on MICA-2.
Power
Sleep 20 µA
Sense and forward (awake) 20 mA
1.0% Duty Cycle for a 300 sec Cycle 66 mAsec
0.5% Duty Cycle for a 300 sec Cycle 36 mAsec
Figure 6 illustrates the energy-efficient MOS scheduler.
The ready Queue of the MOS scheduler consists of five priorities,
high to low: Kernel, Sleep, High, Normal and Idle. The
scheduler selects the highest priority ready task and either
executes it to completion or puts it in the ready queue if its
time slice expired. The scheduler uses 16-bit Timer1 for for
multi threading and time slicing. When no threads are ready
for execution, then the system sleeps automatically instead
of spinning at a 100% duty cycle in the idle loop. The depth
of sleep varies as follows. If the system is suspended on I/O,
Figure 6. Energy-efficient MOS scheduler.
then the system enters the ATMEL’s moderate idle sleep mode.
Otherwise, if all application threads have called sleep(), then
the system enters the deep power-save sleep mode. A separate
sleep queue maintains an ordered list of threads that have
called sleep(), and is ordered by sleep times, low to high.
When the sleep time of the thread in the front of the queue
expires, the queue is shortened and sleep times are readjusted.
Timer/Counter0 is used to implement the sleep timer because
it allows clocking from an external 32 kHz Watch Crystal independent
of the internal CPU clock, which is necessary to
wake the processor from deep sleep. The “sleep” priority in
the ready queue enables newly woken threads to have higher
priority so that they can be serviced first after wake up.
MOS also achieves energy efficiency by implementing the
comm layer so that it is completely interrupt-driven. There is
zero polling in the comm layer.
5. Advanced features of MANTIS OS
Sensor networks impose additional unique demands on the
design of operating systems beyond resource constraints.
572 BHATTI ET AL.
Sensor networking application developers need to be able to
prototype and test applications prior to distribution and physical
deployment in the field. Also, during deployment, in-situ
sensor nodes need to be capable of being both dynamically
reprogrammed and remotely debugged. In the next sections,
MANTIS identifies and implements each of these three key
advanced features for expert users of general-purpose sensor
systems.
5.1. Bridging the internet and sensor network with
multimodal prototyping
The MANTIS prototyping environment provides a framework
for prototyping diverse applications and bridging these applications
between the Internet and the deployed sensor network.
A key requirement of sensor systems is the need to provide
a prototyping environment to test sensor networking applications
prior to deployment. Postponing testing of an application
until after its deployment across a distributed sensor network
can incur severe consequences. As a result, a prototyping environment
is an especially helpful tool for sensor network
application developers.
The MANTIS prototyping environment extends beyond
simulation to provide a larger framework for development of
network management and visualization applications as virtual
nodes within a MANTIS sensor network. First, MANTIS
has the desirable property of enabling an application developer
to test execution of the same C code on both virtual
sensor nodes and later on in-situ physical sensor nodes. Second,
MANTIS seamlessly integrates the virtual environment
with the real deployment network, such that both virtual and
physical nodes can coexist and communicate with each other
in the prototyping environment, as shown in figure 7. Seamless
integration enables phased deployment and testing of an
application, i.e. application code could first be evaluated on
an all-virtual network, then be deployed without modification
to a hybrid network of both virtual and a few physical nodes,
followed by full deployment on an all-physical network. The
Figure 7. Virtual MOS sensor nodes on the Internet are seamlessly connected
with real MOS sensor nodes by preserving a common cross-platform API
across X86 PCs and ATMEL micro sensor nodes.
combination of all-virtual, hybrid, and all-physical modes of
testing form a multimodal prototyping environment. Third,
MANTIS permits a virtual node to leverage other APIs outside
of the MANTIS API, e.g., a virtual node with the MANTIS
API could be realized as a UNIX X windows application
that communicates with other renderering or database APIs to
build visualization and network management applications, respectively.
This virtual node, a.k.a. UNIX application, would
incorporate the MANTIS system API as a simple means of
becoming just another node within the MANTIS network of
virtual and physical nodes. For example, our “cortex” visualization
application connects to two API’s: the MANTIS API
in order to behave as a virtual sensor node and receive sensor
data streams; and a second graphical API in order to render
sensor data. This flexibility is illustrated in figure 7.
MANTIS achieves a multimodal prototyping environment
by preserving a common C API across all platforms. This approach
resembles WINE [58], but eliminates the problems of
hidden system calls, since all such calls are publicly known
in MANTIS. Due to the wide availability and support by the
GNU tool chain for multiple platforms, it is possible to build
MOS, with minor modifications, as an application that runs on
the X86 platform over both Linux and Windows. We call this
user space application running on an X86 platform XMOS.
For example, figure 8 illustrates XMOS utilizing a POSIX
shim layer to translate between MANTIS’ uniform API and
the underlying UNIX operating system. In this way, MOS
applications can be realized as both virtual sensor nodes on
X86 platforms as well as live applications on ATMEL sensor
nodes (AMOS). This enables MANTIS to support multimodal
networks, consisting of XMOS nodes and AMOS nodes
seamlessly interacting with each other. The same C source
code runs transparently over both XMOS and AMOS platforms,
enabling phased deployment from XMOS to AMOS.
Figure 7 shows the structure of the network, with the two networks
connected to each other via a serial RS232 link. Thus, a
com send() system call on the AMOS nodes causes the data to
Figure 8. x86 MANTIS OS (XMOS) architecture uses the POSIX shim layer
to translate to/from underlying OS.
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 573
be transmitted over the radio. The bridge nodes on either side
of the bridging serial link would additionally send the data
over the serial link using the com send(..) call. A com send()
call on the XMOS nodes causes the data to be transmitted over
the IP network instead.
The structural implications of the above multimodal prototyping
environment afford great flexibility to application
developers. First, XMOS nodes need not be identical and indeed
heterogeneous applications can be supported simultaneously.
For example, some XMOS nodes can be written as base
stations, while others may perform aggregation duties for directed
diffusion [26], and still others may coexist to perform
multicast routing [51]. Second, XMOS nodes are not confined
to a single PC, and can be distributed across any number of
PCs, maintaining communication via IP packets. This eases
the ability of the prototyping environment to scale to large
numbers of XMOS virtual nodes. Third, an arbitrary number
of bridging links can connect XMOS and AMOS environments,
and need not be limited to serial links either. Fourth,
virtual nodes must support but are not limited to the MANTIS
API. As a result, a virtual node realized as a UNIX application
could be integrated into the MANTIS sensor network on one
side and speak with a rendering API, database API, X windows
API, or socket API on another side. Thus, the sensor network
can be accessed from any virtual node, easing development
of applications for visualization, network management, and
gateway translation to other networks. The gateway function
is especially critical to translate sensor packet data to/from
IP networks. Fifth, since the network stack is implemented
as user-level thread(s) above the common API, then an added
bonus is that the XMOS environment can be used to prototype
OS functionality in the form of networking routing and reliability
functions. XMOS is not confined to prototyping user
programs only. Finally, provided that hardware translation is
correct, the XMOS architecture offers the potential to feed real
sensor data into virtual nodes to drive prototype evaluation.
A variety of other sensor networking simulators possess
some but not all of the features of the MANTIS multimodal
prototyping environment. TOSSIM is a simulator for TinyOS
[33], and enables the same code to run in PC simulation as
on real sensor nodes, enabling debugging and verification on
PCs prior to deployment. However, the simulator has to run on
one machine and with the same application instance inside.
TOSSF extends TOSSIM to enable heterogeneous applications,
but they’re still confined to one PC [45]. Sensorsim is
an extension to ns2 and provides a simulation framework that
models the sensor nodes and also provides a hybrid simulation
combining the real and virtual network [44]. However, the
sensor network applications are required to be re-implemented
for the target platform, resulting in two completely different
code bases that must be maintained.
emStar is a framework for developing applications for wireless
sensor networks that shares many of the principles of the
MOS system. emStar combines pure simulation, hybrid mode
and real distributed deployments [22]. Just as in MOS, the
same code can be reused in the simulation environment and
the real platform, whose targets include the iPAQ and Crossbow
Stargate platforms. Just as in MOS, a POSIX compatible
programming interface is provided. TinyOS is supported by
the emStar framework.
The MANTIS multimodal framework does have some limitations.
By choosing to preserve a high-level API across
platforms rather than low-level instructions as in a virtual
machine, each XMOS node does not perfectly model the performance
of a sensor node. Our tradeoff has been for improved
flexibility rather than precise emulation. Also, not all OS functionality
can be tested in the above architecture. While the
network stack and remote shell via the command server can
be tested, as well as user programs, other functionality such as
the kernel’s scheduler are at present beyond the cross-platform
testing capabilities of XMOS.
5.2. Dynamic reprogramming
Dynamic reprogramming or retasking is an especially useful
feature for sensor networks. Research has found that sensor
nodes should be remotely reconfigurable over a wireless
multi-hop network after being deployed in the field [38]. Since
sensor networks may be deployed in inaccessible areas and
may scale to thousands of nodes [54], this simplifies management
of the sensor network, i.e. so that biologists need not go
into the field again to reprogram sensors and change parameters
such as the sensor’s sampling rate and trigger threshold or
algorithms such as sensor calibration or time synchronization.
The goal of MOS is to achieve dynamic reprogramming on
several granularities: reflashing of the entire OS; reprogramming
of a single thread; and changing of variables within a
thread. Another feature that is especially useful for sensor systems
is the ability to remotely debug a running thread. MOS
provides a remote shell that enables a user to login and inspect
the sensor node’s memory, e.g., the thread table of an
executing thread.
To overcome the difficulty of reprogramming the network,
MOS includes two reprogramming modes. The simpler programming
mode is similar to that used in many other systems
and involves direct communication with a specific MANTIS
node. On a Nymph, this would be accomplished via the serial
port: The user simply connects the node to a PC and opens
the MANTIS shell. Upon reset, MOS enters a boot loader
that checks for communication from the shell. At this point,
the node will accept a new code image, which is downloaded
from the PC over the direct communication line. From the
shell, the user also has the ability to inspect and modify the
node’s memory directly (peek and poke), as well as spawn
threads and retrieve debugging information including thread
status, stack fill, and other such statistics from the operating
system. The boot loader transfers control to the MOS kernel
on command from the shell, or at startup if the shell is not
present.
The more advanced programming mode is used when a
node is already deployed, and does not require direct access
to the node. The spectrum of dynamic reprogramming of
in-situ sensor networks ranges from fine grained reprogramming
(modifying constants like sampling rate) to complete
574 BHATTI ET AL.
reprogramming of the sensor nodes. At the present time,
MOS can support remote login and changing of variables/parameters.
Support for dynamic reprogramming of the entire OS is
in progress. The dynamic reprogramming capability is actually
implemented as a system call library, which is built into
the MOS kernel. Any application may write a new code image
through calls to this library; the code image is stored into
external storage (flash or EEPROM) as it is written. The application
then calls a commit function that writes out a control
block for the MOS boot loader, which causes it to install the
new code on reset. A software reset completes the reprogramming
process. Using the reprogramming library, the intent is
for an application–such as the MANTIS command server–to
download a patch using any communications method it desires
(typically the regular network stack), apply the patch to the existing
code image, and run the updated code. Thus, the entire
code image, with the exception of the locked boot loader section,
may be reprogrammed over an arbitrary network while
the node is deployed.
Reflashing parts of the OS, e.g., one thread, is a difficult
research challenge that will be addressed after dynamic reprogramming
of the full OS image has been completed.
Current solutions for dynamic reprogramming [34] are virtual
machine (VM) -based where the VM resides over the underlying
sensor operating system and processes the incoming
code capsules. A special stack-based instruction set is used
to reprogram the sensor nodes, reducing the amount of data
that is transmitted over the network. In contrast to the VM
based approach, MOS allows binary updates to reprogram a
node. The developer does not need to learn a new stack-based
instruction set; instead, the existing deployed application only
needs to be modified and recompiled, then a binary patch may
be transmitted to the micro sensor node.
5.3. Remote shell, cortex application and command server
Existing solutions for monitoring sensor networks consider
topology extraction [13] and computing summaries of network
properties for energy efficient monitoring of sensor networks
[59]. In addition to these mechanisms, the user may
wish to manage the nodes in the network in other ways. To
provide this flexibility, MOS includes the MANTIS Command
Server (MCS). From any device in the network equipped with
a terminal (a laptop PC, for example), the user may invoke the
command server client (also referred to as the shell) and log
in to a node. This node may be either a physical node (e.g., on
a Nymph or Mica board) or it may be a virtual node running
as a process on a PC.
The MCS itself is implemented as an application thread.
It listens on the serial and radio for commands either sent to
the kernel or to an application. The user may view the list
of functions supported by the MCS, inspect and modify the
node’s memory, change configuration settings, run or kill programs,
view the thread table or restart the node. Additionally
user applications can register their own functions to be called
when a specific command is entered from the shell. After this
function is called, the user application can receive parameters
for their function. This allows user applications to remain
dormant until a command is issued. The shell is a powerful
debugging tool, since it allows the user to examine and modify
the state of any node, without requiring physical access to the
node.
The remote shell is part of a visualization application called
the “cortex” that runs on a remote laptop. Figure 9 illustrates an
example of the cortex visualization GUI that renders and plots
sensor data in real time, maintaining multiple sliding window
histories. This application is included as part of the MANTIS
release. The cortex can be used not only to receive sensor data,
but also to initiate commands to the sensor network. In this
demo application, clicking on the LED’s will light the LED
on all sensor nodes. More advanced commands are sent via
the remote shell interface, not shown in this screenshot. The
cortex application is an example of an XMOS virtual sensor
node. More precisely, a server application acts as an XMOS
virtual sensor node, receiving sensor data packets from the
real sensor network. The visualization GUI then connects to
the server. This concept of connecting Internet applications as
part of the virtual sensor network in order to receive data is
illustrated in figure 7.
6. MANTIS hardware
The MANTIS hardware nymph’s design was inspired by the
Berkeley MICA and MICA2 Mote architecture [25]. To help
lower our development costs, shorten our development cycle,
and enhance our research goals, we designed the MANTIS
hardware nymph sensor node, adhering to the same themes
of ease of use, flexibility, and adaptation to sensor networks
that characterized our software design. The learning curve for
novice users is lowered by employing a single-board design, as
shown in figure 10, altogether incorporating a low power Atmel
Atmega128(L) microcontroller (MCU) [5], analog sensor
and digital ports, a low power Chipcon CC1000 multi-channel
RF radio [49], EEPROM, power ADC sensor, and serial ports
on a quad-layer 3.67∗3.3 cm Printed Circuit Board (PCB). For
the common user, the single-board design eliminates the need
for a separate sensor board or separate programming board,
which reduces volume and cost. The pins for the serial interface
are directly accessible on the nymph in a standard DIP
package, enabling direct connection of each nymph to a laptop
via a serial cable, as shown in the figure. Direct serial accessibility
combined with dynamic reprogramming over wireless
largely eliminate the need for a programming board for the
common user. Nymphs are versatile in that any node can serve
as a base station or as a leaf. In addition, three sensor interfaces
are built into each nymph and are directly accessible to
the user via wire-wrappable DIP pins, eliminating the need
for the sensor board in the common case. A standard threewire
interface similar to the popular Lego Mindstorms was
selected, enabling a novice to quickly prototype from a large
selection of inexpensive resistive sensors. Also, GPS capability
has been added to each nymph in the form of a connector
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 575
Figure 9. Screenshot of the cortex visualization application for rendering sensor data, part of the MANTIS release.
that fits the Trimble Lassen SQ GPS chip shown to the right
of the nymph in figure 10. Again, the goal is to simplify deployment
of GPS-enabled applications for beginning users.
If the GPS chip is not needed, then the connector is simply
vacant. Finally, the nymph includes an AC/DC option. This
is useful for prototyping in the lab and avoids excessive consumption
of batteries. An AC/DC adapter from Radioshack
is satisfactory. A simple 3-way switch toggles between the
AC/DC option, OFF and the battery option. We envision that
the power option will be useful in future deployments of indoor
sensor networks, where power outlets are readily available for
exploitation.
To support advanced research, the nymph includes several
interfaces that allow expert users to extend its capability.
First, the nymph exports a standard sized JTAG DIP interface
for expert users that need to burn the bootloader into the
Atmel’s flash. For example, researchers experimenting with
dynamic reprogramming may need to reset the fuses on the
flash. For the novice user, we envision that the bootloader
will be preinstalled by the manufacturer or an expert user
with access to a JTAG programming device. In difficult debugging
situations, the JTAG interface can also be used for
line by line, in-system debugging using GDB. Second, the
nymph includes a 20-pin connector with standard DIP interface
for wire-wrapping or development of advanced add-on
boards with mating connector. This connector has direct access
to the MCUs external interrupt pins, I 2C bus, data lines,
timers, and pulse width modulation (PWM) pins. Some potential
add-on boards would be I 2C expanders that use the
interrupt and I 2C pins to add touch pads for example. The
data lines may be used to add liquid crystal displays, while
the PWM pins may be used for controlling motors, timers for
time sensitive applications, or simply as more pins for general
digital I/O. Third, the MANTIS nymph supports multiple antenna
options, including the addition of an antenna amplifier,
via another connector. This connector acts more like a jumper
Figure 10. MANTIS nymph micro sensor node.
576 BHATTI ET AL.
enabling and disabling the built in low-range low power capabilities
and replacing them by add-on circuitry. The addon
circuitry implements a 30 dB low-noise power amplifier
that is a 24-pin chip plus its additional support circuitry and
properly matched 915 MHz antenna. The addition of the amplifier
increases the communication range of the MANTIS
Nymph to up to 2 km at the cost of up to half a Watt additional
power consumption. For those reasons we provide the connector
as an option and not a requirement. One final important
advanced feature is the addition of a single channel I 2C 16-
bit ADC. This ADC enables monitoring of the battery voltage
level.
Power consumption numbers for the nymph are given in
previous work [1]. GPS was found to consume significant
power and will require careful power management to limit
its impact on battery lifetime. Comparable recent hardware
technology with GPS capability includes the MICA2 Motes
[10] and the GPS-enabled GNOMES [56].
7. Future work
The MANTIS system is still very much a work in progress.
Low power management continues to be a challenge, though
sleeping the scheduler has largely eliminated the wasteful busy
waiting or polling of normal threaded systems. A followon
approach would incorporate dynamic hints from within
the application with a power hint call to modify the applicationís
requirements dynamically. Prior work on powerefficient
scheduling and systems should be leveraged [23,24].
Additional complications will result from integrating components
such as the Atmel and CC1000 with multiple low
power modes. At present, MOS exports setting these modes
through the API, but applications have not yet been developed
to exploit these low power features. We are further interested
in pushing the power-efficient scheduler into user space
to further streamline the kernel, similar to the micro-kernel
architecture [20].
There is still some work to be done in demonstrating reliability
for code updates over the network, optimizing the
size of updates, and ensuring the security and authenticity of
updates. Even after those issues are addressed, we have only
solved the problem of reprogramming a single node remotely.
While one could certainly iterate through all nodes in a network
in order to reprogram them all, that would be inefficient
and perhaps infeasible if the network were large. The broader
problem of remotely reprogramming a network, as opposed
to a node, will be addressed in future work.
We also intend to integrate security into dynamic reprogramming,
so that downloaded code can be authenticated,
decrypted, and checked for tampering. At present, we have
implemented an RC5-based CBC mode block cipher encryption/decryption
library. This library also provides functions
for sending encrypted packets and generating message authentication
codes to protect the integrity of packets. The API
is:
mos sec send to(uint16 t addr, uint8 t port, char∗ data,
char dataLen, uint8 t proto, rc5key info ∗rc5key); mos
sec recv(Packet∗ pkt, uint8 t port, uint8 t proto, rc5key info ∗rc5key);
The overhead of this security library is very small, about
110 bytes of RAM. The encrypted packet transmission function
adds about 6% delay compared to non-encrypted packet
transmission.
As MANTIS matures, we see several directions to evolve
the device interface. For example, with the addition of timers,
the devices will gain the ability to set a read interval for
multi-byte reads. More specifically, if the user were trying
to obtain light samples from a sensor board, currently they are
only able to read one byte at a time. With the addition of timers,
users will be able to set the read interval through a dev ioctl()
call, and their dev read() call, called with a multi-byte size,
will fill in the buffer of that length, one byte at a time, for each
interval. As this operation will block, this provides an ideal
method for filling in a radio packet with sensor values over a
period of time, and sending only full radio packets as enough
data are received.
An area that has not yet been addressed is simulating the
wireless channel within the multimodal prototyping environment.
One challenge is the difficulty of simulating wireless
communication channels, especially indoor communication.
Another challenge is building a structure that enables medium
contention among multiple virtual nodes.
The MANTIS project was awarded an NSF SENSORS
2003 grant to study the role of sensor networks in fighting
forest fires Stay tuned to the MANTIS Web site http://mantis.
cs.colorado.edu
8. Conclusion
The MANTIS sensor system achieves a lightweight classically
structured multithreaded operating system in a memory footprint
of less than five hundred bytes, including scheduler and
network stack. The MANTIS OS achieves energy efficiency
by implementing a sleep function. Its power-efficient scheduler
recognizes when all threads are sleeping and then sleeps
the microcontroller for a duration deduced from each thread’s
sleep time. MOS supports a simple C API that enables crossplatform
support, reuse of a large installed code base, and a
low barrier to entry in terms of programming for sensor networks.
MOS also supports advanced sensor OS features such
as multimodal prototyping, dynamic reprogramming, and remote
shells. The MANTIS nymph offers a single-board GPSenabled
solution that is also extensible.
References
[1] H. Abrach, S. Bhatti, J. Carlson, H. Dai, J. Rose, A. Sheth, B. Shucker,
J. Deng and R. Han, “MANTIS: System Support for MultimodAl NeTworks
of In-situ Sensors, in: 2nd ACM International Workshop on Wireless
Sensor Networks and Applications (WSNA) (2003) pp. 50–59.
[2] A. Adya, J. Howell, M. Theimer, W.J. Bolosky and J.R. Douceur, Cooperative
Task Management Without Manual Stack Management, in:
Proceedings of the 2002 Usenix ATC, (June 2002).
MANTIS OS: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 577
[3] I.F. Akyildiz, W. Su, Y. Sankarasubramaniam and E. Cayirci, A Survey
on Sensor Networks, IEEE Communications Magazine, (August 2002).
[4] D. Albonesi, R. Balasubramonian, S. Dropsho, S. Dwarkadas, E. Friedman,
M. Huang, V. Kursun, G. Magklis, M. Scott, G. Semeraro, P. Bose,
A. Buyuktosunoglu, P. Cook, and S. Shuster, Dynamically Tuning Processor
resources with Adaptive processing, IEEE Computer (December
2003) 49–58.
[5] Atmel AVR 8-bit RISC processor, http://www.atmel.com/ products/AVR
[6] AVRX Real-Time Multitasking Kernel for the Atmel AVR series of
micro controllers, http://www.barello.net/avrx/index.htm.
[7] A. Bookstein and S.T. Klein, Is Huffman coding dead?. Computing 50
(1993) 279–296.
[8] J. Carlson, R. Han, S. Lao, C. Narayan and S. Sanghani, Rapid Prototyping
Of Mobile Input Devices Using Wireless Sensor Nodes, in:
5th IEEE Workshop On Mobile Computing Systems and Applications
(WMCSA) (2003).
[9] J.D. Case, M. Fedor, M.L. Schostall and C. Davin, RFC
1157: Simple network management protocol (SNMP). RFC, IETF,
(May 1990).
[10] Crossbow, http://www.xbow.com/.
[11] Crossbow motes, http://www.xbow.com.
[12] H. Dai and R. Han, TSync: A Lightweight Bidirectional Time Synchronization
Service for Wireless Sensor Networks, ACM SIGMOBILE
Mobile Computing and Communications Review, Special Issue
on Wireless PAN and Sensor Networks 8(1) (January 2004) pp. 125–
139.
[13] B. Deb, S. Bhatnagar and B. Nath, A Topology Discovery Algorithm
for Sensor Networks with Applications to Network Management, DCS
Technical Report DCS-TR-441, Rutgers University (May 2001).
[14] J. Deng, R. Han and S. Mishra, A Performance Evaluation of IntrusionTolerant
Routing in Wireless Sensor Networks, IEEE 2nd International
Workshop on Information Processing in Sensor Networks (IPSN ’03),
(2003), Palo Alto, California, pp. 349–364.
[15] J. Elson and D. Estrin, Time Synchronization for Wireless Sensor Networks,
International Parallel and Distributed Processing Symposium
(IPDPS), Workshop on Wireless and Mobile Computing, (April 2001).
[16] J. Elson and K. Rmer, Wireless Sensor Networks: A New Regime for
Time Synchronization, in: proceedings of the First Workshop on Hot
Topics In Networks (HotNets-I), Princeton, New Jersey, October 28–29
(2002).
[17] J. Elson, L. Girod and D. Estrin, Fine-Grained Network Time Synchronization
using Reference Broadcasts, in OSDI 2002, Boston, MA.
(December 2002).
[18] J. Elson, S. Bien, N. Busek, V. Bychkovskiy, A. Cerpa, D. Ganesan, L.
Girod, B. Greenstein, T. Schoellhammer, T. Stathopoulos and D. Estrin,
EmStar: An Environment for Developing Wireless Embedded Systems
Software, CENS Technical Report 0009, (March 24) 2003.
[19] D. Ely, S. Savage, and D. Wetherall, Alpine: A User-level Infrastructure
For Network Protocol Development,” in: Proc. 3rd USENIX Symposium
on Internet Technologies and Systems (March 2001) pp. 171–183.
[20] D.R. Engler, M. Frans Kaashoek and J. O’Toole Jr., Exokernel: An
Operating System Architecture for Application-level Resource Management,
Symposium on Operating Systems Principles (SOSP), (December
1995) 251–266.
[21] S. Ganeriwal, R. Kumar, S. Adlakha and M. Srivastava, Network-wide
Time Synchronization in Sensor Networks, Technical report, UCLA,
Dept of Electrical Engineering (2002).
[22] L. Girod, J. Elson, A. Cerpa, T. Stathopoulos, N. Ramanathan and D.
Estrin, EmStar: A Software Environment for Developing and Deploying
Wireless Sensor Networks, to appear in the Proceedings of USENIX
04.
[23] D. Grunwald, C.B. Morrey III, P. Levis, M. Neufeld and K. Farkas,
Policies for Dynamic Clock Scheduling, Operating Systems Design
and Implementation (2000).
[24] W. Hamburgen, D. Wallach, M. Viredaz, L. Brakmo, C. Waldspurger, J.
Bartlett, T. Mann and K. Farkas, Itsy: Stretching the Bounds of Mobile
Computing, IEEE Computer 34(4) (April 2001) 28–36.
[25] J. Hill, R. Szewczyk, A. Woo, S. Hollar, D. Culler and K. Pister, System
Architecture Directions for Networked Sensors. in: Proceedings
of Ninth International Conference on Architectural Support for Programming
Languages and Operating Systems (ASPLOS), (November
2000).
[26] C. Intanagonwiwat, R. Govindan and D. Estrin, Directed Diffusion,
ACM MobiCom (2000) pp. 56–67.
[27] H.K. Jerry Chu, Zero-Copy TCP in Solaris, in: Proceedings of the
USENIX 1996 Annual Technical Conference, San Diego, California
(January 1996).
[28] P. Juang, H. Oki, Y. Wang, M. Martonosi, L. Peh and D. Rubenstein,
Energy-efficient Computing For Wildlife Tracking: Design Tradeoffs
and Early Experiences With Zebranet, In ASPLOS, San Jose, CA, (October
2002).
[29] J. Kumagi, The Secret Life of Birds, IEEE Spectrum 41(4) (April 2004)
42–49.
[30] J. Labrosse, MicroC/OS-II: The Real-Time Kernel, 2nd edition, CMP
Books, (November 1998).
[31] H.C. Lauer and R.M. Needham, On the Duality of Operating System
Structures, in Second International Symposium on Operating Systems,
IR1A (October 1978).
[32] J. Larus and M. Parkes, Using Cohort Scheduling to Enhance Server
Performance, Technical Report MSR-TR-2001-39, Microsoft Research,
(March 2001).
[33] P. Levis and N. Lee, Simulating Tinyos Networks. http://www.
cs.berkeley.edu/ pal/research/tossim.html.
[34] P. Levis and D. Culler Mate, A Virtual Machine for Tiny Networked
Sensors, ASPLOS, (Oct. 2002).
[35] M. Leopold, M.B. Dydensborg and P. Bonnet, Bluetooth and Sensor
Networks: A Reality Check. 1st ACM conference on Sensor Systems,(Sensys’03)
LA, CA, (November 2003).
[36] C. Lefurgy, K. Rajamani, F. Rawson, W. Felter, M. Kistler and T. Weller,
Energy Management for Commercial Servers, IEEE Computer, (December
2003) pp. 39–48.
[37] J. Luo and N.K. Jha, Battery-Aware Static Scheduling for Distributed
Real Time Embedded Systems, in: Proc. 38th Design Automation Conference,
ACM Press, (2001) pp. 444–449.
[38] A. Mainwaring, J. Polastre, R. Szewczyk D. Culler and J. Anderson,
Wireless Sensor Networks for Habitat Monitoring, First ACM Workshop
on Wireless Sensor Networks and Applications (WSNA) (2002)
pp. 88–97.
[39] F. Martin, B. Mikhak and B. Silverman, MetaCricket: A Designer’s
Kit For Making Computational Devices, IBM Systems Journal 39(3/4)
(2000).
[40] F. Martin, B. Mikhak and B. Silverman, MetaCricket: A designer’s
kit for making computational devices, IBM Systems Journal 39(3/4)
2000.
[41] R. Min, M. Bhardwaj, S. Cho et al., An Architecture for a PowerAware
Distributed Microsensor Node, in: IEEE Workshop on Signal
Proc. Systems (Oct 2000) pp. 581590.
[42] Ning Xu, Implementation of Data Compression and FFT on TinyOS,
Embedded Networks Laboratory, Computer Science Dept. USC. Los
Angeles, http://enl.usc.edu/ ningxu/papers/lzfft.pdf.
[43] J.K. Ousterhout, Why Threads Are A Bad Idea (for most purposes),
Presentation given at the 1996 Usenix Annual Technical Conference,
(January 1996).
[44] S. Park, A. Savvides and M.B. Srivastava, SensorSim: A Simulation
Framework for Sensor Networks, in: the Proceedings of MSWiM 2000,
Boston, MA, August 11 (2000).
[45] L.F. Perrone and D.M. Nicol, A Scalable Simulator for TinyOS Applications,
Winter Simulation Conference, (2002).
[46] Portable Operating System Interface(POSIX)—Part 1: System Application
Programming Interface (API)[C Language] ISO/IEC 9945-
1:1996, IEEE.
[47] N.B. Priyantha, A. Chakraborty and H. Balakrishnan, The Cricket
Location-Support System, in: Proc. of the Sixth Annual ACM International
Conference on Mobile Computing and Networking (MOBICOM),
(August 2000).
578 BHATTI ET AL.
[48] R.L. Rivest, the RC5 Encryption Algorithm, in: Proceedings of the 1994
Leuven Workshop on Fast Software Encryption, pp. 86–96.
[49] Single chip ultra low power RF transceiver http://www.chipcon.com/
files/CC1000 Data Sheet 2 1.pdf, 2001.
[50] Simple Network Time Protocol, (SNTP) version 4. IETF RFC 2030.
[51] A. Sheth, B. Shucker and R. Han, VLM2: A Very Lightweight Mobile
Multicast System for Wireless Sensor Networks, IEEE Wireless
Communications and Networking Conference ( WCNC) (2003), New
Orleans, Louisiana.
[52] The Smart-Its project, http://www.smart-its.org/.
[53] The Eyes project, http://eyes.eu.org/.
[54] S. Tilak, N.B. Abu-Ghazaleh and W. Heinzelman, A Taxonomy of
Wireless Micro-sensor Network Models, ACM SIGMOBILE Mobile
Computing and Communications Review 6(2) (2002) 28–36.
[55] R. von Behren, J. Condit and E. Brewer, Why Events Are A Bad Idea (for
High-concurrency Servers), 9th Workshop on Hot Topics in Operating
Systems (HotOS IX) (2003).
[56] E. Welsh, W. Fish and P. Frantz, GNOMES: A Testbed for Low-Power
Heterogeneous Wireless Sensor Networks, IEEE International Symposium
on Circuits and Systems (ISCAS), Bangkok, Thailand, (2003).
[57] Wei Ye, John Heidemann and Deborah Estrin, An Energy-Efficient
MAC Protocol for Wireless Sensor Networks, in: Proceedings INFOCOM,
New York, NY, USA, (June 2002).
[58] WINE, http://www.winehq.com/.
[59] J. Zhao, R. Govindan and D. Estrin, Computing Aggregates for Monitoring
Wireless Sensor Networks, First IEEE International Workshop
on Sensor Network Protocols and Applications, Anchorage, AK. (May
2003).
Shah Bhatti is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He also
works as a Senior Program Manager in the R&D Lab
for Imaging and Printing Group (IPG) at Hewlett
Packard in Boise, Idaho. He has participated as a
panelist in workshops on Integrated Architecture
for Manufacturing and Component-Based Software
Engineering, at IJCAI ’89 and ICSE ’98, respectively.
Hewlett Packard has filed several patents on
his behalf. He received an MSCS and an MBA from
the University of Colorado, an MSCE from NTU and a BSCS from Wichita
State University. His research interests include power management, operating
system design and efficient models for wireless sensor networks.
E-mail: shah.bhatti@hp.com
James Carlson is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He received
his Bachelor’s degree from Hampshire College
in 1997. His research is supported by the BP
Visualization Center at CU-Boulder. His research
interests include computer graphics, 3D visualization,
and sensor-enabled computer-human user interfaces.
E-mail: James.Carlson@colorado.edu
Hui Dai is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He received
his B.E. from the University of Science and
Technology, China in 2000, and received has M.S.
in Computer Science from the University of Colorado
at Boulder in 2002. He has been co-leading
the development of the MANTIS OS. His research
interests include system design for wireless sensor
networks, time synchronization, distributed systems
and mobile computing.
E-mail: Hui.Dai@colorado.edu
Jing Deng is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He received
his B.E. from Univeristy of Electronic Science
and Technology of China in 1993, and his M.E
from Institute of Computing Technology, Chinese
Academy of Science in 1996. He has published
four papers on security wireless sensor networks
and is preparing a book chapter on security, privacy,
and fault tolerance in sensor networks. His research
interests include wireless security, secure network
routing, and security for sensor networks.
E-mail: Jing.Deng@colorado.edu
Jeff Rose is an M.S. student in Computer Science at the University of
Colorado at Boulder. He received his B.S. in Computer Science from the
University of Colorado at Boulder in 2003. He has been co-leading the development
of the MANTIS operating system. His research interests include
data-driven routing in sensor networks.
E-mail: Jeff.Rose@colorado.edu
Anmol Sheth is a Ph.D. student in Computer Science at the University
of Colorado at Boulder. He received his B.S. in Computer Science from
the University of Pune, India in 2001. His research interests include MAC
layer protocol design, energy-efficient wireless communication, and adapting
communications to mobility.
E-mail: Anmol.Sheth@colorado.edu
Brian Shucker is a Ph.D. student in Computer Science
at the University of Colorado at Boulder. He
received his B.S. in Computer Science from the University
of Arizona in 2001, and his M.S. in Computer
Science from the University of Colorado at
Boulder in December 2003. He has been co-leading
the development of the MANTIS operating system.
His research interests in wireless sensor networks
include operating systems design, communication
networking, and robotic sensor networks.
E-mail: Brian.Shucker@colorado.edu
Charles Gruenwald is an undergraduate student in
Computer Science at the University of Colorado at
Boulder. He joined the MANTIS research group in
Fall 2003 as an undergraduate researcher.
E-mail: Charles.Gruenwald@colorado.edu
Adam Torgerson is an undergraduate student in
Computer Science at the University of Colorado at
Boulder. He joined the MANTIS research group in
Fall 2003 as an undergraduate researcher.
E-mail: Adam.Torgerson@colorado.edu
MANTIS OS
: AN EMBEDDED MULTITHREADED OPERATING SYSTEM 579
Richard Han joined the Department of Computer
Science at the University of Colorado at
Boulder in August 2001 as an Assistant Professor,
http://www.cs.colorado.edu/ rhan. Prof. Han
leads the MANTIS wireless sensor networking
research project, http://mantis.cs.colorado.edu. He
has served on numerous technical program committees
for conferences and workshops in the field of
wireless sensor networks. He received a National
Science Foundation CAREER Award in 2002 and
IBM Faculty Awards in 2002 and 2003. He was a Research Staff Member
at IBM’s Thomas J. Watson Research Center in Hawthorne, New York from
1997-2001. He received his Ph.D. in Electrical Engineering from the University
of California at Berkeley in 1997, and his B.S. in Electrical Engineering
with distinction from Stanford University in 1989. His research interests include
systems design for sensor networks, secure wireless sensor networks,
wireless networking, and sensor-enabled user interfaces.
E-mail: Richard.Han@colorado.edu

54 1536-1284/04/$20.00 © 2004 IEEE IEEE Wireless Communications • December 2004
This work was partly supported
by NCCR-MICS, a
center supported by the
Swiss National Science
Foundation under grant
no. 5005-67322.
WIRELESS SENSOR NETWORKS
INTRODUCTION
In April 2004, the authors organized a workshop,
funded by the European Science Foundation
(ESF), with a view to carrying out
coordinated research into wireless sensor networks
in Europe [1]. Twenty-four experts from
11 European countries including academic
researchers and representatives from industry
were invited to discuss application areas with
particular relevance for Europe as well as various
aspects of the hardware and software architectures
required to support these applications.
Some of the more concrete questions discussed
at the workshop were:
• Which prospective application domains and
concrete applications are of particular value to
Europe? What are the requirements and challenges
involved in implementing these applications?
• What hardware requirements are needed to
support these applications? Are existing systems
sufficient, or is there a gap that needs
additional research and development?
• What type of software is needed (e.g., operating
systems, programming abstractions, tools)
to support these applications and what
requirements have to be met?
• How can we better coordinate the mostly isolated
and disconnected research activities on
sensor networks across Europe?
During the discussions it was observed that
wireless sensor networks have found their way
into a wide variety of applications and systems
with vastly varying requirements and characteristics,
and hence it was very difficult to discuss specific
application requirements, research directions,
and challenges. In the past, a number of early,
mostly U.S.-based research projects established a
de facto definition of a wireless sensor network as
a large-scale, ad hoc, multihop, unpartitioned network
of largely homogeneous, tiny, resource-constrained,
mostly immobile sensor nodes that
would be randomly deployed in the area of interest.
While this characterization is certainly valid
for a large class of applications (in particular from
the military domain), an increasing number of
sensor network applications cannot be adequately
characterized in this way.
As a result of this observation, it was suggested
that the sensor network design space and its various
dimensions should be characterized. Such an
explicit design space might not only prove helpful
as a framework for discussing and structuring
coordinated research (e.g., analyzing mutual
dependencies between applications, software, and
hardware; avoiding duplicate work), but might
also provide a conceptual basis for the development
of flexible software frameworks that can be
adapted to meet different application needs.
This article is a partial answer to the questions
raised during the above-mentioned workshop.
We attempt to specify important
dimensions of the sensor network design space
and justify our findings by showing that existing
sensor network applications occupy different
points in the design space. We build on earlier
work [2] that classified system models of sensor
networks with respect to communication protocols
but did not consider the diverse nature of
concrete applications.
DESIGN SPACE
Initial research into wireless sensor networks was
mainly motivated by military applications, with
the Defense Advanced Research Projects Agency
(DARPA) continuing to fund a number of
prominent research projects (e.g., Smart Dust,
NEST) commonly regarded as the cradle of sensor
network research. The type of applications
considered by these projects led to a de facto
KAY RÖMER AND FRIEDEMANN MATTERN, ETH ZURICH
ABSTRACT
In the recent past, wireless sensor networks
have found their way into a wide variety of applications
and systems with vastly varying requirements
and characteristics. As a consequence, it is
becoming increasingly difficult to discuss typical
requirements regarding hardware issues and software
support. This is particularly problematic in a
multidisciplinary research area such as wireless
sensor networks, where close collaboration
between users, application domain experts, hardware
designers, and software developers is needed
to implement efficient systems. In this article we
discuss the consequences of this fact with regard
to the design space of wireless sensor networks by
considering its various dimensions. We justify our
view by demonstrating that specific existing applications
occupy different points in the design space.
THE DESIGN SPACE OF
WIRELESS SENSOR NETWORKS
In the recent past,
wireless sensor
networks have found
their way into a
wide variety of
applications and
systems with vastly
varying requirements
and characteristics.
As a consequence,
it is becoming
increasingly difficult
to discuss typical
requirements
regarding hardware
issues and software
support.
IEEE Wireless Communications • December 2004 55
definition of a wireless sensor network as a
large-scale (thousands of nodes, covering large
geographical areas), wireless, ad hoc, multihop,
unpartitioned network of homogeneous, tiny
(hardly noticeable), mostly immobile (after
deployment) sensor nodes that would be randomly
deployed in the area of interest.
More recently, other civilian application
domains of wireless sensor networks have been
considered, such as environmental and species
monitoring, agriculture, production and delivery,
and healthcare. Concrete projects targeting these
application areas indicate that the above definition
of a wireless sensor network does not necessarily
apply for these applications: networks may consist
of heterogeneous and mobile sensor nodes; the
network topology may be as simple as a star topology;
networks may make use of existing communication
infrastructures. To meet this general trend
toward diversification, we discuss important
dimensions of the sensor network design space in
the following subsections. We informally characterize
each of the dimensions and, where appropriate,
identify (possibly orthogonal) property
classes in order to support a coarse-grained classification
of sensor network applications.
It is certainly debatable which issues are
important enough to be explicitly considered as
dimensions in the design space, and one could
argue in favor of adding more dimensions or
removing some from our suggestions detailed
below. In fact, we expect that this might become
reasonable in the future as the field and its
applications evolve. However, we have tried to
ensure that our initial suggestion consists of a
sensible set of dimensions, by basing our choice
on two principles. First, there should be notable
variability between applications with respect to
dimensions. Second, a dimension should have a
significant impact on the design and implementation
of technical solutions.
DEPLOYMENT
The deployment of sensor nodes in the physical
environment may take several forms. Nodes may
be deployed at random (e.g., by dropping them
from an aircraft) or installed at deliberately chosen
spots. Deployment may be a one-time activity,
where the installation and use of a sensor
network are strictly separate activities. However,
deployment may also be a continuous process,
with more nodes being deployed at any time
during the use of the network, for example, to
replace failed nodes or improve coverage at certain
interesting locations.
The actual type of deployment affects important
properties such as the expected node density,
node locations, regular patterns in node
locations, and the expected degree of network
dynamics.
Classes: random vs. manual; one-time vs. iterative.
MOBILITY
Sensor nodes may change their location after initial
deployment. Mobility can result from environmental
influences such as wind or water, sensor
nodes may be attached to or carried by mobile
entities, and sensor nodes may possess automotive
capabilities. In other words, mobility may be
either an incidental side effect or a desired property
of the system (e.g., to move nodes to interesting
physical locations), in which case mobility may
be either active (i.e., automotive) or passive (e.g.,
attached to a moving object not under the control
of the sensor node). Mobility may apply to all
nodes within a network or only to subsets of
nodes. The degree of mobility may also vary from
occasional movement with long periods of immobility
in between to constant travel.
Mobility has a large impact on the expected
degree of network dynamics, and hence influences
the design of networking protocols and
distributed algorithms. The actual speed of
movement may also have an impact, for example,
on the amount of time during which nodes
stay within communication range of each other.
Classes: immobile vs. partly vs. all; occasional
vs. continuous; active vs. passive.
COST, SIZE, RESOURCES, AND ENERGY
Depending on the actual needs of the application,
the form factor of a single sensor node may vary
from the size of a shoebox (e.g., a weather station)
to a microscopically small particle (e.g., for military
applications where sensor nodes should be almost
invisible). Similarly, the cost of a single device may
vary from hundreds of Euros (for networks of very
few but powerful nodes) to a few cents (for largescale
networks made up of very simple nodes).
Since sensor nodes are untethered
autonomous devices, their energy and other
resources are limited by size and cost constraints.
Varying size and cost constraints directly result
in corresponding varying limits on the energy
available (i.e., size, cost, and energy density of
batteries or devices for energy scavenging), as
well as on computing, storage and communication
resources. Hence, the energy and other
resources available on a sensor node may also
vary greatly from system to system. Power may
be either stored (e.g., in batteries) or scavenged
from the environment (e.g., by solar cells).
These resource constraints limit the complexity
of the software executed on sensor nodes.
For our classification, we have partitioned sensor
nodes roughly into four classes based on their
physical size: brick, matchbox, grain, and dust.
HETEROGENEITY
Early sensor network visions anticipated that
sensor networks would typically consist of homogeneous
devices that were mostly identical from
a hardware and software point of view. Some
projects, such as Amorphous Computing [3],
even assumed that sensor nodes were indistinguishable,
that is, they did not even possess
unique addresses or IDs within their hardware.
This view was based on the observation that otherwise
it would not be feasible to cheaply produce
vast quantities of sensor nodes.
However, in many prototypical systems available
today, sensor networks consist of a variety of
different devices. Nodes may differ in the type
and number of attached sensors; some computationally
more powerful “compute” nodes may collect,
process, and route sensory data from many
more limited sensing nodes; some sensor nodes
may be equipped with special hardware such as a
Global Positioning System (GPS) receiver to act
These resource
constraints limit the
complexity of the
software executed
on sensor nodes.
For our classification,
we have partitioned
sensor nodes roughly
into four classes
based on their
physical size: brick,
matchbox, grain,
and dust.
56 IEEE Wireless Communications • December 2004
as beacons for other nodes to infer their location;
some nodes may act as gateways to long-range
data communication networks (e.g., GSM networks,
satellite networks, or the Internet).
The degree of heterogeneity in a sensor network
is an important factor since it affects the
complexity of the software executed on the sensor
nodes and the management of the whole system.
Classes: homogeneous vs. heterogeneous.
COMMUNICATION MODALITY
For wireless communication among sensor
nodes, a number of communication modalities
can be used such as radio, diffuse light, laser,
inductive and capacitive coupling, or even sound.
Perhaps the most common modality is radio
waves, since these do not require a free line of
sight, and communication over medium ranges
can be implemented with relatively low power
consumption and relatively small antennas (a few
centimeters in the common sub-gigahertz frequency
bands). Using light beams for communication
requires a free line of sight and may interfere
with ambient light and daylight, but allows for
much smaller and more energy-efficient
transceivers than does radio communication.
Smart Dust [4], for example, uses laser beams for
communication. Inductive and capacitive coupling
only works over small distances, but may be used
to power a sensor node. Most passive radio frequency
identification (RFID) systems use inductive
coupling, for example. Sound or ultrasound is
typically used for communication under water or
to measure distances based on time-of-flight measurements.
Sometimes, multiple modalities are
used by a single sensor network system.
The communication modality used obviously
influences the design of medium access and
communication protocols, but also affects other
properties that are relevant to the application.
Classes: radio vs. light vs. inductive vs. capacitive
vs. sound.
INFRASTRUCTURE
The various communication modalities can be
used in different ways to construct an actual
communication network. Two common forms are
so-called infrastructure-based networks on one
hand and ad hoc networks on the other hand. In
infrastructure-based networks, sensor nodes can
only directly communicate with so-called base
station devices. Communication between sensor
nodes is relayed via the base station. If there are
multiple base stations, these have to be able to
communicate with each other. The number of
base stations depends on the communication
range and the area covered by the sensor nodes.
Mobile phone networks and Smart Dust [4] are
examples of this type of network.
In ad hoc networks, nodes can directly communicate
with each other without an infrastructure.
Nodes may act as routers, forwarding messages
over multiple hops on behalf of other nodes.
Since the deployment of an infrastructure is a
costly process, and the installation of an infrastructure
may often not be feasible, ad hoc networks
are preferred for many applications.
However, if an infrastructure is already available
anyway (e.g., the GSM network), it might also be
used for certain sensor network applications.
Combinations of ad hoc and infrastructurebased
networks are sometimes used, where clusters
of sensor nodes are interconnected by an
infrastructure-based wide area network.
Note that the above arguments not only apply
to communication, but also to other infrastructures,
such as localization or time synchronization
(e.g., GPS satellites).
Classes: infrastructure vs. ad hoc.
NETWORK TOPOLOGY
One important property of a sensor network is its
diameter, that is, the maximum number of hops
between any two nodes in the network. In its
simplest form, a sensor network forms a single-hop
network, with every sensor node able to directly
communicate with every other node. An infrastructure-based
network with a single base station
forms a star network with a diameter of two. A multihop
network may form an arbitrary graph, but often
an overlay network with a simpler structure is constructed
such as a tree or a set of connected stars.
The topology affects many network characteristics
such as latency, robustness, and capacity.
The complexity of data routing and processing
also depends on the topology.
Classes: single-hop vs. star vs. networked stars
vs. tree vs. graph.
COVERAGE
The effective range of the sensors attached to a
sensor node defines the coverage area of a sensor
node. Network coverage measures the degree
of coverage of the area of interest by sensor
nodes. With sparse coverage, only parts of the
area of interest are covered by the sensor nodes.
With dense coverage, the area of interest is completely
(or almost completely) covered by sensors.
With redundant coverage, multiple sensors
cover the same physical location. The actual
degree of coverage is mainly determined by the
observation accuracy and redundancy required.
Coverage may vary across the network. For
example, nodes may be deployed more densely
at interesting physical locations.
The degree of coverage also influences information
processing algorithms. High coverage is
key to robust systems and may be exploited to
extend the network lifetime by switching redundant
nodes to power-saving sleep modes.
Classes: sparse vs. dense vs. redundant.
CONNECTIVITY
The communication ranges and physical locations
of individual sensor nodes define the connectivity
of a network. If there is always a
network connection (possibly over multiple
hops) between any two nodes, the network is
said to be connected. Connectivity is intermittent
if the network may be occasionally partitioned.
If nodes are isolated most of the time
and enter the communication range of other
nodes only occasionally, we say that communication
is sporadic. Note that despite the existence
of partitions, messages may be transported
across partitions by mobile nodes.
Connectivity mainly influences the design of
communication protocols and methods of data
gathering.
Classes: connected vs. intermittent vs. sporadic.
In its simplest form,
a sensor network
forms a single-hop
network, with every
sensor node being
able to directly
communicate with
every other node.
IEEE Wireless Communications • December 2004 57
NETWORK SIZE
The number of nodes participating in a sensor
network is mainly determined by requirements
relating to network connectivity and coverage,
and by the size of the area of interest. The network
size may vary from a few nodes to thousands
of sensor nodes or even more. The
network size determines the scalability requirements
with regard to protocols and algorithms.
LIFETIME
Depending on the application, the required lifetime
of a sensor network may range from some
hours to several years. The necessary lifetime
has a high impact on the required degree of
energy efficiency and robustness of the nodes.
OTHER QOS REQUIREMENTS
Depending on the application, a sensor network
must support certain quality-of-service (QoS)
aspects such as real-time constraints (e.g., a physical
event must be reported within a certain period
of time), robustness (i.e., the network should
remain operational even if certain well defined failures
occur), tamper-resistance (i.e., the network
should remain operational even when subject to
deliberate attacks), eavesdropping resistance (i.e.,
external entities cannot eavesdrop on data traffic),
and unobtrusiveness or stealth (i.e., the presence of
the network must be hard to detect). These
requirements may impact other dimensions of the
design space such as coverage and resources.
APPLICATIONS
In this section we justify our design space model
by locating a number of applications at different
points in the design space. For this, we have selected
concrete applications that are well documented
and have advanced beyond a mere vision. Some of
the applications listed are field experiments, some
are commercial products, and some are advanced
research projects that use sensor networks as a
tool. For classification, we have used the reported
parameters that were actually used in practical settings
and have deliberately refrained from speculation
as to what else could have been done.
Note that there are usually different technical
solutions for a single application, which means
that the concrete projects described below are
only examples drawn from a whole set of possible
solutions. However, these examples reflect
what was technically possible and desirable at
the time the projects were set up. Therefore, we
have decided to base our discussion on these
concrete examples rather than speculating about
the inherent characteristics of a certain type of
application. Table 1 classifies the sample applications
according to the dimensions of the design
space described in the previous section.
BIRD OBSERVATION ON GREAT DUCK ISLAND
A wireless sensor network (WSN) is being used to
observe the breeding behavior of a small bird
called Leach’s Storm Petrel [5] on Great Duck
Island, Maine, United States. These birds are easily
disturbed by the presence of humans, so a
WSN seems an appropriate way of better understanding
their behavior. The breeding season lasts
for seven months from April to October. Biologists
are interested in the usage pattern of their
nesting burrows, changes in environmental conditions
outside and inside the burrows during the
breeding season, variations among breeding sites,
and the parameters of preferred breeding sites.
Sensor nodes are installed inside the burrows
and on the surface. Nodes can measure humidity,
pressure, temperature, and ambient light level.
Burrow nodes are equipped with infrared sensors
to detect the presence of the birds. The burrows
occur in clusters, and the sensor nodes form a
multihop ad hoc network. Each network cluster
contains a sensor node with a long-range directional
antenna that connects the cluster to a central
base station computer. The base station
computer is connected to a database backend
system via a satellite link. Sensor nodes sample
their sensors about once a minute and send their
readings directly to the database backend system.
ZEBRANET
A WSN is being used to observe the behavior of
wild animals within a spacious habitat (e.g., wild
horses, zebras, and lions) [6] at the Mpala
Research Center in Kenya. Of particular interest
is the behavior of individual animals (e.g., activity
patterns of grazing, graze-walking, and fast
moving), interactions within a species, interactions
among different species (e.g., grouping
behavior and group structure), and the impact of
human development on the species. The observation
period is scheduled to last a year or more.
The observation area may be as large as hundreds
or even thousands of square kilometers.
Animals are equipped with sensor nodes. An
integrated GPS receiver is used to obtain estimates
of their position and speed of movement.
Light sensors are used to give an indication of
the current environment. Further sensors (head
up or down, body temperature, ambient temperature)
are planned for the future. Each node logs
readings from its sensors every 3 min. Whenever
a node enters the communication range of another
node, the sensor readings and identities of the
sensor nodes are exchanged (i.e., data is flooded
across network partitions). At regular intervals a
mobile base station (e.g., a car or plane) moves
through the observation area and collects the
recorded data from the animals it passes.
GLACIER MONITORING
A sensor network is being used to monitor subglacier
environments at Briksdalsbreen, Norway, with
the overall goal of better understanding the Earth’s
climate [7]. Of particular interest are displacements
and the dynamics inside the glacier. A lengthy
observation period of months to years is required.
Sensor nodes are deployed in drill holes at
different depths in the glacier ice and in the till
beneath the glacier. Sensor nodes are equipped
with pressure and temperature sensors and a tilt
sensor for measuring the orientation of the
node. Sensor nodes communicate with a base
station deployed on top of the glacier. The base
station measures supra-glacial displacements
using differential GPS and transmits the data
collected via GSM. Nodes are not recoverable
after deployment. Radio communication through
ice and water is a major problem.
Depending on the
application, the
required lifetime of a
sensor network may
range from some
hours to several
years. The necessary
lifetime has a high
impact on the
required degree of
energy efficiency
and robustness
of the nodes.
58 IEEE Wireless Communications • December 2004
CATTLE HERDING
A WSN is being used to implement virtual
fences, with an acoustic stimulus being given to
animals that cross a virtual fence line [8]. Movement
data from the cows controls the virtual
fence algorithm that dynamically shifts fence
lines. Such a system can reduce the overheads of
installing and moving physical fences, and
improve the usage of feedlots.
For the first experiment, each sensor node
consists of a PDA with a GPS receiver, a wireless
LAN (WLAN) card, and a loudspeaker for
providing acoustic stimuli to the cattle as they
approach a fence. These devices are attached to
the neck of the cows. The nodes form a multihop
ad hoc network, forwarding movement data
to a base station (a laptop computer). The base
station transmits fence coordinates to the nodes.
BATHYMETRY
A sensor network is being used to monitor the
impact on the surrounding environment of a
wind farm off the coast of England [9]. Of particular
interest here is the influence on the structure
of the ocean bed (e.g., formation of sand
banks) and on tidal activity.
Sensor nodes are deployed on the ocean bed
by dropping them from a ship at selected positions,
their location being fixed on the ocean bed
by an anchor. Each sensor node is connected via
a cable to a buoy on the ocean surface that contains
the radio equipment and GPS, since radio
communication under water is virtually impossible.
The sensor nodes are able to measure pressure,
temperature, conductivity, current, and
turbidity, and form a self-organized ad hoc network.
Deployment Mobility Resources Cost Energy Heterogeneity Modality
Great Duck Manual, one-time Immobile Matchbox ~200 USD Battery, solar Weather stations, Radio
burrow nodes,
gateways
ZebraNet Manual, one-time All, continuous, Matchbox — Battery Nodes, gateway Radio
passive
Glacier Manual, All, continuous, Brick — Battery Nodes, Radio
one-time passive base station
Herding Manual, one-time All, continuous, Brick ~1000 USD Battery Homogeneous Radio
passive
Bathymetry Manual, one-time All, occasional, Brick — Battery Homogeneous Radio
passive
Ocean Random, iterative All, continuous, Brick ~15000 USD Battery Homogeneous Radio
passive
Grape Manual, one-time Immobile Matchbox ~200 USD Battery Sensors, gateway, Radio
base station
Cold Chain Manual, iterative Partly (sensors), Matchbox — Battery Sensors, relays, Radio
occasional, (sensors), access boxes,
passive brick (relays) warehouse
Avalanche Manual, one-time All, continuous, Matchbox — Battery Homogeneous Radio
passive
Vital Sign Manual All, continuous, Matchbox — Battery Medical sensors, Radio, IR light
passive patient identifier, (for setup pen)
display device,
setup pen
Power Manual, iterative Immobile Matchbox — Power grid Sensor nodes, Radio (sensor
transceivers, unidirectional)
central unit
Assembly Manual, one-time All, occasional, Matchbox ~100 Euro Battery Different sensors Radio
passive
Tracking Random (thrown All, occasional, Matchbox ~ 200 USD Battery Homogeneous Radio
from aircraft) passive
Mines Manual All, occasional, Brick — Battery Homogeneous Radio,
active ultrasound (for
localization)
Sniper Manual Immobile Matchbox ~200 USD Battery Homogeneous Radio
with FPGA
Table 1. Classification of the sample applications according to the design space (continued on next page).
IEEE Wireless Communications • December 2004 59
OCEAN WATER MONITORING
The ARGO project [10] is using a sensor network
to observe the temperature, salinity, and
current profile of the upper ocean. The goal is a
quantitative description of the state of the upper
ocean and the patterns of ocean climate variability,
including heat and freshwater storage and
transport. Intended coverage is global, and observation
is planned to last for several years. Measurement
data is available almost in real time.
The project uses free-drifting profiling sensor
nodes equipped with temperature and salinity
sensors. The nodes are dropped from ships or
planes. The nodes cycle to a depth of 2000 m
every 10 days. Data collected during these cycles
is transmitted to a satellite while nodes are at
the surface. The lifetime of the nodes is about
four to five years.
GRAPE MONITORING
A WSN is being used to monitor the conditions
that influence plant growth (e.g., temperature, soil
moisture, light, and humidity) across a large vineyard
in Oregon, United States [11]. The goals
include supporting precision harvesting (harvesting
an area as soon as the grapes in it are ripe), precision
plant care (adapting the water/fertilizer/pesticide
supply to the needs of individual plants), frost
protection, predicting insect/pest/fungi development,
and developing new agricultural models.
In a first version of the system, sensor nodes are
n Table 1. Classification of the sample applications according to the design space (continued from previous page).
Infrastructure Topology Coverage Connectivity Size Lifetime QoS
Great Duck Base station, Star of clusters Dense (every Connected Tens–hundreds 7 months —
gateways burrow) (~100 (breeding
deployed) period)
ZebraNet Base station, GPS Graph Dense (every Sporadic Tens–hundreds One year —
animal)
Glacier Base station, Star Sparse Connected Tens–hundreds Several months —
GPS, GSM (9 deployed)
Herding Base station, GPS Graph Dense (every Intermittent Up to hundreds Days to weeks —
cow) (10 deployed)
Bathymetry GPS Graph Sparse (0.5– Connected Up to hundreds Several months —
1 km apart) (6 deployed,
50 planned)
Ocean Satellite Star Sparse Intermittent 1300 deployed, 4–5 years —
3000 planned
Grape Base station Tree (two-tiered Sparse (20 m Connected Up to hundreds Several months —
multihop) apart) (65 deployed) (growth period)
Cold Chain Relays, access Tree (three-tiered Sparse Intermittent Up to hundreds Years —
boxes multi-hop) (55 sensors,
4 relays deployed)
Avalanche Rescuer’s PDA Star Dense (every Connected Tens–hundreds Days (duration Dependability
person) (number of of a hike)
victims)
Vital Sign Ad hoc Single-hop Dense Connected Tens Days to months Real-time,
(hospital stay) dependability,
eavesdropping
resistance
Power Transceivers Layered Sparse Connected Tens–hundreds Years (building —
multihop (selected lifecycle)
outlets)
Assembly Ad hoc Star Sparse Connected Tens Hours (duration —
of assembly)
Tracking UAV Graph Sparse Intermittent Tens–thousands Weeks–years Stealth, tamper
(UAV) (5 deployed) (conflict resistance,
duration) real-time
Mines Ad hoc Graph Dense Connected Up to hundreds Months–years Tamper
(20 deployed) resistance
Sniper Ad hoc Graph Redundant Connected Up to hundreds Months–years Real-time
(multiple (60 deployed)
nodes recognize
shot)
 
60 IEEE Wireless Communications • December 2004
deployed across a vineyard in a regular grid about 20
m apart. A temperature sensor is connected to each
sensor node via a cable in order to minimize false
sensor readings due to heat disseminated by the sensor
nodes. A laptop computer is connected to the
sensor network via a gateway to display and log the
temperature distribution across the vineyard. The
sensor nodes form a two-tier multihop network, with
nodes in the second tier sending data to a node in
the first tier. Nodes in the first tier also collect sensor
data, but additionally act as data routers.
COLD CHAIN MANAGEMENT
The commercial Securifood system [12] is a
WSN for monitoring the temperature compliance
of cold chains from production, via distribution
centers and stores, to the consumer.
Clients receive an early warning of possible
breaks in the cold chain.
The system consists of four major components:
sensor nodes, relay units, access boxes, and a warehouse.
Sensor nodes are transported with the products
and collect temperature data. Relay units collect
and store temperature data from sensor nodes —
they are more powerful devices with a permanent
power supply. Multiple relay units form a multihop
ad hoc network. An access box is an even more powerful
embedded Linux device that acts as a gateway
between the network of relay units and the Internet.
There is one access box per production site. An
Internet-hosted data warehouse acts as a central
server, collecting data from all the access boxes. The
data warehouse provides an online image of all the
sensor data in the system and acts as a central data
repository for applications.
RESCUE OF AVALANCHE VICTIMS
A WSN is being used to assist rescue teams in saving
people buried in avalanches [13]. The goal is to
better locate buried people and to limit overall
damage by giving the rescue team additional indications
of the state of the victims and to automate the
prioritization of victims (e.g., based on heart rate,
respiration activity, and level of consciousness).
For this purpose, people at risk (e.g., skiers,
snowboarders, and hikers) carry a sensor node
equipped with an oximeter (a sensor that measures
the oxygen level in blood) that permits
heart rate and respiration activity to be measured.
Additionally, an oxygen sensor is used to
detect air pockets around the victim. Accelerometers
are used to derive the orientation of the
victim. The rescue team uses a PDA to receive
sensory data from buried victims.
VITAL SIGN MONITORING
Wireless sensors are being used to monitor vital
signs of patients in a hospital environment [14].
Compared to conventional approaches, solutions
based on wireless sensors are intended to
improve monitoring accuracy while also being
more convenient for patients.
The system consists of four components: a
patient identifier, medical sensors, a display device,
and a setup pen. The patient identifier is a special
sensor node containing patient data (e.g., name)
that is attached to the patient when he or she
enters the hospital. Various medical sensors (e.g.,
electrocardiogram) may be subsequently attached
to the patient. Patient data and vital signs may be
inspected using a display device. The setup pen is
carried by medical personnel to establish and
remove associations between the various devices.
The pen emits a unique ID via infrared to limit the
scope to a single patient. Devices that receive this
ID form a body area network.
POWER MONITORING
A WSN is being used to monitor power consumption
in large and dispersed office buildings [15].
The goal is to detect locations or devices that are
consuming a lot of power to provide indications
for potential reductions in power consumption.
The system consists of three major components:
sensor nodes, transceivers, and a central
unit. Sensor nodes are connected to the power
grid (at outlets or fuse boxes) to measure power
consumption and for their own power supply. Sensor
nodes directly transmit sensor readings to
transceivers. The transceivers form a multihop
network and forward messages to the central unit.
The central unit acts as a gateway to the Internet
and forwards sensor data to a database system.
PARTS ASSEMBLY
A WSN is being used to assist people during the
assembly of complex composite objects such as doit-yourself
furniture [16]. This saves users from having
to study and understand complex instruction
manuals, and prevents them from making mistakes.
The furniture parts and tools are equipped with
sensor nodes. These nodes are equipped with a variety
of different sensors: force sensors (for joints),
gyroscope (for screwdrivers), and accelerometers
(for hammers). The sensor nodes form an ad hoc
network for detecting certain actions and sequences
thereof, and give visual feedback to the user via
LEDs integrated into the furniture parts.
TRACKING MILITARY VEHICLES
A WSN is being used to track the path of military
vehicles (e.g., tanks) [17]. The sensor network should
be unnoticeable and difficult to destroy. Tracking
results should be reported within given deadlines.
Sensor nodes are deployed from an unmanned
aerial vehicle (UAV). Magnetometer sensors are
attached to the nodes in order to detect the proximity
of tanks. Nodes collaborate in estimating
the path and velocity of a tracked vehicle. Tracking
results are transmitted to the UAV.
SELF-HEALING MINE FIELD
Anti-tank landmines are being equipped with
sensing and communication capabilities to
ensure that a particular area remains covered
even if the enemy tampers with a mine to create
a potential breach lane [18]. If tampering is
detected by the mine network, an intact mine
hops into the breach using a rocket thruster.
The mines form a multihop ad hoc network
and monitor radio link quality to detect failed
mines. Nodes also estimate their location and orientation
using ultrasonic ranging. When a node
failure is detected, one of the mines is selected to
relocate itself using one of eight rocket thrusters.
SNIPER LOCALIZATION
A WSN is being used to locate snipers and the
trajectory of bullets [19], providing valuable
clues for law enforcement. The system consists
The commercial
Securifood system
is a WSN for
monitoring the
temperature
compliance of cold
chains from
production, via
distribution centers
and stores, to the
consumer. Clients
receive an early
warning of possible
breaks in the
cold chain.
IEEE Wireless Communications • December 2004 61
of sensor nodes that measure the muzzle blast
and shockwave using acoustic sensors. The sensor
nodes form a multihop ad hoc network. By
comparing the time of arrival at distributed sensor
nodes, the sniper can be localized with an
accuracy of about 1 m, and with a latency of
under 2 s. The sensor nodes use a field programmable
gate array (FPGA) chip to carry out
the complex signal processing functions.
CONCLUSIONS
There are several important consequences of the
design space as discussed above. Clearly, a single
hardware platform will most likely not be sufficient
to support the wide range of possible applications.
In order to avoid the development of
application-specific hardware, it would be desirable,
however, to have available a (small) set of
platforms with different capabilities that cover
the design space. A modular approach, where
the individual components of a sensor node can
be easily exchanged, might help to partially overcome
this difficulty. Principles and tools for
selecting suitable hardware components for particular
applications would also be desirable.
As far as software is concerned, the situation
becomes even more complex. As with hardware,
one could try to cover the design space with a
(larger) set of different protocols, algorithms,
and basic services. However, a system developer
would then still be faced with the complexity of
the design space, since each application would
potentially require the use of software with different
interfaces and properties.
In conventional distributed systems, middleware
has been introduced to hide such complexity
from the software developer by providing
programming abstractions that are applicable for
a large class of applications. This raises the question
of whether appropriate abstractions and
middleware concepts can be devised that are
applicable for a large portion of the sensor network
design space. This is not an easy task, since
some of the design space dimensions (e.g., network
connectivity) are very hard to hide from
the system developer. Moreover, exposing certain
application characteristics to the system and
vice versa is a key approach for achieving energy
and resource efficiency in sensor networks. Even
if the provision of abstraction layers is conceptually
possible, it would often introduce significant
resource overheads, which is problematic in
highly resource-constrained sensor networks.
At the workshop mentioned above, some possible
directions were discussed for providing general
abstractions despite these difficulties. One
approach is the definition of common service
interfaces independent of their actual implementation.
The interfaces would, however, contain
methods for exposing application characteristics to
the system and vice versa. Different points in the
design space would then require different implementations
of these interfaces. A modular software
architecture would then be needed, together
with tools that would semi-automatically select the
implementations that best fit the application and
hardware requirements. One possible approach
here is the provision of a minimal fixed core functionality
that would be dynamically extended with
appropriate software modules. We acknowledge
that all this is somewhat speculative. However,
research into software support for WSNs is still at
an early stage, and significant advances will be
required to approach the goal of easy and consistent
programmability, testing, and deployment of
applications across the design space.
In addition to these more technical issues, the
design space we advocate can hopefully bring
more clarity to the often somewhat diffuse discussions
about the typical or right characteristics
and requirements of wireless sensor networks.
REFERENCES
[1] “ESF Exploratory Workshop on Wireless Sensor Networks,”
http://www.vs.inf.ethz.ch/events/esf-wsn04
[2] S. Tilak, N. B. Abu-Ghazaleh, and W. Heinzelman, “A
Taxonomy of Wireless Micro-Sensor Network Models,”
MC2R, vol. 6, no. 2, Apr. 2002, pp. 28–36.
[3] H. Abelson et al., “Amorphous Computing,” CACM, vol.
43, no. 5, Mar. 2000, pp. 74–82.
[4] J. M. Kahn, R. H. Katz, and K. S. J. Pister, “Emerging Challenges:
Mobile Networking for Smart Dust,” J. Commun.
and Networks, vol. 2, no. 3, Sept. 2000, pp. 188–96.
[5] A. Mainwaring et al., “Wireless Sensor Networks for
Habitat Monitoring,” WSNA, Atlanta, GA, Sept. 2002.
[6] P. Juang et al., “Energy-Efficient Computing for Wildlife
Tracking: Design Tradeoffs and Early Experiences with
ZebraNet,” Proc. ASPLOS X, San Jose, CA, Oct. 2002.
[7] K. Martinez et al., “GLACSWEB: A Sensor Web for Glaciers,”
Adjunct Proc. EWSN 2004, Berlin, Germany, Jan. 2004.
[8] Z. Butler et al., “Networked Cows: Virtual Fences for Controlling
Cows,” WAMES 2004, Boston, MA, June 2004.
[9] I. W. Marshall et al., “Self-Organizing Sensor Networks,”
UbiNet 2003, London, U.K., Sept. 2003.
[10] “ARGO — Global Ocean Sensor Network,” http://
www.argo.ucsd.edu
[11] R. Beckwith, D. Teibel, and P. Bowen. “Pervasive Computing
and Proactive Agriculture,” Adjunct Proc. PERVASIVE
2004, Vienna, Austria, Apr. 2004.
[12] R. Riem-Vis, “Cold Chain Management Using an Ultra
Low Power Wireless Sensor Network,” WAMES 2004,
Boston, USA, June 2004.
[13] F. Michahelles et al., “Applying Wearable Sensors to
Avalanche Rescue,” Computers and Graphics, vol. 27,
no. 6, 2003, pp. 839–47.
[14] H. Baldus, K. Klabunde, and G. Muesch. “Reliable SetUp
of Medical Body-Sensor Networks,” Proc. EWSN
2004, Berlin, Germany, Jan. 2004.
[15] C. Kappler and G. Riegel, “A Real-World, Simple Wireless
Sensor Network for Monitoring Electrical Energy Consumption,”
Proc. EWSN 2004, Berlin, Germany, Jan. 2004.
[16] S. Antifakos, F. Michahelles, and B. Schiele, “Proactive
Instructions for Furniture Assembly,” Proc. Ubicomp
2002, Gothenburg, Sweden, Sept. 2002.
[17] “The 29 Palms Experiment: Tracking Vehicles with a
UAV-delivered Sensor Network,” tinyos.millennium.
berkeley.edu/29Palms.htm
[18] W. M. Meriall et al., “Collaborative Networking
Requirements for Unattended Ground Sensor Systems,”
Proc. IEEE Aerospace Conf., Mar. 2003.
[19] G. Simon, A. Ledezczi, and M. Maroti. “Sensor Network-Based
Countersniper System,” Proc. SenSys, Baltimore,
MD, Nov. 2004.
BIOGRAPHIES
KAY RÖMER (roemer@inf.ethz.ch) received his Master’s
degree with honors from the University of Frankfurt/Main,
Germany, in 1999. Since 1999 he has been a research
assistant and Ph.D. student at ETH Zurich, Switzerland. His
research interests encompass sensor networks, software
infrastructures for ubiquitous computing, and middleware
for distributed systems.
FRIEDEMANN MATTERN (mattern@inf.ethz.ch) has been a full
professor of computer science at ETH Zurich since 1999. He
is a founding member of the Institute for Pervasive Computing
and heads the Computer Science Department's distributed
systems group. His research interests include
distributed systems and ubiquitous computing. He received
his Ph.D. from the University of Kaiserslautern and served
as professor of computer science at the University of Saarbrucken
from 1991 to 1994, and at Darmstadt University
from 1994 to 1999.
Research into
software support for
WSNs is still at an
early stage, and
significant advances
will be required to
approach the goal of
easy and consistent
programmability,
testing, and
deployment of
applications across
the design space.

1998 IEEE INTERNATIONAL FREQUENCY CONTROL SYMPOSIUM
WIRELESS PASSIVE SAW SENSOR SYSTEMS
FOR INDUSTRIAL AND DOMESTIC APPLICATIONS
G. Scholl, F. Schmidt, T. Ostertag, L. Reindl, H. Scherr, U. Wolff
Siemens AG, Corporate Research and Development, Munich, Germany
Introduction
Sensor systems with unique features can be realized by
combining radar techniques and wireless passive surface
acoustic wave (SAW) sensors. Compared with
conventional telemetry systems the main features are a
large readout distance of several meters and that SAW
sensors do not require a battery or any other power supply.
Another advantage is that SAW sensors are fabricated on
highly stable single crystals and are therefore nearly tiee
of aging. Wireless passive SAW sensors can be
advantageously placed on moving or rotating parts and in
hazardous environments such as contaminated areas or
high-voltage plants. They can also be used for contactless
measurements in high-vacuum process chambers, under
concrete, extreme heat, or strong radioactive radiation,
where the use of conventional sensors is impossible,
dangerous or expensive. SAW sensors can also be
employed to increase comfort or safety at home, e.g. with
personal switches or SAW based security systems.
A high-frequency electromagnetic wave emitted from a
radar unit in fig. 1 is received by the antenna of the SAW
sensor. The interdigital transducer (IDT), which is
connected to the antenna, transforms the received signal
into a surface acoustic wave (SAW). The SAW propagates
on the piezoelectric crystal and is partially reflected by
reflectors placed in the acoustic path. The reflected waves
are reconverted into an electromagnetic pulse train by the
IDT and are retransmitted to the radar unit. The highfrequency
electromagnetic signal is amplified and
downconverted to the baseband frequency in the RF
module of the radar unit. The sensor signals are then
analyzed with adigital signal processor. Finally the
measurement results can be transferred to a personal
computer for post processing and data storage. The
velocity of a SAW is approximately the factor 100 000
smaller than the velocity of light or radio signals.
Therefore signals can be delayed efficiently on a small
chip. A time delay of 1 ps requires a chip length between
1.5 mm and 2 mm (the path length between IDT and
reflecor isused twice), depending on the substrate
material, whereas in 1 p a radio signal propagates 300 m
in free space. Therefore the pulse response of SAW
sensors with time delays of several microseconds can be
Antonna SAW-Sonaw
,/ SAWChip
Figure 1. Schematic drawing of an RF SAW sensor
system.
separated easily from environmental echoes, which
typically fade away in less than 1-2 p. If the reflectors are
arranged in a predefmed bit pattern like a bar code an RF
identification system can be realized with areadout
distance of several meters. Using a standard code of 32
bits (reflectors) it is possible to distinguish between 2’* or
more than four billion objects, animals or people. The
reflectivity at the acoustic ports of an IDT depends on the
termination impedance at the electrical port. Therefore
SAW binary sensors can be achieved by switching the
electrical port of a reflective element from the short to the
open circuited state. An example will be given in the first
paragraph. A change in a physical or chemical quantity
generates a variation in the propagation properties of the
SAW. This effect is used for wireless passive SAW
temperature, pressure and torque sensors, which we will
discuss in the following sections. We will also present
several industrial applications, starting with an RF-IDsystem
for the Munich subway. We then demonstrate the
usefulness of SAW sensors for the diagnosis and control
of electrical motors. The possibility to read out SAW
sensors over large distances makes them the ideal
candidate for high-voltage applications, as isolation
problems can be avoided. We report on the first SAW
based monitoring system for high-voltage surge arresters
and show the latest result of a field test carried out at a
420 kV-substation ear the nuclear power plant of
Brunsbiittel, Germany. Finally we discuss possible
application fields for the private home. Electronic systems
in the domestic area are extremely cost sensitive. For
implementing a low-cost radar unit we investigated
different system architectures. A radar unit based on a
FMCW concept will be presented.
0-7803-4373-5/98/$10.00 0 1998 EEE 595 
Binary SAW Sensors SAW Temperature Sensors
In fig. 2 a Reed element is connected to a reflective
element of a binary SAW sensor. Here an IDT plays the
role of a reflector. If the sensor is accelerated beyond a
r
Reed Element
Figure 2. Binary SAW sensor with switchable reflectors.
specific value, the magnet moves and causes the Reed
contact to change from the open circuited state to the short
circuited state or vice versa. In the upper diagram of fig. 3
all 3 reflectors have the same reflectivity. In the lower
diagram the third reflector is shorted by the Reed element.
A change of approximately 30 dB in the reflectivity can be
c
L 4 I
time [PI
Figure 3. Time domain response of a binary
SAW sensor with switchable reflectors.
observed.
Sensors of this type can be used as sector-alignment
indicators, for checking switch positions, or generally as
radio accessible switches. In the same manner also
classical sensors with a varying impedance can be read out
wirelessly when combined with a SAW transponder.
A change in the environmental temperature A9 results in a
variation of the path length AI and a variation of the
SAW velocity AV. Thus the propagation time r changes
according to
where TCD, represents the fust order temperature
coefficient of delay. On the high coupling YZLithiumniobate
(LiNbO3) substrate the temperature
coefficient of delay is 85 ppM, where the thermal
expansion coefficient is one order smaller compared to the
temperature coefficient of velocity. On special cuts of
Quartz like STX-Quartz the variation in the path length is
compensated by the variation of the SAW velocity in the
first order. Therefore Quartz substrates are traditionally
used for mechanical sensors [l] and LiNbO3 for
temperature sensors [2]. A SAW temperature sensor with
four reflectors and a center frequency of 433 MHz
mounted in a standard SMD package is shown in fig. 4.
The time domain response of an equivalent temperature
sensor at 869 MHz is depicted in fig. 5. The readout
distance was approximately 0.5 m. The delay time is
2.5 p. The sensor pulses are separated by 0.84 PS, 0.7 ps
and 0.73 p, respectively. The reflectors were designed for
high reflectivity to achieve a small return loss of 28 dB.
Therefore the pulses following the four main response
peaks, which are due to multiple reflections between the
reflectors and between the reflectors and the IDT, are only
suppressed by 20 dB. In order to eliminate the influence of
the radio channel on the sensor signal, we only evaluate
differences in the time delay or phase between the sensor
Figure 4. SAW temperature sensor with 4 reflectors
mounted in a SMD package.
596 
-4a2a
D12345678910
i
t1w Cpsl
Figure 5. Measured time domain response of a
SAW reflective delay line.
pulses ("on chip reference"). With the time length between
the first and the last reflector of AT,,,= = 2.27 p, a
measured temperature coefficient of delay of 85 ppm/K
and .a phase resolution of our radar unit of k 1" a
temperature resolution of 0.02 K can be achieved - of
course only with a sufficient signal to noise ratio. If the
temperature varies more than 6 "C the phase shift is
greater than 360" so that a phase ambiguity occurs. This
means that if one is interested not only in measuring
relative temperature changes, but also in determining
absolute temperature values, a minimum of three reflectors
are needed. If the sensors should operate over a broad
temperature range even more than three reflectors are
favorable. The exact number of reflectors is determined by
the desired temperature resolution, the temperature range
and the phase resolution of the radar unit. Our temperature
sensors were successhlly tested from - 196 "C, the
temperature of fluid nitrogen, to several hundred "C. Up to
approximately 200 "C standard package technology can be
used. Above 200 "C special adhesives, solder materials
and printed circuit boards must be employed. Aluminum
electrodes withstand temperatures up to 450 "C. Between
400 "C and 500 "C, where semiconductor devices are
irreversibly damaged, LiNbO, substrates are stable for
several days. For temperature measurements up to
1000 "C we investigate different electrode and substrate
materials [3].
ant-w
Figure 6. Schematic drawing of a SAW pressure sensor.
The diaphragm was then attached to the Quartz coverplate
with an epoxy-adhesive. This all Quartz package
sensor is expected to have minimal thermal stress and
therefore a small temperature sensitivity. For pressure
sensors for which a durability of several years are required
we also apply the glass frit technology already described
in [4]. To determine the geometry of the sensor we use a
Finite Element Method (FEM) program, since it is very
difficult to compute the mechanics of anisotropic materials
analytically. We calculated the bending of the diaphragm
(fig. 7) and the cover plate as well as the stress /strain
distribution (fig. 8). From this calculation and from our
assumption that Quartz will break at a strain of
approximately S= lo", we determine the size of the
diaphragm and the depth of the blind-hole. In fig. 8 it can
be seen that compressed and stretched sections exist. The
phase velocity of the SAW is slower in the stretched
section, whereas it is faster in the compressed section. The
reflective delay line requires at least 3 reflectors. For
optimal reflector configuration two of them are ideally
positioned at the transitions between the stretched and
compressed sections. Because this pressure sensor was
used as a test device, we divided the delay path by 10
instead of 3 reflectors to get more details. In fig. 9 we
SAW Pressure Sensors
A schematic drawing of a SAW pressure sensor is shown
in fig. 6. The SAW propagates on a Quartz diaphragm,
bending under hydrostatic pressure. To bend the
diaphragm in a defined manner, there has to be a constant
reference-pressure at the other side of the diaphragm. This Figure 7. FEM analysis of the membrane
is realized by a hermetically closed cavity with the deformation just before breaking at a pressure of
reference pressure inside. Therefore with a sand-blast unit 600 kPa. The dark frame represents the adhesion
a blind-hole was structured into a Quartz cover plate, area of the membrane and the cover plate.
which is of the same substrate material as the diaphragm.
597 
0 2 4 6 8 10 12 14 16 18 20
loution a1 di.phmgm /mm
Figure. 8. Calculated strain of the diaphragm at a
pressure of 250 kPa -, positions of the interdigital
transducer and the 10 reflectors *.
compare the measured and calculated phase differences
between pulses reflected from adjacent reflectors. We
achieved a very good agreement except at the boundary of
the membrane due to mechanical deformations caused by
the joining of the Quartz plates. SAW pressure sensors can
for example also be used for pressure measurements in
tires or gas-insulated high-voltage switching stations.
1001
80 n
Figure 9. Comparison of phase differences Acp
between reflected pulses at a pressure of 250 kPa
(measured results: 1, calculated results: 0 ).
SAW Torque Sensors
Contactless slip ring free torque measurements can be
carried out with passive RF SAW torque sensors without
the need for breaking up the driving shaft. SAW torque
measurement systems can also operate in industrial
environments with strong electromagnetic interference due
to their high operating frequencies between several
hundred MHz and approximately 3 GHz and the inherent
broadband nature of the SAW sensors. This has been
proven by torque measurements in a 750 kW high-voltage
motor as well as with an identification system for railway
applications, where no interference with the parasitic
radiations of high-power inverters could be observed.
Figure 10. Surface deformation caused by a
torque acting on a shaft.
Another advantage is that SAW sensors offer greater
readout distances compared to conventional RF powered
or magnetically coupled systems. SAW sensors measure,
like resistive strain gauges, the torque indirectly by
detecting the strain or stress distribution generated by a
torque acting on the shaft (fig. 10). The fact that the strain
has an opposite sign in f 45" directions relative to the
shaft axis can be used for temperature compensation. We
investigated Quartz and LiNbO, as substrate materials.
LiNbO, has a much higher electromechanical coupling
coefficient and lower propagation losses than Quartz,
whereas on Quartz substrates the temperature coefficient
of delay vanishes in the first order and the anisotropy in
the extension caused by temperature variations is smaller,
i. e. LiNbO, exhibits better electrical parameters and
Quartz better mechanical parameters for this application.
In our experiments we mounted two sensor elements in a
cohunon housing with a relative angular displacement of
90". In addition, we also made sensor elements with two
and three overlapping SAW paths, oriented in different
directions, on a single chip. The sensors were tested on a
hollow shaft that was heated or cooled by circulating
water. Torque was generated by applying weights to a
crank rigidly mounted to the shaft. Following a typical
design rule for steel shafts, nominal torque by definition
causes a shear stress of 35 N/mm2 at the shaft's surface.
The resulting strain in f45" directions to the shaft's axis at
nominal torque M, is E*.,~~ = 32,2.104. In our experiments,
the test shaft had a diameter of 20 mm, and the nominal
torque value of approximately 50 Nm was exerted by a
10 kg weight on a 0.5 m long lever arm. The packaged
sensors were attached to the shaft by use of two annular
clamps. Other methods, as bonding the SAW crystals on
planarized facets of the shaft, may allow more efficient
strain transmission to the sensor. However, they are
unsuitable for sensor application to motors and machinery
in a production environment. We were able to show that
even on the temperature sensitive LiNbO,, where the
temperature coefficient exceeds the desired sensor effect
by more than one order a simultaneous measurement of
torque and temperature is possible. We determined the
temperature-torque characteristics of our sensor, covering
598 
30"
20"
10" 2 $0"
g -204
-10"
-30"
-1.5 -1.0 -0.5 0.0 0.5 1.0 1.5
torque /multiples of nominal value
Figure 11. Phase difference vs. torque measured at
temperatures between 0 "C and 75 "C.
a range extending ftom 0°C to 75°C and fiom -1.5 M, to
l .5 M,,, respectively (fig. 11). The torque response clearly
depends on temperature; what is decisive, however, is that
there is an unambiguous relation between measured phase
difference and torque for all temperatures. The deviation
of the response functions fiom linearity is small. As a
consequence, a third order polynomial fit in torque and
temperature matched the measured characteristics of
fig. 11 with an accuracy of 1%.
Sensor Systems for Industrial Applications
Intelligent sensor systems play a vital role for power
generation, power transmission and distribution, for largesize
plant construction, for production, transportation,
automation and drives because they help to reduce waste,
labor and energy costs, protect expensive equipment,
extend equipment life and optimize the process efficiency.
They also provide a predictive capability to avoid
unscheduled downtime and allow maintenance on
demand. That SAW sensor systems can improve control,
monitoring and diagnosis systems will be demonstrated in
the following sections.
SAW Identifkation Systems
A readout procedure lasts only afew microseconds.
Therefore 100 000 interrogations per second can be
carried out. This permits the reliable identification of
particularly fast moving objects. The first identification
system for which Siemens shipped 200 000 identification
tags was installed at toll stations on Oslo's expressways,
where vehicles are identified remotely without stopping.
Our latest ID-system SOFIS is optimized for railway
applications. SOFIS operates at 2.45 GHz and has a
readout distance of 1.3 m. The maximum velocity of a
train passing by can be 350 M. The identification tag
has 16 data bits. Among other places this system is also
installed in Munich for the purpose of accounting. A
subway car to which a SAW identification tag is attached
can be seen in fig. 12. SAW ID tags not only make it easy
to identify vehicles, containers, workpieces, people or
animals, they also can for example be used for presence
detection and theft protection.
Figure 12. SAW ID tag with antenna mounted
on a subway car.
Motor Diagnosis and Control
SAW sensor systems can also be advantageously be used
for the measurement of vibrations, rotor temperature or
torque in electric motors. We successfully tested our SAW
sensors in a small 11 kW asynchronous motor as well as in
a high-power 750 kW two-pole machine. In fig. 13 a
temperature sensor was mounted on the short-circuiting
ring of the rotor of the 1 I kW motor. The SAW sensor
was read out with awire loop antenna, which was
mounted on the bearing plate. The motor was loaded with
an eddy-current brake. During run-up and operation under
load the motor warms up, as it is expected. When the
1
Figure 13. Temperature behavior of the rotor of a
11 kW asynchronous motor during operation.
599 
80
60
E 40
= 20 Q)
c
-20
-40 ' I
0 0.02 0.04 0.06 0.08 0.1 0.12
time [S]
Figure 14. Change in the measured torque after a
step excitation of the nominal value of the inverter
(- SAW sensor, - - - reference sensor).
motor is standing still the temperature curve shows an
exponential decay. The crosses mark temperature
measurements with a reference thermometer. Because the
thermal contact of the reference thermometer and the
SAW device are not identical, there is a slight difference
between the measured temperature values. Fig. 14 shows
the behavior of the torque after a step excitation of the
nominal value of the inverter. Because the test stand was
inverter controlled torque increases relatively slowly with
time. The solid line shows the measurement results of the
SAW system, whereas the dashed curve represents the
measured values of a reference shaft torque sensor
connected between the driving and the load machine.
Monitoring System for High-Voltage
Surge Arresters
The benefit of SAW sensor systems for power
transmission and distribution systems can be recognized
with the following example. In December last year
Siemens in cooperation with PreussenElektra started a
field test with a SAW temperature monitoring system for
high-voltage surge arresters at a 420 kV-substation near
the nuclear power plant of Brunsblittel, Germany. Surge
arresters are used to protect the equipment from excessive
overvoltages. In fig. 15 a surge arrester built up of two
stacked units can be seen. Inside the porcelain insulators
many metal oxide (MO) varistors are piled up (fig. 16).
Some of the varistors were substituted by aluminum
housings with a SAW sensor inside. The slot in the wall of
the housing serves as sensor antenna. Each porcelain
housed arrester unit was equipped with one SAW
temperature sensor positioned approximately at the center
of the MO varistor inserts. A third SAW sensor was
mounted outside of the insulators at the intermediate
flanges of the arrester, as indicated in fig. 15. The antenna
of the radar unit and the RF frontend module are attached
Figure 15.420 kV surge arrester in a PreussenElektra
substation, equipped with a SAW temperature
monitoring system.
to an overhang beam at the arrester base. The RF frontend
is connected to the signal processing part of the radar unit
by a coaxial cable laid in the ground. The measured data
can be remotely accessed by a radio modem connected to
the radar unit. The main features of this SAW temperature
measurement system are that a possible long term
temperature increase (aging), sudden temperature rises
(event counter) and the energy absorbed by discharge
currents (energy monitor) of the arrester during its lifetime
can be easily detected. The energy monitor - a feature,
which has not been available for this application so far - is
based on the fact that there exists a simple correlation
MOslot
mtenna housing
Aluminium housing
/ Slot
Sensor chip
Figure 16. SAW temperature sensor in a stack of
MO varistors.
600 
30, , , , , , , , , , , ,
25
20
15
El0
5
0
-5
-lOL!!!!!!!!!!!l
12IlWlS97
o to 20 30 40 50 80 70 m W loo 110 120
time [dm1
Figure 17. Temperatures of the 2 units of a highvoltage
surge arrester and ambient temperature
measured by a SAW monitoring system over a time
period of approximately 4 months.
between temperature rise and the absorbed energy. In
fig. 17 the temperature curves taken over approximately 4
months can be seen. Since the beginning of the field test
the system has reliably operated without any failure. Other
possible high-voltage applications are temperature
measurements from high-voltage open-air transmission
lines, monitoring of the gas density in high-voltage gasinsulated
transmission lines or control of the contact
position of high-voltage circuit breakers.
SAW Sensor Systems for the Private Home
Temperature monitoring of the hot plate, the cook-stove
the refrigerator or the heating system, SAW temperature
sensors in a cooking-pot or in a spit, binary SAW radio
sensors for theft protection, emergency systems or for the
control of windows, doors or the shade or simply for
passive remote control systems are the applications we see
in the private home. Because such applications are
extremely more cost-sensitive than industrial applications,
we studied different system architectures to realize a lowcost
radar unit. In fig. 18 the block diagram of a radar unit
based on a FMCW architecture for 433 MHz is depicted.
The advantage of this architecture is that no fast electronic
components are needed as compared to pulse or pulse
compression radars. The DSP controls the modulation
signal of the Quartz stabilized direct digital synthesizer
(DDS), generating a linear frequency sweep at 10.7 MHz.
This digital signal is converted into an analog one and
serves itself as reference for the phase-locked loop (PLL)
operating at 433 MHz. The RF signal is then filtered,
amplified and transmitted over the antenna. The
transmitted pulse has a time length much longer than the
time distance between two adjacent reflectors on the SAW
sensor. The RF signal received from the SAW sensor is
first amplified and then correlated with the transmitted
signal, resulting in a low-frequency signal, where the
sensor information is given in the frequency domain. To
eliminate environmental echoes the signal is frst filtered
and then digitized in a 12 Bit A/D-converter. Finally a fast
Fourier transform is carried out for the evaluation of the
time or phase differences between the reflected pulses of
the SAW sensor.
t I lo1
Figure 18. Low-cost radar unit for domestic
applications.
Conclusion
We discussed the principle of wireless sensing with
passive SAW devices and investigated binary SAW
sensors and other SAW radio sensors for the non-contact
measurement of temperatures, pressures and torques. An
RF identification system for the Munich subway, a SAW
sensor system for the diagnosis and control of electric
motors and a temperature monitoring system for highvoltage
surge arresters are the applications which were
presented. Finally a low-cost radar unit for domestic
applications was described.
Acknowledgment
The authors would like to thank W.-E. Bulst for
continuous encouragement. We thank B. Bienert,
S. Berek, H. Zottl for quick SAW device fabrication and
K. Riek for joining the SAW pressure sensors. We also
thank our partners in the business units for the support of
our work.
References
[l] F. Seifert, W.-E. Bulst, C.C.W. Ruppel, “Mechanical
Sensors Based on Sufrace Acoustic Waves,” Sensors and
Actuators, vol. A44, pp. 231-239, 1994.
[2] X. Q. Bao, W. Burkhard, V.V. Varadan, V.K. Varadan,
“SAW Temperature Sensor and Remote Reading System,”
Proceedings of the IEEE Ultrasonics Symposium, pp. 519-525,
1985.
[3] J. Homsteiner, E. Bom, G. Fischerauer, E. Riha, “Surface
Acoustic Wave Sensors for High-Temperature Applications,”
Proceedings of the IEEE Frequency Control Symposium 1998.
[4] T.E. Parker, J. Callerame, G. K. Montress, “A New All
Quartz Package for SAW devices,“ Proceedings of the IEEE
Frequency Control Symposium, pp. 519-525, 1985.
60 1 

Versatile Low Power Media Access
for Wireless Sensor Networks
Joseph Polastre
Computer Science Department
University of California, Berkeley
Berkeley, CA 94720
polastre@cs.berkeley.edu
Jason Hill
JLH Labs
35231 Camino Capistrano
Capistrano Beach, CA 92624
jhill@jlhlabs.com
David Culler
Computer Science Department
University of California, Berkeley
Berkeley, CA 94720
culler@cs.berkeley.edu
ABSTRACT
We propose B-MAC, a carrier sense media access protocol for wireless
sensor networks that provides a flexible interface to obtain ultra
low power operation, effective collision avoidance, and high channel
utilization. To achieve low power operation, B-MAC employs
an adaptive preamble sampling scheme to reduce duty cycle and
minimize idle listening. B-MAC supports on-the-fly reconfiguration
and provides bidirectional interfaces for system services to optimize
performance, whether it be for throughput, latency, or power
conservation. We build an analytical model of a class of sensor network
applications. We use the model to show the effect of changing
B-MAC’s parameters and predict the behavior of sensor network
applications. By comparing B-MAC to conventional 802.11-
inspired protocols, specifically S-MAC, we develop an experimental
characterization of B-MAC over a wide range of network conditions.
We show that B-MAC’s flexibility results in better packet
delivery rates, throughput, latency, and energy consumption than
S-MAC. By deploying a real world monitoring application with
multihop networking, we validate our protocol design and model.
Our results illustrate the need for flexible protocols to effectively
realize energy efficient sensor network applications.
Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network Protocols;
D.4.4 [Operating Systems]: Communications Management
General Terms
Performance, Design, Measurement, Experimentation
Keywords
Wireless Sensor Networks, Media Access Protocols, Energy Effi-
cient Operation, Reconfigurable Protocols, Networking, Communication
Interfaces.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SenSys’04, November 3–5, 2004, Baltimore, Maryland, USA.
Copyright 2004 ACM 1-58113-879-2/04/0011 ...$5.00.
1. INTRODUCTION
In wireless sensor network deployments, reliably reporting data
while consuming the least amount of power is the ultimate goal.
One such application that drives the design of low power media access
control (MAC) protocols is environmental monitoring. Mainwaring
et. al. [12] and the UCLA Center for Embedded Network
Sensing [2, 6] have deployed wireless sensors for microclimate
monitoring that operate at low duty cycles with multihop networking
and reliable data reporting. They show that MAC mechanisms
must support duty cycles of 1% while efficiently transferring various
workloads and adapting to changing networking conditions.
These workloads include periodic data reporting, bulk log transfer,
and wirelessly reprogramming a node. In this paper we discuss the
design of a MAC protocol motivated by monitoring applications.
Nodes in a wireless sensor network do not exist in isolation;
rather they are embedded in the environment, causing network links
to be unpredictable [16]. As the surrounding environment changes,
nodes must adjust their operation to maintain connectivity. For example,
RF performance may be hindered by a sudden rain storm or
the opening and closing of doors in a building.
Woo [21] and Zhao [24] have studied the volatility in link quality
in wireless sensor networks. Zhao shows the existence of “gray
areas” where some nodes exceed 90% successful reception while
neighboring nodes receive less than 50% of the packets. He shows
that the gray area is rather large–one-third of the total communication
range. Woo independently verified Zhao’s gray area findings.
In designing a reliable multihop routing protocol, Woo shows that
effectively estimating link qualities is essential. Snooping on traf-
fic over the broadcast medium is crucial for extracting information
about the surrounding topology. By snooping, network protocols
can prevent cycles, notify neighboring nodes of unreachable routes,
improve collision avoidance, and provide link quality information.
Since data must ultimately be reported out of the network, the media
access protocol must be flexible to meet changing network protocol
demands.
Not only are the networking conditions different, applications
for wireless sensor networks have different demands than those designed
for traditional ad-hoc wireless networks. Intanagonwiwat et.
al. [8] show how 802.11 is inappropriate for low duty cycle sensor
network data delivery. Idle listening in 802.11 consumes as much
energy when the protocol is idle as it does when receiving data. Idle
listening occurs when a node is active, but there is no meaningful
activity on the channel resulting in wasted energy. is no activity. It
is absolutely crucial that the MAC protocol support a duty cycling
mechanism to eliminate idle listening.
For wireless sensor networks to gain acceptance in the scientific
95
community, data must flow from the network predictably and reliably.
Scientists determine the sample period and physical deployment
of the nodes. The role of the network is to ensure that data
is delivered as expected. A general rule for achieving predictable
operation is to reduce complexity as much as possible from the
application and its services. Since each node executes a single application,
it is important to optimize communication performance
for that application–not for a generic set of users.
To meet the requirements of wireless sensor network deployments
and monitoring applications, we translate them to a set of
goals for the media access protocol. Our goals for a MAC protocol
for wireless sensor network applications are:
• Low Power Operation
• Effective Collision Avoidance
• Simple Implementation, Small Code and RAM Size
• Efficient Channel Utilization at Low and High Data Rates
• Reconfigurable by Network Protocols
• Tolerant to Changing RF/Networking Conditions
• Scalable to Large Numbers of Nodes
To meet these goals, we propose B-MAC, a configurable MAC
protocol for wireless sensor networks. It is simple in both design
and implementation. It has a small core and factors out higher layer
functionality. Factoring out some functionality and exposing control
to higher services allows the MAC protocol to support a wide
variety of sensor network workloads. This minimalist model of
MAC protocol design is in contrast to the classic monolithic MAC
protocols optimized for a general set of workloads; however this
paper shows the effectiveness of a small, configurable MAC protocol
that supports low duty cycle applications.
The contributions of this paper are not only the design of a versatile
MAC protocol for sensor networks. We propose an adaptive
bidirectional interface for wireless sensor network applications. The
interface allows middleware services to reconfigure the MAC protocol
based on the current workload. We build a model of application
performance that may be used to reconfigure B-MAC and
maximize a node’s lifetime. We use a comprehensive set of microbenchmarks
to experimentally characterize wireless sensor network
(WSN) performance. To validate the model, we built an environmental
monitoring application and show how its performance
matches our model’s predictions. Our model can be used to identify
the best parameters for an arbitrary low power wireless sensor
network application at compile or run time and estimate the application’s
lifetime. We illustrate the importance of reconfiguration
through simple optimizations that extend network lifetime by 50%.
2. RELATED WORK
Most MAC protocols for wireless sensor networks have been
based on conventional wireless protocols, especially 802.11. These
protocols typically provide a general purpose mechanism that works
reasonably well for a large set of traffic workloads. The previous
efforts serve as building blocks for designing a MAC protocol that
meets our goals.
The DARPA Packet Radio Network (PRNET) [10] was one of
the first ad-hoc multihop wireless networks. PRNET had two media
access protocols–Slotted ALOHA [1] and Carrier Sense Multiple
Access [9]. Much of the standard MAC protocol functionality–
including random delays, forwarding delays, link quality estimation,
and low duty cycle through node synchronization–were first
executed in PRNET. CSMA is validated as a way to efficiently use
the majority of the channel’s bandwidth while duty cycling nodes.
TDMA and slotted ALOHA solutions in PRNET were ultimately
dismissed due to their inability to scale.
Woo and Culler [20] illustrate the effect of changing the MAC
protocol based on the workload. They show that sensor network
application scenarios and network traffic characteristics differ significantly
from conventional computer networks. Typically data is
sent periodically in short packets. To achieve fairness and energy
efficient transmission through a multihop network, they design an
adaptive rate control protocol to that is optimized for n-to-1 data
reporting and multihop networking. Existing MAC protocols are
simply not suitable due to their failure to efficiently support sensor
network workloads in low duty cycle conditions.
Hill and Culler [7] demonstrate a form of preamble sampling to
reduce idle listening cost. In Hill’s RF wakeup scheme, the analog
baseband of the radio is sampled for energy every 4 seconds. By
quickly evaluating the channel’s energy, he reduced the duty cycle
of the radio to below 1%. He demonstrated the use of low power
RF wakeup on an 800 node multihop network. The ASK radio
used by Hill allows very brief radio sampling; we develop a related
technique that works on more complex radios.
Published concurrently with Hill’s work, Aloha with preamble
sampling [4] presents a low power technique similar to that used in
paging systems [13]. To let the receiver sleep for most of the time
when the channel is idle, nodes periodically wake up and check for
activity on the channel. If the channel is idle, the receiver goes back
to sleep. Otherwise, the receiver stays on and continues to listen
until the packet is received. Packets are sent with long preambles
to match the channel check period. El-Hoiydi [4] creates a model
for Aloha with preamble sampling and presents the effect of delay
due to long preambles. He proposes using the long preamble for
initial synchronization of nodes; afterwards the nodes transmit and
receive on a schedule with normal sized packets.
WiseMAC [5] is an iteration on Aloha with preamble sampling
specifically designed for infrastructure wireless sensor networks.
The main contribution of WiseMAC is an evaluation of the power
consumption of WiseMAC, 802.11, and 802.15.4 under low traffic
loads. They show that for the same delay, WiseMAC and preamble
sampling lowered power consumption by 57% over PSM used
in 802.11 and 802.15.4. WiseMAC meets many of our goals except
that it has no mechanism to reconfigure based on changing
demands from services using the protocol.
S-MAC [22] is a low power RTS-CTS scheme for wireless sensor
networks inspired by PAMAS [15] and 802.11. S-MAC periodically
sleeps, wakes up, listens to the channel, and then returns
to sleep. Each active period is of fixed size, 115 ms, with a variable
sleep period. The length of the sleep period dictates the duty
cycle of S-MAC. At the beginning of each active period, nodes exchange
synchronization information. Following the SYNC period,
data may be transferred for the remainder of the active period using
RTS-CTS. In a follow up paper [23], the authors add adaptive
listening–when a node overhears a neighbor’s RTS or CTS packets,
it wakes up for a short period of time at the end of their neighbor’s
transmission to immediately transmit its own data. By changing the
duty cycle, S-MAC can trade off energy for latency. S-MAC uses
fragmentation to deliver each piece of the message. Fragmentation
uses the RTS-CTS scheme to reserve the channel, then transmit
packets in a burst. Although S-MAC achieves low power operation,
it does not meet our goals of simple implementation, scalability,
and tolerance to changing network conditions. As the size of
the network increases, S-MAC must maintain an increasing number
of schedules of surrounding nodes or incur additional overhead
96
interface MacControl {
command result_t EnableCCA();
command result_t DisableCCA();
command result_t EnableAck();
command result_t DisableAck();
command void* HaltTx();
}
interface MacBackoff {
event uint16_t initialBackoff(void* msg);
event uint16_t congestionBackoff(void* msg);
}
interface LowPowerListening {
command result_t SetListeningMode(uint8_t mode);
command uint8_t GetListeningMode();
command result_t SetTransmitMode(uint8_t mode);
command uint8_t GetTransmitMode();
command result_t SetPreambleLength(uint16_t bytes);
command uint16_t GetPreambleLength();
command result_t SetCheckInterval(uint16_t ms);
command uint16_t GetCheckInterval();
}
Figure 1: Interfaces for flexible control of B-MAC by higher
layer services. These TinyOS interfaces allow services to toggle
CCA and acknowledgments, set backoffs on a per message
basis, and change the LPL mode for transmit and receive.
through repeated rounds of resynchronization.
T-MAC [19] improves on S-MAC’s energy usage by using a very
short listening window at the beginning of each active period. After
the SYNC section of the active period, there is a short window to
send or receive RTS and CTS packets. If no activity occurs in that
period, the node returns to sleep. By changing the protocol to have
an adaptive duty cycle, T-MAC saves power at a cost of reduced
throughput and additional latency. T-MAC, in variable workloads,
uses one fifth the power of S-MAC. In homogeneous workloads, TMAC
and S-MAC perform equally well. T-MAC suffers from the
same complexity and scaling problems of S-MAC. Shortening the
active window in T-MAC reduces the ability to snoop on surrounding
traffic and adapt to changing network conditions.
Many of these protocols have only been evaluated in simulation.
Not only must the protocol perform well in simulation, it must also
integrate well with the implementation of wireless sensor network
applications. Each of the protocols described in this section provide
solutions that meet a subset of our goals. Motivated by monitoring
applications for wireless sensor networks, we build upon ideas from
previously published work to create a reconfigurable protocol that
meets all of the goals from Section 1.
3. DESIGN AND IMPLEMENTATION
To achieve the goals outlined in Section 1, we designed a CSMA
protocol for wireless sensor networks called B-MAC, Berkeley Media
Access Control for low power wireless sensor networks. Although
B-MAC is motivated by the needs of monitoring applications,
the flexibility of our protocol allows allows other services
and applications to be realized efficiently. These services include,
but are not limited to, target tracking, localization, triggered event
reporting, and multihop routing.
Classical MAC protocols perform channel access arbitration and
are tuned for good performance over a set of workloads thought
to be representative of the domain. S-MAC is an example of a
wireless sensor network protocol designed using a classical approach.
S-MAC provides an RTS-CTS mechanism for channel ar-
0 20 40 60 80 100
110
100
90
80
sig
n
al (d
B
m)
0 20 40 60 80 100
0
1
T
hre
s
h
old
0 20 40 60 80 100
0
1
Time (ms)
O
utlier
Figure 2: Clear Channel Assessment (CCA) effectiveness for a
typical wireless channel. The top graph is a trace of the received
signal strength indicator (RSSI) from a CC1000 transceiver. A
packet arrives between 22 and 54ms. The middle graph shows
the output of a thresholding CCA algorithm. 1 indicates the
channel is clear, 0 indicates it is busy. The bottom graph shows
the output of an outlier detection algorithm.
bitration and hidden terminal avoidance, synchronization with its
neighbors for low power operation, and message fragmentation for
efficiently transferring bulk data. S-MAC is not only a link protocol,
but also network and organization protocol. Applications and
services must rely on S-MAC’s internal policies to adjust its operation
as node and network conditions change; such changes are
opaque to the application. In contrast, the B-MAC protocol contains
a small core of media access functionality. B-MAC uses clear
channel assessment (CCA) and packet backoffs for channel arbitration,
link layer acknowledgments for reliability, and low power listening
(LPL) for low power communication. B-MAC is only a link
protocol, with network services like organization, synchronization,
and routing built above its implementation. Although B-MAC neither
provides multi-packet mechanisms like hidden terminal support
or message fragmentation nor enforces a particular low power
policy, B-MAC has a set of interfaces that allow services to tune its
operation (shown in Figure 1) in addition to the standard message
interfaces1
. These interfaces allow network services to adjust BMAC’s
mechanisms, including CCA, acknowledgments, backoffs,
and LPL. By exposing a set of configurable mechanisms, protocols
built on B-MAC make local policy decisions to optimize power
consumption, latency, throughput, fairness or reliability.
For effective collision avoidance, a MAC protocol must be able
to accurately determine if the channel is clear, referred to as Clear
Channel Assessment (CCA). Since the ambient noise changes depending
on the environment, B-MAC employs software automatic
gain control for estimating the noise floor. Signal strength samples
are taken at times when the channel is assumed to be free–such as
immediately after transmitting a packet or when the data path of
the radio stack is not receiving valid data. Samples are then entered
into a FIFO queue. The median of the queue is added to an
exponentially weighted moving average with decay α. The median
1
Standard interfaces for message transmission in TinyOS [18] are
BareSendMsg for transmission, ReceiveMsg for reception,
and RadioCoordinator for time stamping and start of frame
delimiter (SFD) information.
97
0 0.5 1 1.5 2 2.5 3
0
5
10
15
20
25
30
Time (ms)
Curr
ent (m
A)
(a) (b) (c) (d) (e) (f) (g)
sleep init radio radio crystal startup µc rx adc sleep
Figure 3: When turning on the radio, the node must perform
a sequence of operations. The node first starts in sleep state
(a), then wakes up on a timer interrupt (b). The node initializes
the radio configuration and commences the radio’s startup
phase. The startup phase (c) waits for the radio’s crystal oscillator
to stabilize. Upon stabilization, the radio enters receive
mode (d). After the receive mode switch time, the radio enters
receive mode (e) and a sample of the received signal energy may
begin. After the ADC starts acquisition, the radio is turned off
and the ADC value is analyzed (f). With LPL, if there is no
activity on the channel, the node returns to sleep (g).
is used as a simple low pass filter to add robustness to the noise
floor estimate. An α value of 0.06 and FIFO queue size of 10 provided
the best results for a typical wireless channel. Once a good
estimate of the noise floor is established, a request to transmit a
packet starts the process of monitoring the received signal from the
radio. A common method used in a variety of protocols, including
802.15.4, takes a single sample and compares it to the noise floor.
This thresholding method produces results with a large number of
false negatives that lower the effective channel bandwidth. Since
noise has significant variance in channel energy whereas packet reception
has fairly constant channel energy (as shown in Figure 2),
B-MAC searches for outliers in the received signal such that the
channel energy is significantly below the noise floor. If an outlier
exists during the channel sampling period, B-MAC declares
the channel is clear since a valid packet could never have an outlier
significantly below the noise floor. If five samples are taken and no
outlier is found, the channel is busy. The effectiveness of outlier detection
as compared to thresholding on a trace from a CC1000 [3]
transceiver is shown in Figure 2.
The most basic mechanism allows services to turn CCA on or off
using the MacControl interface in Figure 1. By disabling CCA,
a scheduling protocol may be implemented above B-MAC. If CCA
is enabled, B-MAC uses an initial channel backoff when sending a
packet. B-MAC does not set the backoff time, instead an event is
signaled to the service that sent the packet via the MacBackoff
interface. The service may either return an initial backoff time or
ignore the event. If ignored, a small random backoff is used. After
the initial backoff, the CCA outlier algorithm is run. If the channel
is not clear, an event signals the service for a congestion backoff
time. If no backoff time is given, again a small random backoff
is used. Enabling or disabling CCA and configuring the backoff
allows services to change the fairness and available throughput.
B-MAC provides optional link-layer acknowledgment support.
If acknowledgments are enabled, B-MAC immediately transfers an
acknowledgment code after receiving a unicast packet. If the transmitting
node receives the acknowledgment, an acknowledge bit is
set in the sender’s transmission message buffer.
B-MAC duty cycles the radio through periodic channel sampling
that we call Low Power Listening (LPL). Our technique is similar
to preamble sampling in Aloha [4] but tailored to different radio
characteristics. Each time the node wakes up, it turns on the radio
and checks for activity. If activity is detected, the node powers
up and stays awake for the time required to receive the incoming
packet. After reception, the node returns to sleep. If no packet is
received (a false positive), a timeout forces the node back to sleep.
Accurate channel assessment (CCA) is critical to achieving low
power operation with this method. We use the noise floor estimation
of B-MAC not only for finding a clear channel on transmission
but also for determining if the channel is active during LPL. False
positives in the CCA algorithm (such as those caused by thresholding)
severely affect the duty cycle of LPL due to increased idle
listening.
To reliably receive data, the preamble length is matched to the
interval that the channel is checked for activity. If the channel is
checked every 100 ms, the preamble must be at least 100 ms long
for a node to wake up, detect activity on the channel, receive the
preamble, and then receive the message. Idle listening occurs when
the node wakes up to sample the channel and there is no activity.
The interval between LPL samples is maximized so that the time
spent sampling the channel is minimized. The check interval and
preamble length are examples of parameters exposed through BMAC’s
LowPowerListening interface in Figure 1. Transmit
mode corresponds to the preamble length and the listening mode
corresponds to the check interval. We provide a selection of 8 different
modes (corresponding to 10, 20, 50, 100, 200, 400, 800, and
1600ms for the check interval). Protocols may also set their own
preamble length and check interval through the interface. The effect
of varying the preamble size and check interval is discussed in
more detail in Section 4. Examples of services that use the LPL
interface are given in Subsection 4.3 and Section 8.
A trace of the power consumption while sampling the channel
on a Mica2 mote [17] is shown in Figure 3. The process in Figure 3
applies to essentially any MAC protocol for sensor networks. It
performs initial configuration of the radio (b), starts the radio and
its oscillator (c), switch the radio to receive mode (d), and then perform
the actions of the protocol. As a result, the cost for powering
up the radio is the same for all protocols. The difference between
protocols is how long the radio is on after it has been started and
how many times the radio is started.
In sensor networks, each node typically runs a single application.
Since the RAM and ROM available on sensor nodes are extremely
limited, keeping the size of the MAC implementation small
is important. Reducing the complexity of the protocol reduces state
and the likelihood of race conditions We implemented B-MAC in
TinyOS [11] to evaluate its efficacy in meeting our goals. Since BMAC
does not have the RTS-CTS mechanism or synchronization
requirements of S-MAC2
, the implementation is both simpler and
smaller as shown in Table 1. B-MAC does not hinder efficient implementation
of network protocols; above B-MAC we implemented
an RTS-CTS scheme and a message fragmentation service using
B-MAC’s control interfaces that have equivalent functionality to
S-MAC RTS-CTS and fragmentation services.
2All tests with S-MAC were performed with the implementation
in tinyos-1.x/contrib/s-mac/ in the TinyOS CVS repository
[18] as of March 30, 2004.
98
Protocol ROM RAM
B-MAC 3046 166
B-MAC w/ ACK 3340 168
B-MAC w/ LPL 4092 170
B-MAC w/ LPL & ACK 4386 172
B-MAC w/ LPL & ACK + RTS-CTS 4616 277
S-MAC 6274 516
Table 1: A comparison of the size of B-MAC and S-MAC in
bytes. Both protocols are implemented in TinyOS.
4. CONCEPTS AND TRADEOFFS
In this section we describe a framework for analyzing the operation
of a wireless sensor network application. We build an analytical
model for monitoring applications. The model allows us to
calculate and set B-MAC’s parameters to optimize the application’s
overall power consumption. Using the model, we illustrate the effect
of different application variables including duty cycle, network
density, and sampling rate. We show how B-MAC’s interfaces may
be used by network services to adapt to current demands.
4.1 Modeling Lifetime
To calculate node duty cycle and lifetime, we examine a periodic
sensing application (such as in [12]) that streams sensor data to a
base station. Table 2 lists the primitive operations performed by
a low power monitoring application and the observed costs when
using a CC1000 transceiver. These operations describe a representative
class of radios for wireless sensor networks. Radios with
similar properties are manufactured by Chipcon, Infineon, and Motorola.
We use the notation and values in Table 2 throughout the
remainder of this paper.
The node’s lifetime is determined by its overall energy consumption.
If the lifetime is maximized, then the energy consumption
must be minimized. All of the energies, E, are defined in units of
millijoules per second, or milliwatts. Calculating the total energy
usage can be done by multiplying E by the node lifetime tl. For
wireless sensor network applications, the energy used by a node
consists of the energy consumed by receiving, transmitting, listening
for messages on the radio channel, sampling data, and sleeping.
E = Erx + Etx + Elisten + Ed + Esleep (1)
Sensors are an integral part of wireless sensor networks and must
be considered when calculating a node’s lifetime. Sampling sensors
is often expensive and affects the lifetime of the node. The
sampling parameters (shown in Table 2) are based on an application
deployed by Mainwaring et. al. [12]. In their application, each
node takes 1100 ms to start its sensors, sample, and collect data.
The data is sampled every five minutes, or r = 1/(5 ∗ 60). The
energy associated with sampling data, Ed, is
td = tdata × r
Ed = tdcdataV (2)
The energy consumed by transmitting, Etx, is simply the length
of the packet with the preamble times the rate packets are generated
by the application.
ttx = r × (Lpreamble + Lpacket)ttxb
Etx = ttxctxbV (3)
For a periodic application with a uniform sampling rate, the node
will detect and receive data when each of its n neighbors transmit
Operation Time (s) I (mA)
Initialize radio (b) 350E-6 trinit 6 crinit
Turn on radio (c) 1.5E-3 tron 1 cron
Switch to RX/TX (d) 250E-6 trx/tx 15 crx/tx
Time to sample radio (e) 350E-6 tsr 15 csr
Evaluate radio sample (f) 100E-6 tev 6 cev
Receive 1 byte 416E-6 trxb 15 crxb
Transmit 1 byte 416E-6 ttxb 20 ctxb
Sample sensors 1.1 tdata 20 cdata
Table 2: Time and current consumption (I) for completing
primitive operations of a monitoring application using the
Mica2 mote and CC1000 transceiver. Identifiers on each operation
map back to the activities of acquiring a radio sample
in Figure 3.
Notation Parameter Default
csleep Sleep Current (mA) 0.030
Cbatt Capacity of battery (mAh) 2500
V Voltage 3
Lpreamble Preamble Length (bytes) 271
Lpacket Packet Length (bytes) 36
ti Radio Sampling Interval (s) 100E-3
n Neighborhood Size (nodes) 10
r Sample Rate (packets/s) 1/300
tl Expected Lifetime (s) -
Table 3: Parameters for a monitoring application running BMAC.
The first three parameters are specific to Mica2 motes;
the next three are default values for B-MAC parameters on
the Mica2; the remaining parameters are application semantics
affecting B-MAC’s performance. Each parameter affects
the node’s total energy consumption, E.
a packet, regardless of the packet’s destination. We refer to the
density of neighbors surrounding a node as the neighborhood size
of the node. Although receiving data from neighbors shortens a
node’s lifetime, it allows services to snoop on the channel and make
decisions based on channel activity.
We can bound the total time the node will spend receiving and
calculate an upper bound on the energy consumed by receiving,
Erx.
trx ≤ nr(Lpreamble + Lpacket)trxb
Erx = trxcrxbV (4)
Our analysis is based on a single cell. To analyze a multihop
application, we need to account for the routing traffic through each
node due to its children and its neighbors’ children. Instead of r
packets per second flowing through a particular node, the traffic
through the node must also include all the packets routed by the
node and its neighbors. The function children(i) is defined by the
multihop routing protocol.
r ×
Xn
i=0
(children(i) + 1)
Up to this point, our model has been independent of the MAC
protocol in use. The MAC protocol is responsible for minimizing
idle listening time, tlisten. In B-MAC, idle listening occurs
whenever B-MAC samples the channel for activity but no activity
is present.
99
0 20 40 60 80 100
0
20
40
60
80
100
120
140
160
180
200
Neighborhood size
Channel Activity Check Interval (ms)
0.25
0.5
0.75
1
1.5
1.25
2
2.5
Figure 4: Contour of node lifetime (in years) based on LPL
check time and network density. If both parameters are known,
their intersection is the expected lifetime using the optimal BMAC
parameters.
In order to reliably receive packets, the LPL check interval, ti,
must be less than the time of the preamble. Therefore we have the
constraint:
Lpreamble ≥ dti/trxbe
Given a check interval and associated preamble length, we can
calculate the time spent sampling the channel. From Figure 3, the
power consumption of a single LPL radio sample is 17.3µJ. The
total energy spent listening to the channel is the energy of a single
channel sample times the channel sampling frequency.
Esample = 17.3µJ
tlisten = (trinit + tron + trx/tx + tsr) ×
1
ti
Elisten ≤ Esample ×
1
ti (5)
Finally, the node must sleep for the remainder of the time. The
sleep time, tsleep, is simply the time remaining each second that’s
not consumed by other operations.
tsleep = 1 − trx − ttx − td − tlisten
Esleep = tsleepcsleepV (6)
The lifetime of the node, tl, is dependent on the total energy
consumed, E, and the battery capacity, Cbatt. We must bound the
lifetime by the available capacity of the battery.
tl =
Cbatt × V
E
× 60 × 60 (7)
By solving the system of equations (1 through 6) and entering the
parameters in Table 3, we can find the minimum energy for a given
network configuration. Lifetime may be estimated at compile time,
or computed for a discrete set of values at runtime that provides
reconfiguration feedback to network services.
0 20 40 60 80 100
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.1
Number of neighboring nodes
Effective duty cycle (%)
200ms check interval
100ms check interval
50ms check interval
25ms check interval
10ms check interval
Figure 5: The node’s duty cycle is affected by the network density
and LPL check interval. Typically used LPL check intervals
in B-MAC’s implementation are depicted. The best check
interval is the lowest line at a given network density.
4.2 Parameters
In a typical deployment, scientists will determine the physical
location of the nodes (which affects each node’s neighborhood size,
n) and the ideal sampling rate, r. With this information, we can
calculate the parameters to attain the best lifetime that B-MAC can
achieve. This also provides the scientist with an estimate for how
long the network will live.
If we fix the sample rate and vary the network density, n, we
can evaluate the affect of neighbors on node lifetime. Solving the
system of equations from this section with the sample rate equal to
once every five minutes yields Figure 4. Taking a few slices across
the figure at realistic check intervals is shown in Figure 5. To find
the best LPL check interval for an application, find the expected
neighborhood size in Figure 5 and move up the y-axis to the lowest
line. The check interval corresponding with this line will yield
the maximum lifetime. For example, a check interval of 50 ms is
optimal for a neighborhood size of 20, but if the neighborhood size
is only 5, a check interval of 100 ms is optimal. The size of the
neighborhood affects the amount of traffic flowing by each node.
B-MAC trades off idle listening for a reduced time to transmit and
receive.
If we assume we have a network with approximately 10 neighbors
per node, the optimum LPL check interval changes with sample
rate. Increasing the sample rate increases the amount of traffic
in the network (just as increasing the neighborhood size also increases
the traffic in a periodic application). As a result, each node
overhears more packets. We must find the optimal check interval
ti such that we maximize the lifetime tl. Lowering ti also lowers
the preamble length. The time to transmit and receive a packet is
shorter and the radio is sampled more often.
The tradeoff of more frequently checking the radio in order to
shorten the packet transmission time is shown in Figure 6. Notice
that the penalty for more idle listening than required by the traffic
pattern, left of the maximum lifetime point in Figure 6, is much
more severe than the penalty for sending packets that are longer
than necessary.
100
0 50 100 150 200
0
0.5
1
1.5
2
2.5
3
3.5
4
Check Time (ms)
Lifetime (years)
1−min sample period
5−min sample period
10−min sample period
20−min sample period
Figure 6: The lifetime of each node is dependent on the check
interval and the amount of traffic in the network cell. Each
line shows the lifetime of the node at that sample rate and LPL
check interval. The circles occur at the maximum lifetime (optimal
check interval) for each sample rate.
4.3 Adaptive Control
Our model shows that it is advantageous to change the parameters
of the MAC protocol based on changing network conditions.
Since sensor networks consist of low power volatile nodes, it is
likely that links will appear or disappear over time [21, 24]. Nodes
may join and leave the network, or the size of the neighborhood
will change due to changes in the physical environment. The MAC
protocol must be able to adjust for these changes and optimize its
power consumption, latency, and throughput to support the services
relying on it. The analytical model allows the node to recompute
the check interval and preamble length. To address reconfiguration,
we chose not to implement the functionality in the MAC protocol
as Woo and Culler [20] have done. Instead, we created a set of bidirectional
interfaces that allow services to change the MAC protocol
based on their current operating conditions.
By factoring out more complex parts of conventional MAC protocols,
services can decide which situations warrant the use of additional
control. For example, B-MAC’s link layer acknowledgment
support may be selected on a per-packet basis. When an acknowledgment
fails, services may choose to retransmit the packet, change
the packet’s destination, or reconfigure the LPL parameters.
One scheme implemented above B-MAC is an RTS-CTS channel
acquisition protocol. On each packet transmission, an RTS packet
is sent. A CTS response is sent if the destination node is idle and
not delaying due to other transmissions. The RTS and CTS packets
are sent using LPL. Once the channel is acquired, data and acknowledge
packets are sent immediately with CCA and LPL disabled.
After acknowledgment, both nodes reenable LPL and CCA,
then they return to sleep.
5. EXPERIMENTAL METHOD
To illustrate the effectiveness of a lightweight, configurable MAC
protocol, we compare B-MAC to existing MAC protocols, specifically
S-MAC and T-MAC. Each protocol is run through a set of
simple workloads forming an empirical characterization of protocol
performance. The purpose of these microbenchmarks is to
show how WSN protocols react to typical wireless sensor network
Length (bytes) B-MAC S-MAC
Preamble 8 18
Synchronization 2 2
Header 5 9
Footer (CRC) 2 2
Data Length 29 29
Total 46 60
Table 4: B-MAC and S-MAC as implemented in TinyOS have
different protocol overhead when sending a data packet. SMAC
has a larger header to accommodate timestamp information.
The data payload is the default payload for TinyOS
applications; however, both B-MAC and S-MAC send only the
length specified by higher level services.
conditions–high contention, low to high throughput, low to high latency,
and their correlation with power consumption. We contrast
the use of RTS-CTS and message fragmentation services implemented
using B-MAC’s interfaces to the same mechanisms that are
part of the S-MAC protocol. These microbenchmarks build an understanding
of how a real application would perform. To validate
the model in Section 4, we look in detail at the performance of a
deployed monitoring application that uses B-MAC. We compare
the actual node duty cycles with those predicted by our model and
show that our empirical characterizations apply to real world applications.
Both B-MAC and S-MAC were implemented in TinyOS. We
used the Mica2 [17] wireless sensor nodes to perform our tests.
All tests occurred in an unobstructed area with line of sight to every
other node. To enable multihop networking, we reduced the
RF output power of the node to its minimum value and placed the
nodes with 1 meter spacing. Nodes were elevated 15 centimeters to
reduce near-field effects.
To determine the power consumption of each protocol, we implemented
counters in the MAC protocol that keep track of how
many times various operations were performed. For B-MAC, this
includes receiving a byte, transmitting a byte, and checking the
channel for activity. For S-MAC, we count the amount of time that
the node is active, number of bytes transmitted and received, and
the additional time the node spent awake due to adaptive listening.
Since the S-MAC implementation does not actually put the node
into sleep mode, we had to measure the power consumption indirectly
by multiplying the cumulative time of each operation with
the expected power to operate in that mode. All of our data assumes
that S-MAC actually enters sleep mode even though the implementation
does not. The power consumption of each operation is taken
from Table 2.
In addition to tests on real sensor network hardware, we simulated
T-MAC [19] in Matlab. We calculated the time of each operation
and multiplied by the current consumption in Table 2 to get the
overall expected power consumption of the T-MAC protocol. At
the time of our experiments, there was no TinyOS implementation
of T-MAC available to do a direct comparison between B-MAC,
S-MAC, and T-MAC.
To measure latency, each node is connected to an oscilloscope.
Upon submission of a packet to the MAC protocol, we toggle a
hardware pin. When a packet is received, a different pin is toggled.
Using an oscilloscope, we capture the time between each pin
toggling to yield the total latency.
In some graphs we show the optimal solution. Found by computing
a perfect schedule, the optimal solution is the minimum to-
101
0 5 10 15 20
0
2000
4000
6000
8000
10000
12000
14000
16000
0 5 10 15 20
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of nodes
Percentage of Channel Capacity
B−MAC
B−MAC w/ ACK
B−MAC w/ RTS−CTS
S−MAC unicast
S−MAC broadcast
Channel Capacity
Throughput (bps)
Figure 7: Measured throughput of each protocol with no duty
cycle under a contended channel. The throughput of each protocol
is affected by the amount of nodes contending for the
channel and the protocol’s overhead. B-MAC achieves over 4.5
times the throughput of the standard S-MAC unicast protocol
through lower per-packet processing and effective CCA.
tal transmit and receive costs possible. In this solution, all nodes
are perfectly synchronized with no additional overhead. This metric
serves to show the effect of overhead in sensor network MAC
protocols. To calculate the power consumption, the transmit and
receive times are multiplied by the power to perform those operations.
In all cases, we measure the data throughput of the network. This
factors out the protocol-specific overhead to evaluate the amount of
data that can be delivered by each protocol and the cost of delivering
that data. In all tests where we mention “packet size”, we are
referring to the size of the data payload only, not the header information.
The overhead attributed to each protocol is shown in Table
4. S-MAC uses a longer preamble and contains time stamping
information in the header. Note that control and synchronization
packets in S-MAC are 10 bytes long plus preamble and synchronization
(total 30 bytes). For some tests, we vary the data length.
Table 4 shows the default data lengths; however both B-MAC and
S-MAC only transmit the data length specified by the application
on a per packet basis.
6. MICROBENCHMARK ANALYSIS
In this section we use a variety of microbenchmarks to show how
B-MAC’s functionality may be used effectively. These benchmarks
show the effect of a wide array of network conditions on the energy
consumption of B-MAC, S-MAC, and T-MAC. We show the potency
of B-MAC’s interfaces for building efficient applications and
communications protocols. The results of the microbenchmarks
empirically characterize the performance of B-MAC, providing insight
on B-MAC’s expected behavior in real world applications.
6.1 Channel Utilization
Channel utilization is a traditional metric for MAC protocols that
illustrates protocol efficiency. High channel utilization is critical
for delivering a large number of packets in a short amount of time.
In sensor networks, quickly transferring bulk data typically occurs
in network reprogramming or extracting logged sensor data. By
minimizing the time to send packets, we can also reduce the network
contention. In network reprogramming, the network is woken
0 50 100 150 200 250
0
5
10
15
20
25
30
35
40
45
50
Throughput (bits/second)
Power consumed (mW = mJ/second)
B−MAC
S−MAC
Always On
Figure 8: The measured power consumption of maintaining
a given throughput in a 10-node network. As the throughput
increases, the overhead of S-MAC’s SYNC period causes the
power consumption to increase linearly. The throughput is the
average node bitrate (number of data bytes sent in a 10 second
time period) in the 10 node network.
up and reprogrammed as quickly as possible. To find the channel
utilization under congestion, we placed n nodes equidistant from
a receiver. Each node transmitted as quickly as possible with the
MAC protocol providing collision avoidance. We increased the offered
load by adding transmitters. There is no node or radio duty
cycling in this test. The throughput achieved by B-MAC and SMAC
is shown in Figure 7.
In general, better throughput is attained with fewer nodes trying
to saturate the channel. With one transmitter, B-MAC outperforms
S-MAC broadcast mode (RTS-CTS disabled) by 2.5 times and SMAC
unicast mode (RTS-CTS enabled) by 4.5 times. B-MAC outperforms
S-MAC for broadcast traffic due to more sophisticated
CCA and lower preamble overhead. For unicast traffic, S-MAC
suffers from the overhead of RTS-CTS exchanges. Instead of using
control messages like RTS-CTS for hidden terminal support,
B-MAC’s relies on higher layer services to send data in accordance
with their traffic pattern. These services implement the appropriate
hidden terminal support for their workloads. For example, after
sending a multihop message, all nodes in the cell should refrain
from transmitting until one packet time has elapsed to allow the
parent to retransmit up the tree as proven to be more efficient than
control messages for multihop traffic in [20]. By allowing the service
to decide, many costly control message exchanges are eliminated.
B-MAC exceeds the performance of S-MAC, but does not trade
off fairness in the process. The test in Figure 7 uses a short initial
random backoff proven in [20] to provide fair channel utilization.
By analyzing our dataset, we found that each node in the test
achieves no more than 15% more bandwidth than any other node.
To yield even higher throughput with B-MAC, we can discard fairness
as a requirement. Each transmitter can set its backoff to zero
and take control of the channel. As the number of nodes increases,
channel contention and the capture effect3
causes B-MAC’s perfor-
3The capture effect occurs when overlapping packets are sent due
to one node sensing that the channel is clear while another node is
in the process of switching to transmit mode [10, 14].
102
0 50 100 150 200 250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Fragment size (bytes)
Energy per byte (mJ/byte)
B−MAC w/ no frag control
B−MAC w/ frag control
S−MAC
T−MAC (simulated)
Optimal Schedule
(a) 10 second message generation rate
0 50 100 150 200 250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Fragment size (bytes)
Energy per byte (mJ/byte)
B−MAC w/ no frag control
B−MAC w/ frag control
S−MAC
T−MAC (simulated)
Optimal Schedule
(b) 100 second message generation rate
Figure 9: The effective energy consumption per byte at node C for a network as shown in Figure 10. Each node generates a message
every 10 seconds (left) and every 100 seconds (right) consisting of 10 fragments of the size given on the x-axis.
mance to converge to S-MAC’s performance. Since S-MAC uses
a longer preamble, a larger portion of the channel is dedicated to
incoming signal synchronization by the receiver. Using B-MAC’s
control interfaces, the preamble may be set to the same length as
S-MAC or scale up as the channel contention increases.
To illustrate the effectiveness of a configurable MAC protocol for
sensor networks, we implemented the RTS-CTS scheme described
in Subsection 4.3. This scheme illustrates one method a service
may employ to mitigate the hidden node problem and increase fairness
with B-MAC. Since B-MAC can utilize 2.5 times more of
the channel using the CCA algorithm from Section 3, the RTSCTS
implementation using B-MAC actually provides double the
throughput of S-MAC. When many nodes compete for the channel,
B-MAC with RTS-CTS support provides identical performance to
S-MAC. This test illustrates that system services, like RTS-CTS,
built using B-MAC’s interfaces does not hinder protocol performance.
6.2 Energy vs. Throughput
We designed B-MAC to run at both low and high data rates con-
figured by services relying on it. Low duty cycle applications have
extremely low network throughput; however some application services,
such as bulk data transfer, stress the high throughput functionality
of the MAC protocol. To evaluate how increased throughput
affects power consumption, we vary the transmission rate of
10 nodes in a single cell. We bound the latency such that the data
must arrive within 10 seconds. For B-MAC, the optimal check interval
ti is calculated for the traffic pattern, the test is run, and the
energy consumption is calculated. For S-MAC, the optimal duty
cycle is calculated for the traffic pattern such that the data arrives
within the 10 second period. The results are shown in Figure 8.
At low data rates, S-MAC can use an extremely low duty cycle to
transmit and receive the data. As the amount of data increases, so
must S-MAC’s duty cycle. When the duty cycle increases, there are
more active periods each with a dedicated SYNC period. Due to the
overhead of the SYNC period at the beginning of each wakeup, the
S-MAC energy consumption increases linearly. In B-MAC, at low
throughput we send long preambles with a long check interval ti.
Because of the tradeoff between idle listening and packet length,
the overhead dominates the energy consumption. The overhead
of LPL is mitigated by a more frequent check interval when the
throughput exceeds 45 bits per second. Note that B-MAC’s power
consumption below 45 bits per second is within 25% of S-MAC’s
power consumption; however, B-MAC has significantly less state
and no synchronization requirements. Services using B-MAC may
easily reconfigure the link protocol to change the check interval
based on the network bandwidth whereas services using S-MAC
must force it to create a new schedule and resynchronize.
6.3 Fragmentation
Small periodic data packets are the most common workload in
sensor networks, but certain cases arise where larger transfers are
needed. S-MAC supports large message fragmentation within the
MAC protocol using an RTS-CTS exchange for channel reservation.
To compare B-MAC directly to S-MAC’s design goal of ef-
ficient message fragmentation, we devised an experiment to match
those done by the authors of S-MAC in [23]. Using the network
configuration in Figure 10, we transmitted packets from sources A
and B to sinks D and E by routing through C.
A
B
C
D
E
Figure 10: X network configuration used for packet fragmentation
tests.
As in [23], our test sent 10 fragments per message. We varied
the fragment size and measured the energy consumed for that
transfer. C is the energy bottleneck node in the test network–C will
103
0 2 4 6 8 10
0
500
1000
1500
2000
2500
3000
Number of Hops
Latency (ms)
B−MAC no sleep
B−MAC 100ms check
B−MAC 100ms check /w ACK
S−MAC no sleep
S−MAC 10% adaptive
Figure 11: The end-to-end latency is a linear function of the
number of hops in the network. As the overhead of the MAC
protocol increases, so does the slope of the latency.
cease operation before any other node since it must both receive
and relay packets. We evaluate the energy required to deliver the
fragments with S-MAC running at 10% duty cycle with adaptive
listening. B-MAC is configured with the default parameters from
Table 3. Figure 9(a) shows the energy cost per byte at node C when
a message (consisting of 10 fragments) is sent every 10 seconds.
Figure 9(b) show the energy cost per byte when the message generation
interval is once every 100 seconds.
B-MAC without fragmentation control is simply the B-MAC protocol
with the default parameters. Each fragment is an independent
packet with a long preamble. But, the middleware service could
adjust the MAC protocol to minimize the energy consumed during
bulk transfer. In the measurements with fragmentation control, a
message fragmentation service is built using B-MAC’s interfaces
provided in Figure 1. The first fragment of the message is sent with
LPL enabled and extra bytes to inform the receiver of the number
of fragments. The remaining fragments are sent with LPL disabled.
After the last fragment, the sender and receiver reenable LPL. With
this flexibility, we achieve significant power savings and efficiency
essentially identical to S-MAC without the additional overhead, including
RAM and ROM usage. When the message transmission
period is large (as in Figure 9(b)), the overhead of S-MAC is readily
apparent; the energy consumption per byte of both S-MAC and
T-MAC is greater at all fragment sizes than B-MAC with fragmentation
support. The na¨ıve B-MAC approach with long preambles
for each fragment yields the same power consumption as S-MAC
without the additional complexity. When there is no activity on
the channel, T-MAC removes the overhead incurred by S-MAC by
using adaptive active periods to return to sleep much quicker. Figure
9 shows that the energy cost of breaking up a short message
into even shorter fragments is so high in all of our protocols that it
is simply not a viable option in sensor networks.
6.4 Latency
The authors of S-MAC argue that when the MAC protocol is
permitted to increase latency, S-MAC can reduce the node’s duty
cycle and conserve energy. A test for evaluating end-to-end latency
was devised in [23]. We have reproduced their tests to provide a
direct comparison between B-MAC and S-MAC. The test is run
0 2 4 6 8 10
0
50
100
150
200
250
300
350
400
450
500
550
Latency (s)
Energy (mJ)
B−MAC
S−MAC
Always On
Figure 12: As the latency increases, the energy consumed by
both B-MAC and S-MAC decreases. The point illustrated on
the B-MAC line is the default configuration as shown in Table 3.
The point on the S-MAC line is the default S-MAC configuration
at 10% duty cycle with adaptive listening.
Source Sink
11 10 9 3 2 1
Figure 13: 10 hop configuration used for multihop end-to-end
latency tests.
on a 10-hop network shown in Figure 13. In each test, the source
node sends 20 messages with a payload of 100-bytes. There is no
fragmentation on any message.
The latency at each hop of the network is measured with the
method described in Section 5. S-MAC is tested at a 10% duty
cycle with adaptive listening. B-MAC is tested with the default
parameters. The results are shown in Figure 11. We are able to
reproduce the latency data from [23] and it fits the previously published
results.
The latency of B-MAC and S-MAC increase linearly. When duty
cycling is disabled, the effect of RTS-CTS exchanges in S-MAC
result in a much steeper slope than B-MAC. For low power communications,
B-MAC has a slope almost identical to S-MAC with
adaptive listening, however the y-intercept is much lower. Since
the first packet cannot be sent until an S-MAC active period, it is
delayed by at most 1150 milliseconds. Through adaptive listening,
S-MAC does not incur an expected 1150 milliseconds additional
delay at each hop. One protocol feature of B-MAC, link layer acknowledgments,
increases latency by an insignificant amount.
To better evaluate the effect of increasing the latency to reduce
power consumption, we fixed the throughput to one 100 byte packet
per 10 second interval. We measured the end-to-end latency of the
10 hop network and varied the duty cycle of S-MAC. We also chose
the optimal ti for B-MAC given the latency and throughput. The
results are shown in Figure 12.
For latencies under 6 seconds, B-MAC performs significantly
better than S-MAC. As S-MAC approaches the 10 second latency
limit, its power dips below B-MAC. When the latency exceeds
3 seconds, B-MAC’s power consumption is bounded by the cost
of idle listening. In contrast, the best case performance of S-MAC
104
0 0.5 1 1.5 2 2.5 3 3.5
x 10
4
0
0.5
1
1.5
2
2.5
3
Number of packets forwarded or sent
D
uty
C
y
cle (%)
1 hop from
base station
Leaf nodes
Figure 14: As the traffic around a node increases, so does the
duty cycle when using the B-MAC protocol with LPL. The node
one-hop from the base station forwards 85% of the packets in
the deployment yet achieves a lower duty cycle by minimizing
the preamble length for packets sent to the base station.
shown in Figure 12 relies on S-MAC synchronizing the entire 10-
hop network and using adaptive listening to transmit the data through
the network in one active period. Figure 12 shows the importance
of reconfiguration in wireless sensor networks. If the application’s
required latency is relaxed, S-MAC could achieve lower energy
consumption than B-MAC; however S-MAC operates at a single
setting, is not reconfigurable, and thus cannot realize these energy
savings.
7. MACROBENCHMARK ANALYSIS
The application model in Section 4 predicts the performance of
a monitoring application for wireless sensor networks using the BMAC
protocol. In this section, we examine the behavior of a realworld
monitoring application called Surge. We examine Surge’s
duty cycle and compare the results to predictions from the analytical
model. The empirical characterizations from Section 6 are
evaluated with the networking results from Surge. We also examine
the use of B-MAC’s interfaces for simple optimizations that have a
large impact on the network’s lifetime.
Surge is a periodic data collection application that acquires samples
from the node’s sensors, sends the readings, and sleeps. It was
deployed by placing 14 nodes throughout a 30 meter by 20 meter
home. The nodes automatically configured themselves into an
ad-hoc routing network. Surge collects data from each node once
every three minutes. Instead of collecting sensor data, we acquired
statistical information from B-MAC about its performance (see Section
5 for the energy indicators implemented in B-MAC). Each
node transmits its energy usage, battery voltage, estimated link
quality to surrounding nodes, and its current parent. Data from
Surge is used to verify that the network performance matches the
microbenchmarks from Section 6.
Using our estimate of lifetime versus check interval for a given
sample period (see Figure 6), we selected a 100ms check interval
ti. By evaluating the node communication range and overall
size of the network, we expected a maximum neighborhood size
of 5 nodes. To be conservative, we calculated the preamble length
0 1 2 3 4 5
0
0.5
1
1.5
2
2.5
3
Number of hops
Duty Cycle (%)
Average Duty Cycle
Logarithmic Fit
Figure 15: The position in the network dictates the amount of
traffic flowing through that level. As we approach the base station,
nodes handle an increasing number of packets. The average
duty cycle is computed by finding the average for nodes
at a given hopcount. Fractional hopcounts are correlated with
nodes that oscillated between two levels of the network. Note
that nodes one-hop away from the base station can achieve a
lower duty cycle because the base station is always on. By reconfiguring
B-MAC to use short packets, nodes one-hop from
the base station survive up to 50% longer.
and check interval with a neighborhood size of 10. Using a larger
neighborhood may cause us to overshoot the optimal configuration,
but Section 4 and Figure 5 show that using a longer check interval
is less detrimental to the overall lifetime than checking the channel
too often.
Since the most important thing in a monitoring network is reliably
reporting the data, we must confirm that B-MAC successfully
supports multihop data reporting. Our implementation uses
the default multihop routing protocol from the TinyOS distribution,
called MintRoute. After integrating B-MAC with MintRoute, the
routing layer enables B-MAC’s link layer acknowledgments. Upon
a failed acknowledgment, MintRoute retransmits the message up to
five times. The Surge application was run for a period of 8 days.
We collected over 40,000 data packets profiling the performance of
a real world wireless sensor network.
During the Surge deployment, the network yielded over 98.5%
packet delivery while some nodes achieved an astounding 100%
success rate. In our deployment, there were a total of 71 times
where a node decided to change its parent–and consequently changed
the routing tree–as a result of environmental changes altering the
communication topology. In confirmation of Woo and Zhao’s identification
of gray areas, high-quality links that were stable for hours
were intermittently broken due to environmental changes.
The base station was placed at a convenient location to install infrastructure
in a corner of the network. From the data collected by
the Surge application, we can determine the actual duty cycle of our
deployed network. Surge reports the values of our instrumented operation
counters. These counters translate into a duty cycle based
on a 12mA constant current consumption while active. From the
duty cycle, we can extrapolate the network lifetime. Figure 14
shows the measured duty cycles of each node in the network. The
worst case duty cycle of 2.35% indicates that the first node should
105
0 1 2 3 4 5 6
0
100
200
300
400
500
600
700
800
900
1000
1100
Number of hops
Latency (ms)
B−MAC Avg Latency Std Dev
B−MAC Avg Latency
B−MAC Min Expected Latency
Figure 16: The average latency of packets being delivered by
the Surge application is dependent on the traffic in the network
and reliability of each link. The average exceeds the expected
latency because retransmissions add additional latency to each
packet.
exhaust its battery supply approximately 369 days (1.01 years) into
the deployment.
Our data shows that each node has an average of 5 neighbors,
less than our maximum estimate of 10. Additionally, some nodes
on the edge of the network have less than a 1% duty cycle. We
attribute the lower duty cycle to the significant reduction in traffic
at the edges of the network as compared to central nodes routing a
large amount of data. The variance in leaf node duty cycle is due to
differences in local neighborhood size.
Although the network is homogeneous, we can exploit that the
base station runs with a different duty cycle (since it is always on)
than the data collection network. Instead of sending packets with
long preambles, nodes one hop away send packets with only an
8 byte preamble to the base station. Figure 14 shows the node duty
cycle versus number of packets routed through the node. There
was one node that despite forwarding almost 35,000 packets (about
85% of all data packets), had a duty cycle equal to nodes forwarding
less than 10,000 packets. This node was critical to reliable
data delivery–by forwarding most of the packets, it would have exhausted
its battery supply first and caused a network partition. Figure
15 shows the duty cycle vs. multihop level in the routing tree.
The node routing 35,000 packets one hop from the base station was
able to alter its MAC behavior (send short preambles) based on its
position in the network and optimize performance.
To validate our model, we calculated the expected lifetime based
on the parameters of our deployment. For the function children(i)
in our model, we performed two calculations: the first assumes
that the routing algorithm produces a balanced binary tree, the second
assumes the worst case routing tree–a line topology where all
traffic must be forwarded by the node one hop from the base station.
With a balanced tree and no routing protocol reconfiguration
of B-MAC, the first node should exhaust its battery supply in
385 days (1.06 years). For a line, the worst case lifetime is 256 days
(0.71 years).
In the presence of the one-hop optimization and a balanced tree,
we expect that nodes one-hop from the base station will exhaust
their battery supply 549 days (1.49 years) into the deployment,
nodes two-hops exhaust their supply in 542 days (1.48 years). For
a line, the expected lifetime of the node one hop from the base
station is 391 days (1.07 years). Unfortunately the nodes in our
deployment did not form a balanced tree, nor did they form a line.
Our measured power consumption data shows that a node one hop
away will survive for 1.13 years, slightly higher than our 1.07 year
estimate for a line. At two hops in the Surge application, the worst
case lifetime of 1.01 years is directly between our estimates of
1.48 years for a balanced tree and 0.71 years for a line. This
data validates the model; however, protocol designers must carefully
build network services that uniformly distribute routing (and
thereby uniformly distribute energy consumption) throughout the
network.
Without the one-hop to base station optimization, worst case
power consumption is up to 50% higher. The powered base station
is a simple example of network heterogeneity; one could imagine
much more heterogeneity with a hierarchy of devices. The differences
between devices dictate other optimizations that may be
implemented through bidirectional communication with the MAC
protocol.
In addition to predicting the power consumption of the network,
our empirical model also predicts the network latency that is introduced
by the B-MAC protocol illustrated in Figure 11. Since Surge
is a periodic application, message latency was measured by evaluating
the variations in packet delivery rates. The latencies measured
in our Surge deployment along with the predicted values are plotted
in Figure 16. The average latency is slightly higher than the prediction.
However the minimum latency for each network level exactly
matches the predicted value. The difference between the average
and minimum latencies is due to unexpected network congestion
and packet loss. Surge retransmits messages to increase reliability
when B-MAC indicates an acknowledgment failed. Upon retransmission,
the message incurs additional latency.
8. DISCUSSION
Our benchmarks have shown that a small amount of information
from services using B-MAC can provide significant power savings.
Additional power savings can be achieved through more information
about the application and its operation. In this section, we
discuss the implications and other uses of these ideas.
Because B-MAC is lightweight and configurable, many sensor
network protocols may be implemented efficiently using its primitives.
S-MAC and T-MAC may be implemented as services that
use B-MAC as the underlying link protocol. S-MAC and T-MAC
are more than just link protocols; they perform synchronization, organization,
fragmentation, and hidden terminal support and could
benefit from B-MAC’s flexibility. These protocols could be built on
B-MAC in a modular way to allow applications and other services
to use only necessary subsets of the mechanisms they provide.
To mitigate the cost of reception incurred with B-MAC with
LPL, a packet could be sent cyclically with a short preamble. Although
this does not reduce the transmission cost, it reduces the
time of receiving a packet to:
trx ≤ 2 × (Lpreamble + Lpacket) × trxb
Note that Lpreamble is reduced from the long LPL preamble to only
8 bytes. The node can return to sleep for the check interval after
receiving a packet or can perform early rejection much quicker than
packets sent with the long preambles.
We showed in Section 7 that using the node’s level in the tree
can assist in reducing the duty cycle. To reduce transmission energy
consumption, each node may learn the offset of the check interval
ti that their parent wakes up to sample the channel. Knowing
106
the point at which the parent wakes up allows the node to create a
communication schedule to its parent without any message overhead.
By starting transmission at the parent’s sample time, the
preamble can be significantly reduced in size. This optimization
reduces both the transmission and reception costs. A similar optimization
is proposed by the authors of WiseMAC [5]. Broadcast
packets would still be sent using the long preambles such that other
nodes can snoop on a significant portion of the network traffic. If
the schedule fails due to a change in link quality or parent node failure,
retransmission of the data can fall back to the long preamble
method.
9. CONCLUSION
In this paper we presented a flexible MAC protocol that features
a simple, predictable, yet scalable implementation and is tolerant
to network changes. B-MAC effectively performs clear channel
estimation. At its core, B-MAC exceeds the performance of other
protocols though reconfiguration, feedback, and bidirectional interfaces
for higher layer services. B-MAC may be configured to run at
extremely low duty cycles and does not force applications to incur
the overhead of synchronization and state maintenance.
We presented an analytical model for predicting an application’s
lifetime and setting B-MAC’s parameters. Using microbenchmarks
we showed that B-MAC can outperform existing wireless sensor
network media access protocols with only a small amount of information
from the services using it. With the default B-MAC parameters
and no additional information, B-MAC surpasses existing
protocols in terms of throughput, latency, and often energy consumption.
The performance of B-MAC under various workloads
gave us enough information to make accurate predictions of how a
real world application runs. The Surge application operated within
the realm of our model and reported a significant amount of data
with over 98.5% packet delivery.
Media access reconfiguration is essential for dynamic systems
like wireless sensor networks. Interfacing with services using the
MAC protocol is necessary to meet the demands of protocols and
applications. Optimizing protocol performance for system services
application in a predictable manner proves the feasibility of this
technology for long-term deployments.
Acknowledgments
This work was supported by DARPA grant F33615-01-C1895 (Network
Embedded Systems Technology “NEST”), the National Science
Foundation, the Intel Research Laboratory at Berkeley, and
the Center for Information Technology Research in the Interest of
Society (CITRIS). Special thanks to Wei Ye for his help with SMAC
under TinyOS. Thanks to Deborah Estrin and Nithya Ramanathan,
the anonymous reviewers, and our shepherd, Koen Langendoen,
whose suggestions and feedback significantly improved
our work.
10. REFERENCES
[1] N. Abramson. The aloha system: Another alternative for computer
communications. In Proceedings of the Fall 1970 AFIPS Computer
Conference, pages 281–285, Nov. 1970.
[2] A. Cerpa, J. Elson, D. Estrin, L. Girod, M. Hamilton, and J. Zhao.
Habitat monitoring: Application driver for wireless communications
technology. In 2001 ACM SIGCOMM Workshop on Data
Communications in Latin America and the Caribbean, Apr. 2001.
[3] Chipcon Corporation. CC1000 low power FSK transciever.
http://www.chipcon.com/files/CC1000_Data_
Sheet_2_1.pdf, Apr. 2002.
[4] A. El-Hoiydi. Aloha with preamble sampling for sporadic traffic in
ad hoc wireless sensor networks. In Proceedings of IEEE
International Conference on Communications, Apr. 2002.
[5] A. El-Hoiyi, J.-D. Decotignie, and J. Hernandez. Low power MAC
protocols for infrastructure wireless sensor networks. In Proceedings
of the Fifth European Wireless Conference, Feb. 2004.
[6] M. Hamilton, M. Allen, D. Estrin, J. Rottenberry, P. Rundel,
M. Srivastava, and S. Soatto. Extensible sensing system: An
advanced network design for microclimate sensing.
http://www.cens.ucla.edu, June 2003.
[7] J. Hill and D. Culler. Mica: a wireless platform for deeply embedded
networks. IEEE Micro, 22(6):12–24, November/December 2002.
[8] C. Intanagonwiwat, R. Govindan, and D. Estrin. Directed Diffusion:
A scalable and robust communication paradigm for sensor networks.
In Proceedings of the Sixth Annual International Conference on
Mobile Computing and Networks, Aug. 2000.
[9] J. Jubin and J. Tornow. The DARPA packet radio network protocols.
Proceedings of IEEE, 75(1):21–32, Jan. 1987.
[10] R. E. Kahn, S. A. Gronemeyer, J. Burchfiel, and R. C. Kunzelman.
Advances in packet radio technology. Procedings of the IEEE,
66(11):1468–1496, Nov. 1978.
[11] P. Levis, S. Madden, J. Polastre, R. Szewczyk, K. Whitehouse,
A. Woo, D. Gay, J. Hill, M. Welsh, E. Brewer, and D. Culler.
TinyOS: An operating system for wireless sensor networks. In
Ambient Intelligence. Springer-Verlag, 2004.
[12] A. Mainwaring, J. Polastre, R. Szewczyk, D. Culler, and
J. Anderson. Wireless sensor networks for habitat monitoring. In
Proceedings of the 1st ACM International Workshop on Wireless
Sensor Networks and Applications, pages 88–97. ACM Press, Sept.
2002.
[13] B. Mangione-Smith. Low power communications protocols: paging
and beyond. In Proceedings of the IEEE Symposium on Low Power
Electronics, 1995.
[14] L. G. Roberts. Aloha packet system with and without slots and
capture. Computer Communication Review, 5(2):28–42, Apr. 1975.
[15] S. Singh, M. Woo, and C. S. Raghavendra. Power-aware routing in
mobile ad hoc networks. In Proceedings of the ACM/IEEE
Conference on Mobile Computing and Networking, Oct. 1998.
[16] R. Szewczyk, J. Polastre, A. Mainwaring, and D. Culler. Lessons
from a sensor network expedition. In Proceedings of the First
European Workshop on Sensor Networks (EWSN), Jan. 2004.
[17] University of California, Berkeley. Mica2 schematics. http:
//webs.cs.berkeley.edu/tos/hardware/design/
ORCAD_FILES/MICA2/6310-0306-01ACLEAN.pdf, Mar.
2003.
[18] University of California, Berkeley. TinyOS CVS Repository at
SourceForge. http://sf.net/projects/tinyos/, 2004.
[19] T. van Dam and K. Langendoen. An adaptive energy-efficient mac
protocol for wireless sensor networks. In Proceedings of the First
ACM Conference on Embedded Networked Sensor Systems, Nov.
2003.
[20] A. Woo and D. E. Culler. A transmission control scheme for media
access in sensor networks. In Proceedings of the seventh annual
international conference on mobile computing and networking, July
2001.
[21] A. Woo, T. Tong, and D. Culler. Taming the underlying challenges of
multihop routing in sensor networks. In Proceedings of the First
ACM Conference on Embedded Networked Sensor Systems, Nov.
2003.
[22] W. Ye, J. Heidemann, and D. Estrin. An energy-efficient mac
protocol for wireless sensor networks. In In Proceedings of the 21st
International Annual Joint Conference of the IEEE Computer and
Communications Societies (INFOCOM 2002), June 2002.
[23] W. Ye, J. Heidemann, and D. Estrin. Medium access control with
coordinated, adaptive sleeping for wireless sensor networks. In IEEE
Transactions on Networking, Apr. 2004.
[24] J. Zhao and R. Govindan. Understanding packet delivery
performance in dense wireless sensor networks. In Proceedings of
the First ACM Conference on Embedded Networked Sensor Systems,
Nov. 2003.
107

6 1536-1284/07/$20.00 © 2007 IEEE IEEE Wireless Communications • December 2007
N
N (e)
(x1, y1)
(x2, y2)
(x, y)
d1
d2
(a)
(x3, y3)
d3
(x2, y2)
(x1, y1) (x, y)
θ2
θ1
WIRELESS SENSOR NETWORKING
INTRODUCTION
The definition of a localization system among
sensor nodes is a fundamental issue for many
applications of wireless sensor networks (WSNs).
Because sensor networks may be deployed in
inaccessible terrains or disaster relief operations
[1], the position of sensor nodes may not be predetermined.
Thus, a localization system is
required in order to provide position information
to the nodes.
The importance of localization information
arises from several factors, many of which are
related only to WSNs. These factors include the
identification and correlation of gathered data,
node addressing, management and query of
nodes localized in a determined region, evaluation
of nodes’ density and coverage, energy map
generation, geographic routing, object tracking,
and other geographic algorithms. All of these
factors make localization systems a key technology
for the development and operation of WSNs.
In this article we address the localization
problem from the viewpoint of a WSN. In the
next two sections we briefly present an overview
and definition of localization systems for WSNs
and their components. We show the main methods
used by localization systems to estimate distances
and angles. We show the techniques that
can be used by a node to compute its position,
and how all the estimated information of distances
and positions can be manipulated in
order to allow most or all of the nodes of a WSN
to estimate their positions. Finally, we present
our conclusions.
PROBLEM STATEMENT
A WSN can be composed of n nodes with a communication
range of r, distributed in a twodimensional
squared sensor field Q = [0,s] ×
[0,s]. For the sake of simplification, we consider
symmetric communication link; that is, for any
two nodes u and v, u reaches v if and only if v
reaches u and with the same signal strength w.
Thus, we represent the network by the Euclidean
graph G = (V, E) with the following properties:
• V = {v1, v2, …, vn} is the set of sensor nodes.
• 〈i, j〉 ∈ Ε if vi reaches vj; that is, the distance
between vi and vj is less than r.
• w(e) ≤ r is the weight of edge e = 〈i, j〉, the distance
between vi and vj
.
Some terms can be used to designate the
state of a node:
Definition 1 (Unknown Nodes — U): Also
known as free or dumb nodes, this term refers to
the nodes of the network that do not know their
localization information. To allow these nodes to
estimate their positions is the main goal of a
localization system.
Definition 2 (Settled Nodes — S): These nodes
were initially unknown nodes that managed to
estimate their positions by using the localization
system. The number of settled nodes and the
estimated position error of these nodes are the
main parameters for determining the quality of a
localization system.
AZZEDINE BOUKERCHE, UNIVERSITY OF OTTAWA
HORACIO A. B. F. OLIVEIRA, UNIVERSITY OF OTTAWA, FEDERAL UNIVERSITY OF AMAZONAS
EDUARDO F. NAKAMURA, FEDERAL UNIVERSITY OF MINAS GERAIS AND FUCAPI
ANTONIO A. F. LOUREIRO, FEDERAL UNIVERSITY OF MINAS GERAIS
ABSTRACT
Monitoring applications define an important
class of applications used in wireless sensor networks.
In these applications the network perceives
the environment and searches for event
occurrences (phenomena) by sensing different
physical properties, such as temperature, humidity,
pressure, ambient light, movement, and presence
(for target tracking). In such cases the
location information of both phenomena and
nodes is usually required for tracking and correlation
purposes. In this work we summarize most
of the concepts related to localization systems for
WSNs as well as how to localize the nodes in
these networks (which allows the localization of
phenomena). By dividing the localization systems
into three distinct components — distance/angle
estimation, position computation, and localization
algorithm — besides providing a didactic
viewpoint, we show that these components can
be seen as subareas of the localization problem
that need to be analyzed and studied separately.
LOCALIZATION SYSTEMS FOR
WIRELESS SENSOR NETWORKS
The authors
summarize most of
the concepts related
to localization
systems for WSNs
as well as how to
localize the nodes in
these networks
(which allows the
localization of
phenomena).
BOUKERCHE LAYOUT 12/4/07 1:55 PM Page 6
IEEE Wireless Communications • December 2007 7
Definition 3 (Beacon Nodes — B): Also known
as landmarks or anchors, these are the nodes
that do not need a localization system in order
to estimate their physical positions. Their localization
is obtained by manual placement or
external means such as GPS. These nodes form
the base of most localization systems for WSNs.
The localization problem can then be defined
as follows.
Definition 4 (Localization Problem): Given a
multihop network G = (V, E), and a set of beacon
nodes B and their positions (xb, yb), for all b
∈ B, we want to find the position (xu, yu) of as
many u ∈ U as possible, transforming these
unknown nodes into settled nodes, S.
THE COMPONENTS OF LOCALIZATION SYSTEMS
Localization systems can be divided into three
distinct components:
• Distance/angle estimation: This component is
responsible for estimating information about
the distances and/or angles between two
nodes. This information will be used by the
other components of the localization system.
• Position computation: This component is
responsible for computing a node’s position
based on available information concerning distances/angles
and positions of reference nodes.
• Localization algorithm: This is the main component
of a localization system. It determines
how the available information will be manipulated
in order to allow most or all of the nodes
of a WSN to estimate their positions.
Figure 1 depicts this component division.
Besides providing a didactic viewpoint, the
importance of such a division into components
comes, as we will see, from the need to recognize
that the final performance of a localization
system depends directly on each of these components.
Also, each component has its own goal
and methods of solution. They can thus be seen
as subareas of the localization problem that
need to be analyzed and studied separately.
DISTANCE/ANGLE ESTIMATION
Distance/angle estimation consists in identifying
the distance or angle between two nodes. Such
estimates constitute an important component of
localization systems, because they are used by
both the position computation and localization
algorithm components.
Different methods can be used to estimate
such information. Some of these methods are
very accurate, but with higher costs (in terms of
hardware, energy, and processor resources),
while others are less accurate but already available
on most sensor nodes.
In the following sections some of the main
methods used by localization systems to estimate
distances/angles will be studied. These methods
include received signal strength indication
(RSSI), time of arrival/time difference of arrival
(ToA/TDoA), angle of arrival (AoA), and communication
range.
RECEIVED SIGNAL STRENGTH INDICATOR
RSSI can be used to estimate the distance
between two nodes based on the strength of the
signal received by another node. As depicted in
Fig. 2a, a sender node sends a signal with a
determined strength that fades as the signal
propagates. The bigger the distance to the
receiver node, the lesser the signal strength
when it arrives at that node.
Theoretically, the signal strength is inversely
proportional to squared distance, and a known
radio propagation model can be used to convert
the signal strength into distance. However, in
real-world environments, this indicator is highly
influenced by noises, obstacles, and the type of
antenna, which makes it hard to model mathematically.
In these cases it is common to make a
system calibration [2], where values of RSSI and
distances are evaluated ahead of time in a controlled
environment.
This method, like the others, has both advantages
and disadvantages. The main advantage is
its low cost, because most receivers are capable
■ Figure 1. Division of localization systems into three distinct components.
Localization
Localization algorithm
systems
Distance
estimation
Position
computation
■ Figure 2. a) Decrease in signal strength; b), c) methods to derive the distance from the signal's arrival time; d) angle of arrival of the
signal.
Ultrasound pulse
θ
Sensor node
Time
t1
t2
Transmitter Receiver
(a) (b)
Distance
Communication range
Radio signal
Time
t1
t2
Transmitter Receiver
(c) (d)
Distance
Radio signal
Set
of
receivers
BOUKERCHE LAYOUT 12/4/07 1:55 PM Page 7
8 IEEE Wireless Communications • December 2007
of estimating the received signal strength. The
disadvantage of this method is that it is very susceptible
to noise and interference, which results
in higher inaccuracies of distance estimations.
Some experiments [3] show errors from 2 to 3 m
in scenarios where all nodes are placed in a
plane field 1.5 m from the ground with a communication
range of 10 m.
Although RSSI shows plausible results in simulations
and controlled experiments, its usage in
real-world applications is still questionable [4].
But, considering its low cost, it is possible that a
more sophisticated and precise use of RSSI (e.g.,
with better transmitters) could become the most
used technology of distance estimation from the
cost/precision viewpoint [5]. However, this technology
is not yet available.
TIME [DIFFERENCE] OF ARRIVAL
Different methods try to estimate distances
between two nodes using time based measures.
The most simple and intuitive is ToA [6]. In this
case the distance between two nodes is directly
proportional to the time the signal takes to
propagate from one point to another. This way,
if a signal was sent at time t1 and reached the
receiver node at time t2, the distance between
sender and receiver is d = sr(t2 – t1), where sr is
the propagation speed of the radio signal (speed
of light), and t1 and t2 are the times when the
signal was sent and received (Fig. 2b). This type
of estimation requires precisely synchronized
nodes and the time at which the signal leaves the
node must be in the packet that is sent.
TDoA is based on:
• The difference in the times at which a single
signal from a single node arrives at three or
more nodes
• The difference in the times at which multiple
signals from a single node arrive at another
node
The first case, which is more common in cellular
networks, requires precisely synchronized receiver
nodes (in this case base stations). In the second
case, more common and suitable for WSNs,
the nodes must be equipped with extra hardware
capable of sending two types of signals simultaneously.
These signals must have different propagation
speeds, like radio/ultrasound [7] or
radio/acoustic [2]. Usually, the first signal is the
packet itself, which propagates at the speed of
light (≈ 300.000 km/s), while the second signal is
some kind of sound, because of its slower propagation
(≈ 340 m/s), which is six orders of magnitude
slower then the first signal.
An example of TDoA suitable for WSNs is
used by [3] and depicted in Fig. 2c, where an
ultrasound pulse is sent simultaneously with a
radio signal. In this case nodes compute the difference
in the arrival times of the two signals.
The distance can now be computed by the formula
d = (sr – ss)*(t2 – t1), where sr and ss are
the propagation speed of the radio and ultrasound
signals, and t1 and t2 are the arrival times
of the radio and ultrasound signals, respectively.
Another different and interesting way of computing
distance among nodes using the TDoA is
proposed by Fu et al. [8], and is based on the
direct sequence spread spectrum (DSSS) modulation
technique.
The errors in the distance estimations
obtained by TDoA are approximately centimeters.
Experiments with ultrasound performed in
[3] indicate errors of about 2 or 3 cm (smaller
than the sensor node) in scenarios where nodes
were separated by distances of 3 m. In [9] acoustic
sound was tested, and results showed errors
of about 23 cm, with nodes at distances of 2 m.
Despite the lower errors, these systems have
disadvantages. The first is the need for extra
hardware to send the second signal, which
increases node cost. The second disadvantage is
the generally limited range of the second signal,
which is normally between 3 and 10 m with more
powerful transmitters.
ANGLE/DIRECTION OF ARRIVAL
The AoA of the signal [7, 10] can also be used
by localization systems. This angle can be in
relation to the node itself, to an electronic compass,
or to a second signal received by the node.
The estimation of the AoA is done by using
directive antennas or an array of receivers — usually
three or more — that are uniformly separated.
In the last case, based on the arrival times of the
signal at each of the receivers, it becomes possible
to estimate the AoA of this signal (Fig. 2d).
Experiments show that this method has an
inaccuracy of some degrees (about 5° in [7]). The
need for extra hardware and a minimum distance
between the receivers results in some disadvantages
in terms of the cost and size of nodes.
COMMENTS ABOUT THE
DISTANCE/ANGLE ESTIMATION
The choice of which method to use to estimate
the distance between nodes in a localization system
is an important factor that influences the
final performance of the system. Usually, as
shown in the next section, to estimate a position,
a node uses at least three distance estimations,
each with an associated error. On the other
hand, if only the accuracy of these methods was
important, we could just use TDoA since it has
fewer errors. However, factors including the size
and cost (in terms of hardware, processor, and
energy) of the nodes must also be taken into
consideration. Thus, the method chosen for estimating
distances depends on the application
requirements as well as available resources.
POSITION COMPUTATION
When a node has enough information about distances
and/or angles and positions, it can compute
its own position using one of the methods
studied in this section.
Several methods can be used to compute the
position of a node. Such methods include trilateration,
multilateration, triangulation, probabilistic
approaches, bounding box, and the central
position. The choice of which method to use also
impacts the final performance of the localization
system. Such a choice depends on the information
available and the processor’s limitations.
TRILATERATION AND MULTILATERATION
Trilateration is the most basic and intuitive
method. This method computes a node’s posiDifferent
methods try
to estimate distances
between two nodes
using time based
measures. The most
simple and intuitive
is ToA. In this case,
the distance between
two nodes is directly
proportional to the
time that the signal
takes to propagate
from one point to
another.
BOUKERCHE LAYOUT 12/4/07 1:55 PM Page 8
IEEE Wireless Communications • December 2007 9
tion via the intersection of three circles, as
depicted in Fig. 3a. To estimate its position
using trilateration, a node needs to know the
positions of three reference nodes and its distance
from each of these nodes. Distances can
be estimated using one of the methods explained
in the previous section.
The circles formed by the position and distance
to each of the references can be represented
by the formula (^x – xi)2 + (^y – yi)2 = di
2,
where(^x , ^y ) is the position we want to compute,
(xi, yi) is the position of the ith reference node,
and di is the distance of the ith reference node
to the unknown node. In this case we have three
equations with two unknowns, which can be
solved, theoretically, in one solution.
In real-world applications the distance estimation
inaccuracies as well as the inaccurate
position information of reference nodes make it
difficult to compute a position. As depicted in
Fig. 3b, the circles do not intersect at only one
point, resulting in an infinite set of possible solutions.
Furthermore, when a larger number of reference
points are available, we can use multilateration
to compute the node’s position. In this case
an overdetermined system of equations must be
solved. Figure 3 depicts this case. Usually,
overdetermined systems do not have a unique
solution. When considering n reference points
and also the error of the distance estimations,
which makes di = d
^
i – ε, the system of equations
becomes (^x – xi)2 + (^y – yi)2 = di
2 – e, where ε is
normally considered to be an independent normal
random variable with zero mean. This system
can be linearized, by subtracting the last
equation, into Ax ≈ b. This linear system can be
solved easily using standard methods like the
least squares approach.
The number of floating point operations
needed to compute a position depends on the
method used to solve the system of equations. In
the case of the least square method, (m + n/3)n2
floating point operations (where m is the number
of unknowns and n is the number of equations)
are required to estimate a position.
BOUNDING BOX
The bounding box method proposed in [12] uses
squares — instead of circles as in trilateration —
to bound the possible positions of a node. An
example of this method is depicted in Fig. 3d.
For each reference node i, a bounding box is
defined as a square with its center at the position
of this node (xi, yi), with sides of size 2di
(where d is the estimated distance) and with
coordinates (xi – di, yi – di) and (xi + di, yi +
di). The intersection of all bounding boxes can
be easily computed without any need for floating
point operations by taking the maximum of
the low coordinates and the minimum of the
high coordinates of all bounding boxes. This is
the shaded rectangle in Fig. 3d. The final position
of the unknown node is then computed as
the center of the intersection of all bounding
boxes.
Despite the final error of this method, which
is greater than trilateration, computing the intersection
of squares uses fewer processor resources
than computing the intersection of circles.
TRIANGULATION
In triangulation [7, 10] information about angles
is used instead of distances. Position computation
can be done remotely (Fig. 3e) or by the
node itself; the latter is more common in WSNs.
In this last case, depicted in Fig. 3f, at least
three reference nodes are required. The
unknown node estimates its angle to each of the
three reference nodes and, based on these angles
and the positions of the reference nodes (which
form a triangle), computes its own position using
simple trigonometrical relationships. This technique
is similar to trilateration. In fact, based on
the AoAs, it is possible to derive the distances to
reference nodes [10].
■ Figure 3. a) Theoretical model of trilateration; b) a more realistic model of trilateration; c) multilateration; d) bounding box;
e), f) triangulation; g), h) probabilistic approach (from [11]).
(f)
N
N (e)
(x1, y1)
(x2, y2) (x1, y1)
r1 = d1 – e1
(x, y)
(x, y)
d1
d2 d1 e1
e2 e3
(b) (c) (d) Bounding box (a)
(x3, y3)
d3
(x2, y2)
(x1, y1)
(x3, y3)
(x2, y2)
(x1, y2) (x, y)
(x, y)
θ2
θ23 θ12
θ31 θ1
d3(x
3, y3)
r3
r2 r1
(x2, y2)
(x1, y1) (x2, y2)
d1
(x3, y3)
(x2, y2)
d3
d2 (x3, y3)
(x4, y4)
(x5, y5)
d5 d4
d3
d d2 1
(x, y)
(x, y)
80
2
0
4
6
×104
90
70 60 (g)
5040 50 60 70
80 85
1
0
4
5
×104
3
2
80 75 70 (h) 654045505560657075
Residuals =
r1+r2+r3
(x1, y1)
BOUKERCHE LAYOUT 12/4/07 1:55 PM Page 9
10 IEEE Wireless Communications • December 2007
PROBABILISTIC APPROACHES
The uncertainty in distance estimations has motivated
the appearance of probabilistic approaches
for computing a node’s position. An example of a
probabilistic approach is proposed in [11], where
the errors in distance estimations are modeled as
normal random variables. When an unknown
node receives a packet from a reference node, it
can be in any place around the reference node
with equal probabilities. When another packet is
received from another reference node, the
unknown node computes its position again as
depicted in Fig. 3g. When new position information
is received from other nodes, it becomes
possible to identify the probable location of the
unknown node, as depicted in Fig. 3h.
The main drawbacks of this approach are the
high computational cost and the space required
to store the information.
COMMENTS ABOUT POSITION COMPUTATION
A number of other methods exist that aim to compute
the position of a node. Location fingerprinting
is a method in which the signal characteristics
obtained from a set of locations are catalogued,
and the position computation of a node consists of
comparing its current signal characteristics with
those catalogued previously. This technique is
used by Bahl et al. [13] and other indoor localization
systems, but the need to generate a signal signature
database makes this technique unfeasible
for most scenarios of WSNs. He et al., in the
APIT algorithm [4], use triangles formed by three
beacon nodes, and a node decides if it is inside or
outside these triangles by comparing its signal
strength measurements with the measurements of
its neighbors. The position of the node is computed
by finding the centroid of the intersection of
the beacon triangles the node is within.
Other work concentrates all information
about distances between the nodes into a central
node and uses mathematical optimization techniques
to compute the positions of the nodes. As
an example, we have the work of Doherty et al.
[14] who formulate the localization problem as a
convex optimization problem based only on connectivity-induced
constraints and use a semidefinite
program (SDP) to solve the problem. There
is also the work of Shang et al. [15], who used
multidimensional scale (MDS).
LOCALIZATION ALGORITHM
The localization algorithm is the main component
of a localization system. This component
determines how the information concerning distances
and positions is manipulated in order to
allow most or all of the nodes of a WSN to estimate
their positions.
Localization algorithms can be classified into
a few categories: distributed [6, 16, 17] or centralized
position computation [14]; with [16, 17]
or without an infrastructure [6, 7, 18]; relative
[19, 20] or absolute positioning [6, 16]; designed
for indoor [7, 18] or outdoor scenarios [6]; and
one hop [6, 18] or multihop [16, 17].
Here some proposed localization algorithms
are discussed to show how this component differentiates
from the other components. These
algorithms are the Ad Hoc Positioning System
(APS), Recursive Position Estimation (RPE),
and Localization with a Mobile Beacon (LMB).
AD HOC POSITIONING SYSTEM
In APS [17] a reduced number of beacon nodes
(e.g., three or more) is deployed with the
unknown nodes. Then each node estimates its distance
to the beacon nodes in a multihop way.
Once these distances are estimated, the nodes can
compute their positions using trilateration. Three
methods of hop-by-hop distance propagation are
proposed: Dv-Hop, Dv-Distance, and Euclidean.
In Dv-Hop APS the beacon nodes start the
propagation of their position information (Fig.
4a). Working as an extension of the distance vector
algorithm, all nodes receive the position information
of all beacon nodes as well as the number
of hops to these beacons. When a beacon node
receives the position information of the other
beacon nodes, it has enough information to compute
the average size of one hop based on its own
position, the position of the other beacon nodes,
and the number of hops between them (Fig. 4b).
This last value is then flooded in a controlled way
into the network as a correction factor. When an
unknown node receives a correction, it is able to
convert its distance to the beacon nodes from
number of hops to meters (Fig. 4c). The complexity
of message exchange in this algorithm is driven
by the total number of beacon and normal nodes,
which is O(n*(m + 1)), where n is the number of
nodes and m is the number of beacon nodes.
An advantage of the APS is that its localization
algorithm requires a low number of beacon
nodes in order to work. However, the way distances
are propagated, especially in Dv-Hop and
Dv-Distance, as well as the way these distances
are converted from hops to meters in Dv-Hop,
result in erroneous position computation, which
increases the final localization error of the system.
RECURSIVE POSITION ESTIMATION
In RPE [16] nodes estimate their positions based
on a set of initial beacon nodes (e.g., 5 percent
of the nodes) using only local information. Localization
information increases iteratively as newly
settled nodes become reference nodes.
The RPE algorithm can be divided into four
phases, as depicted in Fig. 5. In the first phase a
node determines its reference nodes. In the second
phase the node estimates its distance to
these reference nodes using, for example, RSSI.
In the third phase the node computes its position
using trilateration (becoming a settled
node). In the final phase the node becomes a
reference node by broadcasting its newly estimated
position to its neighbors. When a node
becomes a reference, it can assist other nodes in
computing their positions as well.
An advantage of this algorithm is that the
number of reference nodes increases quickly, in
such a way that the majority of the nodes can
compute their position. But this technique has the
disadvantage of propagating localization errors.
This means that the inaccurate position estimation
of one node can be used by other nodes to estimate
their positions, increasing this inaccuracy.
Furthermore, a node must have at least three reference
neighbors in order to compute its position.
In APS, a reduced
number of beacon
nodes (e.g., three or
more) is deployed
with the unknown
nodes. Then, each
node estimates its
distance to the
beacon nodes in a
multihop way. Once
these distances are
estimated, the nodes
can compute their
positions using
trilateration.
BOUKERCHE LAYOUT 12/4/07 1:55 PM Page 10
IEEE Wireless Communications • December 2007 11
LOCALIZATION WITH A MOBILE BEACON
Some recent work [21] has proposed the use of
mobile beacons to assist the nodes of a WSN in
estimating their positions. A mobile beacon is a
node that is aware of its position (e.g., equipped
with a GPS receiver) and has the ability to move
around the sensor field. This beacon can be a
human operator, an unmanned vehicle, an aircraft,
or a robot.
The system operation in [21] is quite simple.
Once the nodes are deployed, the mobile beacon
travels through the sensor field broadcasting
messages that contain its current coordinates.
When a free node receives more than three messages
from the mobile beacon it computes its
position, using a probabilistic approach, based
on the received coordinates and RSSI distance
estimations. Figure 6 illustrates this scenario and
three possible trajectories for the mobile beacon.
The communication cost for the WSN is null,
since none of the nodes (except the mobile beacon)
need to send any packets.
An advantage of this algorithm is that position
estimations are computed based on the same
node (mobile beacon), thus keeping the mean
localization error low and preventing the propagation
of this error. In addition, this algorithm
avoids the use of nodes equipped with GPS,
except for the mobile beacon. On the other hand,
in this technique a sensor node can estimate its
position only when the mobile beacon passes near
this node, which may take a long time depending
on such factors as the size of the sensor field, the
beacon’s mobility capacity, and the node’s trajectory.
Also, the mobile beacon may never pass
near some nodes, because of either the trajectory
or a problem with the mobile beacon.
COMMENTS ABOUT LOCALIZATION ALGORITHMS
Several localization algorithms focus on different
aspects such as errors, number of beacons, number
of settled nodes, or GPS usage, among other
things. Usually, these algorithms [19, 20] try to
reduce or completely remove the need for GPS
receivers on beacon nodes. Other algorithms take
advantage of certain network features, such as
beacons with high-powered transmitters [4], a
directed localization recursion [22], or a beacon
infrastructure [18]. The choice of which algorithm
to use depends on the resources available, the scenario,
the requirements of the application, and the
mean localization error acceptable to the nodes.
FINAL REMARKS
This article has addressed the localization problem
from the viewpoint of a WSN. We divided
localization systems into three components: distance/angle
estimation, position computation,
and localization algorithm.
The importance of such a division of localization
systems into components lies in the need to
recognize that the final performance of localization
systems depends directly on each of these
components. For instance, a localization system
should achieve better results if the TDoA
■ Figure 4. Example and phases of APS Dv-Hop.
2 hops, 54 m
3 hops, 68 m
4 hops, 110 m
Beacon node
AvgHop = 27.3 m
AvgHop = 25.4 m
(a) AvgHop = (68 + 54)/(3 + 2)
=24.4 m (b)
(c)
Unknown node
Settled node
■ Figure 5. Example and phases of RPE.
(a) (b)
d9
d7
d13 d13 d8
d9
(c) (d)
■ Figure 6. Operation and possible trajectories of a mobile beacon.
(a)
Trajectory
(b)
Trajectory
(c)
Trajectory
Mobile beacon Mobile beacon
Mobile beacon
BOUKERCHE LAYOUT 12/4/07 1:55 PM Page 11
12 IEEE Wireless Communications • December 2007
method is used instead of RSSI to estimate distances.
The same principle applies to the other
components. These components can be seen as
subareas of the localization problem that need
to be studied separately.
A general rule in WSNs is that there is not a
perfect solution suitable for every scenario. The
same rule applies to the localization problem.
This article has shown a number of proposed
localization systems, each with an emphasis on a
specific scenario and/or application. The necessity
of different solutions for different applications
and also the high number of possible applications
of WSNs have greatly motivated the study
and proposals of new solutions to the localization
problem.
REFERENCES
[1] I. F. Akyildiz et al., “Wireless Sensor Networks: A Survey,”
Comp. Networks, vol. 38, no. 4, Mar. 2002, pp. 393–422.
[2] K. Whitehouse and D. Culler, “Calibration as Parameter
Estimation in Sensor Networks,” WSNA ’02: Proc. 1st
ACM Int’l. Wksp. Wireless Sensor Networks and Apps.,
ACM Press, 2002, pp. 59–67.
[3] A. Savvides, C.-C. Han, and M. B. Strivastava, “Dynamic
Fine-Grained Localization in Ad-Hoc Networks of Sensors,”
7th ACM/IEEE Int’l. Conf. Mobile Computing and
Networking, Rome, Italy, 2001, pp. 166–79.
[4] T. He et al., “Range-Free Localization Schemes for Large
Scale Sensor Networks,” MobiCom ’03, ACM Press,
2003, pp. 81-95.
[5] J. Bachrach and C. Taylor, “Localization in Sensor Networks,”
Handbook of Sensor Networks: Algorithms and
Architectures, I. Stojmenovic, Ed., Wiley, Sept. 2005.
[6] B. Hofmann-Wellenho, H. Lichtenegger, and J. Collins,
Global Positioning System: Theory and Practice, 4th
ed., Springer-Verlag, 1997.
[7] N. B. Priyantha et al., “The Cricket Compass for ContextAware
Mobile Applications,” 7th ACM Int’l. Conf. Mobile
Computing and Networking, Rome, Italy, July 2001.
[8] Y. Fu et al., “The Localization of Wireless Sensor Network
Nodes Based on DSSS,” Electro/Infor. Tech., 2006
IEEE Int’l. Conf., 2006, pp. 465–69.
[9] K. Whitehouse, “The Design of Calamari: An Ad Hoc
Localization System for Sensor Networks,” Master’s thesis,
UC Berkeley, 2002.
[10] D. Niculescu and B. Nath, “Ad Hoc Positioning System
(APS) Using AOA,” Proc. INFOCOM ’03, San Francisco,
CA, 2003.
[11] V. Ramadurai and M. L. Sichitiu, “Localization in Wireless
Sensor Networks: A Probabilistic Approach,” Proc.
ICWN 2003, Las Vegas, NV, June 2003, pp. 275–81.
[12] S. Simic and S. Sastry, “Distributed localization in
wireless ad hoc networks,” UC Berkeley, Tech. rep.
UCB/ERL M02/26, 2002.
[13] P. Bahl and V. N. Padmanabhan, “Radar: An In-Building
RF-Based User Location and Tracking System,” Proc.
IEEE INFOCOM 2000, vol. 2, Tel Aviv, Israel, Mar. 2000,
pp. 775–84.
[14] L. Doherty, K. S. Pister, and L. E. Ghaoui, “Convex
Position Estimation in Wireless Sensor Networks,” IEEE
ICC ’01, vol. 3, Anchorage, AK, Apr. 2001, pp. 1655–63.
[15] Y. Shang and W. Ruml, “Improved MDS-Based Localization,”
IEEE ICC ’04, vol. 4, Mar. 2004, pp. 2640–51.
[16] J. Albowicz, A. Chen, and L. Zhang, “Recursive Position
Estimation in Sensor Networks,” 9th Int’l. Conf. Network
Protocols, Nov. 2001, pp. 35–41.
[17] D. Niculescu and B. Nath, “Ad Hoc Positioning System
(APS),” IEEE GLOBECOM ‘01, San Antonio, TX, Nov.
2001, pp. 2926–31.
[18] N. B. Priyantha, A. Chakraborty, and H. Balakrishnan,
“The Cricket Location-Support System,” Mobile Comp.
and Networking, Boston, MA, Aug. 2000, pp. 32–43.
[19] N. Bulusu, J. Heidemann, and D. Estrin, “GPS-Less Low
Cost Outdoor Localization for Very Small Devices,” IEEE
Pers. Commun., vol. 7, no. 5, Oct. 2000, pp. 28–34.
[20] S. Capkun, M. Hamdi, and J.-P. Hubaux, “GPS-Free
Positioning in Mobile Ad Hoc Networks,” Cluster Computing,
vol. 5, no. 2, 2002, pp. 157–67.
[21] M. L. Sichitiu and V. Ramadurai, “Localization of Wireless
Sensor Networks with A Mobile Beacon,” Proc. 1st
IEEE Int’l. Conf. Mobile Ad Hoc and Sensor Sys., FL,
Oct. 2004, pp. 174–83.
[22] H. A. F. Oliveira et al., “Directed Position Estimation: A
Recursive Localization Approach for Wireless Sensor
Networks,” Proc. 14th IEEE Int’l. Conf. Comp. Commun.
and Networks, S. R. Thuel, Y. Yang, and E. Park, Eds.
San Diego, CA, Oct. 2005, pp. 557–62.
BIOGRAPHIES
AZZEDINE BOUKERCHE (boukerch@site.uottawa.ca) is a full
professor and holds a Canada Research Chair position at
the University of Ottawa. He is the founding director of the
PARADISE Research Laboratory at the university. Prior to
this, he held a faculty position at the University of North
Texas and worked as a senior scientist at the Simulation
Sciences Division, Metron Corporation, San Diego, California.
He was also employed on the faculty of the School of
Computer Science, McGill University, and taught at Polytechnic
of Montreal. He spent a year at the JPL/NASA-California
Institute of Technology where he contributed to a
project centered on the specification and verification of the
software used to control interplanetary spacecraft operated
by JPL/NASA Laboratory. His current research interests
include wireless ad hoc and sensor networks, wireless networks,
mobile and pervasive computing, wireless multimedia,
QoS service provisioning, performance evaluation and
modeling of large-scale distributed systems, distributed
computing, large-scale distributed interactive simulation,
and parallel discrete event simulation. He has published
several research papers in these areas. He was the recipient
of the Best Research Paper Award at IEEE/ACM PADS ’97
and ACM MobiWac’06; of the 3rd National Award for
Telecommunication Software in 1999 for his work on a distributed
security system on mobile phone operations; and
has been nominated for the Best Paper Award at IEEE/ACM
PADS ’99 and ACM MSWiM ’01. He is a holder of an
Ontario Early Research Excellence Award (previously known
as the Premier of Ontario Research Excellence Award), an
Ontario Distinguished Researcher Award, and a Glinski
Research Excellence Award. He is a co-founder of QShine,
the International Conference on Quality of Service for Wireless/Wired
Heterogeneous Networks, served as a General
Chair for the 8th ACM/IEEE Symposium on Modeling, Analysis
and Simulation of wireless and mobile systems, and
the 9th ACM/IEEE Symposium on distributed simulation
and real-time application; has been Program Chair for ACM
Workshop on QoS and Security for Wireless and Mobile
Networks, ACM/IFIPS Europar 200, IEEE/SCS Annual Simulation
Symposium ’02, ACM WWW ’02, IEEE MWCN ’02,
IEEE/ACM MASCOTS ’02, IEEE Wireless Local Networks WLN
’03–’04, IEEE WMAN ’04–’05, and ACM MSWiM ’98–’99;
and has been a Technical Program Committee member of
numerous IEEE and ACM sponsored conferences. He has
served as a Guest Editor for several publications.
ANTONIO A. F. LOUREIRO (loureiro@dcc.ufmg.br) holds a B.Sc.
and an M.Sc. in computer science, both from the Federal
University of Minas Gerais (UFMG), and a Ph.D. in computer
science from the University of British Columbia, Canada.
Currently he is an associate professor of computer science
at UFMG, where he leads the research group on wireless
sensor networks. His main research areas are wireless sensor
networks, mobile computing, and distributed algorithms.
EDUARDO FREIRE NAKAMURA (eduardo.nakamura@fucapi.br) is
a researcher and full professor at the Center of Research
and Technological Innovation, Brazil. He received his Ph.D.
in computer science from the Federal University of Minas
Gerais, Brazil, in 2007. His research interests include
data/information fusion, distributed algorithms, localization
algorithms, wireless ad hoc and sensor networks, and
mobile and pervasive computing. He has published several
papers in the area of WSNs, and served as a Technical Program
Committee member of the 2nd Latin American Autonomic
Computing Symposium, supported by the IEEE
Computer Society.
HORACIO A. B. F. OLIVEIRA (horacio@site.uottawa.ca) is a
professor of computer science at Federal University of
Amazonas (UFAM), Brazil. He is currently working toward a
Ph.D. degree in computer science at UFMG) with a partial
doctoral fellowship at the University of Ottawa, Canada.
He holds an M.Sc. in computer science from UFMG and a
B.Sc. in computer science from UFAM. His research interests
include localization and synchronization algorithms,
distributed algorithms, and wireless ad hoc, vehicular, and
sensor networks. He is author of several papers in different
areas of his research interests.
The necessity of
different solutions for
different applications
and also the high
number of possible
applications of
WSNs has greatly
motivated the study
and proposals of
new solutions to the
localization problem.
BOUKERCHE LAYOUT 12/4/07 1:55 PM Page 12

BACKGROKUND OF THE INVENTION
1. Field of the Invention

The invention relates to wireless telemetry, security networks, or monitoring of physical conditions. In particular, the invention relates to the remote detection, monitoring or tracking of vehicles, personnel, or other physical conditions, for example in industrial equipment monitoring and control systems.

2. Description of the Related Art

Sensor networks have numerous applications, such as security, industrial monitoring, military reconnaissance and biomedical monitoring. In many such applications it is either inconvenient or impossible to connect the sensors by wire or cable; a wireless network is preferable.

Seismic sensors, for example, can be used to detect intrusion or movement of vehicles, personnel or large earth masses. For example, U.S. Pat. No. 4,649,524 to Vance (1987) describes an integrated acoustic network which provides warning of impending groundfall in underground mines. The system includes a plurality of geophones which derive acoustic signals from which the source of seismic disturbances is located, and an array of high frequency piezoelectric sensors which pick up signals from small ground disturbances which precede groundfall.

The detection of vehicles and personnel is more difficult than detecting large signals, as from earthquakes or movement of earth masses. Quiet vehicles and personnel movement produce seismic signals which may not be detectable by geophones at ranges of more than tens of meters, particularly in the presence of background noise. The reliable detection or tracking over large areas thus requires very large numbers of sensitive detectors, spaced closely. The placement of such large numbers of conventional detectors is generally inconvenient, expensive and time consuming if they must be wired for communication or power supply. A wireless network of numerous sensitive, low cost, low powered sensor stations would be more desirable.

Wireless networks of sensor stations, however, present several technical challenges. Wireless communication generally requires higher power than wired communication over the same distance; but an individual wireless sensor station requires a limited, self- contained power supply, which usually dictates that it conserve energy. The resulting low power constraint severely limits the range of wireless transmission by an individual sensor station. There are other drawbacks: wireless communication is vulnerable to jamming or unintentional interference. It is also overt in that the source of a transmission can be located by a hostile agent. If control or data processing occurs at a central location, then the entire network is vulnerable to failure of the central processor. Such an architecture has low reliability and cannot easily survive in a hostile environment. Wireless communication among large numbers of densely placed sensor stations requires sophisticated multiplexing or scheduling to avoid cross-interference. If the stations are placed randomly or some have initially unknown locations, it is difficult to learn the topology of the network so that multi-hop communications (communications relayed among multiple stations) may be scheduled.

Wireless security devices, such as wireless alarms, are widely available. Such systems generally employ only one-way wireless communication. For example, Brunius, U.S. Pat. No. 4,855,713 describes a system in which one-way alarm transmitters report to a central processing unit (CPU). The system even permits the CPU to detect new alarm transmitters and add them to the programmed system. Such systems are limited by one-way communication from the alarms to the central control. This limits their flexibility and utility, because it is impossible to remotely reprogram or adapt the network of sensors to a changing environment or a new purpose. An additional problem in the patented system is that the alarm transmitters must each have sufficient power to be received by the central receivers, or a repeater must be provided. This requires relatively high power to cover a significant area. The number of possible transmitters is also limited to the number of communication channels available; otherwise, simultaneous transmissions on the same channel will interfere with one another and be unintelligible. This system cannot be extended to permit a truly distributed, multihop network containing very high numbers of densely placed, low power sensor stations.

Another shortcoming of prior detection and alarm systems is that very little signal processing of the alarm condition is available at the sensor station, especially with wireless systems. This makes it difficult to distinguish among relevant, urgent or irrelevant signals unless the entire signal is transmitted, which would require a large expenditure of energy.

SUMMARY OF THE INVENTION
The invention is a miniature electronic sensing station, adaptable for two-way wireless communication in a network with other similar sensing devices, for sensing events such as an intrusion, vehicle movement, a change in status of some industrial process, or any physical change that can be detected by the sensors. Deployment in a network allows monitoring of the spatial extent and distribution of the sensed condition. Each sensing station in the network includes one or more sensors; a digital signal processor for analyzing the data from the sensors; a programmable microprocessor for making decisions based upon the analyzed data, and for controlling communication functions; a power supply; and a wireless transceiver, for communicating with other sensing devices in the network and with users. All of the components of the sensing station are enclosed in a single package and collectively constitute a “node” of the network. In a typical application a network of such nodes may contain large numbers of such sensing nodes (more than 100), spaced fairly closely together (typically within less than 100 yards). The nodes can be placed randomly. They could, for example, be dropped from an aircraft or a ship; they could be placed manually. It is not necessary for each node to have a known location before startup; the nodes are programmable to organize themselves in a distributed fashion. Control of the network is distributed among the nodes; no indispensable central controller is necessary.

The invention preferably is used in a large network of wireless nodes, each of which is very compact and has a very limited power supply. The limitation on available power makes low power consumption an objective at every level of the invention. The practical implementation of this network architecture depends on several features which cooperate in a synergistic manner to allow effective, low powered sensing and wireless communication. At the node level the invention uses low powered sensors, low powered digital signal processing, a micropower programmable microprocessor, and a low powered RF transceiver, all cooperating in an architecture well adapted to conserve energy. At the network level, the design also conserves energy by fully utilizing the large number of nodes and low powered short range multi-hop communication in a web-like network.

Two techniques are used at the node level as energy conserving motifs: (1) circuits which are not required to be active during a time window are held in an inactive “sleep mode” so as to conserve energy, and (2) whenever possible, data is processed, compressed or summarized before transmission. This latter technique is effective because wireless transmission consumes vastly more energy than computation, especially where low power complementary metal oxide semiconductor (CMOS) circuitry can be used for computation.

The sensor or sensors may be of several types, such as seismic, acoustic, infrared, thermal, optical, magnetic or mechanical (for example, an accelerometer). The invention includes realizations of micro-seismic and micro-infrared sensors, but other sensors could also be used, as long as they consume low power and are small.

The sensor may include a sensing device that produces an analog output indicative of the sensed condition, coupled with an analog-to-digital converter (ADC) that digitizes the analog output. The ADC operates at low duty cycle and is preferably a Σ-Δ converter, consuming very low power. The ADC displays low switching activity in the absence of a change in input signal level. It thus operates at minimum power for normal operation in the absence of a “threat” signal.

The digitized signal from the ADC is processed by a low power digital signal processor which analyzes power spectral density in selected bands. The power spectral density of the signal is then compared to a profile and a decision is made based on the result of the comparison. When the spectral density of the signal exceeds the threshold profile, the output of a series of comparators causes the programmable microprocessor to “wake up” and go from its power conserving state to a higher power operating state. The microprocessor then decides what action to take: whether to perform more signal processing and analysis, to activate the transmitter, to transmit the spectral density of the signal, to transmit the raw signal data or perhaps to do nothing, depending on the signal and the programming of the microprocessor.

The microprocessor is preferably adapted to conserve power by not continuously operating in the usual sequence of instruction fetch and decode operations. Rather, it is only activated for critical, low duty-cycle windows and when a decision is required based on an event.

The wireless transceiver allows the node to communicate with other nodes (including user nodes, which provide communication with the user) when it is enabled by the microprocessor. The invention preferably uses low power radio frequency (RF) circuitry. In one embodiment, the RF transceiver is designed to consume minimal power when not in demand, but to turn on and off quickly as required.

Power is also conserved at the network level by organizing the nodes to communicate by a multihop method, relaying messages through a series of short, low power RF transmissions or “hops,” rather than by long, high power jumps. The nodes may be programmed to organize themselves into a communication topology so as to enable wireless communication throughout the network, using a time division multiple access (TDMA) scheme. TDMA is preferred because it allows transceivers to remain in a power conserving, off state for periods of time when not in use, turning on only for short bursts. Because each node has a very short range, multiple nodes may use the same channel simultaneously, so long as the simultaneous users are out of range of one another. This enables reuse of wireless communication channels and makes it possible for a large number of nodes to communicate on a relatively small number of channels.

The ability to use two-way wireless communication enables the network to respond to changes in environment or changes in command priorities. Each node can be reprogrammed by wireless transmissions relayed through the network. For example, new spectral profiles can be entered, or nodes can be reprogrammed for a higher duty cycle during critical periods of activity. Loss of nodes or the addition of new nodes can be accommodated easily.

The invention also benefits from a high degree or integration of the components--sensors, micropower control processor, ADC, wireless transceiver, and signal processor-into a compact package. Relative ease of manufacture and compact, durable packaging make practical the deployment of large numbers of short range, densely placed wireless sensor nodes.

BRIEF DESCRIPTION OF THE DRAWINGS
FIG. 1 is a perspective view of one embodiment of an electronic sensing station or “node” of the invention;

FIG. 2 is a perspective view of a network of nodes deployed in a landscape;

FIG. 3 is a block diagram showing the architecture of an exemplary node;

FIG. 4 is a block diagram of a digital signal processor that can be used with the invention;

FIG. 5 is a block diagram of one realization of a four pole digital filter in IIR form that can be used in the digital signal processor to extract spectral power information from the sensor data;

FIG. 6 is a graph showing the frequency responses of selected digital bandpass filters realized according to FIG.5 which can be used with the invention;

FIG. 7 is a flow chart showing the control activities performed by a microprocessor used in the invention;

FIG. 8 is a timing diagram showing a possible subdivision of a repeating time frame which can be used by the invention to allow multiple access node communications; and

FIG. 9 is a block diagram of a wireless transceiver which can be used with the invention.

DETAILED DESCRIPTION
The invention is a highly integrated, miniature electronic sensing station which is specially adapted for use with other such sensing stations in a wireless, communicating network. The station and the network of which it is a part can be used for sensing conditions or events such as an intrusion, vehicle movement, a condition or change in status of some industrial process, or any physical change or condition which can be detected by the sensors. Because they function as members of a network, the sensing stations will hereinafter be referred to as “nodes” in recognition of their similarity to nodes in a communication network or graph.

FIG. 1 shows one possible realization of a single device or node, as it might be deployed in terrain. The node includes an enclosure 1, which houses and provides environmental protection for the functional components (shown in phantom) including circuitry 2 and power supply (batteries) 3. An antenna 4 is mounted atop the enclosure 1, for transmitting and receiving radio signals. Although the antenna 4 is shown as a vertical dipole with artificial groundplane, other configurations may be used, including internal covert antenna loops or even an integrated antenna element. The exterior shape of the node housing 1 could also be varied to take almost any shape, as the application demands. The dimensions of the housing 1 can be varied, with the minimum size limited only by the degree of integration and miniaturization of the circuitry 2 and power supply 3.

FIG. 2 shows an example of how the nodes might be deployed in terrain. The nodes can be dropped, for example from an aircraft, a ground vehicle, or even by walking personnel. Individual nodes 6 are scattered in a more or less random fashion, but are able to establish wireless radio communication, as indicated by the dotted lines 7, collectively forming a network.

FIG. 3 shows an architecture for an individual node. Local environmental conditions or changes are sensed by a sensor or sensor arrays 12. In the typical case in which the sensor(s) produce an analog signal or signals, an analog-to-digital converter (ADC) 14 is provided to digitize the data from the sensors. The data is stored for processing in a buffer memory 16. A digital signal processor (DSP) 18 (which preferably includes a buffer 16, a spectrum analyzer 17, a multi-channel sum of squares accumulator 80 and threshold comparators 19) filters and analyzes the stored data to improve signal-to-noise ratio and extract information regarding the amplitude and spectral characteristics of the sensor data. After filtering, the DSP 18 compares the characteristics to user-programmed profiles, and presents the results of the comparison to a microprocessor 20. The microprocessor 20 makes decisions based upon the information from the DSP 18. For example, if certain low frequency signals are detected, indicating a vehicle, it may cause a wireless transceiver 22 to transmit a warning. The microprocessor 20 can if required perform additional signal processing and analysis (for example, a Fourier transform analysis) of the data, or by reconfiguring DSP 18 to more closely examine specific spectrum bands. In addition, the microprocessor 20 can be responsible for controlling and scheduling communications with other nodes and/or users, or a second microprocessor can be provided for controlling a wireless transceiver 22 to perform those functions.

Many of the functions of the node, including signal processing, decision making and communication management, could be performed by separate dedicated microprocessors. Although the invention encompasses multiple microprocessor embodiments, for the sake of simplicity the figures show only one microprocessor 20 performing various functions. As used herein, microprocessor 20 should be understood to symbolize and refer to at least one microprocessor.

The transceiver 22, controlled by microprocessor 20, provides communications with a network 32 of other nodes and with a user or users 34. Communications are two-way: data (spectral or time domain) or instructions can be transmitted or received. The received data or instructions are stored by the microprocessor 20 and can be used to modify the programming of either the microprocessor 20 or the DSP 18. The invention is preferably used in a network of numerous nodes with limited power supplies: typically battery or solar cell. Low power consumption is thus preferred. At the node level power consumption is reduced by using circuitry which can frequently be held in an inactive “sleep mode” when not immediately required. The nodes also conserve energy by summarizing or analyzing data and then transmitting only the summary or result, rather than the raw data. This technique, sometimes call “pre-processing,” is effective because computation can be performed (for example, by CMOS logic) with much lower power consumption than wireless transmission of data. At the network level, communications are preferably scheduled and routed to exploit low powered, multiple hop relayed communications.

In the preferred embodiment, the several component subsections of the node (the sensors 12, the ADC 14, the DSP 18, the microprocessor 20 and the wireless transceiver 22) are all fully integrated on a chip 24, powered by a power supply 3 and housed in an enclosure 1. Such integration enables low cost manufacture and an extremely compact package. However, greater or lesser degrees of integration are possible and the resulting nodes are also within the scope of the invention.

The detailed operation and structure of the node's subsections will be discussed in sequence, beginning with the sensors 12.

A. The Sensors:

The sensor system must identify a signal in the presence of environmental noise. Source signals (such as seismic, infrared, thermal, optical, acoustic, mechanical, and others) all decay in amplitude rapidly with distance from the source. To increase the detection range, sensor sensitivity must be increased. In addition, due to the fundamental limits of background noise, a maximum detection range exists for any sensor. Thus, it may be desirable to obtain the greatest sensitivity and to utilize compact sensors that may be distributed both widely and densely. In addition, in some applications it is desirable to integrate multiple sensors (with varying characteristics) with the signal processing, control, and wireless transceiver portions of the node, thus increasing the information available from that node.

Integration of the sensors with the other electronics is preferably accomplished by conventional “flip-chip” bonding. In the “flip-chip” process a sensor die and a CMOS interface die are each fabricated. The CMOS interface die is then flipped and bonded to the sensor die, which typically includes the bulk micro-machined sensor structures. This process allows modular processing: the fabrication of the sensor die (with materials incompatible with CMOS processing) is separated from CMOS fabrication. Thus, high performance piezoelectric and pyroelectric actuator and sensor materials may be integrated with CMOS measurement and control systems without interference with CMOS fabrication.

Typical sensors which could be used in the invention are disclosed by U.S. Pat. No. 5,659,195 to William J. Kaiser. This patent discloses, for example, a CMOS integrated microaccelerometer which could be used as a seismometer or vibration sensor. Integrated microacoustic sensors and thermoelectric sensors are also disclosed by the patent. Another thermal infrared sensor suitable for use with the invention is a high sensitivity thin-film radiation thermopile sensor described by David T. Chang in “Micropower High-Detectivity Infrared Sensor System,” Solid State Sensor and Actuator Workshop (Technical Digest), TRF cat. no. 98TRF-001, Lib. of Congress no. 98-60214, ISBN no. 0-9640024-2-6, pp. 205-208 (1998). Such devices are well suited to large scale integration with the other components of a node of the present invention; however, non-integrated sensors such as geophones, acoustic detectors, thermal sensors, photoelectric detectors, or even mechanical transducers can be employed either together with or as alternatives to integrated sensors.

B. The ADC:

In a typical embodiment of the invention shown in FIG. 3 the sensors produce analog signal outputs. An ADC 14 must then be provided to convert the sensor output to digital form for processing. A Σ-Δ architecture is suitable for use in the ADC for the invention, as it provides low power and low noise operation. Although the low power constraint discourages the use of flash, pipelined, and sequential approximation architectures, any ADC architecture could be used provided that it has sufficient bandwidth and resolution for the sensor data of interest, and further provided that the ADC power consumption is not inconsistent with available power and power supply lifetime considerations.

C. The DSP:

The DSP 18 analyzes the amplitude and spectral characteristics of the signal acquired by the sensors, while improving signal-to-noise ratio for signals within spectral regions of interest. The DSP 18 can then compare amplitude and spectral characteristics of the signal with spectral profiles (either stored or communicated from a network). The results of the comparison, the spectral data, and the raw signal data are made available to the microprocessor 20. This data can be combined by the microprocessor 20 with data from other sensors, if multiple sensors are provided on the node, to extract clues as to the identity, number, size, distance and direction of the signal source (or sources).

The DSP 18 is preferably implemented with emphasis on low power. Signal processing rate may reasonably be sacrificed to enable low power continuous operation, because the bandwidth of typical sensor systems is low, for example approximately 100 Hz for a seismic vibration sensor.

FIG. 4 shows one example of an appropriate architecture for the DSP 18. In the embodiment shown, a low sampling rate, resulting from band-limited sensor response, allows the DSP unit to operate at low clock frequency (less than 100 KHz). Because the sensor signals are slowly changing, the DSP may effectively be reconfigured to reprocess the sensor signals in the event of overflow or unusual signal events. The illustrated DSP unit contains a clock divider 50 to divide a clock pulse train from clock 51 (which may operate at a frequency on the order of 100 Khz) down to a lower sampling rate which is appropriate to the sensor data of the specific application. The resulting lower clock rate is used by ADC 14 to trigger sampling of the sensor signal. The input end of the DSP can be the last stage of a Σ-Δ ADC. An up-down counter 52 counts pulses output by a Σ-Δ ADC 14. A unidirectional counter 56 controls the resolution of the ADC 14 by setting the length of time in each cycle during which counter 52 will count pulses. The output of counter 52 is then converted by converter 53 to two's complement representation with an offset of 128, for the purpose of centering the filter output around zero, and the resulting data is stored in a buffer 16.

The data stored in the buffer 16 is next processed by a spectrum analyzer 17 which is preferably a bank of digital filters. Each of the digital filters may be realized as an eight-channel, eight bit infinite impulse response (IIR) digital filter. In order to reduce the effect of truncation error, a cascaded structure of two second order IIR filters can be used, providing a four pole bandpass filter.

FIG. 5 shows a suitable four-pole configuration, a conventional direct form II realization suitable for use as a single channel of the multiple channel digital filter bank. In accordance with common convention, each of the triangles (such as 61) indicate multiplication by a specific coefficient (stored in coefficient memory 81 on FIG. 5. Circles such as 62 with a+sign indicate a summation. Boxes such as 64 marked by Z−1 indicate a memory register storing the input value latched in on the previous clock cycle. Thus, the input sensor data byte at an input terminal 65 is summed at a summation junction 66 with a number calculated by summing at summation junction 68 the contents of two registers 63 and 64 multiplied respectively by coefficients 70 and 72. The summed output of summation junction 66 is multiplied by coefficient 61 and summed at summation junction 62 with the output of summation junction 74, which sums the contents of registers 63 and 64, multiplied respectively by coefficients 76 and 78. The output of summation junction 66 is then clocked into register 63 at the end of the clock cycle, at which time the contents of 63 are clocked into register 64. (register 64 thus always holds the previous clock cycle's value from register 63.) The process is repeated with the next data byte in sequence.

The choice of coefficients 61, 70, 72, 76 and 78 for each channel determines the shape, bandwidth, and center frequency of the resulting filter function and may be calculated according by methods well known in the art. The coefficients for each spectral band are stored in memory 21. The microprocessor 20 can dynamically change the coefficients stored in memory 21, thus providing a way to dynamically reconfigure or program the spectrum analyzer 17.

FIG. 6 shows the frequency response of three exemplary bandpass filters realized in the form shown in FIG. 5, each ten Hz wide, with passband center frequencies at 5Hz, 25 Hz, and 45 Hz and an input byte rate of 100 Hz.

The spectrum analyzer 17 made up of multiple channels of bandpass filters enables spectral analysis of the input signal, by producing multiple outputs 84 each representing the spectral power density within a specific frequency band. The bandpass filters may be implemented in parallel, or arithmetic units (multipliers and adders) may be shared, saving power and chip area.

The output of the spectrum analyzer 17 is preferably accumulated in a sum-of-squares (SSQ) accumulator 80 in FIG. 4, with multiple frequency slots. In one embodiment, multiplexing allows the channels of the SSQ accumulator 80 to share a single multiplier and accumulator. Multiple separate register words accumulate the SSQ values of the multiple channels respectively. After accumulation, the SSQ values are placed consecutively on an output port to the threshold comparators 19.

The threshold comparators 19 compare each of the multiple outputs of the SSQ accumulator with thresholds stored in memory 21. The multiple outputs may be compared sequentially, using a multiplexer to sequentially compare each SSQ value to the corresponding programmed threshold. If any SSQ value falls outside of programmed parameters, for example, if it is greater than or equal to its corresponding stored threshold value, an interrupt bit 83 is set to request attention from the microprocessor 20 (also shown in FIG. 3). The power spectral densities accumulated by accumulator 80 and/or the time domain data stored in buffer 57 are also made available to the microprocessor 20 on demand from the microprocessor.

The above described apparatus for comparing an analyzed spectrum to a profile provides a way of identifying signals. For example, large heavy vehicles producing a distinctive low frequency rumble can be distinguished from other types of signal sources by reference to a pre-programmed frequency profile. In other applications, for example industrial control, it may be desirable to detect when a signal falls below a threshold, as for example when a motor fails; the threshold comparators 19 would in that case be configured to produce an interrupt output when the signal falls below the appropriate threshold.

The digital bandpass filter spectrum analyzer described above offers a simple and low power method of signal analysis; however, other methods including but not limited to Fourier transform and wavelet analysis are also possible and are within the scope of the invention. The spectrum analysis could be performed by microprocessor 20 in some embodiments, or by a separate microprocessor provided for that purpose. Such variations are also within the scope of the invention.

C. The Microprocessor:

The microprocessor 20 provides essential control, logic, and programming functions for the node. In addition to making decisions based upon the sensor data, it handles multiple tasks including communication scheduling, topology learning for the network, maintenance and updating of routing tables, calculation of range relative to neighbor nodes or targets, storage of data and relaying of communications between nodes and to or from a user 34.

All of the functions involved in communication scheduling and topology learning are controlled by the (at least one) node microprocessor. The microprocessor at each member node may, for example, have stored matrices identifying other network member nodes, their connecting communication links and scheduled time slots for transmission and reception, and their locations.

The microprocessor 20 may be any of a number of suitable commercially available microprocessors, but should preferably be chosen for low power and flexible power management functions, low cost, and adequate processing capability. For example, candidates would include the AMD “186ER,” available from Advanced Micro Devices Corp., or a low power “80186” family processor from Intel. The microprocessor should preferably be capable of temporarily operating in a low power, “sleep” mode, from which it can be “awakened” by an interrupt (generated from, for example, detection of an interesting signal). An application specific processor could be used; in such a case the design should emphasize low power and the ability to exploit low duty cycle by use of a “sleep” mode. When awakened from “sleep” mode by detection of a signal the microprocessor can make a decision regarding the signal and the appropriate course of action—whether to warn other nodes, increase data acquisition, check other spectral signatures, etc. The microprocessor should preferably also be capable of scheduling and controlling RF communications and of enabling/disabling RF and other circuits as the situation demands. If appropriate, the microprocessor may route the spectral density information from the DSP 18 and/or the buffered time domain sensor data to the RF transceiver 22 for transmission to the network. The microprocessor 20 can also control uploading or coefficients for the DSP 18 and thus may reconfigure the DSP dynamically, in response to conditions, data, received instructions or programming. For example, the microprocessor 20 can upload coefficients from the memory 21 (typically on-chip memory integral to the microprocessor) into the DSP 18 to narrow or widen the spectral region of focus, move the center frequencies (by modification of the coefficients), or load a new threshold profile for comparison with the signal. This allows the node to cooperate with other nodes in concerted tasks or data acquisition, or to modify its data processing based on the current characteristics of the sensor data.

FIG. 7 shows a sequence which can be used by the microprocessor 20 to allow the node to function in a synchronized TDMA communication scheme. The microprocessor begins by initializing processes (85) including its internal registers, pointers, memory and I/O addressing functions. Next the microprocessor 20 forms a schedule (86) for communications with neighbors. In a simple embodiment, the microprocessor 20 might consult a pre-stored schedule for initial time slot activity scheduling information. For example, the microprocessor on an individual node may compare a pre-stored identity to a pre-programmed master table or schedule to determine what time slots in a TDMA scheme are allocated to that node. In more complex self-organizing embodiments, forming a schedule may require topology learning and communication slot allocation, as discussed below (“E. Network organization”).

FIG. 8 shows a generalized timing diagram of a TDMA scheme which may be used by the invention to schedule node activities. Node activities including communication are scheduled in a repeating time frame 95, broken up into shorter time slices such as 95 a-d. Specific nodes are scheduled to transmit and receive during respective specific time slices. For example, a microprocessor on a given node may be scheduled to transmit data in slice 95 c and receive data in slice 95 d. A frame synch slice 95 a is defined by a previously programmed command which is recognized by the nodes, to allow the nodes to achieve synchronization. Other synchronization slices such as synch slices 95 e and 95 f may also be provided, to aid in maintaining timing synchrony within the frame 95.

Referring again to FIG. 7, after initialization 85 the microprocessor 20 forms a schedule (86), then sets transceiver 12 to listen for the frame synch slice 95 a. When frame synch slice 95a is received the microprocessor 20 sets an internal timer to and commences the appropriate activity according to its schedule (86). For example, if the particular node is not scheduled to receive or transmit in the upcoming slice, it would load DSP coefficients (88), then acquire sensor data (89), analyze the DSP output (90) (including detecting any alarm conditions output by threshold comparators 19); then, during the appropriately scheduled slices the microprocessor enables the transceiver to receive data and commands (91) and to transmit (92) data, including alarm conditions and relayed messages and commands to other nodes. The microprocessor then waits (93) for the next frame synch 95 a and repeats the activities 88-93 in a loop.

D.) The RF Transceiver:

In a preferred embodiment, an RF transceiver 22, under control of the microprocessor 20, provides bidirectional communication between a node and other nodes or users, for communicating data, decisions, programming or routine network protocol maintenance information. The transceiver should preferably have the ability to assume a low power consuming “off” mode when it is not needed in a time slot, so that power can be conserved in a TDMA communication scheme.

As shown in FIG. 9, the transceiver 22 includes a transmitter 96 and a receiver 97, which share an antenna 4 and power supply 3 (typically batteries). Transmitter 96 and receiver 97 are enabled/disabled by by respective enable signals 98 and 99 from microprocessor 20; a universal asynchronous receiver/ transmitter (UART) controller 40 (for example, the MAX3243CAI chip available from Maxim) handles data transfer between the receiver 97, the transmitter 96 and microprocessor 20. The receiver design should preferably provide low noise and high selectivity while maintaining low power requirements. For some protocols, the receiver should be able to operate during some period at high duty cycle to enable each node to capture randomly arriving signals.

Conventional highly integrated transceivers are available which are suitable for use in the invention. For example, commercially available chipsets would include the Rockwell Digital Cordless Telephone (DCT) chipset, based around the R900DCTM-4 or R900DCTM-3 transceiver modules. These highly integrated transceiver integrated circuits (ICs) are suitable for operation in the 902 to 928 MHz. band, and with suitable accompanying chips, commercially available from the same source, are capable of digital spread spectrum (DSS) operation. Other commercially available ICs which are suitable for use in the invention include the RX2010 receiver and HX2000 or AT1000 transmitters all from RF Monolithics, Inc. Whichever RF ICs are used, they should preferably be chosen for small size, low quiescent and peak power consumption, and short turn on/turn off times. It is most preferred that the transceiver electronics be integrated with the sensor, microprocessor, and signal processing electronics.

Although the invention is primarily discussed in the context of radio communicating wireless node, the medium of communication could be any other wireless medium, including infrared, optical, acoustic, microwave, or ultrasonic waves. Various means of modulation are all possible and within the intended scope of the invention.

E. Network Organization:

At the network level, the invention employs various techniques to minimize power consumption by the nodes and to exploit the large numbers of nodes and their density of placement. Along with the low frequency of sensor data and the more or less permanent placement of the nodes, these factors weigh in favor of a network using multi-hop routed communication within a complex topology of overlapping wireless communication neighborhoods.

In an environment of densely placed nodes, low transmission power is advantageous. It is often more power efficient to relay a message via multiple relayed low power transmissions (referred to as “multihops”) rather than one high powered long range transmission. This is a consequence of the variation of radiation intensity with distance from the transmitter, which takes the form of an inverse square or higher power function, depending on terrain. In ideal terrain, assuming a minimum inverse square attenuation, ten short, straight line path transmissions of distance d require only one tenth the power of one long transmission across 10 d (assuming omnidirectional antennas). With real terrain effects the difference is generally even more pronounced. It is therefore preferred that each transmitter operate at a power level not in excess of that required to reach only a small subset of the other nodes, relying on relayed transmissions to span the network. This also enables channel reuse by nodes out of range of one another, conserving bandwidth. Low transmission power levels also provide low probability of interception and low probability of detection, both desirable in some applications.

A synchronous multi-access protocol such as TDMA is preferred to schedule communications within the network. In this method, multiple nodes are synchronized in a repeating time frame, the parameters of which are stored in memory on or associated with the respective microprocessors 20 on each of the multiple nodes. As previously discussed, the time frame is divided into shorter time slices, which can serve as channels. For example, the transceiver on a specific node can be caused to transmit by that node's microprocessor 20 during a programmed time slot. Other nodes within transmission range of the transmitting node are controlled by their microprocessors 20 to receive data via their respective transceivers 22 during the same time slot. If the received data is earmarked for another destination node (such as a user interface node) the receiving node is controlled by its microprocessor 20 to store the message (for example in memory 21) and relay the message by re-transmitting the data through transceiver 22 during another assigned time slot. In this way data is relayed through the network and routed toward its destination, usually a node which is accessible to a user.

TDMA is advantageous in a low powered network, since both transmitters and receivers can be idled in an off or power conserving state during time intervals when not required. However, the programmability of the node microprocessor enables many other methods of organizing access to the communication medium which are also within the intended scope of the invention, including code division multiple access (CDMA) and frequency division multiple access (FDMA) as examples.

In some applications of the invention the locations of the nodes may not be known in advance of deployment, and it is highly desirable to learn the communication topology of the network which results from placement and terrain. Furthermore, in some applications it may be most desirable to operate in a distributed manner, controlled from multiple nodes, rather than from a central location. This protects the network from jamming, interference, and accidental or intentional destruction. The resulting network controls are widely distributed so the network can reconfigure to adapt to changing conditions.

In the invention, microprocessor 20 can be programmed to learn the topology and routing needs of a network, either autonomously or with user input. A variety of conventional methods may be programmed, including the “layer net protocol” suggested by A. Bhatnagar, “Layer Net: A New Self-Organizing Network Protocol,” I.E.E.E. Military Communications Conference Record, Vol. 2, pp. 845-49 (1990), or that described by A. Ephremides, “A Design Concept for Reliable Mobile Radio Networks with Frequency Hopping Signaling,” Proceedings of the I.E.E.E., vol. 75, no. 1, pp. 56-73 (1987). If a TDMA access method is used, time slots within a repeating time frame can be allocated by conventional methods such as the “Unifying Slot Assignment Protocol” (USAP) described by C. David Young, “USAP: A Unifying Dynamic Distributed Multichannel TDMA Slot assignment Protocol,” I.E.E.E. Military Communications Conference Record, Vol. 1, pp .235-39 (1996).

The aforementioned methods provide examples of distributed, autonomous methods for organizing the network communications, but in some applications even simple methods such as direct assignment of channels by a user may be useful and appropriate.

While particular embodiments of the invention have been shown and described, numerous variations and alternate embodiments will occur to those skilled in the art. Accordingly, it is intended that the invention be limited only in terms of the appended claims.
